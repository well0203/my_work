{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 90363\n",
      "val 19443\n",
      "test 19371\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-16 19:44:11,332] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-16 19:44:12,138] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-16 19:44:12,139] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-16 19:44:12,139] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-16 19:44:12,966] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-16 19:44:12,966] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-16 19:44:13,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-16 19:44:13,549] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-16 19:44:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-16 19:44:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-16 19:44:13,551] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-16 19:44:13,551] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-16 19:44:13,551] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-16 19:44:13,551] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-16 19:44:13,551] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-16 19:44:13,551] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-16 19:44:13,836] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-16 19:44:13,837] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-16 19:44:13,837] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 479.74 GB, percent = 63.6%\n",
      "[2024-05-16 19:44:13,945] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-16 19:44:13,946] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-16 19:44:13,946] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 479.69 GB, percent = 63.6%\n",
      "[2024-05-16 19:44:13,946] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-16 19:44:14,057] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-16 19:44:14,057] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-16 19:44:14,058] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 479.74 GB, percent = 63.6%\n",
      "[2024-05-16 19:44:14,058] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-16 19:44:14,058] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-16 19:44:14,058] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-16 19:44:14,058] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe764715a50>\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-16 19:44:14,059] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-16 19:44:14,060] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:14,  7.32it/s]\titers: 100, epoch: 1 | loss: 0.5444238\n",
      "\tspeed: 0.1745s/iter; left time: 6554.3007s\n",
      "199it [00:27,  7.37it/s]\titers: 200, epoch: 1 | loss: 0.4104359\n",
      "\tspeed: 0.1363s/iter; left time: 5106.3481s\n",
      "299it [00:41,  7.34it/s]\titers: 300, epoch: 1 | loss: 0.4074034\n",
      "\tspeed: 0.1357s/iter; left time: 5069.8843s\n",
      "399it [00:54,  7.36it/s]\titers: 400, epoch: 1 | loss: 0.5265598\n",
      "\tspeed: 0.1361s/iter; left time: 5071.4657s\n",
      "499it [01:08,  7.38it/s]\titers: 500, epoch: 1 | loss: 0.2807295\n",
      "\tspeed: 0.1358s/iter; left time: 5043.9680s\n",
      "599it [01:22,  7.39it/s]\titers: 600, epoch: 1 | loss: 0.5387488\n",
      "\tspeed: 0.1359s/iter; left time: 5036.1779s\n",
      "699it [01:35,  7.36it/s]\titers: 700, epoch: 1 | loss: 0.2135512\n",
      "\tspeed: 0.1362s/iter; left time: 5033.3591s\n",
      "799it [01:49,  7.37it/s]\titers: 800, epoch: 1 | loss: 0.2850479\n",
      "\tspeed: 0.1359s/iter; left time: 5008.5004s\n",
      "899it [02:03,  7.43it/s]\titers: 900, epoch: 1 | loss: 0.2934930\n",
      "\tspeed: 0.1363s/iter; left time: 5009.1247s\n",
      "999it [02:16,  7.42it/s]\titers: 1000, epoch: 1 | loss: 0.2978153\n",
      "\tspeed: 0.1348s/iter; left time: 4941.1510s\n",
      "1099it [02:30,  7.40it/s]\titers: 1100, epoch: 1 | loss: 0.2092738\n",
      "\tspeed: 0.1364s/iter; left time: 4985.9823s\n",
      "1199it [02:43,  7.41it/s]\titers: 1200, epoch: 1 | loss: 0.1737960\n",
      "\tspeed: 0.1349s/iter; left time: 4918.5710s\n",
      "1299it [02:57,  7.41it/s]\titers: 1300, epoch: 1 | loss: 0.1932664\n",
      "\tspeed: 0.1348s/iter; left time: 4900.1357s\n",
      "1399it [03:10,  7.42it/s]\titers: 1400, epoch: 1 | loss: 0.2342813\n",
      "\tspeed: 0.1349s/iter; left time: 4891.0240s\n",
      "1499it [03:24,  7.38it/s]\titers: 1500, epoch: 1 | loss: 0.4414093\n",
      "\tspeed: 0.1350s/iter; left time: 4878.7582s\n",
      "1599it [03:37,  7.38it/s]\titers: 1600, epoch: 1 | loss: 0.4585559\n",
      "\tspeed: 0.1364s/iter; left time: 4916.3070s\n",
      "1699it [03:51,  7.36it/s]\titers: 1700, epoch: 1 | loss: 0.2643373\n",
      "\tspeed: 0.1361s/iter; left time: 4891.7086s\n",
      "1799it [04:04,  7.43it/s]\titers: 1800, epoch: 1 | loss: 0.2432564\n",
      "\tspeed: 0.1358s/iter; left time: 4869.0283s\n",
      "1899it [04:18,  7.42it/s]\titers: 1900, epoch: 1 | loss: 0.1711638\n",
      "\tspeed: 0.1347s/iter; left time: 4815.2909s\n",
      "1999it [04:31,  7.36it/s]\titers: 2000, epoch: 1 | loss: 0.1636032\n",
      "\tspeed: 0.1350s/iter; left time: 4811.7229s\n",
      "2099it [04:45,  7.38it/s]\titers: 2100, epoch: 1 | loss: 0.2445004\n",
      "\tspeed: 0.1357s/iter; left time: 4823.9708s\n",
      "2199it [04:59,  7.36it/s]\titers: 2200, epoch: 1 | loss: 0.4539610\n",
      "\tspeed: 0.1363s/iter; left time: 4830.9949s\n",
      "2299it [05:12,  7.34it/s]\titers: 2300, epoch: 1 | loss: 0.2724272\n",
      "\tspeed: 0.1368s/iter; left time: 4837.7720s\n",
      "2399it [05:26,  7.39it/s]\titers: 2400, epoch: 1 | loss: 0.4076100\n",
      "\tspeed: 0.1367s/iter; left time: 4817.4510s\n",
      "2499it [05:40,  7.33it/s]\titers: 2500, epoch: 1 | loss: 0.1925327\n",
      "\tspeed: 0.1360s/iter; left time: 4781.2800s\n",
      "2599it [05:53,  7.37it/s]\titers: 2600, epoch: 1 | loss: 0.3031555\n",
      "\tspeed: 0.1366s/iter; left time: 4788.3093s\n",
      "2699it [06:07,  7.35it/s]\titers: 2700, epoch: 1 | loss: 0.4735817\n",
      "\tspeed: 0.1362s/iter; left time: 4761.3737s\n",
      "2799it [06:20,  7.37it/s]\titers: 2800, epoch: 1 | loss: 0.2143671\n",
      "\tspeed: 0.1363s/iter; left time: 4748.5502s\n",
      "2899it [06:34,  7.21it/s]\titers: 2900, epoch: 1 | loss: 0.3639215\n",
      "\tspeed: 0.1360s/iter; left time: 4726.7645s\n",
      "2999it [06:48,  7.36it/s]\titers: 3000, epoch: 1 | loss: 0.3485069\n",
      "\tspeed: 0.1362s/iter; left time: 4720.3578s\n",
      "3099it [07:01,  7.37it/s]\titers: 3100, epoch: 1 | loss: 0.2981286\n",
      "\tspeed: 0.1357s/iter; left time: 4689.2952s\n",
      "3199it [07:15,  7.38it/s]\titers: 3200, epoch: 1 | loss: 0.4006509\n",
      "\tspeed: 0.1357s/iter; left time: 4675.5226s\n",
      "3299it [07:28,  7.38it/s]\titers: 3300, epoch: 1 | loss: 0.2170447\n",
      "\tspeed: 0.1357s/iter; left time: 4660.0974s\n",
      "3399it [07:42,  7.35it/s]\titers: 3400, epoch: 1 | loss: 0.3905250\n",
      "\tspeed: 0.1368s/iter; left time: 4684.5064s\n",
      "3499it [07:56,  7.35it/s]\titers: 3500, epoch: 1 | loss: 0.2816363\n",
      "\tspeed: 0.1365s/iter; left time: 4662.2885s\n",
      "3599it [08:09,  7.38it/s]\titers: 3600, epoch: 1 | loss: 0.3380325\n",
      "\tspeed: 0.1355s/iter; left time: 4615.1793s\n",
      "3699it [08:23,  7.36it/s]\titers: 3700, epoch: 1 | loss: 0.2030608\n",
      "\tspeed: 0.1359s/iter; left time: 4612.9207s\n",
      "3765it [08:32,  7.35it/s]\n",
      "Epoch: 1 cost time: 512.4030148983002\n",
      "810it [00:54, 14.77it/s]\n",
      "807it [00:54, 14.76it/s]\n",
      "Epoch: 1 | Train Loss: 0.3081911 Vali Loss: 0.3295813 Test Loss: 0.3944334 MAE Loss: 0.3974499\n",
      "Validation loss decreased (inf --> 0.329581).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:13,  7.59it/s]\titers: 100, epoch: 2 | loss: 0.1639574\n",
      "\tspeed: 1.3308s/iter; left time: 44962.5603s\n",
      "199it [00:26,  7.59it/s]\titers: 200, epoch: 2 | loss: 0.5405571\n",
      "\tspeed: 0.1321s/iter; left time: 4451.6021s\n",
      "299it [00:39,  7.22it/s]\titers: 300, epoch: 2 | loss: 0.1843774\n",
      "\tspeed: 0.1328s/iter; left time: 4459.3794s\n",
      "399it [00:53,  7.59it/s]\titers: 400, epoch: 2 | loss: 0.1597055\n",
      "\tspeed: 0.1320s/iter; left time: 4421.7719s\n",
      "499it [01:06,  7.53it/s]\titers: 500, epoch: 2 | loss: 0.2466474\n",
      "\tspeed: 0.1328s/iter; left time: 4434.4015s\n",
      "599it [01:19,  7.57it/s]\titers: 600, epoch: 2 | loss: 0.1386792\n",
      "\tspeed: 0.1323s/iter; left time: 4404.3537s\n",
      "699it [01:32,  7.57it/s]\titers: 700, epoch: 2 | loss: 0.4463665\n",
      "\tspeed: 0.1325s/iter; left time: 4397.6110s\n",
      "799it [01:46,  7.44it/s]\titers: 800, epoch: 2 | loss: 0.2692041\n",
      "\tspeed: 0.1321s/iter; left time: 4370.2985s\n",
      "899it [01:59,  7.59it/s]\titers: 900, epoch: 2 | loss: 0.3635383\n",
      "\tspeed: 0.1324s/iter; left time: 4366.5591s\n",
      "999it [02:12,  7.55it/s]\titers: 1000, epoch: 2 | loss: 0.3119984\n",
      "\tspeed: 0.1320s/iter; left time: 4339.7068s\n",
      "1099it [02:25,  7.47it/s]\titers: 1100, epoch: 2 | loss: 0.6365123\n",
      "\tspeed: 0.1324s/iter; left time: 4339.7744s\n",
      "1199it [02:39,  7.60it/s]\titers: 1200, epoch: 2 | loss: 0.3789161\n",
      "\tspeed: 0.1319s/iter; left time: 4312.3449s\n",
      "1299it [02:52,  7.56it/s]\titers: 1300, epoch: 2 | loss: 0.2570554\n",
      "\tspeed: 0.1322s/iter; left time: 4306.4677s\n",
      "1399it [03:05,  7.58it/s]\titers: 1400, epoch: 2 | loss: 0.1983924\n",
      "\tspeed: 0.1319s/iter; left time: 4283.5818s\n",
      "1499it [03:18,  7.57it/s]\titers: 1500, epoch: 2 | loss: 0.1906707\n",
      "\tspeed: 0.1320s/iter; left time: 4273.7912s\n",
      "1599it [03:31,  7.57it/s]\titers: 1600, epoch: 2 | loss: 0.2400161\n",
      "\tspeed: 0.1321s/iter; left time: 4266.4344s\n",
      "1699it [03:45,  7.62it/s]\titers: 1700, epoch: 2 | loss: 0.3308109\n",
      "\tspeed: 0.1322s/iter; left time: 4255.2711s\n",
      "1799it [03:58,  7.58it/s]\titers: 1800, epoch: 2 | loss: 0.3109717\n",
      "\tspeed: 0.1318s/iter; left time: 4228.7816s\n",
      "1899it [04:11,  7.59it/s]\titers: 1900, epoch: 2 | loss: 0.1874094\n",
      "\tspeed: 0.1322s/iter; left time: 4227.3428s\n",
      "1999it [04:24,  7.55it/s]\titers: 2000, epoch: 2 | loss: 0.2633019\n",
      "\tspeed: 0.1320s/iter; left time: 4209.7489s\n",
      "2099it [04:37,  7.61it/s]\titers: 2100, epoch: 2 | loss: 0.1405029\n",
      "\tspeed: 0.1319s/iter; left time: 4192.4973s\n",
      "2199it [04:51,  7.58it/s]\titers: 2200, epoch: 2 | loss: 0.3681089\n",
      "\tspeed: 0.1320s/iter; left time: 4184.0048s\n",
      "2299it [05:04,  7.34it/s]\titers: 2300, epoch: 2 | loss: 0.1729460\n",
      "\tspeed: 0.1334s/iter; left time: 4214.2706s\n",
      "2399it [05:17,  7.50it/s]\titers: 2400, epoch: 2 | loss: 0.1386145\n",
      "\tspeed: 0.1335s/iter; left time: 4203.9278s\n",
      "2499it [05:31,  7.55it/s]\titers: 2500, epoch: 2 | loss: 0.2711107\n",
      "\tspeed: 0.1329s/iter; left time: 4171.2821s\n",
      "2599it [05:44,  7.52it/s]\titers: 2600, epoch: 2 | loss: 0.2899007\n",
      "\tspeed: 0.1330s/iter; left time: 4160.7598s\n",
      "2699it [05:57,  7.54it/s]\titers: 2700, epoch: 2 | loss: 0.1953906\n",
      "\tspeed: 0.1326s/iter; left time: 4136.6706s\n",
      "2799it [06:10,  7.51it/s]\titers: 2800, epoch: 2 | loss: 0.1765995\n",
      "\tspeed: 0.1332s/iter; left time: 4142.2019s\n",
      "2899it [06:24,  7.52it/s]\titers: 2900, epoch: 2 | loss: 0.2706118\n",
      "\tspeed: 0.1329s/iter; left time: 4117.3060s\n",
      "2999it [06:37,  7.58it/s]\titers: 3000, epoch: 2 | loss: 0.2374129\n",
      "\tspeed: 0.1325s/iter; left time: 4092.8108s\n",
      "3099it [06:50,  7.30it/s]\titers: 3100, epoch: 2 | loss: 0.3832311\n",
      "\tspeed: 0.1341s/iter; left time: 4127.1200s\n",
      "3199it [07:04,  7.55it/s]\titers: 3200, epoch: 2 | loss: 0.4006540\n",
      "\tspeed: 0.1333s/iter; left time: 4090.0951s\n",
      "3299it [07:17,  7.53it/s]\titers: 3300, epoch: 2 | loss: 0.2149494\n",
      "\tspeed: 0.1328s/iter; left time: 4060.6090s\n",
      "3399it [07:30,  7.28it/s]\titers: 3400, epoch: 2 | loss: 0.2486580\n",
      "\tspeed: 0.1327s/iter; left time: 4044.7987s\n",
      "3499it [07:44,  7.54it/s]\titers: 3500, epoch: 2 | loss: 0.2286827\n",
      "\tspeed: 0.1330s/iter; left time: 4041.7779s\n",
      "3599it [07:57,  7.50it/s]\titers: 3600, epoch: 2 | loss: 0.3397874\n",
      "\tspeed: 0.1336s/iter; left time: 4045.8610s\n",
      "3699it [08:10,  7.40it/s]\titers: 3700, epoch: 2 | loss: 0.2991925\n",
      "\tspeed: 0.1330s/iter; left time: 4013.4711s\n",
      "3765it [08:19,  7.54it/s]\n",
      "Epoch: 2 cost time: 499.4950647354126\n",
      "810it [00:52, 15.56it/s]\n",
      "807it [00:51, 15.59it/s]\n",
      "Epoch: 2 | Train Loss: 0.2648553 Vali Loss: 0.3046619 Test Loss: 0.3734396 MAE Loss: 0.3793366\n",
      "Validation loss decreased (0.329581 --> 0.304662).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:13,  7.49it/s]\titers: 100, epoch: 3 | loss: 0.2093413\n",
      "\tspeed: 1.2722s/iter; left time: 38193.9278s\n",
      "199it [00:26,  7.54it/s]\titers: 200, epoch: 3 | loss: 0.2412249\n",
      "\tspeed: 0.1330s/iter; left time: 3979.2402s\n",
      "299it [00:40,  7.54it/s]\titers: 300, epoch: 3 | loss: 0.2878701\n",
      "\tspeed: 0.1325s/iter; left time: 3950.3112s\n",
      "399it [00:53,  7.52it/s]\titers: 400, epoch: 3 | loss: 0.2571405\n",
      "\tspeed: 0.1323s/iter; left time: 3931.7609s\n",
      "499it [01:06,  7.55it/s]\titers: 500, epoch: 3 | loss: 0.1948572\n",
      "\tspeed: 0.1327s/iter; left time: 3929.9438s\n",
      "599it [01:19,  7.55it/s]\titers: 600, epoch: 3 | loss: 0.1865165\n",
      "\tspeed: 0.1327s/iter; left time: 3917.2771s\n",
      "699it [01:33,  7.55it/s]\titers: 700, epoch: 3 | loss: 0.2182564\n",
      "\tspeed: 0.1338s/iter; left time: 3937.6387s\n",
      "799it [01:46,  7.53it/s]\titers: 800, epoch: 3 | loss: 0.1523785\n",
      "\tspeed: 0.1334s/iter; left time: 3912.8294s\n",
      "899it [01:59,  7.58it/s]\titers: 900, epoch: 3 | loss: 0.3450936\n",
      "\tspeed: 0.1327s/iter; left time: 3878.8543s\n",
      "999it [02:13,  7.53it/s]\titers: 1000, epoch: 3 | loss: 0.1820113\n",
      "\tspeed: 0.1327s/iter; left time: 3863.9830s\n",
      "1099it [02:26,  7.56it/s]\titers: 1100, epoch: 3 | loss: 0.2890514\n",
      "\tspeed: 0.1329s/iter; left time: 3857.0475s\n",
      "1199it [02:39,  7.52it/s]\titers: 1200, epoch: 3 | loss: 0.1903125\n",
      "\tspeed: 0.1332s/iter; left time: 3852.9397s\n",
      "1299it [02:52,  7.53it/s]\titers: 1300, epoch: 3 | loss: 0.1512738\n",
      "\tspeed: 0.1326s/iter; left time: 3820.6317s\n",
      "1399it [03:06,  7.54it/s]\titers: 1400, epoch: 3 | loss: 0.1770290\n",
      "\tspeed: 0.1325s/iter; left time: 3804.2849s\n",
      "1499it [03:19,  7.53it/s]\titers: 1500, epoch: 3 | loss: 0.2750645\n",
      "\tspeed: 0.1327s/iter; left time: 3797.5773s\n",
      "1599it [03:32,  7.53it/s]\titers: 1600, epoch: 3 | loss: 0.2504632\n",
      "\tspeed: 0.1327s/iter; left time: 3784.2435s\n",
      "1699it [03:46,  7.58it/s]\titers: 1700, epoch: 3 | loss: 0.2141457\n",
      "\tspeed: 0.1327s/iter; left time: 3770.6069s\n",
      "1799it [03:59,  7.55it/s]\titers: 1800, epoch: 3 | loss: 0.1819759\n",
      "\tspeed: 0.1331s/iter; left time: 3768.2339s\n",
      "1899it [04:12,  7.57it/s]\titers: 1900, epoch: 3 | loss: 0.2926572\n",
      "\tspeed: 0.1326s/iter; left time: 3742.9956s\n",
      "1999it [04:25,  7.54it/s]\titers: 2000, epoch: 3 | loss: 0.2725919\n",
      "\tspeed: 0.1326s/iter; left time: 3729.4863s\n",
      "2099it [04:39,  7.57it/s]\titers: 2100, epoch: 3 | loss: 0.2264288\n",
      "\tspeed: 0.1321s/iter; left time: 3701.1604s\n",
      "2199it [04:52,  7.59it/s]\titers: 2200, epoch: 3 | loss: 0.1622341\n",
      "\tspeed: 0.1329s/iter; left time: 3710.8892s\n",
      "2299it [05:05,  7.50it/s]\titers: 2300, epoch: 3 | loss: 0.2355407\n",
      "\tspeed: 0.1328s/iter; left time: 3695.2239s\n",
      "2399it [05:18,  7.55it/s]\titers: 2400, epoch: 3 | loss: 0.2252967\n",
      "\tspeed: 0.1321s/iter; left time: 3661.5852s\n",
      "2499it [05:32,  7.57it/s]\titers: 2500, epoch: 3 | loss: 0.1823240\n",
      "\tspeed: 0.1322s/iter; left time: 3651.4408s\n",
      "2599it [05:45,  7.59it/s]\titers: 2600, epoch: 3 | loss: 0.1959126\n",
      "\tspeed: 0.1320s/iter; left time: 3633.1091s\n",
      "2699it [05:58,  7.57it/s]\titers: 2700, epoch: 3 | loss: 0.3472180\n",
      "\tspeed: 0.1319s/iter; left time: 3617.7800s\n",
      "2799it [06:11,  7.57it/s]\titers: 2800, epoch: 3 | loss: 0.1436818\n",
      "\tspeed: 0.1321s/iter; left time: 3610.0668s\n",
      "2899it [06:24,  7.57it/s]\titers: 2900, epoch: 3 | loss: 0.2979626\n",
      "\tspeed: 0.1322s/iter; left time: 3598.7545s\n",
      "2999it [06:38,  7.53it/s]\titers: 3000, epoch: 3 | loss: 0.1734074\n",
      "\tspeed: 0.1324s/iter; left time: 3591.6529s\n",
      "3099it [06:51,  7.53it/s]\titers: 3100, epoch: 3 | loss: 0.1960131\n",
      "\tspeed: 0.1329s/iter; left time: 3590.0403s\n",
      "3199it [07:04,  7.57it/s]\titers: 3200, epoch: 3 | loss: 0.2625073\n",
      "\tspeed: 0.1325s/iter; left time: 3567.7611s\n",
      "3299it [07:17,  7.57it/s]\titers: 3300, epoch: 3 | loss: 0.2109915\n",
      "\tspeed: 0.1323s/iter; left time: 3547.2994s\n",
      "3399it [07:31,  7.57it/s]\titers: 3400, epoch: 3 | loss: 0.1227532\n",
      "\tspeed: 0.1321s/iter; left time: 3529.1480s\n",
      "3499it [07:44,  7.52it/s]\titers: 3500, epoch: 3 | loss: 0.3649703\n",
      "\tspeed: 0.1322s/iter; left time: 3519.1234s\n",
      "3599it [07:57,  7.56it/s]\titers: 3600, epoch: 3 | loss: 0.1288858\n",
      "\tspeed: 0.1332s/iter; left time: 3531.4956s\n",
      "3699it [08:10,  7.60it/s]\titers: 3700, epoch: 3 | loss: 0.1547276\n",
      "\tspeed: 0.1320s/iter; left time: 3487.0944s\n",
      "3765it [08:19,  7.54it/s]\n",
      "Epoch: 3 cost time: 499.6046266555786\n",
      "810it [00:51, 15.59it/s]\n",
      "807it [00:52, 15.38it/s]\n",
      "Epoch: 3 | Train Loss: 0.2490945 Vali Loss: 0.2926479 Test Loss: 0.3656700 MAE Loss: 0.3646462\n",
      "Validation loss decreased (0.304662 --> 0.292648).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "99it [00:13,  7.56it/s]\titers: 100, epoch: 4 | loss: 0.2759263\n",
      "\tspeed: 1.2780s/iter; left time: 33555.4243s\n",
      "199it [00:26,  7.59it/s]\titers: 200, epoch: 4 | loss: 0.2688626\n",
      "\tspeed: 0.1323s/iter; left time: 3461.6520s\n",
      "299it [00:39,  7.59it/s]\titers: 300, epoch: 4 | loss: 0.1620458\n",
      "\tspeed: 0.1320s/iter; left time: 3439.2737s\n",
      "399it [00:53,  7.58it/s]\titers: 400, epoch: 4 | loss: 0.3921472\n",
      "\tspeed: 0.1322s/iter; left time: 3431.5047s\n",
      "499it [01:06,  7.58it/s]\titers: 500, epoch: 4 | loss: 0.3646387\n",
      "\tspeed: 0.1322s/iter; left time: 3418.5346s\n",
      "599it [01:19,  7.56it/s]\titers: 600, epoch: 4 | loss: 0.3020435\n",
      "\tspeed: 0.1324s/iter; left time: 3409.0587s\n",
      "699it [01:32,  7.55it/s]\titers: 700, epoch: 4 | loss: 0.2508266\n",
      "\tspeed: 0.1329s/iter; left time: 3410.1556s\n",
      "799it [01:46,  7.55it/s]\titers: 800, epoch: 4 | loss: 0.3295434\n",
      "\tspeed: 0.1327s/iter; left time: 3390.8359s\n",
      "899it [01:59,  7.57it/s]\titers: 900, epoch: 4 | loss: 0.1927819\n",
      "\tspeed: 0.1321s/iter; left time: 3362.3725s\n",
      "999it [02:12,  7.58it/s]\titers: 1000, epoch: 4 | loss: 0.2571589\n",
      "\tspeed: 0.1324s/iter; left time: 3357.3529s\n",
      "1099it [02:25,  7.59it/s]\titers: 1100, epoch: 4 | loss: 0.2878469\n",
      "\tspeed: 0.1325s/iter; left time: 3346.0604s\n",
      "1199it [02:39,  7.60it/s]\titers: 1200, epoch: 4 | loss: 0.3565212\n",
      "\tspeed: 0.1324s/iter; left time: 3329.8223s\n",
      "1299it [02:52,  7.46it/s]\titers: 1300, epoch: 4 | loss: 0.2147350\n",
      "\tspeed: 0.1335s/iter; left time: 3346.1436s\n",
      "1399it [03:05,  7.53it/s]\titers: 1400, epoch: 4 | loss: 0.2387441\n",
      "\tspeed: 0.1333s/iter; left time: 3326.5425s\n",
      "1499it [03:19,  7.57it/s]\titers: 1500, epoch: 4 | loss: 0.4468493\n",
      "\tspeed: 0.1328s/iter; left time: 3301.8544s\n",
      "1599it [03:32,  7.57it/s]\titers: 1600, epoch: 4 | loss: 0.1831624\n",
      "\tspeed: 0.1320s/iter; left time: 3267.2144s\n",
      "1699it [03:45,  7.57it/s]\titers: 1700, epoch: 4 | loss: 0.5170913\n",
      "\tspeed: 0.1322s/iter; left time: 3258.4198s\n",
      "1799it [03:58,  7.54it/s]\titers: 1800, epoch: 4 | loss: 0.2346326\n",
      "\tspeed: 0.1321s/iter; left time: 3244.4253s\n",
      "1899it [04:11,  7.59it/s]\titers: 1900, epoch: 4 | loss: 0.3640767\n",
      "\tspeed: 0.1320s/iter; left time: 3229.3617s\n",
      "1999it [04:25,  7.56it/s]\titers: 2000, epoch: 4 | loss: 0.3537697\n",
      "\tspeed: 0.1321s/iter; left time: 3216.8289s\n",
      "2099it [04:38,  7.56it/s]\titers: 2100, epoch: 4 | loss: 0.2310031\n",
      "\tspeed: 0.1321s/iter; left time: 3205.3738s\n",
      "2199it [04:51,  7.55it/s]\titers: 2200, epoch: 4 | loss: 0.3086650\n",
      "\tspeed: 0.1326s/iter; left time: 3202.0230s\n",
      "2299it [05:04,  7.58it/s]\titers: 2300, epoch: 4 | loss: 0.3222348\n",
      "\tspeed: 0.1324s/iter; left time: 3185.2207s\n",
      "2399it [05:18,  7.56it/s]\titers: 2400, epoch: 4 | loss: 0.2270203\n",
      "\tspeed: 0.1323s/iter; left time: 3168.5461s\n",
      "2499it [05:31,  7.51it/s]\titers: 2500, epoch: 4 | loss: 0.1147346\n",
      "\tspeed: 0.1341s/iter; left time: 3199.6179s\n",
      "2599it [05:44,  7.55it/s]\titers: 2600, epoch: 4 | loss: 0.2836791\n",
      "\tspeed: 0.1322s/iter; left time: 3140.1287s\n",
      "2699it [05:57,  7.56it/s]\titers: 2700, epoch: 4 | loss: 0.1636396\n",
      "\tspeed: 0.1321s/iter; left time: 3125.3402s\n",
      "2799it [06:11,  7.57it/s]\titers: 2800, epoch: 4 | loss: 0.2994059\n",
      "\tspeed: 0.1322s/iter; left time: 3114.6640s\n",
      "2899it [06:24,  7.54it/s]\titers: 2900, epoch: 4 | loss: 0.3039326\n",
      "\tspeed: 0.1325s/iter; left time: 3108.2394s\n",
      "2999it [06:37,  7.35it/s]\titers: 3000, epoch: 4 | loss: 0.2165833\n",
      "\tspeed: 0.1327s/iter; left time: 3099.0823s\n",
      "3099it [06:50,  7.58it/s]\titers: 3100, epoch: 4 | loss: 0.2040674\n",
      "\tspeed: 0.1330s/iter; left time: 3093.5986s\n",
      "3199it [07:04,  7.56it/s]\titers: 3200, epoch: 4 | loss: 0.1911794\n",
      "\tspeed: 0.1331s/iter; left time: 3081.1424s\n",
      "3299it [07:17,  7.52it/s]\titers: 3300, epoch: 4 | loss: 0.2202309\n",
      "\tspeed: 0.1334s/iter; left time: 3075.5599s\n",
      "3399it [07:30,  7.54it/s]\titers: 3400, epoch: 4 | loss: 0.1280185\n",
      "\tspeed: 0.1326s/iter; left time: 3044.0447s\n",
      "3499it [07:44,  7.54it/s]\titers: 3500, epoch: 4 | loss: 0.2306248\n",
      "\tspeed: 0.1328s/iter; left time: 3034.3671s\n",
      "3599it [07:57,  7.54it/s]\titers: 3600, epoch: 4 | loss: 0.1040642\n",
      "\tspeed: 0.1335s/iter; left time: 3037.8985s\n",
      "3699it [08:10,  7.53it/s]\titers: 3700, epoch: 4 | loss: 0.2552805\n",
      "\tspeed: 0.1321s/iter; left time: 2991.8523s\n",
      "3765it [08:19,  7.54it/s]\n",
      "Epoch: 4 cost time: 499.4989092350006\n",
      "810it [00:51, 15.58it/s]\n",
      "807it [00:52, 15.47it/s]\n",
      "Epoch: 4 | Train Loss: 0.2373823 Vali Loss: 0.2769820 Test Loss: 0.3434146 MAE Loss: 0.3444500\n",
      "Validation loss decreased (0.292648 --> 0.276982).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "learning_rate 0.001\n",
      "lr 3.9999999999999996e-05\n",
      "60it [00:08,  7.52it/s]^C\n",
      "60it [00:08,  7.17it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/./Time-LLM/run_main.py\", line 234, in <module>\n",
      "    \n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1852, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 242, in forward\n",
      "    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/my_work/Time-LLM/models/TimeLLM.py\", line 280, in forecast\n",
      "    prompt = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).input_ids\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2577, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2663, in _call_one\n",
      "    return self.batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2854, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 733, in _batch_encode_plus\n",
      "    first_ids = get_input_ids(ids)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 701, in get_input_ids\n",
      "    return self.convert_tokens_to_ids(tokens)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 579, in convert_tokens_to_ids\n",
      "    ids.append(self._convert_token_to_id_with_added_voc(token))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/cs-hu/riabchuv/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 582, in _convert_token_to_id_with_added_voc\n",
      "    def _convert_token_to_id_with_added_voc(self, token):\n",
      "\n",
      "KeyboardInterrupt\n",
      "Total time: 41.04080427090327 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=10\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='TimeLLM-FR'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path FR_data.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data FR \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "train 695\n",
      "val 195\n",
      "test 75\n",
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n",
      "[2024-05-16 23:51:06,607] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-16 23:51:07,637] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-05-16 23:51:07,637] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-05-16 23:51:07,638] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-05-16 23:51:08,481] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.164, master_port=29500\n",
      "[2024-05-16 23:51:08,482] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-05-16 23:51:09,247] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-05-16 23:51:09,248] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-05-16 23:51:09,248] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-05-16 23:51:09,249] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-05-16 23:51:09,249] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-05-16 23:51:09,249] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-05-16 23:51:09,249] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-05-16 23:51:09,250] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-05-16 23:51:09,250] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-05-16 23:51:09,250] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-05-16 23:51:09,524] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-05-16 23:51:09,525] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.56 GB         CA 0.57 GB         Max_CA 1 GB \n",
      "[2024-05-16 23:51:09,525] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 57.43 GB, percent = 7.6%\n",
      "[2024-05-16 23:51:09,631] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-05-16 23:51:09,632] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.66 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-16 23:51:09,632] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 57.44 GB, percent = 7.6%\n",
      "[2024-05-16 23:51:09,632] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-05-16 23:51:09,735] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-05-16 23:51:09,735] [INFO] [utils.py:801:see_memory_usage] MA 0.46 GB         Max_MA 0.46 GB         CA 0.77 GB         Max_CA 1 GB \n",
      "[2024-05-16 23:51:09,735] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 57.44 GB, percent = 7.6%\n",
      "[2024-05-16 23:51:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-05-16 23:51:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-05-16 23:51:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-05-16 23:51:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-05-16 23:51:09,736] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9442402a50>\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-05-16 23:51:09,737] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   train_batch_size ............. 24\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  24\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-05-16 23:51:09,738] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 24, \n",
      "    \"train_micro_batch_size_per_gpu\": 24, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "28it [00:04,  6.66it/s]\n",
      "Epoch: 1 cost time: 4.20566725730896\n",
      "8it [00:00,  9.11it/s]\n",
      "3it [00:00,  6.03it/s]\n",
      "Epoch: 1 | Train Loss: 1.4741421 Vali Loss: 0.5478141 Test Loss: 0.4153075 MAE Loss: 0.4097095\n",
      "Validation loss decreased (inf --> 0.547814).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "28it [00:03,  7.55it/s]\n",
      "Epoch: 2 cost time: 3.7086031436920166\n",
      "8it [00:00,  9.27it/s]\n",
      "3it [00:00,  6.89it/s]\n",
      "Epoch: 2 | Train Loss: 1.2331938 Vali Loss: 0.3760620 Test Loss: 0.2861228 MAE Loss: 0.3509554\n",
      "Validation loss decreased (0.547814 --> 0.376062).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "3it [00:00,  3.22it/s]\n",
      "mse:0.28612278401851654, mae:0.35095538198947906\n",
      "train_losses [1.4741421192884445, 1.2331938381705965]\n",
      "val_losses [0.5478140860795975, 0.3760619945824146]\n",
      "Total time: 0.5582523663838704 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set the logging level for the `accelerate` library (or its submodules) to a higher level like `WARNING` or `ERROR`. This will suppress informational messages like the ones you're seeing.\n",
    "\n",
    "#logging.getLogger('accelerator').setLevel(logging.WARNING)  # Adjust level as needed\n",
    "logging.getLogger('DeepSpeed').setLevel(logging.WARNING)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_epochs=2\n",
    "learning_rate=0.001\n",
    "llama_layers=6\n",
    "\n",
    "# num_process=1\n",
    "batch_size=24\n",
    "d_model=32\n",
    "d_ff=128\n",
    "# --num_processes 1 --num_machines 1\n",
    "comment='GB_data_small'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "!accelerate launch --mixed_precision bf16 --num_processes=1 --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./datasets/ \\\n",
    "  --data_path GB_data_small.csv \\\n",
    "  --model_id 1 \\\n",
    "  --model \"TimeLLM\" \\\n",
    "  --data GB \\\n",
    "  --features M \\\n",
    "  --seq_len 20 \\\n",
    "  --label_len 10 \\\n",
    "  --pred_len 10 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 3 \\\n",
    "  --dec_in 3 \\\n",
    "  --c_out 3 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model \"GPT2\" \\\n",
    "  --llm_dim 768 \\\n",
    "  --d_model $d_model \\\n",
    "  --d_ff $d_ff \\\n",
    "  --batch_size $batch_size \\\n",
    "  --learning_rate $learning_rate \\\n",
    "  --llm_layers $llama_layers \\\n",
    "  --train_epochs $train_epochs \\\n",
    "  --model_comment $comment\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 16 16:02:30 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             36W /  250W |   18158MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off |   00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             35W /  250W |    1287MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                Off |   00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   26C    P8             13W /  250W |       8MiB /  23040MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    0   N/A  N/A     67979      C   ...1/reinbene/bene/MA/myenv/bin/python       9316MiB |\n",
      "|    0   N/A  N/A     73599      C   ...1/reinbene/bene/MA/myenv/bin/python       8824MiB |\n",
      "|    1   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    1   N/A  N/A     73599      C   ...1/reinbene/bene/MA/myenv/bin/python       1278MiB |\n",
      "|    2   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "\n",
    "args = dotdict()\n",
    "\n",
    "args.task_name = \"long_term_forecast\"\n",
    "args.is_training = 1\n",
    "args.model_id = 1\n",
    "args.model_comment = \"TimeLLM-FR\"\n",
    "args.model = \"TimeLLM\"\n",
    "args.seed = 2021\n",
    "args.data = \"FR\"\n",
    "args.root_path = \"./datasets/\"\n",
    "args.data_path = \"FR_data.csv\"\n",
    "args.features = \"M\"\n",
    "args.target = \"OT\"\n",
    "args.loader = \"modal\"\n",
    "args.freq = \"h\"\n",
    "args.checkpoints = \"./checkpoints/\"\n",
    "args.seq_len = 96\n",
    "args.label_len = 48\n",
    "args.pred_len = 24\n",
    "args.seasonal_patterns = \"Monthly\"\n",
    "args.enc_in = 3\n",
    "args.dec_in = 3\n",
    "args.c_out = 3\n",
    "args.d_model = 32\n",
    "args.n_heads = 8\n",
    "args.e_layers = 2\n",
    "args.d_layers = 1\n",
    "args.d_ff = 128\n",
    "args.moving_avg = 25\n",
    "args.factor = 3\n",
    "args.dropout = 0.1\n",
    "args.embed = \"timeF\"\n",
    "args.activation = \"gelu\"\n",
    "args.output_attention = False\n",
    "args.patch_len = 16\n",
    "args.stride = 8\n",
    "args.prompt_domain = 0\n",
    "args.llm_model = \"GPT2\"\n",
    "args.llm_dim = 768\n",
    "args.num_workers = 10\n",
    "args.itr = 1\n",
    "args.train_epochs = 20\n",
    "args.align_epochs = 10\n",
    "args.batch_size = 24\n",
    "args.eval_batch_size = 8\n",
    "args.patience = 3\n",
    "args.learning_rate = 0.001\n",
    "args.des = \"Exp\"\n",
    "args.loss = \"MSE\"\n",
    "args.lradj = \"type1\"\n",
    "args.pct_start = 0.2\n",
    "args.use_amp = False\n",
    "args.llm_layers = 6\n",
    "args.percent = 100\n",
    "args.content = \"Hourly data detailing load, solar generation, and wind generation in France. Wind generation is onshore wind eneration.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly data detailing load (electricity consumption), solar generation, and wind generation. These metrics are crucial in the electric power demand planning. \n"
     ]
    }
   ],
   "source": [
    "from models.TimeLLM import Model\n",
    "model = Model(configs=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings\n",
      "llm_model.wte.weight\n",
      "llm_model.wpe.weight\n",
      "llm_model.h.0.ln_1.weight\n",
      "llm_model.h.0.ln_1.bias\n",
      "llm_model.h.0.attn.c_attn.weight\n",
      "llm_model.h.0.attn.c_attn.bias\n",
      "llm_model.h.0.attn.c_proj.weight\n",
      "llm_model.h.0.attn.c_proj.bias\n",
      "llm_model.h.0.ln_2.weight\n",
      "llm_model.h.0.ln_2.bias\n",
      "llm_model.h.0.mlp.c_fc.weight\n",
      "llm_model.h.0.mlp.c_fc.bias\n",
      "llm_model.h.0.mlp.c_proj.weight\n",
      "llm_model.h.0.mlp.c_proj.bias\n",
      "llm_model.h.1.ln_1.weight\n",
      "llm_model.h.1.ln_1.bias\n",
      "llm_model.h.1.attn.c_attn.weight\n",
      "llm_model.h.1.attn.c_attn.bias\n",
      "llm_model.h.1.attn.c_proj.weight\n",
      "llm_model.h.1.attn.c_proj.bias\n",
      "llm_model.h.1.ln_2.weight\n",
      "llm_model.h.1.ln_2.bias\n",
      "llm_model.h.1.mlp.c_fc.weight\n",
      "llm_model.h.1.mlp.c_fc.bias\n",
      "llm_model.h.1.mlp.c_proj.weight\n",
      "llm_model.h.1.mlp.c_proj.bias\n",
      "llm_model.h.2.ln_1.weight\n",
      "llm_model.h.2.ln_1.bias\n",
      "llm_model.h.2.attn.c_attn.weight\n",
      "llm_model.h.2.attn.c_attn.bias\n",
      "llm_model.h.2.attn.c_proj.weight\n",
      "llm_model.h.2.attn.c_proj.bias\n",
      "llm_model.h.2.ln_2.weight\n",
      "llm_model.h.2.ln_2.bias\n",
      "llm_model.h.2.mlp.c_fc.weight\n",
      "llm_model.h.2.mlp.c_fc.bias\n",
      "llm_model.h.2.mlp.c_proj.weight\n",
      "llm_model.h.2.mlp.c_proj.bias\n",
      "llm_model.h.3.ln_1.weight\n",
      "llm_model.h.3.ln_1.bias\n",
      "llm_model.h.3.attn.c_attn.weight\n",
      "llm_model.h.3.attn.c_attn.bias\n",
      "llm_model.h.3.attn.c_proj.weight\n",
      "llm_model.h.3.attn.c_proj.bias\n",
      "llm_model.h.3.ln_2.weight\n",
      "llm_model.h.3.ln_2.bias\n",
      "llm_model.h.3.mlp.c_fc.weight\n",
      "llm_model.h.3.mlp.c_fc.bias\n",
      "llm_model.h.3.mlp.c_proj.weight\n",
      "llm_model.h.3.mlp.c_proj.bias\n",
      "llm_model.h.4.ln_1.weight\n",
      "llm_model.h.4.ln_1.bias\n",
      "llm_model.h.4.attn.c_attn.weight\n",
      "llm_model.h.4.attn.c_attn.bias\n",
      "llm_model.h.4.attn.c_proj.weight\n",
      "llm_model.h.4.attn.c_proj.bias\n",
      "llm_model.h.4.ln_2.weight\n",
      "llm_model.h.4.ln_2.bias\n",
      "llm_model.h.4.mlp.c_fc.weight\n",
      "llm_model.h.4.mlp.c_fc.bias\n",
      "llm_model.h.4.mlp.c_proj.weight\n",
      "llm_model.h.4.mlp.c_proj.bias\n",
      "llm_model.h.5.ln_1.weight\n",
      "llm_model.h.5.ln_1.bias\n",
      "llm_model.h.5.attn.c_attn.weight\n",
      "llm_model.h.5.attn.c_attn.bias\n",
      "llm_model.h.5.attn.c_proj.weight\n",
      "llm_model.h.5.attn.c_proj.bias\n",
      "llm_model.h.5.ln_2.weight\n",
      "llm_model.h.5.ln_2.bias\n",
      "llm_model.h.5.mlp.c_fc.weight\n",
      "llm_model.h.5.mlp.c_fc.bias\n",
      "llm_model.h.5.mlp.c_proj.weight\n",
      "llm_model.h.5.mlp.c_proj.bias\n",
      "llm_model.ln_f.weight\n",
      "llm_model.ln_f.bias\n",
      "patch_embedding.value_embedding.tokenConv.weight\n",
      "mapping_layer.weight\n",
      "mapping_layer.bias\n",
      "reprogramming_layer.query_projection.weight\n",
      "reprogramming_layer.query_projection.bias\n",
      "reprogramming_layer.key_projection.weight\n",
      "reprogramming_layer.key_projection.bias\n",
      "reprogramming_layer.value_projection.weight\n",
      "reprogramming_layer.value_projection.bias\n",
      "reprogramming_layer.out_projection.weight\n",
      "reprogramming_layer.out_projection.bias\n",
      "output_projection.linear.weight\n",
      "output_projection.linear.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('/vol/cs-hu/riabchuv/my_work/checkpoints/long_term_forecast_1_TimeLLM_GB_ftM_sl20_ll10_pl10_dm32_nh8_el2_dl1_df128_fc3_ebtimeF_Exp_0-GB_data_small/checkpoint.pth')\n",
    "\n",
    "# Print the keys in the checkpoint\n",
    "for key in checkpoint.keys():\n",
    "    print(key)\n",
    "\n",
    "\n",
    "# Access the model's state dictionary using the key 'llm_model'\n",
    "#model_state_dict = checkpoint['llm_model']\n",
    "\n",
    "# Load the model's state dictionary into your model\n",
    "#model.load_state_dict(model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings\n",
      "llm_model.wte.weight\n",
      "llm_model.wpe.weight\n",
      "llm_model.h.0.ln_1.weight\n",
      "llm_model.h.0.ln_1.bias\n",
      "llm_model.h.0.attn.c_attn.weight\n",
      "llm_model.h.0.attn.c_attn.bias\n",
      "llm_model.h.0.attn.c_proj.weight\n",
      "llm_model.h.0.attn.c_proj.bias\n",
      "llm_model.h.0.ln_2.weight\n",
      "llm_model.h.0.ln_2.bias\n",
      "llm_model.h.0.mlp.c_fc.weight\n",
      "llm_model.h.0.mlp.c_fc.bias\n",
      "llm_model.h.0.mlp.c_proj.weight\n",
      "llm_model.h.0.mlp.c_proj.bias\n",
      "llm_model.h.1.ln_1.weight\n",
      "llm_model.h.1.ln_1.bias\n",
      "llm_model.h.1.attn.c_attn.weight\n",
      "llm_model.h.1.attn.c_attn.bias\n",
      "llm_model.h.1.attn.c_proj.weight\n",
      "llm_model.h.1.attn.c_proj.bias\n",
      "llm_model.h.1.ln_2.weight\n",
      "llm_model.h.1.ln_2.bias\n",
      "llm_model.h.1.mlp.c_fc.weight\n",
      "llm_model.h.1.mlp.c_fc.bias\n",
      "llm_model.h.1.mlp.c_proj.weight\n",
      "llm_model.h.1.mlp.c_proj.bias\n",
      "llm_model.h.2.ln_1.weight\n",
      "llm_model.h.2.ln_1.bias\n",
      "llm_model.h.2.attn.c_attn.weight\n",
      "llm_model.h.2.attn.c_attn.bias\n",
      "llm_model.h.2.attn.c_proj.weight\n",
      "llm_model.h.2.attn.c_proj.bias\n",
      "llm_model.h.2.ln_2.weight\n",
      "llm_model.h.2.ln_2.bias\n",
      "llm_model.h.2.mlp.c_fc.weight\n",
      "llm_model.h.2.mlp.c_fc.bias\n",
      "llm_model.h.2.mlp.c_proj.weight\n",
      "llm_model.h.2.mlp.c_proj.bias\n",
      "llm_model.h.3.ln_1.weight\n",
      "llm_model.h.3.ln_1.bias\n",
      "llm_model.h.3.attn.c_attn.weight\n",
      "llm_model.h.3.attn.c_attn.bias\n",
      "llm_model.h.3.attn.c_proj.weight\n",
      "llm_model.h.3.attn.c_proj.bias\n",
      "llm_model.h.3.ln_2.weight\n",
      "llm_model.h.3.ln_2.bias\n",
      "llm_model.h.3.mlp.c_fc.weight\n",
      "llm_model.h.3.mlp.c_fc.bias\n",
      "llm_model.h.3.mlp.c_proj.weight\n",
      "llm_model.h.3.mlp.c_proj.bias\n",
      "llm_model.h.4.ln_1.weight\n",
      "llm_model.h.4.ln_1.bias\n",
      "llm_model.h.4.attn.c_attn.weight\n",
      "llm_model.h.4.attn.c_attn.bias\n",
      "llm_model.h.4.attn.c_proj.weight\n",
      "llm_model.h.4.attn.c_proj.bias\n",
      "llm_model.h.4.ln_2.weight\n",
      "llm_model.h.4.ln_2.bias\n",
      "llm_model.h.4.mlp.c_fc.weight\n",
      "llm_model.h.4.mlp.c_fc.bias\n",
      "llm_model.h.4.mlp.c_proj.weight\n",
      "llm_model.h.4.mlp.c_proj.bias\n",
      "llm_model.h.5.ln_1.weight\n",
      "llm_model.h.5.ln_1.bias\n",
      "llm_model.h.5.attn.c_attn.weight\n",
      "llm_model.h.5.attn.c_attn.bias\n",
      "llm_model.h.5.attn.c_proj.weight\n",
      "llm_model.h.5.attn.c_proj.bias\n",
      "llm_model.h.5.ln_2.weight\n",
      "llm_model.h.5.ln_2.bias\n",
      "llm_model.h.5.mlp.c_fc.weight\n",
      "llm_model.h.5.mlp.c_fc.bias\n",
      "llm_model.h.5.mlp.c_proj.weight\n",
      "llm_model.h.5.mlp.c_proj.bias\n",
      "llm_model.ln_f.weight\n",
      "llm_model.ln_f.bias\n",
      "patch_embedding.value_embedding.tokenConv.weight\n",
      "mapping_layer.weight\n",
      "mapping_layer.bias\n",
      "reprogramming_layer.query_projection.weight\n",
      "reprogramming_layer.query_projection.bias\n",
      "reprogramming_layer.key_projection.weight\n",
      "reprogramming_layer.key_projection.bias\n",
      "reprogramming_layer.value_projection.weight\n",
      "reprogramming_layer.value_projection.bias\n",
      "reprogramming_layer.out_projection.weight\n",
      "reprogramming_layer.out_projection.bias\n",
      "output_projection.linear.weight\n",
      "output_projection.linear.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('/vol/cs-hu/riabchuv/my_work/checkpoints/long_term_forecast_1_TimeLLM_FR_ftM_sl96_ll48_pl24_dm32_nh8_el2_dl1_df128_fc3_ebtimeF_Exp_0-TimeLLM-FR/checkpoint.pth')\n",
    "\n",
    "# Print the keys in the checkpoint\n",
    "for key in checkpoint.keys():\n",
    "    print(key)\n",
    "\n",
    "\n",
    "# Access the model's state dictionary using the key 'llm_model'\n",
    "#model_state_dict = checkpoint['llm_model']\n",
    "\n",
    "# Load the model's state dictionary into your model\n",
    "#model.load_state_dict(model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "0.68 < np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/vol/cs-hu/riabchuv/my_work/checkpoints/long_term_forecast_1_TimeLLM_FR_ftM_sl96_ll48_pl24_dm32_nh8_el2_dl1_df128_fc3_ebtimeF_Exp_0-TimeLLM-FR/long_term_forecast__24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['enc_embedding.value_embedding.tokenConv.weight', 'enc_embedding.position_embedding.pe', 'enc_embedding.temporal_embedding.embed.weight', 'dec_embedding.value_embedding.tokenConv.weight', 'dec_embedding.position_embedding.pe', 'dec_embedding.temporal_embedding.embed.weight', 'encoder.attn_layers.0.attention.query_projection.weight', 'encoder.attn_layers.0.attention.query_projection.bias', 'encoder.attn_layers.0.attention.key_projection.weight', 'encoder.attn_layers.0.attention.key_projection.bias', 'encoder.attn_layers.0.attention.value_projection.weight', 'encoder.attn_layers.0.attention.value_projection.bias', 'encoder.attn_layers.0.attention.out_projection.weight', 'encoder.attn_layers.0.attention.out_projection.bias', 'encoder.attn_layers.0.conv1.weight', 'encoder.attn_layers.0.conv1.bias', 'encoder.attn_layers.0.conv2.weight', 'encoder.attn_layers.0.conv2.bias', 'encoder.attn_layers.0.norm1.weight', 'encoder.attn_layers.0.norm1.bias', 'encoder.attn_layers.0.norm2.weight', 'encoder.attn_layers.0.norm2.bias', 'encoder.attn_layers.1.attention.query_projection.weight', 'encoder.attn_layers.1.attention.query_projection.bias', 'encoder.attn_layers.1.attention.key_projection.weight', 'encoder.attn_layers.1.attention.key_projection.bias', 'encoder.attn_layers.1.attention.value_projection.weight', 'encoder.attn_layers.1.attention.value_projection.bias', 'encoder.attn_layers.1.attention.out_projection.weight', 'encoder.attn_layers.1.attention.out_projection.bias', 'encoder.attn_layers.1.conv1.weight', 'encoder.attn_layers.1.conv1.bias', 'encoder.attn_layers.1.conv2.weight', 'encoder.attn_layers.1.conv2.bias', 'encoder.attn_layers.1.norm1.weight', 'encoder.attn_layers.1.norm1.bias', 'encoder.attn_layers.1.norm2.weight', 'encoder.attn_layers.1.norm2.bias', 'encoder.conv_layers.0.downConv.weight', 'encoder.conv_layers.0.downConv.bias', 'encoder.conv_layers.0.norm.weight', 'encoder.conv_layers.0.norm.bias', 'encoder.conv_layers.0.norm.running_mean', 'encoder.conv_layers.0.norm.running_var', 'encoder.conv_layers.0.norm.num_batches_tracked', 'encoder.norm.weight', 'encoder.norm.bias', 'decoder.layers.0.self_attention.query_projection.weight', 'decoder.layers.0.self_attention.query_projection.bias', 'decoder.layers.0.self_attention.key_projection.weight', 'decoder.layers.0.self_attention.key_projection.bias', 'decoder.layers.0.self_attention.value_projection.weight', 'decoder.layers.0.self_attention.value_projection.bias', 'decoder.layers.0.self_attention.out_projection.weight', 'decoder.layers.0.self_attention.out_projection.bias', 'decoder.layers.0.cross_attention.query_projection.weight', 'decoder.layers.0.cross_attention.query_projection.bias', 'decoder.layers.0.cross_attention.key_projection.weight', 'decoder.layers.0.cross_attention.key_projection.bias', 'decoder.layers.0.cross_attention.value_projection.weight', 'decoder.layers.0.cross_attention.value_projection.bias', 'decoder.layers.0.cross_attention.out_projection.weight', 'decoder.layers.0.cross_attention.out_projection.bias', 'decoder.layers.0.conv1.weight', 'decoder.layers.0.conv1.bias', 'decoder.layers.0.conv2.weight', 'decoder.layers.0.conv2.bias', 'decoder.layers.0.norm1.weight', 'decoder.layers.0.norm1.bias', 'decoder.layers.0.norm2.weight', 'decoder.layers.0.norm2.bias', 'decoder.layers.0.norm3.weight', 'decoder.layers.0.norm3.bias', 'decoder.layers.1.self_attention.query_projection.weight', 'decoder.layers.1.self_attention.query_projection.bias', 'decoder.layers.1.self_attention.key_projection.weight', 'decoder.layers.1.self_attention.key_projection.bias', 'decoder.layers.1.self_attention.value_projection.weight', 'decoder.layers.1.self_attention.value_projection.bias', 'decoder.layers.1.self_attention.out_projection.weight', 'decoder.layers.1.self_attention.out_projection.bias', 'decoder.layers.1.cross_attention.query_projection.weight', 'decoder.layers.1.cross_attention.query_projection.bias', 'decoder.layers.1.cross_attention.key_projection.weight', 'decoder.layers.1.cross_attention.key_projection.bias', 'decoder.layers.1.cross_attention.value_projection.weight', 'decoder.layers.1.cross_attention.value_projection.bias', 'decoder.layers.1.cross_attention.out_projection.weight', 'decoder.layers.1.cross_attention.out_projection.bias', 'decoder.layers.1.conv1.weight', 'decoder.layers.1.conv1.bias', 'decoder.layers.1.conv2.weight', 'decoder.layers.1.conv2.bias', 'decoder.layers.1.norm1.weight', 'decoder.layers.1.norm1.bias', 'decoder.layers.1.norm2.weight', 'decoder.layers.1.norm2.bias', 'decoder.layers.1.norm3.weight', 'decoder.layers.1.norm3.bias', 'decoder.layers.2.self_attention.query_projection.weight', 'decoder.layers.2.self_attention.query_projection.bias', 'decoder.layers.2.self_attention.key_projection.weight', 'decoder.layers.2.self_attention.key_projection.bias', 'decoder.layers.2.self_attention.value_projection.weight', 'decoder.layers.2.self_attention.value_projection.bias', 'decoder.layers.2.self_attention.out_projection.weight', 'decoder.layers.2.self_attention.out_projection.bias', 'decoder.layers.2.cross_attention.query_projection.weight', 'decoder.layers.2.cross_attention.query_projection.bias', 'decoder.layers.2.cross_attention.key_projection.weight', 'decoder.layers.2.cross_attention.key_projection.bias', 'decoder.layers.2.cross_attention.value_projection.weight', 'decoder.layers.2.cross_attention.value_projection.bias', 'decoder.layers.2.cross_attention.out_projection.weight', 'decoder.layers.2.cross_attention.out_projection.bias', 'decoder.layers.2.conv1.weight', 'decoder.layers.2.conv1.bias', 'decoder.layers.2.conv2.weight', 'decoder.layers.2.conv2.bias', 'decoder.layers.2.norm1.weight', 'decoder.layers.2.norm1.bias', 'decoder.layers.2.norm2.weight', 'decoder.layers.2.norm2.bias', 'decoder.layers.2.norm3.weight', 'decoder.layers.2.norm3.bias', 'decoder.layers.3.self_attention.query_projection.weight', 'decoder.layers.3.self_attention.query_projection.bias', 'decoder.layers.3.self_attention.key_projection.weight', 'decoder.layers.3.self_attention.key_projection.bias', 'decoder.layers.3.self_attention.value_projection.weight', 'decoder.layers.3.self_attention.value_projection.bias', 'decoder.layers.3.self_attention.out_projection.weight', 'decoder.layers.3.self_attention.out_projection.bias', 'decoder.layers.3.cross_attention.query_projection.weight', 'decoder.layers.3.cross_attention.query_projection.bias', 'decoder.layers.3.cross_attention.key_projection.weight', 'decoder.layers.3.cross_attention.key_projection.bias', 'decoder.layers.3.cross_attention.value_projection.weight', 'decoder.layers.3.cross_attention.value_projection.bias', 'decoder.layers.3.cross_attention.out_projection.weight', 'decoder.layers.3.cross_attention.out_projection.bias', 'decoder.layers.3.conv1.weight', 'decoder.layers.3.conv1.bias', 'decoder.layers.3.conv2.weight', 'decoder.layers.3.conv2.bias', 'decoder.layers.3.norm1.weight', 'decoder.layers.3.norm1.bias', 'decoder.layers.3.norm2.weight', 'decoder.layers.3.norm2.bias', 'decoder.layers.3.norm3.weight', 'decoder.layers.3.norm3.bias', 'decoder.layers.4.self_attention.query_projection.weight', 'decoder.layers.4.self_attention.query_projection.bias', 'decoder.layers.4.self_attention.key_projection.weight', 'decoder.layers.4.self_attention.key_projection.bias', 'decoder.layers.4.self_attention.value_projection.weight', 'decoder.layers.4.self_attention.value_projection.bias', 'decoder.layers.4.self_attention.out_projection.weight', 'decoder.layers.4.self_attention.out_projection.bias', 'decoder.layers.4.cross_attention.query_projection.weight', 'decoder.layers.4.cross_attention.query_projection.bias', 'decoder.layers.4.cross_attention.key_projection.weight', 'decoder.layers.4.cross_attention.key_projection.bias', 'decoder.layers.4.cross_attention.value_projection.weight', 'decoder.layers.4.cross_attention.value_projection.bias', 'decoder.layers.4.cross_attention.out_projection.weight', 'decoder.layers.4.cross_attention.out_projection.bias', 'decoder.layers.4.conv1.weight', 'decoder.layers.4.conv1.bias', 'decoder.layers.4.conv2.weight', 'decoder.layers.4.conv2.bias', 'decoder.layers.4.norm1.weight', 'decoder.layers.4.norm1.bias', 'decoder.layers.4.norm2.weight', 'decoder.layers.4.norm2.bias', 'decoder.layers.4.norm3.weight', 'decoder.layers.4.norm3.bias', 'decoder.norm.weight', 'decoder.norm.bias', 'decoder.projection.weight', 'decoder.projection.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "# Assign values to its attributes\n",
    "args.task_name = \"long_term_forecast\"\n",
    "args.is_training = 1\n",
    "args.model_id = 1\n",
    "args.model_comment = \"TimeLLM-GB\"\n",
    "args.model = \"TimeLLM\"\n",
    "args.seed = 2021\n",
    "args.data = \"GB\"\n",
    "args.root_path = \"./datasets/\"\n",
    "args.data_path = \"GB_data.csv\"\n",
    "args.features = \"M\"\n",
    "args.target = \"OT\"\n",
    "args.loader = \"modal\"\n",
    "args.freq = \"h\"\n",
    "args.checkpoints = \"./checkpoints/\"\n",
    "args.seq_len = 512\n",
    "args.label_len = 48\n",
    "args.pred_len = 96\n",
    "args.seasonal_patterns = \"Monthly\"\n",
    "args.enc_in = 5\n",
    "args.dec_in = 5\n",
    "args.c_out = 5\n",
    "args.d_model = 16\n",
    "args.n_heads = 8\n",
    "args.e_layers = 2\n",
    "args.d_layers = 1\n",
    "args.d_ff = 64\n",
    "args.moving_avg = 25\n",
    "args.factor = 3\n",
    "args.dropout = 0.1\n",
    "args.embed = \"timeF\"\n",
    "args.activation = \"gelu\"\n",
    "args.output_attention = False\n",
    "args.patch_len = 16\n",
    "args.stride = 8\n",
    "args.prompt_domain = 0\n",
    "args.llm_model = \"GPT2\"\n",
    "args.llm_dim = 768\n",
    "args.num_workers = 10\n",
    "args.itr = 1\n",
    "args.train_epochs = 20\n",
    "args.align_epochs = 10\n",
    "args.batch_size = 128\n",
    "args.eval_batch_size = 8\n",
    "args.patience = 3\n",
    "args.learning_rate = 4.0000110639950106e-05\n",
    "args.des = \"Exp\"\n",
    "args.loss = \"MSE\"\n",
    "args.lradj = \"type1\"\n",
    "args.pct_start = 0.2\n",
    "args.use_amp = False\n",
    "args.llm_layers = 12\n",
    "args.percent = 100\n",
    "args.content = \"Hourly data detailing load, solar generation, and wind generation in Great Britain. Wind generation is segmented into offshore, onshore, and total generation, with the latter being the combined sum of onshore and offshore wind generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TimeLLM import Model\n",
    "model = Model(configs=args)\n",
    "checkpoint = torch.load('/vol/cs-hu/riabchuv/my_work/checkpoints/long_term_forecast_1_TimeLLM_GB_ftM_sl512_ll48_pl96_dm16_nh8_el2_dl1_df64_fc3_ebtimeF_Exp_0-TimeLLM-GB/checkpoint.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
