{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test for Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8754409\n",
      "\tspeed: 0.0778s/iter; left time: 696.8565s\n",
      "\titers: 200, epoch: 1 | loss: 0.7260861\n",
      "\tspeed: 0.0452s/iter; left time: 400.6435s\n",
      "\titers: 300, epoch: 1 | loss: 0.5881239\n",
      "\tspeed: 0.0424s/iter; left time: 371.4244s\n",
      "\titers: 400, epoch: 1 | loss: 0.5317206\n",
      "\tspeed: 0.0456s/iter; left time: 394.6381s\n",
      "\titers: 500, epoch: 1 | loss: 0.4490079\n",
      "\tspeed: 0.0467s/iter; left time: 399.9881s\n",
      "\titers: 600, epoch: 1 | loss: 0.4366098\n",
      "\tspeed: 0.0423s/iter; left time: 357.7978s\n",
      "\titers: 700, epoch: 1 | loss: 0.5984434\n",
      "\tspeed: 0.0358s/iter; left time: 299.2334s\n",
      "\titers: 800, epoch: 1 | loss: 0.4468952\n",
      "\tspeed: 0.0375s/iter; left time: 309.6802s\n",
      "\titers: 900, epoch: 1 | loss: 0.3504356\n",
      "\tspeed: 0.0438s/iter; left time: 357.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.64s\n",
      "Steps: 906 | Train Loss: 0.5984609 Vali Loss: 0.5636209 Test Loss: 0.6419901\n",
      "Validation loss decreased (inf --> 0.563621).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2546865\n",
      "\tspeed: 0.1047s/iter; left time: 843.0712s\n",
      "\titers: 200, epoch: 2 | loss: 0.4297647\n",
      "\tspeed: 0.0487s/iter; left time: 387.4217s\n",
      "\titers: 300, epoch: 2 | loss: 0.2928289\n",
      "\tspeed: 0.0470s/iter; left time: 368.9475s\n",
      "\titers: 400, epoch: 2 | loss: 0.3814909\n",
      "\tspeed: 0.0492s/iter; left time: 381.4445s\n",
      "\titers: 500, epoch: 2 | loss: 0.2418542\n",
      "\tspeed: 0.0326s/iter; left time: 249.5587s\n",
      "\titers: 600, epoch: 2 | loss: 0.2771155\n",
      "\tspeed: 0.0279s/iter; left time: 210.8315s\n",
      "\titers: 700, epoch: 2 | loss: 0.2600983\n",
      "\tspeed: 0.0347s/iter; left time: 258.9305s\n",
      "\titers: 800, epoch: 2 | loss: 0.3986025\n",
      "\tspeed: 0.0480s/iter; left time: 353.0235s\n",
      "\titers: 900, epoch: 2 | loss: 0.2961993\n",
      "\tspeed: 0.0484s/iter; left time: 351.4884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 906 | Train Loss: 0.3344372 Vali Loss: 0.4406978 Test Loss: 0.5047123\n",
      "Validation loss decreased (0.563621 --> 0.440698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3222269\n",
      "\tspeed: 0.1112s/iter; left time: 795.1280s\n",
      "\titers: 200, epoch: 3 | loss: 0.2550934\n",
      "\tspeed: 0.0480s/iter; left time: 338.1748s\n",
      "\titers: 300, epoch: 3 | loss: 0.2760914\n",
      "\tspeed: 0.0470s/iter; left time: 326.6396s\n",
      "\titers: 400, epoch: 3 | loss: 0.2655979\n",
      "\tspeed: 0.0461s/iter; left time: 315.6396s\n",
      "\titers: 500, epoch: 3 | loss: 0.3568298\n",
      "\tspeed: 0.0478s/iter; left time: 322.5830s\n",
      "\titers: 600, epoch: 3 | loss: 0.3077882\n",
      "\tspeed: 0.0469s/iter; left time: 311.7862s\n",
      "\titers: 700, epoch: 3 | loss: 0.2796648\n",
      "\tspeed: 0.0377s/iter; left time: 247.1040s\n",
      "\titers: 800, epoch: 3 | loss: 0.2527131\n",
      "\tspeed: 0.0339s/iter; left time: 218.3229s\n",
      "\titers: 900, epoch: 3 | loss: 0.2725163\n",
      "\tspeed: 0.0438s/iter; left time: 277.8193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 906 | Train Loss: 0.2789132 Vali Loss: 0.4363867 Test Loss: 0.4842115\n",
      "Validation loss decreased (0.440698 --> 0.436387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2329618\n",
      "\tspeed: 0.1049s/iter; left time: 654.6495s\n",
      "\titers: 200, epoch: 4 | loss: 0.2417155\n",
      "\tspeed: 0.0404s/iter; left time: 248.0477s\n",
      "\titers: 300, epoch: 4 | loss: 0.2286840\n",
      "\tspeed: 0.0448s/iter; left time: 270.6984s\n",
      "\titers: 400, epoch: 4 | loss: 0.2005890\n",
      "\tspeed: 0.0444s/iter; left time: 263.9388s\n",
      "\titers: 500, epoch: 4 | loss: 0.3193380\n",
      "\tspeed: 0.0407s/iter; left time: 237.9689s\n",
      "\titers: 600, epoch: 4 | loss: 0.2470205\n",
      "\tspeed: 0.0476s/iter; left time: 273.3899s\n",
      "\titers: 700, epoch: 4 | loss: 0.2137513\n",
      "\tspeed: 0.0352s/iter; left time: 198.5729s\n",
      "\titers: 800, epoch: 4 | loss: 0.2644546\n",
      "\tspeed: 0.0427s/iter; left time: 236.9054s\n",
      "\titers: 900, epoch: 4 | loss: 0.2470621\n",
      "\tspeed: 0.0432s/iter; left time: 235.1178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 906 | Train Loss: 0.2380960 Vali Loss: 0.4675660 Test Loss: 0.5229828\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2264290\n",
      "\tspeed: 0.0933s/iter; left time: 497.7238s\n",
      "\titers: 200, epoch: 5 | loss: 0.2064114\n",
      "\tspeed: 0.0412s/iter; left time: 215.7277s\n",
      "\titers: 300, epoch: 5 | loss: 0.1771473\n",
      "\tspeed: 0.0426s/iter; left time: 218.9850s\n",
      "\titers: 400, epoch: 5 | loss: 0.2180729\n",
      "\tspeed: 0.0423s/iter; left time: 213.3164s\n",
      "\titers: 500, epoch: 5 | loss: 0.1669089\n",
      "\tspeed: 0.0453s/iter; left time: 223.4675s\n",
      "\titers: 600, epoch: 5 | loss: 0.1975233\n",
      "\tspeed: 0.0442s/iter; left time: 213.8881s\n",
      "\titers: 700, epoch: 5 | loss: 0.1766317\n",
      "\tspeed: 0.0468s/iter; left time: 221.8981s\n",
      "\titers: 800, epoch: 5 | loss: 0.1944941\n",
      "\tspeed: 0.0340s/iter; left time: 157.7132s\n",
      "\titers: 900, epoch: 5 | loss: 0.2040730\n",
      "\tspeed: 0.0364s/iter; left time: 165.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.26s\n",
      "Steps: 906 | Train Loss: 0.1967699 Vali Loss: 0.4598494 Test Loss: 0.5197368\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1980289\n",
      "\tspeed: 0.1038s/iter; left time: 460.0989s\n",
      "\titers: 200, epoch: 6 | loss: 0.1421976\n",
      "\tspeed: 0.0345s/iter; left time: 149.2401s\n",
      "\titers: 300, epoch: 6 | loss: 0.1634986\n",
      "\tspeed: 0.0453s/iter; left time: 191.6598s\n",
      "\titers: 400, epoch: 6 | loss: 0.1626134\n",
      "\tspeed: 0.0476s/iter; left time: 196.8071s\n",
      "\titers: 500, epoch: 6 | loss: 0.1830469\n",
      "\tspeed: 0.0394s/iter; left time: 159.0024s\n",
      "\titers: 600, epoch: 6 | loss: 0.1461178\n",
      "\tspeed: 0.0373s/iter; left time: 146.7247s\n",
      "\titers: 700, epoch: 6 | loss: 0.1799205\n",
      "\tspeed: 0.0397s/iter; left time: 152.2671s\n",
      "\titers: 800, epoch: 6 | loss: 0.1406301\n",
      "\tspeed: 0.0466s/iter; left time: 173.7980s\n",
      "\titers: 900, epoch: 6 | loss: 0.1443603\n",
      "\tspeed: 0.0461s/iter; left time: 167.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.96s\n",
      "Steps: 906 | Train Loss: 0.1648386 Vali Loss: 0.5146403 Test Loss: 0.5780380\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4845530688762665, rmse:0.6960984468460083, mae:0.4747908413410187, rse:0.5509179830551147\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7940848\n",
      "\tspeed: 0.0506s/iter; left time: 453.7479s\n",
      "\titers: 200, epoch: 1 | loss: 0.6955079\n",
      "\tspeed: 0.0475s/iter; left time: 420.6656s\n",
      "\titers: 300, epoch: 1 | loss: 0.5134652\n",
      "\tspeed: 0.0445s/iter; left time: 390.2384s\n",
      "\titers: 400, epoch: 1 | loss: 0.5164902\n",
      "\tspeed: 0.0409s/iter; left time: 354.0445s\n",
      "\titers: 500, epoch: 1 | loss: 0.5536527\n",
      "\tspeed: 0.0477s/iter; left time: 408.2700s\n",
      "\titers: 600, epoch: 1 | loss: 0.5545563\n",
      "\tspeed: 0.0352s/iter; left time: 298.1310s\n",
      "\titers: 700, epoch: 1 | loss: 0.4522658\n",
      "\tspeed: 0.0459s/iter; left time: 384.0210s\n",
      "\titers: 800, epoch: 1 | loss: 0.4030414\n",
      "\tspeed: 0.0423s/iter; left time: 349.2533s\n",
      "\titers: 900, epoch: 1 | loss: 0.4324321\n",
      "\tspeed: 0.0431s/iter; left time: 351.3455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 906 | Train Loss: 0.5985398 Vali Loss: 0.5592329 Test Loss: 0.6520282\n",
      "Validation loss decreased (inf --> 0.559233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4809588\n",
      "\tspeed: 0.1058s/iter; left time: 852.4460s\n",
      "\titers: 200, epoch: 2 | loss: 0.3434350\n",
      "\tspeed: 0.0399s/iter; left time: 317.5238s\n",
      "\titers: 300, epoch: 2 | loss: 0.2876355\n",
      "\tspeed: 0.0433s/iter; left time: 339.9899s\n",
      "\titers: 400, epoch: 2 | loss: 0.3155873\n",
      "\tspeed: 0.0466s/iter; left time: 361.6544s\n",
      "\titers: 500, epoch: 2 | loss: 0.3069152\n",
      "\tspeed: 0.0447s/iter; left time: 342.5052s\n",
      "\titers: 600, epoch: 2 | loss: 0.2878850\n",
      "\tspeed: 0.0460s/iter; left time: 347.4171s\n",
      "\titers: 700, epoch: 2 | loss: 0.3604871\n",
      "\tspeed: 0.0413s/iter; left time: 307.6469s\n",
      "\titers: 800, epoch: 2 | loss: 0.3090978\n",
      "\tspeed: 0.0469s/iter; left time: 345.0912s\n",
      "\titers: 900, epoch: 2 | loss: 0.2337791\n",
      "\tspeed: 0.0503s/iter; left time: 364.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.94s\n",
      "Steps: 906 | Train Loss: 0.3341385 Vali Loss: 0.4505811 Test Loss: 0.4896597\n",
      "Validation loss decreased (0.559233 --> 0.450581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2500563\n",
      "\tspeed: 0.1103s/iter; left time: 788.3263s\n",
      "\titers: 200, epoch: 3 | loss: 0.2749220\n",
      "\tspeed: 0.0433s/iter; left time: 305.4884s\n",
      "\titers: 300, epoch: 3 | loss: 0.4003462\n",
      "\tspeed: 0.0353s/iter; left time: 245.3431s\n",
      "\titers: 400, epoch: 3 | loss: 0.2279331\n",
      "\tspeed: 0.0459s/iter; left time: 314.3691s\n",
      "\titers: 500, epoch: 3 | loss: 0.3449506\n",
      "\tspeed: 0.0461s/iter; left time: 311.1603s\n",
      "\titers: 600, epoch: 3 | loss: 0.3044321\n",
      "\tspeed: 0.0457s/iter; left time: 303.7476s\n",
      "\titers: 700, epoch: 3 | loss: 0.2671725\n",
      "\tspeed: 0.0453s/iter; left time: 296.4362s\n",
      "\titers: 800, epoch: 3 | loss: 0.1682917\n",
      "\tspeed: 0.0416s/iter; left time: 268.4880s\n",
      "\titers: 900, epoch: 3 | loss: 0.1908576\n",
      "\tspeed: 0.0456s/iter; left time: 289.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 906 | Train Loss: 0.2793407 Vali Loss: 0.4617786 Test Loss: 0.4950074\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3186104\n",
      "\tspeed: 0.1065s/iter; left time: 664.7993s\n",
      "\titers: 200, epoch: 4 | loss: 0.2130065\n",
      "\tspeed: 0.0437s/iter; left time: 268.7288s\n",
      "\titers: 300, epoch: 4 | loss: 0.2003538\n",
      "\tspeed: 0.0415s/iter; left time: 251.0598s\n",
      "\titers: 400, epoch: 4 | loss: 0.2623422\n",
      "\tspeed: 0.0414s/iter; left time: 246.2597s\n",
      "\titers: 500, epoch: 4 | loss: 0.2018044\n",
      "\tspeed: 0.0388s/iter; left time: 226.9231s\n",
      "\titers: 600, epoch: 4 | loss: 0.2563125\n",
      "\tspeed: 0.0424s/iter; left time: 243.6071s\n",
      "\titers: 700, epoch: 4 | loss: 0.2433040\n",
      "\tspeed: 0.0319s/iter; left time: 180.1321s\n",
      "\titers: 800, epoch: 4 | loss: 0.2440763\n",
      "\tspeed: 0.0362s/iter; left time: 200.7529s\n",
      "\titers: 900, epoch: 4 | loss: 0.2041423\n",
      "\tspeed: 0.0438s/iter; left time: 238.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.38s\n",
      "Steps: 906 | Train Loss: 0.2388206 Vali Loss: 0.4481942 Test Loss: 0.4855444\n",
      "Validation loss decreased (0.450581 --> 0.448194).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1715127\n",
      "\tspeed: 0.1071s/iter; left time: 571.5746s\n",
      "\titers: 200, epoch: 5 | loss: 0.2226924\n",
      "\tspeed: 0.0460s/iter; left time: 241.1263s\n",
      "\titers: 300, epoch: 5 | loss: 0.2717839\n",
      "\tspeed: 0.0442s/iter; left time: 227.2244s\n",
      "\titers: 400, epoch: 5 | loss: 0.2395192\n",
      "\tspeed: 0.0456s/iter; left time: 229.6526s\n",
      "\titers: 500, epoch: 5 | loss: 0.1965641\n",
      "\tspeed: 0.0446s/iter; left time: 220.0817s\n",
      "\titers: 600, epoch: 5 | loss: 0.1854599\n",
      "\tspeed: 0.0433s/iter; left time: 209.2563s\n",
      "\titers: 700, epoch: 5 | loss: 0.1827174\n",
      "\tspeed: 0.0402s/iter; left time: 190.2235s\n",
      "\titers: 800, epoch: 5 | loss: 0.1854400\n",
      "\tspeed: 0.0413s/iter; left time: 191.6723s\n",
      "\titers: 900, epoch: 5 | loss: 0.1974044\n",
      "\tspeed: 0.0350s/iter; left time: 158.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.98s\n",
      "Steps: 906 | Train Loss: 0.1954678 Vali Loss: 0.4819650 Test Loss: 0.5250737\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1990901\n",
      "\tspeed: 0.1067s/iter; left time: 472.7643s\n",
      "\titers: 200, epoch: 6 | loss: 0.1494676\n",
      "\tspeed: 0.0369s/iter; left time: 159.9909s\n",
      "\titers: 300, epoch: 6 | loss: 0.1395076\n",
      "\tspeed: 0.0496s/iter; left time: 209.9134s\n",
      "\titers: 400, epoch: 6 | loss: 0.1950423\n",
      "\tspeed: 0.0456s/iter; left time: 188.4768s\n",
      "\titers: 500, epoch: 6 | loss: 0.1667301\n",
      "\tspeed: 0.0468s/iter; left time: 188.5987s\n",
      "\titers: 600, epoch: 6 | loss: 0.1673328\n",
      "\tspeed: 0.0423s/iter; left time: 166.3496s\n",
      "\titers: 700, epoch: 6 | loss: 0.1498653\n",
      "\tspeed: 0.0397s/iter; left time: 151.9794s\n",
      "\titers: 800, epoch: 6 | loss: 0.1240760\n",
      "\tspeed: 0.0489s/iter; left time: 182.2889s\n",
      "\titers: 900, epoch: 6 | loss: 0.1456304\n",
      "\tspeed: 0.0486s/iter; left time: 176.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.48s\n",
      "Steps: 906 | Train Loss: 0.1586516 Vali Loss: 0.4916697 Test Loss: 0.5453984\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1205320\n",
      "\tspeed: 0.1042s/iter; left time: 367.4559s\n",
      "\titers: 200, epoch: 7 | loss: 0.1105122\n",
      "\tspeed: 0.0391s/iter; left time: 133.9393s\n",
      "\titers: 300, epoch: 7 | loss: 0.1347716\n",
      "\tspeed: 0.0485s/iter; left time: 161.2269s\n",
      "\titers: 400, epoch: 7 | loss: 0.1331866\n",
      "\tspeed: 0.0456s/iter; left time: 147.1258s\n",
      "\titers: 500, epoch: 7 | loss: 0.1755069\n",
      "\tspeed: 0.0467s/iter; left time: 145.9249s\n",
      "\titers: 600, epoch: 7 | loss: 0.1452723\n",
      "\tspeed: 0.0474s/iter; left time: 143.2657s\n",
      "\titers: 700, epoch: 7 | loss: 0.1658157\n",
      "\tspeed: 0.0432s/iter; left time: 126.2940s\n",
      "\titers: 800, epoch: 7 | loss: 0.1823024\n",
      "\tspeed: 0.0414s/iter; left time: 116.9523s\n",
      "\titers: 900, epoch: 7 | loss: 0.1335696\n",
      "\tspeed: 0.0481s/iter; left time: 130.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 906 | Train Loss: 0.1325223 Vali Loss: 0.4990247 Test Loss: 0.5457581\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.48707887530326843, rmse:0.6979103684425354, mae:0.4671614170074463, rse:0.5523520112037659\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0553409\n",
      "\tspeed: 0.0825s/iter; left time: 737.7451s\n",
      "\titers: 200, epoch: 1 | loss: 0.9618088\n",
      "\tspeed: 0.0443s/iter; left time: 391.6192s\n",
      "\titers: 300, epoch: 1 | loss: 0.9252958\n",
      "\tspeed: 0.0464s/iter; left time: 405.7008s\n",
      "\titers: 400, epoch: 1 | loss: 0.7812807\n",
      "\tspeed: 0.0377s/iter; left time: 325.7346s\n",
      "\titers: 500, epoch: 1 | loss: 0.7889023\n",
      "\tspeed: 0.0497s/iter; left time: 424.6929s\n",
      "\titers: 600, epoch: 1 | loss: 0.6611272\n",
      "\tspeed: 0.0460s/iter; left time: 388.2220s\n",
      "\titers: 700, epoch: 1 | loss: 0.6259105\n",
      "\tspeed: 0.0357s/iter; left time: 297.9437s\n",
      "\titers: 800, epoch: 1 | loss: 0.6513122\n",
      "\tspeed: 0.0449s/iter; left time: 369.7824s\n",
      "\titers: 900, epoch: 1 | loss: 0.6578389\n",
      "\tspeed: 0.0471s/iter; left time: 383.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.03s\n",
      "Steps: 904 | Train Loss: 0.8172180 Vali Loss: 0.8336484 Test Loss: 1.0374128\n",
      "Validation loss decreased (inf --> 0.833648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5250234\n",
      "\tspeed: 0.1087s/iter; left time: 873.4304s\n",
      "\titers: 200, epoch: 2 | loss: 0.5788298\n",
      "\tspeed: 0.0457s/iter; left time: 362.8730s\n",
      "\titers: 300, epoch: 2 | loss: 0.5285784\n",
      "\tspeed: 0.0472s/iter; left time: 369.7265s\n",
      "\titers: 400, epoch: 2 | loss: 0.4928753\n",
      "\tspeed: 0.0468s/iter; left time: 362.3718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4880221\n",
      "\tspeed: 0.0455s/iter; left time: 347.1073s\n",
      "\titers: 600, epoch: 2 | loss: 0.5831410\n",
      "\tspeed: 0.0490s/iter; left time: 369.2193s\n",
      "\titers: 700, epoch: 2 | loss: 0.4683133\n",
      "\tspeed: 0.0457s/iter; left time: 339.5314s\n",
      "\titers: 800, epoch: 2 | loss: 0.5395126\n",
      "\tspeed: 0.0481s/iter; left time: 352.6610s\n",
      "\titers: 900, epoch: 2 | loss: 0.4574910\n",
      "\tspeed: 0.0471s/iter; left time: 340.9618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.61s\n",
      "Steps: 904 | Train Loss: 0.5348569 Vali Loss: 0.6813359 Test Loss: 0.8255704\n",
      "Validation loss decreased (0.833648 --> 0.681336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5549014\n",
      "\tspeed: 0.1104s/iter; left time: 787.1515s\n",
      "\titers: 200, epoch: 3 | loss: 0.4220436\n",
      "\tspeed: 0.0471s/iter; left time: 331.2751s\n",
      "\titers: 300, epoch: 3 | loss: 0.3837465\n",
      "\tspeed: 0.0432s/iter; left time: 299.7599s\n",
      "\titers: 400, epoch: 3 | loss: 0.3859476\n",
      "\tspeed: 0.0404s/iter; left time: 276.1103s\n",
      "\titers: 500, epoch: 3 | loss: 0.4555952\n",
      "\tspeed: 0.0384s/iter; left time: 258.2731s\n",
      "\titers: 600, epoch: 3 | loss: 0.3960175\n",
      "\tspeed: 0.0469s/iter; left time: 311.1699s\n",
      "\titers: 700, epoch: 3 | loss: 0.3825842\n",
      "\tspeed: 0.0479s/iter; left time: 312.6801s\n",
      "\titers: 800, epoch: 3 | loss: 0.4188156\n",
      "\tspeed: 0.0470s/iter; left time: 302.6478s\n",
      "\titers: 900, epoch: 3 | loss: 0.4259931\n",
      "\tspeed: 0.0487s/iter; left time: 308.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.25s\n",
      "Steps: 904 | Train Loss: 0.4311757 Vali Loss: 0.6887811 Test Loss: 0.8447679\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3707462\n",
      "\tspeed: 0.1024s/iter; left time: 638.0022s\n",
      "\titers: 200, epoch: 4 | loss: 0.3540020\n",
      "\tspeed: 0.0483s/iter; left time: 295.8267s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549272\n",
      "\tspeed: 0.0479s/iter; left time: 289.0715s\n",
      "\titers: 400, epoch: 4 | loss: 0.2774632\n",
      "\tspeed: 0.0477s/iter; left time: 282.5976s\n",
      "\titers: 500, epoch: 4 | loss: 0.3796825\n",
      "\tspeed: 0.0451s/iter; left time: 262.9672s\n",
      "\titers: 600, epoch: 4 | loss: 0.3225014\n",
      "\tspeed: 0.0468s/iter; left time: 267.8884s\n",
      "\titers: 700, epoch: 4 | loss: 0.3709828\n",
      "\tspeed: 0.0420s/iter; left time: 236.1600s\n",
      "\titers: 800, epoch: 4 | loss: 0.3402101\n",
      "\tspeed: 0.0416s/iter; left time: 230.1532s\n",
      "\titers: 900, epoch: 4 | loss: 0.3628283\n",
      "\tspeed: 0.0391s/iter; left time: 212.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.68s\n",
      "Steps: 904 | Train Loss: 0.3601861 Vali Loss: 0.7525234 Test Loss: 0.9388931\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2761967\n",
      "\tspeed: 0.1010s/iter; left time: 537.8523s\n",
      "\titers: 200, epoch: 5 | loss: 0.3742134\n",
      "\tspeed: 0.0353s/iter; left time: 184.6572s\n",
      "\titers: 300, epoch: 5 | loss: 0.2969899\n",
      "\tspeed: 0.0480s/iter; left time: 245.7618s\n",
      "\titers: 400, epoch: 5 | loss: 0.3104628\n",
      "\tspeed: 0.0469s/iter; left time: 235.4532s\n",
      "\titers: 500, epoch: 5 | loss: 0.2954840\n",
      "\tspeed: 0.0479s/iter; left time: 235.7295s\n",
      "\titers: 600, epoch: 5 | loss: 0.2894021\n",
      "\tspeed: 0.0437s/iter; left time: 210.6768s\n",
      "\titers: 700, epoch: 5 | loss: 0.2815764\n",
      "\tspeed: 0.0318s/iter; left time: 150.2007s\n",
      "\titers: 800, epoch: 5 | loss: 0.2494880\n",
      "\tspeed: 0.0468s/iter; left time: 216.4946s\n",
      "\titers: 900, epoch: 5 | loss: 0.2636387\n",
      "\tspeed: 0.0493s/iter; left time: 222.8792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.79s\n",
      "Steps: 904 | Train Loss: 0.2992973 Vali Loss: 0.7255701 Test Loss: 0.9204978\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.825575590133667, rmse:0.9086118936538696, mae:0.6690298318862915, rse:0.7206411957740784\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9072584\n",
      "\tspeed: 0.0414s/iter; left time: 370.3475s\n",
      "\titers: 200, epoch: 1 | loss: 0.8246167\n",
      "\tspeed: 0.0476s/iter; left time: 420.4649s\n",
      "\titers: 300, epoch: 1 | loss: 0.8606612\n",
      "\tspeed: 0.0439s/iter; left time: 383.5549s\n",
      "\titers: 400, epoch: 1 | loss: 0.8278546\n",
      "\tspeed: 0.0469s/iter; left time: 404.9379s\n",
      "\titers: 500, epoch: 1 | loss: 0.8659052\n",
      "\tspeed: 0.0383s/iter; left time: 326.9555s\n",
      "\titers: 600, epoch: 1 | loss: 0.6688741\n",
      "\tspeed: 0.0462s/iter; left time: 390.2551s\n",
      "\titers: 700, epoch: 1 | loss: 0.9305874\n",
      "\tspeed: 0.0452s/iter; left time: 376.6472s\n",
      "\titers: 800, epoch: 1 | loss: 0.6930461\n",
      "\tspeed: 0.0382s/iter; left time: 314.5850s\n",
      "\titers: 900, epoch: 1 | loss: 0.7392390\n",
      "\tspeed: 0.0428s/iter; left time: 348.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.23s\n",
      "Steps: 904 | Train Loss: 0.8262640 Vali Loss: 0.8313039 Test Loss: 1.0475183\n",
      "Validation loss decreased (inf --> 0.831304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6534256\n",
      "\tspeed: 0.1083s/iter; left time: 870.3419s\n",
      "\titers: 200, epoch: 2 | loss: 0.6242445\n",
      "\tspeed: 0.0523s/iter; left time: 414.8537s\n",
      "\titers: 300, epoch: 2 | loss: 0.5559287\n",
      "\tspeed: 0.0486s/iter; left time: 381.1464s\n",
      "\titers: 400, epoch: 2 | loss: 0.4323021\n",
      "\tspeed: 0.0485s/iter; left time: 375.1369s\n",
      "\titers: 500, epoch: 2 | loss: 0.4811127\n",
      "\tspeed: 0.0339s/iter; left time: 258.9540s\n",
      "\titers: 600, epoch: 2 | loss: 0.6024867\n",
      "\tspeed: 0.0473s/iter; left time: 356.7255s\n",
      "\titers: 700, epoch: 2 | loss: 0.5007147\n",
      "\tspeed: 0.0391s/iter; left time: 290.7631s\n",
      "\titers: 800, epoch: 2 | loss: 0.5252903\n",
      "\tspeed: 0.0370s/iter; left time: 271.2524s\n",
      "\titers: 900, epoch: 2 | loss: 0.4161828\n",
      "\tspeed: 0.0443s/iter; left time: 320.9604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.22s\n",
      "Steps: 904 | Train Loss: 0.5329223 Vali Loss: 0.6859319 Test Loss: 0.8439868\n",
      "Validation loss decreased (0.831304 --> 0.685932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4529830\n",
      "\tspeed: 0.1102s/iter; left time: 786.3889s\n",
      "\titers: 200, epoch: 3 | loss: 0.4495713\n",
      "\tspeed: 0.0401s/iter; left time: 281.9221s\n",
      "\titers: 300, epoch: 3 | loss: 0.3820248\n",
      "\tspeed: 0.0403s/iter; left time: 279.5123s\n",
      "\titers: 400, epoch: 3 | loss: 0.3778513\n",
      "\tspeed: 0.0450s/iter; left time: 307.5329s\n",
      "\titers: 500, epoch: 3 | loss: 0.3880405\n",
      "\tspeed: 0.0432s/iter; left time: 290.6809s\n",
      "\titers: 600, epoch: 3 | loss: 0.4034651\n",
      "\tspeed: 0.0404s/iter; left time: 268.1672s\n",
      "\titers: 700, epoch: 3 | loss: 0.4091071\n",
      "\tspeed: 0.0464s/iter; left time: 303.0628s\n",
      "\titers: 800, epoch: 3 | loss: 0.4530527\n",
      "\tspeed: 0.0410s/iter; left time: 263.8092s\n",
      "\titers: 900, epoch: 3 | loss: 0.4016001\n",
      "\tspeed: 0.0475s/iter; left time: 300.7579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.36s\n",
      "Steps: 904 | Train Loss: 0.4237194 Vali Loss: 0.7496722 Test Loss: 0.9063830\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3607888\n",
      "\tspeed: 0.1091s/iter; left time: 679.7466s\n",
      "\titers: 200, epoch: 4 | loss: 0.3745221\n",
      "\tspeed: 0.0455s/iter; left time: 278.6431s\n",
      "\titers: 300, epoch: 4 | loss: 0.3643158\n",
      "\tspeed: 0.0477s/iter; left time: 287.5050s\n",
      "\titers: 400, epoch: 4 | loss: 0.3181264\n",
      "\tspeed: 0.0474s/iter; left time: 281.0763s\n",
      "\titers: 500, epoch: 4 | loss: 0.3359987\n",
      "\tspeed: 0.0422s/iter; left time: 245.7988s\n",
      "\titers: 600, epoch: 4 | loss: 0.3656865\n",
      "\tspeed: 0.0462s/iter; left time: 264.7626s\n",
      "\titers: 700, epoch: 4 | loss: 0.3352043\n",
      "\tspeed: 0.0480s/iter; left time: 270.0593s\n",
      "\titers: 800, epoch: 4 | loss: 0.3765287\n",
      "\tspeed: 0.0473s/iter; left time: 261.7970s\n",
      "\titers: 900, epoch: 4 | loss: 0.2844599\n",
      "\tspeed: 0.0409s/iter; left time: 222.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 904 | Train Loss: 0.3620985 Vali Loss: 0.7326247 Test Loss: 0.9396789\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2786411\n",
      "\tspeed: 0.1063s/iter; left time: 566.1962s\n",
      "\titers: 200, epoch: 5 | loss: 0.3380631\n",
      "\tspeed: 0.0485s/iter; left time: 253.3826s\n",
      "\titers: 300, epoch: 5 | loss: 0.3191465\n",
      "\tspeed: 0.0467s/iter; left time: 239.4464s\n",
      "\titers: 400, epoch: 5 | loss: 0.2925112\n",
      "\tspeed: 0.0485s/iter; left time: 243.5183s\n",
      "\titers: 500, epoch: 5 | loss: 0.3090059\n",
      "\tspeed: 0.0398s/iter; left time: 196.1319s\n",
      "\titers: 600, epoch: 5 | loss: 0.2894770\n",
      "\tspeed: 0.0432s/iter; left time: 208.6541s\n",
      "\titers: 700, epoch: 5 | loss: 0.3082345\n",
      "\tspeed: 0.0436s/iter; left time: 205.9031s\n",
      "\titers: 800, epoch: 5 | loss: 0.3322985\n",
      "\tspeed: 0.0441s/iter; left time: 203.9892s\n",
      "\titers: 900, epoch: 5 | loss: 0.2782825\n",
      "\tspeed: 0.0467s/iter; left time: 211.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 904 | Train Loss: 0.3037740 Vali Loss: 0.7241696 Test Loss: 0.9566291\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.8441876769065857, rmse:0.9187968373298645, mae:0.6719043254852295, rse:0.728719174861908\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9002920\n",
      "\tspeed: 0.0826s/iter; left time: 737.1773s\n",
      "\titers: 200, epoch: 1 | loss: 0.9796243\n",
      "\tspeed: 0.0466s/iter; left time: 410.9277s\n",
      "\titers: 300, epoch: 1 | loss: 0.8703567\n",
      "\tspeed: 0.0366s/iter; left time: 319.4518s\n",
      "\titers: 400, epoch: 1 | loss: 0.8750377\n",
      "\tspeed: 0.0435s/iter; left time: 374.9156s\n",
      "\titers: 500, epoch: 1 | loss: 0.8427003\n",
      "\tspeed: 0.0503s/iter; left time: 428.5262s\n",
      "\titers: 600, epoch: 1 | loss: 0.8892862\n",
      "\tspeed: 0.0466s/iter; left time: 392.1361s\n",
      "\titers: 700, epoch: 1 | loss: 0.8373239\n",
      "\tspeed: 0.0451s/iter; left time: 375.4546s\n",
      "\titers: 800, epoch: 1 | loss: 0.7697777\n",
      "\tspeed: 0.0422s/iter; left time: 346.7610s\n",
      "\titers: 900, epoch: 1 | loss: 0.8343865\n",
      "\tspeed: 0.0506s/iter; left time: 410.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 902 | Train Loss: 0.8779987 Vali Loss: 0.9820610 Test Loss: 1.2618014\n",
      "Validation loss decreased (inf --> 0.982061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8210352\n",
      "\tspeed: 0.1193s/iter; left time: 957.0468s\n",
      "\titers: 200, epoch: 2 | loss: 0.7023198\n",
      "\tspeed: 0.0436s/iter; left time: 345.3177s\n",
      "\titers: 300, epoch: 2 | loss: 0.7391762\n",
      "\tspeed: 0.0471s/iter; left time: 368.4579s\n",
      "\titers: 400, epoch: 2 | loss: 0.6218180\n",
      "\tspeed: 0.0478s/iter; left time: 368.7111s\n",
      "\titers: 500, epoch: 2 | loss: 0.6234000\n",
      "\tspeed: 0.0425s/iter; left time: 323.4990s\n",
      "\titers: 600, epoch: 2 | loss: 0.5244492\n",
      "\tspeed: 0.0440s/iter; left time: 331.1241s\n",
      "\titers: 700, epoch: 2 | loss: 0.5347773\n",
      "\tspeed: 0.0495s/iter; left time: 367.4920s\n",
      "\titers: 800, epoch: 2 | loss: 0.6071605\n",
      "\tspeed: 0.0462s/iter; left time: 338.0066s\n",
      "\titers: 900, epoch: 2 | loss: 0.4984582\n",
      "\tspeed: 0.0421s/iter; left time: 303.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 902 | Train Loss: 0.6055719 Vali Loss: 0.7250192 Test Loss: 0.8691709\n",
      "Validation loss decreased (0.982061 --> 0.725019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4981438\n",
      "\tspeed: 0.1169s/iter; left time: 831.8804s\n",
      "\titers: 200, epoch: 3 | loss: 0.4806912\n",
      "\tspeed: 0.0492s/iter; left time: 345.0297s\n",
      "\titers: 300, epoch: 3 | loss: 0.4771298\n",
      "\tspeed: 0.0421s/iter; left time: 291.1495s\n",
      "\titers: 400, epoch: 3 | loss: 0.5351637\n",
      "\tspeed: 0.0484s/iter; left time: 330.0315s\n",
      "\titers: 500, epoch: 3 | loss: 0.4567018\n",
      "\tspeed: 0.0500s/iter; left time: 335.5747s\n",
      "\titers: 600, epoch: 3 | loss: 0.4690168\n",
      "\tspeed: 0.0443s/iter; left time: 293.1614s\n",
      "\titers: 700, epoch: 3 | loss: 0.5097059\n",
      "\tspeed: 0.0472s/iter; left time: 307.8238s\n",
      "\titers: 800, epoch: 3 | loss: 0.4482544\n",
      "\tspeed: 0.0481s/iter; left time: 308.5456s\n",
      "\titers: 900, epoch: 3 | loss: 0.4206373\n",
      "\tspeed: 0.0460s/iter; left time: 290.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.56s\n",
      "Steps: 902 | Train Loss: 0.4569905 Vali Loss: 0.7368394 Test Loss: 0.9019122\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3673571\n",
      "\tspeed: 0.1138s/iter; left time: 707.2451s\n",
      "\titers: 200, epoch: 4 | loss: 0.3366677\n",
      "\tspeed: 0.0441s/iter; left time: 269.6832s\n",
      "\titers: 300, epoch: 4 | loss: 0.4368373\n",
      "\tspeed: 0.0462s/iter; left time: 277.7793s\n",
      "\titers: 400, epoch: 4 | loss: 0.4143197\n",
      "\tspeed: 0.0474s/iter; left time: 280.2939s\n",
      "\titers: 500, epoch: 4 | loss: 0.4315954\n",
      "\tspeed: 0.0452s/iter; left time: 262.5614s\n",
      "\titers: 600, epoch: 4 | loss: 0.3634006\n",
      "\tspeed: 0.0445s/iter; left time: 254.1167s\n",
      "\titers: 700, epoch: 4 | loss: 0.3813722\n",
      "\tspeed: 0.0431s/iter; left time: 241.9370s\n",
      "\titers: 800, epoch: 4 | loss: 0.3931862\n",
      "\tspeed: 0.0325s/iter; left time: 179.1061s\n",
      "\titers: 900, epoch: 4 | loss: 0.3680252\n",
      "\tspeed: 0.0471s/iter; left time: 255.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.09s\n",
      "Steps: 902 | Train Loss: 0.3843258 Vali Loss: 0.7553437 Test Loss: 0.9959126\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3882638\n",
      "\tspeed: 0.1177s/iter; left time: 625.2141s\n",
      "\titers: 200, epoch: 5 | loss: 0.3447854\n",
      "\tspeed: 0.0365s/iter; left time: 190.0267s\n",
      "\titers: 300, epoch: 5 | loss: 0.3297175\n",
      "\tspeed: 0.0511s/iter; left time: 261.3647s\n",
      "\titers: 400, epoch: 5 | loss: 0.3546920\n",
      "\tspeed: 0.0445s/iter; left time: 223.0862s\n",
      "\titers: 500, epoch: 5 | loss: 0.2664817\n",
      "\tspeed: 0.0477s/iter; left time: 234.5420s\n",
      "\titers: 600, epoch: 5 | loss: 0.3219320\n",
      "\tspeed: 0.0511s/iter; left time: 246.1578s\n",
      "\titers: 700, epoch: 5 | loss: 0.3419119\n",
      "\tspeed: 0.0491s/iter; left time: 231.2912s\n",
      "\titers: 800, epoch: 5 | loss: 0.2921619\n",
      "\tspeed: 0.0474s/iter; left time: 218.5608s\n",
      "\titers: 900, epoch: 5 | loss: 0.2600665\n",
      "\tspeed: 0.0495s/iter; left time: 223.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.15s\n",
      "Steps: 902 | Train Loss: 0.3190285 Vali Loss: 0.8093616 Test Loss: 1.0327603\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8688871264457703, rmse:0.932141125202179, mae:0.6895283460617065, rse:0.738420844078064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1393566\n",
      "\tspeed: 0.0476s/iter; left time: 424.9194s\n",
      "\titers: 200, epoch: 1 | loss: 0.9143065\n",
      "\tspeed: 0.0430s/iter; left time: 379.5376s\n",
      "\titers: 300, epoch: 1 | loss: 0.7530119\n",
      "\tspeed: 0.0373s/iter; left time: 325.3811s\n",
      "\titers: 400, epoch: 1 | loss: 0.8853310\n",
      "\tspeed: 0.0519s/iter; left time: 447.6585s\n",
      "\titers: 500, epoch: 1 | loss: 0.8174672\n",
      "\tspeed: 0.0429s/iter; left time: 365.3990s\n",
      "\titers: 600, epoch: 1 | loss: 0.8674576\n",
      "\tspeed: 0.0463s/iter; left time: 389.4913s\n",
      "\titers: 700, epoch: 1 | loss: 0.8745298\n",
      "\tspeed: 0.0404s/iter; left time: 336.0357s\n",
      "\titers: 800, epoch: 1 | loss: 0.7719849\n",
      "\tspeed: 0.0415s/iter; left time: 340.8900s\n",
      "\titers: 900, epoch: 1 | loss: 0.7784532\n",
      "\tspeed: 0.0495s/iter; left time: 402.3670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.23s\n",
      "Steps: 902 | Train Loss: 0.8739690 Vali Loss: 0.9911066 Test Loss: 1.2682191\n",
      "Validation loss decreased (inf --> 0.991107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8160771\n",
      "\tspeed: 0.1201s/iter; left time: 963.0008s\n",
      "\titers: 200, epoch: 2 | loss: 0.6649356\n",
      "\tspeed: 0.0379s/iter; left time: 300.4086s\n",
      "\titers: 300, epoch: 2 | loss: 0.7001882\n",
      "\tspeed: 0.0465s/iter; left time: 363.3010s\n",
      "\titers: 400, epoch: 2 | loss: 0.4958862\n",
      "\tspeed: 0.0449s/iter; left time: 346.9608s\n",
      "\titers: 500, epoch: 2 | loss: 0.6312916\n",
      "\tspeed: 0.0474s/iter; left time: 361.4229s\n",
      "\titers: 600, epoch: 2 | loss: 0.5352398\n",
      "\tspeed: 0.0486s/iter; left time: 365.3652s\n",
      "\titers: 700, epoch: 2 | loss: 0.5689325\n",
      "\tspeed: 0.0482s/iter; left time: 357.7574s\n",
      "\titers: 800, epoch: 2 | loss: 0.5168986\n",
      "\tspeed: 0.0437s/iter; left time: 319.9723s\n",
      "\titers: 900, epoch: 2 | loss: 0.4881203\n",
      "\tspeed: 0.0473s/iter; left time: 341.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 902 | Train Loss: 0.6218363 Vali Loss: 0.7711947 Test Loss: 0.8897678\n",
      "Validation loss decreased (0.991107 --> 0.771195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4910145\n",
      "\tspeed: 0.1172s/iter; left time: 834.1210s\n",
      "\titers: 200, epoch: 3 | loss: 0.4448029\n",
      "\tspeed: 0.0460s/iter; left time: 322.4591s\n",
      "\titers: 300, epoch: 3 | loss: 0.4320655\n",
      "\tspeed: 0.0497s/iter; left time: 344.0262s\n",
      "\titers: 400, epoch: 3 | loss: 0.3874965\n",
      "\tspeed: 0.0489s/iter; left time: 333.3263s\n",
      "\titers: 500, epoch: 3 | loss: 0.4855063\n",
      "\tspeed: 0.0429s/iter; left time: 288.1246s\n",
      "\titers: 600, epoch: 3 | loss: 0.4454901\n",
      "\tspeed: 0.0461s/iter; left time: 305.2392s\n",
      "\titers: 700, epoch: 3 | loss: 0.4698119\n",
      "\tspeed: 0.0471s/iter; left time: 306.7477s\n",
      "\titers: 800, epoch: 3 | loss: 0.3589253\n",
      "\tspeed: 0.0479s/iter; left time: 307.4533s\n",
      "\titers: 900, epoch: 3 | loss: 0.4190975\n",
      "\tspeed: 0.0480s/iter; left time: 303.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 902 | Train Loss: 0.4638550 Vali Loss: 0.7277861 Test Loss: 0.9262581\n",
      "Validation loss decreased (0.771195 --> 0.727786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3920750\n",
      "\tspeed: 0.1172s/iter; left time: 728.5566s\n",
      "\titers: 200, epoch: 4 | loss: 0.4400256\n",
      "\tspeed: 0.0436s/iter; left time: 266.3261s\n",
      "\titers: 300, epoch: 4 | loss: 0.4587332\n",
      "\tspeed: 0.0477s/iter; left time: 287.1800s\n",
      "\titers: 400, epoch: 4 | loss: 0.4224612\n",
      "\tspeed: 0.0436s/iter; left time: 257.7865s\n",
      "\titers: 500, epoch: 4 | loss: 0.4056634\n",
      "\tspeed: 0.0338s/iter; left time: 196.5805s\n",
      "\titers: 600, epoch: 4 | loss: 0.3859549\n",
      "\tspeed: 0.0357s/iter; left time: 203.8124s\n",
      "\titers: 700, epoch: 4 | loss: 0.3446541\n",
      "\tspeed: 0.0498s/iter; left time: 279.8716s\n",
      "\titers: 800, epoch: 4 | loss: 0.3232461\n",
      "\tspeed: 0.0485s/iter; left time: 267.6031s\n",
      "\titers: 900, epoch: 4 | loss: 0.3906113\n",
      "\tspeed: 0.0484s/iter; left time: 262.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.33s\n",
      "Steps: 902 | Train Loss: 0.3897519 Vali Loss: 0.7961924 Test Loss: 0.9809527\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3371960\n",
      "\tspeed: 0.1162s/iter; left time: 617.5159s\n",
      "\titers: 200, epoch: 5 | loss: 0.3259346\n",
      "\tspeed: 0.0398s/iter; left time: 207.6394s\n",
      "\titers: 300, epoch: 5 | loss: 0.3361426\n",
      "\tspeed: 0.0430s/iter; left time: 219.8740s\n",
      "\titers: 400, epoch: 5 | loss: 0.3220299\n",
      "\tspeed: 0.0473s/iter; left time: 236.9785s\n",
      "\titers: 500, epoch: 5 | loss: 0.3229633\n",
      "\tspeed: 0.0484s/iter; left time: 237.6353s\n",
      "\titers: 600, epoch: 5 | loss: 0.3446602\n",
      "\tspeed: 0.0437s/iter; left time: 210.1247s\n",
      "\titers: 700, epoch: 5 | loss: 0.2994532\n",
      "\tspeed: 0.0453s/iter; left time: 213.5172s\n",
      "\titers: 800, epoch: 5 | loss: 0.3389182\n",
      "\tspeed: 0.0469s/iter; left time: 216.3645s\n",
      "\titers: 900, epoch: 5 | loss: 0.3102732\n",
      "\tspeed: 0.0458s/iter; left time: 206.4917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.54s\n",
      "Steps: 902 | Train Loss: 0.3286309 Vali Loss: 0.8320279 Test Loss: 1.0124506\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2721474\n",
      "\tspeed: 0.1133s/iter; left time: 499.6856s\n",
      "\titers: 200, epoch: 6 | loss: 0.2796655\n",
      "\tspeed: 0.0492s/iter; left time: 212.0922s\n",
      "\titers: 300, epoch: 6 | loss: 0.2728179\n",
      "\tspeed: 0.0477s/iter; left time: 200.6867s\n",
      "\titers: 400, epoch: 6 | loss: 0.2818705\n",
      "\tspeed: 0.0485s/iter; left time: 199.2769s\n",
      "\titers: 500, epoch: 6 | loss: 0.3008921\n",
      "\tspeed: 0.0451s/iter; left time: 180.9723s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391719\n",
      "\tspeed: 0.0483s/iter; left time: 188.7859s\n",
      "\titers: 700, epoch: 6 | loss: 0.2640676\n",
      "\tspeed: 0.0461s/iter; left time: 175.7160s\n",
      "\titers: 800, epoch: 6 | loss: 0.2629663\n",
      "\tspeed: 0.0476s/iter; left time: 176.4960s\n",
      "\titers: 900, epoch: 6 | loss: 0.2862093\n",
      "\tspeed: 0.0474s/iter; left time: 171.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 902 | Train Loss: 0.2777607 Vali Loss: 0.8101708 Test Loss: 1.0729544\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.9266458749771118, rmse:0.9626244902610779, mae:0.7018088698387146, rse:0.762569010257721\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9330069\n",
      "\tspeed: 0.0757s/iter; left time: 678.4545s\n",
      "\titers: 200, epoch: 1 | loss: 0.8453555\n",
      "\tspeed: 0.0411s/iter; left time: 364.5196s\n",
      "\titers: 300, epoch: 1 | loss: 0.7602814\n",
      "\tspeed: 0.0434s/iter; left time: 380.6528s\n",
      "\titers: 400, epoch: 1 | loss: 0.7186459\n",
      "\tspeed: 0.0469s/iter; left time: 406.2299s\n",
      "\titers: 500, epoch: 1 | loss: 0.6569836\n",
      "\tspeed: 0.0463s/iter; left time: 396.5698s\n",
      "\titers: 600, epoch: 1 | loss: 0.6428289\n",
      "\tspeed: 0.0491s/iter; left time: 415.6338s\n",
      "\titers: 700, epoch: 1 | loss: 0.7695857\n",
      "\tspeed: 0.0453s/iter; left time: 378.5774s\n",
      "\titers: 800, epoch: 1 | loss: 0.6622694\n",
      "\tspeed: 0.0471s/iter; left time: 389.1302s\n",
      "\titers: 900, epoch: 1 | loss: 0.5839673\n",
      "\tspeed: 0.0450s/iter; left time: 367.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 906 | Train Loss: 0.7568683 Vali Loss: 0.5546314 Test Loss: 0.6297955\n",
      "Validation loss decreased (inf --> 0.554631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4925327\n",
      "\tspeed: 0.1021s/iter; left time: 822.4155s\n",
      "\titers: 200, epoch: 2 | loss: 0.6552089\n",
      "\tspeed: 0.0460s/iter; left time: 365.7620s\n",
      "\titers: 300, epoch: 2 | loss: 0.5369264\n",
      "\tspeed: 0.0481s/iter; left time: 378.1335s\n",
      "\titers: 400, epoch: 2 | loss: 0.6216661\n",
      "\tspeed: 0.0464s/iter; left time: 359.9221s\n",
      "\titers: 500, epoch: 2 | loss: 0.4922632\n",
      "\tspeed: 0.0385s/iter; left time: 294.8366s\n",
      "\titers: 600, epoch: 2 | loss: 0.5242267\n",
      "\tspeed: 0.0474s/iter; left time: 358.2048s\n",
      "\titers: 700, epoch: 2 | loss: 0.5080407\n",
      "\tspeed: 0.0447s/iter; left time: 332.9718s\n",
      "\titers: 800, epoch: 2 | loss: 0.6309784\n",
      "\tspeed: 0.0441s/iter; left time: 324.4123s\n",
      "\titers: 900, epoch: 2 | loss: 0.5376483\n",
      "\tspeed: 0.0462s/iter; left time: 335.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.90s\n",
      "Steps: 906 | Train Loss: 0.5750265 Vali Loss: 0.4414624 Test Loss: 0.5053346\n",
      "Validation loss decreased (0.554631 --> 0.441462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5605602\n",
      "\tspeed: 0.1117s/iter; left time: 798.6254s\n",
      "\titers: 200, epoch: 3 | loss: 0.4999320\n",
      "\tspeed: 0.0484s/iter; left time: 341.0114s\n",
      "\titers: 300, epoch: 3 | loss: 0.5261015\n",
      "\tspeed: 0.0481s/iter; left time: 334.2855s\n",
      "\titers: 400, epoch: 3 | loss: 0.5118964\n",
      "\tspeed: 0.0463s/iter; left time: 317.3303s\n",
      "\titers: 500, epoch: 3 | loss: 0.6048349\n",
      "\tspeed: 0.0475s/iter; left time: 320.5629s\n",
      "\titers: 600, epoch: 3 | loss: 0.5581745\n",
      "\tspeed: 0.0482s/iter; left time: 320.7651s\n",
      "\titers: 700, epoch: 3 | loss: 0.5284329\n",
      "\tspeed: 0.0454s/iter; left time: 297.4727s\n",
      "\titers: 800, epoch: 3 | loss: 0.5078094\n",
      "\tspeed: 0.0431s/iter; left time: 277.6537s\n",
      "\titers: 900, epoch: 3 | loss: 0.5344877\n",
      "\tspeed: 0.0445s/iter; left time: 282.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.24s\n",
      "Steps: 906 | Train Loss: 0.5267524 Vali Loss: 0.4544460 Test Loss: 0.4899718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4936729\n",
      "\tspeed: 0.1149s/iter; left time: 717.3971s\n",
      "\titers: 200, epoch: 4 | loss: 0.4679694\n",
      "\tspeed: 0.0480s/iter; left time: 294.7833s\n",
      "\titers: 300, epoch: 4 | loss: 0.4733409\n",
      "\tspeed: 0.0475s/iter; left time: 286.8630s\n",
      "\titers: 400, epoch: 4 | loss: 0.4508262\n",
      "\tspeed: 0.0439s/iter; left time: 261.1532s\n",
      "\titers: 500, epoch: 4 | loss: 0.5471892\n",
      "\tspeed: 0.0484s/iter; left time: 282.9299s\n",
      "\titers: 600, epoch: 4 | loss: 0.5013523\n",
      "\tspeed: 0.0389s/iter; left time: 223.3281s\n",
      "\titers: 700, epoch: 4 | loss: 0.4698382\n",
      "\tspeed: 0.0436s/iter; left time: 246.2966s\n",
      "\titers: 800, epoch: 4 | loss: 0.5174342\n",
      "\tspeed: 0.0498s/iter; left time: 276.0929s\n",
      "\titers: 900, epoch: 4 | loss: 0.4840794\n",
      "\tspeed: 0.0442s/iter; left time: 240.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.26s\n",
      "Steps: 906 | Train Loss: 0.4860738 Vali Loss: 0.4616316 Test Loss: 0.4971804\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4414572\n",
      "\tspeed: 0.1078s/iter; left time: 575.0675s\n",
      "\titers: 200, epoch: 5 | loss: 0.4247738\n",
      "\tspeed: 0.0466s/iter; left time: 243.8683s\n",
      "\titers: 300, epoch: 5 | loss: 0.4171564\n",
      "\tspeed: 0.0467s/iter; left time: 239.9151s\n",
      "\titers: 400, epoch: 5 | loss: 0.4687782\n",
      "\tspeed: 0.0400s/iter; left time: 201.3142s\n",
      "\titers: 500, epoch: 5 | loss: 0.4089259\n",
      "\tspeed: 0.0466s/iter; left time: 229.9950s\n",
      "\titers: 600, epoch: 5 | loss: 0.4598964\n",
      "\tspeed: 0.0434s/iter; left time: 210.1435s\n",
      "\titers: 700, epoch: 5 | loss: 0.4366154\n",
      "\tspeed: 0.0466s/iter; left time: 220.8223s\n",
      "\titers: 800, epoch: 5 | loss: 0.4666919\n",
      "\tspeed: 0.0438s/iter; left time: 203.0281s\n",
      "\titers: 900, epoch: 5 | loss: 0.4258851\n",
      "\tspeed: 0.0391s/iter; left time: 177.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.66s\n",
      "Steps: 906 | Train Loss: 0.4412755 Vali Loss: 0.4771856 Test Loss: 0.5294752\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.5057210326194763, rmse:0.7111406326293945, mae:0.4946559965610504, rse:0.5628229379653931\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8535094\n",
      "\tspeed: 0.0503s/iter; left time: 450.3869s\n",
      "\titers: 200, epoch: 1 | loss: 0.7946691\n",
      "\tspeed: 0.0478s/iter; left time: 423.7283s\n",
      "\titers: 300, epoch: 1 | loss: 0.8239724\n",
      "\tspeed: 0.0411s/iter; left time: 360.2720s\n",
      "\titers: 400, epoch: 1 | loss: 0.7694098\n",
      "\tspeed: 0.0464s/iter; left time: 401.5208s\n",
      "\titers: 500, epoch: 1 | loss: 0.7350209\n",
      "\tspeed: 0.0447s/iter; left time: 382.3435s\n",
      "\titers: 600, epoch: 1 | loss: 0.6871554\n",
      "\tspeed: 0.0484s/iter; left time: 409.2717s\n",
      "\titers: 700, epoch: 1 | loss: 0.6397360\n",
      "\tspeed: 0.0470s/iter; left time: 392.9268s\n",
      "\titers: 800, epoch: 1 | loss: 0.6996447\n",
      "\tspeed: 0.0416s/iter; left time: 343.4839s\n",
      "\titers: 900, epoch: 1 | loss: 0.6448403\n",
      "\tspeed: 0.0423s/iter; left time: 344.8698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.29s\n",
      "Steps: 906 | Train Loss: 0.7621180 Vali Loss: 0.5469301 Test Loss: 0.6322393\n",
      "Validation loss decreased (inf --> 0.546930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5901652\n",
      "\tspeed: 0.1033s/iter; left time: 832.4697s\n",
      "\titers: 200, epoch: 2 | loss: 0.5678676\n",
      "\tspeed: 0.0445s/iter; left time: 354.1259s\n",
      "\titers: 300, epoch: 2 | loss: 0.5308166\n",
      "\tspeed: 0.0455s/iter; left time: 357.6625s\n",
      "\titers: 400, epoch: 2 | loss: 0.5040628\n",
      "\tspeed: 0.0445s/iter; left time: 344.9546s\n",
      "\titers: 500, epoch: 2 | loss: 0.5594317\n",
      "\tspeed: 0.0416s/iter; left time: 318.1548s\n",
      "\titers: 600, epoch: 2 | loss: 0.5838062\n",
      "\tspeed: 0.0451s/iter; left time: 341.0750s\n",
      "\titers: 700, epoch: 2 | loss: 0.5541881\n",
      "\tspeed: 0.0279s/iter; left time: 208.2252s\n",
      "\titers: 800, epoch: 2 | loss: 0.4941785\n",
      "\tspeed: 0.0393s/iter; left time: 289.3656s\n",
      "\titers: 900, epoch: 2 | loss: 0.5622355\n",
      "\tspeed: 0.0440s/iter; left time: 319.5572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 906 | Train Loss: 0.5777639 Vali Loss: 0.4899707 Test Loss: 0.5332431\n",
      "Validation loss decreased (0.546930 --> 0.489971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6155403\n",
      "\tspeed: 0.1131s/iter; left time: 808.2134s\n",
      "\titers: 200, epoch: 3 | loss: 0.5076671\n",
      "\tspeed: 0.0474s/iter; left time: 334.2322s\n",
      "\titers: 300, epoch: 3 | loss: 0.4814539\n",
      "\tspeed: 0.0477s/iter; left time: 331.6706s\n",
      "\titers: 400, epoch: 3 | loss: 0.5277675\n",
      "\tspeed: 0.0349s/iter; left time: 239.0048s\n",
      "\titers: 500, epoch: 3 | loss: 0.5166872\n",
      "\tspeed: 0.0440s/iter; left time: 297.2397s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973823\n",
      "\tspeed: 0.0386s/iter; left time: 256.7637s\n",
      "\titers: 700, epoch: 3 | loss: 0.5548823\n",
      "\tspeed: 0.0448s/iter; left time: 293.6382s\n",
      "\titers: 800, epoch: 3 | loss: 0.5437278\n",
      "\tspeed: 0.0464s/iter; left time: 299.2056s\n",
      "\titers: 900, epoch: 3 | loss: 0.4600593\n",
      "\tspeed: 0.0430s/iter; left time: 272.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 906 | Train Loss: 0.5295003 Vali Loss: 0.4463684 Test Loss: 0.4901480\n",
      "Validation loss decreased (0.489971 --> 0.446368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4812785\n",
      "\tspeed: 0.1083s/iter; left time: 675.8931s\n",
      "\titers: 200, epoch: 4 | loss: 0.4892790\n",
      "\tspeed: 0.0496s/iter; left time: 304.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.6160949\n",
      "\tspeed: 0.0494s/iter; left time: 298.7421s\n",
      "\titers: 400, epoch: 4 | loss: 0.4594419\n",
      "\tspeed: 0.0470s/iter; left time: 279.6086s\n",
      "\titers: 500, epoch: 4 | loss: 0.5361103\n",
      "\tspeed: 0.0432s/iter; left time: 252.4201s\n",
      "\titers: 600, epoch: 4 | loss: 0.5496232\n",
      "\tspeed: 0.0459s/iter; left time: 263.8301s\n",
      "\titers: 700, epoch: 4 | loss: 0.5037587\n",
      "\tspeed: 0.0458s/iter; left time: 258.6352s\n",
      "\titers: 800, epoch: 4 | loss: 0.4001136\n",
      "\tspeed: 0.0461s/iter; left time: 255.2893s\n",
      "\titers: 900, epoch: 4 | loss: 0.3969443\n",
      "\tspeed: 0.0466s/iter; left time: 253.5491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.36s\n",
      "Steps: 906 | Train Loss: 0.4886948 Vali Loss: 0.4524543 Test Loss: 0.5091438\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5059643\n",
      "\tspeed: 0.1103s/iter; left time: 588.4948s\n",
      "\titers: 200, epoch: 5 | loss: 0.4228405\n",
      "\tspeed: 0.0444s/iter; left time: 232.7318s\n",
      "\titers: 300, epoch: 5 | loss: 0.4532999\n",
      "\tspeed: 0.0477s/iter; left time: 244.9761s\n",
      "\titers: 400, epoch: 5 | loss: 0.4513590\n",
      "\tspeed: 0.0462s/iter; left time: 232.9449s\n",
      "\titers: 500, epoch: 5 | loss: 0.3767618\n",
      "\tspeed: 0.0473s/iter; left time: 233.4467s\n",
      "\titers: 600, epoch: 5 | loss: 0.4681946\n",
      "\tspeed: 0.0504s/iter; left time: 243.7942s\n",
      "\titers: 700, epoch: 5 | loss: 0.4070669\n",
      "\tspeed: 0.0478s/iter; left time: 226.4354s\n",
      "\titers: 800, epoch: 5 | loss: 0.4433880\n",
      "\tspeed: 0.0469s/iter; left time: 217.4913s\n",
      "\titers: 900, epoch: 5 | loss: 0.4146545\n",
      "\tspeed: 0.0467s/iter; left time: 211.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 906 | Train Loss: 0.4431850 Vali Loss: 0.4535797 Test Loss: 0.4955657\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4227463\n",
      "\tspeed: 0.1035s/iter; left time: 458.7956s\n",
      "\titers: 200, epoch: 6 | loss: 0.4208098\n",
      "\tspeed: 0.0474s/iter; left time: 205.1766s\n",
      "\titers: 300, epoch: 6 | loss: 0.4598391\n",
      "\tspeed: 0.0461s/iter; left time: 195.1145s\n",
      "\titers: 400, epoch: 6 | loss: 0.4062849\n",
      "\tspeed: 0.0481s/iter; left time: 198.9043s\n",
      "\titers: 500, epoch: 6 | loss: 0.3981254\n",
      "\tspeed: 0.0462s/iter; left time: 186.2537s\n",
      "\titers: 600, epoch: 6 | loss: 0.3871465\n",
      "\tspeed: 0.0453s/iter; left time: 178.2389s\n",
      "\titers: 700, epoch: 6 | loss: 0.3854539\n",
      "\tspeed: 0.0477s/iter; left time: 182.7942s\n",
      "\titers: 800, epoch: 6 | loss: 0.3696713\n",
      "\tspeed: 0.0488s/iter; left time: 181.9935s\n",
      "\titers: 900, epoch: 6 | loss: 0.3746774\n",
      "\tspeed: 0.0431s/iter; left time: 156.6726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.07s\n",
      "Steps: 906 | Train Loss: 0.4019445 Vali Loss: 0.4811350 Test Loss: 0.5307937\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.48906710743904114, rmse:0.6993333101272583, mae:0.47708749771118164, rse:0.5534781813621521\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0264677\n",
      "\tspeed: 0.0818s/iter; left time: 731.1856s\n",
      "\titers: 200, epoch: 1 | loss: 0.9801179\n",
      "\tspeed: 0.0337s/iter; left time: 298.0465s\n",
      "\titers: 300, epoch: 1 | loss: 0.9595107\n",
      "\tspeed: 0.0469s/iter; left time: 409.6896s\n",
      "\titers: 400, epoch: 1 | loss: 0.8818166\n",
      "\tspeed: 0.0454s/iter; left time: 392.4995s\n",
      "\titers: 500, epoch: 1 | loss: 0.8849459\n",
      "\tspeed: 0.0464s/iter; left time: 396.4358s\n",
      "\titers: 600, epoch: 1 | loss: 0.8034068\n",
      "\tspeed: 0.0441s/iter; left time: 372.5535s\n",
      "\titers: 700, epoch: 1 | loss: 0.7850668\n",
      "\tspeed: 0.0459s/iter; left time: 382.7622s\n",
      "\titers: 800, epoch: 1 | loss: 0.8018121\n",
      "\tspeed: 0.0442s/iter; left time: 364.5291s\n",
      "\titers: 900, epoch: 1 | loss: 0.8086565\n",
      "\tspeed: 0.0447s/iter; left time: 363.9261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.22s\n",
      "Steps: 904 | Train Loss: 0.8982253 Vali Loss: 0.8284824 Test Loss: 1.0305047\n",
      "Validation loss decreased (inf --> 0.828482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7219115\n",
      "\tspeed: 0.1064s/iter; left time: 854.7557s\n",
      "\titers: 200, epoch: 2 | loss: 0.7575591\n",
      "\tspeed: 0.0488s/iter; left time: 387.1885s\n",
      "\titers: 300, epoch: 2 | loss: 0.7236546\n",
      "\tspeed: 0.0485s/iter; left time: 380.4791s\n",
      "\titers: 400, epoch: 2 | loss: 0.6981441\n",
      "\tspeed: 0.0512s/iter; left time: 396.4393s\n",
      "\titers: 500, epoch: 2 | loss: 0.6987032\n",
      "\tspeed: 0.0469s/iter; left time: 358.3607s\n",
      "\titers: 600, epoch: 2 | loss: 0.7710373\n",
      "\tspeed: 0.0450s/iter; left time: 339.4294s\n",
      "\titers: 700, epoch: 2 | loss: 0.6912770\n",
      "\tspeed: 0.0475s/iter; left time: 353.1112s\n",
      "\titers: 800, epoch: 2 | loss: 0.7383023\n",
      "\tspeed: 0.0360s/iter; left time: 264.3670s\n",
      "\titers: 900, epoch: 2 | loss: 0.6886944\n",
      "\tspeed: 0.0403s/iter; left time: 291.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.41s\n",
      "Steps: 904 | Train Loss: 0.7270669 Vali Loss: 0.6901102 Test Loss: 0.8281889\n",
      "Validation loss decreased (0.828482 --> 0.690110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7503220\n",
      "\tspeed: 0.1059s/iter; left time: 755.0869s\n",
      "\titers: 200, epoch: 3 | loss: 0.6363679\n",
      "\tspeed: 0.0373s/iter; left time: 262.2750s\n",
      "\titers: 300, epoch: 3 | loss: 0.6213876\n",
      "\tspeed: 0.0480s/iter; left time: 332.5645s\n",
      "\titers: 400, epoch: 3 | loss: 0.6248445\n",
      "\tspeed: 0.0496s/iter; left time: 339.0722s\n",
      "\titers: 500, epoch: 3 | loss: 0.6535972\n",
      "\tspeed: 0.0430s/iter; left time: 289.3550s\n",
      "\titers: 600, epoch: 3 | loss: 0.6578666\n",
      "\tspeed: 0.0408s/iter; left time: 270.6746s\n",
      "\titers: 700, epoch: 3 | loss: 0.6138929\n",
      "\tspeed: 0.0435s/iter; left time: 283.8799s\n",
      "\titers: 800, epoch: 3 | loss: 0.6245969\n",
      "\tspeed: 0.0453s/iter; left time: 291.6374s\n",
      "\titers: 900, epoch: 3 | loss: 0.6433622\n",
      "\tspeed: 0.0462s/iter; left time: 292.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.13s\n",
      "Steps: 904 | Train Loss: 0.6530545 Vali Loss: 0.6907275 Test Loss: 0.8539100\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5800280\n",
      "\tspeed: 0.1072s/iter; left time: 667.6298s\n",
      "\titers: 200, epoch: 4 | loss: 0.6194643\n",
      "\tspeed: 0.0472s/iter; left time: 289.1371s\n",
      "\titers: 300, epoch: 4 | loss: 0.5794554\n",
      "\tspeed: 0.0477s/iter; left time: 287.4611s\n",
      "\titers: 400, epoch: 4 | loss: 0.5340925\n",
      "\tspeed: 0.0465s/iter; left time: 275.9308s\n",
      "\titers: 500, epoch: 4 | loss: 0.6164418\n",
      "\tspeed: 0.0484s/iter; left time: 282.2499s\n",
      "\titers: 600, epoch: 4 | loss: 0.5517719\n",
      "\tspeed: 0.0474s/iter; left time: 271.2856s\n",
      "\titers: 700, epoch: 4 | loss: 0.6099968\n",
      "\tspeed: 0.0479s/iter; left time: 269.4988s\n",
      "\titers: 800, epoch: 4 | loss: 0.5545557\n",
      "\tspeed: 0.0353s/iter; left time: 194.9819s\n",
      "\titers: 900, epoch: 4 | loss: 0.6094258\n",
      "\tspeed: 0.0318s/iter; left time: 172.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 904 | Train Loss: 0.5975364 Vali Loss: 0.7084284 Test Loss: 0.9339083\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5656684\n",
      "\tspeed: 0.0889s/iter; left time: 473.6508s\n",
      "\titers: 200, epoch: 5 | loss: 0.6042323\n",
      "\tspeed: 0.0435s/iter; left time: 227.1767s\n",
      "\titers: 300, epoch: 5 | loss: 0.5565632\n",
      "\tspeed: 0.0480s/iter; left time: 245.8606s\n",
      "\titers: 400, epoch: 5 | loss: 0.5871056\n",
      "\tspeed: 0.0449s/iter; left time: 225.6866s\n",
      "\titers: 500, epoch: 5 | loss: 0.5080324\n",
      "\tspeed: 0.0460s/iter; left time: 226.5098s\n",
      "\titers: 600, epoch: 5 | loss: 0.5494707\n",
      "\tspeed: 0.0471s/iter; left time: 227.4873s\n",
      "\titers: 700, epoch: 5 | loss: 0.5326818\n",
      "\tspeed: 0.0493s/iter; left time: 233.1622s\n",
      "\titers: 800, epoch: 5 | loss: 0.4755292\n",
      "\tspeed: 0.0456s/iter; left time: 211.1026s\n",
      "\titers: 900, epoch: 5 | loss: 0.5099325\n",
      "\tspeed: 0.0460s/iter; left time: 208.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.59s\n",
      "Steps: 904 | Train Loss: 0.5448991 Vali Loss: 0.7290903 Test Loss: 0.9332197\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.8274734616279602, rmse:0.9096556901931763, mae:0.6720293760299683, rse:0.7214690446853638\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9505200\n",
      "\tspeed: 0.0483s/iter; left time: 431.6384s\n",
      "\titers: 200, epoch: 1 | loss: 0.9048980\n",
      "\tspeed: 0.0457s/iter; left time: 404.2320s\n",
      "\titers: 300, epoch: 1 | loss: 0.9254318\n",
      "\tspeed: 0.0450s/iter; left time: 392.9740s\n",
      "\titers: 400, epoch: 1 | loss: 0.9067376\n",
      "\tspeed: 0.0436s/iter; left time: 376.4874s\n",
      "\titers: 500, epoch: 1 | loss: 0.9278110\n",
      "\tspeed: 0.0468s/iter; left time: 399.7317s\n",
      "\titers: 600, epoch: 1 | loss: 0.8114620\n",
      "\tspeed: 0.0464s/iter; left time: 391.7953s\n",
      "\titers: 700, epoch: 1 | loss: 0.9604274\n",
      "\tspeed: 0.0466s/iter; left time: 388.6727s\n",
      "\titers: 800, epoch: 1 | loss: 0.8274011\n",
      "\tspeed: 0.0459s/iter; left time: 378.4566s\n",
      "\titers: 900, epoch: 1 | loss: 0.8536888\n",
      "\tspeed: 0.0449s/iter; left time: 365.2601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 904 | Train Loss: 0.9021629 Vali Loss: 0.8219671 Test Loss: 1.0340171\n",
      "Validation loss decreased (inf --> 0.821967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8083791\n",
      "\tspeed: 0.1068s/iter; left time: 858.1971s\n",
      "\titers: 200, epoch: 2 | loss: 0.7864435\n",
      "\tspeed: 0.0476s/iter; left time: 377.4207s\n",
      "\titers: 300, epoch: 2 | loss: 0.7446700\n",
      "\tspeed: 0.0484s/iter; left time: 379.0859s\n",
      "\titers: 400, epoch: 2 | loss: 0.6564226\n",
      "\tspeed: 0.0477s/iter; left time: 368.9011s\n",
      "\titers: 500, epoch: 2 | loss: 0.6981217\n",
      "\tspeed: 0.0439s/iter; left time: 335.6301s\n",
      "\titers: 600, epoch: 2 | loss: 0.7814509\n",
      "\tspeed: 0.0315s/iter; left time: 237.1978s\n",
      "\titers: 700, epoch: 2 | loss: 0.7051031\n",
      "\tspeed: 0.0393s/iter; left time: 291.9354s\n",
      "\titers: 800, epoch: 2 | loss: 0.7401963\n",
      "\tspeed: 0.0453s/iter; left time: 332.2627s\n",
      "\titers: 900, epoch: 2 | loss: 0.6389695\n",
      "\tspeed: 0.0417s/iter; left time: 301.8124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.64s\n",
      "Steps: 904 | Train Loss: 0.7266495 Vali Loss: 0.6755250 Test Loss: 0.8264167\n",
      "Validation loss decreased (0.821967 --> 0.675525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6733680\n",
      "\tspeed: 0.1069s/iter; left time: 762.7999s\n",
      "\titers: 200, epoch: 3 | loss: 0.6566669\n",
      "\tspeed: 0.0471s/iter; left time: 331.2583s\n",
      "\titers: 300, epoch: 3 | loss: 0.6292443\n",
      "\tspeed: 0.0444s/iter; left time: 307.5608s\n",
      "\titers: 400, epoch: 3 | loss: 0.6274866\n",
      "\tspeed: 0.0472s/iter; left time: 322.6036s\n",
      "\titers: 500, epoch: 3 | loss: 0.6195701\n",
      "\tspeed: 0.0434s/iter; left time: 291.9572s\n",
      "\titers: 600, epoch: 3 | loss: 0.6395187\n",
      "\tspeed: 0.0482s/iter; left time: 319.8340s\n",
      "\titers: 700, epoch: 3 | loss: 0.6765928\n",
      "\tspeed: 0.0434s/iter; left time: 283.2637s\n",
      "\titers: 800, epoch: 3 | loss: 0.6868142\n",
      "\tspeed: 0.0458s/iter; left time: 294.4147s\n",
      "\titers: 900, epoch: 3 | loss: 0.6339136\n",
      "\tspeed: 0.0482s/iter; left time: 305.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.70s\n",
      "Steps: 904 | Train Loss: 0.6473826 Vali Loss: 0.7033238 Test Loss: 0.8842263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5862736\n",
      "\tspeed: 0.1056s/iter; left time: 658.0080s\n",
      "\titers: 200, epoch: 4 | loss: 0.5791789\n",
      "\tspeed: 0.0442s/iter; left time: 271.0017s\n",
      "\titers: 300, epoch: 4 | loss: 0.5872557\n",
      "\tspeed: 0.0481s/iter; left time: 289.7939s\n",
      "\titers: 400, epoch: 4 | loss: 0.5707231\n",
      "\tspeed: 0.0469s/iter; left time: 277.9367s\n",
      "\titers: 500, epoch: 4 | loss: 0.5918388\n",
      "\tspeed: 0.0437s/iter; left time: 254.9425s\n",
      "\titers: 600, epoch: 4 | loss: 0.5781083\n",
      "\tspeed: 0.0452s/iter; left time: 258.7665s\n",
      "\titers: 700, epoch: 4 | loss: 0.5535720\n",
      "\tspeed: 0.0394s/iter; left time: 221.9433s\n",
      "\titers: 800, epoch: 4 | loss: 0.5847025\n",
      "\tspeed: 0.0475s/iter; left time: 262.6802s\n",
      "\titers: 900, epoch: 4 | loss: 0.5420276\n",
      "\tspeed: 0.0502s/iter; left time: 272.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 904 | Train Loss: 0.5948404 Vali Loss: 0.7119789 Test Loss: 0.9509454\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5292706\n",
      "\tspeed: 0.1079s/iter; left time: 574.5897s\n",
      "\titers: 200, epoch: 5 | loss: 0.5874758\n",
      "\tspeed: 0.0474s/iter; left time: 247.5933s\n",
      "\titers: 300, epoch: 5 | loss: 0.5466622\n",
      "\tspeed: 0.0486s/iter; left time: 249.2745s\n",
      "\titers: 400, epoch: 5 | loss: 0.4963609\n",
      "\tspeed: 0.0463s/iter; left time: 232.8750s\n",
      "\titers: 500, epoch: 5 | loss: 0.5946056\n",
      "\tspeed: 0.0414s/iter; left time: 203.7038s\n",
      "\titers: 600, epoch: 5 | loss: 0.5386021\n",
      "\tspeed: 0.0420s/iter; left time: 202.6301s\n",
      "\titers: 700, epoch: 5 | loss: 0.5422313\n",
      "\tspeed: 0.0419s/iter; left time: 197.9839s\n",
      "\titers: 800, epoch: 5 | loss: 0.5409650\n",
      "\tspeed: 0.0387s/iter; left time: 178.9359s\n",
      "\titers: 900, epoch: 5 | loss: 0.5217851\n",
      "\tspeed: 0.0487s/iter; left time: 220.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 904 | Train Loss: 0.5457621 Vali Loss: 0.6975093 Test Loss: 0.9718154\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.8260217308998108, rmse:0.9088574051856995, mae:0.6637703776359558, rse:0.7208359241485596\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9474945\n",
      "\tspeed: 0.0842s/iter; left time: 751.0800s\n",
      "\titers: 200, epoch: 1 | loss: 0.9880003\n",
      "\tspeed: 0.0464s/iter; left time: 409.4297s\n",
      "\titers: 300, epoch: 1 | loss: 0.9314516\n",
      "\tspeed: 0.0505s/iter; left time: 440.4310s\n",
      "\titers: 400, epoch: 1 | loss: 0.9342875\n",
      "\tspeed: 0.0488s/iter; left time: 420.3275s\n",
      "\titers: 500, epoch: 1 | loss: 0.9170157\n",
      "\tspeed: 0.0441s/iter; left time: 376.1227s\n",
      "\titers: 600, epoch: 1 | loss: 0.9418470\n",
      "\tspeed: 0.0485s/iter; left time: 408.7062s\n",
      "\titers: 700, epoch: 1 | loss: 0.9130619\n",
      "\tspeed: 0.0483s/iter; left time: 401.9092s\n",
      "\titers: 800, epoch: 1 | loss: 0.8756982\n",
      "\tspeed: 0.0427s/iter; left time: 351.4144s\n",
      "\titers: 900, epoch: 1 | loss: 0.9110941\n",
      "\tspeed: 0.0483s/iter; left time: 391.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.77s\n",
      "Steps: 902 | Train Loss: 0.9340611 Vali Loss: 0.9775705 Test Loss: 1.2568259\n",
      "Validation loss decreased (inf --> 0.977571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9062395\n",
      "\tspeed: 0.1190s/iter; left time: 953.9984s\n",
      "\titers: 200, epoch: 2 | loss: 0.8344246\n",
      "\tspeed: 0.0504s/iter; left time: 399.1297s\n",
      "\titers: 300, epoch: 2 | loss: 0.8586082\n",
      "\tspeed: 0.0455s/iter; left time: 355.9932s\n",
      "\titers: 400, epoch: 2 | loss: 0.7839647\n",
      "\tspeed: 0.0422s/iter; left time: 325.7750s\n",
      "\titers: 500, epoch: 2 | loss: 0.7777457\n",
      "\tspeed: 0.0403s/iter; left time: 306.8636s\n",
      "\titers: 600, epoch: 2 | loss: 0.7107472\n",
      "\tspeed: 0.0330s/iter; left time: 248.2740s\n",
      "\titers: 700, epoch: 2 | loss: 0.7191603\n",
      "\tspeed: 0.0448s/iter; left time: 332.7316s\n",
      "\titers: 800, epoch: 2 | loss: 0.7799003\n",
      "\tspeed: 0.0452s/iter; left time: 330.6656s\n",
      "\titers: 900, epoch: 2 | loss: 0.6977441\n",
      "\tspeed: 0.0394s/iter; left time: 284.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.31s\n",
      "Steps: 902 | Train Loss: 0.7721754 Vali Loss: 0.7377347 Test Loss: 0.8857483\n",
      "Validation loss decreased (0.977571 --> 0.737735).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7026943\n",
      "\tspeed: 0.1114s/iter; left time: 792.5189s\n",
      "\titers: 200, epoch: 3 | loss: 0.6979058\n",
      "\tspeed: 0.0459s/iter; left time: 322.1674s\n",
      "\titers: 300, epoch: 3 | loss: 0.7006507\n",
      "\tspeed: 0.0436s/iter; left time: 301.4883s\n",
      "\titers: 400, epoch: 3 | loss: 0.6993150\n",
      "\tspeed: 0.0454s/iter; left time: 309.5378s\n",
      "\titers: 500, epoch: 3 | loss: 0.6774469\n",
      "\tspeed: 0.0483s/iter; left time: 324.5061s\n",
      "\titers: 600, epoch: 3 | loss: 0.6877993\n",
      "\tspeed: 0.0456s/iter; left time: 301.6082s\n",
      "\titers: 700, epoch: 3 | loss: 0.6872499\n",
      "\tspeed: 0.0486s/iter; left time: 317.0035s\n",
      "\titers: 800, epoch: 3 | loss: 0.6633852\n",
      "\tspeed: 0.0471s/iter; left time: 302.3795s\n",
      "\titers: 900, epoch: 3 | loss: 0.6497076\n",
      "\tspeed: 0.0447s/iter; left time: 282.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 902 | Train Loss: 0.6727804 Vali Loss: 0.7758864 Test Loss: 0.9433555\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6027426\n",
      "\tspeed: 0.1043s/iter; left time: 648.3207s\n",
      "\titers: 200, epoch: 4 | loss: 0.5640168\n",
      "\tspeed: 0.0481s/iter; left time: 293.8482s\n",
      "\titers: 300, epoch: 4 | loss: 0.6507311\n",
      "\tspeed: 0.0470s/iter; left time: 282.4644s\n",
      "\titers: 400, epoch: 4 | loss: 0.6264582\n",
      "\tspeed: 0.0474s/iter; left time: 280.1881s\n",
      "\titers: 500, epoch: 4 | loss: 0.6524476\n",
      "\tspeed: 0.0395s/iter; left time: 229.7198s\n",
      "\titers: 600, epoch: 4 | loss: 0.5816422\n",
      "\tspeed: 0.0500s/iter; left time: 285.9913s\n",
      "\titers: 700, epoch: 4 | loss: 0.6202571\n",
      "\tspeed: 0.0473s/iter; left time: 265.5145s\n",
      "\titers: 800, epoch: 4 | loss: 0.6127720\n",
      "\tspeed: 0.0478s/iter; left time: 263.4674s\n",
      "\titers: 900, epoch: 4 | loss: 0.5799875\n",
      "\tspeed: 0.0467s/iter; left time: 252.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 902 | Train Loss: 0.6133093 Vali Loss: 0.8142605 Test Loss: 0.9736470\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6158162\n",
      "\tspeed: 0.1087s/iter; left time: 577.3763s\n",
      "\titers: 200, epoch: 5 | loss: 0.5823934\n",
      "\tspeed: 0.0456s/iter; left time: 237.7623s\n",
      "\titers: 300, epoch: 5 | loss: 0.5776101\n",
      "\tspeed: 0.0397s/iter; left time: 202.9117s\n",
      "\titers: 400, epoch: 5 | loss: 0.5875373\n",
      "\tspeed: 0.0435s/iter; left time: 217.9909s\n",
      "\titers: 500, epoch: 5 | loss: 0.5067228\n",
      "\tspeed: 0.0489s/iter; left time: 240.0825s\n",
      "\titers: 600, epoch: 5 | loss: 0.5445983\n",
      "\tspeed: 0.0459s/iter; left time: 220.8986s\n",
      "\titers: 700, epoch: 5 | loss: 0.5707757\n",
      "\tspeed: 0.0424s/iter; left time: 199.7329s\n",
      "\titers: 800, epoch: 5 | loss: 0.5409237\n",
      "\tspeed: 0.0434s/iter; left time: 200.1174s\n",
      "\titers: 900, epoch: 5 | loss: 0.5059790\n",
      "\tspeed: 0.0491s/iter; left time: 221.4147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 902 | Train Loss: 0.5592844 Vali Loss: 0.8281794 Test Loss: 1.0037689\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8860350251197815, rmse:0.9412943124771118, mae:0.698183000087738, rse:0.745671808719635\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0668987\n",
      "\tspeed: 0.0441s/iter; left time: 393.2643s\n",
      "\titers: 200, epoch: 1 | loss: 0.9551254\n",
      "\tspeed: 0.0436s/iter; left time: 384.2397s\n",
      "\titers: 300, epoch: 1 | loss: 0.8664408\n",
      "\tspeed: 0.0483s/iter; left time: 421.6565s\n",
      "\titers: 400, epoch: 1 | loss: 0.9394103\n",
      "\tspeed: 0.0476s/iter; left time: 410.6138s\n",
      "\titers: 500, epoch: 1 | loss: 0.9028875\n",
      "\tspeed: 0.0479s/iter; left time: 408.2730s\n",
      "\titers: 600, epoch: 1 | loss: 0.9296364\n",
      "\tspeed: 0.0467s/iter; left time: 393.0940s\n",
      "\titers: 700, epoch: 1 | loss: 0.9338796\n",
      "\tspeed: 0.0395s/iter; left time: 328.3337s\n",
      "\titers: 800, epoch: 1 | loss: 0.8771542\n",
      "\tspeed: 0.0461s/iter; left time: 378.9000s\n",
      "\titers: 900, epoch: 1 | loss: 0.8804492\n",
      "\tspeed: 0.0488s/iter; left time: 396.4345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.42s\n",
      "Steps: 902 | Train Loss: 0.9323722 Vali Loss: 0.9888522 Test Loss: 1.2656890\n",
      "Validation loss decreased (inf --> 0.988852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9009312\n",
      "\tspeed: 0.1178s/iter; left time: 944.5419s\n",
      "\titers: 200, epoch: 2 | loss: 0.8135657\n",
      "\tspeed: 0.0479s/iter; left time: 378.9337s\n",
      "\titers: 300, epoch: 2 | loss: 0.8319606\n",
      "\tspeed: 0.0462s/iter; left time: 361.3329s\n",
      "\titers: 400, epoch: 2 | loss: 0.7027991\n",
      "\tspeed: 0.0386s/iter; left time: 298.1869s\n",
      "\titers: 500, epoch: 2 | loss: 0.7844998\n",
      "\tspeed: 0.0489s/iter; left time: 372.2256s\n",
      "\titers: 600, epoch: 2 | loss: 0.7350895\n",
      "\tspeed: 0.0414s/iter; left time: 310.9113s\n",
      "\titers: 700, epoch: 2 | loss: 0.7573729\n",
      "\tspeed: 0.0465s/iter; left time: 345.2184s\n",
      "\titers: 800, epoch: 2 | loss: 0.7036802\n",
      "\tspeed: 0.0468s/iter; left time: 342.7650s\n",
      "\titers: 900, epoch: 2 | loss: 0.6937279\n",
      "\tspeed: 0.0469s/iter; left time: 338.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 902 | Train Loss: 0.7838762 Vali Loss: 0.7578838 Test Loss: 0.8892961\n",
      "Validation loss decreased (0.988852 --> 0.757884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6972606\n",
      "\tspeed: 0.1183s/iter; left time: 842.0171s\n",
      "\titers: 200, epoch: 3 | loss: 0.6568254\n",
      "\tspeed: 0.0435s/iter; left time: 305.3319s\n",
      "\titers: 300, epoch: 3 | loss: 0.6503654\n",
      "\tspeed: 0.0500s/iter; left time: 346.0632s\n",
      "\titers: 400, epoch: 3 | loss: 0.6296730\n",
      "\tspeed: 0.0457s/iter; left time: 311.3428s\n",
      "\titers: 500, epoch: 3 | loss: 0.6704645\n",
      "\tspeed: 0.0458s/iter; left time: 307.9493s\n",
      "\titers: 600, epoch: 3 | loss: 0.6691087\n",
      "\tspeed: 0.0460s/iter; left time: 304.0803s\n",
      "\titers: 700, epoch: 3 | loss: 0.6822655\n",
      "\tspeed: 0.0500s/iter; left time: 325.9312s\n",
      "\titers: 800, epoch: 3 | loss: 0.5971730\n",
      "\tspeed: 0.0419s/iter; left time: 268.7210s\n",
      "\titers: 900, epoch: 3 | loss: 0.6552797\n",
      "\tspeed: 0.0424s/iter; left time: 267.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.83s\n",
      "Steps: 902 | Train Loss: 0.6800711 Vali Loss: 0.7312239 Test Loss: 0.9080275\n",
      "Validation loss decreased (0.757884 --> 0.731224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6022609\n",
      "\tspeed: 0.1184s/iter; left time: 735.7443s\n",
      "\titers: 200, epoch: 4 | loss: 0.6469847\n",
      "\tspeed: 0.0484s/iter; left time: 296.0590s\n",
      "\titers: 300, epoch: 4 | loss: 0.6710585\n",
      "\tspeed: 0.0439s/iter; left time: 264.1506s\n",
      "\titers: 400, epoch: 4 | loss: 0.6569029\n",
      "\tspeed: 0.0472s/iter; left time: 279.0485s\n",
      "\titers: 500, epoch: 4 | loss: 0.6609409\n",
      "\tspeed: 0.0395s/iter; left time: 229.8602s\n",
      "\titers: 600, epoch: 4 | loss: 0.6275567\n",
      "\tspeed: 0.0367s/iter; left time: 209.9763s\n",
      "\titers: 700, epoch: 4 | loss: 0.5990750\n",
      "\tspeed: 0.0482s/iter; left time: 270.6426s\n",
      "\titers: 800, epoch: 4 | loss: 0.5690438\n",
      "\tspeed: 0.0451s/iter; left time: 248.9726s\n",
      "\titers: 900, epoch: 4 | loss: 0.6207455\n",
      "\tspeed: 0.0452s/iter; left time: 244.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.69s\n",
      "Steps: 902 | Train Loss: 0.6193849 Vali Loss: 0.7912178 Test Loss: 0.9645185\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5901183\n",
      "\tspeed: 0.1121s/iter; left time: 595.5942s\n",
      "\titers: 200, epoch: 5 | loss: 0.5357261\n",
      "\tspeed: 0.0465s/iter; left time: 242.1696s\n",
      "\titers: 300, epoch: 5 | loss: 0.5676790\n",
      "\tspeed: 0.0488s/iter; left time: 249.3625s\n",
      "\titers: 400, epoch: 5 | loss: 0.5470582\n",
      "\tspeed: 0.0463s/iter; left time: 232.0109s\n",
      "\titers: 500, epoch: 5 | loss: 0.5785877\n",
      "\tspeed: 0.0458s/iter; left time: 225.0886s\n",
      "\titers: 600, epoch: 5 | loss: 0.5758328\n",
      "\tspeed: 0.0471s/iter; left time: 226.5465s\n",
      "\titers: 700, epoch: 5 | loss: 0.5455018\n",
      "\tspeed: 0.0505s/iter; left time: 237.7742s\n",
      "\titers: 800, epoch: 5 | loss: 0.5653980\n",
      "\tspeed: 0.0390s/iter; left time: 180.0585s\n",
      "\titers: 900, epoch: 5 | loss: 0.5421784\n",
      "\tspeed: 0.0471s/iter; left time: 212.7865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.07s\n",
      "Steps: 902 | Train Loss: 0.5636586 Vali Loss: 0.8288397 Test Loss: 0.9748059\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5102292\n",
      "\tspeed: 0.1028s/iter; left time: 453.5305s\n",
      "\titers: 200, epoch: 6 | loss: 0.5145868\n",
      "\tspeed: 0.0451s/iter; left time: 194.5062s\n",
      "\titers: 300, epoch: 6 | loss: 0.5022091\n",
      "\tspeed: 0.0433s/iter; left time: 182.5153s\n",
      "\titers: 400, epoch: 6 | loss: 0.5260614\n",
      "\tspeed: 0.0432s/iter; left time: 177.4205s\n",
      "\titers: 500, epoch: 6 | loss: 0.5395907\n",
      "\tspeed: 0.0437s/iter; left time: 175.0813s\n",
      "\titers: 600, epoch: 6 | loss: 0.4853570\n",
      "\tspeed: 0.0458s/iter; left time: 179.1295s\n",
      "\titers: 700, epoch: 6 | loss: 0.5272974\n",
      "\tspeed: 0.0468s/iter; left time: 178.4430s\n",
      "\titers: 800, epoch: 6 | loss: 0.4901076\n",
      "\tspeed: 0.0498s/iter; left time: 184.7655s\n",
      "\titers: 900, epoch: 6 | loss: 0.5051708\n",
      "\tspeed: 0.0496s/iter; left time: 179.1110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.92s\n",
      "Steps: 902 | Train Loss: 0.5145088 Vali Loss: 0.8555480 Test Loss: 1.0754648\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.9077568054199219, rmse:0.9527627229690552, mae:0.6933366656303406, rse:0.7547568082809448\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7291694\n",
      "\tspeed: 0.0714s/iter; left time: 639.7119s\n",
      "\titers: 200, epoch: 1 | loss: 0.6625319\n",
      "\tspeed: 0.0420s/iter; left time: 372.4430s\n",
      "\titers: 300, epoch: 1 | loss: 0.6019017\n",
      "\tspeed: 0.0470s/iter; left time: 411.5196s\n",
      "\titers: 400, epoch: 1 | loss: 0.5508921\n",
      "\tspeed: 0.0462s/iter; left time: 399.9227s\n",
      "\titers: 500, epoch: 1 | loss: 0.5146177\n",
      "\tspeed: 0.0450s/iter; left time: 385.2477s\n",
      "\titers: 600, epoch: 1 | loss: 0.5150010\n",
      "\tspeed: 0.0465s/iter; left time: 393.8133s\n",
      "\titers: 700, epoch: 1 | loss: 0.6034381\n",
      "\tspeed: 0.0450s/iter; left time: 376.0126s\n",
      "\titers: 800, epoch: 1 | loss: 0.5074895\n",
      "\tspeed: 0.0448s/iter; left time: 369.8282s\n",
      "\titers: 900, epoch: 1 | loss: 0.4430981\n",
      "\tspeed: 0.0454s/iter; left time: 370.6810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.13s\n",
      "Steps: 906 | Train Loss: 0.5920067 Vali Loss: 0.5611692 Test Loss: 0.5965769\n",
      "Validation loss decreased (inf --> 0.561169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3720299\n",
      "\tspeed: 0.1095s/iter; left time: 882.3953s\n",
      "\titers: 200, epoch: 2 | loss: 0.4639956\n",
      "\tspeed: 0.0476s/iter; left time: 378.5216s\n",
      "\titers: 300, epoch: 2 | loss: 0.3745648\n",
      "\tspeed: 0.0471s/iter; left time: 370.3589s\n",
      "\titers: 400, epoch: 2 | loss: 0.4133372\n",
      "\tspeed: 0.0473s/iter; left time: 366.4460s\n",
      "\titers: 500, epoch: 2 | loss: 0.3466574\n",
      "\tspeed: 0.0449s/iter; left time: 343.4915s\n",
      "\titers: 600, epoch: 2 | loss: 0.3551471\n",
      "\tspeed: 0.0485s/iter; left time: 366.5772s\n",
      "\titers: 700, epoch: 2 | loss: 0.3540934\n",
      "\tspeed: 0.0476s/iter; left time: 354.7835s\n",
      "\titers: 800, epoch: 2 | loss: 0.4193859\n",
      "\tspeed: 0.0466s/iter; left time: 342.4704s\n",
      "\titers: 900, epoch: 2 | loss: 0.3925616\n",
      "\tspeed: 0.0418s/iter; left time: 303.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.41s\n",
      "Steps: 906 | Train Loss: 0.4024890 Vali Loss: 0.4482407 Test Loss: 0.4752986\n",
      "Validation loss decreased (0.561169 --> 0.448241).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3761962\n",
      "\tspeed: 0.1062s/iter; left time: 759.5561s\n",
      "\titers: 200, epoch: 3 | loss: 0.3349366\n",
      "\tspeed: 0.0371s/iter; left time: 261.7124s\n",
      "\titers: 300, epoch: 3 | loss: 0.3515136\n",
      "\tspeed: 0.0457s/iter; left time: 317.3230s\n",
      "\titers: 400, epoch: 3 | loss: 0.3453909\n",
      "\tspeed: 0.0480s/iter; left time: 328.4386s\n",
      "\titers: 500, epoch: 3 | loss: 0.4114959\n",
      "\tspeed: 0.0324s/iter; left time: 218.3501s\n",
      "\titers: 600, epoch: 3 | loss: 0.3672501\n",
      "\tspeed: 0.0476s/iter; left time: 316.3833s\n",
      "\titers: 700, epoch: 3 | loss: 0.3614201\n",
      "\tspeed: 0.0456s/iter; left time: 298.9448s\n",
      "\titers: 800, epoch: 3 | loss: 0.3395962\n",
      "\tspeed: 0.0437s/iter; left time: 282.1270s\n",
      "\titers: 900, epoch: 3 | loss: 0.3495890\n",
      "\tspeed: 0.0455s/iter; left time: 288.7292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 906 | Train Loss: 0.3549216 Vali Loss: 0.4410602 Test Loss: 0.4640522\n",
      "Validation loss decreased (0.448241 --> 0.441060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248505\n",
      "\tspeed: 0.1003s/iter; left time: 625.8939s\n",
      "\titers: 200, epoch: 4 | loss: 0.3409783\n",
      "\tspeed: 0.0347s/iter; left time: 213.3199s\n",
      "\titers: 300, epoch: 4 | loss: 0.3119107\n",
      "\tspeed: 0.0325s/iter; left time: 196.6699s\n",
      "\titers: 400, epoch: 4 | loss: 0.2825992\n",
      "\tspeed: 0.0471s/iter; left time: 280.1340s\n",
      "\titers: 500, epoch: 4 | loss: 0.3735337\n",
      "\tspeed: 0.0420s/iter; left time: 245.4236s\n",
      "\titers: 600, epoch: 4 | loss: 0.3239299\n",
      "\tspeed: 0.0424s/iter; left time: 243.2485s\n",
      "\titers: 700, epoch: 4 | loss: 0.3046439\n",
      "\tspeed: 0.0473s/iter; left time: 267.1870s\n",
      "\titers: 800, epoch: 4 | loss: 0.3458192\n",
      "\tspeed: 0.0440s/iter; left time: 243.7060s\n",
      "\titers: 900, epoch: 4 | loss: 0.3197863\n",
      "\tspeed: 0.0481s/iter; left time: 261.6592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 906 | Train Loss: 0.3301053 Vali Loss: 0.4434324 Test Loss: 0.4585804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3173523\n",
      "\tspeed: 0.1063s/iter; left time: 567.5174s\n",
      "\titers: 200, epoch: 5 | loss: 0.2918978\n",
      "\tspeed: 0.0446s/iter; left time: 233.7640s\n",
      "\titers: 300, epoch: 5 | loss: 0.2791134\n",
      "\tspeed: 0.0450s/iter; left time: 231.4130s\n",
      "\titers: 400, epoch: 5 | loss: 0.3412134\n",
      "\tspeed: 0.0417s/iter; left time: 210.1884s\n",
      "\titers: 500, epoch: 5 | loss: 0.2887617\n",
      "\tspeed: 0.0441s/iter; left time: 217.9036s\n",
      "\titers: 600, epoch: 5 | loss: 0.3212793\n",
      "\tspeed: 0.0462s/iter; left time: 223.6551s\n",
      "\titers: 700, epoch: 5 | loss: 0.2760491\n",
      "\tspeed: 0.0466s/iter; left time: 220.8770s\n",
      "\titers: 800, epoch: 5 | loss: 0.3113039\n",
      "\tspeed: 0.0431s/iter; left time: 199.7606s\n",
      "\titers: 900, epoch: 5 | loss: 0.3274809\n",
      "\tspeed: 0.0469s/iter; left time: 212.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.17s\n",
      "Steps: 906 | Train Loss: 0.3028348 Vali Loss: 0.4478417 Test Loss: 0.4733604\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3078453\n",
      "\tspeed: 0.1063s/iter; left time: 470.9263s\n",
      "\titers: 200, epoch: 6 | loss: 0.2830877\n",
      "\tspeed: 0.0460s/iter; left time: 199.4183s\n",
      "\titers: 300, epoch: 6 | loss: 0.2912150\n",
      "\tspeed: 0.0452s/iter; left time: 191.3419s\n",
      "\titers: 400, epoch: 6 | loss: 0.2746114\n",
      "\tspeed: 0.0373s/iter; left time: 153.8925s\n",
      "\titers: 500, epoch: 6 | loss: 0.2967163\n",
      "\tspeed: 0.0449s/iter; left time: 180.8511s\n",
      "\titers: 600, epoch: 6 | loss: 0.2600384\n",
      "\tspeed: 0.0419s/iter; left time: 164.7979s\n",
      "\titers: 700, epoch: 6 | loss: 0.2873008\n",
      "\tspeed: 0.0460s/iter; left time: 176.1733s\n",
      "\titers: 800, epoch: 6 | loss: 0.2397701\n",
      "\tspeed: 0.0388s/iter; left time: 144.6253s\n",
      "\titers: 900, epoch: 6 | loss: 0.2614063\n",
      "\tspeed: 0.0358s/iter; left time: 129.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.2783248 Vali Loss: 0.4407871 Test Loss: 0.4576899\n",
      "Validation loss decreased (0.441060 --> 0.440787).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2589685\n",
      "\tspeed: 0.1033s/iter; left time: 364.0404s\n",
      "\titers: 200, epoch: 7 | loss: 0.2718148\n",
      "\tspeed: 0.0382s/iter; left time: 130.9269s\n",
      "\titers: 300, epoch: 7 | loss: 0.2943646\n",
      "\tspeed: 0.0394s/iter; left time: 131.0179s\n",
      "\titers: 400, epoch: 7 | loss: 0.2814744\n",
      "\tspeed: 0.0417s/iter; left time: 134.4425s\n",
      "\titers: 500, epoch: 7 | loss: 0.2526398\n",
      "\tspeed: 0.0466s/iter; left time: 145.7595s\n",
      "\titers: 600, epoch: 7 | loss: 0.2305333\n",
      "\tspeed: 0.0436s/iter; left time: 131.8062s\n",
      "\titers: 700, epoch: 7 | loss: 0.2285726\n",
      "\tspeed: 0.0372s/iter; left time: 108.8920s\n",
      "\titers: 800, epoch: 7 | loss: 0.2442082\n",
      "\tspeed: 0.0459s/iter; left time: 129.6812s\n",
      "\titers: 900, epoch: 7 | loss: 0.2665747\n",
      "\tspeed: 0.0329s/iter; left time: 89.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.2552269 Vali Loss: 0.4491005 Test Loss: 0.4817139\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2641042\n",
      "\tspeed: 0.1015s/iter; left time: 265.9365s\n",
      "\titers: 200, epoch: 8 | loss: 0.2304286\n",
      "\tspeed: 0.0439s/iter; left time: 110.4893s\n",
      "\titers: 300, epoch: 8 | loss: 0.2364748\n",
      "\tspeed: 0.0465s/iter; left time: 112.5713s\n",
      "\titers: 400, epoch: 8 | loss: 0.2366613\n",
      "\tspeed: 0.0450s/iter; left time: 104.3791s\n",
      "\titers: 500, epoch: 8 | loss: 0.2366679\n",
      "\tspeed: 0.0467s/iter; left time: 103.6715s\n",
      "\titers: 600, epoch: 8 | loss: 0.2136285\n",
      "\tspeed: 0.0443s/iter; left time: 93.7882s\n",
      "\titers: 700, epoch: 8 | loss: 0.2616574\n",
      "\tspeed: 0.0414s/iter; left time: 83.6217s\n",
      "\titers: 800, epoch: 8 | loss: 0.2531595\n",
      "\tspeed: 0.0436s/iter; left time: 83.5961s\n",
      "\titers: 900, epoch: 8 | loss: 0.2318582\n",
      "\tspeed: 0.0462s/iter; left time: 84.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.79s\n",
      "Steps: 906 | Train Loss: 0.2383089 Vali Loss: 0.4535426 Test Loss: 0.4727233\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2337920\n",
      "\tspeed: 0.1020s/iter; left time: 174.7699s\n",
      "\titers: 200, epoch: 9 | loss: 0.2150753\n",
      "\tspeed: 0.0402s/iter; left time: 64.9126s\n",
      "\titers: 300, epoch: 9 | loss: 0.1994082\n",
      "\tspeed: 0.0433s/iter; left time: 65.5384s\n",
      "\titers: 400, epoch: 9 | loss: 0.1872013\n",
      "\tspeed: 0.0394s/iter; left time: 55.7024s\n",
      "\titers: 500, epoch: 9 | loss: 0.2625577\n",
      "\tspeed: 0.0424s/iter; left time: 55.7075s\n",
      "\titers: 600, epoch: 9 | loss: 0.2212823\n",
      "\tspeed: 0.0459s/iter; left time: 55.7359s\n",
      "\titers: 700, epoch: 9 | loss: 0.2057136\n",
      "\tspeed: 0.0484s/iter; left time: 53.8649s\n",
      "\titers: 800, epoch: 9 | loss: 0.2123671\n",
      "\tspeed: 0.0410s/iter; left time: 41.5381s\n",
      "\titers: 900, epoch: 9 | loss: 0.2399411\n",
      "\tspeed: 0.0361s/iter; left time: 32.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.2207743 Vali Loss: 0.4465204 Test Loss: 0.4781870\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.5188416242599487, rmse:0.7203066349029541, mae:0.45719295740127563, rse:0.5700771808624268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7663413\n",
      "\tspeed: 0.0387s/iter; left time: 346.4035s\n",
      "\titers: 200, epoch: 1 | loss: 0.6485021\n",
      "\tspeed: 0.0462s/iter; left time: 409.2441s\n",
      "\titers: 300, epoch: 1 | loss: 0.5757578\n",
      "\tspeed: 0.0438s/iter; left time: 383.4591s\n",
      "\titers: 400, epoch: 1 | loss: 0.6212713\n",
      "\tspeed: 0.0466s/iter; left time: 403.6473s\n",
      "\titers: 500, epoch: 1 | loss: 0.5127186\n",
      "\tspeed: 0.0438s/iter; left time: 374.6563s\n",
      "\titers: 600, epoch: 1 | loss: 0.5530728\n",
      "\tspeed: 0.0450s/iter; left time: 380.5488s\n",
      "\titers: 700, epoch: 1 | loss: 0.5311509\n",
      "\tspeed: 0.0473s/iter; left time: 395.5852s\n",
      "\titers: 800, epoch: 1 | loss: 0.5241462\n",
      "\tspeed: 0.0476s/iter; left time: 393.0399s\n",
      "\titers: 900, epoch: 1 | loss: 0.4979602\n",
      "\tspeed: 0.0450s/iter; left time: 367.0440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 906 | Train Loss: 0.5916661 Vali Loss: 0.5558083 Test Loss: 0.5964805\n",
      "Validation loss decreased (inf --> 0.555808).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4336141\n",
      "\tspeed: 0.1052s/iter; left time: 847.6697s\n",
      "\titers: 200, epoch: 2 | loss: 0.5146539\n",
      "\tspeed: 0.0465s/iter; left time: 369.7881s\n",
      "\titers: 300, epoch: 2 | loss: 0.4029806\n",
      "\tspeed: 0.0465s/iter; left time: 365.2358s\n",
      "\titers: 400, epoch: 2 | loss: 0.4548421\n",
      "\tspeed: 0.0425s/iter; left time: 329.3296s\n",
      "\titers: 500, epoch: 2 | loss: 0.4255509\n",
      "\tspeed: 0.0430s/iter; left time: 328.9554s\n",
      "\titers: 600, epoch: 2 | loss: 0.3443504\n",
      "\tspeed: 0.0326s/iter; left time: 246.4440s\n",
      "\titers: 700, epoch: 2 | loss: 0.3624960\n",
      "\tspeed: 0.0442s/iter; left time: 329.7258s\n",
      "\titers: 800, epoch: 2 | loss: 0.3500257\n",
      "\tspeed: 0.0452s/iter; left time: 332.6718s\n",
      "\titers: 900, epoch: 2 | loss: 0.3510049\n",
      "\tspeed: 0.0455s/iter; left time: 329.7678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.95s\n",
      "Steps: 906 | Train Loss: 0.4025312 Vali Loss: 0.4525728 Test Loss: 0.4585328\n",
      "Validation loss decreased (0.555808 --> 0.452573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3646318\n",
      "\tspeed: 0.1071s/iter; left time: 765.9629s\n",
      "\titers: 200, epoch: 3 | loss: 0.3351053\n",
      "\tspeed: 0.0453s/iter; left time: 319.0055s\n",
      "\titers: 300, epoch: 3 | loss: 0.3731779\n",
      "\tspeed: 0.0426s/iter; left time: 295.7350s\n",
      "\titers: 400, epoch: 3 | loss: 0.3862885\n",
      "\tspeed: 0.0375s/iter; left time: 257.1324s\n",
      "\titers: 500, epoch: 3 | loss: 0.4007759\n",
      "\tspeed: 0.0459s/iter; left time: 309.6851s\n",
      "\titers: 600, epoch: 3 | loss: 0.3929105\n",
      "\tspeed: 0.0460s/iter; left time: 305.7504s\n",
      "\titers: 700, epoch: 3 | loss: 0.3533075\n",
      "\tspeed: 0.0415s/iter; left time: 271.9870s\n",
      "\titers: 800, epoch: 3 | loss: 0.3429417\n",
      "\tspeed: 0.0368s/iter; left time: 237.1391s\n",
      "\titers: 900, epoch: 3 | loss: 0.3384899\n",
      "\tspeed: 0.0421s/iter; left time: 267.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 906 | Train Loss: 0.3550890 Vali Loss: 0.4418871 Test Loss: 0.4460518\n",
      "Validation loss decreased (0.452573 --> 0.441887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3175507\n",
      "\tspeed: 0.1042s/iter; left time: 650.4543s\n",
      "\titers: 200, epoch: 4 | loss: 0.3441693\n",
      "\tspeed: 0.0417s/iter; left time: 256.2691s\n",
      "\titers: 300, epoch: 4 | loss: 0.3254147\n",
      "\tspeed: 0.0432s/iter; left time: 260.7656s\n",
      "\titers: 400, epoch: 4 | loss: 0.3307195\n",
      "\tspeed: 0.0424s/iter; left time: 252.2096s\n",
      "\titers: 500, epoch: 4 | loss: 0.3794867\n",
      "\tspeed: 0.0461s/iter; left time: 269.6351s\n",
      "\titers: 600, epoch: 4 | loss: 0.3249062\n",
      "\tspeed: 0.0356s/iter; left time: 204.6808s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429216\n",
      "\tspeed: 0.0348s/iter; left time: 196.5237s\n",
      "\titers: 800, epoch: 4 | loss: 0.3966985\n",
      "\tspeed: 0.0324s/iter; left time: 179.3998s\n",
      "\titers: 900, epoch: 4 | loss: 0.3426206\n",
      "\tspeed: 0.0419s/iter; left time: 228.0963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.77s\n",
      "Steps: 906 | Train Loss: 0.3285498 Vali Loss: 0.4358843 Test Loss: 0.4459069\n",
      "Validation loss decreased (0.441887 --> 0.435884).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2845316\n",
      "\tspeed: 0.1076s/iter; left time: 574.3523s\n",
      "\titers: 200, epoch: 5 | loss: 0.3353932\n",
      "\tspeed: 0.0427s/iter; left time: 223.5565s\n",
      "\titers: 300, epoch: 5 | loss: 0.3241500\n",
      "\tspeed: 0.0477s/iter; left time: 245.2350s\n",
      "\titers: 400, epoch: 5 | loss: 0.3284504\n",
      "\tspeed: 0.0371s/iter; left time: 186.8177s\n",
      "\titers: 500, epoch: 5 | loss: 0.3038191\n",
      "\tspeed: 0.0434s/iter; left time: 214.2425s\n",
      "\titers: 600, epoch: 5 | loss: 0.2700494\n",
      "\tspeed: 0.0478s/iter; left time: 231.3698s\n",
      "\titers: 700, epoch: 5 | loss: 0.2971236\n",
      "\tspeed: 0.0482s/iter; left time: 228.3911s\n",
      "\titers: 800, epoch: 5 | loss: 0.3002537\n",
      "\tspeed: 0.0443s/iter; left time: 205.4548s\n",
      "\titers: 900, epoch: 5 | loss: 0.2977143\n",
      "\tspeed: 0.0475s/iter; left time: 215.3953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.20s\n",
      "Steps: 906 | Train Loss: 0.3019121 Vali Loss: 0.4237208 Test Loss: 0.4594835\n",
      "Validation loss decreased (0.435884 --> 0.423721).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3062578\n",
      "\tspeed: 0.1094s/iter; left time: 484.9593s\n",
      "\titers: 200, epoch: 6 | loss: 0.2654166\n",
      "\tspeed: 0.0488s/iter; left time: 211.1693s\n",
      "\titers: 300, epoch: 6 | loss: 0.2942485\n",
      "\tspeed: 0.0419s/iter; left time: 177.1388s\n",
      "\titers: 400, epoch: 6 | loss: 0.3022459\n",
      "\tspeed: 0.0442s/iter; left time: 182.7024s\n",
      "\titers: 500, epoch: 6 | loss: 0.2812643\n",
      "\tspeed: 0.0484s/iter; left time: 194.9745s\n",
      "\titers: 600, epoch: 6 | loss: 0.2917507\n",
      "\tspeed: 0.0480s/iter; left time: 188.5206s\n",
      "\titers: 700, epoch: 6 | loss: 0.2915955\n",
      "\tspeed: 0.0458s/iter; left time: 175.3792s\n",
      "\titers: 800, epoch: 6 | loss: 0.2462863\n",
      "\tspeed: 0.0487s/iter; left time: 181.7507s\n",
      "\titers: 900, epoch: 6 | loss: 0.2766623\n",
      "\tspeed: 0.0468s/iter; left time: 169.9807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.66s\n",
      "Steps: 906 | Train Loss: 0.2773862 Vali Loss: 0.4452073 Test Loss: 0.4664961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2722317\n",
      "\tspeed: 0.1041s/iter; left time: 366.8277s\n",
      "\titers: 200, epoch: 7 | loss: 0.2920038\n",
      "\tspeed: 0.0436s/iter; left time: 149.4853s\n",
      "\titers: 300, epoch: 7 | loss: 0.2533202\n",
      "\tspeed: 0.0410s/iter; left time: 136.1747s\n",
      "\titers: 400, epoch: 7 | loss: 0.2270028\n",
      "\tspeed: 0.0458s/iter; left time: 147.6808s\n",
      "\titers: 500, epoch: 7 | loss: 0.2566482\n",
      "\tspeed: 0.0459s/iter; left time: 143.3255s\n",
      "\titers: 600, epoch: 7 | loss: 0.2476297\n",
      "\tspeed: 0.0485s/iter; left time: 146.5693s\n",
      "\titers: 700, epoch: 7 | loss: 0.2665338\n",
      "\tspeed: 0.0438s/iter; left time: 128.1700s\n",
      "\titers: 800, epoch: 7 | loss: 0.2844218\n",
      "\tspeed: 0.0471s/iter; left time: 133.1314s\n",
      "\titers: 900, epoch: 7 | loss: 0.2454531\n",
      "\tspeed: 0.0429s/iter; left time: 116.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.11s\n",
      "Steps: 906 | Train Loss: 0.2564889 Vali Loss: 0.4482238 Test Loss: 0.4680468\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2528011\n",
      "\tspeed: 0.1013s/iter; left time: 265.3165s\n",
      "\titers: 200, epoch: 8 | loss: 0.2499335\n",
      "\tspeed: 0.0422s/iter; left time: 106.3937s\n",
      "\titers: 300, epoch: 8 | loss: 0.2507049\n",
      "\tspeed: 0.0477s/iter; left time: 115.3215s\n",
      "\titers: 400, epoch: 8 | loss: 0.2264348\n",
      "\tspeed: 0.0489s/iter; left time: 113.3848s\n",
      "\titers: 500, epoch: 8 | loss: 0.2077545\n",
      "\tspeed: 0.0336s/iter; left time: 74.4785s\n",
      "\titers: 600, epoch: 8 | loss: 0.2186678\n",
      "\tspeed: 0.0444s/iter; left time: 93.9908s\n",
      "\titers: 700, epoch: 8 | loss: 0.2397504\n",
      "\tspeed: 0.0498s/iter; left time: 100.5781s\n",
      "\titers: 800, epoch: 8 | loss: 0.2378334\n",
      "\tspeed: 0.0478s/iter; left time: 91.7329s\n",
      "\titers: 900, epoch: 8 | loss: 0.2434639\n",
      "\tspeed: 0.0425s/iter; left time: 77.3655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 906 | Train Loss: 0.2388158 Vali Loss: 0.4419125 Test Loss: 0.4689014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4891737401485443, rmse:0.699409544467926, mae:0.4595417380332947, rse:0.5535385012626648\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8067917\n",
      "\tspeed: 0.0840s/iter; left time: 751.4469s\n",
      "\titers: 200, epoch: 1 | loss: 0.7688307\n",
      "\tspeed: 0.0394s/iter; left time: 348.2751s\n",
      "\titers: 300, epoch: 1 | loss: 0.7508007\n",
      "\tspeed: 0.0465s/iter; left time: 406.7211s\n",
      "\titers: 400, epoch: 1 | loss: 0.7012591\n",
      "\tspeed: 0.0491s/iter; left time: 424.3091s\n",
      "\titers: 500, epoch: 1 | loss: 0.6997176\n",
      "\tspeed: 0.0479s/iter; left time: 409.1456s\n",
      "\titers: 600, epoch: 1 | loss: 0.6242710\n",
      "\tspeed: 0.0460s/iter; left time: 387.9298s\n",
      "\titers: 700, epoch: 1 | loss: 0.6133171\n",
      "\tspeed: 0.0472s/iter; left time: 393.5347s\n",
      "\titers: 800, epoch: 1 | loss: 0.6298627\n",
      "\tspeed: 0.0479s/iter; left time: 394.3600s\n",
      "\titers: 900, epoch: 1 | loss: 0.6329895\n",
      "\tspeed: 0.0472s/iter; left time: 384.5678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.26s\n",
      "Steps: 904 | Train Loss: 0.7062791 Vali Loss: 0.7041736 Test Loss: 0.7890770\n",
      "Validation loss decreased (inf --> 0.704174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5741602\n",
      "\tspeed: 0.1124s/iter; left time: 903.5141s\n",
      "\titers: 200, epoch: 2 | loss: 0.5573565\n",
      "\tspeed: 0.0462s/iter; left time: 367.0080s\n",
      "\titers: 300, epoch: 2 | loss: 0.5360226\n",
      "\tspeed: 0.0471s/iter; left time: 369.0028s\n",
      "\titers: 400, epoch: 2 | loss: 0.5210469\n",
      "\tspeed: 0.0450s/iter; left time: 348.1139s\n",
      "\titers: 500, epoch: 2 | loss: 0.4852026\n",
      "\tspeed: 0.0451s/iter; left time: 344.7610s\n",
      "\titers: 600, epoch: 2 | loss: 0.5197762\n",
      "\tspeed: 0.0425s/iter; left time: 320.4571s\n",
      "\titers: 700, epoch: 2 | loss: 0.4818439\n",
      "\tspeed: 0.0484s/iter; left time: 359.6217s\n",
      "\titers: 800, epoch: 2 | loss: 0.5260186\n",
      "\tspeed: 0.0476s/iter; left time: 349.0707s\n",
      "\titers: 900, epoch: 2 | loss: 0.4836222\n",
      "\tspeed: 0.0439s/iter; left time: 317.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 904 | Train Loss: 0.5302526 Vali Loss: 0.5876943 Test Loss: 0.6581249\n",
      "Validation loss decreased (0.704174 --> 0.587694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5143448\n",
      "\tspeed: 0.1112s/iter; left time: 792.9913s\n",
      "\titers: 200, epoch: 3 | loss: 0.4555106\n",
      "\tspeed: 0.0429s/iter; left time: 301.9961s\n",
      "\titers: 300, epoch: 3 | loss: 0.4323205\n",
      "\tspeed: 0.0520s/iter; left time: 360.1868s\n",
      "\titers: 400, epoch: 3 | loss: 0.4212284\n",
      "\tspeed: 0.0483s/iter; left time: 329.7653s\n",
      "\titers: 500, epoch: 3 | loss: 0.4699768\n",
      "\tspeed: 0.0460s/iter; left time: 309.6412s\n",
      "\titers: 600, epoch: 3 | loss: 0.4816353\n",
      "\tspeed: 0.0453s/iter; left time: 300.7830s\n",
      "\titers: 700, epoch: 3 | loss: 0.4266669\n",
      "\tspeed: 0.0446s/iter; left time: 291.3849s\n",
      "\titers: 800, epoch: 3 | loss: 0.4492370\n",
      "\tspeed: 0.0470s/iter; left time: 302.5023s\n",
      "\titers: 900, epoch: 3 | loss: 0.4507588\n",
      "\tspeed: 0.0424s/iter; left time: 268.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.95s\n",
      "Steps: 904 | Train Loss: 0.4610911 Vali Loss: 0.5697786 Test Loss: 0.6448624\n",
      "Validation loss decreased (0.587694 --> 0.569779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4120070\n",
      "\tspeed: 0.1038s/iter; left time: 646.6130s\n",
      "\titers: 200, epoch: 4 | loss: 0.4231596\n",
      "\tspeed: 0.0375s/iter; left time: 230.1011s\n",
      "\titers: 300, epoch: 4 | loss: 0.4169765\n",
      "\tspeed: 0.0467s/iter; left time: 281.5541s\n",
      "\titers: 400, epoch: 4 | loss: 0.3556132\n",
      "\tspeed: 0.0408s/iter; left time: 242.1545s\n",
      "\titers: 500, epoch: 4 | loss: 0.4291881\n",
      "\tspeed: 0.0470s/iter; left time: 273.7635s\n",
      "\titers: 600, epoch: 4 | loss: 0.3928163\n",
      "\tspeed: 0.0444s/iter; left time: 254.2628s\n",
      "\titers: 700, epoch: 4 | loss: 0.4445765\n",
      "\tspeed: 0.0449s/iter; left time: 252.7680s\n",
      "\titers: 800, epoch: 4 | loss: 0.4147629\n",
      "\tspeed: 0.0480s/iter; left time: 265.1543s\n",
      "\titers: 900, epoch: 4 | loss: 0.4494169\n",
      "\tspeed: 0.0390s/iter; left time: 211.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.36s\n",
      "Steps: 904 | Train Loss: 0.4237256 Vali Loss: 0.5744144 Test Loss: 0.6609067\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3808894\n",
      "\tspeed: 0.1092s/iter; left time: 581.7101s\n",
      "\titers: 200, epoch: 5 | loss: 0.4379567\n",
      "\tspeed: 0.0455s/iter; left time: 237.4947s\n",
      "\titers: 300, epoch: 5 | loss: 0.4309290\n",
      "\tspeed: 0.0334s/iter; left time: 171.3153s\n",
      "\titers: 400, epoch: 5 | loss: 0.3985155\n",
      "\tspeed: 0.0452s/iter; left time: 227.1895s\n",
      "\titers: 500, epoch: 5 | loss: 0.3633554\n",
      "\tspeed: 0.0486s/iter; left time: 239.3908s\n",
      "\titers: 600, epoch: 5 | loss: 0.3638545\n",
      "\tspeed: 0.0458s/iter; left time: 220.9650s\n",
      "\titers: 700, epoch: 5 | loss: 0.3683217\n",
      "\tspeed: 0.0474s/iter; left time: 223.7781s\n",
      "\titers: 800, epoch: 5 | loss: 0.3484431\n",
      "\tspeed: 0.0443s/iter; left time: 205.0952s\n",
      "\titers: 900, epoch: 5 | loss: 0.3746142\n",
      "\tspeed: 0.0449s/iter; left time: 203.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.80s\n",
      "Steps: 904 | Train Loss: 0.3867548 Vali Loss: 0.5776727 Test Loss: 0.6671416\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3486542\n",
      "\tspeed: 0.1004s/iter; left time: 443.9235s\n",
      "\titers: 200, epoch: 6 | loss: 0.3392638\n",
      "\tspeed: 0.0477s/iter; left time: 205.9746s\n",
      "\titers: 300, epoch: 6 | loss: 0.3697442\n",
      "\tspeed: 0.0429s/iter; left time: 180.9403s\n",
      "\titers: 400, epoch: 6 | loss: 0.3674991\n",
      "\tspeed: 0.0473s/iter; left time: 194.9381s\n",
      "\titers: 500, epoch: 6 | loss: 0.3660162\n",
      "\tspeed: 0.0461s/iter; left time: 185.5115s\n",
      "\titers: 600, epoch: 6 | loss: 0.3611535\n",
      "\tspeed: 0.0463s/iter; left time: 181.6486s\n",
      "\titers: 700, epoch: 6 | loss: 0.3432849\n",
      "\tspeed: 0.0465s/iter; left time: 177.8420s\n",
      "\titers: 800, epoch: 6 | loss: 0.3864821\n",
      "\tspeed: 0.0438s/iter; left time: 162.8306s\n",
      "\titers: 900, epoch: 6 | loss: 0.3490607\n",
      "\tspeed: 0.0472s/iter; left time: 171.0809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.54s\n",
      "Steps: 904 | Train Loss: 0.3563989 Vali Loss: 0.5858901 Test Loss: 0.6636922\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.8605884313583374, rmse:0.9276790618896484, mae:0.6448208689689636, rse:0.7357637882232666\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7958822\n",
      "\tspeed: 0.0440s/iter; left time: 392.9672s\n",
      "\titers: 200, epoch: 1 | loss: 0.7839687\n",
      "\tspeed: 0.0474s/iter; left time: 419.3232s\n",
      "\titers: 300, epoch: 1 | loss: 0.7392733\n",
      "\tspeed: 0.0444s/iter; left time: 388.4331s\n",
      "\titers: 400, epoch: 1 | loss: 0.6705455\n",
      "\tspeed: 0.0394s/iter; left time: 340.8571s\n",
      "\titers: 500, epoch: 1 | loss: 0.7188321\n",
      "\tspeed: 0.0473s/iter; left time: 404.0221s\n",
      "\titers: 600, epoch: 1 | loss: 0.7047096\n",
      "\tspeed: 0.0388s/iter; left time: 327.2205s\n",
      "\titers: 700, epoch: 1 | loss: 0.6298293\n",
      "\tspeed: 0.0370s/iter; left time: 308.9929s\n",
      "\titers: 800, epoch: 1 | loss: 0.6690677\n",
      "\tspeed: 0.0454s/iter; left time: 373.7955s\n",
      "\titers: 900, epoch: 1 | loss: 0.5942121\n",
      "\tspeed: 0.0473s/iter; left time: 384.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.40s\n",
      "Steps: 904 | Train Loss: 0.7041365 Vali Loss: 0.7075946 Test Loss: 0.7944186\n",
      "Validation loss decreased (inf --> 0.707595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5957434\n",
      "\tspeed: 0.1104s/iter; left time: 887.3121s\n",
      "\titers: 200, epoch: 2 | loss: 0.5940323\n",
      "\tspeed: 0.0467s/iter; left time: 370.2614s\n",
      "\titers: 300, epoch: 2 | loss: 0.5177482\n",
      "\tspeed: 0.0484s/iter; left time: 379.5623s\n",
      "\titers: 400, epoch: 2 | loss: 0.5124515\n",
      "\tspeed: 0.0483s/iter; left time: 373.9555s\n",
      "\titers: 500, epoch: 2 | loss: 0.5041392\n",
      "\tspeed: 0.0473s/iter; left time: 361.4489s\n",
      "\titers: 600, epoch: 2 | loss: 0.5169987\n",
      "\tspeed: 0.0456s/iter; left time: 343.8892s\n",
      "\titers: 700, epoch: 2 | loss: 0.5079450\n",
      "\tspeed: 0.0462s/iter; left time: 343.3849s\n",
      "\titers: 800, epoch: 2 | loss: 0.5539059\n",
      "\tspeed: 0.0494s/iter; left time: 362.4364s\n",
      "\titers: 900, epoch: 2 | loss: 0.4816802\n",
      "\tspeed: 0.0437s/iter; left time: 316.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.64s\n",
      "Steps: 904 | Train Loss: 0.5333013 Vali Loss: 0.6118372 Test Loss: 0.6438490\n",
      "Validation loss decreased (0.707595 --> 0.611837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4765821\n",
      "\tspeed: 0.1101s/iter; left time: 785.3193s\n",
      "\titers: 200, epoch: 3 | loss: 0.4696513\n",
      "\tspeed: 0.0496s/iter; left time: 348.8956s\n",
      "\titers: 300, epoch: 3 | loss: 0.4342611\n",
      "\tspeed: 0.0444s/iter; left time: 307.6478s\n",
      "\titers: 400, epoch: 3 | loss: 0.4118306\n",
      "\tspeed: 0.0452s/iter; left time: 308.7545s\n",
      "\titers: 500, epoch: 3 | loss: 0.4146205\n",
      "\tspeed: 0.0486s/iter; left time: 327.0580s\n",
      "\titers: 600, epoch: 3 | loss: 0.4872401\n",
      "\tspeed: 0.0448s/iter; left time: 297.3007s\n",
      "\titers: 700, epoch: 3 | loss: 0.4506579\n",
      "\tspeed: 0.0502s/iter; left time: 327.9693s\n",
      "\titers: 800, epoch: 3 | loss: 0.4589255\n",
      "\tspeed: 0.0421s/iter; left time: 270.5509s\n",
      "\titers: 900, epoch: 3 | loss: 0.4285489\n",
      "\tspeed: 0.0465s/iter; left time: 294.2709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 904 | Train Loss: 0.4630802 Vali Loss: 0.5959297 Test Loss: 0.6734436\n",
      "Validation loss decreased (0.611837 --> 0.595930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3916527\n",
      "\tspeed: 0.1092s/iter; left time: 679.9300s\n",
      "\titers: 200, epoch: 4 | loss: 0.4424612\n",
      "\tspeed: 0.0424s/iter; left time: 260.0619s\n",
      "\titers: 300, epoch: 4 | loss: 0.4169645\n",
      "\tspeed: 0.0423s/iter; left time: 254.7540s\n",
      "\titers: 400, epoch: 4 | loss: 0.4057310\n",
      "\tspeed: 0.0349s/iter; left time: 206.9678s\n",
      "\titers: 500, epoch: 4 | loss: 0.4517982\n",
      "\tspeed: 0.0413s/iter; left time: 240.6672s\n",
      "\titers: 600, epoch: 4 | loss: 0.4000244\n",
      "\tspeed: 0.0485s/iter; left time: 278.1114s\n",
      "\titers: 700, epoch: 4 | loss: 0.4279825\n",
      "\tspeed: 0.0444s/iter; left time: 249.7216s\n",
      "\titers: 800, epoch: 4 | loss: 0.4368097\n",
      "\tspeed: 0.0439s/iter; left time: 242.4667s\n",
      "\titers: 900, epoch: 4 | loss: 0.3883900\n",
      "\tspeed: 0.0468s/iter; left time: 253.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.67s\n",
      "Steps: 904 | Train Loss: 0.4223682 Vali Loss: 0.5835855 Test Loss: 0.6440173\n",
      "Validation loss decreased (0.595930 --> 0.583586).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3722683\n",
      "\tspeed: 0.0939s/iter; left time: 500.2594s\n",
      "\titers: 200, epoch: 5 | loss: 0.4122548\n",
      "\tspeed: 0.0457s/iter; left time: 239.0075s\n",
      "\titers: 300, epoch: 5 | loss: 0.3921342\n",
      "\tspeed: 0.0466s/iter; left time: 238.6816s\n",
      "\titers: 400, epoch: 5 | loss: 0.3807038\n",
      "\tspeed: 0.0468s/iter; left time: 235.3918s\n",
      "\titers: 500, epoch: 5 | loss: 0.3871912\n",
      "\tspeed: 0.0373s/iter; left time: 183.5810s\n",
      "\titers: 600, epoch: 5 | loss: 0.4224902\n",
      "\tspeed: 0.0431s/iter; left time: 207.9042s\n",
      "\titers: 700, epoch: 5 | loss: 0.3636874\n",
      "\tspeed: 0.0473s/iter; left time: 223.3519s\n",
      "\titers: 800, epoch: 5 | loss: 0.3763137\n",
      "\tspeed: 0.0395s/iter; left time: 182.5043s\n",
      "\titers: 900, epoch: 5 | loss: 0.3757822\n",
      "\tspeed: 0.0449s/iter; left time: 203.1007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 904 | Train Loss: 0.3853117 Vali Loss: 0.5932398 Test Loss: 0.6455393\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3310162\n",
      "\tspeed: 0.1025s/iter; left time: 452.9974s\n",
      "\titers: 200, epoch: 6 | loss: 0.3540734\n",
      "\tspeed: 0.0458s/iter; left time: 197.9555s\n",
      "\titers: 300, epoch: 6 | loss: 0.3805029\n",
      "\tspeed: 0.0468s/iter; left time: 197.3601s\n",
      "\titers: 400, epoch: 6 | loss: 0.3458270\n",
      "\tspeed: 0.0448s/iter; left time: 184.6888s\n",
      "\titers: 500, epoch: 6 | loss: 0.3366010\n",
      "\tspeed: 0.0356s/iter; left time: 143.1543s\n",
      "\titers: 600, epoch: 6 | loss: 0.3225587\n",
      "\tspeed: 0.0445s/iter; left time: 174.5343s\n",
      "\titers: 700, epoch: 6 | loss: 0.3334104\n",
      "\tspeed: 0.0455s/iter; left time: 173.8534s\n",
      "\titers: 800, epoch: 6 | loss: 0.3155001\n",
      "\tspeed: 0.0336s/iter; left time: 125.1019s\n",
      "\titers: 900, epoch: 6 | loss: 0.3178173\n",
      "\tspeed: 0.0465s/iter; left time: 168.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.35s\n",
      "Steps: 904 | Train Loss: 0.3539380 Vali Loss: 0.5974894 Test Loss: 0.6660232\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3371837\n",
      "\tspeed: 0.1005s/iter; left time: 353.5739s\n",
      "\titers: 200, epoch: 7 | loss: 0.3259185\n",
      "\tspeed: 0.0471s/iter; left time: 160.9637s\n",
      "\titers: 300, epoch: 7 | loss: 0.3114211\n",
      "\tspeed: 0.0487s/iter; left time: 161.4826s\n",
      "\titers: 400, epoch: 7 | loss: 0.3071353\n",
      "\tspeed: 0.0459s/iter; left time: 147.7451s\n",
      "\titers: 500, epoch: 7 | loss: 0.3179525\n",
      "\tspeed: 0.0473s/iter; left time: 147.3717s\n",
      "\titers: 600, epoch: 7 | loss: 0.3134637\n",
      "\tspeed: 0.0466s/iter; left time: 140.4863s\n",
      "\titers: 700, epoch: 7 | loss: 0.3499774\n",
      "\tspeed: 0.0492s/iter; left time: 143.5175s\n",
      "\titers: 800, epoch: 7 | loss: 0.3171128\n",
      "\tspeed: 0.0476s/iter; left time: 133.9584s\n",
      "\titers: 900, epoch: 7 | loss: 0.3237043\n",
      "\tspeed: 0.0485s/iter; left time: 131.8639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.90s\n",
      "Steps: 904 | Train Loss: 0.3271561 Vali Loss: 0.5955210 Test Loss: 0.6735355\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.9031488299369812, rmse:0.9503414034843445, mae:0.6443209052085876, rse:0.7537378668785095\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7432773\n",
      "\tspeed: 0.0833s/iter; left time: 743.5652s\n",
      "\titers: 200, epoch: 1 | loss: 0.7939355\n",
      "\tspeed: 0.0512s/iter; left time: 451.3642s\n",
      "\titers: 300, epoch: 1 | loss: 0.7317653\n",
      "\tspeed: 0.0490s/iter; left time: 427.5547s\n",
      "\titers: 400, epoch: 1 | loss: 0.7309682\n",
      "\tspeed: 0.0399s/iter; left time: 343.7290s\n",
      "\titers: 500, epoch: 1 | loss: 0.7174807\n",
      "\tspeed: 0.0408s/iter; left time: 347.6815s\n",
      "\titers: 600, epoch: 1 | loss: 0.7427214\n",
      "\tspeed: 0.0440s/iter; left time: 370.9285s\n",
      "\titers: 700, epoch: 1 | loss: 0.7085695\n",
      "\tspeed: 0.0431s/iter; left time: 358.4131s\n",
      "\titers: 800, epoch: 1 | loss: 0.6773993\n",
      "\tspeed: 0.0500s/iter; left time: 411.3716s\n",
      "\titers: 900, epoch: 1 | loss: 0.7027309\n",
      "\tspeed: 0.0478s/iter; left time: 388.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.44s\n",
      "Steps: 902 | Train Loss: 0.7345921 Vali Loss: 0.7742499 Test Loss: 0.8810522\n",
      "Validation loss decreased (inf --> 0.774250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6915616\n",
      "\tspeed: 0.1172s/iter; left time: 939.8777s\n",
      "\titers: 200, epoch: 2 | loss: 0.6296236\n",
      "\tspeed: 0.0490s/iter; left time: 387.7840s\n",
      "\titers: 300, epoch: 2 | loss: 0.6338568\n",
      "\tspeed: 0.0409s/iter; left time: 319.6037s\n",
      "\titers: 400, epoch: 2 | loss: 0.5708992\n",
      "\tspeed: 0.0496s/iter; left time: 383.0056s\n",
      "\titers: 500, epoch: 2 | loss: 0.5656452\n",
      "\tspeed: 0.0507s/iter; left time: 385.9538s\n",
      "\titers: 600, epoch: 2 | loss: 0.5171528\n",
      "\tspeed: 0.0489s/iter; left time: 367.6375s\n",
      "\titers: 700, epoch: 2 | loss: 0.5277460\n",
      "\tspeed: 0.0509s/iter; left time: 377.5986s\n",
      "\titers: 800, epoch: 2 | loss: 0.5613817\n",
      "\tspeed: 0.0502s/iter; left time: 367.7378s\n",
      "\titers: 900, epoch: 2 | loss: 0.5136336\n",
      "\tspeed: 0.0506s/iter; left time: 365.1110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.10s\n",
      "Steps: 902 | Train Loss: 0.5769524 Vali Loss: 0.6167185 Test Loss: 0.6815776\n",
      "Validation loss decreased (0.774250 --> 0.616719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5195920\n",
      "\tspeed: 0.1214s/iter; left time: 864.2220s\n",
      "\titers: 200, epoch: 3 | loss: 0.4820179\n",
      "\tspeed: 0.0513s/iter; left time: 360.2389s\n",
      "\titers: 300, epoch: 3 | loss: 0.4975570\n",
      "\tspeed: 0.0450s/iter; left time: 311.3766s\n",
      "\titers: 400, epoch: 3 | loss: 0.4995791\n",
      "\tspeed: 0.0427s/iter; left time: 291.1482s\n",
      "\titers: 500, epoch: 3 | loss: 0.4637761\n",
      "\tspeed: 0.0443s/iter; left time: 297.8450s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987577\n",
      "\tspeed: 0.0376s/iter; left time: 248.9684s\n",
      "\titers: 700, epoch: 3 | loss: 0.4995336\n",
      "\tspeed: 0.0477s/iter; left time: 310.6498s\n",
      "\titers: 800, epoch: 3 | loss: 0.4750866\n",
      "\tspeed: 0.0476s/iter; left time: 305.5828s\n",
      "\titers: 900, epoch: 3 | loss: 0.4593079\n",
      "\tspeed: 0.0382s/iter; left time: 241.6135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.78s\n",
      "Steps: 902 | Train Loss: 0.4844140 Vali Loss: 0.6013861 Test Loss: 0.6744983\n",
      "Validation loss decreased (0.616719 --> 0.601386).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4199736\n",
      "\tspeed: 0.1153s/iter; left time: 716.3061s\n",
      "\titers: 200, epoch: 4 | loss: 0.4067586\n",
      "\tspeed: 0.0415s/iter; left time: 253.8962s\n",
      "\titers: 300, epoch: 4 | loss: 0.4709497\n",
      "\tspeed: 0.0456s/iter; left time: 274.5633s\n",
      "\titers: 400, epoch: 4 | loss: 0.4624965\n",
      "\tspeed: 0.0467s/iter; left time: 276.0444s\n",
      "\titers: 500, epoch: 4 | loss: 0.4708977\n",
      "\tspeed: 0.0405s/iter; left time: 235.6641s\n",
      "\titers: 600, epoch: 4 | loss: 0.4219711\n",
      "\tspeed: 0.0423s/iter; left time: 241.9992s\n",
      "\titers: 700, epoch: 4 | loss: 0.4578864\n",
      "\tspeed: 0.0434s/iter; left time: 243.7187s\n",
      "\titers: 800, epoch: 4 | loss: 0.4533421\n",
      "\tspeed: 0.0433s/iter; left time: 238.5710s\n",
      "\titers: 900, epoch: 4 | loss: 0.4198165\n",
      "\tspeed: 0.0434s/iter; left time: 235.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.95s\n",
      "Steps: 902 | Train Loss: 0.4426506 Vali Loss: 0.6053154 Test Loss: 0.6779942\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4462722\n",
      "\tspeed: 0.1153s/iter; left time: 612.4162s\n",
      "\titers: 200, epoch: 5 | loss: 0.4145476\n",
      "\tspeed: 0.0486s/iter; left time: 253.2895s\n",
      "\titers: 300, epoch: 5 | loss: 0.4069575\n",
      "\tspeed: 0.0484s/iter; left time: 247.3172s\n",
      "\titers: 400, epoch: 5 | loss: 0.4398940\n",
      "\tspeed: 0.0473s/iter; left time: 237.3475s\n",
      "\titers: 500, epoch: 5 | loss: 0.3539902\n",
      "\tspeed: 0.0491s/iter; left time: 241.3685s\n",
      "\titers: 600, epoch: 5 | loss: 0.3999235\n",
      "\tspeed: 0.0479s/iter; left time: 230.5647s\n",
      "\titers: 700, epoch: 5 | loss: 0.4306205\n",
      "\tspeed: 0.0479s/iter; left time: 225.6778s\n",
      "\titers: 800, epoch: 5 | loss: 0.3808160\n",
      "\tspeed: 0.0460s/iter; left time: 212.1231s\n",
      "\titers: 900, epoch: 5 | loss: 0.3558828\n",
      "\tspeed: 0.0490s/iter; left time: 220.9672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 902 | Train Loss: 0.4057229 Vali Loss: 0.6094700 Test Loss: 0.6841301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3801375\n",
      "\tspeed: 0.1138s/iter; left time: 501.9657s\n",
      "\titers: 200, epoch: 6 | loss: 0.3963151\n",
      "\tspeed: 0.0478s/iter; left time: 206.0785s\n",
      "\titers: 300, epoch: 6 | loss: 0.3608236\n",
      "\tspeed: 0.0462s/iter; left time: 194.6091s\n",
      "\titers: 400, epoch: 6 | loss: 0.3986512\n",
      "\tspeed: 0.0466s/iter; left time: 191.5625s\n",
      "\titers: 500, epoch: 6 | loss: 0.3677309\n",
      "\tspeed: 0.0480s/iter; left time: 192.5430s\n",
      "\titers: 600, epoch: 6 | loss: 0.3556405\n",
      "\tspeed: 0.0459s/iter; left time: 179.5492s\n",
      "\titers: 700, epoch: 6 | loss: 0.3937513\n",
      "\tspeed: 0.0502s/iter; left time: 191.4566s\n",
      "\titers: 800, epoch: 6 | loss: 0.3524588\n",
      "\tspeed: 0.0435s/iter; left time: 161.5104s\n",
      "\titers: 900, epoch: 6 | loss: 0.4020260\n",
      "\tspeed: 0.0430s/iter; left time: 155.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.36s\n",
      "Steps: 902 | Train Loss: 0.3728632 Vali Loss: 0.6032423 Test Loss: 0.6830379\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.9181895852088928, rmse:0.9582220911979675, mae:0.6743886470794678, rse:0.7590816020965576\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8299315\n",
      "\tspeed: 0.0544s/iter; left time: 485.0039s\n",
      "\titers: 200, epoch: 1 | loss: 0.7454510\n",
      "\tspeed: 0.0456s/iter; left time: 402.5963s\n",
      "\titers: 300, epoch: 1 | loss: 0.7466465\n",
      "\tspeed: 0.0480s/iter; left time: 418.5842s\n",
      "\titers: 400, epoch: 1 | loss: 0.6557025\n",
      "\tspeed: 0.0498s/iter; left time: 429.1631s\n",
      "\titers: 500, epoch: 1 | loss: 0.7619171\n",
      "\tspeed: 0.0486s/iter; left time: 414.3322s\n",
      "\titers: 600, epoch: 1 | loss: 0.6939421\n",
      "\tspeed: 0.0501s/iter; left time: 421.5456s\n",
      "\titers: 700, epoch: 1 | loss: 0.6871172\n",
      "\tspeed: 0.0515s/iter; left time: 428.2527s\n",
      "\titers: 800, epoch: 1 | loss: 0.6730585\n",
      "\tspeed: 0.0495s/iter; left time: 407.2343s\n",
      "\titers: 900, epoch: 1 | loss: 0.6839611\n",
      "\tspeed: 0.0471s/iter; left time: 382.2429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.61s\n",
      "Steps: 902 | Train Loss: 0.7359966 Vali Loss: 0.7750741 Test Loss: 0.8830065\n",
      "Validation loss decreased (inf --> 0.775074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6534581\n",
      "\tspeed: 0.1104s/iter; left time: 885.1009s\n",
      "\titers: 200, epoch: 2 | loss: 0.6015845\n",
      "\tspeed: 0.0473s/iter; left time: 374.8443s\n",
      "\titers: 300, epoch: 2 | loss: 0.5685660\n",
      "\tspeed: 0.0467s/iter; left time: 365.3289s\n",
      "\titers: 400, epoch: 2 | loss: 0.5155253\n",
      "\tspeed: 0.0462s/iter; left time: 356.4591s\n",
      "\titers: 500, epoch: 2 | loss: 0.5459198\n",
      "\tspeed: 0.0395s/iter; left time: 301.2098s\n",
      "\titers: 600, epoch: 2 | loss: 0.5458264\n",
      "\tspeed: 0.0513s/iter; left time: 386.0754s\n",
      "\titers: 700, epoch: 2 | loss: 0.5243857\n",
      "\tspeed: 0.0474s/iter; left time: 351.9616s\n",
      "\titers: 800, epoch: 2 | loss: 0.4769245\n",
      "\tspeed: 0.0465s/iter; left time: 340.4534s\n",
      "\titers: 900, epoch: 2 | loss: 0.5050618\n",
      "\tspeed: 0.0470s/iter; left time: 339.3225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.40s\n",
      "Steps: 902 | Train Loss: 0.5828387 Vali Loss: 0.6318169 Test Loss: 0.6922542\n",
      "Validation loss decreased (0.775074 --> 0.631817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4728614\n",
      "\tspeed: 0.1218s/iter; left time: 866.5262s\n",
      "\titers: 200, epoch: 3 | loss: 0.5261030\n",
      "\tspeed: 0.0504s/iter; left time: 353.5869s\n",
      "\titers: 300, epoch: 3 | loss: 0.5349222\n",
      "\tspeed: 0.0484s/iter; left time: 335.0392s\n",
      "\titers: 400, epoch: 3 | loss: 0.4912176\n",
      "\tspeed: 0.0450s/iter; left time: 306.4674s\n",
      "\titers: 500, epoch: 3 | loss: 0.4878269\n",
      "\tspeed: 0.0477s/iter; left time: 320.6275s\n",
      "\titers: 600, epoch: 3 | loss: 0.4733405\n",
      "\tspeed: 0.0477s/iter; left time: 315.7988s\n",
      "\titers: 700, epoch: 3 | loss: 0.4788861\n",
      "\tspeed: 0.0466s/iter; left time: 303.4377s\n",
      "\titers: 800, epoch: 3 | loss: 0.4421423\n",
      "\tspeed: 0.0489s/iter; left time: 313.8948s\n",
      "\titers: 900, epoch: 3 | loss: 0.4829474\n",
      "\tspeed: 0.0469s/iter; left time: 296.4990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 902 | Train Loss: 0.4822041 Vali Loss: 0.6058274 Test Loss: 0.6784457\n",
      "Validation loss decreased (0.631817 --> 0.605827).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4432037\n",
      "\tspeed: 0.1160s/iter; left time: 720.7727s\n",
      "\titers: 200, epoch: 4 | loss: 0.4207739\n",
      "\tspeed: 0.0451s/iter; left time: 275.8593s\n",
      "\titers: 300, epoch: 4 | loss: 0.4485465\n",
      "\tspeed: 0.0457s/iter; left time: 274.8385s\n",
      "\titers: 400, epoch: 4 | loss: 0.4216956\n",
      "\tspeed: 0.0476s/iter; left time: 281.7872s\n",
      "\titers: 500, epoch: 4 | loss: 0.4323597\n",
      "\tspeed: 0.0425s/iter; left time: 247.3266s\n",
      "\titers: 600, epoch: 4 | loss: 0.4566031\n",
      "\tspeed: 0.0455s/iter; left time: 259.8650s\n",
      "\titers: 700, epoch: 4 | loss: 0.4132438\n",
      "\tspeed: 0.0439s/iter; left time: 246.3665s\n",
      "\titers: 800, epoch: 4 | loss: 0.4526260\n",
      "\tspeed: 0.0400s/iter; left time: 220.6084s\n",
      "\titers: 900, epoch: 4 | loss: 0.4229877\n",
      "\tspeed: 0.0394s/iter; left time: 213.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.02s\n",
      "Steps: 902 | Train Loss: 0.4381912 Vali Loss: 0.6134671 Test Loss: 0.6851713\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3913986\n",
      "\tspeed: 0.1141s/iter; left time: 605.9583s\n",
      "\titers: 200, epoch: 5 | loss: 0.4092474\n",
      "\tspeed: 0.0353s/iter; left time: 184.0592s\n",
      "\titers: 300, epoch: 5 | loss: 0.4011174\n",
      "\tspeed: 0.0318s/iter; left time: 162.7182s\n",
      "\titers: 400, epoch: 5 | loss: 0.4198884\n",
      "\tspeed: 0.0480s/iter; left time: 240.5887s\n",
      "\titers: 500, epoch: 5 | loss: 0.4173927\n",
      "\tspeed: 0.0450s/iter; left time: 221.1302s\n",
      "\titers: 600, epoch: 5 | loss: 0.3680047\n",
      "\tspeed: 0.0456s/iter; left time: 219.6033s\n",
      "\titers: 700, epoch: 5 | loss: 0.3919460\n",
      "\tspeed: 0.0409s/iter; left time: 192.5841s\n",
      "\titers: 800, epoch: 5 | loss: 0.3730892\n",
      "\tspeed: 0.0413s/iter; left time: 190.6214s\n",
      "\titers: 900, epoch: 5 | loss: 0.3954324\n",
      "\tspeed: 0.0479s/iter; left time: 215.9963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.78s\n",
      "Steps: 902 | Train Loss: 0.3990515 Vali Loss: 0.6189988 Test Loss: 0.7172663\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3820037\n",
      "\tspeed: 0.1137s/iter; left time: 501.7216s\n",
      "\titers: 200, epoch: 6 | loss: 0.3538638\n",
      "\tspeed: 0.0422s/iter; left time: 181.9069s\n",
      "\titers: 300, epoch: 6 | loss: 0.3834887\n",
      "\tspeed: 0.0498s/iter; left time: 209.5323s\n",
      "\titers: 400, epoch: 6 | loss: 0.3656156\n",
      "\tspeed: 0.0468s/iter; left time: 192.4982s\n",
      "\titers: 500, epoch: 6 | loss: 0.3440894\n",
      "\tspeed: 0.0456s/iter; left time: 182.7710s\n",
      "\titers: 600, epoch: 6 | loss: 0.3865888\n",
      "\tspeed: 0.0477s/iter; left time: 186.5412s\n",
      "\titers: 700, epoch: 6 | loss: 0.3846876\n",
      "\tspeed: 0.0441s/iter; left time: 167.9876s\n",
      "\titers: 800, epoch: 6 | loss: 0.3305223\n",
      "\tspeed: 0.0505s/iter; left time: 187.5696s\n",
      "\titers: 900, epoch: 6 | loss: 0.3503212\n",
      "\tspeed: 0.0390s/iter; left time: 140.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 902 | Train Loss: 0.3667933 Vali Loss: 0.6223052 Test Loss: 0.6999300\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.918017566204071, rmse:0.9581323266029358, mae:0.6783621907234192, rse:0.7590104937553406\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "informer_results = []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Join all the output lines into a single string\n",
    "            output_str = \"\".join(output)\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, metrics in enumerate(iteration_metrics, start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"MSE: {metrics[0]}, RMSE: {metrics[1]}, MAE: {metrics[2]}, RSE: {metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results list\n",
    "                informer_results.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>0.4748</td>\n",
       "      <td>0.5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4871</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.4672</td>\n",
       "      <td>0.5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.7384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.7626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8606</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.7358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.7537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.7590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4846  0.6961  0.4748  0.5509\n",
       "              2         24        0.4871  0.6979  0.4672  0.5524\n",
       "              1         96        0.8256  0.9086  0.6690  0.7206\n",
       "              2         96        0.8442  0.9188  0.6719  0.7287\n",
       "              1         168       0.8689  0.9321  0.6895  0.7384\n",
       "              2         168       0.9266  0.9626  0.7018  0.7626\n",
       "RMSE          1         24        0.5057  0.7111  0.4947  0.5628\n",
       "              2         24        0.4891  0.6993  0.4771  0.5535\n",
       "              1         96        0.8275  0.9097  0.6720  0.7215\n",
       "              2         96        0.8260  0.9089  0.6638  0.7208\n",
       "              1         168       0.8860  0.9413  0.6982  0.7457\n",
       "              2         168       0.9078  0.9528  0.6933  0.7548\n",
       "MAE           1         24        0.5188  0.7203  0.4572  0.5701\n",
       "              2         24        0.4892  0.6994  0.4595  0.5535\n",
       "              1         96        0.8606  0.9277  0.6448  0.7358\n",
       "              2         96        0.9031  0.9503  0.6443  0.7537\n",
       "              1         168       0.9182  0.9582  0.6744  0.7591\n",
       "              2         168       0.9180  0.9581  0.6784  0.7590"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name = 'informer_loss_functions_results.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df = convert_results_into_df(informer_results, path_dir, csv_name)\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MAE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>0.4584</td>\n",
       "      <td>0.5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.7448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MSE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4858</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.8349</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.7247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>0.7505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RMSE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>0.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.8267</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.8969</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Loss_function Pred_len                                \n",
       "MAE           24        0.5040  0.7099  0.4584  0.5618\n",
       "              96        0.8819  0.9390  0.6446  0.7448\n",
       "              168       0.9181  0.9582  0.6764  0.7590\n",
       "MSE           24        0.4858  0.6970  0.4710  0.5516\n",
       "              96        0.8349  0.9137  0.6705  0.7247\n",
       "              168       0.8978  0.9474  0.6957  0.7505\n",
       "RMSE          24        0.4974  0.7052  0.4859  0.5582\n",
       "              96        0.8267  0.9093  0.6679  0.7212\n",
       "              168       0.8969  0.9470  0.6958  0.7502"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "inf_res_scaled = pd.read_csv(os.path.join(path_dir, csv_name))\n",
    "inf_res_scaled = inf_res_scaled.groupby(['Loss_function', 'Pred_len']).mean().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test for PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4067861\n",
      "\tspeed: 0.0618s/iter; left time: 545.4145s\n",
      "\titers: 200, epoch: 1 | loss: 0.4441505\n",
      "\tspeed: 0.0314s/iter; left time: 273.9523s\n",
      "\titers: 300, epoch: 1 | loss: 0.3466372\n",
      "\tspeed: 0.0303s/iter; left time: 261.5679s\n",
      "\titers: 400, epoch: 1 | loss: 0.4167347\n",
      "\tspeed: 0.0316s/iter; left time: 269.8851s\n",
      "\titers: 500, epoch: 1 | loss: 0.3797604\n",
      "\tspeed: 0.0318s/iter; left time: 267.8762s\n",
      "\titers: 600, epoch: 1 | loss: 0.4442339\n",
      "\tspeed: 0.0309s/iter; left time: 257.3937s\n",
      "\titers: 700, epoch: 1 | loss: 0.3530229\n",
      "\tspeed: 0.0307s/iter; left time: 252.5693s\n",
      "\titers: 800, epoch: 1 | loss: 0.3307920\n",
      "\tspeed: 0.0314s/iter; left time: 255.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.50s\n",
      "Steps: 893 | Train Loss: 0.3779220 Vali Loss: 0.4366884 Test Loss: 0.4747182\n",
      "Validation loss decreased (inf --> 0.436688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4191621\n",
      "\tspeed: 0.1230s/iter; left time: 976.7399s\n",
      "\titers: 200, epoch: 2 | loss: 0.3883949\n",
      "\tspeed: 0.0312s/iter; left time: 244.4270s\n",
      "\titers: 300, epoch: 2 | loss: 0.2853642\n",
      "\tspeed: 0.0312s/iter; left time: 241.0462s\n",
      "\titers: 400, epoch: 2 | loss: 0.2934545\n",
      "\tspeed: 0.0308s/iter; left time: 235.0003s\n",
      "\titers: 500, epoch: 2 | loss: 0.2700022\n",
      "\tspeed: 0.0315s/iter; left time: 237.1714s\n",
      "\titers: 600, epoch: 2 | loss: 0.2921529\n",
      "\tspeed: 0.0310s/iter; left time: 230.4819s\n",
      "\titers: 700, epoch: 2 | loss: 0.3560504\n",
      "\tspeed: 0.0311s/iter; left time: 228.2321s\n",
      "\titers: 800, epoch: 2 | loss: 0.2627692\n",
      "\tspeed: 0.0317s/iter; left time: 229.6937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.21s\n",
      "Steps: 893 | Train Loss: 0.3095934 Vali Loss: 0.4201360 Test Loss: 0.4733070\n",
      "Validation loss decreased (0.436688 --> 0.420136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1976226\n",
      "\tspeed: 0.1193s/iter; left time: 840.1474s\n",
      "\titers: 200, epoch: 3 | loss: 0.2761410\n",
      "\tspeed: 0.0311s/iter; left time: 215.7002s\n",
      "\titers: 300, epoch: 3 | loss: 0.2458653\n",
      "\tspeed: 0.0310s/iter; left time: 211.8804s\n",
      "\titers: 400, epoch: 3 | loss: 0.2557061\n",
      "\tspeed: 0.0316s/iter; left time: 212.8690s\n",
      "\titers: 500, epoch: 3 | loss: 0.2356212\n",
      "\tspeed: 0.0314s/iter; left time: 208.6934s\n",
      "\titers: 600, epoch: 3 | loss: 0.2879966\n",
      "\tspeed: 0.0319s/iter; left time: 208.4661s\n",
      "\titers: 700, epoch: 3 | loss: 0.1753839\n",
      "\tspeed: 0.0316s/iter; left time: 203.6462s\n",
      "\titers: 800, epoch: 3 | loss: 0.3488563\n",
      "\tspeed: 0.0320s/iter; left time: 202.7771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.2753121 Vali Loss: 0.4047166 Test Loss: 0.4483665\n",
      "Validation loss decreased (0.420136 --> 0.404717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2410289\n",
      "\tspeed: 0.1208s/iter; left time: 743.4668s\n",
      "\titers: 200, epoch: 4 | loss: 0.2470481\n",
      "\tspeed: 0.0313s/iter; left time: 189.4012s\n",
      "\titers: 300, epoch: 4 | loss: 0.2601063\n",
      "\tspeed: 0.0317s/iter; left time: 188.6144s\n",
      "\titers: 400, epoch: 4 | loss: 0.2026358\n",
      "\tspeed: 0.0324s/iter; left time: 189.6287s\n",
      "\titers: 500, epoch: 4 | loss: 0.3785451\n",
      "\tspeed: 0.0317s/iter; left time: 182.1979s\n",
      "\titers: 600, epoch: 4 | loss: 0.2231348\n",
      "\tspeed: 0.0323s/iter; left time: 182.6004s\n",
      "\titers: 700, epoch: 4 | loss: 0.2442176\n",
      "\tspeed: 0.0313s/iter; left time: 173.6814s\n",
      "\titers: 800, epoch: 4 | loss: 0.3108157\n",
      "\tspeed: 0.0310s/iter; left time: 169.2098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.61s\n",
      "Steps: 893 | Train Loss: 0.2664523 Vali Loss: 0.4257482 Test Loss: 0.4693747\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2611023\n",
      "\tspeed: 0.1209s/iter; left time: 636.0070s\n",
      "\titers: 200, epoch: 5 | loss: 0.1960735\n",
      "\tspeed: 0.0313s/iter; left time: 161.3559s\n",
      "\titers: 300, epoch: 5 | loss: 0.2680487\n",
      "\tspeed: 0.0316s/iter; left time: 160.0397s\n",
      "\titers: 400, epoch: 5 | loss: 0.2046869\n",
      "\tspeed: 0.0317s/iter; left time: 157.3545s\n",
      "\titers: 500, epoch: 5 | loss: 0.2397768\n",
      "\tspeed: 0.0312s/iter; left time: 151.6406s\n",
      "\titers: 600, epoch: 5 | loss: 0.1906617\n",
      "\tspeed: 0.0311s/iter; left time: 147.8660s\n",
      "\titers: 700, epoch: 5 | loss: 0.2341967\n",
      "\tspeed: 0.0313s/iter; left time: 145.8992s\n",
      "\titers: 800, epoch: 5 | loss: 0.2201203\n",
      "\tspeed: 0.0316s/iter; left time: 143.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 893 | Train Loss: 0.2545215 Vali Loss: 0.4124806 Test Loss: 0.4621130\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1729541\n",
      "\tspeed: 0.1201s/iter; left time: 524.2352s\n",
      "\titers: 200, epoch: 6 | loss: 0.2716974\n",
      "\tspeed: 0.0309s/iter; left time: 131.6079s\n",
      "\titers: 300, epoch: 6 | loss: 0.1882301\n",
      "\tspeed: 0.0307s/iter; left time: 128.0949s\n",
      "\titers: 400, epoch: 6 | loss: 0.1796709\n",
      "\tspeed: 0.0312s/iter; left time: 126.8079s\n",
      "\titers: 500, epoch: 6 | loss: 0.1980457\n",
      "\tspeed: 0.0312s/iter; left time: 123.8855s\n",
      "\titers: 600, epoch: 6 | loss: 0.2305602\n",
      "\tspeed: 0.0308s/iter; left time: 119.2580s\n",
      "\titers: 700, epoch: 6 | loss: 0.1816547\n",
      "\tspeed: 0.0313s/iter; left time: 117.8817s\n",
      "\titers: 800, epoch: 6 | loss: 0.2198416\n",
      "\tspeed: 0.0313s/iter; left time: 114.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.18s\n",
      "Steps: 893 | Train Loss: 0.2311724 Vali Loss: 0.4321579 Test Loss: 0.4777981\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.44836655259132385, rmse:0.6696017980575562, mae:0.4417327344417572, rse:0.5299475193023682\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5262045\n",
      "\tspeed: 0.0346s/iter; left time: 305.5105s\n",
      "\titers: 200, epoch: 1 | loss: 0.3315853\n",
      "\tspeed: 0.0314s/iter; left time: 274.5611s\n",
      "\titers: 300, epoch: 1 | loss: 0.3316531\n",
      "\tspeed: 0.0318s/iter; left time: 274.8647s\n",
      "\titers: 400, epoch: 1 | loss: 0.3081319\n",
      "\tspeed: 0.0311s/iter; left time: 265.1606s\n",
      "\titers: 500, epoch: 1 | loss: 0.3540432\n",
      "\tspeed: 0.0313s/iter; left time: 264.0409s\n",
      "\titers: 600, epoch: 1 | loss: 0.3433473\n",
      "\tspeed: 0.0316s/iter; left time: 263.6753s\n",
      "\titers: 700, epoch: 1 | loss: 0.3508300\n",
      "\tspeed: 0.0318s/iter; left time: 261.4705s\n",
      "\titers: 800, epoch: 1 | loss: 0.3784662\n",
      "\tspeed: 0.0306s/iter; left time: 249.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 893 | Train Loss: 0.3757420 Vali Loss: 0.4322510 Test Loss: 0.4751531\n",
      "Validation loss decreased (inf --> 0.432251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3585857\n",
      "\tspeed: 0.1212s/iter; left time: 961.7677s\n",
      "\titers: 200, epoch: 2 | loss: 0.3756787\n",
      "\tspeed: 0.0324s/iter; left time: 254.0281s\n",
      "\titers: 300, epoch: 2 | loss: 0.2872087\n",
      "\tspeed: 0.0312s/iter; left time: 241.6454s\n",
      "\titers: 400, epoch: 2 | loss: 0.3223063\n",
      "\tspeed: 0.0315s/iter; left time: 240.7486s\n",
      "\titers: 500, epoch: 2 | loss: 0.2732984\n",
      "\tspeed: 0.0317s/iter; left time: 238.5880s\n",
      "\titers: 600, epoch: 2 | loss: 0.2680305\n",
      "\tspeed: 0.0309s/iter; left time: 229.6253s\n",
      "\titers: 700, epoch: 2 | loss: 0.1938201\n",
      "\tspeed: 0.0310s/iter; left time: 227.4841s\n",
      "\titers: 800, epoch: 2 | loss: 0.2850960\n",
      "\tspeed: 0.0309s/iter; left time: 223.3719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 893 | Train Loss: 0.3116849 Vali Loss: 0.4068280 Test Loss: 0.4500532\n",
      "Validation loss decreased (0.432251 --> 0.406828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2115857\n",
      "\tspeed: 0.1194s/iter; left time: 841.0148s\n",
      "\titers: 200, epoch: 3 | loss: 0.2527627\n",
      "\tspeed: 0.0311s/iter; left time: 216.2180s\n",
      "\titers: 300, epoch: 3 | loss: 0.2349344\n",
      "\tspeed: 0.0313s/iter; left time: 214.2754s\n",
      "\titers: 400, epoch: 3 | loss: 0.2312559\n",
      "\tspeed: 0.0312s/iter; left time: 210.4607s\n",
      "\titers: 500, epoch: 3 | loss: 0.2591968\n",
      "\tspeed: 0.0314s/iter; left time: 208.5553s\n",
      "\titers: 600, epoch: 3 | loss: 0.2584438\n",
      "\tspeed: 0.0313s/iter; left time: 205.0976s\n",
      "\titers: 700, epoch: 3 | loss: 0.1912299\n",
      "\tspeed: 0.0309s/iter; left time: 199.3710s\n",
      "\titers: 800, epoch: 3 | loss: 0.2341460\n",
      "\tspeed: 0.0319s/iter; left time: 202.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.33s\n",
      "Steps: 893 | Train Loss: 0.2722220 Vali Loss: 0.4083535 Test Loss: 0.4452906\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2545739\n",
      "\tspeed: 0.1202s/iter; left time: 739.3227s\n",
      "\titers: 200, epoch: 4 | loss: 0.2334660\n",
      "\tspeed: 0.0307s/iter; left time: 185.7667s\n",
      "\titers: 300, epoch: 4 | loss: 0.2265522\n",
      "\tspeed: 0.0312s/iter; left time: 185.8752s\n",
      "\titers: 400, epoch: 4 | loss: 0.3044085\n",
      "\tspeed: 0.0313s/iter; left time: 183.2433s\n",
      "\titers: 500, epoch: 4 | loss: 0.2946774\n",
      "\tspeed: 0.0316s/iter; left time: 181.8553s\n",
      "\titers: 600, epoch: 4 | loss: 0.2919169\n",
      "\tspeed: 0.0313s/iter; left time: 176.6453s\n",
      "\titers: 700, epoch: 4 | loss: 0.2638292\n",
      "\tspeed: 0.0310s/iter; left time: 172.2544s\n",
      "\titers: 800, epoch: 4 | loss: 0.3133108\n",
      "\tspeed: 0.0315s/iter; left time: 171.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.12s\n",
      "Steps: 893 | Train Loss: 0.2747090 Vali Loss: 0.4111806 Test Loss: 0.4471633\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2393840\n",
      "\tspeed: 0.1196s/iter; left time: 629.0070s\n",
      "\titers: 200, epoch: 5 | loss: 0.2559421\n",
      "\tspeed: 0.0316s/iter; left time: 163.1251s\n",
      "\titers: 300, epoch: 5 | loss: 0.2435157\n",
      "\tspeed: 0.0307s/iter; left time: 155.0725s\n",
      "\titers: 400, epoch: 5 | loss: 0.2586333\n",
      "\tspeed: 0.0317s/iter; left time: 157.3260s\n",
      "\titers: 500, epoch: 5 | loss: 0.1682083\n",
      "\tspeed: 0.0307s/iter; left time: 149.2570s\n",
      "\titers: 600, epoch: 5 | loss: 0.2274452\n",
      "\tspeed: 0.0321s/iter; left time: 152.7707s\n",
      "\titers: 700, epoch: 5 | loss: 0.2368916\n",
      "\tspeed: 0.0308s/iter; left time: 143.4999s\n",
      "\titers: 800, epoch: 5 | loss: 0.2482656\n",
      "\tspeed: 0.0318s/iter; left time: 145.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.17s\n",
      "Steps: 893 | Train Loss: 0.2490787 Vali Loss: 0.4261985 Test Loss: 0.4697030\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.45005327463150024, rmse:0.6708601117134094, mae:0.44774743914604187, rse:0.5309433937072754\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7350927\n",
      "\tspeed: 0.0651s/iter; left time: 573.6591s\n",
      "\titers: 200, epoch: 1 | loss: 0.5331434\n",
      "\tspeed: 0.0318s/iter; left time: 276.7058s\n",
      "\titers: 300, epoch: 1 | loss: 0.5643482\n",
      "\tspeed: 0.0311s/iter; left time: 267.8018s\n",
      "\titers: 400, epoch: 1 | loss: 0.4737360\n",
      "\tspeed: 0.0316s/iter; left time: 268.8895s\n",
      "\titers: 500, epoch: 1 | loss: 0.5555341\n",
      "\tspeed: 0.0313s/iter; left time: 263.3108s\n",
      "\titers: 600, epoch: 1 | loss: 0.4801058\n",
      "\tspeed: 0.0333s/iter; left time: 277.1614s\n",
      "\titers: 700, epoch: 1 | loss: 0.5420830\n",
      "\tspeed: 0.0316s/iter; left time: 259.5095s\n",
      "\titers: 800, epoch: 1 | loss: 0.6246823\n",
      "\tspeed: 0.0323s/iter; left time: 261.8027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.98s\n",
      "Steps: 891 | Train Loss: 0.5666696 Vali Loss: 0.6507550 Test Loss: 0.7603688\n",
      "Validation loss decreased (inf --> 0.650755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5508886\n",
      "\tspeed: 0.1190s/iter; left time: 942.5543s\n",
      "\titers: 200, epoch: 2 | loss: 0.4782372\n",
      "\tspeed: 0.0316s/iter; left time: 246.8407s\n",
      "\titers: 300, epoch: 2 | loss: 0.4537062\n",
      "\tspeed: 0.0309s/iter; left time: 238.7313s\n",
      "\titers: 400, epoch: 2 | loss: 0.5367521\n",
      "\tspeed: 0.0317s/iter; left time: 241.5106s\n",
      "\titers: 500, epoch: 2 | loss: 0.4129211\n",
      "\tspeed: 0.0314s/iter; left time: 235.9067s\n",
      "\titers: 600, epoch: 2 | loss: 0.3939895\n",
      "\tspeed: 0.0320s/iter; left time: 237.1966s\n",
      "\titers: 700, epoch: 2 | loss: 0.3940258\n",
      "\tspeed: 0.0314s/iter; left time: 229.7309s\n",
      "\titers: 800, epoch: 2 | loss: 0.5477642\n",
      "\tspeed: 0.0321s/iter; left time: 231.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 891 | Train Loss: 0.5034053 Vali Loss: 0.6302209 Test Loss: 0.7422130\n",
      "Validation loss decreased (0.650755 --> 0.630221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4207375\n",
      "\tspeed: 0.1197s/iter; left time: 841.6217s\n",
      "\titers: 200, epoch: 3 | loss: 0.4774581\n",
      "\tspeed: 0.0319s/iter; left time: 221.2736s\n",
      "\titers: 300, epoch: 3 | loss: 0.4797868\n",
      "\tspeed: 0.0312s/iter; left time: 213.3556s\n",
      "\titers: 400, epoch: 3 | loss: 0.4654181\n",
      "\tspeed: 0.0322s/iter; left time: 216.4540s\n",
      "\titers: 500, epoch: 3 | loss: 0.4620503\n",
      "\tspeed: 0.0313s/iter; left time: 207.3079s\n",
      "\titers: 600, epoch: 3 | loss: 0.3983879\n",
      "\tspeed: 0.0318s/iter; left time: 207.5139s\n",
      "\titers: 700, epoch: 3 | loss: 0.4545757\n",
      "\tspeed: 0.0310s/iter; left time: 199.5943s\n",
      "\titers: 800, epoch: 3 | loss: 0.3508699\n",
      "\tspeed: 0.0317s/iter; left time: 200.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.41s\n",
      "Steps: 891 | Train Loss: 0.4436112 Vali Loss: 0.6790225 Test Loss: 0.8343483\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3930919\n",
      "\tspeed: 0.1210s/iter; left time: 742.9491s\n",
      "\titers: 200, epoch: 4 | loss: 0.3857051\n",
      "\tspeed: 0.0317s/iter; left time: 191.2645s\n",
      "\titers: 300, epoch: 4 | loss: 0.3910512\n",
      "\tspeed: 0.0310s/iter; left time: 184.2469s\n",
      "\titers: 400, epoch: 4 | loss: 0.3440876\n",
      "\tspeed: 0.0313s/iter; left time: 182.9644s\n",
      "\titers: 500, epoch: 4 | loss: 0.3572256\n",
      "\tspeed: 0.0314s/iter; left time: 180.3815s\n",
      "\titers: 600, epoch: 4 | loss: 0.3604954\n",
      "\tspeed: 0.0312s/iter; left time: 176.0264s\n",
      "\titers: 700, epoch: 4 | loss: 0.3148938\n",
      "\tspeed: 0.0313s/iter; left time: 173.4297s\n",
      "\titers: 800, epoch: 4 | loss: 0.2804092\n",
      "\tspeed: 0.0311s/iter; left time: 169.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.27s\n",
      "Steps: 891 | Train Loss: 0.3506069 Vali Loss: 0.7364413 Test Loss: 0.9841605\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992230\n",
      "\tspeed: 0.1204s/iter; left time: 631.6144s\n",
      "\titers: 200, epoch: 5 | loss: 0.2692065\n",
      "\tspeed: 0.0311s/iter; left time: 159.8641s\n",
      "\titers: 300, epoch: 5 | loss: 0.3012003\n",
      "\tspeed: 0.0316s/iter; left time: 159.4622s\n",
      "\titers: 400, epoch: 5 | loss: 0.2610649\n",
      "\tspeed: 0.0316s/iter; left time: 156.2331s\n",
      "\titers: 500, epoch: 5 | loss: 0.2403007\n",
      "\tspeed: 0.0320s/iter; left time: 155.0884s\n",
      "\titers: 600, epoch: 5 | loss: 0.2463413\n",
      "\tspeed: 0.0313s/iter; left time: 148.7368s\n",
      "\titers: 700, epoch: 5 | loss: 0.2088397\n",
      "\tspeed: 0.0319s/iter; left time: 148.3819s\n",
      "\titers: 800, epoch: 5 | loss: 0.1900299\n",
      "\tspeed: 0.0310s/iter; left time: 140.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 891 | Train Loss: 0.2549890 Vali Loss: 0.7904755 Test Loss: 0.9790931\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7422130107879639, rmse:0.8615178465843201, mae:0.6124135255813599, rse:0.6832898259162903\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5492080\n",
      "\tspeed: 0.0342s/iter; left time: 301.0513s\n",
      "\titers: 200, epoch: 1 | loss: 0.4859957\n",
      "\tspeed: 0.0316s/iter; left time: 275.0552s\n",
      "\titers: 300, epoch: 1 | loss: 0.6569293\n",
      "\tspeed: 0.0312s/iter; left time: 268.4826s\n",
      "\titers: 400, epoch: 1 | loss: 0.6637321\n",
      "\tspeed: 0.0317s/iter; left time: 269.7454s\n",
      "\titers: 500, epoch: 1 | loss: 0.4725395\n",
      "\tspeed: 0.0320s/iter; left time: 269.3996s\n",
      "\titers: 600, epoch: 1 | loss: 0.6087062\n",
      "\tspeed: 0.0318s/iter; left time: 264.3549s\n",
      "\titers: 700, epoch: 1 | loss: 0.5336012\n",
      "\tspeed: 0.0316s/iter; left time: 259.3402s\n",
      "\titers: 800, epoch: 1 | loss: 0.4981490\n",
      "\tspeed: 0.0318s/iter; left time: 257.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 891 | Train Loss: 0.5658145 Vali Loss: 0.6509723 Test Loss: 0.7613885\n",
      "Validation loss decreased (inf --> 0.650972).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5161237\n",
      "\tspeed: 0.1269s/iter; left time: 1005.2414s\n",
      "\titers: 200, epoch: 2 | loss: 0.4519113\n",
      "\tspeed: 0.0313s/iter; left time: 244.6382s\n",
      "\titers: 300, epoch: 2 | loss: 0.5050961\n",
      "\tspeed: 0.0313s/iter; left time: 242.0134s\n",
      "\titers: 400, epoch: 2 | loss: 0.4837454\n",
      "\tspeed: 0.0326s/iter; left time: 248.1126s\n",
      "\titers: 500, epoch: 2 | loss: 0.3912456\n",
      "\tspeed: 0.0318s/iter; left time: 239.4667s\n",
      "\titers: 600, epoch: 2 | loss: 0.4848349\n",
      "\tspeed: 0.0319s/iter; left time: 236.8622s\n",
      "\titers: 700, epoch: 2 | loss: 0.5555402\n",
      "\tspeed: 0.0321s/iter; left time: 234.9810s\n",
      "\titers: 800, epoch: 2 | loss: 0.4755200\n",
      "\tspeed: 0.0314s/iter; left time: 226.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.62s\n",
      "Steps: 891 | Train Loss: 0.5040694 Vali Loss: 0.6160402 Test Loss: 0.7765765\n",
      "Validation loss decreased (0.650972 --> 0.616040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5024767\n",
      "\tspeed: 0.1229s/iter; left time: 863.5161s\n",
      "\titers: 200, epoch: 3 | loss: 0.4118575\n",
      "\tspeed: 0.0319s/iter; left time: 220.9479s\n",
      "\titers: 300, epoch: 3 | loss: 0.3771535\n",
      "\tspeed: 0.0312s/iter; left time: 212.7627s\n",
      "\titers: 400, epoch: 3 | loss: 0.4179978\n",
      "\tspeed: 0.0315s/iter; left time: 211.8641s\n",
      "\titers: 500, epoch: 3 | loss: 0.3775936\n",
      "\tspeed: 0.0319s/iter; left time: 211.7567s\n",
      "\titers: 600, epoch: 3 | loss: 0.4359340\n",
      "\tspeed: 0.0316s/iter; left time: 206.5479s\n",
      "\titers: 700, epoch: 3 | loss: 0.4540095\n",
      "\tspeed: 0.0314s/iter; left time: 201.6101s\n",
      "\titers: 800, epoch: 3 | loss: 0.3968827\n",
      "\tspeed: 0.0320s/iter; left time: 202.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 891 | Train Loss: 0.4337413 Vali Loss: 0.6738052 Test Loss: 0.8782709\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3413571\n",
      "\tspeed: 0.1236s/iter; left time: 758.8777s\n",
      "\titers: 200, epoch: 4 | loss: 0.3642122\n",
      "\tspeed: 0.0314s/iter; left time: 189.5118s\n",
      "\titers: 300, epoch: 4 | loss: 0.3214867\n",
      "\tspeed: 0.0313s/iter; left time: 186.0472s\n",
      "\titers: 400, epoch: 4 | loss: 0.3307844\n",
      "\tspeed: 0.0314s/iter; left time: 183.4687s\n",
      "\titers: 500, epoch: 4 | loss: 0.2876466\n",
      "\tspeed: 0.0319s/iter; left time: 182.9022s\n",
      "\titers: 600, epoch: 4 | loss: 0.3171612\n",
      "\tspeed: 0.0319s/iter; left time: 179.6451s\n",
      "\titers: 700, epoch: 4 | loss: 0.3564140\n",
      "\tspeed: 0.0313s/iter; left time: 173.1075s\n",
      "\titers: 800, epoch: 4 | loss: 0.2793794\n",
      "\tspeed: 0.0312s/iter; left time: 169.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 891 | Train Loss: 0.3311874 Vali Loss: 0.7461717 Test Loss: 0.9487936\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2640831\n",
      "\tspeed: 0.1229s/iter; left time: 644.7111s\n",
      "\titers: 200, epoch: 5 | loss: 0.2520849\n",
      "\tspeed: 0.0312s/iter; left time: 160.4071s\n",
      "\titers: 300, epoch: 5 | loss: 0.2518609\n",
      "\tspeed: 0.0314s/iter; left time: 158.4034s\n",
      "\titers: 400, epoch: 5 | loss: 0.2524282\n",
      "\tspeed: 0.0312s/iter; left time: 154.2794s\n",
      "\titers: 500, epoch: 5 | loss: 0.2023046\n",
      "\tspeed: 0.0322s/iter; left time: 156.1406s\n",
      "\titers: 600, epoch: 5 | loss: 0.2215946\n",
      "\tspeed: 0.0319s/iter; left time: 151.3647s\n",
      "\titers: 700, epoch: 5 | loss: 0.2187695\n",
      "\tspeed: 0.0317s/iter; left time: 147.5358s\n",
      "\titers: 800, epoch: 5 | loss: 0.2183925\n",
      "\tspeed: 0.0310s/iter; left time: 140.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 891 | Train Loss: 0.2421987 Vali Loss: 0.8076875 Test Loss: 1.0193228\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7765764594078064, rmse:0.8812357783317566, mae:0.6239685416221619, rse:0.6989285945892334\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7521098\n",
      "\tspeed: 0.0623s/iter; left time: 547.3055s\n",
      "\titers: 200, epoch: 1 | loss: 0.6007847\n",
      "\tspeed: 0.0312s/iter; left time: 271.4089s\n",
      "\titers: 300, epoch: 1 | loss: 0.6152054\n",
      "\tspeed: 0.0319s/iter; left time: 274.0422s\n",
      "\titers: 400, epoch: 1 | loss: 0.7049997\n",
      "\tspeed: 0.0317s/iter; left time: 268.8858s\n",
      "\titers: 500, epoch: 1 | loss: 0.6788938\n",
      "\tspeed: 0.0320s/iter; left time: 268.3110s\n",
      "\titers: 600, epoch: 1 | loss: 0.5894001\n",
      "\tspeed: 0.0317s/iter; left time: 262.6517s\n",
      "\titers: 700, epoch: 1 | loss: 0.5699273\n",
      "\tspeed: 0.0314s/iter; left time: 256.7889s\n",
      "\titers: 800, epoch: 1 | loss: 0.5969278\n",
      "\tspeed: 0.0322s/iter; left time: 260.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 889 | Train Loss: 0.6099524 Vali Loss: 0.6799847 Test Loss: 0.8065665\n",
      "Validation loss decreased (inf --> 0.679985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6172050\n",
      "\tspeed: 0.1248s/iter; left time: 986.4427s\n",
      "\titers: 200, epoch: 2 | loss: 0.4975815\n",
      "\tspeed: 0.0314s/iter; left time: 244.6376s\n",
      "\titers: 300, epoch: 2 | loss: 0.6476253\n",
      "\tspeed: 0.0316s/iter; left time: 243.6439s\n",
      "\titers: 400, epoch: 2 | loss: 0.5246449\n",
      "\tspeed: 0.0325s/iter; left time: 246.7248s\n",
      "\titers: 500, epoch: 2 | loss: 0.5240585\n",
      "\tspeed: 0.0324s/iter; left time: 242.8323s\n",
      "\titers: 600, epoch: 2 | loss: 0.5292070\n",
      "\tspeed: 0.0312s/iter; left time: 231.3082s\n",
      "\titers: 700, epoch: 2 | loss: 0.4574342\n",
      "\tspeed: 0.0320s/iter; left time: 233.7413s\n",
      "\titers: 800, epoch: 2 | loss: 0.5481951\n",
      "\tspeed: 0.0323s/iter; left time: 232.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.65s\n",
      "Steps: 889 | Train Loss: 0.5429346 Vali Loss: 0.6640639 Test Loss: 0.8117316\n",
      "Validation loss decreased (0.679985 --> 0.664064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4886448\n",
      "\tspeed: 0.1225s/iter; left time: 858.8833s\n",
      "\titers: 200, epoch: 3 | loss: 0.3973114\n",
      "\tspeed: 0.0325s/iter; left time: 224.5257s\n",
      "\titers: 300, epoch: 3 | loss: 0.4314150\n",
      "\tspeed: 0.0316s/iter; left time: 215.3087s\n",
      "\titers: 400, epoch: 3 | loss: 0.4969940\n",
      "\tspeed: 0.0312s/iter; left time: 209.4185s\n",
      "\titers: 500, epoch: 3 | loss: 0.5164841\n",
      "\tspeed: 0.0319s/iter; left time: 210.9488s\n",
      "\titers: 600, epoch: 3 | loss: 0.4380926\n",
      "\tspeed: 0.0316s/iter; left time: 206.1277s\n",
      "\titers: 700, epoch: 3 | loss: 0.4044043\n",
      "\tspeed: 0.0318s/iter; left time: 203.9479s\n",
      "\titers: 800, epoch: 3 | loss: 0.3843125\n",
      "\tspeed: 0.0323s/iter; left time: 204.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 889 | Train Loss: 0.4357219 Vali Loss: 0.7769464 Test Loss: 0.9891453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3211450\n",
      "\tspeed: 0.1200s/iter; left time: 735.1505s\n",
      "\titers: 200, epoch: 4 | loss: 0.3304462\n",
      "\tspeed: 0.0315s/iter; left time: 189.6313s\n",
      "\titers: 300, epoch: 4 | loss: 0.3415274\n",
      "\tspeed: 0.0321s/iter; left time: 190.0003s\n",
      "\titers: 400, epoch: 4 | loss: 0.3021772\n",
      "\tspeed: 0.0328s/iter; left time: 190.8846s\n",
      "\titers: 500, epoch: 4 | loss: 0.3135553\n",
      "\tspeed: 0.0314s/iter; left time: 179.8967s\n",
      "\titers: 600, epoch: 4 | loss: 0.2619257\n",
      "\tspeed: 0.0319s/iter; left time: 179.3353s\n",
      "\titers: 700, epoch: 4 | loss: 0.2942001\n",
      "\tspeed: 0.0319s/iter; left time: 176.0368s\n",
      "\titers: 800, epoch: 4 | loss: 0.2700432\n",
      "\tspeed: 0.0312s/iter; left time: 169.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.64s\n",
      "Steps: 889 | Train Loss: 0.3104558 Vali Loss: 0.8652552 Test Loss: 1.1168098\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2556500\n",
      "\tspeed: 0.1178s/iter; left time: 616.6828s\n",
      "\titers: 200, epoch: 5 | loss: 0.2300823\n",
      "\tspeed: 0.0315s/iter; left time: 161.7034s\n",
      "\titers: 300, epoch: 5 | loss: 0.2233204\n",
      "\tspeed: 0.0321s/iter; left time: 161.5478s\n",
      "\titers: 400, epoch: 5 | loss: 0.2191859\n",
      "\tspeed: 0.0324s/iter; left time: 159.9081s\n",
      "\titers: 500, epoch: 5 | loss: 0.2317215\n",
      "\tspeed: 0.0318s/iter; left time: 153.5836s\n",
      "\titers: 600, epoch: 5 | loss: 0.2150825\n",
      "\tspeed: 0.0322s/iter; left time: 152.3327s\n",
      "\titers: 700, epoch: 5 | loss: 0.2159313\n",
      "\tspeed: 0.0329s/iter; left time: 152.5604s\n",
      "\titers: 800, epoch: 5 | loss: 0.2022086\n",
      "\tspeed: 0.0317s/iter; left time: 143.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.71s\n",
      "Steps: 889 | Train Loss: 0.2222990 Vali Loss: 0.9255603 Test Loss: 1.1465713\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8117320537567139, rmse:0.9009617567062378, mae:0.6470239162445068, rse:0.7137212157249451\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7978647\n",
      "\tspeed: 0.0342s/iter; left time: 300.4114s\n",
      "\titers: 200, epoch: 1 | loss: 0.6837984\n",
      "\tspeed: 0.0321s/iter; left time: 279.1424s\n",
      "\titers: 300, epoch: 1 | loss: 0.7392839\n",
      "\tspeed: 0.0316s/iter; left time: 271.1981s\n",
      "\titers: 400, epoch: 1 | loss: 0.6827503\n",
      "\tspeed: 0.0321s/iter; left time: 272.2672s\n",
      "\titers: 500, epoch: 1 | loss: 0.6033980\n",
      "\tspeed: 0.0317s/iter; left time: 266.1128s\n",
      "\titers: 600, epoch: 1 | loss: 0.4859983\n",
      "\tspeed: 0.0320s/iter; left time: 265.4535s\n",
      "\titers: 700, epoch: 1 | loss: 0.5655484\n",
      "\tspeed: 0.0316s/iter; left time: 258.4526s\n",
      "\titers: 800, epoch: 1 | loss: 0.5079218\n",
      "\tspeed: 0.0323s/iter; left time: 261.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.64s\n",
      "Steps: 889 | Train Loss: 0.6113329 Vali Loss: 0.6772429 Test Loss: 0.8047687\n",
      "Validation loss decreased (inf --> 0.677243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6033688\n",
      "\tspeed: 0.1274s/iter; left time: 1006.9282s\n",
      "\titers: 200, epoch: 2 | loss: 0.5683392\n",
      "\tspeed: 0.0315s/iter; left time: 245.8377s\n",
      "\titers: 300, epoch: 2 | loss: 0.5827187\n",
      "\tspeed: 0.0317s/iter; left time: 244.5075s\n",
      "\titers: 400, epoch: 2 | loss: 0.5492290\n",
      "\tspeed: 0.0316s/iter; left time: 240.4446s\n",
      "\titers: 500, epoch: 2 | loss: 0.5587810\n",
      "\tspeed: 0.0320s/iter; left time: 239.6955s\n",
      "\titers: 600, epoch: 2 | loss: 0.5635834\n",
      "\tspeed: 0.0316s/iter; left time: 233.7961s\n",
      "\titers: 700, epoch: 2 | loss: 0.4950199\n",
      "\tspeed: 0.0319s/iter; left time: 232.7123s\n",
      "\titers: 800, epoch: 2 | loss: 0.4720615\n",
      "\tspeed: 0.0316s/iter; left time: 227.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 889 | Train Loss: 0.5432593 Vali Loss: 0.6869962 Test Loss: 0.8683541\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4402420\n",
      "\tspeed: 0.1195s/iter; left time: 838.3172s\n",
      "\titers: 200, epoch: 3 | loss: 0.4191861\n",
      "\tspeed: 0.0313s/iter; left time: 216.0320s\n",
      "\titers: 300, epoch: 3 | loss: 0.5186195\n",
      "\tspeed: 0.0318s/iter; left time: 216.5130s\n",
      "\titers: 400, epoch: 3 | loss: 0.5220535\n",
      "\tspeed: 0.0313s/iter; left time: 210.3194s\n",
      "\titers: 500, epoch: 3 | loss: 0.4451554\n",
      "\tspeed: 0.0318s/iter; left time: 209.9855s\n",
      "\titers: 600, epoch: 3 | loss: 0.4743469\n",
      "\tspeed: 0.0316s/iter; left time: 205.6034s\n",
      "\titers: 700, epoch: 3 | loss: 0.4111080\n",
      "\tspeed: 0.0320s/iter; left time: 205.4636s\n",
      "\titers: 800, epoch: 3 | loss: 0.4094478\n",
      "\tspeed: 0.0316s/iter; left time: 199.4904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.46s\n",
      "Steps: 889 | Train Loss: 0.4466548 Vali Loss: 0.7438418 Test Loss: 0.9441403\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3602397\n",
      "\tspeed: 0.1202s/iter; left time: 735.8068s\n",
      "\titers: 200, epoch: 4 | loss: 0.3151694\n",
      "\tspeed: 0.0317s/iter; left time: 190.7147s\n",
      "\titers: 300, epoch: 4 | loss: 0.3296907\n",
      "\tspeed: 0.0318s/iter; left time: 188.5246s\n",
      "\titers: 400, epoch: 4 | loss: 0.2959401\n",
      "\tspeed: 0.0315s/iter; left time: 183.4164s\n",
      "\titers: 500, epoch: 4 | loss: 0.3110943\n",
      "\tspeed: 0.0320s/iter; left time: 183.2242s\n",
      "\titers: 600, epoch: 4 | loss: 0.2497295\n",
      "\tspeed: 0.0315s/iter; left time: 177.3294s\n",
      "\titers: 700, epoch: 4 | loss: 0.3455361\n",
      "\tspeed: 0.0316s/iter; left time: 174.6610s\n",
      "\titers: 800, epoch: 4 | loss: 0.2981187\n",
      "\tspeed: 0.0313s/iter; left time: 169.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 889 | Train Loss: 0.3199539 Vali Loss: 0.7973347 Test Loss: 1.0295899\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.804768979549408, rmse:0.8970891833305359, mae:0.6460970044136047, rse:0.7106534838676453\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6306419\n",
      "\tspeed: 0.0640s/iter; left time: 564.7426s\n",
      "\titers: 200, epoch: 1 | loss: 0.6611215\n",
      "\tspeed: 0.0314s/iter; left time: 274.3284s\n",
      "\titers: 300, epoch: 1 | loss: 0.5860810\n",
      "\tspeed: 0.0313s/iter; left time: 269.9036s\n",
      "\titers: 400, epoch: 1 | loss: 0.6398843\n",
      "\tspeed: 0.0316s/iter; left time: 269.2117s\n",
      "\titers: 500, epoch: 1 | loss: 0.6135658\n",
      "\tspeed: 0.0323s/iter; left time: 272.3531s\n",
      "\titers: 600, epoch: 1 | loss: 0.6647395\n",
      "\tspeed: 0.0312s/iter; left time: 260.1544s\n",
      "\titers: 700, epoch: 1 | loss: 0.5875278\n",
      "\tspeed: 0.0318s/iter; left time: 261.3359s\n",
      "\titers: 800, epoch: 1 | loss: 0.5724316\n",
      "\tspeed: 0.0313s/iter; left time: 254.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.87s\n",
      "Steps: 893 | Train Loss: 0.6036288 Vali Loss: 0.4337196 Test Loss: 0.4717034\n",
      "Validation loss decreased (inf --> 0.433720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6398687\n",
      "\tspeed: 0.1244s/iter; left time: 987.5048s\n",
      "\titers: 200, epoch: 2 | loss: 0.6453094\n",
      "\tspeed: 0.0314s/iter; left time: 245.7919s\n",
      "\titers: 300, epoch: 2 | loss: 0.5391042\n",
      "\tspeed: 0.0317s/iter; left time: 245.2001s\n",
      "\titers: 400, epoch: 2 | loss: 0.5529380\n",
      "\tspeed: 0.0313s/iter; left time: 239.0921s\n",
      "\titers: 500, epoch: 2 | loss: 0.5247909\n",
      "\tspeed: 0.0321s/iter; left time: 241.6444s\n",
      "\titers: 600, epoch: 2 | loss: 0.5369955\n",
      "\tspeed: 0.0313s/iter; left time: 233.0395s\n",
      "\titers: 700, epoch: 2 | loss: 0.5967123\n",
      "\tspeed: 0.0322s/iter; left time: 236.1179s\n",
      "\titers: 800, epoch: 2 | loss: 0.5144974\n",
      "\tspeed: 0.0312s/iter; left time: 225.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.75s\n",
      "Steps: 893 | Train Loss: 0.5559510 Vali Loss: 0.4287280 Test Loss: 0.4820982\n",
      "Validation loss decreased (0.433720 --> 0.428728).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4278529\n",
      "\tspeed: 0.1257s/iter; left time: 885.3648s\n",
      "\titers: 200, epoch: 3 | loss: 0.5275069\n",
      "\tspeed: 0.0316s/iter; left time: 219.7905s\n",
      "\titers: 300, epoch: 3 | loss: 0.4856922\n",
      "\tspeed: 0.0315s/iter; left time: 215.7468s\n",
      "\titers: 400, epoch: 3 | loss: 0.4997658\n",
      "\tspeed: 0.0323s/iter; left time: 217.6868s\n",
      "\titers: 500, epoch: 3 | loss: 0.5009803\n",
      "\tspeed: 0.0312s/iter; left time: 207.6077s\n",
      "\titers: 600, epoch: 3 | loss: 0.5341697\n",
      "\tspeed: 0.0310s/iter; left time: 203.0264s\n",
      "\titers: 700, epoch: 3 | loss: 0.4221507\n",
      "\tspeed: 0.0320s/iter; left time: 206.0449s\n",
      "\titers: 800, epoch: 3 | loss: 0.5832732\n",
      "\tspeed: 0.0312s/iter; left time: 198.0396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.56s\n",
      "Steps: 893 | Train Loss: 0.5241427 Vali Loss: 0.4048121 Test Loss: 0.4476352\n",
      "Validation loss decreased (0.428728 --> 0.404812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4958416\n",
      "\tspeed: 0.1255s/iter; left time: 771.9298s\n",
      "\titers: 200, epoch: 4 | loss: 0.4999856\n",
      "\tspeed: 0.0315s/iter; left time: 190.3799s\n",
      "\titers: 300, epoch: 4 | loss: 0.5057938\n",
      "\tspeed: 0.0313s/iter; left time: 186.1839s\n",
      "\titers: 400, epoch: 4 | loss: 0.4670918\n",
      "\tspeed: 0.0315s/iter; left time: 184.1373s\n",
      "\titers: 500, epoch: 4 | loss: 0.6183814\n",
      "\tspeed: 0.0316s/iter; left time: 181.9041s\n",
      "\titers: 600, epoch: 4 | loss: 0.4631292\n",
      "\tspeed: 0.0313s/iter; left time: 176.8603s\n",
      "\titers: 700, epoch: 4 | loss: 0.4937069\n",
      "\tspeed: 0.0321s/iter; left time: 178.3477s\n",
      "\titers: 800, epoch: 4 | loss: 0.5554444\n",
      "\tspeed: 0.0314s/iter; left time: 170.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.58s\n",
      "Steps: 893 | Train Loss: 0.5139221 Vali Loss: 0.4354493 Test Loss: 0.4744281\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5021319\n",
      "\tspeed: 0.1264s/iter; left time: 664.4925s\n",
      "\titers: 200, epoch: 5 | loss: 0.4403253\n",
      "\tspeed: 0.0314s/iter; left time: 161.7772s\n",
      "\titers: 300, epoch: 5 | loss: 0.5177681\n",
      "\tspeed: 0.0322s/iter; left time: 162.9241s\n",
      "\titers: 400, epoch: 5 | loss: 0.4587646\n",
      "\tspeed: 0.0325s/iter; left time: 161.1807s\n",
      "\titers: 500, epoch: 5 | loss: 0.5097665\n",
      "\tspeed: 0.0314s/iter; left time: 152.4998s\n",
      "\titers: 600, epoch: 5 | loss: 0.4541710\n",
      "\tspeed: 0.0319s/iter; left time: 151.9291s\n",
      "\titers: 700, epoch: 5 | loss: 0.5660053\n",
      "\tspeed: 0.0323s/iter; left time: 150.3806s\n",
      "\titers: 800, epoch: 5 | loss: 0.4755559\n",
      "\tspeed: 0.0317s/iter; left time: 144.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.80s\n",
      "Steps: 893 | Train Loss: 0.5083974 Vali Loss: 0.4190204 Test Loss: 0.4725757\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4143098\n",
      "\tspeed: 0.1238s/iter; left time: 540.5898s\n",
      "\titers: 200, epoch: 6 | loss: 0.5083456\n",
      "\tspeed: 0.0319s/iter; left time: 136.0709s\n",
      "\titers: 300, epoch: 6 | loss: 0.4344662\n",
      "\tspeed: 0.0319s/iter; left time: 132.7055s\n",
      "\titers: 400, epoch: 6 | loss: 0.4197027\n",
      "\tspeed: 0.0317s/iter; left time: 129.0491s\n",
      "\titers: 500, epoch: 6 | loss: 0.4462408\n",
      "\tspeed: 0.0314s/iter; left time: 124.6646s\n",
      "\titers: 600, epoch: 6 | loss: 0.4646135\n",
      "\tspeed: 0.0314s/iter; left time: 121.2203s\n",
      "\titers: 700, epoch: 6 | loss: 0.4330247\n",
      "\tspeed: 0.0311s/iter; left time: 116.9648s\n",
      "\titers: 800, epoch: 6 | loss: 0.4684691\n",
      "\tspeed: 0.0317s/iter; left time: 116.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.56s\n",
      "Steps: 893 | Train Loss: 0.4796921 Vali Loss: 0.4317868 Test Loss: 0.4954451\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4476352035999298, rmse:0.6690554618835449, mae:0.44015392661094666, rse:0.5295150876045227\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7209547\n",
      "\tspeed: 0.0351s/iter; left time: 309.7420s\n",
      "\titers: 200, epoch: 1 | loss: 0.5681710\n",
      "\tspeed: 0.0308s/iter; left time: 268.5008s\n",
      "\titers: 300, epoch: 1 | loss: 0.5730618\n",
      "\tspeed: 0.0310s/iter; left time: 267.9551s\n",
      "\titers: 400, epoch: 1 | loss: 0.5510901\n",
      "\tspeed: 0.0312s/iter; left time: 266.4246s\n",
      "\titers: 500, epoch: 1 | loss: 0.5910584\n",
      "\tspeed: 0.0306s/iter; left time: 257.8354s\n",
      "\titers: 600, epoch: 1 | loss: 0.5827394\n",
      "\tspeed: 0.0320s/iter; left time: 266.3621s\n",
      "\titers: 700, epoch: 1 | loss: 0.5872463\n",
      "\tspeed: 0.0313s/iter; left time: 257.2663s\n",
      "\titers: 800, epoch: 1 | loss: 0.6149690\n",
      "\tspeed: 0.0315s/iter; left time: 256.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.33s\n",
      "Steps: 893 | Train Loss: 0.6028042 Vali Loss: 0.4291976 Test Loss: 0.4720151\n",
      "Validation loss decreased (inf --> 0.429198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5982184\n",
      "\tspeed: 0.1236s/iter; left time: 981.1310s\n",
      "\titers: 200, epoch: 2 | loss: 0.6220253\n",
      "\tspeed: 0.0305s/iter; left time: 239.0741s\n",
      "\titers: 300, epoch: 2 | loss: 0.5384790\n",
      "\tspeed: 0.0314s/iter; left time: 242.5897s\n",
      "\titers: 400, epoch: 2 | loss: 0.5649377\n",
      "\tspeed: 0.0310s/iter; left time: 237.1137s\n",
      "\titers: 500, epoch: 2 | loss: 0.5155175\n",
      "\tspeed: 0.0309s/iter; left time: 232.6462s\n",
      "\titers: 600, epoch: 2 | loss: 0.5144204\n",
      "\tspeed: 0.0307s/iter; left time: 228.5634s\n",
      "\titers: 700, epoch: 2 | loss: 0.4374761\n",
      "\tspeed: 0.0312s/iter; left time: 228.8485s\n",
      "\titers: 800, epoch: 2 | loss: 0.5402030\n",
      "\tspeed: 0.0323s/iter; left time: 234.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 893 | Train Loss: 0.5564877 Vali Loss: 0.4047059 Test Loss: 0.4470728\n",
      "Validation loss decreased (0.429198 --> 0.404706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4594583\n",
      "\tspeed: 0.1258s/iter; left time: 885.9825s\n",
      "\titers: 200, epoch: 3 | loss: 0.5097250\n",
      "\tspeed: 0.0308s/iter; left time: 213.9676s\n",
      "\titers: 300, epoch: 3 | loss: 0.4779473\n",
      "\tspeed: 0.0311s/iter; left time: 212.6097s\n",
      "\titers: 400, epoch: 3 | loss: 0.4807352\n",
      "\tspeed: 0.0316s/iter; left time: 213.1869s\n",
      "\titers: 500, epoch: 3 | loss: 0.4999452\n",
      "\tspeed: 0.0315s/iter; left time: 209.6272s\n",
      "\titers: 600, epoch: 3 | loss: 0.4971805\n",
      "\tspeed: 0.0312s/iter; left time: 204.3450s\n",
      "\titers: 700, epoch: 3 | loss: 0.4480288\n",
      "\tspeed: 0.0317s/iter; left time: 204.1592s\n",
      "\titers: 800, epoch: 3 | loss: 0.4836207\n",
      "\tspeed: 0.0315s/iter; left time: 199.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.35s\n",
      "Steps: 893 | Train Loss: 0.5232027 Vali Loss: 0.4138152 Test Loss: 0.4506558\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5189600\n",
      "\tspeed: 0.1251s/iter; left time: 769.6491s\n",
      "\titers: 200, epoch: 4 | loss: 0.4675849\n",
      "\tspeed: 0.0310s/iter; left time: 187.8746s\n",
      "\titers: 300, epoch: 4 | loss: 0.4786075\n",
      "\tspeed: 0.0317s/iter; left time: 188.8516s\n",
      "\titers: 400, epoch: 4 | loss: 0.5510435\n",
      "\tspeed: 0.0313s/iter; left time: 183.1879s\n",
      "\titers: 500, epoch: 4 | loss: 0.5418715\n",
      "\tspeed: 0.0309s/iter; left time: 177.8385s\n",
      "\titers: 600, epoch: 4 | loss: 0.5635501\n",
      "\tspeed: 0.0310s/iter; left time: 175.1978s\n",
      "\titers: 700, epoch: 4 | loss: 0.4920141\n",
      "\tspeed: 0.0318s/iter; left time: 176.6435s\n",
      "\titers: 800, epoch: 4 | loss: 0.5535968\n",
      "\tspeed: 0.0316s/iter; left time: 172.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 893 | Train Loss: 0.5202639 Vali Loss: 0.4220220 Test Loss: 0.4567698\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4775448\n",
      "\tspeed: 0.1296s/iter; left time: 681.3702s\n",
      "\titers: 200, epoch: 5 | loss: 0.4947301\n",
      "\tspeed: 0.0312s/iter; left time: 160.8462s\n",
      "\titers: 300, epoch: 5 | loss: 0.4907745\n",
      "\tspeed: 0.0314s/iter; left time: 158.8643s\n",
      "\titers: 400, epoch: 5 | loss: 0.5026156\n",
      "\tspeed: 0.0314s/iter; left time: 155.6005s\n",
      "\titers: 500, epoch: 5 | loss: 0.4048417\n",
      "\tspeed: 0.0307s/iter; left time: 149.1069s\n",
      "\titers: 600, epoch: 5 | loss: 0.4991512\n",
      "\tspeed: 0.0325s/iter; left time: 154.6961s\n",
      "\titers: 700, epoch: 5 | loss: 0.5023703\n",
      "\tspeed: 0.0317s/iter; left time: 147.8478s\n",
      "\titers: 800, epoch: 5 | loss: 0.4935438\n",
      "\tspeed: 0.0309s/iter; left time: 140.9561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.4987596 Vali Loss: 0.4615467 Test Loss: 0.4894193\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4470727741718292, rmse:0.6686350107192993, mae:0.4456162452697754, rse:0.5291823744773865\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8551165\n",
      "\tspeed: 0.0648s/iter; left time: 570.9000s\n",
      "\titers: 200, epoch: 1 | loss: 0.7275238\n",
      "\tspeed: 0.0309s/iter; left time: 269.0381s\n",
      "\titers: 300, epoch: 1 | loss: 0.7499614\n",
      "\tspeed: 0.0315s/iter; left time: 270.8352s\n",
      "\titers: 400, epoch: 1 | loss: 0.6867551\n",
      "\tspeed: 0.0309s/iter; left time: 263.4053s\n",
      "\titers: 500, epoch: 1 | loss: 0.7444054\n",
      "\tspeed: 0.0317s/iter; left time: 266.7848s\n",
      "\titers: 600, epoch: 1 | loss: 0.6919510\n",
      "\tspeed: 0.0317s/iter; left time: 263.8553s\n",
      "\titers: 700, epoch: 1 | loss: 0.7340229\n",
      "\tspeed: 0.0311s/iter; left time: 255.3822s\n",
      "\titers: 800, epoch: 1 | loss: 0.7879623\n",
      "\tspeed: 0.0317s/iter; left time: 257.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.64s\n",
      "Steps: 891 | Train Loss: 0.7488321 Vali Loss: 0.6496287 Test Loss: 0.7595803\n",
      "Validation loss decreased (inf --> 0.649629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7427295\n",
      "\tspeed: 0.1208s/iter; left time: 956.4855s\n",
      "\titers: 200, epoch: 2 | loss: 0.6940724\n",
      "\tspeed: 0.0319s/iter; left time: 249.6257s\n",
      "\titers: 300, epoch: 2 | loss: 0.6690348\n",
      "\tspeed: 0.0310s/iter; left time: 239.6982s\n",
      "\titers: 400, epoch: 2 | loss: 0.7337179\n",
      "\tspeed: 0.0319s/iter; left time: 242.8671s\n",
      "\titers: 500, epoch: 2 | loss: 0.6424186\n",
      "\tspeed: 0.0312s/iter; left time: 234.6206s\n",
      "\titers: 600, epoch: 2 | loss: 0.6271749\n",
      "\tspeed: 0.0319s/iter; left time: 237.0159s\n",
      "\titers: 700, epoch: 2 | loss: 0.6315809\n",
      "\tspeed: 0.0310s/iter; left time: 227.0848s\n",
      "\titers: 800, epoch: 2 | loss: 0.7384393\n",
      "\tspeed: 0.0317s/iter; left time: 229.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 891 | Train Loss: 0.7082598 Vali Loss: 0.6239884 Test Loss: 0.7428920\n",
      "Validation loss decreased (0.649629 --> 0.623988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6441697\n",
      "\tspeed: 0.1235s/iter; left time: 867.9806s\n",
      "\titers: 200, epoch: 3 | loss: 0.6923946\n",
      "\tspeed: 0.0315s/iter; left time: 218.6018s\n",
      "\titers: 300, epoch: 3 | loss: 0.7000110\n",
      "\tspeed: 0.0308s/iter; left time: 210.5785s\n",
      "\titers: 400, epoch: 3 | loss: 0.6698459\n",
      "\tspeed: 0.0320s/iter; left time: 215.1696s\n",
      "\titers: 500, epoch: 3 | loss: 0.6986030\n",
      "\tspeed: 0.0312s/iter; left time: 206.6854s\n",
      "\titers: 600, epoch: 3 | loss: 0.6141424\n",
      "\tspeed: 0.0319s/iter; left time: 208.0199s\n",
      "\titers: 700, epoch: 3 | loss: 0.6633720\n",
      "\tspeed: 0.0320s/iter; left time: 205.6119s\n",
      "\titers: 800, epoch: 3 | loss: 0.6220537\n",
      "\tspeed: 0.0326s/iter; left time: 206.0397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.53s\n",
      "Steps: 891 | Train Loss: 0.6660963 Vali Loss: 0.6843256 Test Loss: 0.8240702\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6505235\n",
      "\tspeed: 0.1202s/iter; left time: 737.9664s\n",
      "\titers: 200, epoch: 4 | loss: 0.6160887\n",
      "\tspeed: 0.0318s/iter; left time: 191.7701s\n",
      "\titers: 300, epoch: 4 | loss: 0.6249479\n",
      "\tspeed: 0.0312s/iter; left time: 185.4266s\n",
      "\titers: 400, epoch: 4 | loss: 0.5798933\n",
      "\tspeed: 0.0323s/iter; left time: 188.3485s\n",
      "\titers: 500, epoch: 4 | loss: 0.6653641\n",
      "\tspeed: 0.0313s/iter; left time: 179.4912s\n",
      "\titers: 600, epoch: 4 | loss: 0.6005571\n",
      "\tspeed: 0.0314s/iter; left time: 177.0213s\n",
      "\titers: 700, epoch: 4 | loss: 0.5836991\n",
      "\tspeed: 0.0311s/iter; left time: 172.4638s\n",
      "\titers: 800, epoch: 4 | loss: 0.5284066\n",
      "\tspeed: 0.0317s/iter; left time: 172.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 891 | Train Loss: 0.5903637 Vali Loss: 0.7355981 Test Loss: 0.9551089\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5572412\n",
      "\tspeed: 0.1203s/iter; left time: 631.2956s\n",
      "\titers: 200, epoch: 5 | loss: 0.5138145\n",
      "\tspeed: 0.0319s/iter; left time: 164.3843s\n",
      "\titers: 300, epoch: 5 | loss: 0.5459602\n",
      "\tspeed: 0.0311s/iter; left time: 157.0917s\n",
      "\titers: 400, epoch: 5 | loss: 0.5314591\n",
      "\tspeed: 0.0322s/iter; left time: 159.0606s\n",
      "\titers: 500, epoch: 5 | loss: 0.4832170\n",
      "\tspeed: 0.0312s/iter; left time: 151.0278s\n",
      "\titers: 600, epoch: 5 | loss: 0.4965318\n",
      "\tspeed: 0.0313s/iter; left time: 148.4642s\n",
      "\titers: 700, epoch: 5 | loss: 0.4626929\n",
      "\tspeed: 0.0313s/iter; left time: 145.2405s\n",
      "\titers: 800, epoch: 5 | loss: 0.4363517\n",
      "\tspeed: 0.0315s/iter; left time: 143.2008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 891 | Train Loss: 0.5032746 Vali Loss: 0.8040149 Test Loss: 0.9901147\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7428922057151794, rmse:0.861911952495575, mae:0.6125141382217407, rse:0.6836023926734924\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7386350\n",
      "\tspeed: 0.0343s/iter; left time: 302.1746s\n",
      "\titers: 200, epoch: 1 | loss: 0.6948522\n",
      "\tspeed: 0.0312s/iter; left time: 272.1980s\n",
      "\titers: 300, epoch: 1 | loss: 0.8089753\n",
      "\tspeed: 0.0312s/iter; left time: 268.5395s\n",
      "\titers: 400, epoch: 1 | loss: 0.8129569\n",
      "\tspeed: 0.0310s/iter; left time: 263.6603s\n",
      "\titers: 500, epoch: 1 | loss: 0.6866592\n",
      "\tspeed: 0.0311s/iter; left time: 261.7534s\n",
      "\titers: 600, epoch: 1 | loss: 0.7793033\n",
      "\tspeed: 0.0313s/iter; left time: 260.2689s\n",
      "\titers: 700, epoch: 1 | loss: 0.7290387\n",
      "\tspeed: 0.0320s/iter; left time: 262.9732s\n",
      "\titers: 800, epoch: 1 | loss: 0.7036978\n",
      "\tspeed: 0.0314s/iter; left time: 254.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 891 | Train Loss: 0.7481921 Vali Loss: 0.6502001 Test Loss: 0.7608920\n",
      "Validation loss decreased (inf --> 0.650200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7197387\n",
      "\tspeed: 0.1225s/iter; left time: 970.3645s\n",
      "\titers: 200, epoch: 2 | loss: 0.6739196\n",
      "\tspeed: 0.0310s/iter; left time: 242.7330s\n",
      "\titers: 300, epoch: 2 | loss: 0.7115756\n",
      "\tspeed: 0.0311s/iter; left time: 240.1334s\n",
      "\titers: 400, epoch: 2 | loss: 0.6979533\n",
      "\tspeed: 0.0309s/iter; left time: 235.3234s\n",
      "\titers: 500, epoch: 2 | loss: 0.6213402\n",
      "\tspeed: 0.0310s/iter; left time: 233.3990s\n",
      "\titers: 600, epoch: 2 | loss: 0.6970428\n",
      "\tspeed: 0.0312s/iter; left time: 231.5359s\n",
      "\titers: 700, epoch: 2 | loss: 0.7448217\n",
      "\tspeed: 0.0312s/iter; left time: 228.4076s\n",
      "\titers: 800, epoch: 2 | loss: 0.6938311\n",
      "\tspeed: 0.0310s/iter; left time: 223.8095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 891 | Train Loss: 0.7085056 Vali Loss: 0.6196545 Test Loss: 0.7808328\n",
      "Validation loss decreased (0.650200 --> 0.619654).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7071263\n",
      "\tspeed: 0.1225s/iter; left time: 860.8250s\n",
      "\titers: 200, epoch: 3 | loss: 0.6279897\n",
      "\tspeed: 0.0309s/iter; left time: 214.3040s\n",
      "\titers: 300, epoch: 3 | loss: 0.6168377\n",
      "\tspeed: 0.0309s/iter; left time: 210.9635s\n",
      "\titers: 400, epoch: 3 | loss: 0.6488326\n",
      "\tspeed: 0.0311s/iter; left time: 209.5330s\n",
      "\titers: 500, epoch: 3 | loss: 0.6204570\n",
      "\tspeed: 0.0311s/iter; left time: 206.2659s\n",
      "\titers: 600, epoch: 3 | loss: 0.6481993\n",
      "\tspeed: 0.0312s/iter; left time: 203.3880s\n",
      "\titers: 700, epoch: 3 | loss: 0.6715887\n",
      "\tspeed: 0.0309s/iter; left time: 198.9761s\n",
      "\titers: 800, epoch: 3 | loss: 0.6255332\n",
      "\tspeed: 0.0308s/iter; left time: 194.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 891 | Train Loss: 0.6568723 Vali Loss: 0.6982144 Test Loss: 0.8748479\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5834135\n",
      "\tspeed: 0.1183s/iter; left time: 726.2662s\n",
      "\titers: 200, epoch: 4 | loss: 0.5909123\n",
      "\tspeed: 0.0310s/iter; left time: 187.4219s\n",
      "\titers: 300, epoch: 4 | loss: 0.5620769\n",
      "\tspeed: 0.0315s/iter; left time: 187.2557s\n",
      "\titers: 400, epoch: 4 | loss: 0.5910230\n",
      "\tspeed: 0.0320s/iter; left time: 187.0761s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391406\n",
      "\tspeed: 0.0311s/iter; left time: 178.6278s\n",
      "\titers: 600, epoch: 4 | loss: 0.5656529\n",
      "\tspeed: 0.0316s/iter; left time: 178.0327s\n",
      "\titers: 700, epoch: 4 | loss: 0.5960336\n",
      "\tspeed: 0.0311s/iter; left time: 172.1415s\n",
      "\titers: 800, epoch: 4 | loss: 0.5181675\n",
      "\tspeed: 0.0313s/iter; left time: 170.0781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.35s\n",
      "Steps: 891 | Train Loss: 0.5783299 Vali Loss: 0.7609456 Test Loss: 0.9216359\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5148483\n",
      "\tspeed: 0.1203s/iter; left time: 631.2459s\n",
      "\titers: 200, epoch: 5 | loss: 0.4840738\n",
      "\tspeed: 0.0312s/iter; left time: 160.3840s\n",
      "\titers: 300, epoch: 5 | loss: 0.4952115\n",
      "\tspeed: 0.0310s/iter; left time: 156.3367s\n",
      "\titers: 400, epoch: 5 | loss: 0.5140916\n",
      "\tspeed: 0.0313s/iter; left time: 154.6576s\n",
      "\titers: 500, epoch: 5 | loss: 0.4592392\n",
      "\tspeed: 0.0313s/iter; left time: 151.5003s\n",
      "\titers: 600, epoch: 5 | loss: 0.4631857\n",
      "\tspeed: 0.0318s/iter; left time: 151.0228s\n",
      "\titers: 700, epoch: 5 | loss: 0.4553634\n",
      "\tspeed: 0.0313s/iter; left time: 145.5672s\n",
      "\titers: 800, epoch: 5 | loss: 0.4650083\n",
      "\tspeed: 0.0316s/iter; left time: 143.7388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.27s\n",
      "Steps: 891 | Train Loss: 0.4927720 Vali Loss: 0.7901865 Test Loss: 1.0063701\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7808329463005066, rmse:0.8836475014686584, mae:0.6238866448402405, rse:0.7008413672447205\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=False, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8664844\n",
      "\tspeed: 0.0627s/iter; left time: 551.6082s\n",
      "\titers: 200, epoch: 1 | loss: 0.7748420\n",
      "\tspeed: 0.0318s/iter; left time: 276.7149s\n",
      "\titers: 300, epoch: 1 | loss: 0.7827786\n",
      "\tspeed: 0.0311s/iter; left time: 267.0268s\n",
      "\titers: 400, epoch: 1 | loss: 0.8379393\n",
      "\tspeed: 0.0325s/iter; left time: 275.8619s\n",
      "\titers: 500, epoch: 1 | loss: 0.8223366\n",
      "\tspeed: 0.0313s/iter; left time: 262.4407s\n",
      "\titers: 600, epoch: 1 | loss: 0.7661328\n",
      "\tspeed: 0.0320s/iter; left time: 265.5354s\n",
      "\titers: 700, epoch: 1 | loss: 0.7546901\n",
      "\tspeed: 0.0317s/iter; left time: 259.9031s\n",
      "\titers: 800, epoch: 1 | loss: 0.7720103\n",
      "\tspeed: 0.0314s/iter; left time: 254.4125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.81s\n",
      "Steps: 889 | Train Loss: 0.7773525 Vali Loss: 0.6789535 Test Loss: 0.8056106\n",
      "Validation loss decreased (inf --> 0.678953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7863541\n",
      "\tspeed: 0.1273s/iter; left time: 1005.9784s\n",
      "\titers: 200, epoch: 2 | loss: 0.7006351\n",
      "\tspeed: 0.0325s/iter; left time: 253.8217s\n",
      "\titers: 300, epoch: 2 | loss: 0.8034087\n",
      "\tspeed: 0.0319s/iter; left time: 245.3718s\n",
      "\titers: 400, epoch: 2 | loss: 0.7269821\n",
      "\tspeed: 0.0325s/iter; left time: 247.1504s\n",
      "\titers: 500, epoch: 2 | loss: 0.7219657\n",
      "\tspeed: 0.0318s/iter; left time: 238.3624s\n",
      "\titers: 600, epoch: 2 | loss: 0.7261241\n",
      "\tspeed: 0.0324s/iter; left time: 239.7191s\n",
      "\titers: 700, epoch: 2 | loss: 0.6683892\n",
      "\tspeed: 0.0325s/iter; left time: 237.6109s\n",
      "\titers: 800, epoch: 2 | loss: 0.7402905\n",
      "\tspeed: 0.0323s/iter; left time: 232.3065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 889 | Train Loss: 0.7352908 Vali Loss: 0.6641684 Test Loss: 0.8142335\n",
      "Validation loss decreased (0.678953 --> 0.664168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7025980\n",
      "\tspeed: 0.1285s/iter; left time: 901.0149s\n",
      "\titers: 200, epoch: 3 | loss: 0.6293545\n",
      "\tspeed: 0.0325s/iter; left time: 224.9107s\n",
      "\titers: 300, epoch: 3 | loss: 0.6693157\n",
      "\tspeed: 0.0316s/iter; left time: 215.0341s\n",
      "\titers: 400, epoch: 3 | loss: 0.7198443\n",
      "\tspeed: 0.0318s/iter; left time: 213.4193s\n",
      "\titers: 500, epoch: 3 | loss: 0.7189937\n",
      "\tspeed: 0.0318s/iter; left time: 210.1895s\n",
      "\titers: 600, epoch: 3 | loss: 0.6458587\n",
      "\tspeed: 0.0325s/iter; left time: 211.5648s\n",
      "\titers: 700, epoch: 3 | loss: 0.6749094\n",
      "\tspeed: 0.0322s/iter; left time: 206.1900s\n",
      "\titers: 800, epoch: 3 | loss: 0.6469948\n",
      "\tspeed: 0.0324s/iter; left time: 204.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.95s\n",
      "Steps: 889 | Train Loss: 0.6639157 Vali Loss: 0.7572297 Test Loss: 1.0168014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5768374\n",
      "\tspeed: 0.1244s/iter; left time: 761.8419s\n",
      "\titers: 200, epoch: 4 | loss: 0.5386745\n",
      "\tspeed: 0.0324s/iter; left time: 195.1184s\n",
      "\titers: 300, epoch: 4 | loss: 0.6037575\n",
      "\tspeed: 0.0317s/iter; left time: 187.6741s\n",
      "\titers: 400, epoch: 4 | loss: 0.5637009\n",
      "\tspeed: 0.0325s/iter; left time: 189.1898s\n",
      "\titers: 500, epoch: 4 | loss: 0.5611549\n",
      "\tspeed: 0.0318s/iter; left time: 181.8663s\n",
      "\titers: 600, epoch: 4 | loss: 0.5001844\n",
      "\tspeed: 0.0323s/iter; left time: 181.8691s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733401\n",
      "\tspeed: 0.0317s/iter; left time: 175.1115s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321149\n",
      "\tspeed: 0.0322s/iter; left time: 174.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.86s\n",
      "Steps: 889 | Train Loss: 0.5621209 Vali Loss: 0.8297581 Test Loss: 1.0995700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4945532\n",
      "\tspeed: 0.1222s/iter; left time: 639.4879s\n",
      "\titers: 200, epoch: 5 | loss: 0.4656978\n",
      "\tspeed: 0.0317s/iter; left time: 162.6200s\n",
      "\titers: 300, epoch: 5 | loss: 0.4696138\n",
      "\tspeed: 0.0318s/iter; left time: 160.3375s\n",
      "\titers: 400, epoch: 5 | loss: 0.4734173\n",
      "\tspeed: 0.0324s/iter; left time: 159.6897s\n",
      "\titers: 500, epoch: 5 | loss: 0.4793583\n",
      "\tspeed: 0.0313s/iter; left time: 151.4147s\n",
      "\titers: 600, epoch: 5 | loss: 0.4472002\n",
      "\tspeed: 0.0321s/iter; left time: 151.9695s\n",
      "\titers: 700, epoch: 5 | loss: 0.4455522\n",
      "\tspeed: 0.0317s/iter; left time: 146.7927s\n",
      "\titers: 800, epoch: 5 | loss: 0.4503470\n",
      "\tspeed: 0.0318s/iter; left time: 144.4218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.59s\n",
      "Steps: 889 | Train Loss: 0.4681812 Vali Loss: 0.8629620 Test Loss: 1.1571960\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8142335414886475, rmse:0.9023488759994507, mae:0.6528554558753967, rse:0.714820146560669\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919581\n",
      "\tspeed: 0.0348s/iter; left time: 305.9101s\n",
      "\titers: 200, epoch: 1 | loss: 0.8252969\n",
      "\tspeed: 0.0319s/iter; left time: 277.2214s\n",
      "\titers: 300, epoch: 1 | loss: 0.8585888\n",
      "\tspeed: 0.0314s/iter; left time: 269.5646s\n",
      "\titers: 400, epoch: 1 | loss: 0.8244462\n",
      "\tspeed: 0.0319s/iter; left time: 270.7022s\n",
      "\titers: 500, epoch: 1 | loss: 0.7751122\n",
      "\tspeed: 0.0315s/iter; left time: 264.2738s\n",
      "\titers: 600, epoch: 1 | loss: 0.6955832\n",
      "\tspeed: 0.0319s/iter; left time: 264.5787s\n",
      "\titers: 700, epoch: 1 | loss: 0.7508373\n",
      "\tspeed: 0.0322s/iter; left time: 264.0141s\n",
      "\titers: 800, epoch: 1 | loss: 0.7120806\n",
      "\tspeed: 0.0318s/iter; left time: 257.0580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.63s\n",
      "Steps: 889 | Train Loss: 0.7785295 Vali Loss: 0.6763564 Test Loss: 0.8040371\n",
      "Validation loss decreased (inf --> 0.676356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7783805\n",
      "\tspeed: 0.1293s/iter; left time: 1022.0571s\n",
      "\titers: 200, epoch: 2 | loss: 0.7515687\n",
      "\tspeed: 0.0317s/iter; left time: 247.4296s\n",
      "\titers: 300, epoch: 2 | loss: 0.7622487\n",
      "\tspeed: 0.0319s/iter; left time: 245.6844s\n",
      "\titers: 400, epoch: 2 | loss: 0.7399257\n",
      "\tspeed: 0.0327s/iter; left time: 248.8870s\n",
      "\titers: 500, epoch: 2 | loss: 0.7407348\n",
      "\tspeed: 0.0316s/iter; left time: 237.3097s\n",
      "\titers: 600, epoch: 2 | loss: 0.7529413\n",
      "\tspeed: 0.0313s/iter; left time: 232.0121s\n",
      "\titers: 700, epoch: 2 | loss: 0.7048910\n",
      "\tspeed: 0.0319s/iter; left time: 233.0779s\n",
      "\titers: 800, epoch: 2 | loss: 0.7002239\n",
      "\tspeed: 0.0314s/iter; left time: 225.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.66s\n",
      "Steps: 889 | Train Loss: 0.7359209 Vali Loss: 0.6813703 Test Loss: 0.8545573\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6593481\n",
      "\tspeed: 0.1222s/iter; left time: 856.8371s\n",
      "\titers: 200, epoch: 3 | loss: 0.6439144\n",
      "\tspeed: 0.0315s/iter; left time: 217.5329s\n",
      "\titers: 300, epoch: 3 | loss: 0.7430762\n",
      "\tspeed: 0.0319s/iter; left time: 217.0483s\n",
      "\titers: 400, epoch: 3 | loss: 0.7178846\n",
      "\tspeed: 0.0315s/iter; left time: 211.5972s\n",
      "\titers: 500, epoch: 3 | loss: 0.6631711\n",
      "\tspeed: 0.0318s/iter; left time: 210.1972s\n",
      "\titers: 600, epoch: 3 | loss: 0.6815755\n",
      "\tspeed: 0.0318s/iter; left time: 207.2213s\n",
      "\titers: 700, epoch: 3 | loss: 0.6479614\n",
      "\tspeed: 0.0315s/iter; left time: 201.9630s\n",
      "\titers: 800, epoch: 3 | loss: 0.6170415\n",
      "\tspeed: 0.0320s/iter; left time: 202.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.65s\n",
      "Steps: 889 | Train Loss: 0.6674439 Vali Loss: 0.7393171 Test Loss: 0.9578838\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6242051\n",
      "\tspeed: 0.1289s/iter; left time: 789.2178s\n",
      "\titers: 200, epoch: 4 | loss: 0.5492404\n",
      "\tspeed: 0.0324s/iter; left time: 195.2559s\n",
      "\titers: 300, epoch: 4 | loss: 0.5889360\n",
      "\tspeed: 0.0321s/iter; left time: 190.1155s\n",
      "\titers: 400, epoch: 4 | loss: 0.5327770\n",
      "\tspeed: 0.0326s/iter; left time: 190.1081s\n",
      "\titers: 500, epoch: 4 | loss: 0.5683498\n",
      "\tspeed: 0.0321s/iter; left time: 183.5004s\n",
      "\titers: 600, epoch: 4 | loss: 0.5250277\n",
      "\tspeed: 0.0324s/iter; left time: 182.0802s\n",
      "\titers: 700, epoch: 4 | loss: 0.5925252\n",
      "\tspeed: 0.0325s/iter; left time: 179.4312s\n",
      "\titers: 800, epoch: 4 | loss: 0.5309951\n",
      "\tspeed: 0.0327s/iter; left time: 177.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 889 | Train Loss: 0.5663641 Vali Loss: 0.8234245 Test Loss: 1.0187939\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8040378093719482, rmse:0.896681547164917, mae:0.645296037197113, rse:0.710330605506897\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4692602\n",
      "\tspeed: 0.0643s/iter; left time: 567.5166s\n",
      "\titers: 200, epoch: 1 | loss: 0.4826890\n",
      "\tspeed: 0.0340s/iter; left time: 296.7482s\n",
      "\titers: 300, epoch: 1 | loss: 0.4208876\n",
      "\tspeed: 0.0319s/iter; left time: 274.9318s\n",
      "\titers: 400, epoch: 1 | loss: 0.4328028\n",
      "\tspeed: 0.0316s/iter; left time: 269.8162s\n",
      "\titers: 500, epoch: 1 | loss: 0.4134938\n",
      "\tspeed: 0.0322s/iter; left time: 271.6427s\n",
      "\titers: 600, epoch: 1 | loss: 0.4544778\n",
      "\tspeed: 0.0319s/iter; left time: 265.8358s\n",
      "\titers: 700, epoch: 1 | loss: 0.4050779\n",
      "\tspeed: 0.0312s/iter; left time: 257.2183s\n",
      "\titers: 800, epoch: 1 | loss: 0.3972898\n",
      "\tspeed: 0.0309s/iter; left time: 251.5567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 893 | Train Loss: 0.4295209 Vali Loss: 0.4416631 Test Loss: 0.4512539\n",
      "Validation loss decreased (inf --> 0.441663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4723760\n",
      "\tspeed: 0.1251s/iter; left time: 992.9101s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526318\n",
      "\tspeed: 0.0317s/iter; left time: 248.4943s\n",
      "\titers: 300, epoch: 2 | loss: 0.3957632\n",
      "\tspeed: 0.0312s/iter; left time: 241.6016s\n",
      "\titers: 400, epoch: 2 | loss: 0.4068731\n",
      "\tspeed: 0.0328s/iter; left time: 250.2863s\n",
      "\titers: 500, epoch: 2 | loss: 0.3810674\n",
      "\tspeed: 0.0311s/iter; left time: 234.3269s\n",
      "\titers: 600, epoch: 2 | loss: 0.3773602\n",
      "\tspeed: 0.0326s/iter; left time: 242.1182s\n",
      "\titers: 700, epoch: 2 | loss: 0.3963671\n",
      "\tspeed: 0.0312s/iter; left time: 229.0499s\n",
      "\titers: 800, epoch: 2 | loss: 0.3412838\n",
      "\tspeed: 0.0318s/iter; left time: 230.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 893 | Train Loss: 0.3958481 Vali Loss: 0.4360829 Test Loss: 0.4510309\n",
      "Validation loss decreased (0.441663 --> 0.436083).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3033213\n",
      "\tspeed: 0.1254s/iter; left time: 883.7646s\n",
      "\titers: 200, epoch: 3 | loss: 0.3558081\n",
      "\tspeed: 0.0310s/iter; left time: 215.4864s\n",
      "\titers: 300, epoch: 3 | loss: 0.3438061\n",
      "\tspeed: 0.0318s/iter; left time: 217.5107s\n",
      "\titers: 400, epoch: 3 | loss: 0.3275199\n",
      "\tspeed: 0.0315s/iter; left time: 212.2071s\n",
      "\titers: 500, epoch: 3 | loss: 0.3249809\n",
      "\tspeed: 0.0317s/iter; left time: 210.5228s\n",
      "\titers: 600, epoch: 3 | loss: 0.3659201\n",
      "\tspeed: 0.0314s/iter; left time: 205.2418s\n",
      "\titers: 700, epoch: 3 | loss: 0.2826349\n",
      "\tspeed: 0.0309s/iter; left time: 199.1220s\n",
      "\titers: 800, epoch: 3 | loss: 0.3769347\n",
      "\tspeed: 0.0315s/iter; left time: 199.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.50s\n",
      "Steps: 893 | Train Loss: 0.3496050 Vali Loss: 0.4151997 Test Loss: 0.4266690\n",
      "Validation loss decreased (0.436083 --> 0.415200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3469096\n",
      "\tspeed: 0.1237s/iter; left time: 761.2428s\n",
      "\titers: 200, epoch: 4 | loss: 0.3214944\n",
      "\tspeed: 0.0313s/iter; left time: 189.6632s\n",
      "\titers: 300, epoch: 4 | loss: 0.3675947\n",
      "\tspeed: 0.0320s/iter; left time: 190.4399s\n",
      "\titers: 400, epoch: 4 | loss: 0.3105823\n",
      "\tspeed: 0.0312s/iter; left time: 182.6113s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273520\n",
      "\tspeed: 0.0322s/iter; left time: 185.0141s\n",
      "\titers: 600, epoch: 4 | loss: 0.3280369\n",
      "\tspeed: 0.0315s/iter; left time: 178.1662s\n",
      "\titers: 700, epoch: 4 | loss: 0.3103571\n",
      "\tspeed: 0.0307s/iter; left time: 170.5252s\n",
      "\titers: 800, epoch: 4 | loss: 0.3762110\n",
      "\tspeed: 0.0312s/iter; left time: 169.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 893 | Train Loss: 0.3415693 Vali Loss: 0.4205004 Test Loss: 0.4308024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3305167\n",
      "\tspeed: 0.1177s/iter; left time: 618.8313s\n",
      "\titers: 200, epoch: 5 | loss: 0.2902519\n",
      "\tspeed: 0.0311s/iter; left time: 160.5745s\n",
      "\titers: 300, epoch: 5 | loss: 0.3372947\n",
      "\tspeed: 0.0318s/iter; left time: 160.7446s\n",
      "\titers: 400, epoch: 5 | loss: 0.3056050\n",
      "\tspeed: 0.0310s/iter; left time: 153.8307s\n",
      "\titers: 500, epoch: 5 | loss: 0.3246832\n",
      "\tspeed: 0.0316s/iter; left time: 153.7059s\n",
      "\titers: 600, epoch: 5 | loss: 0.2964298\n",
      "\tspeed: 0.0307s/iter; left time: 145.9964s\n",
      "\titers: 700, epoch: 5 | loss: 0.3289536\n",
      "\tspeed: 0.0327s/iter; left time: 152.2036s\n",
      "\titers: 800, epoch: 5 | loss: 0.3078716\n",
      "\tspeed: 0.0310s/iter; left time: 141.2425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.56s\n",
      "Steps: 893 | Train Loss: 0.3342783 Vali Loss: 0.4146983 Test Loss: 0.4238309\n",
      "Validation loss decreased (0.415200 --> 0.414698).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2857200\n",
      "\tspeed: 0.1232s/iter; left time: 537.7607s\n",
      "\titers: 200, epoch: 6 | loss: 0.3541664\n",
      "\tspeed: 0.0330s/iter; left time: 140.6900s\n",
      "\titers: 300, epoch: 6 | loss: 0.3079217\n",
      "\tspeed: 0.0313s/iter; left time: 130.2218s\n",
      "\titers: 400, epoch: 6 | loss: 0.2834402\n",
      "\tspeed: 0.0324s/iter; left time: 131.7948s\n",
      "\titers: 500, epoch: 6 | loss: 0.3246792\n",
      "\tspeed: 0.0322s/iter; left time: 127.6369s\n",
      "\titers: 600, epoch: 6 | loss: 0.3336233\n",
      "\tspeed: 0.0312s/iter; left time: 120.6996s\n",
      "\titers: 700, epoch: 6 | loss: 0.2927261\n",
      "\tspeed: 0.0319s/iter; left time: 120.3085s\n",
      "\titers: 800, epoch: 6 | loss: 0.3122388\n",
      "\tspeed: 0.0306s/iter; left time: 112.0636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.72s\n",
      "Steps: 893 | Train Loss: 0.3281333 Vali Loss: 0.4171371 Test Loss: 0.4247621\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3376304\n",
      "\tspeed: 0.1211s/iter; left time: 420.4962s\n",
      "\titers: 200, epoch: 7 | loss: 0.3259957\n",
      "\tspeed: 0.0308s/iter; left time: 103.9742s\n",
      "\titers: 300, epoch: 7 | loss: 0.3266780\n",
      "\tspeed: 0.0314s/iter; left time: 102.6729s\n",
      "\titers: 400, epoch: 7 | loss: 0.3166734\n",
      "\tspeed: 0.0306s/iter; left time: 97.0289s\n",
      "\titers: 500, epoch: 7 | loss: 0.3427626\n",
      "\tspeed: 0.0308s/iter; left time: 94.6246s\n",
      "\titers: 600, epoch: 7 | loss: 0.3274685\n",
      "\tspeed: 0.0312s/iter; left time: 92.6688s\n",
      "\titers: 700, epoch: 7 | loss: 0.2957838\n",
      "\tspeed: 0.0315s/iter; left time: 90.4718s\n",
      "\titers: 800, epoch: 7 | loss: 0.3123882\n",
      "\tspeed: 0.0310s/iter; left time: 85.9485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.09s\n",
      "Steps: 893 | Train Loss: 0.3205336 Vali Loss: 0.4159477 Test Loss: 0.4322074\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3153378\n",
      "\tspeed: 0.1168s/iter; left time: 301.3146s\n",
      "\titers: 200, epoch: 8 | loss: 0.3067007\n",
      "\tspeed: 0.0308s/iter; left time: 76.4936s\n",
      "\titers: 300, epoch: 8 | loss: 0.2802638\n",
      "\tspeed: 0.0314s/iter; left time: 74.6458s\n",
      "\titers: 400, epoch: 8 | loss: 0.3474216\n",
      "\tspeed: 0.0309s/iter; left time: 70.4765s\n",
      "\titers: 500, epoch: 8 | loss: 0.3567826\n",
      "\tspeed: 0.0307s/iter; left time: 66.8678s\n",
      "\titers: 600, epoch: 8 | loss: 0.2638480\n",
      "\tspeed: 0.0321s/iter; left time: 66.8690s\n",
      "\titers: 700, epoch: 8 | loss: 0.3169650\n",
      "\tspeed: 0.0310s/iter; left time: 61.3193s\n",
      "\titers: 800, epoch: 8 | loss: 0.3482744\n",
      "\tspeed: 0.0316s/iter; left time: 59.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.18s\n",
      "Steps: 893 | Train Loss: 0.3131179 Vali Loss: 0.4130378 Test Loss: 0.4307779\n",
      "Validation loss decreased (0.414698 --> 0.413038).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2497387\n",
      "\tspeed: 0.1215s/iter; left time: 204.9973s\n",
      "\titers: 200, epoch: 9 | loss: 0.2682638\n",
      "\tspeed: 0.0312s/iter; left time: 49.4447s\n",
      "\titers: 300, epoch: 9 | loss: 0.3058367\n",
      "\tspeed: 0.0310s/iter; left time: 46.0418s\n",
      "\titers: 400, epoch: 9 | loss: 0.2953742\n",
      "\tspeed: 0.0308s/iter; left time: 42.7077s\n",
      "\titers: 500, epoch: 9 | loss: 0.2881396\n",
      "\tspeed: 0.0315s/iter; left time: 40.5010s\n",
      "\titers: 600, epoch: 9 | loss: 0.2972685\n",
      "\tspeed: 0.0308s/iter; left time: 36.5120s\n",
      "\titers: 700, epoch: 9 | loss: 0.3488926\n",
      "\tspeed: 0.0310s/iter; left time: 33.6854s\n",
      "\titers: 800, epoch: 9 | loss: 0.2915761\n",
      "\tspeed: 0.0313s/iter; left time: 30.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 893 | Train Loss: 0.3013023 Vali Loss: 0.4133577 Test Loss: 0.4378560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.3355217\n",
      "\tspeed: 0.1194s/iter; left time: 94.7763s\n",
      "\titers: 200, epoch: 10 | loss: 0.2714426\n",
      "\tspeed: 0.0316s/iter; left time: 21.9065s\n",
      "\titers: 300, epoch: 10 | loss: 0.2644854\n",
      "\tspeed: 0.0309s/iter; left time: 18.3607s\n",
      "\titers: 400, epoch: 10 | loss: 0.3232498\n",
      "\tspeed: 0.0310s/iter; left time: 15.2990s\n",
      "\titers: 500, epoch: 10 | loss: 0.2707618\n",
      "\tspeed: 0.0318s/iter; left time: 12.5194s\n",
      "\titers: 600, epoch: 10 | loss: 0.2962871\n",
      "\tspeed: 0.0310s/iter; left time: 9.0994s\n",
      "\titers: 700, epoch: 10 | loss: 0.3301148\n",
      "\tspeed: 0.0308s/iter; left time: 5.9682s\n",
      "\titers: 800, epoch: 10 | loss: 0.2883853\n",
      "\tspeed: 0.0317s/iter; left time: 2.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 893 | Train Loss: 0.2927158 Vali Loss: 0.4144575 Test Loss: 0.4384505\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4807750880718231, rmse:0.6933794617652893, mae:0.430777907371521, rse:0.548766016960144\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4772317\n",
      "\tspeed: 0.0355s/iter; left time: 313.3311s\n",
      "\titers: 200, epoch: 1 | loss: 0.4692693\n",
      "\tspeed: 0.0315s/iter; left time: 275.0776s\n",
      "\titers: 300, epoch: 1 | loss: 0.4209013\n",
      "\tspeed: 0.0320s/iter; left time: 275.8852s\n",
      "\titers: 400, epoch: 1 | loss: 0.4363210\n",
      "\tspeed: 0.0321s/iter; left time: 273.7280s\n",
      "\titers: 500, epoch: 1 | loss: 0.3628700\n",
      "\tspeed: 0.0315s/iter; left time: 265.2938s\n",
      "\titers: 600, epoch: 1 | loss: 0.3669860\n",
      "\tspeed: 0.0315s/iter; left time: 262.4845s\n",
      "\titers: 700, epoch: 1 | loss: 0.4072750\n",
      "\tspeed: 0.0309s/iter; left time: 254.4932s\n",
      "\titers: 800, epoch: 1 | loss: 0.3957990\n",
      "\tspeed: 0.0308s/iter; left time: 250.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 893 | Train Loss: 0.4273530 Vali Loss: 0.4435184 Test Loss: 0.4528420\n",
      "Validation loss decreased (inf --> 0.443518).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4409744\n",
      "\tspeed: 0.1217s/iter; left time: 966.2587s\n",
      "\titers: 200, epoch: 2 | loss: 0.4431063\n",
      "\tspeed: 0.0308s/iter; left time: 241.4006s\n",
      "\titers: 300, epoch: 2 | loss: 0.4094855\n",
      "\tspeed: 0.0315s/iter; left time: 243.9499s\n",
      "\titers: 400, epoch: 2 | loss: 0.3431304\n",
      "\tspeed: 0.0315s/iter; left time: 240.5868s\n",
      "\titers: 500, epoch: 2 | loss: 0.3625501\n",
      "\tspeed: 0.0310s/iter; left time: 233.4001s\n",
      "\titers: 600, epoch: 2 | loss: 0.3513249\n",
      "\tspeed: 0.0310s/iter; left time: 230.3857s\n",
      "\titers: 700, epoch: 2 | loss: 0.3615639\n",
      "\tspeed: 0.0308s/iter; left time: 226.3682s\n",
      "\titers: 800, epoch: 2 | loss: 0.3092341\n",
      "\tspeed: 0.0309s/iter; left time: 223.9405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.13s\n",
      "Steps: 893 | Train Loss: 0.3892517 Vali Loss: 0.4184927 Test Loss: 0.4321904\n",
      "Validation loss decreased (0.443518 --> 0.418493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3465152\n",
      "\tspeed: 0.1213s/iter; left time: 854.8936s\n",
      "\titers: 200, epoch: 3 | loss: 0.3315549\n",
      "\tspeed: 0.0307s/iter; left time: 213.4009s\n",
      "\titers: 300, epoch: 3 | loss: 0.3514994\n",
      "\tspeed: 0.0312s/iter; left time: 213.6548s\n",
      "\titers: 400, epoch: 3 | loss: 0.3923259\n",
      "\tspeed: 0.0308s/iter; left time: 207.7771s\n",
      "\titers: 500, epoch: 3 | loss: 0.4310986\n",
      "\tspeed: 0.0316s/iter; left time: 210.1296s\n",
      "\titers: 600, epoch: 3 | loss: 0.3581219\n",
      "\tspeed: 0.0318s/iter; left time: 208.1970s\n",
      "\titers: 700, epoch: 3 | loss: 0.3690543\n",
      "\tspeed: 0.0315s/iter; left time: 203.0564s\n",
      "\titers: 800, epoch: 3 | loss: 0.3258447\n",
      "\tspeed: 0.0320s/iter; left time: 202.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 893 | Train Loss: 0.3471851 Vali Loss: 0.4111527 Test Loss: 0.4207281\n",
      "Validation loss decreased (0.418493 --> 0.411153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3941467\n",
      "\tspeed: 0.1295s/iter; left time: 796.5369s\n",
      "\titers: 200, epoch: 4 | loss: 0.2989146\n",
      "\tspeed: 0.0312s/iter; left time: 188.7493s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161282\n",
      "\tspeed: 0.0315s/iter; left time: 187.6016s\n",
      "\titers: 400, epoch: 4 | loss: 0.3821313\n",
      "\tspeed: 0.0308s/iter; left time: 180.2768s\n",
      "\titers: 500, epoch: 4 | loss: 0.3067269\n",
      "\tspeed: 0.0316s/iter; left time: 181.5926s\n",
      "\titers: 600, epoch: 4 | loss: 0.3505353\n",
      "\tspeed: 0.0320s/iter; left time: 180.6114s\n",
      "\titers: 700, epoch: 4 | loss: 0.3634263\n",
      "\tspeed: 0.0321s/iter; left time: 178.4348s\n",
      "\titers: 800, epoch: 4 | loss: 0.3408167\n",
      "\tspeed: 0.0315s/iter; left time: 171.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 893 | Train Loss: 0.3404690 Vali Loss: 0.4110176 Test Loss: 0.4248865\n",
      "Validation loss decreased (0.411153 --> 0.411018).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3741923\n",
      "\tspeed: 0.1246s/iter; left time: 655.4052s\n",
      "\titers: 200, epoch: 5 | loss: 0.3787712\n",
      "\tspeed: 0.0317s/iter; left time: 163.6757s\n",
      "\titers: 300, epoch: 5 | loss: 0.3627296\n",
      "\tspeed: 0.0314s/iter; left time: 158.7491s\n",
      "\titers: 400, epoch: 5 | loss: 0.3224845\n",
      "\tspeed: 0.0321s/iter; left time: 159.1529s\n",
      "\titers: 500, epoch: 5 | loss: 0.3078940\n",
      "\tspeed: 0.0317s/iter; left time: 154.2343s\n",
      "\titers: 600, epoch: 5 | loss: 0.3362175\n",
      "\tspeed: 0.0316s/iter; left time: 150.3329s\n",
      "\titers: 700, epoch: 5 | loss: 0.3201645\n",
      "\tspeed: 0.0313s/iter; left time: 145.8576s\n",
      "\titers: 800, epoch: 5 | loss: 0.3398321\n",
      "\tspeed: 0.0308s/iter; left time: 140.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 893 | Train Loss: 0.3340832 Vali Loss: 0.4138320 Test Loss: 0.4243123\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3132715\n",
      "\tspeed: 0.1189s/iter; left time: 519.2387s\n",
      "\titers: 200, epoch: 6 | loss: 0.3214878\n",
      "\tspeed: 0.0307s/iter; left time: 131.0504s\n",
      "\titers: 300, epoch: 6 | loss: 0.2599081\n",
      "\tspeed: 0.0324s/iter; left time: 134.9031s\n",
      "\titers: 400, epoch: 6 | loss: 0.3778115\n",
      "\tspeed: 0.0308s/iter; left time: 125.2856s\n",
      "\titers: 500, epoch: 6 | loss: 0.3067705\n",
      "\tspeed: 0.0313s/iter; left time: 124.2566s\n",
      "\titers: 600, epoch: 6 | loss: 0.3270652\n",
      "\tspeed: 0.0313s/iter; left time: 120.9163s\n",
      "\titers: 700, epoch: 6 | loss: 0.3400143\n",
      "\tspeed: 0.0316s/iter; left time: 118.9149s\n",
      "\titers: 800, epoch: 6 | loss: 0.3287427\n",
      "\tspeed: 0.0315s/iter; left time: 115.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 893 | Train Loss: 0.3267248 Vali Loss: 0.4080245 Test Loss: 0.4219659\n",
      "Validation loss decreased (0.411018 --> 0.408024).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3882087\n",
      "\tspeed: 0.1238s/iter; left time: 430.1020s\n",
      "\titers: 200, epoch: 7 | loss: 0.3309156\n",
      "\tspeed: 0.0307s/iter; left time: 103.6135s\n",
      "\titers: 300, epoch: 7 | loss: 0.2970034\n",
      "\tspeed: 0.0308s/iter; left time: 100.6584s\n",
      "\titers: 400, epoch: 7 | loss: 0.2852074\n",
      "\tspeed: 0.0317s/iter; left time: 100.5603s\n",
      "\titers: 500, epoch: 7 | loss: 0.2680917\n",
      "\tspeed: 0.0314s/iter; left time: 96.5282s\n",
      "\titers: 600, epoch: 7 | loss: 0.3089650\n",
      "\tspeed: 0.0314s/iter; left time: 93.2828s\n",
      "\titers: 700, epoch: 7 | loss: 0.3190245\n",
      "\tspeed: 0.0309s/iter; left time: 88.7821s\n",
      "\titers: 800, epoch: 7 | loss: 0.3067529\n",
      "\tspeed: 0.0313s/iter; left time: 86.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.31s\n",
      "Steps: 893 | Train Loss: 0.3202767 Vali Loss: 0.4048426 Test Loss: 0.4236824\n",
      "Validation loss decreased (0.408024 --> 0.404843).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2900766\n",
      "\tspeed: 0.1272s/iter; left time: 328.0726s\n",
      "\titers: 200, epoch: 8 | loss: 0.3137262\n",
      "\tspeed: 0.0326s/iter; left time: 80.8998s\n",
      "\titers: 300, epoch: 8 | loss: 0.2868597\n",
      "\tspeed: 0.0313s/iter; left time: 74.4847s\n",
      "\titers: 400, epoch: 8 | loss: 0.2992349\n",
      "\tspeed: 0.0315s/iter; left time: 71.7242s\n",
      "\titers: 500, epoch: 8 | loss: 0.3163836\n",
      "\tspeed: 0.0317s/iter; left time: 69.1419s\n",
      "\titers: 600, epoch: 8 | loss: 0.2870176\n",
      "\tspeed: 0.0313s/iter; left time: 65.1639s\n",
      "\titers: 700, epoch: 8 | loss: 0.2599227\n",
      "\tspeed: 0.0313s/iter; left time: 62.0551s\n",
      "\titers: 800, epoch: 8 | loss: 0.3581468\n",
      "\tspeed: 0.0314s/iter; left time: 59.0049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.64s\n",
      "Steps: 893 | Train Loss: 0.3141176 Vali Loss: 0.4151950 Test Loss: 0.4343016\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2814345\n",
      "\tspeed: 0.1281s/iter; left time: 216.0775s\n",
      "\titers: 200, epoch: 9 | loss: 0.3211882\n",
      "\tspeed: 0.0318s/iter; left time: 50.4293s\n",
      "\titers: 300, epoch: 9 | loss: 0.2929524\n",
      "\tspeed: 0.0311s/iter; left time: 46.2183s\n",
      "\titers: 400, epoch: 9 | loss: 0.3166829\n",
      "\tspeed: 0.0309s/iter; left time: 42.8863s\n",
      "\titers: 500, epoch: 9 | loss: 0.3306493\n",
      "\tspeed: 0.0314s/iter; left time: 40.4678s\n",
      "\titers: 600, epoch: 9 | loss: 0.2720787\n",
      "\tspeed: 0.0311s/iter; left time: 36.8818s\n",
      "\titers: 700, epoch: 9 | loss: 0.2996348\n",
      "\tspeed: 0.0318s/iter; left time: 34.5674s\n",
      "\titers: 800, epoch: 9 | loss: 0.3032248\n",
      "\tspeed: 0.0323s/iter; left time: 31.8530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.50s\n",
      "Steps: 893 | Train Loss: 0.3076932 Vali Loss: 0.4119829 Test Loss: 0.4308245\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2797729\n",
      "\tspeed: 0.1250s/iter; left time: 99.2768s\n",
      "\titers: 200, epoch: 10 | loss: 0.3107279\n",
      "\tspeed: 0.0320s/iter; left time: 22.1838s\n",
      "\titers: 300, epoch: 10 | loss: 0.2929021\n",
      "\tspeed: 0.0322s/iter; left time: 19.1564s\n",
      "\titers: 400, epoch: 10 | loss: 0.2972355\n",
      "\tspeed: 0.0315s/iter; left time: 15.5572s\n",
      "\titers: 500, epoch: 10 | loss: 0.3222616\n",
      "\tspeed: 0.0315s/iter; left time: 12.4176s\n",
      "\titers: 600, epoch: 10 | loss: 0.3390655\n",
      "\tspeed: 0.0321s/iter; left time: 9.4246s\n",
      "\titers: 700, epoch: 10 | loss: 0.2697753\n",
      "\tspeed: 0.0317s/iter; left time: 6.1405s\n",
      "\titers: 800, epoch: 10 | loss: 0.2926307\n",
      "\tspeed: 0.0313s/iter; left time: 2.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.61s\n",
      "Steps: 893 | Train Loss: 0.2971417 Vali Loss: 0.4108424 Test Loss: 0.4363282\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:0.4558711349964142, rmse:0.6751822829246521, mae:0.42368245124816895, rse:0.5343641042709351\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6369737\n",
      "\tspeed: 0.0625s/iter; left time: 550.6353s\n",
      "\titers: 200, epoch: 1 | loss: 0.5264497\n",
      "\tspeed: 0.0309s/iter; left time: 268.9052s\n",
      "\titers: 300, epoch: 1 | loss: 0.5511164\n",
      "\tspeed: 0.0315s/iter; left time: 271.6315s\n",
      "\titers: 400, epoch: 1 | loss: 0.4838751\n",
      "\tspeed: 0.0305s/iter; left time: 259.8806s\n",
      "\titers: 500, epoch: 1 | loss: 0.5324259\n",
      "\tspeed: 0.0318s/iter; left time: 267.1543s\n",
      "\titers: 600, epoch: 1 | loss: 0.4854627\n",
      "\tspeed: 0.0312s/iter; left time: 259.6425s\n",
      "\titers: 700, epoch: 1 | loss: 0.5239050\n",
      "\tspeed: 0.0317s/iter; left time: 260.1783s\n",
      "\titers: 800, epoch: 1 | loss: 0.5559114\n",
      "\tspeed: 0.0313s/iter; left time: 253.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 891 | Train Loss: 0.5396533 Vali Loss: 0.5698075 Test Loss: 0.6036955\n",
      "Validation loss decreased (inf --> 0.569807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5392140\n",
      "\tspeed: 0.1181s/iter; left time: 935.4416s\n",
      "\titers: 200, epoch: 2 | loss: 0.5315067\n",
      "\tspeed: 0.0313s/iter; left time: 244.5675s\n",
      "\titers: 300, epoch: 2 | loss: 0.4970773\n",
      "\tspeed: 0.0309s/iter; left time: 238.5880s\n",
      "\titers: 400, epoch: 2 | loss: 0.5163004\n",
      "\tspeed: 0.0311s/iter; left time: 237.1817s\n",
      "\titers: 500, epoch: 2 | loss: 0.4707017\n",
      "\tspeed: 0.0310s/iter; left time: 233.4798s\n",
      "\titers: 600, epoch: 2 | loss: 0.4387707\n",
      "\tspeed: 0.0309s/iter; left time: 229.3493s\n",
      "\titers: 700, epoch: 2 | loss: 0.4332939\n",
      "\tspeed: 0.0310s/iter; left time: 226.7725s\n",
      "\titers: 800, epoch: 2 | loss: 0.5253047\n",
      "\tspeed: 0.0314s/iter; left time: 226.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 891 | Train Loss: 0.5085972 Vali Loss: 0.5565106 Test Loss: 0.5942929\n",
      "Validation loss decreased (0.569807 --> 0.556511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4558531\n",
      "\tspeed: 0.1214s/iter; left time: 853.2263s\n",
      "\titers: 200, epoch: 3 | loss: 0.4703476\n",
      "\tspeed: 0.0317s/iter; left time: 219.9606s\n",
      "\titers: 300, epoch: 3 | loss: 0.5083911\n",
      "\tspeed: 0.0311s/iter; left time: 212.5798s\n",
      "\titers: 400, epoch: 3 | loss: 0.4844401\n",
      "\tspeed: 0.0322s/iter; left time: 216.9718s\n",
      "\titers: 500, epoch: 3 | loss: 0.4749599\n",
      "\tspeed: 0.0309s/iter; left time: 205.0257s\n",
      "\titers: 600, epoch: 3 | loss: 0.4395661\n",
      "\tspeed: 0.0314s/iter; left time: 205.1823s\n",
      "\titers: 700, epoch: 3 | loss: 0.4869038\n",
      "\tspeed: 0.0309s/iter; left time: 198.8703s\n",
      "\titers: 800, epoch: 3 | loss: 0.4124657\n",
      "\tspeed: 0.0313s/iter; left time: 198.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 891 | Train Loss: 0.4669132 Vali Loss: 0.5608602 Test Loss: 0.6058698\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4732015\n",
      "\tspeed: 0.1188s/iter; left time: 729.0098s\n",
      "\titers: 200, epoch: 4 | loss: 0.4760290\n",
      "\tspeed: 0.0310s/iter; left time: 187.3144s\n",
      "\titers: 300, epoch: 4 | loss: 0.4733590\n",
      "\tspeed: 0.0316s/iter; left time: 187.8926s\n",
      "\titers: 400, epoch: 4 | loss: 0.4703676\n",
      "\tspeed: 0.0311s/iter; left time: 181.4982s\n",
      "\titers: 500, epoch: 4 | loss: 0.4437554\n",
      "\tspeed: 0.0321s/iter; left time: 184.0743s\n",
      "\titers: 600, epoch: 4 | loss: 0.4576108\n",
      "\tspeed: 0.0312s/iter; left time: 175.9430s\n",
      "\titers: 700, epoch: 4 | loss: 0.4398981\n",
      "\tspeed: 0.0320s/iter; left time: 177.4155s\n",
      "\titers: 800, epoch: 4 | loss: 0.3772960\n",
      "\tspeed: 0.0310s/iter; left time: 168.5752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 891 | Train Loss: 0.4380162 Vali Loss: 0.5808157 Test Loss: 0.6243102\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4276128\n",
      "\tspeed: 0.1212s/iter; left time: 635.9770s\n",
      "\titers: 200, epoch: 5 | loss: 0.4113550\n",
      "\tspeed: 0.0309s/iter; left time: 159.2836s\n",
      "\titers: 300, epoch: 5 | loss: 0.4492574\n",
      "\tspeed: 0.0320s/iter; left time: 161.2970s\n",
      "\titers: 400, epoch: 5 | loss: 0.3822852\n",
      "\tspeed: 0.0311s/iter; left time: 153.8821s\n",
      "\titers: 500, epoch: 5 | loss: 0.3961447\n",
      "\tspeed: 0.0315s/iter; left time: 152.8533s\n",
      "\titers: 600, epoch: 5 | loss: 0.3869801\n",
      "\tspeed: 0.0319s/iter; left time: 151.4772s\n",
      "\titers: 700, epoch: 5 | loss: 0.3441559\n",
      "\tspeed: 0.0315s/iter; left time: 146.2106s\n",
      "\titers: 800, epoch: 5 | loss: 0.3324410\n",
      "\tspeed: 0.0311s/iter; left time: 141.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 891 | Train Loss: 0.3963335 Vali Loss: 0.5885389 Test Loss: 0.6322095\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7753313779830933, rmse:0.8805290460586548, mae:0.5942929983139038, rse:0.6983680129051208\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5565214\n",
      "\tspeed: 0.0337s/iter; left time: 296.9389s\n",
      "\titers: 200, epoch: 1 | loss: 0.5114530\n",
      "\tspeed: 0.0312s/iter; left time: 271.5064s\n",
      "\titers: 300, epoch: 1 | loss: 0.5684246\n",
      "\tspeed: 0.0312s/iter; left time: 268.4284s\n",
      "\titers: 400, epoch: 1 | loss: 0.5877912\n",
      "\tspeed: 0.0326s/iter; left time: 277.6092s\n",
      "\titers: 500, epoch: 1 | loss: 0.4928245\n",
      "\tspeed: 0.0317s/iter; left time: 266.5914s\n",
      "\titers: 600, epoch: 1 | loss: 0.5564559\n",
      "\tspeed: 0.0310s/iter; left time: 257.2990s\n",
      "\titers: 700, epoch: 1 | loss: 0.5013328\n",
      "\tspeed: 0.0324s/iter; left time: 266.0568s\n",
      "\titers: 800, epoch: 1 | loss: 0.4997501\n",
      "\tspeed: 0.0320s/iter; left time: 259.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 891 | Train Loss: 0.5401486 Vali Loss: 0.5690104 Test Loss: 0.6026319\n",
      "Validation loss decreased (inf --> 0.569010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5433310\n",
      "\tspeed: 0.1230s/iter; left time: 974.2568s\n",
      "\titers: 200, epoch: 2 | loss: 0.5072238\n",
      "\tspeed: 0.0318s/iter; left time: 248.4765s\n",
      "\titers: 300, epoch: 2 | loss: 0.5275637\n",
      "\tspeed: 0.0319s/iter; left time: 246.0406s\n",
      "\titers: 400, epoch: 2 | loss: 0.5100987\n",
      "\tspeed: 0.0321s/iter; left time: 244.6204s\n",
      "\titers: 500, epoch: 2 | loss: 0.4528213\n",
      "\tspeed: 0.0316s/iter; left time: 237.8192s\n",
      "\titers: 600, epoch: 2 | loss: 0.4773233\n",
      "\tspeed: 0.0314s/iter; left time: 233.1796s\n",
      "\titers: 700, epoch: 2 | loss: 0.5251233\n",
      "\tspeed: 0.0317s/iter; left time: 232.0115s\n",
      "\titers: 800, epoch: 2 | loss: 0.4828992\n",
      "\tspeed: 0.0317s/iter; left time: 228.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 891 | Train Loss: 0.5107582 Vali Loss: 0.5602374 Test Loss: 0.6012450\n",
      "Validation loss decreased (0.569010 --> 0.560237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4949780\n",
      "\tspeed: 0.1212s/iter; left time: 852.0268s\n",
      "\titers: 200, epoch: 3 | loss: 0.4411833\n",
      "\tspeed: 0.0325s/iter; left time: 224.9337s\n",
      "\titers: 300, epoch: 3 | loss: 0.4278958\n",
      "\tspeed: 0.0322s/iter; left time: 219.6381s\n",
      "\titers: 400, epoch: 3 | loss: 0.4544521\n",
      "\tspeed: 0.0315s/iter; left time: 211.7660s\n",
      "\titers: 500, epoch: 3 | loss: 0.4254411\n",
      "\tspeed: 0.0313s/iter; left time: 207.4760s\n",
      "\titers: 600, epoch: 3 | loss: 0.4486544\n",
      "\tspeed: 0.0317s/iter; left time: 206.7794s\n",
      "\titers: 700, epoch: 3 | loss: 0.5207402\n",
      "\tspeed: 0.0320s/iter; left time: 205.5012s\n",
      "\titers: 800, epoch: 3 | loss: 0.4496346\n",
      "\tspeed: 0.0314s/iter; left time: 198.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 891 | Train Loss: 0.4656656 Vali Loss: 0.5687023 Test Loss: 0.6184984\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4596697\n",
      "\tspeed: 0.1215s/iter; left time: 745.6858s\n",
      "\titers: 200, epoch: 4 | loss: 0.4064750\n",
      "\tspeed: 0.0315s/iter; left time: 190.4779s\n",
      "\titers: 300, epoch: 4 | loss: 0.4302755\n",
      "\tspeed: 0.0317s/iter; left time: 187.9676s\n",
      "\titers: 400, epoch: 4 | loss: 0.4398806\n",
      "\tspeed: 0.0314s/iter; left time: 183.4829s\n",
      "\titers: 500, epoch: 4 | loss: 0.3848476\n",
      "\tspeed: 0.0310s/iter; left time: 177.9201s\n",
      "\titers: 600, epoch: 4 | loss: 0.4336455\n",
      "\tspeed: 0.0319s/iter; left time: 179.9186s\n",
      "\titers: 700, epoch: 4 | loss: 0.4454004\n",
      "\tspeed: 0.0319s/iter; left time: 176.5721s\n",
      "\titers: 800, epoch: 4 | loss: 0.4041622\n",
      "\tspeed: 0.0313s/iter; left time: 170.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 891 | Train Loss: 0.4314818 Vali Loss: 0.5717245 Test Loss: 0.6355796\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3826390\n",
      "\tspeed: 0.1196s/iter; left time: 627.5524s\n",
      "\titers: 200, epoch: 5 | loss: 0.3844303\n",
      "\tspeed: 0.0312s/iter; left time: 160.5922s\n",
      "\titers: 300, epoch: 5 | loss: 0.3899621\n",
      "\tspeed: 0.0315s/iter; left time: 159.1394s\n",
      "\titers: 400, epoch: 5 | loss: 0.3982004\n",
      "\tspeed: 0.0315s/iter; left time: 155.8671s\n",
      "\titers: 500, epoch: 5 | loss: 0.3457469\n",
      "\tspeed: 0.0315s/iter; left time: 152.6729s\n",
      "\titers: 600, epoch: 5 | loss: 0.3690679\n",
      "\tspeed: 0.0312s/iter; left time: 147.8984s\n",
      "\titers: 700, epoch: 5 | loss: 0.3734826\n",
      "\tspeed: 0.0328s/iter; left time: 152.4475s\n",
      "\titers: 800, epoch: 5 | loss: 0.3513436\n",
      "\tspeed: 0.0328s/iter; left time: 149.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.62s\n",
      "Steps: 891 | Train Loss: 0.3899179 Vali Loss: 0.5878887 Test Loss: 0.6547346\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:0.7856805324554443, rmse:0.8863862156867981, mae:0.6012449264526367, rse:0.70301353931427\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454058\n",
      "\tspeed: 0.0642s/iter; left time: 564.7961s\n",
      "\titers: 200, epoch: 1 | loss: 0.5555871\n",
      "\tspeed: 0.0314s/iter; left time: 272.6138s\n",
      "\titers: 300, epoch: 1 | loss: 0.5632789\n",
      "\tspeed: 0.0320s/iter; left time: 274.5247s\n",
      "\titers: 400, epoch: 1 | loss: 0.6170827\n",
      "\tspeed: 0.0318s/iter; left time: 269.8399s\n",
      "\titers: 500, epoch: 1 | loss: 0.5989822\n",
      "\tspeed: 0.0320s/iter; left time: 268.1129s\n",
      "\titers: 600, epoch: 1 | loss: 0.5544778\n",
      "\tspeed: 0.0322s/iter; left time: 266.9050s\n",
      "\titers: 700, epoch: 1 | loss: 0.5398436\n",
      "\tspeed: 0.0320s/iter; left time: 262.4445s\n",
      "\titers: 800, epoch: 1 | loss: 0.5397340\n",
      "\tspeed: 0.0328s/iter; left time: 265.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.11s\n",
      "Steps: 889 | Train Loss: 0.5634604 Vali Loss: 0.5876431 Test Loss: 0.6291971\n",
      "Validation loss decreased (inf --> 0.587643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5788656\n",
      "\tspeed: 0.1225s/iter; left time: 967.8490s\n",
      "\titers: 200, epoch: 2 | loss: 0.5177796\n",
      "\tspeed: 0.0319s/iter; left time: 249.0531s\n",
      "\titers: 300, epoch: 2 | loss: 0.5796047\n",
      "\tspeed: 0.0321s/iter; left time: 247.3917s\n",
      "\titers: 400, epoch: 2 | loss: 0.5203755\n",
      "\tspeed: 0.0322s/iter; left time: 244.4638s\n",
      "\titers: 500, epoch: 2 | loss: 0.5105063\n",
      "\tspeed: 0.0331s/iter; left time: 248.3327s\n",
      "\titers: 600, epoch: 2 | loss: 0.5109118\n",
      "\tspeed: 0.0326s/iter; left time: 241.6281s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622101\n",
      "\tspeed: 0.0322s/iter; left time: 234.8052s\n",
      "\titers: 800, epoch: 2 | loss: 0.5308465\n",
      "\tspeed: 0.0328s/iter; left time: 236.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.00s\n",
      "Steps: 889 | Train Loss: 0.5291454 Vali Loss: 0.5735648 Test Loss: 0.6237272\n",
      "Validation loss decreased (0.587643 --> 0.573565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5009058\n",
      "\tspeed: 0.1257s/iter; left time: 881.7558s\n",
      "\titers: 200, epoch: 3 | loss: 0.4269744\n",
      "\tspeed: 0.0326s/iter; left time: 225.4464s\n",
      "\titers: 300, epoch: 3 | loss: 0.4711000\n",
      "\tspeed: 0.0323s/iter; left time: 220.2523s\n",
      "\titers: 400, epoch: 3 | loss: 0.5427369\n",
      "\tspeed: 0.0331s/iter; left time: 222.1998s\n",
      "\titers: 500, epoch: 3 | loss: 0.5353034\n",
      "\tspeed: 0.0320s/iter; left time: 211.5663s\n",
      "\titers: 600, epoch: 3 | loss: 0.4894514\n",
      "\tspeed: 0.0329s/iter; left time: 214.3849s\n",
      "\titers: 700, epoch: 3 | loss: 0.4871123\n",
      "\tspeed: 0.0325s/iter; left time: 208.5850s\n",
      "\titers: 800, epoch: 3 | loss: 0.4519639\n",
      "\tspeed: 0.0332s/iter; left time: 209.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.40s\n",
      "Steps: 889 | Train Loss: 0.4810101 Vali Loss: 0.5896177 Test Loss: 0.6445822\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4645985\n",
      "\tspeed: 0.1247s/iter; left time: 763.9253s\n",
      "\titers: 200, epoch: 4 | loss: 0.3999841\n",
      "\tspeed: 0.0312s/iter; left time: 188.0624s\n",
      "\titers: 300, epoch: 4 | loss: 0.4893686\n",
      "\tspeed: 0.0319s/iter; left time: 189.1777s\n",
      "\titers: 400, epoch: 4 | loss: 0.4284677\n",
      "\tspeed: 0.0313s/iter; left time: 182.5149s\n",
      "\titers: 500, epoch: 4 | loss: 0.4492616\n",
      "\tspeed: 0.0317s/iter; left time: 181.6782s\n",
      "\titers: 600, epoch: 4 | loss: 0.4024676\n",
      "\tspeed: 0.0314s/iter; left time: 176.7372s\n",
      "\titers: 700, epoch: 4 | loss: 0.4348423\n",
      "\tspeed: 0.0323s/iter; left time: 178.2770s\n",
      "\titers: 800, epoch: 4 | loss: 0.4392750\n",
      "\tspeed: 0.0325s/iter; left time: 176.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 889 | Train Loss: 0.4387718 Vali Loss: 0.6055065 Test Loss: 0.6647702\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3934732\n",
      "\tspeed: 0.1214s/iter; left time: 635.4467s\n",
      "\titers: 200, epoch: 5 | loss: 0.3872448\n",
      "\tspeed: 0.0324s/iter; left time: 166.3032s\n",
      "\titers: 300, epoch: 5 | loss: 0.3816791\n",
      "\tspeed: 0.0329s/iter; left time: 165.6034s\n",
      "\titers: 400, epoch: 5 | loss: 0.4011735\n",
      "\tspeed: 0.0325s/iter; left time: 160.5489s\n",
      "\titers: 500, epoch: 5 | loss: 0.3884066\n",
      "\tspeed: 0.0330s/iter; left time: 159.3459s\n",
      "\titers: 600, epoch: 5 | loss: 0.3754794\n",
      "\tspeed: 0.0324s/iter; left time: 153.3371s\n",
      "\titers: 700, epoch: 5 | loss: 0.3835490\n",
      "\tspeed: 0.0325s/iter; left time: 150.8688s\n",
      "\titers: 800, epoch: 5 | loss: 0.3651342\n",
      "\tspeed: 0.0321s/iter; left time: 145.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.32s\n",
      "Steps: 889 | Train Loss: 0.3857119 Vali Loss: 0.5997841 Test Loss: 0.6688671\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8269767165184021, rmse:0.9093825817108154, mae:0.6237272620201111, rse:0.720392107963562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6608180\n",
      "\tspeed: 0.0355s/iter; left time: 312.0840s\n",
      "\titers: 200, epoch: 1 | loss: 0.5952601\n",
      "\tspeed: 0.0327s/iter; left time: 284.1398s\n",
      "\titers: 300, epoch: 1 | loss: 0.6304548\n",
      "\tspeed: 0.0331s/iter; left time: 284.5506s\n",
      "\titers: 400, epoch: 1 | loss: 0.6052954\n",
      "\tspeed: 0.0325s/iter; left time: 276.1080s\n",
      "\titers: 500, epoch: 1 | loss: 0.5645452\n",
      "\tspeed: 0.0326s/iter; left time: 273.7882s\n",
      "\titers: 600, epoch: 1 | loss: 0.4899762\n",
      "\tspeed: 0.0328s/iter; left time: 271.7122s\n",
      "\titers: 700, epoch: 1 | loss: 0.5379741\n",
      "\tspeed: 0.0325s/iter; left time: 266.4361s\n",
      "\titers: 800, epoch: 1 | loss: 0.5126909\n",
      "\tspeed: 0.0329s/iter; left time: 266.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 889 | Train Loss: 0.5642891 Vali Loss: 0.5859143 Test Loss: 0.6276789\n",
      "Validation loss decreased (inf --> 0.585914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5888051\n",
      "\tspeed: 0.1267s/iter; left time: 1001.3307s\n",
      "\titers: 200, epoch: 2 | loss: 0.5628304\n",
      "\tspeed: 0.0338s/iter; left time: 263.7148s\n",
      "\titers: 300, epoch: 2 | loss: 0.5554127\n",
      "\tspeed: 0.0323s/iter; left time: 248.6057s\n",
      "\titers: 400, epoch: 2 | loss: 0.5313405\n",
      "\tspeed: 0.0327s/iter; left time: 248.7995s\n",
      "\titers: 500, epoch: 2 | loss: 0.5446224\n",
      "\tspeed: 0.0329s/iter; left time: 246.4698s\n",
      "\titers: 600, epoch: 2 | loss: 0.5402369\n",
      "\tspeed: 0.0326s/iter; left time: 241.4352s\n",
      "\titers: 700, epoch: 2 | loss: 0.4923036\n",
      "\tspeed: 0.0325s/iter; left time: 237.6371s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971512\n",
      "\tspeed: 0.0329s/iter; left time: 237.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.48s\n",
      "Steps: 889 | Train Loss: 0.5298607 Vali Loss: 0.5875971 Test Loss: 0.6376969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4780531\n",
      "\tspeed: 0.1282s/iter; left time: 899.3253s\n",
      "\titers: 200, epoch: 3 | loss: 0.4675881\n",
      "\tspeed: 0.0328s/iter; left time: 227.0422s\n",
      "\titers: 300, epoch: 3 | loss: 0.5299440\n",
      "\tspeed: 0.0323s/iter; left time: 220.0075s\n",
      "\titers: 400, epoch: 3 | loss: 0.5300975\n",
      "\tspeed: 0.0326s/iter; left time: 218.5464s\n",
      "\titers: 500, epoch: 3 | loss: 0.4848637\n",
      "\tspeed: 0.0327s/iter; left time: 216.1395s\n",
      "\titers: 600, epoch: 3 | loss: 0.5039218\n",
      "\tspeed: 0.0335s/iter; left time: 218.0693s\n",
      "\titers: 700, epoch: 3 | loss: 0.4659222\n",
      "\tspeed: 0.0328s/iter; left time: 210.1497s\n",
      "\titers: 800, epoch: 3 | loss: 0.4836134\n",
      "\tspeed: 0.0332s/iter; left time: 209.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.45s\n",
      "Steps: 889 | Train Loss: 0.4798462 Vali Loss: 0.6004242 Test Loss: 0.6522380\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4724112\n",
      "\tspeed: 0.1243s/iter; left time: 760.9341s\n",
      "\titers: 200, epoch: 4 | loss: 0.4390196\n",
      "\tspeed: 0.0326s/iter; left time: 196.5578s\n",
      "\titers: 300, epoch: 4 | loss: 0.4227666\n",
      "\tspeed: 0.0324s/iter; left time: 191.6781s\n",
      "\titers: 400, epoch: 4 | loss: 0.3925024\n",
      "\tspeed: 0.0328s/iter; left time: 190.9296s\n",
      "\titers: 500, epoch: 4 | loss: 0.4314044\n",
      "\tspeed: 0.0329s/iter; left time: 188.2347s\n",
      "\titers: 600, epoch: 4 | loss: 0.3973061\n",
      "\tspeed: 0.0333s/iter; left time: 187.1419s\n",
      "\titers: 700, epoch: 4 | loss: 0.4806811\n",
      "\tspeed: 0.0322s/iter; left time: 178.0485s\n",
      "\titers: 800, epoch: 4 | loss: 0.4275246\n",
      "\tspeed: 0.0328s/iter; left time: 178.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.32s\n",
      "Steps: 889 | Train Loss: 0.4332576 Vali Loss: 0.6057205 Test Loss: 0.6672873\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:0.8162832260131836, rmse:0.9034839272499084, mae:0.6276787519454956, rse:0.7157192826271057\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results = []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Join the captured output into a single string\n",
    "            output_str = \"\".join(output)\n",
    "\n",
    "            # Extract metrics for each iteration from the captured output\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, metrics in enumerate(iteration_metrics, start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"MSE: {metrics[0]}, RMSE: {metrics[1]}, MAE: {metrics[2]}, RSE: {metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the patchtst_results list\n",
    "                patchtst_results.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.4417</td>\n",
       "      <td>0.5299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.5309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.6833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.6989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.7137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.7107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4476</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.6836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7808</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8142</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.7148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.5488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4559</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.4237</td>\n",
       "      <td>0.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7753</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>0.6984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.7030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>0.7157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4484  0.6696  0.4417  0.5299\n",
       "              2         24        0.4501  0.6709  0.4477  0.5309\n",
       "              1         96        0.7422  0.8615  0.6124  0.6833\n",
       "              2         96        0.7766  0.8812  0.6240  0.6989\n",
       "              1         168       0.8117  0.9010  0.6470  0.7137\n",
       "              2         168       0.8048  0.8971  0.6461  0.7107\n",
       "RMSE          1         24        0.4476  0.6691  0.4402  0.5295\n",
       "              2         24        0.4471  0.6686  0.4456  0.5292\n",
       "              1         96        0.7429  0.8619  0.6125  0.6836\n",
       "              2         96        0.7808  0.8836  0.6239  0.7008\n",
       "              1         168       0.8142  0.9023  0.6529  0.7148\n",
       "              2         168       0.8040  0.8967  0.6453  0.7103\n",
       "MAE           1         24        0.4808  0.6934  0.4308  0.5488\n",
       "              2         24        0.4559  0.6752  0.4237  0.5344\n",
       "              1         96        0.7753  0.8805  0.5943  0.6984\n",
       "              2         96        0.7857  0.8864  0.6012  0.7030\n",
       "              1         168       0.8270  0.9094  0.6237  0.7204\n",
       "              2         168       0.8163  0.9035  0.6277  0.7157"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name = 'patchtst_loss_functions_results.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df = convert_results_into_df(patchtst_results, path_dir, csv_name)\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MAE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4683</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.5978</td>\n",
       "      <td>0.7007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.8216</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.6257</td>\n",
       "      <td>0.7181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MSE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.4447</td>\n",
       "      <td>0.5304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.8083</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.7122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RMSE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.6688</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>0.6922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.7126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Loss_function Pred_len                                \n",
       "MAE           24        0.4683  0.6843  0.4272  0.5416\n",
       "              96        0.7805  0.8835  0.5978  0.7007\n",
       "              168       0.8216  0.9064  0.6257  0.7181\n",
       "MSE           24        0.4492  0.6702  0.4447  0.5304\n",
       "              96        0.7594  0.8714  0.6182  0.6911\n",
       "              168       0.8083  0.8990  0.6466  0.7122\n",
       "RMSE          24        0.4474  0.6688  0.4429  0.5293\n",
       "              96        0.7619  0.8728  0.6182  0.6922\n",
       "              168       0.8091  0.8995  0.6491  0.7126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_res_scaled = pd.read_csv(os.path.join(path_dir, csv_name))\n",
    "ptst_res_scaled = ptst_res_scaled.groupby(['Loss_function', 'Pred_len']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test for Informer unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8668807\n",
      "\tspeed: 0.2449s/iter; left time: 2194.5979s\n",
      "\titers: 200, epoch: 1 | loss: 0.7329679\n",
      "\tspeed: 0.0407s/iter; left time: 360.2425s\n",
      "\titers: 300, epoch: 1 | loss: 0.5921891\n",
      "\tspeed: 0.0404s/iter; left time: 354.1649s\n",
      "\titers: 400, epoch: 1 | loss: 0.5284466\n",
      "\tspeed: 0.0409s/iter; left time: 354.1457s\n",
      "\titers: 500, epoch: 1 | loss: 0.4583203\n",
      "\tspeed: 0.0413s/iter; left time: 353.8058s\n",
      "\titers: 600, epoch: 1 | loss: 0.4369217\n",
      "\tspeed: 0.0415s/iter; left time: 350.9416s\n",
      "\titers: 700, epoch: 1 | loss: 0.6045229\n",
      "\tspeed: 0.0412s/iter; left time: 344.7556s\n",
      "\titers: 800, epoch: 1 | loss: 0.4428935\n",
      "\tspeed: 0.0406s/iter; left time: 335.3231s\n",
      "\titers: 900, epoch: 1 | loss: 0.3517039\n",
      "\tspeed: 0.0412s/iter; left time: 336.0541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.30s\n",
      "Steps: 906 | Train Loss: 0.5982595 Vali Loss: 0.5633035 Test Loss: 0.6410481\n",
      "Validation loss decreased (inf --> 0.563303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2530900\n",
      "\tspeed: 0.0961s/iter; left time: 774.2057s\n",
      "\titers: 200, epoch: 2 | loss: 0.4280434\n",
      "\tspeed: 0.0404s/iter; left time: 321.4746s\n",
      "\titers: 300, epoch: 2 | loss: 0.2945775\n",
      "\tspeed: 0.0406s/iter; left time: 318.7039s\n",
      "\titers: 400, epoch: 2 | loss: 0.3808749\n",
      "\tspeed: 0.0408s/iter; left time: 316.1860s\n",
      "\titers: 500, epoch: 2 | loss: 0.2412574\n",
      "\tspeed: 0.0401s/iter; left time: 306.6602s\n",
      "\titers: 600, epoch: 2 | loss: 0.2762078\n",
      "\tspeed: 0.0406s/iter; left time: 306.8623s\n",
      "\titers: 700, epoch: 2 | loss: 0.2622375\n",
      "\tspeed: 0.0406s/iter; left time: 302.3864s\n",
      "\titers: 800, epoch: 2 | loss: 0.3842992\n",
      "\tspeed: 0.0408s/iter; left time: 299.9698s\n",
      "\titers: 900, epoch: 2 | loss: 0.2897162\n",
      "\tspeed: 0.0410s/iter; left time: 297.3082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.3337178 Vali Loss: 0.4458787 Test Loss: 0.5076840\n",
      "Validation loss decreased (0.563303 --> 0.445879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3126185\n",
      "\tspeed: 0.0980s/iter; left time: 700.8740s\n",
      "\titers: 200, epoch: 3 | loss: 0.2431651\n",
      "\tspeed: 0.0413s/iter; left time: 290.8490s\n",
      "\titers: 300, epoch: 3 | loss: 0.2869850\n",
      "\tspeed: 0.0412s/iter; left time: 286.5031s\n",
      "\titers: 400, epoch: 3 | loss: 0.2651891\n",
      "\tspeed: 0.0415s/iter; left time: 284.1734s\n",
      "\titers: 500, epoch: 3 | loss: 0.3693432\n",
      "\tspeed: 0.0408s/iter; left time: 275.6540s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180302\n",
      "\tspeed: 0.0409s/iter; left time: 272.0882s\n",
      "\titers: 700, epoch: 3 | loss: 0.2797669\n",
      "\tspeed: 0.0409s/iter; left time: 267.5731s\n",
      "\titers: 800, epoch: 3 | loss: 0.2634023\n",
      "\tspeed: 0.0408s/iter; left time: 263.1222s\n",
      "\titers: 900, epoch: 3 | loss: 0.2757514\n",
      "\tspeed: 0.0412s/iter; left time: 261.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.40s\n",
      "Steps: 906 | Train Loss: 0.2798561 Vali Loss: 0.4500093 Test Loss: 0.4852419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2148001\n",
      "\tspeed: 0.0932s/iter; left time: 582.0182s\n",
      "\titers: 200, epoch: 4 | loss: 0.2167519\n",
      "\tspeed: 0.0414s/iter; left time: 254.4150s\n",
      "\titers: 300, epoch: 4 | loss: 0.2506799\n",
      "\tspeed: 0.0418s/iter; left time: 252.6642s\n",
      "\titers: 400, epoch: 4 | loss: 0.1949622\n",
      "\tspeed: 0.0415s/iter; left time: 246.9020s\n",
      "\titers: 500, epoch: 4 | loss: 0.2937187\n",
      "\tspeed: 0.0418s/iter; left time: 244.1888s\n",
      "\titers: 600, epoch: 4 | loss: 0.2424507\n",
      "\tspeed: 0.0416s/iter; left time: 239.1368s\n",
      "\titers: 700, epoch: 4 | loss: 0.2249872\n",
      "\tspeed: 0.0421s/iter; left time: 237.6401s\n",
      "\titers: 800, epoch: 4 | loss: 0.2772225\n",
      "\tspeed: 0.0415s/iter; left time: 230.1339s\n",
      "\titers: 900, epoch: 4 | loss: 0.2324552\n",
      "\tspeed: 0.0418s/iter; left time: 227.3455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 906 | Train Loss: 0.2384659 Vali Loss: 0.4899858 Test Loss: 0.5276760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1861539\n",
      "\tspeed: 0.0934s/iter; left time: 498.5835s\n",
      "\titers: 200, epoch: 5 | loss: 0.2107085\n",
      "\tspeed: 0.0413s/iter; left time: 216.3375s\n",
      "\titers: 300, epoch: 5 | loss: 0.1716803\n",
      "\tspeed: 0.0407s/iter; left time: 209.2470s\n",
      "\titers: 400, epoch: 5 | loss: 0.2353648\n",
      "\tspeed: 0.0407s/iter; left time: 205.0769s\n",
      "\titers: 500, epoch: 5 | loss: 0.1783587\n",
      "\tspeed: 0.0409s/iter; left time: 201.9028s\n",
      "\titers: 600, epoch: 5 | loss: 0.2087311\n",
      "\tspeed: 0.0406s/iter; left time: 196.3531s\n",
      "\titers: 700, epoch: 5 | loss: 0.1905097\n",
      "\tspeed: 0.0411s/iter; left time: 194.7493s\n",
      "\titers: 800, epoch: 5 | loss: 0.2120116\n",
      "\tspeed: 0.0406s/iter; left time: 188.0318s\n",
      "\titers: 900, epoch: 5 | loss: 0.2095568\n",
      "\tspeed: 0.0409s/iter; left time: 185.7637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.23s\n",
      "Steps: 906 | Train Loss: 0.1973772 Vali Loss: 0.4915508 Test Loss: 0.5555537\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:20262616.0, rmse:4501.4013671875, mae:3016.667236328125, rse:0.22381876409053802\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7432261\n",
      "\tspeed: 0.0457s/iter; left time: 409.6381s\n",
      "\titers: 200, epoch: 1 | loss: 0.6501400\n",
      "\tspeed: 0.0420s/iter; left time: 372.6024s\n",
      "\titers: 300, epoch: 1 | loss: 0.6982846\n",
      "\tspeed: 0.0420s/iter; left time: 368.3785s\n",
      "\titers: 400, epoch: 1 | loss: 0.6108430\n",
      "\tspeed: 0.0420s/iter; left time: 364.0803s\n",
      "\titers: 500, epoch: 1 | loss: 0.5608808\n",
      "\tspeed: 0.0414s/iter; left time: 354.4283s\n",
      "\titers: 600, epoch: 1 | loss: 0.4887934\n",
      "\tspeed: 0.0421s/iter; left time: 356.3337s\n",
      "\titers: 700, epoch: 1 | loss: 0.4168018\n",
      "\tspeed: 0.0419s/iter; left time: 350.5175s\n",
      "\titers: 800, epoch: 1 | loss: 0.5055439\n",
      "\tspeed: 0.0419s/iter; left time: 346.2598s\n",
      "\titers: 900, epoch: 1 | loss: 0.4256987\n",
      "\tspeed: 0.0417s/iter; left time: 340.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 906 | Train Loss: 0.6086861 Vali Loss: 0.5567614 Test Loss: 0.6454746\n",
      "Validation loss decreased (inf --> 0.556761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3540336\n",
      "\tspeed: 0.0971s/iter; left time: 782.0119s\n",
      "\titers: 200, epoch: 2 | loss: 0.3325537\n",
      "\tspeed: 0.0415s/iter; left time: 329.9720s\n",
      "\titers: 300, epoch: 2 | loss: 0.2796101\n",
      "\tspeed: 0.0418s/iter; left time: 328.3857s\n",
      "\titers: 400, epoch: 2 | loss: 0.2513244\n",
      "\tspeed: 0.0419s/iter; left time: 325.1109s\n",
      "\titers: 500, epoch: 2 | loss: 0.3176331\n",
      "\tspeed: 0.0417s/iter; left time: 318.8633s\n",
      "\titers: 600, epoch: 2 | loss: 0.3459046\n",
      "\tspeed: 0.0420s/iter; left time: 317.1639s\n",
      "\titers: 700, epoch: 2 | loss: 0.3034120\n",
      "\tspeed: 0.0416s/iter; left time: 310.4163s\n",
      "\titers: 800, epoch: 2 | loss: 0.2387425\n",
      "\tspeed: 0.0414s/iter; left time: 304.8394s\n",
      "\titers: 900, epoch: 2 | loss: 0.3125600\n",
      "\tspeed: 0.0415s/iter; left time: 301.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.3379571 Vali Loss: 0.4827415 Test Loss: 0.5245702\n",
      "Validation loss decreased (0.556761 --> 0.482742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3740808\n",
      "\tspeed: 0.0979s/iter; left time: 699.6422s\n",
      "\titers: 200, epoch: 3 | loss: 0.2651302\n",
      "\tspeed: 0.0427s/iter; left time: 300.8668s\n",
      "\titers: 300, epoch: 3 | loss: 0.2314308\n",
      "\tspeed: 0.0416s/iter; left time: 288.7815s\n",
      "\titers: 400, epoch: 3 | loss: 0.2778544\n",
      "\tspeed: 0.0425s/iter; left time: 291.1671s\n",
      "\titers: 500, epoch: 3 | loss: 0.2816418\n",
      "\tspeed: 0.0420s/iter; left time: 283.5136s\n",
      "\titers: 600, epoch: 3 | loss: 0.2536219\n",
      "\tspeed: 0.0416s/iter; left time: 276.5544s\n",
      "\titers: 700, epoch: 3 | loss: 0.3004388\n",
      "\tspeed: 0.0419s/iter; left time: 274.3270s\n",
      "\titers: 800, epoch: 3 | loss: 0.3086251\n",
      "\tspeed: 0.0413s/iter; left time: 266.4247s\n",
      "\titers: 900, epoch: 3 | loss: 0.2157228\n",
      "\tspeed: 0.0415s/iter; left time: 263.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 906 | Train Loss: 0.2835519 Vali Loss: 0.4392605 Test Loss: 0.4886339\n",
      "Validation loss decreased (0.482742 --> 0.439261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2430649\n",
      "\tspeed: 0.0974s/iter; left time: 608.2318s\n",
      "\titers: 200, epoch: 4 | loss: 0.2590898\n",
      "\tspeed: 0.0419s/iter; left time: 257.5346s\n",
      "\titers: 300, epoch: 4 | loss: 0.3631294\n",
      "\tspeed: 0.0424s/iter; left time: 256.1453s\n",
      "\titers: 400, epoch: 4 | loss: 0.2209840\n",
      "\tspeed: 0.0417s/iter; left time: 247.6767s\n",
      "\titers: 500, epoch: 4 | loss: 0.2981814\n",
      "\tspeed: 0.0417s/iter; left time: 243.4160s\n",
      "\titers: 600, epoch: 4 | loss: 0.2587925\n",
      "\tspeed: 0.0418s/iter; left time: 240.2489s\n",
      "\titers: 700, epoch: 4 | loss: 0.2709548\n",
      "\tspeed: 0.0415s/iter; left time: 234.3542s\n",
      "\titers: 800, epoch: 4 | loss: 0.1581628\n",
      "\tspeed: 0.0419s/iter; left time: 232.3713s\n",
      "\titers: 900, epoch: 4 | loss: 0.1487662\n",
      "\tspeed: 0.0423s/iter; left time: 230.2583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 906 | Train Loss: 0.2429381 Vali Loss: 0.4431614 Test Loss: 0.4938792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2189480\n",
      "\tspeed: 0.0889s/iter; left time: 474.6399s\n",
      "\titers: 200, epoch: 5 | loss: 0.1875956\n",
      "\tspeed: 0.0415s/iter; left time: 217.3845s\n",
      "\titers: 300, epoch: 5 | loss: 0.1857948\n",
      "\tspeed: 0.0413s/iter; left time: 212.1533s\n",
      "\titers: 400, epoch: 5 | loss: 0.2114488\n",
      "\tspeed: 0.0412s/iter; left time: 207.5048s\n",
      "\titers: 500, epoch: 5 | loss: 0.1357018\n",
      "\tspeed: 0.0410s/iter; left time: 202.2231s\n",
      "\titers: 600, epoch: 5 | loss: 0.2276186\n",
      "\tspeed: 0.0411s/iter; left time: 198.7869s\n",
      "\titers: 700, epoch: 5 | loss: 0.1714303\n",
      "\tspeed: 0.0412s/iter; left time: 195.0124s\n",
      "\titers: 800, epoch: 5 | loss: 0.2150388\n",
      "\tspeed: 0.0408s/iter; left time: 189.3044s\n",
      "\titers: 900, epoch: 5 | loss: 0.1828143\n",
      "\tspeed: 0.0411s/iter; left time: 186.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.99s\n",
      "Steps: 906 | Train Loss: 0.1994748 Vali Loss: 0.4670032 Test Loss: 0.5031238\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1696045\n",
      "\tspeed: 0.0941s/iter; left time: 416.7514s\n",
      "\titers: 200, epoch: 6 | loss: 0.1791843\n",
      "\tspeed: 0.0416s/iter; left time: 180.3737s\n",
      "\titers: 300, epoch: 6 | loss: 0.2508294\n",
      "\tspeed: 0.0414s/iter; left time: 174.9959s\n",
      "\titers: 400, epoch: 6 | loss: 0.1741999\n",
      "\tspeed: 0.0416s/iter; left time: 172.0414s\n",
      "\titers: 500, epoch: 6 | loss: 0.1608908\n",
      "\tspeed: 0.0417s/iter; left time: 168.1116s\n",
      "\titers: 600, epoch: 6 | loss: 0.1402602\n",
      "\tspeed: 0.0414s/iter; left time: 162.8358s\n",
      "\titers: 700, epoch: 6 | loss: 0.1637850\n",
      "\tspeed: 0.0411s/iter; left time: 157.4484s\n",
      "\titers: 800, epoch: 6 | loss: 0.1464395\n",
      "\tspeed: 0.0418s/iter; left time: 155.9371s\n",
      "\titers: 900, epoch: 6 | loss: 0.1418985\n",
      "\tspeed: 0.0419s/iter; left time: 152.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 906 | Train Loss: 0.1654440 Vali Loss: 0.5088816 Test Loss: 0.5175062\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:19436216.0, rmse:4408.65234375, mae:2875.55859375, rse:0.21920709311962128\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0522838\n",
      "\tspeed: 0.0801s/iter; left time: 716.0267s\n",
      "\titers: 200, epoch: 1 | loss: 0.9666416\n",
      "\tspeed: 0.0504s/iter; left time: 445.3423s\n",
      "\titers: 300, epoch: 1 | loss: 0.9245752\n",
      "\tspeed: 0.0502s/iter; left time: 439.0347s\n",
      "\titers: 400, epoch: 1 | loss: 0.7863439\n",
      "\tspeed: 0.0480s/iter; left time: 414.6369s\n",
      "\titers: 500, epoch: 1 | loss: 0.7835494\n",
      "\tspeed: 0.0471s/iter; left time: 402.3890s\n",
      "\titers: 600, epoch: 1 | loss: 0.6639153\n",
      "\tspeed: 0.0473s/iter; left time: 399.0708s\n",
      "\titers: 700, epoch: 1 | loss: 0.6276757\n",
      "\tspeed: 0.0472s/iter; left time: 393.6579s\n",
      "\titers: 800, epoch: 1 | loss: 0.6528488\n",
      "\tspeed: 0.0471s/iter; left time: 388.1032s\n",
      "\titers: 900, epoch: 1 | loss: 0.6513734\n",
      "\tspeed: 0.0470s/iter; left time: 382.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.33s\n",
      "Steps: 904 | Train Loss: 0.8170802 Vali Loss: 0.8335947 Test Loss: 1.0375565\n",
      "Validation loss decreased (inf --> 0.833595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5232227\n",
      "\tspeed: 0.1168s/iter; left time: 939.1134s\n",
      "\titers: 200, epoch: 2 | loss: 0.5794776\n",
      "\tspeed: 0.0474s/iter; left time: 376.1601s\n",
      "\titers: 300, epoch: 2 | loss: 0.5255210\n",
      "\tspeed: 0.0474s/iter; left time: 371.2123s\n",
      "\titers: 400, epoch: 2 | loss: 0.4926725\n",
      "\tspeed: 0.0475s/iter; left time: 367.1997s\n",
      "\titers: 500, epoch: 2 | loss: 0.4981970\n",
      "\tspeed: 0.0473s/iter; left time: 361.5501s\n",
      "\titers: 600, epoch: 2 | loss: 0.5888463\n",
      "\tspeed: 0.0474s/iter; left time: 357.4459s\n",
      "\titers: 700, epoch: 2 | loss: 0.4668635\n",
      "\tspeed: 0.0474s/iter; left time: 352.8247s\n",
      "\titers: 800, epoch: 2 | loss: 0.5131143\n",
      "\tspeed: 0.0475s/iter; left time: 348.5702s\n",
      "\titers: 900, epoch: 2 | loss: 0.4530048\n",
      "\tspeed: 0.0475s/iter; left time: 343.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.5329359 Vali Loss: 0.6914768 Test Loss: 0.8287142\n",
      "Validation loss decreased (0.833595 --> 0.691477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5407680\n",
      "\tspeed: 0.1147s/iter; left time: 817.8818s\n",
      "\titers: 200, epoch: 3 | loss: 0.3946598\n",
      "\tspeed: 0.0473s/iter; left time: 332.6669s\n",
      "\titers: 300, epoch: 3 | loss: 0.3622131\n",
      "\tspeed: 0.0473s/iter; left time: 327.9141s\n",
      "\titers: 400, epoch: 3 | loss: 0.3672664\n",
      "\tspeed: 0.0475s/iter; left time: 324.4194s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548235\n",
      "\tspeed: 0.0475s/iter; left time: 319.5747s\n",
      "\titers: 600, epoch: 3 | loss: 0.4472606\n",
      "\tspeed: 0.0472s/iter; left time: 313.2551s\n",
      "\titers: 700, epoch: 3 | loss: 0.3666580\n",
      "\tspeed: 0.0472s/iter; left time: 308.3322s\n",
      "\titers: 800, epoch: 3 | loss: 0.4022273\n",
      "\tspeed: 0.0473s/iter; left time: 304.0252s\n",
      "\titers: 900, epoch: 3 | loss: 0.4221560\n",
      "\tspeed: 0.0472s/iter; left time: 298.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.4274466 Vali Loss: 0.7251076 Test Loss: 0.8448725\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3476723\n",
      "\tspeed: 0.1110s/iter; left time: 691.4144s\n",
      "\titers: 200, epoch: 4 | loss: 0.3722265\n",
      "\tspeed: 0.0475s/iter; left time: 291.0399s\n",
      "\titers: 300, epoch: 4 | loss: 0.3409472\n",
      "\tspeed: 0.0475s/iter; left time: 286.2834s\n",
      "\titers: 400, epoch: 4 | loss: 0.3054693\n",
      "\tspeed: 0.0475s/iter; left time: 281.7098s\n",
      "\titers: 500, epoch: 4 | loss: 0.4120376\n",
      "\tspeed: 0.0474s/iter; left time: 276.5049s\n",
      "\titers: 600, epoch: 4 | loss: 0.3229454\n",
      "\tspeed: 0.0476s/iter; left time: 272.7034s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860872\n",
      "\tspeed: 0.0474s/iter; left time: 267.0329s\n",
      "\titers: 800, epoch: 4 | loss: 0.3114266\n",
      "\tspeed: 0.0475s/iter; left time: 262.7169s\n",
      "\titers: 900, epoch: 4 | loss: 0.3609830\n",
      "\tspeed: 0.0475s/iter; left time: 257.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.3587939 Vali Loss: 0.7235217 Test Loss: 0.9472639\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992413\n",
      "\tspeed: 0.1117s/iter; left time: 595.0272s\n",
      "\titers: 200, epoch: 5 | loss: 0.3733294\n",
      "\tspeed: 0.0475s/iter; left time: 248.0889s\n",
      "\titers: 300, epoch: 5 | loss: 0.3371202\n",
      "\tspeed: 0.0475s/iter; left time: 243.4205s\n",
      "\titers: 400, epoch: 5 | loss: 0.3143236\n",
      "\tspeed: 0.0475s/iter; left time: 238.7427s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918294\n",
      "\tspeed: 0.0475s/iter; left time: 233.9151s\n",
      "\titers: 600, epoch: 5 | loss: 0.2968202\n",
      "\tspeed: 0.0472s/iter; left time: 227.8241s\n",
      "\titers: 700, epoch: 5 | loss: 0.2790029\n",
      "\tspeed: 0.0472s/iter; left time: 222.8407s\n",
      "\titers: 800, epoch: 5 | loss: 0.2449622\n",
      "\tspeed: 0.0472s/iter; left time: 218.4010s\n",
      "\titers: 900, epoch: 5 | loss: 0.2711503\n",
      "\tspeed: 0.0473s/iter; left time: 213.9157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 904 | Train Loss: 0.2995826 Vali Loss: 0.7070563 Test Loss: 0.9387065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:35706256.0, rmse:5975.47119140625, mae:4163.154296875, rse:0.2975805997848511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9143165\n",
      "\tspeed: 0.0516s/iter; left time: 461.6672s\n",
      "\titers: 200, epoch: 1 | loss: 0.8231269\n",
      "\tspeed: 0.0503s/iter; left time: 444.7269s\n",
      "\titers: 300, epoch: 1 | loss: 0.8590661\n",
      "\tspeed: 0.0504s/iter; left time: 440.8350s\n",
      "\titers: 400, epoch: 1 | loss: 0.8273649\n",
      "\tspeed: 0.0504s/iter; left time: 435.9231s\n",
      "\titers: 500, epoch: 1 | loss: 0.8597592\n",
      "\tspeed: 0.0517s/iter; left time: 441.4624s\n",
      "\titers: 600, epoch: 1 | loss: 0.6699688\n",
      "\tspeed: 0.0528s/iter; left time: 445.6165s\n",
      "\titers: 700, epoch: 1 | loss: 0.9264821\n",
      "\tspeed: 0.0525s/iter; left time: 438.1487s\n",
      "\titers: 800, epoch: 1 | loss: 0.6948530\n",
      "\tspeed: 0.0527s/iter; left time: 434.3824s\n",
      "\titers: 900, epoch: 1 | loss: 0.7380019\n",
      "\tspeed: 0.0527s/iter; left time: 429.1799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.82s\n",
      "Steps: 904 | Train Loss: 0.8259976 Vali Loss: 0.8315275 Test Loss: 1.0468974\n",
      "Validation loss decreased (inf --> 0.831528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6546626\n",
      "\tspeed: 0.1235s/iter; left time: 992.1767s\n",
      "\titers: 200, epoch: 2 | loss: 0.6274150\n",
      "\tspeed: 0.0513s/iter; left time: 407.3020s\n",
      "\titers: 300, epoch: 2 | loss: 0.5482291\n",
      "\tspeed: 0.0529s/iter; left time: 414.5615s\n",
      "\titers: 400, epoch: 2 | loss: 0.4350376\n",
      "\tspeed: 0.0531s/iter; left time: 410.8373s\n",
      "\titers: 500, epoch: 2 | loss: 0.4925019\n",
      "\tspeed: 0.0527s/iter; left time: 402.5600s\n",
      "\titers: 600, epoch: 2 | loss: 0.6154686\n",
      "\tspeed: 0.0528s/iter; left time: 398.0413s\n",
      "\titers: 700, epoch: 2 | loss: 0.5049326\n",
      "\tspeed: 0.0509s/iter; left time: 378.1737s\n",
      "\titers: 800, epoch: 2 | loss: 0.5443966\n",
      "\tspeed: 0.0507s/iter; left time: 371.7652s\n",
      "\titers: 900, epoch: 2 | loss: 0.4095918\n",
      "\tspeed: 0.0506s/iter; left time: 365.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 904 | Train Loss: 0.5347245 Vali Loss: 0.6814697 Test Loss: 0.8716580\n",
      "Validation loss decreased (0.831528 --> 0.681470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4723068\n",
      "\tspeed: 0.1198s/iter; left time: 854.4822s\n",
      "\titers: 200, epoch: 3 | loss: 0.5130894\n",
      "\tspeed: 0.0504s/iter; left time: 354.7114s\n",
      "\titers: 300, epoch: 3 | loss: 0.3773848\n",
      "\tspeed: 0.0503s/iter; left time: 348.4412s\n",
      "\titers: 400, epoch: 3 | loss: 0.3935299\n",
      "\tspeed: 0.0527s/iter; left time: 360.2613s\n",
      "\titers: 500, epoch: 3 | loss: 0.4303985\n",
      "\tspeed: 0.0528s/iter; left time: 355.3135s\n",
      "\titers: 600, epoch: 3 | loss: 0.4050925\n",
      "\tspeed: 0.0505s/iter; left time: 335.0345s\n",
      "\titers: 700, epoch: 3 | loss: 0.4072495\n",
      "\tspeed: 0.0506s/iter; left time: 330.4861s\n",
      "\titers: 800, epoch: 3 | loss: 0.4411655\n",
      "\tspeed: 0.0503s/iter; left time: 323.5867s\n",
      "\titers: 900, epoch: 3 | loss: 0.4036132\n",
      "\tspeed: 0.0504s/iter; left time: 319.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.24s\n",
      "Steps: 904 | Train Loss: 0.4316325 Vali Loss: 0.7312940 Test Loss: 0.8559389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3354936\n",
      "\tspeed: 0.1156s/iter; left time: 720.0006s\n",
      "\titers: 200, epoch: 4 | loss: 0.3472808\n",
      "\tspeed: 0.0504s/iter; left time: 309.1483s\n",
      "\titers: 300, epoch: 4 | loss: 0.3451594\n",
      "\tspeed: 0.0504s/iter; left time: 304.1135s\n",
      "\titers: 400, epoch: 4 | loss: 0.3125092\n",
      "\tspeed: 0.0505s/iter; left time: 299.2103s\n",
      "\titers: 500, epoch: 4 | loss: 0.3426646\n",
      "\tspeed: 0.0486s/iter; left time: 283.0442s\n",
      "\titers: 600, epoch: 4 | loss: 0.3740831\n",
      "\tspeed: 0.0530s/iter; left time: 303.9092s\n",
      "\titers: 700, epoch: 4 | loss: 0.3379540\n",
      "\tspeed: 0.0531s/iter; left time: 298.7864s\n",
      "\titers: 800, epoch: 4 | loss: 0.3604316\n",
      "\tspeed: 0.0505s/iter; left time: 279.1842s\n",
      "\titers: 900, epoch: 4 | loss: 0.3078305\n",
      "\tspeed: 0.0505s/iter; left time: 273.9508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.14s\n",
      "Steps: 904 | Train Loss: 0.3627788 Vali Loss: 0.7563289 Test Loss: 0.9437141\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2672817\n",
      "\tspeed: 0.1153s/iter; left time: 613.7091s\n",
      "\titers: 200, epoch: 5 | loss: 0.3515173\n",
      "\tspeed: 0.0506s/iter; left time: 264.1614s\n",
      "\titers: 300, epoch: 5 | loss: 0.3082839\n",
      "\tspeed: 0.0506s/iter; left time: 259.1705s\n",
      "\titers: 400, epoch: 5 | loss: 0.3019142\n",
      "\tspeed: 0.0505s/iter; left time: 253.5257s\n",
      "\titers: 500, epoch: 5 | loss: 0.3102745\n",
      "\tspeed: 0.0515s/iter; left time: 253.8433s\n",
      "\titers: 600, epoch: 5 | loss: 0.2675474\n",
      "\tspeed: 0.0529s/iter; left time: 255.1877s\n",
      "\titers: 700, epoch: 5 | loss: 0.3005226\n",
      "\tspeed: 0.0518s/iter; left time: 244.9669s\n",
      "\titers: 800, epoch: 5 | loss: 0.3071508\n",
      "\tspeed: 0.0503s/iter; left time: 232.7265s\n",
      "\titers: 900, epoch: 5 | loss: 0.2667807\n",
      "\tspeed: 0.0505s/iter; left time: 228.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.34s\n",
      "Steps: 904 | Train Loss: 0.3004628 Vali Loss: 0.7473243 Test Loss: 0.9708486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:38053568.0, rmse:6168.75732421875, mae:4203.2880859375, rse:0.30720630288124084\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8996492\n",
      "\tspeed: 0.0841s/iter; left time: 750.3963s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759548\n",
      "\tspeed: 0.0541s/iter; left time: 477.1340s\n",
      "\titers: 300, epoch: 1 | loss: 0.8695518\n",
      "\tspeed: 0.0540s/iter; left time: 471.3614s\n",
      "\titers: 400, epoch: 1 | loss: 0.8800810\n",
      "\tspeed: 0.0542s/iter; left time: 467.0353s\n",
      "\titers: 500, epoch: 1 | loss: 0.8453556\n",
      "\tspeed: 0.0542s/iter; left time: 462.0242s\n",
      "\titers: 600, epoch: 1 | loss: 0.8907446\n",
      "\tspeed: 0.0545s/iter; left time: 458.7675s\n",
      "\titers: 700, epoch: 1 | loss: 0.8326300\n",
      "\tspeed: 0.0545s/iter; left time: 453.2269s\n",
      "\titers: 800, epoch: 1 | loss: 0.7673663\n",
      "\tspeed: 0.0545s/iter; left time: 447.9698s\n",
      "\titers: 900, epoch: 1 | loss: 0.8367926\n",
      "\tspeed: 0.0547s/iter; left time: 443.8342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.70s\n",
      "Steps: 902 | Train Loss: 0.8779309 Vali Loss: 0.9823749 Test Loss: 1.2618978\n",
      "Validation loss decreased (inf --> 0.982375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8131427\n",
      "\tspeed: 0.1342s/iter; left time: 1076.1621s\n",
      "\titers: 200, epoch: 2 | loss: 0.7040696\n",
      "\tspeed: 0.0545s/iter; left time: 431.5071s\n",
      "\titers: 300, epoch: 2 | loss: 0.7396861\n",
      "\tspeed: 0.0545s/iter; left time: 426.2390s\n",
      "\titers: 400, epoch: 2 | loss: 0.6244543\n",
      "\tspeed: 0.0544s/iter; left time: 420.2862s\n",
      "\titers: 500, epoch: 2 | loss: 0.6054553\n",
      "\tspeed: 0.0543s/iter; left time: 413.4311s\n",
      "\titers: 600, epoch: 2 | loss: 0.4985499\n",
      "\tspeed: 0.0544s/iter; left time: 409.0553s\n",
      "\titers: 700, epoch: 2 | loss: 0.5293226\n",
      "\tspeed: 0.0543s/iter; left time: 402.7144s\n",
      "\titers: 800, epoch: 2 | loss: 0.6061723\n",
      "\tspeed: 0.0537s/iter; left time: 393.0163s\n",
      "\titers: 900, epoch: 2 | loss: 0.4838333\n",
      "\tspeed: 0.0535s/iter; left time: 386.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.11s\n",
      "Steps: 902 | Train Loss: 0.6046631 Vali Loss: 0.7293260 Test Loss: 0.8842466\n",
      "Validation loss decreased (0.982375 --> 0.729326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5083361\n",
      "\tspeed: 0.1344s/iter; left time: 956.8486s\n",
      "\titers: 200, epoch: 3 | loss: 0.4712097\n",
      "\tspeed: 0.0538s/iter; left time: 377.8476s\n",
      "\titers: 300, epoch: 3 | loss: 0.4754631\n",
      "\tspeed: 0.0537s/iter; left time: 371.5486s\n",
      "\titers: 400, epoch: 3 | loss: 0.5324599\n",
      "\tspeed: 0.0537s/iter; left time: 365.7506s\n",
      "\titers: 500, epoch: 3 | loss: 0.4271317\n",
      "\tspeed: 0.0536s/iter; left time: 359.9554s\n",
      "\titers: 600, epoch: 3 | loss: 0.4579096\n",
      "\tspeed: 0.0536s/iter; left time: 354.7526s\n",
      "\titers: 700, epoch: 3 | loss: 0.4870133\n",
      "\tspeed: 0.0537s/iter; left time: 349.8731s\n",
      "\titers: 800, epoch: 3 | loss: 0.4459608\n",
      "\tspeed: 0.0536s/iter; left time: 343.7922s\n",
      "\titers: 900, epoch: 3 | loss: 0.4197437\n",
      "\tspeed: 0.0536s/iter; left time: 338.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.4552675 Vali Loss: 0.7132370 Test Loss: 0.9254080\n",
      "Validation loss decreased (0.729326 --> 0.713237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3725089\n",
      "\tspeed: 0.1328s/iter; left time: 825.5429s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399079\n",
      "\tspeed: 0.0538s/iter; left time: 329.1249s\n",
      "\titers: 300, epoch: 4 | loss: 0.4262986\n",
      "\tspeed: 0.0537s/iter; left time: 322.9572s\n",
      "\titers: 400, epoch: 4 | loss: 0.3951728\n",
      "\tspeed: 0.0538s/iter; left time: 318.0749s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273083\n",
      "\tspeed: 0.0538s/iter; left time: 312.6107s\n",
      "\titers: 600, epoch: 4 | loss: 0.3536602\n",
      "\tspeed: 0.0539s/iter; left time: 308.0397s\n",
      "\titers: 700, epoch: 4 | loss: 0.3747369\n",
      "\tspeed: 0.0537s/iter; left time: 301.7435s\n",
      "\titers: 800, epoch: 4 | loss: 0.3719158\n",
      "\tspeed: 0.0538s/iter; left time: 296.4321s\n",
      "\titers: 900, epoch: 4 | loss: 0.3601287\n",
      "\tspeed: 0.0537s/iter; left time: 290.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.3793745 Vali Loss: 0.7713831 Test Loss: 0.9924561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3638352\n",
      "\tspeed: 0.1299s/iter; left time: 690.0304s\n",
      "\titers: 200, epoch: 5 | loss: 0.3390375\n",
      "\tspeed: 0.0535s/iter; left time: 278.7309s\n",
      "\titers: 300, epoch: 5 | loss: 0.3258272\n",
      "\tspeed: 0.0536s/iter; left time: 273.9789s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470738\n",
      "\tspeed: 0.0536s/iter; left time: 268.5060s\n",
      "\titers: 500, epoch: 5 | loss: 0.2690118\n",
      "\tspeed: 0.0536s/iter; left time: 263.2747s\n",
      "\titers: 600, epoch: 5 | loss: 0.3021259\n",
      "\tspeed: 0.0536s/iter; left time: 257.8962s\n",
      "\titers: 700, epoch: 5 | loss: 0.3265553\n",
      "\tspeed: 0.0535s/iter; left time: 251.9163s\n",
      "\titers: 800, epoch: 5 | loss: 0.2861528\n",
      "\tspeed: 0.0535s/iter; left time: 246.8863s\n",
      "\titers: 900, epoch: 5 | loss: 0.2557895\n",
      "\tspeed: 0.0535s/iter; left time: 241.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.3167043 Vali Loss: 0.7697710 Test Loss: 0.9987172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2949107\n",
      "\tspeed: 0.1300s/iter; left time: 573.6183s\n",
      "\titers: 200, epoch: 6 | loss: 0.3065024\n",
      "\tspeed: 0.0545s/iter; left time: 234.9501s\n",
      "\titers: 300, epoch: 6 | loss: 0.2583741\n",
      "\tspeed: 0.0544s/iter; left time: 229.2113s\n",
      "\titers: 400, epoch: 6 | loss: 0.3096471\n",
      "\tspeed: 0.0546s/iter; left time: 224.3012s\n",
      "\titers: 500, epoch: 6 | loss: 0.2568293\n",
      "\tspeed: 0.0544s/iter; left time: 218.3045s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391598\n",
      "\tspeed: 0.0545s/iter; left time: 213.3099s\n",
      "\titers: 700, epoch: 6 | loss: 0.2993651\n",
      "\tspeed: 0.0544s/iter; left time: 207.3554s\n",
      "\titers: 800, epoch: 6 | loss: 0.2426711\n",
      "\tspeed: 0.0544s/iter; left time: 201.9766s\n",
      "\titers: 900, epoch: 6 | loss: 0.2972760\n",
      "\tspeed: 0.0545s/iter; left time: 196.8851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.31s\n",
      "Steps: 902 | Train Loss: 0.2691092 Vali Loss: 0.8078781 Test Loss: 1.0506176\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:41039112.0, rmse:6406.177734375, mae:4328.85498046875, rse:0.3191865384578705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0736581\n",
      "\tspeed: 0.0560s/iter; left time: 499.6946s\n",
      "\titers: 200, epoch: 1 | loss: 0.8831307\n",
      "\tspeed: 0.0546s/iter; left time: 481.5929s\n",
      "\titers: 300, epoch: 1 | loss: 0.8966042\n",
      "\tspeed: 0.0544s/iter; left time: 474.5739s\n",
      "\titers: 400, epoch: 1 | loss: 0.7405317\n",
      "\tspeed: 0.0543s/iter; left time: 468.2059s\n",
      "\titers: 500, epoch: 1 | loss: 0.9314477\n",
      "\tspeed: 0.0546s/iter; left time: 465.4200s\n",
      "\titers: 600, epoch: 1 | loss: 0.7962927\n",
      "\tspeed: 0.0543s/iter; left time: 456.8548s\n",
      "\titers: 700, epoch: 1 | loss: 0.7819531\n",
      "\tspeed: 0.0547s/iter; left time: 455.0447s\n",
      "\titers: 800, epoch: 1 | loss: 0.7549212\n",
      "\tspeed: 0.0545s/iter; left time: 447.7655s\n",
      "\titers: 900, epoch: 1 | loss: 0.7729616\n",
      "\tspeed: 0.0540s/iter; left time: 438.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.33s\n",
      "Steps: 902 | Train Loss: 0.8827498 Vali Loss: 0.9831725 Test Loss: 1.2678595\n",
      "Validation loss decreased (inf --> 0.983173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6917587\n",
      "\tspeed: 0.1369s/iter; left time: 1097.6157s\n",
      "\titers: 200, epoch: 2 | loss: 0.6385450\n",
      "\tspeed: 0.0537s/iter; left time: 424.8557s\n",
      "\titers: 300, epoch: 2 | loss: 0.6272208\n",
      "\tspeed: 0.0537s/iter; left time: 419.9171s\n",
      "\titers: 400, epoch: 2 | loss: 0.5154302\n",
      "\tspeed: 0.0535s/iter; left time: 412.7117s\n",
      "\titers: 500, epoch: 2 | loss: 0.5767449\n",
      "\tspeed: 0.0536s/iter; left time: 408.5784s\n",
      "\titers: 600, epoch: 2 | loss: 0.5526741\n",
      "\tspeed: 0.0538s/iter; left time: 404.5274s\n",
      "\titers: 700, epoch: 2 | loss: 0.5340019\n",
      "\tspeed: 0.0538s/iter; left time: 399.3843s\n",
      "\titers: 800, epoch: 2 | loss: 0.4381602\n",
      "\tspeed: 0.0538s/iter; left time: 393.7361s\n",
      "\titers: 900, epoch: 2 | loss: 0.4901657\n",
      "\tspeed: 0.0537s/iter; left time: 387.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.6127766 Vali Loss: 0.7626251 Test Loss: 0.8730339\n",
      "Validation loss decreased (0.983173 --> 0.762625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4595468\n",
      "\tspeed: 0.1338s/iter; left time: 952.2436s\n",
      "\titers: 200, epoch: 3 | loss: 0.5015832\n",
      "\tspeed: 0.0538s/iter; left time: 377.5282s\n",
      "\titers: 300, epoch: 3 | loss: 0.5812056\n",
      "\tspeed: 0.0537s/iter; left time: 371.5321s\n",
      "\titers: 400, epoch: 3 | loss: 0.4741263\n",
      "\tspeed: 0.0538s/iter; left time: 366.8960s\n",
      "\titers: 500, epoch: 3 | loss: 0.4783198\n",
      "\tspeed: 0.0541s/iter; left time: 363.7189s\n",
      "\titers: 600, epoch: 3 | loss: 0.4453655\n",
      "\tspeed: 0.0545s/iter; left time: 360.3728s\n",
      "\titers: 700, epoch: 3 | loss: 0.4122199\n",
      "\tspeed: 0.0543s/iter; left time: 353.8732s\n",
      "\titers: 800, epoch: 3 | loss: 0.3615236\n",
      "\tspeed: 0.0537s/iter; left time: 344.8459s\n",
      "\titers: 900, epoch: 3 | loss: 0.4355072\n",
      "\tspeed: 0.0537s/iter; left time: 339.1334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.87s\n",
      "Steps: 902 | Train Loss: 0.4525444 Vali Loss: 0.7806315 Test Loss: 0.9514728\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4056771\n",
      "\tspeed: 0.1313s/iter; left time: 815.8269s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399343\n",
      "\tspeed: 0.0537s/iter; left time: 328.4439s\n",
      "\titers: 300, epoch: 4 | loss: 0.3804121\n",
      "\tspeed: 0.0537s/iter; left time: 323.1142s\n",
      "\titers: 400, epoch: 4 | loss: 0.3706331\n",
      "\tspeed: 0.0538s/iter; left time: 318.3533s\n",
      "\titers: 500, epoch: 4 | loss: 0.3810227\n",
      "\tspeed: 0.0539s/iter; left time: 313.2999s\n",
      "\titers: 600, epoch: 4 | loss: 0.3974872\n",
      "\tspeed: 0.0538s/iter; left time: 307.2977s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429693\n",
      "\tspeed: 0.0536s/iter; left time: 301.1952s\n",
      "\titers: 800, epoch: 4 | loss: 0.3861212\n",
      "\tspeed: 0.0537s/iter; left time: 296.1659s\n",
      "\titers: 900, epoch: 4 | loss: 0.3614337\n",
      "\tspeed: 0.0537s/iter; left time: 290.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.3713848 Vali Loss: 0.7981377 Test Loss: 0.9633971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2858317\n",
      "\tspeed: 0.1308s/iter; left time: 694.6781s\n",
      "\titers: 200, epoch: 5 | loss: 0.3296789\n",
      "\tspeed: 0.0539s/iter; left time: 280.8013s\n",
      "\titers: 300, epoch: 5 | loss: 0.3004401\n",
      "\tspeed: 0.0537s/iter; left time: 274.3695s\n",
      "\titers: 400, epoch: 5 | loss: 0.3365834\n",
      "\tspeed: 0.0541s/iter; left time: 271.3776s\n",
      "\titers: 500, epoch: 5 | loss: 0.3448044\n",
      "\tspeed: 0.0539s/iter; left time: 264.9474s\n",
      "\titers: 600, epoch: 5 | loss: 0.2779492\n",
      "\tspeed: 0.0536s/iter; left time: 258.2024s\n",
      "\titers: 700, epoch: 5 | loss: 0.2858480\n",
      "\tspeed: 0.0537s/iter; left time: 253.0254s\n",
      "\titers: 800, epoch: 5 | loss: 0.2892428\n",
      "\tspeed: 0.0537s/iter; left time: 247.5195s\n",
      "\titers: 900, epoch: 5 | loss: 0.2999575\n",
      "\tspeed: 0.0535s/iter; left time: 241.5851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.3065489 Vali Loss: 0.8347104 Test Loss: 1.0182045\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:37693112.0, rmse:6139.4716796875, mae:4274.00537109375, rse:0.30589795112609863\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9276407\n",
      "\tspeed: 0.0757s/iter; left time: 678.2660s\n",
      "\titers: 200, epoch: 1 | loss: 0.8493971\n",
      "\tspeed: 0.0414s/iter; left time: 366.8928s\n",
      "\titers: 300, epoch: 1 | loss: 0.7614538\n",
      "\tspeed: 0.0417s/iter; left time: 364.9957s\n",
      "\titers: 400, epoch: 1 | loss: 0.7148305\n",
      "\tspeed: 0.0415s/iter; left time: 359.2575s\n",
      "\titers: 500, epoch: 1 | loss: 0.6615688\n",
      "\tspeed: 0.0417s/iter; left time: 357.3229s\n",
      "\titers: 600, epoch: 1 | loss: 0.6439044\n",
      "\tspeed: 0.0412s/iter; left time: 349.0103s\n",
      "\titers: 700, epoch: 1 | loss: 0.7704166\n",
      "\tspeed: 0.0408s/iter; left time: 340.7394s\n",
      "\titers: 800, epoch: 1 | loss: 0.6550638\n",
      "\tspeed: 0.0414s/iter; left time: 342.2192s\n",
      "\titers: 900, epoch: 1 | loss: 0.5864573\n",
      "\tspeed: 0.0410s/iter; left time: 334.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 906 | Train Loss: 0.7567487 Vali Loss: 0.5543883 Test Loss: 0.6288404\n",
      "Validation loss decreased (inf --> 0.554388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4949431\n",
      "\tspeed: 0.1002s/iter; left time: 807.3155s\n",
      "\titers: 200, epoch: 2 | loss: 0.6551993\n",
      "\tspeed: 0.0412s/iter; left time: 327.5392s\n",
      "\titers: 300, epoch: 2 | loss: 0.5400851\n",
      "\tspeed: 0.0415s/iter; left time: 325.8201s\n",
      "\titers: 400, epoch: 2 | loss: 0.6192174\n",
      "\tspeed: 0.0409s/iter; left time: 316.7934s\n",
      "\titers: 500, epoch: 2 | loss: 0.4943135\n",
      "\tspeed: 0.0415s/iter; left time: 317.4239s\n",
      "\titers: 600, epoch: 2 | loss: 0.5266612\n",
      "\tspeed: 0.0411s/iter; left time: 310.1542s\n",
      "\titers: 700, epoch: 2 | loss: 0.5126165\n",
      "\tspeed: 0.0410s/iter; left time: 305.9084s\n",
      "\titers: 800, epoch: 2 | loss: 0.6232010\n",
      "\tspeed: 0.0409s/iter; left time: 301.0122s\n",
      "\titers: 900, epoch: 2 | loss: 0.5411612\n",
      "\tspeed: 0.0407s/iter; left time: 295.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.46s\n",
      "Steps: 906 | Train Loss: 0.5740920 Vali Loss: 0.4399104 Test Loss: 0.5069085\n",
      "Validation loss decreased (0.554388 --> 0.439910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5629239\n",
      "\tspeed: 0.0973s/iter; left time: 695.5544s\n",
      "\titers: 200, epoch: 3 | loss: 0.4941055\n",
      "\tspeed: 0.0409s/iter; left time: 288.4643s\n",
      "\titers: 300, epoch: 3 | loss: 0.5275605\n",
      "\tspeed: 0.0409s/iter; left time: 283.9152s\n",
      "\titers: 400, epoch: 3 | loss: 0.5161560\n",
      "\tspeed: 0.0414s/iter; left time: 283.4299s\n",
      "\titers: 500, epoch: 3 | loss: 0.5798593\n",
      "\tspeed: 0.0451s/iter; left time: 304.6658s\n",
      "\titers: 600, epoch: 3 | loss: 0.5651723\n",
      "\tspeed: 0.0449s/iter; left time: 298.7615s\n",
      "\titers: 700, epoch: 3 | loss: 0.5228499\n",
      "\tspeed: 0.0450s/iter; left time: 294.5282s\n",
      "\titers: 800, epoch: 3 | loss: 0.5283095\n",
      "\tspeed: 0.0449s/iter; left time: 289.3854s\n",
      "\titers: 900, epoch: 3 | loss: 0.5182760\n",
      "\tspeed: 0.0450s/iter; left time: 286.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.42s\n",
      "Steps: 906 | Train Loss: 0.5248068 Vali Loss: 0.4539682 Test Loss: 0.4925095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4896143\n",
      "\tspeed: 0.0962s/iter; left time: 600.5804s\n",
      "\titers: 200, epoch: 4 | loss: 0.4587334\n",
      "\tspeed: 0.0417s/iter; left time: 256.3405s\n",
      "\titers: 300, epoch: 4 | loss: 0.4971539\n",
      "\tspeed: 0.0419s/iter; left time: 252.9689s\n",
      "\titers: 400, epoch: 4 | loss: 0.4374260\n",
      "\tspeed: 0.0416s/iter; left time: 247.1535s\n",
      "\titers: 500, epoch: 4 | loss: 0.5398332\n",
      "\tspeed: 0.0421s/iter; left time: 246.1577s\n",
      "\titers: 600, epoch: 4 | loss: 0.5343698\n",
      "\tspeed: 0.0421s/iter; left time: 241.5014s\n",
      "\titers: 700, epoch: 4 | loss: 0.4609941\n",
      "\tspeed: 0.0408s/iter; left time: 230.4575s\n",
      "\titers: 800, epoch: 4 | loss: 0.5253209\n",
      "\tspeed: 0.0412s/iter; left time: 228.5134s\n",
      "\titers: 900, epoch: 4 | loss: 0.4564810\n",
      "\tspeed: 0.0413s/iter; left time: 224.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.4849790 Vali Loss: 0.4594938 Test Loss: 0.5241997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4823216\n",
      "\tspeed: 0.0963s/iter; left time: 514.1201s\n",
      "\titers: 200, epoch: 5 | loss: 0.4644124\n",
      "\tspeed: 0.0420s/iter; left time: 219.9127s\n",
      "\titers: 300, epoch: 5 | loss: 0.4214824\n",
      "\tspeed: 0.0417s/iter; left time: 213.9667s\n",
      "\titers: 400, epoch: 5 | loss: 0.4996223\n",
      "\tspeed: 0.0422s/iter; left time: 212.3340s\n",
      "\titers: 500, epoch: 5 | loss: 0.4287166\n",
      "\tspeed: 0.0418s/iter; left time: 206.3609s\n",
      "\titers: 600, epoch: 5 | loss: 0.4123247\n",
      "\tspeed: 0.0417s/iter; left time: 201.5653s\n",
      "\titers: 700, epoch: 5 | loss: 0.4194843\n",
      "\tspeed: 0.0412s/iter; left time: 195.3309s\n",
      "\titers: 800, epoch: 5 | loss: 0.4636900\n",
      "\tspeed: 0.0414s/iter; left time: 192.1173s\n",
      "\titers: 900, epoch: 5 | loss: 0.4432615\n",
      "\tspeed: 0.0416s/iter; left time: 188.8808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 906 | Train Loss: 0.4400303 Vali Loss: 0.4821237 Test Loss: 0.5637830\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:20156686.0, rmse:4489.61962890625, mae:2999.142578125, rse:0.2232329547405243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8588779\n",
      "\tspeed: 0.0436s/iter; left time: 390.4637s\n",
      "\titers: 200, epoch: 1 | loss: 0.7982945\n",
      "\tspeed: 0.0436s/iter; left time: 386.2265s\n",
      "\titers: 300, epoch: 1 | loss: 0.8250256\n",
      "\tspeed: 0.0451s/iter; left time: 394.8142s\n",
      "\titers: 400, epoch: 1 | loss: 0.7691973\n",
      "\tspeed: 0.0421s/iter; left time: 364.8814s\n",
      "\titers: 500, epoch: 1 | loss: 0.7309195\n",
      "\tspeed: 0.0419s/iter; left time: 358.5713s\n",
      "\titers: 600, epoch: 1 | loss: 0.6879429\n",
      "\tspeed: 0.0420s/iter; left time: 355.6810s\n",
      "\titers: 700, epoch: 1 | loss: 0.6365433\n",
      "\tspeed: 0.0421s/iter; left time: 352.2279s\n",
      "\titers: 800, epoch: 1 | loss: 0.7065768\n",
      "\tspeed: 0.0424s/iter; left time: 350.1286s\n",
      "\titers: 900, epoch: 1 | loss: 0.6446868\n",
      "\tspeed: 0.0423s/iter; left time: 345.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 906 | Train Loss: 0.7622878 Vali Loss: 0.5469300 Test Loss: 0.6323155\n",
      "Validation loss decreased (inf --> 0.546930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5923141\n",
      "\tspeed: 0.0989s/iter; left time: 796.2743s\n",
      "\titers: 200, epoch: 2 | loss: 0.5748015\n",
      "\tspeed: 0.0419s/iter; left time: 333.4026s\n",
      "\titers: 300, epoch: 2 | loss: 0.5269984\n",
      "\tspeed: 0.0419s/iter; left time: 329.0490s\n",
      "\titers: 400, epoch: 2 | loss: 0.5026063\n",
      "\tspeed: 0.0415s/iter; left time: 321.7275s\n",
      "\titers: 500, epoch: 2 | loss: 0.5611269\n",
      "\tspeed: 0.0416s/iter; left time: 318.2837s\n",
      "\titers: 600, epoch: 2 | loss: 0.5893219\n",
      "\tspeed: 0.0414s/iter; left time: 312.6318s\n",
      "\titers: 700, epoch: 2 | loss: 0.5543723\n",
      "\tspeed: 0.0409s/iter; left time: 304.7035s\n",
      "\titers: 800, epoch: 2 | loss: 0.4901477\n",
      "\tspeed: 0.0412s/iter; left time: 302.7216s\n",
      "\titers: 900, epoch: 2 | loss: 0.5559916\n",
      "\tspeed: 0.0408s/iter; left time: 296.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.5776560 Vali Loss: 0.4851062 Test Loss: 0.5314170\n",
      "Validation loss decreased (0.546930 --> 0.485106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6048454\n",
      "\tspeed: 0.0852s/iter; left time: 609.3212s\n",
      "\titers: 200, epoch: 3 | loss: 0.5126129\n",
      "\tspeed: 0.0283s/iter; left time: 199.7834s\n",
      "\titers: 300, epoch: 3 | loss: 0.4772909\n",
      "\tspeed: 0.0284s/iter; left time: 197.1216s\n",
      "\titers: 400, epoch: 3 | loss: 0.5289421\n",
      "\tspeed: 0.0283s/iter; left time: 193.9530s\n",
      "\titers: 500, epoch: 3 | loss: 0.5147277\n",
      "\tspeed: 0.0283s/iter; left time: 191.1642s\n",
      "\titers: 600, epoch: 3 | loss: 0.5077899\n",
      "\tspeed: 0.0283s/iter; left time: 188.2461s\n",
      "\titers: 700, epoch: 3 | loss: 0.5518087\n",
      "\tspeed: 0.0283s/iter; left time: 185.5900s\n",
      "\titers: 800, epoch: 3 | loss: 0.5423992\n",
      "\tspeed: 0.0283s/iter; left time: 182.5899s\n",
      "\titers: 900, epoch: 3 | loss: 0.4665054\n",
      "\tspeed: 0.0283s/iter; left time: 179.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.92s\n",
      "Steps: 906 | Train Loss: 0.5296453 Vali Loss: 0.4397265 Test Loss: 0.4830378\n",
      "Validation loss decreased (0.485106 --> 0.439726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4773476\n",
      "\tspeed: 0.0979s/iter; left time: 611.3075s\n",
      "\titers: 200, epoch: 4 | loss: 0.5036800\n",
      "\tspeed: 0.0398s/iter; left time: 244.6981s\n",
      "\titers: 300, epoch: 4 | loss: 0.6146199\n",
      "\tspeed: 0.0421s/iter; left time: 254.5834s\n",
      "\titers: 400, epoch: 4 | loss: 0.4577895\n",
      "\tspeed: 0.0424s/iter; left time: 251.7237s\n",
      "\titers: 500, epoch: 4 | loss: 0.5661929\n",
      "\tspeed: 0.0421s/iter; left time: 245.9545s\n",
      "\titers: 600, epoch: 4 | loss: 0.5100247\n",
      "\tspeed: 0.0420s/iter; left time: 241.4254s\n",
      "\titers: 700, epoch: 4 | loss: 0.4980476\n",
      "\tspeed: 0.0418s/iter; left time: 235.6703s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978939\n",
      "\tspeed: 0.0415s/iter; left time: 230.0816s\n",
      "\titers: 900, epoch: 4 | loss: 0.3861069\n",
      "\tspeed: 0.0416s/iter; left time: 226.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 906 | Train Loss: 0.4899198 Vali Loss: 0.4603651 Test Loss: 0.5041409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4936487\n",
      "\tspeed: 0.0965s/iter; left time: 515.0918s\n",
      "\titers: 200, epoch: 5 | loss: 0.4334660\n",
      "\tspeed: 0.0412s/iter; left time: 215.6197s\n",
      "\titers: 300, epoch: 5 | loss: 0.4235884\n",
      "\tspeed: 0.0422s/iter; left time: 216.5946s\n",
      "\titers: 400, epoch: 5 | loss: 0.4626411\n",
      "\tspeed: 0.0423s/iter; left time: 212.9521s\n",
      "\titers: 500, epoch: 5 | loss: 0.3728518\n",
      "\tspeed: 0.0423s/iter; left time: 208.9653s\n",
      "\titers: 600, epoch: 5 | loss: 0.4660599\n",
      "\tspeed: 0.0427s/iter; left time: 206.4414s\n",
      "\titers: 700, epoch: 5 | loss: 0.4180226\n",
      "\tspeed: 0.0424s/iter; left time: 200.8397s\n",
      "\titers: 800, epoch: 5 | loss: 0.4556598\n",
      "\tspeed: 0.0425s/iter; left time: 196.9624s\n",
      "\titers: 900, epoch: 5 | loss: 0.4162793\n",
      "\tspeed: 0.0423s/iter; left time: 191.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 906 | Train Loss: 0.4432991 Vali Loss: 0.4867482 Test Loss: 0.5200544\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3990616\n",
      "\tspeed: 0.0954s/iter; left time: 422.7948s\n",
      "\titers: 200, epoch: 6 | loss: 0.4005626\n",
      "\tspeed: 0.0416s/iter; left time: 180.2355s\n",
      "\titers: 300, epoch: 6 | loss: 0.4957956\n",
      "\tspeed: 0.0422s/iter; left time: 178.3781s\n",
      "\titers: 400, epoch: 6 | loss: 0.4094400\n",
      "\tspeed: 0.0418s/iter; left time: 172.6916s\n",
      "\titers: 500, epoch: 6 | loss: 0.3923487\n",
      "\tspeed: 0.0423s/iter; left time: 170.6079s\n",
      "\titers: 600, epoch: 6 | loss: 0.3940423\n",
      "\tspeed: 0.0428s/iter; left time: 168.2335s\n",
      "\titers: 700, epoch: 6 | loss: 0.3931371\n",
      "\tspeed: 0.0455s/iter; left time: 174.5014s\n",
      "\titers: 800, epoch: 6 | loss: 0.3574754\n",
      "\tspeed: 0.0443s/iter; left time: 165.1868s\n",
      "\titers: 900, epoch: 6 | loss: 0.3599356\n",
      "\tspeed: 0.0422s/iter; left time: 153.2047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 906 | Train Loss: 0.4004315 Vali Loss: 0.5209612 Test Loss: 0.5491917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:19259186.0, rmse:4388.52880859375, mae:2873.763671875, rse:0.2182064950466156\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0252380\n",
      "\tspeed: 0.0804s/iter; left time: 718.6038s\n",
      "\titers: 200, epoch: 1 | loss: 0.9821252\n",
      "\tspeed: 0.0473s/iter; left time: 418.3235s\n",
      "\titers: 300, epoch: 1 | loss: 0.9594889\n",
      "\tspeed: 0.0473s/iter; left time: 413.5021s\n",
      "\titers: 400, epoch: 1 | loss: 0.8844653\n",
      "\tspeed: 0.0475s/iter; left time: 410.1857s\n",
      "\titers: 500, epoch: 1 | loss: 0.8824679\n",
      "\tspeed: 0.0473s/iter; left time: 403.5627s\n",
      "\titers: 600, epoch: 1 | loss: 0.8055439\n",
      "\tspeed: 0.0473s/iter; left time: 398.9660s\n",
      "\titers: 700, epoch: 1 | loss: 0.7853126\n",
      "\tspeed: 0.0474s/iter; left time: 394.9504s\n",
      "\titers: 800, epoch: 1 | loss: 0.8030834\n",
      "\tspeed: 0.0472s/iter; left time: 388.9499s\n",
      "\titers: 900, epoch: 1 | loss: 0.8041261\n",
      "\tspeed: 0.0472s/iter; left time: 384.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.77s\n",
      "Steps: 904 | Train Loss: 0.8981916 Vali Loss: 0.8284516 Test Loss: 1.0307974\n",
      "Validation loss decreased (inf --> 0.828452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7219144\n",
      "\tspeed: 0.1161s/iter; left time: 933.2057s\n",
      "\titers: 200, epoch: 2 | loss: 0.7597279\n",
      "\tspeed: 0.0473s/iter; left time: 375.5679s\n",
      "\titers: 300, epoch: 2 | loss: 0.7219747\n",
      "\tspeed: 0.0473s/iter; left time: 370.9652s\n",
      "\titers: 400, epoch: 2 | loss: 0.6980771\n",
      "\tspeed: 0.0474s/iter; left time: 366.7596s\n",
      "\titers: 500, epoch: 2 | loss: 0.6995429\n",
      "\tspeed: 0.0475s/iter; left time: 362.4922s\n",
      "\titers: 600, epoch: 2 | loss: 0.7647797\n",
      "\tspeed: 0.0473s/iter; left time: 356.5068s\n",
      "\titers: 700, epoch: 2 | loss: 0.6916636\n",
      "\tspeed: 0.0474s/iter; left time: 352.2363s\n",
      "\titers: 800, epoch: 2 | loss: 0.7342687\n",
      "\tspeed: 0.0473s/iter; left time: 347.3650s\n",
      "\titers: 900, epoch: 2 | loss: 0.6819095\n",
      "\tspeed: 0.0472s/iter; left time: 341.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.7261729 Vali Loss: 0.6847084 Test Loss: 0.8025894\n",
      "Validation loss decreased (0.828452 --> 0.684708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7336022\n",
      "\tspeed: 0.1170s/iter; left time: 834.9038s\n",
      "\titers: 200, epoch: 3 | loss: 0.6408885\n",
      "\tspeed: 0.0476s/iter; left time: 335.0265s\n",
      "\titers: 300, epoch: 3 | loss: 0.6044647\n",
      "\tspeed: 0.0475s/iter; left time: 329.5931s\n",
      "\titers: 400, epoch: 3 | loss: 0.6270521\n",
      "\tspeed: 0.0477s/iter; left time: 325.7077s\n",
      "\titers: 500, epoch: 3 | loss: 0.6593441\n",
      "\tspeed: 0.0477s/iter; left time: 320.9628s\n",
      "\titers: 600, epoch: 3 | loss: 0.6727517\n",
      "\tspeed: 0.0476s/iter; left time: 315.8295s\n",
      "\titers: 700, epoch: 3 | loss: 0.6100384\n",
      "\tspeed: 0.0474s/iter; left time: 309.8342s\n",
      "\titers: 800, epoch: 3 | loss: 0.6660968\n",
      "\tspeed: 0.0476s/iter; left time: 306.0772s\n",
      "\titers: 900, epoch: 3 | loss: 0.6544979\n",
      "\tspeed: 0.0477s/iter; left time: 301.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.6540388 Vali Loss: 0.6982146 Test Loss: 0.8181267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5878187\n",
      "\tspeed: 0.1141s/iter; left time: 710.7130s\n",
      "\titers: 200, epoch: 4 | loss: 0.5915712\n",
      "\tspeed: 0.0478s/iter; left time: 292.7560s\n",
      "\titers: 300, epoch: 4 | loss: 0.5916324\n",
      "\tspeed: 0.0477s/iter; left time: 287.6630s\n",
      "\titers: 400, epoch: 4 | loss: 0.5480406\n",
      "\tspeed: 0.0476s/iter; left time: 282.4779s\n",
      "\titers: 500, epoch: 4 | loss: 0.6060248\n",
      "\tspeed: 0.0475s/iter; left time: 277.1158s\n",
      "\titers: 600, epoch: 4 | loss: 0.5727869\n",
      "\tspeed: 0.0476s/iter; left time: 272.5974s\n",
      "\titers: 700, epoch: 4 | loss: 0.6088339\n",
      "\tspeed: 0.0477s/iter; left time: 268.3468s\n",
      "\titers: 800, epoch: 4 | loss: 0.5749963\n",
      "\tspeed: 0.0475s/iter; left time: 262.6967s\n",
      "\titers: 900, epoch: 4 | loss: 0.5974422\n",
      "\tspeed: 0.0474s/iter; left time: 257.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.5986204 Vali Loss: 0.7151270 Test Loss: 0.9077851\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5486233\n",
      "\tspeed: 0.1122s/iter; left time: 597.6500s\n",
      "\titers: 200, epoch: 5 | loss: 0.6009266\n",
      "\tspeed: 0.0474s/iter; left time: 247.9076s\n",
      "\titers: 300, epoch: 5 | loss: 0.5961829\n",
      "\tspeed: 0.0473s/iter; left time: 242.2497s\n",
      "\titers: 400, epoch: 5 | loss: 0.5412604\n",
      "\tspeed: 0.0472s/iter; left time: 237.2861s\n",
      "\titers: 500, epoch: 5 | loss: 0.5200085\n",
      "\tspeed: 0.0473s/iter; left time: 232.8035s\n",
      "\titers: 600, epoch: 5 | loss: 0.5370143\n",
      "\tspeed: 0.0473s/iter; left time: 228.0368s\n",
      "\titers: 700, epoch: 5 | loss: 0.5396135\n",
      "\tspeed: 0.0473s/iter; left time: 223.4067s\n",
      "\titers: 800, epoch: 5 | loss: 0.4846662\n",
      "\tspeed: 0.0472s/iter; left time: 218.4918s\n",
      "\titers: 900, epoch: 5 | loss: 0.5213868\n",
      "\tspeed: 0.0474s/iter; left time: 214.4804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.97s\n",
      "Steps: 904 | Train Loss: 0.5498217 Vali Loss: 0.7051411 Test Loss: 0.8774026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:34543984.0, rmse:5877.4130859375, mae:4100.0751953125, rse:0.2926972508430481\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9545566\n",
      "\tspeed: 0.0517s/iter; left time: 462.5331s\n",
      "\titers: 200, epoch: 1 | loss: 0.9046481\n",
      "\tspeed: 0.0502s/iter; left time: 443.8647s\n",
      "\titers: 300, epoch: 1 | loss: 0.9244955\n",
      "\tspeed: 0.0504s/iter; left time: 440.1747s\n",
      "\titers: 400, epoch: 1 | loss: 0.9064289\n",
      "\tspeed: 0.0492s/iter; left time: 425.1655s\n",
      "\titers: 500, epoch: 1 | loss: 0.9243618\n",
      "\tspeed: 0.0478s/iter; left time: 408.4232s\n",
      "\titers: 600, epoch: 1 | loss: 0.8122278\n",
      "\tspeed: 0.0480s/iter; left time: 405.2706s\n",
      "\titers: 700, epoch: 1 | loss: 0.9583504\n",
      "\tspeed: 0.0479s/iter; left time: 399.8818s\n",
      "\titers: 800, epoch: 1 | loss: 0.8278310\n",
      "\tspeed: 0.0479s/iter; left time: 394.7133s\n",
      "\titers: 900, epoch: 1 | loss: 0.8535752\n",
      "\tspeed: 0.0478s/iter; left time: 388.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.36s\n",
      "Steps: 904 | Train Loss: 0.9020157 Vali Loss: 0.8226253 Test Loss: 1.0339608\n",
      "Validation loss decreased (inf --> 0.822625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8071152\n",
      "\tspeed: 0.1164s/iter; left time: 935.4424s\n",
      "\titers: 200, epoch: 2 | loss: 0.7878410\n",
      "\tspeed: 0.0479s/iter; left time: 379.8506s\n",
      "\titers: 300, epoch: 2 | loss: 0.7395509\n",
      "\tspeed: 0.0476s/iter; left time: 373.4012s\n",
      "\titers: 400, epoch: 2 | loss: 0.6591961\n",
      "\tspeed: 0.0479s/iter; left time: 370.4204s\n",
      "\titers: 500, epoch: 2 | loss: 0.6968939\n",
      "\tspeed: 0.0478s/iter; left time: 365.4031s\n",
      "\titers: 600, epoch: 2 | loss: 0.7799301\n",
      "\tspeed: 0.0479s/iter; left time: 360.9616s\n",
      "\titers: 700, epoch: 2 | loss: 0.7029775\n",
      "\tspeed: 0.0478s/iter; left time: 355.4067s\n",
      "\titers: 800, epoch: 2 | loss: 0.7345486\n",
      "\tspeed: 0.0478s/iter; left time: 350.3565s\n",
      "\titers: 900, epoch: 2 | loss: 0.6330129\n",
      "\tspeed: 0.0475s/iter; left time: 343.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.7273200 Vali Loss: 0.6909656 Test Loss: 0.8539773\n",
      "Validation loss decreased (0.822625 --> 0.690966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6829980\n",
      "\tspeed: 0.1180s/iter; left time: 841.3737s\n",
      "\titers: 200, epoch: 3 | loss: 0.6691113\n",
      "\tspeed: 0.0475s/iter; left time: 334.0720s\n",
      "\titers: 300, epoch: 3 | loss: 0.6194271\n",
      "\tspeed: 0.0476s/iter; left time: 330.0211s\n",
      "\titers: 400, epoch: 3 | loss: 0.6320899\n",
      "\tspeed: 0.0477s/iter; left time: 326.0673s\n",
      "\titers: 500, epoch: 3 | loss: 0.6391604\n",
      "\tspeed: 0.0476s/iter; left time: 320.7649s\n",
      "\titers: 600, epoch: 3 | loss: 0.6362435\n",
      "\tspeed: 0.0475s/iter; left time: 315.3285s\n",
      "\titers: 700, epoch: 3 | loss: 0.6481073\n",
      "\tspeed: 0.0474s/iter; left time: 309.7803s\n",
      "\titers: 800, epoch: 3 | loss: 0.6707047\n",
      "\tspeed: 0.0475s/iter; left time: 305.6507s\n",
      "\titers: 900, epoch: 3 | loss: 0.6414825\n",
      "\tspeed: 0.0474s/iter; left time: 300.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.26s\n",
      "Steps: 904 | Train Loss: 0.6500887 Vali Loss: 0.7310898 Test Loss: 0.8651748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5668097\n",
      "\tspeed: 0.1129s/iter; left time: 703.5223s\n",
      "\titers: 200, epoch: 4 | loss: 0.6010278\n",
      "\tspeed: 0.0477s/iter; left time: 292.1757s\n",
      "\titers: 300, epoch: 4 | loss: 0.5805757\n",
      "\tspeed: 0.0479s/iter; left time: 288.5480s\n",
      "\titers: 400, epoch: 4 | loss: 0.5756222\n",
      "\tspeed: 0.0476s/iter; left time: 282.2316s\n",
      "\titers: 500, epoch: 4 | loss: 0.6019570\n",
      "\tspeed: 0.0476s/iter; left time: 277.5727s\n",
      "\titers: 600, epoch: 4 | loss: 0.5867005\n",
      "\tspeed: 0.0477s/iter; left time: 273.2703s\n",
      "\titers: 700, epoch: 4 | loss: 0.5590611\n",
      "\tspeed: 0.0477s/iter; left time: 268.2850s\n",
      "\titers: 800, epoch: 4 | loss: 0.5786862\n",
      "\tspeed: 0.0478s/iter; left time: 264.0333s\n",
      "\titers: 900, epoch: 4 | loss: 0.5570041\n",
      "\tspeed: 0.0477s/iter; left time: 259.0693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.5954686 Vali Loss: 0.7804562 Test Loss: 0.9499455\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5297164\n",
      "\tspeed: 0.1130s/iter; left time: 601.5214s\n",
      "\titers: 200, epoch: 5 | loss: 0.5754976\n",
      "\tspeed: 0.0474s/iter; left time: 247.5521s\n",
      "\titers: 300, epoch: 5 | loss: 0.5536209\n",
      "\tspeed: 0.0474s/iter; left time: 243.1519s\n",
      "\titers: 400, epoch: 5 | loss: 0.5372819\n",
      "\tspeed: 0.0474s/iter; left time: 238.0515s\n",
      "\titers: 500, epoch: 5 | loss: 0.5717360\n",
      "\tspeed: 0.0459s/iter; left time: 226.2410s\n",
      "\titers: 600, epoch: 5 | loss: 0.5239812\n",
      "\tspeed: 0.0354s/iter; left time: 170.8353s\n",
      "\titers: 700, epoch: 5 | loss: 0.5715138\n",
      "\tspeed: 0.0354s/iter; left time: 167.1501s\n",
      "\titers: 800, epoch: 5 | loss: 0.5439026\n",
      "\tspeed: 0.0354s/iter; left time: 163.6351s\n",
      "\titers: 900, epoch: 5 | loss: 0.5221722\n",
      "\tspeed: 0.0354s/iter; left time: 160.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 904 | Train Loss: 0.5448839 Vali Loss: 0.7546401 Test Loss: 0.9773735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:36986492.0, rmse:6081.65185546875, mae:4114.8583984375, rse:0.30286842584609985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9471332\n",
      "\tspeed: 0.0817s/iter; left time: 728.7798s\n",
      "\titers: 200, epoch: 1 | loss: 0.9861875\n",
      "\tspeed: 0.0533s/iter; left time: 470.3506s\n",
      "\titers: 300, epoch: 1 | loss: 0.9315915\n",
      "\tspeed: 0.0536s/iter; left time: 467.2185s\n",
      "\titers: 400, epoch: 1 | loss: 0.9368693\n",
      "\tspeed: 0.0537s/iter; left time: 462.5347s\n",
      "\titers: 500, epoch: 1 | loss: 0.9175271\n",
      "\tspeed: 0.0538s/iter; left time: 458.0388s\n",
      "\titers: 600, epoch: 1 | loss: 0.9426318\n",
      "\tspeed: 0.0536s/iter; left time: 451.4380s\n",
      "\titers: 700, epoch: 1 | loss: 0.9106294\n",
      "\tspeed: 0.0536s/iter; left time: 445.6202s\n",
      "\titers: 800, epoch: 1 | loss: 0.8740443\n",
      "\tspeed: 0.0535s/iter; left time: 439.8874s\n",
      "\titers: 900, epoch: 1 | loss: 0.9128570\n",
      "\tspeed: 0.0535s/iter; left time: 434.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.01s\n",
      "Steps: 902 | Train Loss: 0.9340369 Vali Loss: 0.9780082 Test Loss: 1.2568091\n",
      "Validation loss decreased (inf --> 0.978008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9008682\n",
      "\tspeed: 0.1331s/iter; left time: 1067.0884s\n",
      "\titers: 200, epoch: 2 | loss: 0.8331870\n",
      "\tspeed: 0.0535s/iter; left time: 423.3039s\n",
      "\titers: 300, epoch: 2 | loss: 0.8587946\n",
      "\tspeed: 0.0533s/iter; left time: 417.1203s\n",
      "\titers: 400, epoch: 2 | loss: 0.7877640\n",
      "\tspeed: 0.0539s/iter; left time: 416.3058s\n",
      "\titers: 500, epoch: 2 | loss: 0.7759214\n",
      "\tspeed: 0.0540s/iter; left time: 411.5723s\n",
      "\titers: 600, epoch: 2 | loss: 0.7217450\n",
      "\tspeed: 0.0533s/iter; left time: 400.7927s\n",
      "\titers: 700, epoch: 2 | loss: 0.7161107\n",
      "\tspeed: 0.0535s/iter; left time: 396.6114s\n",
      "\titers: 800, epoch: 2 | loss: 0.7566212\n",
      "\tspeed: 0.0536s/iter; left time: 392.3444s\n",
      "\titers: 900, epoch: 2 | loss: 0.7012705\n",
      "\tspeed: 0.0532s/iter; left time: 383.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.46s\n",
      "Steps: 902 | Train Loss: 0.7724640 Vali Loss: 0.7328678 Test Loss: 0.8932632\n",
      "Validation loss decreased (0.978008 --> 0.732868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7165682\n",
      "\tspeed: 0.1358s/iter; left time: 966.2102s\n",
      "\titers: 200, epoch: 3 | loss: 0.6870352\n",
      "\tspeed: 0.0538s/iter; left time: 377.1680s\n",
      "\titers: 300, epoch: 3 | loss: 0.6787533\n",
      "\tspeed: 0.0537s/iter; left time: 371.2603s\n",
      "\titers: 400, epoch: 3 | loss: 0.7236806\n",
      "\tspeed: 0.0536s/iter; left time: 365.2206s\n",
      "\titers: 500, epoch: 3 | loss: 0.6608443\n",
      "\tspeed: 0.0536s/iter; left time: 359.8560s\n",
      "\titers: 600, epoch: 3 | loss: 0.6809654\n",
      "\tspeed: 0.0537s/iter; left time: 355.4332s\n",
      "\titers: 700, epoch: 3 | loss: 0.6834272\n",
      "\tspeed: 0.0537s/iter; left time: 350.0114s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417248\n",
      "\tspeed: 0.0536s/iter; left time: 344.1741s\n",
      "\titers: 900, epoch: 3 | loss: 0.6610432\n",
      "\tspeed: 0.0536s/iter; left time: 338.6078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.6721240 Vali Loss: 0.7346251 Test Loss: 0.9027070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6154931\n",
      "\tspeed: 0.1286s/iter; left time: 799.0317s\n",
      "\titers: 200, epoch: 4 | loss: 0.5788427\n",
      "\tspeed: 0.0534s/iter; left time: 326.6820s\n",
      "\titers: 300, epoch: 4 | loss: 0.6534283\n",
      "\tspeed: 0.0534s/iter; left time: 321.3475s\n",
      "\titers: 400, epoch: 4 | loss: 0.6317046\n",
      "\tspeed: 0.0534s/iter; left time: 315.6342s\n",
      "\titers: 500, epoch: 4 | loss: 0.6388951\n",
      "\tspeed: 0.0534s/iter; left time: 310.6626s\n",
      "\titers: 600, epoch: 4 | loss: 0.5904660\n",
      "\tspeed: 0.0534s/iter; left time: 305.4364s\n",
      "\titers: 700, epoch: 4 | loss: 0.6414444\n",
      "\tspeed: 0.0533s/iter; left time: 299.4470s\n",
      "\titers: 800, epoch: 4 | loss: 0.6158543\n",
      "\tspeed: 0.0530s/iter; left time: 292.2795s\n",
      "\titers: 900, epoch: 4 | loss: 0.5860508\n",
      "\tspeed: 0.0536s/iter; left time: 290.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.32s\n",
      "Steps: 902 | Train Loss: 0.6109018 Vali Loss: 0.7862337 Test Loss: 1.0190303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6108308\n",
      "\tspeed: 0.1284s/iter; left time: 682.3775s\n",
      "\titers: 200, epoch: 5 | loss: 0.5784037\n",
      "\tspeed: 0.0536s/iter; left time: 279.3415s\n",
      "\titers: 300, epoch: 5 | loss: 0.5641100\n",
      "\tspeed: 0.0534s/iter; left time: 272.9503s\n",
      "\titers: 400, epoch: 5 | loss: 0.5748665\n",
      "\tspeed: 0.0535s/iter; left time: 268.2843s\n",
      "\titers: 500, epoch: 5 | loss: 0.5016975\n",
      "\tspeed: 0.0535s/iter; left time: 263.0165s\n",
      "\titers: 600, epoch: 5 | loss: 0.5542794\n",
      "\tspeed: 0.0533s/iter; left time: 256.3859s\n",
      "\titers: 700, epoch: 5 | loss: 0.5704201\n",
      "\tspeed: 0.0536s/iter; left time: 252.7457s\n",
      "\titers: 800, epoch: 5 | loss: 0.5250012\n",
      "\tspeed: 0.0533s/iter; left time: 245.9909s\n",
      "\titers: 900, epoch: 5 | loss: 0.4947276\n",
      "\tspeed: 0.0532s/iter; left time: 240.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.34s\n",
      "Steps: 902 | Train Loss: 0.5555994 Vali Loss: 0.8196364 Test Loss: 1.0833149\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:38815100.0, rmse:6230.1767578125, mae:4220.97314453125, rse:0.3104173243045807\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0656863\n",
      "\tspeed: 0.0547s/iter; left time: 488.1585s\n",
      "\titers: 200, epoch: 1 | loss: 0.9557311\n",
      "\tspeed: 0.0537s/iter; left time: 473.9343s\n",
      "\titers: 300, epoch: 1 | loss: 0.8678913\n",
      "\tspeed: 0.0534s/iter; left time: 465.5421s\n",
      "\titers: 400, epoch: 1 | loss: 0.9394004\n",
      "\tspeed: 0.0533s/iter; left time: 459.2489s\n",
      "\titers: 500, epoch: 1 | loss: 0.9029401\n",
      "\tspeed: 0.0532s/iter; left time: 453.3726s\n",
      "\titers: 600, epoch: 1 | loss: 0.9282050\n",
      "\tspeed: 0.0534s/iter; left time: 449.2711s\n",
      "\titers: 700, epoch: 1 | loss: 0.9335796\n",
      "\tspeed: 0.0535s/iter; left time: 445.5314s\n",
      "\titers: 800, epoch: 1 | loss: 0.8777130\n",
      "\tspeed: 0.0534s/iter; left time: 438.6919s\n",
      "\titers: 900, epoch: 1 | loss: 0.8798903\n",
      "\tspeed: 0.0533s/iter; left time: 433.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.9323759 Vali Loss: 0.9880757 Test Loss: 1.2649819\n",
      "Validation loss decreased (inf --> 0.988076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8998638\n",
      "\tspeed: 0.1329s/iter; left time: 1065.8573s\n",
      "\titers: 200, epoch: 2 | loss: 0.8122976\n",
      "\tspeed: 0.0535s/iter; left time: 423.9767s\n",
      "\titers: 300, epoch: 2 | loss: 0.8411333\n",
      "\tspeed: 0.0533s/iter; left time: 416.9521s\n",
      "\titers: 400, epoch: 2 | loss: 0.7060408\n",
      "\tspeed: 0.0536s/iter; left time: 413.9906s\n",
      "\titers: 500, epoch: 2 | loss: 0.7866837\n",
      "\tspeed: 0.0536s/iter; left time: 408.0196s\n",
      "\titers: 600, epoch: 2 | loss: 0.7293652\n",
      "\tspeed: 0.0534s/iter; left time: 401.7036s\n",
      "\titers: 700, epoch: 2 | loss: 0.7686659\n",
      "\tspeed: 0.0536s/iter; left time: 397.8076s\n",
      "\titers: 800, epoch: 2 | loss: 0.7129799\n",
      "\tspeed: 0.0536s/iter; left time: 392.3847s\n",
      "\titers: 900, epoch: 2 | loss: 0.6920627\n",
      "\tspeed: 0.0533s/iter; left time: 385.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.7832593 Vali Loss: 0.7692808 Test Loss: 0.8737599\n",
      "Validation loss decreased (0.988076 --> 0.769281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6975249\n",
      "\tspeed: 0.1325s/iter; left time: 943.3359s\n",
      "\titers: 200, epoch: 3 | loss: 0.6490678\n",
      "\tspeed: 0.0534s/iter; left time: 375.0366s\n",
      "\titers: 300, epoch: 3 | loss: 0.6470399\n",
      "\tspeed: 0.0534s/iter; left time: 369.5214s\n",
      "\titers: 400, epoch: 3 | loss: 0.6277720\n",
      "\tspeed: 0.0535s/iter; left time: 364.8278s\n",
      "\titers: 500, epoch: 3 | loss: 0.6651936\n",
      "\tspeed: 0.0535s/iter; left time: 359.2406s\n",
      "\titers: 600, epoch: 3 | loss: 0.6629560\n",
      "\tspeed: 0.0533s/iter; left time: 352.9878s\n",
      "\titers: 700, epoch: 3 | loss: 0.6748104\n",
      "\tspeed: 0.0536s/iter; left time: 349.3547s\n",
      "\titers: 800, epoch: 3 | loss: 0.6037708\n",
      "\tspeed: 0.0536s/iter; left time: 344.1212s\n",
      "\titers: 900, epoch: 3 | loss: 0.6436216\n",
      "\tspeed: 0.0535s/iter; left time: 338.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.46s\n",
      "Steps: 902 | Train Loss: 0.6772264 Vali Loss: 0.7475495 Test Loss: 0.9241825\n",
      "Validation loss decreased (0.769281 --> 0.747550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5969893\n",
      "\tspeed: 0.1330s/iter; left time: 826.6453s\n",
      "\titers: 200, epoch: 4 | loss: 0.6450239\n",
      "\tspeed: 0.0536s/iter; left time: 327.5878s\n",
      "\titers: 300, epoch: 4 | loss: 0.6595438\n",
      "\tspeed: 0.0537s/iter; left time: 322.7565s\n",
      "\titers: 400, epoch: 4 | loss: 0.6280913\n",
      "\tspeed: 0.0536s/iter; left time: 317.3214s\n",
      "\titers: 500, epoch: 4 | loss: 0.6201030\n",
      "\tspeed: 0.0533s/iter; left time: 309.9725s\n",
      "\titers: 600, epoch: 4 | loss: 0.6041957\n",
      "\tspeed: 0.0533s/iter; left time: 304.8020s\n",
      "\titers: 700, epoch: 4 | loss: 0.5926436\n",
      "\tspeed: 0.0533s/iter; left time: 299.5533s\n",
      "\titers: 800, epoch: 4 | loss: 0.5527857\n",
      "\tspeed: 0.0533s/iter; left time: 294.0161s\n",
      "\titers: 900, epoch: 4 | loss: 0.6230676\n",
      "\tspeed: 0.0537s/iter; left time: 290.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.6172915 Vali Loss: 0.7728670 Test Loss: 0.9370694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5788156\n",
      "\tspeed: 0.1298s/iter; left time: 689.3736s\n",
      "\titers: 200, epoch: 5 | loss: 0.5334616\n",
      "\tspeed: 0.0536s/iter; left time: 279.5280s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742775\n",
      "\tspeed: 0.0535s/iter; left time: 273.7121s\n",
      "\titers: 400, epoch: 5 | loss: 0.5482292\n",
      "\tspeed: 0.0536s/iter; left time: 268.7321s\n",
      "\titers: 500, epoch: 5 | loss: 0.5712826\n",
      "\tspeed: 0.0536s/iter; left time: 263.5734s\n",
      "\titers: 600, epoch: 5 | loss: 0.5743529\n",
      "\tspeed: 0.0535s/iter; left time: 257.3408s\n",
      "\titers: 700, epoch: 5 | loss: 0.5463770\n",
      "\tspeed: 0.0538s/iter; left time: 253.7110s\n",
      "\titers: 800, epoch: 5 | loss: 0.5580187\n",
      "\tspeed: 0.0535s/iter; left time: 246.8271s\n",
      "\titers: 900, epoch: 5 | loss: 0.5339939\n",
      "\tspeed: 0.0536s/iter; left time: 241.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.5604885 Vali Loss: 0.8126694 Test Loss: 0.9670021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5250809\n",
      "\tspeed: 0.1293s/iter; left time: 570.3191s\n",
      "\titers: 200, epoch: 6 | loss: 0.5023152\n",
      "\tspeed: 0.0534s/iter; left time: 230.2865s\n",
      "\titers: 300, epoch: 6 | loss: 0.4989885\n",
      "\tspeed: 0.0536s/iter; left time: 225.5270s\n",
      "\titers: 400, epoch: 6 | loss: 0.5178986\n",
      "\tspeed: 0.0536s/iter; left time: 220.2334s\n",
      "\titers: 500, epoch: 6 | loss: 0.5457343\n",
      "\tspeed: 0.0535s/iter; left time: 214.4821s\n",
      "\titers: 600, epoch: 6 | loss: 0.5038822\n",
      "\tspeed: 0.0537s/iter; left time: 209.8450s\n",
      "\titers: 700, epoch: 6 | loss: 0.5238547\n",
      "\tspeed: 0.0536s/iter; left time: 204.1221s\n",
      "\titers: 800, epoch: 6 | loss: 0.4924663\n",
      "\tspeed: 0.0537s/iter; left time: 199.1944s\n",
      "\titers: 900, epoch: 6 | loss: 0.5068249\n",
      "\tspeed: 0.0537s/iter; left time: 193.8258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.5112046 Vali Loss: 0.8424274 Test Loss: 1.0782026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:40210260.0, rmse:6341.15625, mae:4216.42529296875, rse:0.3159468472003937\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7215695\n",
      "\tspeed: 0.0713s/iter; left time: 639.1218s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677415\n",
      "\tspeed: 0.0412s/iter; left time: 365.0549s\n",
      "\titers: 300, epoch: 1 | loss: 0.5992011\n",
      "\tspeed: 0.0412s/iter; left time: 360.9374s\n",
      "\titers: 400, epoch: 1 | loss: 0.5512000\n",
      "\tspeed: 0.0410s/iter; left time: 355.2174s\n",
      "\titers: 500, epoch: 1 | loss: 0.5238050\n",
      "\tspeed: 0.0415s/iter; left time: 355.7063s\n",
      "\titers: 600, epoch: 1 | loss: 0.5131288\n",
      "\tspeed: 0.0419s/iter; left time: 354.1264s\n",
      "\titers: 700, epoch: 1 | loss: 0.6015207\n",
      "\tspeed: 0.0413s/iter; left time: 345.1080s\n",
      "\titers: 800, epoch: 1 | loss: 0.5066000\n",
      "\tspeed: 0.0412s/iter; left time: 340.5173s\n",
      "\titers: 900, epoch: 1 | loss: 0.4471631\n",
      "\tspeed: 0.0410s/iter; left time: 334.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.5917037 Vali Loss: 0.5611537 Test Loss: 0.5962256\n",
      "Validation loss decreased (inf --> 0.561154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3709538\n",
      "\tspeed: 0.0972s/iter; left time: 782.7107s\n",
      "\titers: 200, epoch: 2 | loss: 0.4661245\n",
      "\tspeed: 0.0414s/iter; left time: 329.4762s\n",
      "\titers: 300, epoch: 2 | loss: 0.3768515\n",
      "\tspeed: 0.0415s/iter; left time: 325.7430s\n",
      "\titers: 400, epoch: 2 | loss: 0.4144876\n",
      "\tspeed: 0.0409s/iter; left time: 317.1335s\n",
      "\titers: 500, epoch: 2 | loss: 0.3443320\n",
      "\tspeed: 0.0412s/iter; left time: 315.5854s\n",
      "\titers: 600, epoch: 2 | loss: 0.3588921\n",
      "\tspeed: 0.0411s/iter; left time: 310.5233s\n",
      "\titers: 700, epoch: 2 | loss: 0.3583628\n",
      "\tspeed: 0.0408s/iter; left time: 303.9320s\n",
      "\titers: 800, epoch: 2 | loss: 0.4166490\n",
      "\tspeed: 0.0413s/iter; left time: 303.5237s\n",
      "\titers: 900, epoch: 2 | loss: 0.3890607\n",
      "\tspeed: 0.0412s/iter; left time: 298.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.53s\n",
      "Steps: 906 | Train Loss: 0.4025906 Vali Loss: 0.4453301 Test Loss: 0.4756032\n",
      "Validation loss decreased (0.561154 --> 0.445330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3711495\n",
      "\tspeed: 0.0998s/iter; left time: 713.4005s\n",
      "\titers: 200, epoch: 3 | loss: 0.3322031\n",
      "\tspeed: 0.0418s/iter; left time: 294.8313s\n",
      "\titers: 300, epoch: 3 | loss: 0.3484581\n",
      "\tspeed: 0.0412s/iter; left time: 286.0158s\n",
      "\titers: 400, epoch: 3 | loss: 0.3441037\n",
      "\tspeed: 0.0414s/iter; left time: 283.5539s\n",
      "\titers: 500, epoch: 3 | loss: 0.4129507\n",
      "\tspeed: 0.0417s/iter; left time: 281.1132s\n",
      "\titers: 600, epoch: 3 | loss: 0.3717259\n",
      "\tspeed: 0.0414s/iter; left time: 275.2640s\n",
      "\titers: 700, epoch: 3 | loss: 0.3695573\n",
      "\tspeed: 0.0422s/iter; left time: 276.5842s\n",
      "\titers: 800, epoch: 3 | loss: 0.3394932\n",
      "\tspeed: 0.0419s/iter; left time: 270.4495s\n",
      "\titers: 900, epoch: 3 | loss: 0.3480455\n",
      "\tspeed: 0.0418s/iter; left time: 265.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.3552150 Vali Loss: 0.4405829 Test Loss: 0.4628681\n",
      "Validation loss decreased (0.445330 --> 0.440583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3240797\n",
      "\tspeed: 0.0979s/iter; left time: 610.8837s\n",
      "\titers: 200, epoch: 4 | loss: 0.3329988\n",
      "\tspeed: 0.0412s/iter; left time: 253.1716s\n",
      "\titers: 300, epoch: 4 | loss: 0.3138479\n",
      "\tspeed: 0.0411s/iter; left time: 248.0967s\n",
      "\titers: 400, epoch: 4 | loss: 0.2903596\n",
      "\tspeed: 0.0408s/iter; left time: 242.5376s\n",
      "\titers: 500, epoch: 4 | loss: 0.3638243\n",
      "\tspeed: 0.0413s/iter; left time: 241.0574s\n",
      "\titers: 600, epoch: 4 | loss: 0.3209779\n",
      "\tspeed: 0.0410s/iter; left time: 235.5281s\n",
      "\titers: 700, epoch: 4 | loss: 0.3025450\n",
      "\tspeed: 0.0411s/iter; left time: 231.6747s\n",
      "\titers: 800, epoch: 4 | loss: 0.3539144\n",
      "\tspeed: 0.0413s/iter; left time: 229.1972s\n",
      "\titers: 900, epoch: 4 | loss: 0.3243295\n",
      "\tspeed: 0.0413s/iter; left time: 224.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.3304306 Vali Loss: 0.4461254 Test Loss: 0.4630463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3200391\n",
      "\tspeed: 0.0956s/iter; left time: 510.0521s\n",
      "\titers: 200, epoch: 5 | loss: 0.3002499\n",
      "\tspeed: 0.0417s/iter; left time: 218.5176s\n",
      "\titers: 300, epoch: 5 | loss: 0.2781452\n",
      "\tspeed: 0.0429s/iter; left time: 220.3941s\n",
      "\titers: 400, epoch: 5 | loss: 0.3169612\n",
      "\tspeed: 0.0449s/iter; left time: 226.1848s\n",
      "\titers: 500, epoch: 5 | loss: 0.3001828\n",
      "\tspeed: 0.0448s/iter; left time: 221.1722s\n",
      "\titers: 600, epoch: 5 | loss: 0.3253998\n",
      "\tspeed: 0.0455s/iter; left time: 219.9040s\n",
      "\titers: 700, epoch: 5 | loss: 0.2686165\n",
      "\tspeed: 0.0451s/iter; left time: 213.6605s\n",
      "\titers: 800, epoch: 5 | loss: 0.3044296\n",
      "\tspeed: 0.0445s/iter; left time: 206.1175s\n",
      "\titers: 900, epoch: 5 | loss: 0.3225136\n",
      "\tspeed: 0.0451s/iter; left time: 204.6525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.05s\n",
      "Steps: 906 | Train Loss: 0.3035686 Vali Loss: 0.4407153 Test Loss: 0.4767428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2985508\n",
      "\tspeed: 0.0950s/iter; left time: 420.7511s\n",
      "\titers: 200, epoch: 6 | loss: 0.2633336\n",
      "\tspeed: 0.0418s/iter; left time: 180.9391s\n",
      "\titers: 300, epoch: 6 | loss: 0.2996624\n",
      "\tspeed: 0.0417s/iter; left time: 176.3544s\n",
      "\titers: 400, epoch: 6 | loss: 0.2697504\n",
      "\tspeed: 0.0426s/iter; left time: 176.0461s\n",
      "\titers: 500, epoch: 6 | loss: 0.3121417\n",
      "\tspeed: 0.0412s/iter; left time: 166.0480s\n",
      "\titers: 600, epoch: 6 | loss: 0.2498942\n",
      "\tspeed: 0.0410s/iter; left time: 161.3533s\n",
      "\titers: 700, epoch: 6 | loss: 0.2871542\n",
      "\tspeed: 0.0409s/iter; left time: 156.8186s\n",
      "\titers: 800, epoch: 6 | loss: 0.2544069\n",
      "\tspeed: 0.0414s/iter; left time: 154.4190s\n",
      "\titers: 900, epoch: 6 | loss: 0.2554080\n",
      "\tspeed: 0.0412s/iter; left time: 149.7296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 906 | Train Loss: 0.2803099 Vali Loss: 0.4469062 Test Loss: 0.4820318\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:19648216.0, rmse:4432.630859375, mae:2762.43359375, rse:0.22039934992790222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6933636\n",
      "\tspeed: 0.0473s/iter; left time: 423.7730s\n",
      "\titers: 200, epoch: 1 | loss: 0.6457908\n",
      "\tspeed: 0.0450s/iter; left time: 399.0857s\n",
      "\titers: 300, epoch: 1 | loss: 0.5454914\n",
      "\tspeed: 0.0448s/iter; left time: 392.5721s\n",
      "\titers: 400, epoch: 1 | loss: 0.5511503\n",
      "\tspeed: 0.0451s/iter; left time: 391.0149s\n",
      "\titers: 500, epoch: 1 | loss: 0.5786752\n",
      "\tspeed: 0.0459s/iter; left time: 392.9156s\n",
      "\titers: 600, epoch: 1 | loss: 0.5497690\n",
      "\tspeed: 0.0451s/iter; left time: 381.3979s\n",
      "\titers: 700, epoch: 1 | loss: 0.5148432\n",
      "\tspeed: 0.0452s/iter; left time: 377.8594s\n",
      "\titers: 800, epoch: 1 | loss: 0.5002761\n",
      "\tspeed: 0.0453s/iter; left time: 374.1560s\n",
      "\titers: 900, epoch: 1 | loss: 0.5042391\n",
      "\tspeed: 0.0456s/iter; left time: 372.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.24s\n",
      "Steps: 906 | Train Loss: 0.5909449 Vali Loss: 0.5603049 Test Loss: 0.6012501\n",
      "Validation loss decreased (inf --> 0.560305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4975006\n",
      "\tspeed: 0.0996s/iter; left time: 802.2857s\n",
      "\titers: 200, epoch: 2 | loss: 0.4123350\n",
      "\tspeed: 0.0414s/iter; left time: 329.6894s\n",
      "\titers: 300, epoch: 2 | loss: 0.3612792\n",
      "\tspeed: 0.0416s/iter; left time: 326.5759s\n",
      "\titers: 400, epoch: 2 | loss: 0.3984689\n",
      "\tspeed: 0.0421s/iter; left time: 326.4151s\n",
      "\titers: 500, epoch: 2 | loss: 0.3699860\n",
      "\tspeed: 0.0414s/iter; left time: 316.8381s\n",
      "\titers: 600, epoch: 2 | loss: 0.3737260\n",
      "\tspeed: 0.0418s/iter; left time: 315.6650s\n",
      "\titers: 700, epoch: 2 | loss: 0.4142011\n",
      "\tspeed: 0.0416s/iter; left time: 310.1979s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857327\n",
      "\tspeed: 0.0417s/iter; left time: 307.0364s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409123\n",
      "\tspeed: 0.0413s/iter; left time: 299.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 906 | Train Loss: 0.4034030 Vali Loss: 0.4392297 Test Loss: 0.4641765\n",
      "Validation loss decreased (0.560305 --> 0.439230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3298930\n",
      "\tspeed: 0.0986s/iter; left time: 704.6036s\n",
      "\titers: 200, epoch: 3 | loss: 0.3437467\n",
      "\tspeed: 0.0421s/iter; left time: 296.5369s\n",
      "\titers: 300, epoch: 3 | loss: 0.4309845\n",
      "\tspeed: 0.0421s/iter; left time: 292.2529s\n",
      "\titers: 400, epoch: 3 | loss: 0.3171408\n",
      "\tspeed: 0.0420s/iter; left time: 287.9174s\n",
      "\titers: 500, epoch: 3 | loss: 0.3937010\n",
      "\tspeed: 0.0426s/iter; left time: 287.4583s\n",
      "\titers: 600, epoch: 3 | loss: 0.3775530\n",
      "\tspeed: 0.0419s/iter; left time: 278.8118s\n",
      "\titers: 700, epoch: 3 | loss: 0.3584513\n",
      "\tspeed: 0.0413s/iter; left time: 270.3759s\n",
      "\titers: 800, epoch: 3 | loss: 0.2602788\n",
      "\tspeed: 0.0418s/iter; left time: 269.6926s\n",
      "\titers: 900, epoch: 3 | loss: 0.2889211\n",
      "\tspeed: 0.0417s/iter; left time: 264.6688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 906 | Train Loss: 0.3539314 Vali Loss: 0.4312690 Test Loss: 0.4557568\n",
      "Validation loss decreased (0.439230 --> 0.431269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3537179\n",
      "\tspeed: 0.0993s/iter; left time: 620.1984s\n",
      "\titers: 200, epoch: 4 | loss: 0.3129574\n",
      "\tspeed: 0.0419s/iter; left time: 257.1443s\n",
      "\titers: 300, epoch: 4 | loss: 0.2914827\n",
      "\tspeed: 0.0422s/iter; left time: 255.3054s\n",
      "\titers: 400, epoch: 4 | loss: 0.3527328\n",
      "\tspeed: 0.0415s/iter; left time: 246.7362s\n",
      "\titers: 500, epoch: 4 | loss: 0.2786991\n",
      "\tspeed: 0.0416s/iter; left time: 243.1454s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483981\n",
      "\tspeed: 0.0427s/iter; left time: 245.1166s\n",
      "\titers: 700, epoch: 4 | loss: 0.3014231\n",
      "\tspeed: 0.0421s/iter; left time: 237.3942s\n",
      "\titers: 800, epoch: 4 | loss: 0.3250557\n",
      "\tspeed: 0.0423s/iter; left time: 234.2888s\n",
      "\titers: 900, epoch: 4 | loss: 0.3409735\n",
      "\tspeed: 0.0421s/iter; left time: 228.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.3276601 Vali Loss: 0.4329171 Test Loss: 0.4587655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2832368\n",
      "\tspeed: 0.0952s/iter; left time: 508.2438s\n",
      "\titers: 200, epoch: 5 | loss: 0.3461204\n",
      "\tspeed: 0.0419s/iter; left time: 219.1791s\n",
      "\titers: 300, epoch: 5 | loss: 0.3221009\n",
      "\tspeed: 0.0417s/iter; left time: 214.0631s\n",
      "\titers: 400, epoch: 5 | loss: 0.3311023\n",
      "\tspeed: 0.0420s/iter; left time: 211.3265s\n",
      "\titers: 500, epoch: 5 | loss: 0.2930217\n",
      "\tspeed: 0.0417s/iter; left time: 205.8042s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887761\n",
      "\tspeed: 0.0417s/iter; left time: 201.7045s\n",
      "\titers: 700, epoch: 5 | loss: 0.3053557\n",
      "\tspeed: 0.0420s/iter; left time: 198.7482s\n",
      "\titers: 800, epoch: 5 | loss: 0.2880615\n",
      "\tspeed: 0.0419s/iter; left time: 194.4137s\n",
      "\titers: 900, epoch: 5 | loss: 0.3189270\n",
      "\tspeed: 0.0416s/iter; left time: 188.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.3014971 Vali Loss: 0.4485994 Test Loss: 0.4587874\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3184680\n",
      "\tspeed: 0.0954s/iter; left time: 422.5107s\n",
      "\titers: 200, epoch: 6 | loss: 0.2596821\n",
      "\tspeed: 0.0420s/iter; left time: 182.0176s\n",
      "\titers: 300, epoch: 6 | loss: 0.2904953\n",
      "\tspeed: 0.0423s/iter; left time: 179.0787s\n",
      "\titers: 400, epoch: 6 | loss: 0.3148658\n",
      "\tspeed: 0.0418s/iter; left time: 172.7924s\n",
      "\titers: 500, epoch: 6 | loss: 0.3033264\n",
      "\tspeed: 0.0425s/iter; left time: 171.2977s\n",
      "\titers: 600, epoch: 6 | loss: 0.3050017\n",
      "\tspeed: 0.0419s/iter; left time: 164.7700s\n",
      "\titers: 700, epoch: 6 | loss: 0.2470572\n",
      "\tspeed: 0.0419s/iter; left time: 160.3540s\n",
      "\titers: 800, epoch: 6 | loss: 0.2386658\n",
      "\tspeed: 0.0413s/iter; left time: 153.9128s\n",
      "\titers: 900, epoch: 6 | loss: 0.2651795\n",
      "\tspeed: 0.0417s/iter; left time: 151.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.2773427 Vali Loss: 0.4407897 Test Loss: 0.4618565\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:19207616.0, rmse:4382.6494140625, mae:2741.959716796875, rse:0.2179141640663147\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8046664\n",
      "\tspeed: 0.0742s/iter; left time: 663.3104s\n",
      "\titers: 200, epoch: 1 | loss: 0.7705905\n",
      "\tspeed: 0.0478s/iter; left time: 422.9692s\n",
      "\titers: 300, epoch: 1 | loss: 0.7503831\n",
      "\tspeed: 0.0473s/iter; left time: 413.4381s\n",
      "\titers: 400, epoch: 1 | loss: 0.7038482\n",
      "\tspeed: 0.0470s/iter; left time: 405.8283s\n",
      "\titers: 500, epoch: 1 | loss: 0.6970635\n",
      "\tspeed: 0.0474s/iter; left time: 404.8969s\n",
      "\titers: 600, epoch: 1 | loss: 0.6281009\n",
      "\tspeed: 0.0481s/iter; left time: 405.7492s\n",
      "\titers: 700, epoch: 1 | loss: 0.6151747\n",
      "\tspeed: 0.0479s/iter; left time: 399.1773s\n",
      "\titers: 800, epoch: 1 | loss: 0.6306651\n",
      "\tspeed: 0.0476s/iter; left time: 392.1035s\n",
      "\titers: 900, epoch: 1 | loss: 0.6298555\n",
      "\tspeed: 0.0475s/iter; left time: 386.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.69s\n",
      "Steps: 904 | Train Loss: 0.7062457 Vali Loss: 0.7044919 Test Loss: 0.7897239\n",
      "Validation loss decreased (inf --> 0.704492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5724813\n",
      "\tspeed: 0.1149s/iter; left time: 923.4044s\n",
      "\titers: 200, epoch: 2 | loss: 0.5583884\n",
      "\tspeed: 0.0465s/iter; left time: 368.7232s\n",
      "\titers: 300, epoch: 2 | loss: 0.5384585\n",
      "\tspeed: 0.0478s/iter; left time: 374.6183s\n",
      "\titers: 400, epoch: 2 | loss: 0.5218018\n",
      "\tspeed: 0.0465s/iter; left time: 359.6235s\n",
      "\titers: 500, epoch: 2 | loss: 0.4906337\n",
      "\tspeed: 0.0475s/iter; left time: 362.9083s\n",
      "\titers: 600, epoch: 2 | loss: 0.5179666\n",
      "\tspeed: 0.0478s/iter; left time: 360.4268s\n",
      "\titers: 700, epoch: 2 | loss: 0.4819083\n",
      "\tspeed: 0.0476s/iter; left time: 354.0944s\n",
      "\titers: 800, epoch: 2 | loss: 0.5324076\n",
      "\tspeed: 0.0472s/iter; left time: 346.5868s\n",
      "\titers: 900, epoch: 2 | loss: 0.4802623\n",
      "\tspeed: 0.0476s/iter; left time: 344.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.89s\n",
      "Steps: 904 | Train Loss: 0.5296305 Vali Loss: 0.5895641 Test Loss: 0.6527810\n",
      "Validation loss decreased (0.704492 --> 0.589564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5235303\n",
      "\tspeed: 0.1144s/iter; left time: 816.2685s\n",
      "\titers: 200, epoch: 3 | loss: 0.4529510\n",
      "\tspeed: 0.0470s/iter; left time: 330.6518s\n",
      "\titers: 300, epoch: 3 | loss: 0.4261545\n",
      "\tspeed: 0.0471s/iter; left time: 326.3782s\n",
      "\titers: 400, epoch: 3 | loss: 0.4284749\n",
      "\tspeed: 0.0474s/iter; left time: 323.7585s\n",
      "\titers: 500, epoch: 3 | loss: 0.4677834\n",
      "\tspeed: 0.0470s/iter; left time: 316.7477s\n",
      "\titers: 600, epoch: 3 | loss: 0.4825233\n",
      "\tspeed: 0.0465s/iter; left time: 308.1762s\n",
      "\titers: 700, epoch: 3 | loss: 0.4077120\n",
      "\tspeed: 0.0469s/iter; left time: 306.5085s\n",
      "\titers: 800, epoch: 3 | loss: 0.4685313\n",
      "\tspeed: 0.0470s/iter; left time: 302.3641s\n",
      "\titers: 900, epoch: 3 | loss: 0.4599987\n",
      "\tspeed: 0.0472s/iter; left time: 298.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.70s\n",
      "Steps: 904 | Train Loss: 0.4619799 Vali Loss: 0.5771369 Test Loss: 0.6438022\n",
      "Validation loss decreased (0.589564 --> 0.577137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4089474\n",
      "\tspeed: 0.1139s/iter; left time: 709.2750s\n",
      "\titers: 200, epoch: 4 | loss: 0.4214315\n",
      "\tspeed: 0.0470s/iter; left time: 287.8314s\n",
      "\titers: 300, epoch: 4 | loss: 0.4180072\n",
      "\tspeed: 0.0470s/iter; left time: 283.2638s\n",
      "\titers: 400, epoch: 4 | loss: 0.3611583\n",
      "\tspeed: 0.0472s/iter; left time: 279.8165s\n",
      "\titers: 500, epoch: 4 | loss: 0.4712610\n",
      "\tspeed: 0.0477s/iter; left time: 277.7972s\n",
      "\titers: 600, epoch: 4 | loss: 0.3901211\n",
      "\tspeed: 0.0453s/iter; left time: 259.4384s\n",
      "\titers: 700, epoch: 4 | loss: 0.4416049\n",
      "\tspeed: 0.0473s/iter; left time: 266.4507s\n",
      "\titers: 800, epoch: 4 | loss: 0.4008536\n",
      "\tspeed: 0.0471s/iter; left time: 260.1921s\n",
      "\titers: 900, epoch: 4 | loss: 0.4347542\n",
      "\tspeed: 0.0474s/iter; left time: 257.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.63s\n",
      "Steps: 904 | Train Loss: 0.4246630 Vali Loss: 0.5828032 Test Loss: 0.6657495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3883911\n",
      "\tspeed: 0.1109s/iter; left time: 590.5864s\n",
      "\titers: 200, epoch: 5 | loss: 0.4428380\n",
      "\tspeed: 0.0474s/iter; left time: 247.8474s\n",
      "\titers: 300, epoch: 5 | loss: 0.4127674\n",
      "\tspeed: 0.0470s/iter; left time: 241.0675s\n",
      "\titers: 400, epoch: 5 | loss: 0.3990879\n",
      "\tspeed: 0.0470s/iter; left time: 236.0721s\n",
      "\titers: 500, epoch: 5 | loss: 0.3641529\n",
      "\tspeed: 0.0470s/iter; left time: 231.6822s\n",
      "\titers: 600, epoch: 5 | loss: 0.3592767\n",
      "\tspeed: 0.0473s/iter; left time: 228.0845s\n",
      "\titers: 700, epoch: 5 | loss: 0.3591104\n",
      "\tspeed: 0.0472s/iter; left time: 223.1429s\n",
      "\titers: 800, epoch: 5 | loss: 0.3547353\n",
      "\tspeed: 0.0465s/iter; left time: 215.1750s\n",
      "\titers: 900, epoch: 5 | loss: 0.3660108\n",
      "\tspeed: 0.0471s/iter; left time: 212.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.78s\n",
      "Steps: 904 | Train Loss: 0.3870160 Vali Loss: 0.5739987 Test Loss: 0.6677375\n",
      "Validation loss decreased (0.577137 --> 0.573999).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3589998\n",
      "\tspeed: 0.1151s/iter; left time: 508.7946s\n",
      "\titers: 200, epoch: 6 | loss: 0.3397861\n",
      "\tspeed: 0.0479s/iter; left time: 206.7708s\n",
      "\titers: 300, epoch: 6 | loss: 0.3761511\n",
      "\tspeed: 0.0478s/iter; left time: 201.6430s\n",
      "\titers: 400, epoch: 6 | loss: 0.3682893\n",
      "\tspeed: 0.0477s/iter; left time: 196.5912s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682757\n",
      "\tspeed: 0.0476s/iter; left time: 191.2295s\n",
      "\titers: 600, epoch: 6 | loss: 0.3621927\n",
      "\tspeed: 0.0477s/iter; left time: 186.8885s\n",
      "\titers: 700, epoch: 6 | loss: 0.3596643\n",
      "\tspeed: 0.0476s/iter; left time: 181.7272s\n",
      "\titers: 800, epoch: 6 | loss: 0.3902473\n",
      "\tspeed: 0.0472s/iter; left time: 175.7417s\n",
      "\titers: 900, epoch: 6 | loss: 0.3462842\n",
      "\tspeed: 0.0474s/iter; left time: 171.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.3578898 Vali Loss: 0.5850427 Test Loss: 0.6497733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3130277\n",
      "\tspeed: 0.1116s/iter; left time: 392.4395s\n",
      "\titers: 200, epoch: 7 | loss: 0.3050972\n",
      "\tspeed: 0.0474s/iter; left time: 162.1188s\n",
      "\titers: 300, epoch: 7 | loss: 0.3185982\n",
      "\tspeed: 0.0478s/iter; left time: 158.5704s\n",
      "\titers: 400, epoch: 7 | loss: 0.3193868\n",
      "\tspeed: 0.0470s/iter; left time: 151.2419s\n",
      "\titers: 500, epoch: 7 | loss: 0.3336236\n",
      "\tspeed: 0.0469s/iter; left time: 146.2726s\n",
      "\titers: 600, epoch: 7 | loss: 0.3138655\n",
      "\tspeed: 0.0470s/iter; left time: 141.8646s\n",
      "\titers: 700, epoch: 7 | loss: 0.3336879\n",
      "\tspeed: 0.0470s/iter; left time: 137.1604s\n",
      "\titers: 800, epoch: 7 | loss: 0.3205555\n",
      "\tspeed: 0.0466s/iter; left time: 131.2342s\n",
      "\titers: 900, epoch: 7 | loss: 0.3355069\n",
      "\tspeed: 0.0471s/iter; left time: 127.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.3297362 Vali Loss: 0.5939113 Test Loss: 0.6703900\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3147684\n",
      "\tspeed: 0.0991s/iter; left time: 258.9412s\n",
      "\titers: 200, epoch: 8 | loss: 0.3183024\n",
      "\tspeed: 0.0352s/iter; left time: 88.4124s\n",
      "\titers: 300, epoch: 8 | loss: 0.3203939\n",
      "\tspeed: 0.0352s/iter; left time: 84.8560s\n",
      "\titers: 400, epoch: 8 | loss: 0.2972348\n",
      "\tspeed: 0.0352s/iter; left time: 81.3773s\n",
      "\titers: 500, epoch: 8 | loss: 0.3417727\n",
      "\tspeed: 0.0352s/iter; left time: 77.8058s\n",
      "\titers: 600, epoch: 8 | loss: 0.3158745\n",
      "\tspeed: 0.0352s/iter; left time: 74.3072s\n",
      "\titers: 700, epoch: 8 | loss: 0.3234260\n",
      "\tspeed: 0.0352s/iter; left time: 70.9187s\n",
      "\titers: 800, epoch: 8 | loss: 0.3083707\n",
      "\tspeed: 0.0353s/iter; left time: 67.4617s\n",
      "\titers: 900, epoch: 8 | loss: 0.3016308\n",
      "\tspeed: 0.0352s/iter; left time: 63.7828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.01s\n",
      "Steps: 904 | Train Loss: 0.3082505 Vali Loss: 0.5874403 Test Loss: 0.6553872\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:41247308.0, rmse:6422.40673828125, mae:4063.66357421875, rse:0.31983813643455505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8010994\n",
      "\tspeed: 0.0491s/iter; left time: 439.1843s\n",
      "\titers: 200, epoch: 1 | loss: 0.7328934\n",
      "\tspeed: 0.0478s/iter; left time: 422.4787s\n",
      "\titers: 300, epoch: 1 | loss: 0.6795613\n",
      "\tspeed: 0.0477s/iter; left time: 416.9035s\n",
      "\titers: 400, epoch: 1 | loss: 0.6432170\n",
      "\tspeed: 0.0480s/iter; left time: 415.0435s\n",
      "\titers: 500, epoch: 1 | loss: 0.6418213\n",
      "\tspeed: 0.0478s/iter; left time: 407.8902s\n",
      "\titers: 600, epoch: 1 | loss: 0.6962131\n",
      "\tspeed: 0.0477s/iter; left time: 402.3515s\n",
      "\titers: 700, epoch: 1 | loss: 0.6652902\n",
      "\tspeed: 0.0476s/iter; left time: 397.4173s\n",
      "\titers: 800, epoch: 1 | loss: 0.6485575\n",
      "\tspeed: 0.0476s/iter; left time: 391.9822s\n",
      "\titers: 900, epoch: 1 | loss: 0.6165783\n",
      "\tspeed: 0.0479s/iter; left time: 389.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.38s\n",
      "Steps: 904 | Train Loss: 0.7043722 Vali Loss: 0.7044099 Test Loss: 0.7934921\n",
      "Validation loss decreased (inf --> 0.704410).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5258688\n",
      "\tspeed: 0.1185s/iter; left time: 952.1371s\n",
      "\titers: 200, epoch: 2 | loss: 0.5637795\n",
      "\tspeed: 0.0477s/iter; left time: 378.3946s\n",
      "\titers: 300, epoch: 2 | loss: 0.4972985\n",
      "\tspeed: 0.0475s/iter; left time: 372.3561s\n",
      "\titers: 400, epoch: 2 | loss: 0.5150353\n",
      "\tspeed: 0.0477s/iter; left time: 368.6878s\n",
      "\titers: 500, epoch: 2 | loss: 0.4983087\n",
      "\tspeed: 0.0477s/iter; left time: 364.4167s\n",
      "\titers: 600, epoch: 2 | loss: 0.5076133\n",
      "\tspeed: 0.0479s/iter; left time: 360.8547s\n",
      "\titers: 700, epoch: 2 | loss: 0.5290806\n",
      "\tspeed: 0.0476s/iter; left time: 353.9898s\n",
      "\titers: 800, epoch: 2 | loss: 0.4902735\n",
      "\tspeed: 0.0469s/iter; left time: 344.1174s\n",
      "\titers: 900, epoch: 2 | loss: 0.4747526\n",
      "\tspeed: 0.0477s/iter; left time: 345.1757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.26s\n",
      "Steps: 904 | Train Loss: 0.5341266 Vali Loss: 0.6049233 Test Loss: 0.6428112\n",
      "Validation loss decreased (0.704410 --> 0.604923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4757680\n",
      "\tspeed: 0.1167s/iter; left time: 832.1777s\n",
      "\titers: 200, epoch: 3 | loss: 0.5231443\n",
      "\tspeed: 0.0477s/iter; left time: 335.3677s\n",
      "\titers: 300, epoch: 3 | loss: 0.4881614\n",
      "\tspeed: 0.0476s/iter; left time: 329.7139s\n",
      "\titers: 400, epoch: 3 | loss: 0.4571269\n",
      "\tspeed: 0.0477s/iter; left time: 325.7557s\n",
      "\titers: 500, epoch: 3 | loss: 0.4369162\n",
      "\tspeed: 0.0474s/iter; left time: 319.2730s\n",
      "\titers: 600, epoch: 3 | loss: 0.4874011\n",
      "\tspeed: 0.0474s/iter; left time: 314.5178s\n",
      "\titers: 700, epoch: 3 | loss: 0.4290618\n",
      "\tspeed: 0.0478s/iter; left time: 312.5932s\n",
      "\titers: 800, epoch: 3 | loss: 0.4576441\n",
      "\tspeed: 0.0475s/iter; left time: 305.6016s\n",
      "\titers: 900, epoch: 3 | loss: 0.4671273\n",
      "\tspeed: 0.0473s/iter; left time: 299.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.4611585 Vali Loss: 0.6028454 Test Loss: 0.6184371\n",
      "Validation loss decreased (0.604923 --> 0.602845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3998677\n",
      "\tspeed: 0.1168s/iter; left time: 727.2765s\n",
      "\titers: 200, epoch: 4 | loss: 0.4132229\n",
      "\tspeed: 0.0479s/iter; left time: 293.3200s\n",
      "\titers: 300, epoch: 4 | loss: 0.4334919\n",
      "\tspeed: 0.0477s/iter; left time: 287.5304s\n",
      "\titers: 400, epoch: 4 | loss: 0.4044308\n",
      "\tspeed: 0.0482s/iter; left time: 285.9834s\n",
      "\titers: 500, epoch: 4 | loss: 0.4421014\n",
      "\tspeed: 0.0479s/iter; left time: 279.1623s\n",
      "\titers: 600, epoch: 4 | loss: 0.3875317\n",
      "\tspeed: 0.0469s/iter; left time: 268.9028s\n",
      "\titers: 700, epoch: 4 | loss: 0.4230910\n",
      "\tspeed: 0.0480s/iter; left time: 270.0182s\n",
      "\titers: 800, epoch: 4 | loss: 0.3707693\n",
      "\tspeed: 0.0478s/iter; left time: 264.2625s\n",
      "\titers: 900, epoch: 4 | loss: 0.3769258\n",
      "\tspeed: 0.0478s/iter; left time: 259.5549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.4218997 Vali Loss: 0.5859396 Test Loss: 0.6591363\n",
      "Validation loss decreased (0.602845 --> 0.585940).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3925479\n",
      "\tspeed: 0.1150s/iter; left time: 612.1783s\n",
      "\titers: 200, epoch: 5 | loss: 0.4102021\n",
      "\tspeed: 0.0475s/iter; left time: 248.3227s\n",
      "\titers: 300, epoch: 5 | loss: 0.3620060\n",
      "\tspeed: 0.0472s/iter; left time: 241.6479s\n",
      "\titers: 400, epoch: 5 | loss: 0.3668549\n",
      "\tspeed: 0.0473s/iter; left time: 237.8696s\n",
      "\titers: 500, epoch: 5 | loss: 0.3692132\n",
      "\tspeed: 0.0474s/iter; left time: 233.2102s\n",
      "\titers: 600, epoch: 5 | loss: 0.4087869\n",
      "\tspeed: 0.0473s/iter; left time: 228.2993s\n",
      "\titers: 700, epoch: 5 | loss: 0.4011775\n",
      "\tspeed: 0.0477s/iter; left time: 225.4452s\n",
      "\titers: 800, epoch: 5 | loss: 0.3626934\n",
      "\tspeed: 0.0478s/iter; left time: 220.8441s\n",
      "\titers: 900, epoch: 5 | loss: 0.3683335\n",
      "\tspeed: 0.0478s/iter; left time: 216.2912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.3884230 Vali Loss: 0.5717269 Test Loss: 0.6363498\n",
      "Validation loss decreased (0.585940 --> 0.571727).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3924609\n",
      "\tspeed: 0.1159s/iter; left time: 512.3896s\n",
      "\titers: 200, epoch: 6 | loss: 0.3637329\n",
      "\tspeed: 0.0478s/iter; left time: 206.5110s\n",
      "\titers: 300, epoch: 6 | loss: 0.3533712\n",
      "\tspeed: 0.0478s/iter; left time: 201.9557s\n",
      "\titers: 400, epoch: 6 | loss: 0.3886940\n",
      "\tspeed: 0.0477s/iter; left time: 196.4489s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682318\n",
      "\tspeed: 0.0478s/iter; left time: 192.2112s\n",
      "\titers: 600, epoch: 6 | loss: 0.3522940\n",
      "\tspeed: 0.0478s/iter; left time: 187.4405s\n",
      "\titers: 700, epoch: 6 | loss: 0.3701428\n",
      "\tspeed: 0.0479s/iter; left time: 182.9580s\n",
      "\titers: 800, epoch: 6 | loss: 0.3493035\n",
      "\tspeed: 0.0477s/iter; left time: 177.3458s\n",
      "\titers: 900, epoch: 6 | loss: 0.3459255\n",
      "\tspeed: 0.0476s/iter; left time: 172.3546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.38s\n",
      "Steps: 904 | Train Loss: 0.3607185 Vali Loss: 0.5945458 Test Loss: 0.6467904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3271553\n",
      "\tspeed: 0.1004s/iter; left time: 353.0381s\n",
      "\titers: 200, epoch: 7 | loss: 0.3415232\n",
      "\tspeed: 0.0468s/iter; left time: 159.9356s\n",
      "\titers: 300, epoch: 7 | loss: 0.3429954\n",
      "\tspeed: 0.0385s/iter; left time: 127.5450s\n",
      "\titers: 400, epoch: 7 | loss: 0.3336126\n",
      "\tspeed: 0.0354s/iter; left time: 113.7266s\n",
      "\titers: 500, epoch: 7 | loss: 0.3125392\n",
      "\tspeed: 0.0354s/iter; left time: 110.2424s\n",
      "\titers: 600, epoch: 7 | loss: 0.3629393\n",
      "\tspeed: 0.0354s/iter; left time: 106.6926s\n",
      "\titers: 700, epoch: 7 | loss: 0.3249076\n",
      "\tspeed: 0.0354s/iter; left time: 103.1920s\n",
      "\titers: 800, epoch: 7 | loss: 0.3575486\n",
      "\tspeed: 0.0354s/iter; left time: 99.7040s\n",
      "\titers: 900, epoch: 7 | loss: 0.3155114\n",
      "\tspeed: 0.0355s/iter; left time: 96.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 904 | Train Loss: 0.3354452 Vali Loss: 0.5961151 Test Loss: 0.6505117\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3284198\n",
      "\tspeed: 0.1115s/iter; left time: 291.4194s\n",
      "\titers: 200, epoch: 8 | loss: 0.2889812\n",
      "\tspeed: 0.0474s/iter; left time: 119.0441s\n",
      "\titers: 300, epoch: 8 | loss: 0.3065237\n",
      "\tspeed: 0.0476s/iter; left time: 114.8926s\n",
      "\titers: 400, epoch: 8 | loss: 0.3156983\n",
      "\tspeed: 0.0477s/iter; left time: 110.2330s\n",
      "\titers: 500, epoch: 8 | loss: 0.3216363\n",
      "\tspeed: 0.0477s/iter; left time: 105.5066s\n",
      "\titers: 600, epoch: 8 | loss: 0.2931251\n",
      "\tspeed: 0.0476s/iter; left time: 100.6482s\n",
      "\titers: 700, epoch: 8 | loss: 0.3140359\n",
      "\tspeed: 0.0474s/iter; left time: 95.4709s\n",
      "\titers: 800, epoch: 8 | loss: 0.3071438\n",
      "\tspeed: 0.0476s/iter; left time: 91.0155s\n",
      "\titers: 900, epoch: 8 | loss: 0.3071236\n",
      "\tspeed: 0.0474s/iter; left time: 86.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.3142988 Vali Loss: 0.5842171 Test Loss: 0.6662861\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:37667352.0, rmse:6137.37353515625, mae:3862.161865234375, rse:0.3056434094905853\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7432280\n",
      "\tspeed: 0.0843s/iter; left time: 751.9843s\n",
      "\titers: 200, epoch: 1 | loss: 0.7924978\n",
      "\tspeed: 0.0543s/iter; left time: 479.1086s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319275\n",
      "\tspeed: 0.0544s/iter; left time: 473.9982s\n",
      "\titers: 400, epoch: 1 | loss: 0.7333213\n",
      "\tspeed: 0.0543s/iter; left time: 467.7469s\n",
      "\titers: 500, epoch: 1 | loss: 0.7180915\n",
      "\tspeed: 0.0543s/iter; left time: 462.3477s\n",
      "\titers: 600, epoch: 1 | loss: 0.7430111\n",
      "\tspeed: 0.0540s/iter; left time: 454.9663s\n",
      "\titers: 700, epoch: 1 | loss: 0.7065840\n",
      "\tspeed: 0.0541s/iter; left time: 449.8325s\n",
      "\titers: 800, epoch: 1 | loss: 0.6746759\n",
      "\tspeed: 0.0541s/iter; left time: 444.5706s\n",
      "\titers: 900, epoch: 1 | loss: 0.7036165\n",
      "\tspeed: 0.0542s/iter; left time: 440.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.64s\n",
      "Steps: 902 | Train Loss: 0.7345527 Vali Loss: 0.7737989 Test Loss: 0.8803952\n",
      "Validation loss decreased (inf --> 0.773799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6868786\n",
      "\tspeed: 0.1330s/iter; left time: 1066.7057s\n",
      "\titers: 200, epoch: 2 | loss: 0.6350537\n",
      "\tspeed: 0.0533s/iter; left time: 422.0502s\n",
      "\titers: 300, epoch: 2 | loss: 0.6338754\n",
      "\tspeed: 0.0533s/iter; left time: 416.5883s\n",
      "\titers: 400, epoch: 2 | loss: 0.5741463\n",
      "\tspeed: 0.0535s/iter; left time: 412.8525s\n",
      "\titers: 500, epoch: 2 | loss: 0.5673126\n",
      "\tspeed: 0.0533s/iter; left time: 406.2043s\n",
      "\titers: 600, epoch: 2 | loss: 0.5258488\n",
      "\tspeed: 0.0534s/iter; left time: 401.4329s\n",
      "\titers: 700, epoch: 2 | loss: 0.5364168\n",
      "\tspeed: 0.0535s/iter; left time: 397.1914s\n",
      "\titers: 800, epoch: 2 | loss: 0.5658613\n",
      "\tspeed: 0.0535s/iter; left time: 391.6061s\n",
      "\titers: 900, epoch: 2 | loss: 0.4998148\n",
      "\tspeed: 0.0533s/iter; left time: 384.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.5770481 Vali Loss: 0.6151103 Test Loss: 0.6770754\n",
      "Validation loss decreased (0.773799 --> 0.615110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5180974\n",
      "\tspeed: 0.1327s/iter; left time: 944.1720s\n",
      "\titers: 200, epoch: 3 | loss: 0.4734910\n",
      "\tspeed: 0.0534s/iter; left time: 374.9763s\n",
      "\titers: 300, epoch: 3 | loss: 0.4999493\n",
      "\tspeed: 0.0534s/iter; left time: 369.2577s\n",
      "\titers: 400, epoch: 3 | loss: 0.5183615\n",
      "\tspeed: 0.0532s/iter; left time: 362.6153s\n",
      "\titers: 500, epoch: 3 | loss: 0.4752620\n",
      "\tspeed: 0.0535s/iter; left time: 359.4321s\n",
      "\titers: 600, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0532s/iter; left time: 352.3041s\n",
      "\titers: 700, epoch: 3 | loss: 0.5015286\n",
      "\tspeed: 0.0536s/iter; left time: 349.5358s\n",
      "\titers: 800, epoch: 3 | loss: 0.4726277\n",
      "\tspeed: 0.0535s/iter; left time: 343.2718s\n",
      "\titers: 900, epoch: 3 | loss: 0.4481099\n",
      "\tspeed: 0.0533s/iter; left time: 336.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.4826820 Vali Loss: 0.6081653 Test Loss: 0.6789765\n",
      "Validation loss decreased (0.615110 --> 0.608165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4161480\n",
      "\tspeed: 0.1330s/iter; left time: 826.8955s\n",
      "\titers: 200, epoch: 4 | loss: 0.4256495\n",
      "\tspeed: 0.0544s/iter; left time: 332.5436s\n",
      "\titers: 300, epoch: 4 | loss: 0.4600742\n",
      "\tspeed: 0.0543s/iter; left time: 326.3739s\n",
      "\titers: 400, epoch: 4 | loss: 0.4594116\n",
      "\tspeed: 0.0542s/iter; left time: 320.3390s\n",
      "\titers: 500, epoch: 4 | loss: 0.4682472\n",
      "\tspeed: 0.0542s/iter; left time: 315.3531s\n",
      "\titers: 600, epoch: 4 | loss: 0.4279153\n",
      "\tspeed: 0.0542s/iter; left time: 309.6010s\n",
      "\titers: 700, epoch: 4 | loss: 0.4593164\n",
      "\tspeed: 0.0530s/iter; left time: 297.3352s\n",
      "\titers: 800, epoch: 4 | loss: 0.4496114\n",
      "\tspeed: 0.0533s/iter; left time: 294.0028s\n",
      "\titers: 900, epoch: 4 | loss: 0.4105683\n",
      "\tspeed: 0.0535s/iter; left time: 289.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.84s\n",
      "Steps: 902 | Train Loss: 0.4414160 Vali Loss: 0.6163542 Test Loss: 0.6771622\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4379938\n",
      "\tspeed: 0.1286s/iter; left time: 683.1379s\n",
      "\titers: 200, epoch: 5 | loss: 0.4133421\n",
      "\tspeed: 0.0535s/iter; left time: 278.6723s\n",
      "\titers: 300, epoch: 5 | loss: 0.4182612\n",
      "\tspeed: 0.0534s/iter; left time: 273.2545s\n",
      "\titers: 400, epoch: 5 | loss: 0.4328923\n",
      "\tspeed: 0.0535s/iter; left time: 267.9617s\n",
      "\titers: 500, epoch: 5 | loss: 0.3644622\n",
      "\tspeed: 0.0538s/iter; left time: 264.2711s\n",
      "\titers: 600, epoch: 5 | loss: 0.4028292\n",
      "\tspeed: 0.0534s/iter; left time: 256.9064s\n",
      "\titers: 700, epoch: 5 | loss: 0.4268283\n",
      "\tspeed: 0.0535s/iter; left time: 252.2309s\n",
      "\titers: 800, epoch: 5 | loss: 0.3848646\n",
      "\tspeed: 0.0534s/iter; left time: 246.3605s\n",
      "\titers: 900, epoch: 5 | loss: 0.3503802\n",
      "\tspeed: 0.0534s/iter; left time: 240.8134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.4047783 Vali Loss: 0.6162719 Test Loss: 0.7085742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3884669\n",
      "\tspeed: 0.1287s/iter; left time: 567.5034s\n",
      "\titers: 200, epoch: 6 | loss: 0.3919015\n",
      "\tspeed: 0.0536s/iter; left time: 231.0094s\n",
      "\titers: 300, epoch: 6 | loss: 0.3709927\n",
      "\tspeed: 0.0535s/iter; left time: 225.3098s\n",
      "\titers: 400, epoch: 6 | loss: 0.4029219\n",
      "\tspeed: 0.0536s/iter; left time: 220.1941s\n",
      "\titers: 500, epoch: 6 | loss: 0.3664319\n",
      "\tspeed: 0.0534s/iter; left time: 214.1027s\n",
      "\titers: 600, epoch: 6 | loss: 0.3598861\n",
      "\tspeed: 0.0533s/iter; left time: 208.3620s\n",
      "\titers: 700, epoch: 6 | loss: 0.3954958\n",
      "\tspeed: 0.0532s/iter; left time: 202.7783s\n",
      "\titers: 800, epoch: 6 | loss: 0.3583177\n",
      "\tspeed: 0.0533s/iter; left time: 197.9797s\n",
      "\titers: 900, epoch: 6 | loss: 0.3972457\n",
      "\tspeed: 0.0532s/iter; left time: 192.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.33s\n",
      "Steps: 902 | Train Loss: 0.3720988 Vali Loss: 0.6230050 Test Loss: 0.7020154\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:39692484.0, rmse:6300.197265625, mae:4161.8623046875, rse:0.31390610337257385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8304041\n",
      "\tspeed: 0.0551s/iter; left time: 491.1625s\n",
      "\titers: 200, epoch: 1 | loss: 0.7432838\n",
      "\tspeed: 0.0535s/iter; left time: 472.0525s\n",
      "\titers: 300, epoch: 1 | loss: 0.7456986\n",
      "\tspeed: 0.0535s/iter; left time: 466.8380s\n",
      "\titers: 400, epoch: 1 | loss: 0.6537443\n",
      "\tspeed: 0.0538s/iter; left time: 463.7744s\n",
      "\titers: 500, epoch: 1 | loss: 0.7623785\n",
      "\tspeed: 0.0541s/iter; left time: 460.6937s\n",
      "\titers: 600, epoch: 1 | loss: 0.6968405\n",
      "\tspeed: 0.0544s/iter; left time: 458.1209s\n",
      "\titers: 700, epoch: 1 | loss: 0.6879818\n",
      "\tspeed: 0.0541s/iter; left time: 450.1253s\n",
      "\titers: 800, epoch: 1 | loss: 0.6725203\n",
      "\tspeed: 0.0542s/iter; left time: 445.2599s\n",
      "\titers: 900, epoch: 1 | loss: 0.6846584\n",
      "\tspeed: 0.0540s/iter; left time: 438.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.84s\n",
      "Steps: 902 | Train Loss: 0.7359149 Vali Loss: 0.7748347 Test Loss: 0.8825503\n",
      "Validation loss decreased (inf --> 0.774835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6500419\n",
      "\tspeed: 0.1366s/iter; left time: 1095.0127s\n",
      "\titers: 200, epoch: 2 | loss: 0.6053997\n",
      "\tspeed: 0.0546s/iter; left time: 432.1073s\n",
      "\titers: 300, epoch: 2 | loss: 0.5713702\n",
      "\tspeed: 0.0545s/iter; left time: 426.3546s\n",
      "\titers: 400, epoch: 2 | loss: 0.5136937\n",
      "\tspeed: 0.0541s/iter; left time: 417.9499s\n",
      "\titers: 500, epoch: 2 | loss: 0.5401712\n",
      "\tspeed: 0.0545s/iter; left time: 415.3483s\n",
      "\titers: 600, epoch: 2 | loss: 0.5388100\n",
      "\tspeed: 0.0542s/iter; left time: 407.6319s\n",
      "\titers: 700, epoch: 2 | loss: 0.5284830\n",
      "\tspeed: 0.0544s/iter; left time: 403.7326s\n",
      "\titers: 800, epoch: 2 | loss: 0.4723913\n",
      "\tspeed: 0.0543s/iter; left time: 397.6314s\n",
      "\titers: 900, epoch: 2 | loss: 0.4965907\n",
      "\tspeed: 0.0543s/iter; left time: 391.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.32s\n",
      "Steps: 902 | Train Loss: 0.5826588 Vali Loss: 0.6296505 Test Loss: 0.6879032\n",
      "Validation loss decreased (0.774835 --> 0.629650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4773910\n",
      "\tspeed: 0.1356s/iter; left time: 964.8443s\n",
      "\titers: 200, epoch: 3 | loss: 0.5161944\n",
      "\tspeed: 0.0536s/iter; left time: 375.9894s\n",
      "\titers: 300, epoch: 3 | loss: 0.5555186\n",
      "\tspeed: 0.0534s/iter; left time: 369.6094s\n",
      "\titers: 400, epoch: 3 | loss: 0.4888589\n",
      "\tspeed: 0.0536s/iter; left time: 365.2699s\n",
      "\titers: 500, epoch: 3 | loss: 0.4900426\n",
      "\tspeed: 0.0537s/iter; left time: 360.8040s\n",
      "\titers: 600, epoch: 3 | loss: 0.4695053\n",
      "\tspeed: 0.0535s/iter; left time: 354.0774s\n",
      "\titers: 700, epoch: 3 | loss: 0.4767488\n",
      "\tspeed: 0.0532s/iter; left time: 347.0163s\n",
      "\titers: 800, epoch: 3 | loss: 0.4401937\n",
      "\tspeed: 0.0533s/iter; left time: 341.8295s\n",
      "\titers: 900, epoch: 3 | loss: 0.4702183\n",
      "\tspeed: 0.0534s/iter; left time: 337.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.4825615 Vali Loss: 0.6113480 Test Loss: 0.6961012\n",
      "Validation loss decreased (0.629650 --> 0.611348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552673\n",
      "\tspeed: 0.1333s/iter; left time: 828.3912s\n",
      "\titers: 200, epoch: 4 | loss: 0.4182002\n",
      "\tspeed: 0.0535s/iter; left time: 327.2015s\n",
      "\titers: 300, epoch: 4 | loss: 0.4482407\n",
      "\tspeed: 0.0533s/iter; left time: 320.5387s\n",
      "\titers: 400, epoch: 4 | loss: 0.4379449\n",
      "\tspeed: 0.0535s/iter; left time: 316.2984s\n",
      "\titers: 500, epoch: 4 | loss: 0.4325068\n",
      "\tspeed: 0.0537s/iter; left time: 312.2006s\n",
      "\titers: 600, epoch: 4 | loss: 0.4607576\n",
      "\tspeed: 0.0536s/iter; left time: 306.5717s\n",
      "\titers: 700, epoch: 4 | loss: 0.4113523\n",
      "\tspeed: 0.0535s/iter; left time: 300.3203s\n",
      "\titers: 800, epoch: 4 | loss: 0.4501538\n",
      "\tspeed: 0.0534s/iter; left time: 294.3266s\n",
      "\titers: 900, epoch: 4 | loss: 0.4170002\n",
      "\tspeed: 0.0537s/iter; left time: 290.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.4399437 Vali Loss: 0.6030498 Test Loss: 0.6659666\n",
      "Validation loss decreased (0.611348 --> 0.603050).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3798306\n",
      "\tspeed: 0.1336s/iter; left time: 709.9540s\n",
      "\titers: 200, epoch: 5 | loss: 0.4068514\n",
      "\tspeed: 0.0538s/iter; left time: 280.2065s\n",
      "\titers: 300, epoch: 5 | loss: 0.4011664\n",
      "\tspeed: 0.0536s/iter; left time: 273.8673s\n",
      "\titers: 400, epoch: 5 | loss: 0.4041094\n",
      "\tspeed: 0.0535s/iter; left time: 268.1497s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307121\n",
      "\tspeed: 0.0535s/iter; left time: 262.9106s\n",
      "\titers: 600, epoch: 5 | loss: 0.3717445\n",
      "\tspeed: 0.0537s/iter; left time: 258.2801s\n",
      "\titers: 700, epoch: 5 | loss: 0.3898468\n",
      "\tspeed: 0.0535s/iter; left time: 252.2196s\n",
      "\titers: 800, epoch: 5 | loss: 0.3740286\n",
      "\tspeed: 0.0536s/iter; left time: 247.2319s\n",
      "\titers: 900, epoch: 5 | loss: 0.4056983\n",
      "\tspeed: 0.0535s/iter; left time: 241.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.3987529 Vali Loss: 0.6140500 Test Loss: 0.6948121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3816989\n",
      "\tspeed: 0.1296s/iter; left time: 571.7230s\n",
      "\titers: 200, epoch: 6 | loss: 0.3667590\n",
      "\tspeed: 0.0533s/iter; left time: 229.7297s\n",
      "\titers: 300, epoch: 6 | loss: 0.3843067\n",
      "\tspeed: 0.0533s/iter; left time: 224.3219s\n",
      "\titers: 400, epoch: 6 | loss: 0.3731487\n",
      "\tspeed: 0.0537s/iter; left time: 220.6474s\n",
      "\titers: 500, epoch: 6 | loss: 0.3392414\n",
      "\tspeed: 0.0533s/iter; left time: 213.8691s\n",
      "\titers: 600, epoch: 6 | loss: 0.3976587\n",
      "\tspeed: 0.0534s/iter; left time: 208.9248s\n",
      "\titers: 700, epoch: 6 | loss: 0.3745137\n",
      "\tspeed: 0.0534s/iter; left time: 203.4178s\n",
      "\titers: 800, epoch: 6 | loss: 0.3319488\n",
      "\tspeed: 0.0533s/iter; left time: 197.8471s\n",
      "\titers: 900, epoch: 6 | loss: 0.3574228\n",
      "\tspeed: 0.0535s/iter; left time: 193.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.3675826 Vali Loss: 0.6191680 Test Loss: 0.6964089\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3543683\n",
      "\tspeed: 0.1310s/iter; left time: 459.6289s\n",
      "\titers: 200, epoch: 7 | loss: 0.3584929\n",
      "\tspeed: 0.0537s/iter; left time: 183.0792s\n",
      "\titers: 300, epoch: 7 | loss: 0.3529427\n",
      "\tspeed: 0.0536s/iter; left time: 177.3488s\n",
      "\titers: 400, epoch: 7 | loss: 0.3259368\n",
      "\tspeed: 0.0537s/iter; left time: 172.3941s\n",
      "\titers: 500, epoch: 7 | loss: 0.3047194\n",
      "\tspeed: 0.0536s/iter; left time: 166.5526s\n",
      "\titers: 600, epoch: 7 | loss: 0.3544034\n",
      "\tspeed: 0.0535s/iter; left time: 161.0382s\n",
      "\titers: 700, epoch: 7 | loss: 0.3244225\n",
      "\tspeed: 0.0535s/iter; left time: 155.7545s\n",
      "\titers: 800, epoch: 7 | loss: 0.3500791\n",
      "\tspeed: 0.0533s/iter; left time: 149.7624s\n",
      "\titers: 900, epoch: 7 | loss: 0.3353058\n",
      "\tspeed: 0.0535s/iter; left time: 144.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.3403212 Vali Loss: 0.6217956 Test Loss: 0.7023885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:40591140.0, rmse:6371.11767578125, mae:4053.178955078125, rse:0.3174396753311157\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "informer_results = []\n",
    "# Define a function to extract metrics for both iterations\n",
    "def extract_metrics_from_output(output, itr):\n",
    "    # Define a combined pattern to capture all metrics in a single match\n",
    "    pattern = re.compile(\n",
    "        r\"mse:\\s*([\\d.]+),\\s*rmse:\\s*([\\d.]+),\\s*mae:\\s*([\\d.]+),\\s*rse:\\s*([\\d.]+)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Join the output lines into a single string for easier regex matching\n",
    "    output_str = \"\\n\".join(output)\n",
    "    \n",
    "    # Debug: Print the output string to ensure it contains the metrics\n",
    "    #print(\"Captured Output:\\n\", output_str)\n",
    "    \n",
    "    # Find all matches of the combined metric pattern\n",
    "    matches = pattern.findall(output_str)\n",
    "    \n",
    "    # Ensure we have enough matches for the number of iterations requested\n",
    "    if len(matches) < itr:\n",
    "        raise ValueError(f\"Expected at least {itr} iterations, but found only {len(matches)}.\")\n",
    "    \n",
    "    # Convert each match to a tuple of floats and return the first 'itr' matches\n",
    "    return [tuple(map(float, match)) for match in matches[:itr]]\n",
    "\n",
    "# Example usage: running the subprocess and capturing the output\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Run command with --itr 2 to ensure 2 iterations are handled internally\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --inverse \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Combine the output into a single string for easier pattern matching\n",
    "            output_str = \"\".join(output)\n",
    "\n",
    "            # Extract metrics for each iteration from the captured output\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, metrics in enumerate(iteration_metrics, start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"MSE: {metrics[0]}, RMSE: {metrics[1]}, MAE: {metrics[2]}, RSE: {metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results list\n",
    "                informer_results.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20262616.0</td>\n",
       "      <td>4501.4014</td>\n",
       "      <td>3016.6672</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19436216.0</td>\n",
       "      <td>4408.6523</td>\n",
       "      <td>2875.5586</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20156686.0</td>\n",
       "      <td>4489.6196</td>\n",
       "      <td>2999.1426</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19259186.0</td>\n",
       "      <td>4388.5288</td>\n",
       "      <td>2873.7637</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>34543984.0</td>\n",
       "      <td>5877.4131</td>\n",
       "      <td>4100.0752</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36986492.0</td>\n",
       "      <td>6081.6519</td>\n",
       "      <td>4114.8584</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38815100.0</td>\n",
       "      <td>6230.1768</td>\n",
       "      <td>4220.9731</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40210260.0</td>\n",
       "      <td>6341.1562</td>\n",
       "      <td>4216.4253</td>\n",
       "      <td>0.3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19648216.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2762.4336</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19207616.0</td>\n",
       "      <td>4382.6494</td>\n",
       "      <td>2741.9597</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20262616.0  4501.4014  3016.6672  0.2238\n",
       "              2         24        19436216.0  4408.6523  2875.5586  0.2192\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "RMSE          1         24        20156686.0  4489.6196  2999.1426  0.2232\n",
       "              2         24        19259186.0  4388.5288  2873.7637  0.2182\n",
       "              1         96        34543984.0  5877.4131  4100.0752  0.2927\n",
       "              2         96        36986492.0  6081.6519  4114.8584  0.3029\n",
       "              1         168       38815100.0  6230.1768  4220.9731  0.3104\n",
       "              2         168       40210260.0  6341.1562  4216.4253  0.3159\n",
       "MAE           1         24        19648216.0  4432.6309  2762.4336  0.2204\n",
       "              2         24        19207616.0  4382.6494  2741.9597  0.2179\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the collected data into a DataFrame and save as CSV\n",
    "informer_df = convert_results_into_df(informer_results, path_dir, csv_name)\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MAE</th>\n",
       "      <th>24</th>\n",
       "      <td>19427916.0</td>\n",
       "      <td>4407.6401</td>\n",
       "      <td>2752.1967</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MSE</th>\n",
       "      <th>24</th>\n",
       "      <td>19849416.0</td>\n",
       "      <td>4455.0269</td>\n",
       "      <td>2946.1129</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RMSE</th>\n",
       "      <th>24</th>\n",
       "      <td>19707936.0</td>\n",
       "      <td>4439.0742</td>\n",
       "      <td>2936.4531</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35765238.0</td>\n",
       "      <td>5979.5325</td>\n",
       "      <td>4107.4668</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>39512680.0</td>\n",
       "      <td>6285.6665</td>\n",
       "      <td>4218.6992</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Loss_function Pred_len                                          \n",
       "MAE           24        19427916.0  4407.6401  2752.1967  0.2192\n",
       "              96        39457330.0  6279.8901  3962.9127  0.3127\n",
       "              168       40141812.0  6335.6575  4107.5206  0.3157\n",
       "MSE           24        19849416.0  4455.0269  2946.1129  0.2215\n",
       "              96        36879912.0  6072.1143  4183.2212  0.3024\n",
       "              168       39366112.0  6272.8247  4301.4302  0.3125\n",
       "RMSE          24        19707936.0  4439.0742  2936.4531  0.2207\n",
       "              96        35765238.0  5979.5325  4107.4668  0.2978\n",
       "              168       39512680.0  6285.6665  4218.6992  0.3132"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "inf_res_scaled = pd.read_csv(os.path.join(path_dir, csv_name))\n",
    "inf_res_scaled = inf_res_scaled.groupby(['Loss_function', 'Pred_len']).mean().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test for PatchTST unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4062752\n",
      "\tspeed: 0.0670s/iter; left time: 591.7244s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490731\n",
      "\tspeed: 0.0423s/iter; left time: 369.1628s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447189\n",
      "\tspeed: 0.0423s/iter; left time: 364.9744s\n",
      "\titers: 400, epoch: 1 | loss: 0.4202814\n",
      "\tspeed: 0.0423s/iter; left time: 360.8832s\n",
      "\titers: 500, epoch: 1 | loss: 0.3825126\n",
      "\tspeed: 0.0423s/iter; left time: 356.6922s\n",
      "\titers: 600, epoch: 1 | loss: 0.4463949\n",
      "\tspeed: 0.0423s/iter; left time: 352.2706s\n",
      "\titers: 700, epoch: 1 | loss: 0.3554860\n",
      "\tspeed: 0.0423s/iter; left time: 348.2319s\n",
      "\titers: 800, epoch: 1 | loss: 0.3329375\n",
      "\tspeed: 0.0423s/iter; left time: 343.9961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.3779395 Vali Loss: 0.4368218 Test Loss: 0.4749455\n",
      "Validation loss decreased (inf --> 0.436822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4321591\n",
      "\tspeed: 0.1508s/iter; left time: 1196.8340s\n",
      "\titers: 200, epoch: 2 | loss: 0.3975809\n",
      "\tspeed: 0.0423s/iter; left time: 331.5500s\n",
      "\titers: 300, epoch: 2 | loss: 0.2834045\n",
      "\tspeed: 0.0423s/iter; left time: 327.4759s\n",
      "\titers: 400, epoch: 2 | loss: 0.2936918\n",
      "\tspeed: 0.0423s/iter; left time: 323.0621s\n",
      "\titers: 500, epoch: 2 | loss: 0.2714845\n",
      "\tspeed: 0.0423s/iter; left time: 318.7826s\n",
      "\titers: 600, epoch: 2 | loss: 0.2872095\n",
      "\tspeed: 0.0423s/iter; left time: 314.6603s\n",
      "\titers: 700, epoch: 2 | loss: 0.3408362\n",
      "\tspeed: 0.0423s/iter; left time: 310.4448s\n",
      "\titers: 800, epoch: 2 | loss: 0.2582404\n",
      "\tspeed: 0.0423s/iter; left time: 306.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 893 | Train Loss: 0.3092715 Vali Loss: 0.4199357 Test Loss: 0.4742230\n",
      "Validation loss decreased (0.436822 --> 0.419936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2012810\n",
      "\tspeed: 0.1517s/iter; left time: 1068.9135s\n",
      "\titers: 200, epoch: 3 | loss: 0.2745693\n",
      "\tspeed: 0.0423s/iter; left time: 293.8992s\n",
      "\titers: 300, epoch: 3 | loss: 0.2421604\n",
      "\tspeed: 0.0423s/iter; left time: 289.7526s\n",
      "\titers: 400, epoch: 3 | loss: 0.2551808\n",
      "\tspeed: 0.0423s/iter; left time: 285.5984s\n",
      "\titers: 500, epoch: 3 | loss: 0.2312551\n",
      "\tspeed: 0.0423s/iter; left time: 281.2982s\n",
      "\titers: 600, epoch: 3 | loss: 0.2817569\n",
      "\tspeed: 0.0423s/iter; left time: 277.0796s\n",
      "\titers: 700, epoch: 3 | loss: 0.1640334\n",
      "\tspeed: 0.0424s/iter; left time: 273.1153s\n",
      "\titers: 800, epoch: 3 | loss: 0.3372894\n",
      "\tspeed: 0.0423s/iter; left time: 268.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 893 | Train Loss: 0.2761120 Vali Loss: 0.4101853 Test Loss: 0.4503999\n",
      "Validation loss decreased (0.419936 --> 0.410185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537383\n",
      "\tspeed: 0.1511s/iter; left time: 929.5799s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325063\n",
      "\tspeed: 0.0423s/iter; left time: 256.1094s\n",
      "\titers: 300, epoch: 4 | loss: 0.2676595\n",
      "\tspeed: 0.0423s/iter; left time: 251.8302s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086366\n",
      "\tspeed: 0.0423s/iter; left time: 247.6670s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853133\n",
      "\tspeed: 0.0424s/iter; left time: 243.6811s\n",
      "\titers: 600, epoch: 4 | loss: 0.2249607\n",
      "\tspeed: 0.0423s/iter; left time: 239.1265s\n",
      "\titers: 700, epoch: 4 | loss: 0.2668764\n",
      "\tspeed: 0.0424s/iter; left time: 235.3041s\n",
      "\titers: 800, epoch: 4 | loss: 0.2927850\n",
      "\tspeed: 0.0424s/iter; left time: 231.2678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.2687885 Vali Loss: 0.4336080 Test Loss: 0.4734263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2390144\n",
      "\tspeed: 0.1490s/iter; left time: 783.5232s\n",
      "\titers: 200, epoch: 5 | loss: 0.1977134\n",
      "\tspeed: 0.0423s/iter; left time: 217.9737s\n",
      "\titers: 300, epoch: 5 | loss: 0.2724915\n",
      "\tspeed: 0.0423s/iter; left time: 213.9453s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195267\n",
      "\tspeed: 0.0423s/iter; left time: 209.8818s\n",
      "\titers: 500, epoch: 5 | loss: 0.2479026\n",
      "\tspeed: 0.0423s/iter; left time: 205.4747s\n",
      "\titers: 600, epoch: 5 | loss: 0.2113601\n",
      "\tspeed: 0.0423s/iter; left time: 201.1776s\n",
      "\titers: 700, epoch: 5 | loss: 0.2392982\n",
      "\tspeed: 0.0423s/iter; left time: 196.9194s\n",
      "\titers: 800, epoch: 5 | loss: 0.2210716\n",
      "\tspeed: 0.0422s/iter; left time: 192.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.2557502 Vali Loss: 0.4083221 Test Loss: 0.4551176\n",
      "Validation loss decreased (0.410185 --> 0.408322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2018318\n",
      "\tspeed: 0.1503s/iter; left time: 656.3672s\n",
      "\titers: 200, epoch: 6 | loss: 0.2799388\n",
      "\tspeed: 0.0422s/iter; left time: 180.2093s\n",
      "\titers: 300, epoch: 6 | loss: 0.1967447\n",
      "\tspeed: 0.0422s/iter; left time: 175.9630s\n",
      "\titers: 400, epoch: 6 | loss: 0.2135415\n",
      "\tspeed: 0.0422s/iter; left time: 171.7024s\n",
      "\titers: 500, epoch: 6 | loss: 0.2062024\n",
      "\tspeed: 0.0422s/iter; left time: 167.4376s\n",
      "\titers: 600, epoch: 6 | loss: 0.2476224\n",
      "\tspeed: 0.0422s/iter; left time: 163.2864s\n",
      "\titers: 700, epoch: 6 | loss: 0.1791212\n",
      "\tspeed: 0.0422s/iter; left time: 159.0378s\n",
      "\titers: 800, epoch: 6 | loss: 0.2224586\n",
      "\tspeed: 0.0423s/iter; left time: 155.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 893 | Train Loss: 0.2370440 Vali Loss: 0.4499719 Test Loss: 0.4937295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2283527\n",
      "\tspeed: 0.1490s/iter; left time: 517.4287s\n",
      "\titers: 200, epoch: 7 | loss: 0.2216568\n",
      "\tspeed: 0.0424s/iter; left time: 142.8822s\n",
      "\titers: 300, epoch: 7 | loss: 0.2187734\n",
      "\tspeed: 0.0424s/iter; left time: 138.6808s\n",
      "\titers: 400, epoch: 7 | loss: 0.2077828\n",
      "\tspeed: 0.0423s/iter; left time: 134.2979s\n",
      "\titers: 500, epoch: 7 | loss: 0.1985875\n",
      "\tspeed: 0.0423s/iter; left time: 130.0093s\n",
      "\titers: 600, epoch: 7 | loss: 0.2054232\n",
      "\tspeed: 0.0423s/iter; left time: 125.7248s\n",
      "\titers: 700, epoch: 7 | loss: 0.1703641\n",
      "\tspeed: 0.0423s/iter; left time: 121.5158s\n",
      "\titers: 800, epoch: 7 | loss: 0.1733078\n",
      "\tspeed: 0.0422s/iter; left time: 117.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2119504 Vali Loss: 0.4550525 Test Loss: 0.5188643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2100210\n",
      "\tspeed: 0.1491s/iter; left time: 384.7571s\n",
      "\titers: 200, epoch: 8 | loss: 0.1868386\n",
      "\tspeed: 0.0422s/iter; left time: 104.7703s\n",
      "\titers: 300, epoch: 8 | loss: 0.1724563\n",
      "\tspeed: 0.0422s/iter; left time: 100.5207s\n",
      "\titers: 400, epoch: 8 | loss: 0.2129223\n",
      "\tspeed: 0.0422s/iter; left time: 96.2813s\n",
      "\titers: 500, epoch: 8 | loss: 0.2158544\n",
      "\tspeed: 0.0422s/iter; left time: 92.0758s\n",
      "\titers: 600, epoch: 8 | loss: 0.1620623\n",
      "\tspeed: 0.0423s/iter; left time: 87.9485s\n",
      "\titers: 700, epoch: 8 | loss: 0.1801844\n",
      "\tspeed: 0.0423s/iter; left time: 83.6658s\n",
      "\titers: 800, epoch: 8 | loss: 0.2255919\n",
      "\tspeed: 0.0422s/iter; left time: 79.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 893 | Train Loss: 0.1881337 Vali Loss: 0.4813017 Test Loss: 0.5380040\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:17261680.0, rmse:4154.7177734375, mae:2581.17822265625, rse:0.20658095180988312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3967359\n",
      "\tspeed: 0.0437s/iter; left time: 385.5696s\n",
      "\titers: 200, epoch: 1 | loss: 0.4064189\n",
      "\tspeed: 0.0424s/iter; left time: 369.8663s\n",
      "\titers: 300, epoch: 1 | loss: 0.2779341\n",
      "\tspeed: 0.0423s/iter; left time: 365.2927s\n",
      "\titers: 400, epoch: 1 | loss: 0.2643839\n",
      "\tspeed: 0.0423s/iter; left time: 360.8686s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900892\n",
      "\tspeed: 0.0422s/iter; left time: 356.1574s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112502\n",
      "\tspeed: 0.0423s/iter; left time: 352.0808s\n",
      "\titers: 700, epoch: 1 | loss: 0.2473065\n",
      "\tspeed: 0.0422s/iter; left time: 347.6884s\n",
      "\titers: 800, epoch: 1 | loss: 0.2575147\n",
      "\tspeed: 0.0422s/iter; left time: 343.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 893 | Train Loss: 0.3743255 Vali Loss: 0.4390815 Test Loss: 0.4765824\n",
      "Validation loss decreased (inf --> 0.439081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3144976\n",
      "\tspeed: 0.1522s/iter; left time: 1207.7796s\n",
      "\titers: 200, epoch: 2 | loss: 0.2808562\n",
      "\tspeed: 0.0423s/iter; left time: 331.2060s\n",
      "\titers: 300, epoch: 2 | loss: 0.2744709\n",
      "\tspeed: 0.0422s/iter; left time: 326.9262s\n",
      "\titers: 400, epoch: 2 | loss: 0.3588106\n",
      "\tspeed: 0.0422s/iter; left time: 322.6897s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180828\n",
      "\tspeed: 0.0422s/iter; left time: 318.4318s\n",
      "\titers: 600, epoch: 2 | loss: 0.2916528\n",
      "\tspeed: 0.0422s/iter; left time: 314.1434s\n",
      "\titers: 700, epoch: 2 | loss: 0.2639987\n",
      "\tspeed: 0.0422s/iter; left time: 309.9364s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295977\n",
      "\tspeed: 0.0422s/iter; left time: 305.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 893 | Train Loss: 0.3134294 Vali Loss: 0.4065219 Test Loss: 0.4498437\n",
      "Validation loss decreased (0.439081 --> 0.406522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2422723\n",
      "\tspeed: 0.1526s/iter; left time: 1075.1726s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763481\n",
      "\tspeed: 0.0423s/iter; left time: 293.5217s\n",
      "\titers: 300, epoch: 3 | loss: 0.2693237\n",
      "\tspeed: 0.0423s/iter; left time: 289.2466s\n",
      "\titers: 400, epoch: 3 | loss: 0.3108239\n",
      "\tspeed: 0.0423s/iter; left time: 285.4115s\n",
      "\titers: 500, epoch: 3 | loss: 0.1933685\n",
      "\tspeed: 0.0423s/iter; left time: 280.9610s\n",
      "\titers: 600, epoch: 3 | loss: 0.2856435\n",
      "\tspeed: 0.0422s/iter; left time: 276.4869s\n",
      "\titers: 700, epoch: 3 | loss: 0.2616338\n",
      "\tspeed: 0.0423s/iter; left time: 272.3817s\n",
      "\titers: 800, epoch: 3 | loss: 0.2869773\n",
      "\tspeed: 0.0423s/iter; left time: 268.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 893 | Train Loss: 0.2774806 Vali Loss: 0.4149170 Test Loss: 0.4646415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248570\n",
      "\tspeed: 0.1505s/iter; left time: 926.1064s\n",
      "\titers: 200, epoch: 4 | loss: 0.2699777\n",
      "\tspeed: 0.0423s/iter; left time: 255.7683s\n",
      "\titers: 300, epoch: 4 | loss: 0.2988690\n",
      "\tspeed: 0.0423s/iter; left time: 251.4940s\n",
      "\titers: 400, epoch: 4 | loss: 0.2862901\n",
      "\tspeed: 0.0423s/iter; left time: 247.2716s\n",
      "\titers: 500, epoch: 4 | loss: 0.2651158\n",
      "\tspeed: 0.0423s/iter; left time: 243.0862s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613765\n",
      "\tspeed: 0.0423s/iter; left time: 238.9611s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783110\n",
      "\tspeed: 0.0423s/iter; left time: 234.5767s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053535\n",
      "\tspeed: 0.0423s/iter; left time: 230.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 893 | Train Loss: 0.2820289 Vali Loss: 0.4095885 Test Loss: 0.4661101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2652097\n",
      "\tspeed: 0.1501s/iter; left time: 789.2298s\n",
      "\titers: 200, epoch: 5 | loss: 0.2383111\n",
      "\tspeed: 0.0424s/iter; left time: 218.6952s\n",
      "\titers: 300, epoch: 5 | loss: 0.2541043\n",
      "\tspeed: 0.0423s/iter; left time: 213.7568s\n",
      "\titers: 400, epoch: 5 | loss: 0.2939530\n",
      "\tspeed: 0.0423s/iter; left time: 209.6394s\n",
      "\titers: 500, epoch: 5 | loss: 0.3624977\n",
      "\tspeed: 0.0422s/iter; left time: 205.2899s\n",
      "\titers: 600, epoch: 5 | loss: 0.2916973\n",
      "\tspeed: 0.0423s/iter; left time: 201.3076s\n",
      "\titers: 700, epoch: 5 | loss: 0.2681513\n",
      "\tspeed: 0.0423s/iter; left time: 196.9329s\n",
      "\titers: 800, epoch: 5 | loss: 0.2681236\n",
      "\tspeed: 0.0423s/iter; left time: 192.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.2520440 Vali Loss: 0.4063278 Test Loss: 0.4664033\n",
      "Validation loss decreased (0.406522 --> 0.406328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3188669\n",
      "\tspeed: 0.1523s/iter; left time: 664.7476s\n",
      "\titers: 200, epoch: 6 | loss: 0.2008031\n",
      "\tspeed: 0.0423s/iter; left time: 180.4757s\n",
      "\titers: 300, epoch: 6 | loss: 0.2052909\n",
      "\tspeed: 0.0423s/iter; left time: 176.1233s\n",
      "\titers: 400, epoch: 6 | loss: 0.2591189\n",
      "\tspeed: 0.0423s/iter; left time: 171.8447s\n",
      "\titers: 500, epoch: 6 | loss: 0.1943497\n",
      "\tspeed: 0.0423s/iter; left time: 167.6000s\n",
      "\titers: 600, epoch: 6 | loss: 0.2352947\n",
      "\tspeed: 0.0424s/iter; left time: 163.7528s\n",
      "\titers: 700, epoch: 6 | loss: 0.2489737\n",
      "\tspeed: 0.0423s/iter; left time: 159.3153s\n",
      "\titers: 800, epoch: 6 | loss: 0.2547600\n",
      "\tspeed: 0.0423s/iter; left time: 155.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2338442 Vali Loss: 0.4190404 Test Loss: 0.4860373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2307729\n",
      "\tspeed: 0.1512s/iter; left time: 525.1497s\n",
      "\titers: 200, epoch: 7 | loss: 0.3084017\n",
      "\tspeed: 0.0426s/iter; left time: 143.7272s\n",
      "\titers: 300, epoch: 7 | loss: 0.2080216\n",
      "\tspeed: 0.0424s/iter; left time: 138.8907s\n",
      "\titers: 400, epoch: 7 | loss: 0.2292389\n",
      "\tspeed: 0.0424s/iter; left time: 134.5541s\n",
      "\titers: 500, epoch: 7 | loss: 0.1513019\n",
      "\tspeed: 0.0424s/iter; left time: 130.3895s\n",
      "\titers: 600, epoch: 7 | loss: 0.1729813\n",
      "\tspeed: 0.0424s/iter; left time: 126.0802s\n",
      "\titers: 700, epoch: 7 | loss: 0.1880350\n",
      "\tspeed: 0.0424s/iter; left time: 121.8792s\n",
      "\titers: 800, epoch: 7 | loss: 0.1786184\n",
      "\tspeed: 0.0424s/iter; left time: 117.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.2103385 Vali Loss: 0.4527536 Test Loss: 0.5490917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1798774\n",
      "\tspeed: 0.1502s/iter; left time: 387.6204s\n",
      "\titers: 200, epoch: 8 | loss: 0.1682350\n",
      "\tspeed: 0.0423s/iter; left time: 104.9621s\n",
      "\titers: 300, epoch: 8 | loss: 0.1307397\n",
      "\tspeed: 0.0423s/iter; left time: 100.7076s\n",
      "\titers: 400, epoch: 8 | loss: 0.2033289\n",
      "\tspeed: 0.0423s/iter; left time: 96.4539s\n",
      "\titers: 500, epoch: 8 | loss: 0.1776353\n",
      "\tspeed: 0.0423s/iter; left time: 92.1544s\n",
      "\titers: 600, epoch: 8 | loss: 0.1967961\n",
      "\tspeed: 0.0423s/iter; left time: 87.9254s\n",
      "\titers: 700, epoch: 8 | loss: 0.1893690\n",
      "\tspeed: 0.0423s/iter; left time: 83.7588s\n",
      "\titers: 800, epoch: 8 | loss: 0.1618215\n",
      "\tspeed: 0.0423s/iter; left time: 79.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.1851797 Vali Loss: 0.4516812 Test Loss: 0.5370039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:17762658.0, rmse:4214.57666015625, mae:2639.203857421875, rse:0.20955726504325867\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7372616\n",
      "\tspeed: 0.0691s/iter; left time: 608.6407s\n",
      "\titers: 200, epoch: 1 | loss: 0.5333896\n",
      "\tspeed: 0.0428s/iter; left time: 373.1290s\n",
      "\titers: 300, epoch: 1 | loss: 0.5598907\n",
      "\tspeed: 0.0429s/iter; left time: 369.0035s\n",
      "\titers: 400, epoch: 1 | loss: 0.4729436\n",
      "\tspeed: 0.0429s/iter; left time: 364.7546s\n",
      "\titers: 500, epoch: 1 | loss: 0.5560483\n",
      "\tspeed: 0.0427s/iter; left time: 359.0596s\n",
      "\titers: 600, epoch: 1 | loss: 0.4819749\n",
      "\tspeed: 0.0428s/iter; left time: 355.7508s\n",
      "\titers: 700, epoch: 1 | loss: 0.5415132\n",
      "\tspeed: 0.0428s/iter; left time: 351.5529s\n",
      "\titers: 800, epoch: 1 | loss: 0.6243510\n",
      "\tspeed: 0.0428s/iter; left time: 347.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 891 | Train Loss: 0.5668236 Vali Loss: 0.6507477 Test Loss: 0.7603212\n",
      "Validation loss decreased (inf --> 0.650748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5540779\n",
      "\tspeed: 0.1531s/iter; left time: 1212.6890s\n",
      "\titers: 200, epoch: 2 | loss: 0.4847487\n",
      "\tspeed: 0.0428s/iter; left time: 334.3348s\n",
      "\titers: 300, epoch: 2 | loss: 0.4586814\n",
      "\tspeed: 0.0427s/iter; left time: 329.9709s\n",
      "\titers: 400, epoch: 2 | loss: 0.5438913\n",
      "\tspeed: 0.0427s/iter; left time: 325.1850s\n",
      "\titers: 500, epoch: 2 | loss: 0.4111202\n",
      "\tspeed: 0.0428s/iter; left time: 321.7575s\n",
      "\titers: 600, epoch: 2 | loss: 0.3895184\n",
      "\tspeed: 0.0427s/iter; left time: 316.8272s\n",
      "\titers: 700, epoch: 2 | loss: 0.3883051\n",
      "\tspeed: 0.0427s/iter; left time: 312.6037s\n",
      "\titers: 800, epoch: 2 | loss: 0.5433491\n",
      "\tspeed: 0.0427s/iter; left time: 308.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.5033157 Vali Loss: 0.6297555 Test Loss: 0.7439358\n",
      "Validation loss decreased (0.650748 --> 0.629755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4145484\n",
      "\tspeed: 0.1549s/iter; left time: 1088.6829s\n",
      "\titers: 200, epoch: 3 | loss: 0.4595998\n",
      "\tspeed: 0.0427s/iter; left time: 295.9030s\n",
      "\titers: 300, epoch: 3 | loss: 0.4619078\n",
      "\tspeed: 0.0427s/iter; left time: 291.5679s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526187\n",
      "\tspeed: 0.0427s/iter; left time: 287.1276s\n",
      "\titers: 500, epoch: 3 | loss: 0.4454547\n",
      "\tspeed: 0.0427s/iter; left time: 283.0420s\n",
      "\titers: 600, epoch: 3 | loss: 0.3692695\n",
      "\tspeed: 0.0427s/iter; left time: 278.9095s\n",
      "\titers: 700, epoch: 3 | loss: 0.4703220\n",
      "\tspeed: 0.0427s/iter; left time: 274.6825s\n",
      "\titers: 800, epoch: 3 | loss: 0.3812272\n",
      "\tspeed: 0.0427s/iter; left time: 270.3075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.4455938 Vali Loss: 0.6881084 Test Loss: 0.8548705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4174319\n",
      "\tspeed: 0.1502s/iter; left time: 921.6323s\n",
      "\titers: 200, epoch: 4 | loss: 0.4014978\n",
      "\tspeed: 0.0427s/iter; left time: 258.1130s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054119\n",
      "\tspeed: 0.0427s/iter; left time: 253.7498s\n",
      "\titers: 400, epoch: 4 | loss: 0.3589748\n",
      "\tspeed: 0.0427s/iter; left time: 249.5192s\n",
      "\titers: 500, epoch: 4 | loss: 0.3653719\n",
      "\tspeed: 0.0427s/iter; left time: 245.0934s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618014\n",
      "\tspeed: 0.0427s/iter; left time: 240.5876s\n",
      "\titers: 700, epoch: 4 | loss: 0.3188422\n",
      "\tspeed: 0.0427s/iter; left time: 236.3262s\n",
      "\titers: 800, epoch: 4 | loss: 0.2926117\n",
      "\tspeed: 0.0427s/iter; left time: 232.3004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 891 | Train Loss: 0.3568448 Vali Loss: 0.7477230 Test Loss: 0.9618957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811221\n",
      "\tspeed: 0.1516s/iter; left time: 795.5394s\n",
      "\titers: 200, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0428s/iter; left time: 220.1880s\n",
      "\titers: 300, epoch: 5 | loss: 0.3285968\n",
      "\tspeed: 0.0428s/iter; left time: 215.8488s\n",
      "\titers: 400, epoch: 5 | loss: 0.2673545\n",
      "\tspeed: 0.0428s/iter; left time: 211.4899s\n",
      "\titers: 500, epoch: 5 | loss: 0.2493921\n",
      "\tspeed: 0.0428s/iter; left time: 207.2938s\n",
      "\titers: 600, epoch: 5 | loss: 0.2386115\n",
      "\tspeed: 0.0428s/iter; left time: 203.0974s\n",
      "\titers: 700, epoch: 5 | loss: 0.2263911\n",
      "\tspeed: 0.0428s/iter; left time: 199.0389s\n",
      "\titers: 800, epoch: 5 | loss: 0.1957354\n",
      "\tspeed: 0.0428s/iter; left time: 194.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.2605241 Vali Loss: 0.8050478 Test Loss: 0.9919707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:30875704.0, rmse:5556.5908203125, mae:3633.89697265625, rse:0.27672022581100464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5473459\n",
      "\tspeed: 0.0448s/iter; left time: 395.1016s\n",
      "\titers: 200, epoch: 1 | loss: 0.4877608\n",
      "\tspeed: 0.0428s/iter; left time: 373.0619s\n",
      "\titers: 300, epoch: 1 | loss: 0.6598209\n",
      "\tspeed: 0.0427s/iter; left time: 367.6284s\n",
      "\titers: 400, epoch: 1 | loss: 0.6614044\n",
      "\tspeed: 0.0427s/iter; left time: 363.3734s\n",
      "\titers: 500, epoch: 1 | loss: 0.4741346\n",
      "\tspeed: 0.0427s/iter; left time: 359.0478s\n",
      "\titers: 600, epoch: 1 | loss: 0.6109210\n",
      "\tspeed: 0.0427s/iter; left time: 354.8942s\n",
      "\titers: 700, epoch: 1 | loss: 0.5352585\n",
      "\tspeed: 0.0427s/iter; left time: 350.4884s\n",
      "\titers: 800, epoch: 1 | loss: 0.5013155\n",
      "\tspeed: 0.0427s/iter; left time: 346.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.5658269 Vali Loss: 0.6509469 Test Loss: 0.7612176\n",
      "Validation loss decreased (inf --> 0.650947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5183153\n",
      "\tspeed: 0.1539s/iter; left time: 1219.2386s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526019\n",
      "\tspeed: 0.0429s/iter; left time: 335.7057s\n",
      "\titers: 300, epoch: 2 | loss: 0.5071620\n",
      "\tspeed: 0.0429s/iter; left time: 331.4799s\n",
      "\titers: 400, epoch: 2 | loss: 0.4839136\n",
      "\tspeed: 0.0430s/iter; left time: 327.4541s\n",
      "\titers: 500, epoch: 2 | loss: 0.3920006\n",
      "\tspeed: 0.0429s/iter; left time: 322.4180s\n",
      "\titers: 600, epoch: 2 | loss: 0.4868114\n",
      "\tspeed: 0.0427s/iter; left time: 316.8429s\n",
      "\titers: 700, epoch: 2 | loss: 0.5634870\n",
      "\tspeed: 0.0427s/iter; left time: 312.8853s\n",
      "\titers: 800, epoch: 2 | loss: 0.4724952\n",
      "\tspeed: 0.0427s/iter; left time: 308.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 891 | Train Loss: 0.5043234 Vali Loss: 0.6191998 Test Loss: 0.7726130\n",
      "Validation loss decreased (0.650947 --> 0.619200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5086631\n",
      "\tspeed: 0.1534s/iter; left time: 1078.5332s\n",
      "\titers: 200, epoch: 3 | loss: 0.4055051\n",
      "\tspeed: 0.0430s/iter; left time: 297.6563s\n",
      "\titers: 300, epoch: 3 | loss: 0.3720219\n",
      "\tspeed: 0.0430s/iter; left time: 293.6046s\n",
      "\titers: 400, epoch: 3 | loss: 0.4331014\n",
      "\tspeed: 0.0428s/iter; left time: 287.7558s\n",
      "\titers: 500, epoch: 3 | loss: 0.3976127\n",
      "\tspeed: 0.0427s/iter; left time: 283.1273s\n",
      "\titers: 600, epoch: 3 | loss: 0.4022872\n",
      "\tspeed: 0.0427s/iter; left time: 278.7256s\n",
      "\titers: 700, epoch: 3 | loss: 0.4675071\n",
      "\tspeed: 0.0427s/iter; left time: 274.4350s\n",
      "\titers: 800, epoch: 3 | loss: 0.3814891\n",
      "\tspeed: 0.0427s/iter; left time: 270.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.4320488 Vali Loss: 0.6841762 Test Loss: 0.8737969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3273250\n",
      "\tspeed: 0.1521s/iter; left time: 933.6524s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400194\n",
      "\tspeed: 0.0426s/iter; left time: 257.0641s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161496\n",
      "\tspeed: 0.0426s/iter; left time: 253.1545s\n",
      "\titers: 400, epoch: 4 | loss: 0.3390466\n",
      "\tspeed: 0.0429s/iter; left time: 250.6232s\n",
      "\titers: 500, epoch: 4 | loss: 0.2879927\n",
      "\tspeed: 0.0426s/iter; left time: 244.4521s\n",
      "\titers: 600, epoch: 4 | loss: 0.3149875\n",
      "\tspeed: 0.0427s/iter; left time: 241.0035s\n",
      "\titers: 700, epoch: 4 | loss: 0.3463651\n",
      "\tspeed: 0.0431s/iter; left time: 238.6413s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761787\n",
      "\tspeed: 0.0427s/iter; left time: 232.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3297124 Vali Loss: 0.7400400 Test Loss: 0.9315168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2692976\n",
      "\tspeed: 0.1510s/iter; left time: 792.3380s\n",
      "\titers: 200, epoch: 5 | loss: 0.2221422\n",
      "\tspeed: 0.0430s/iter; left time: 221.2273s\n",
      "\titers: 300, epoch: 5 | loss: 0.2397722\n",
      "\tspeed: 0.0430s/iter; left time: 216.8036s\n",
      "\titers: 400, epoch: 5 | loss: 0.2549823\n",
      "\tspeed: 0.0430s/iter; left time: 212.5369s\n",
      "\titers: 500, epoch: 5 | loss: 0.2158701\n",
      "\tspeed: 0.0430s/iter; left time: 208.2185s\n",
      "\titers: 600, epoch: 5 | loss: 0.2114049\n",
      "\tspeed: 0.0429s/iter; left time: 203.6976s\n",
      "\titers: 700, epoch: 5 | loss: 0.2200302\n",
      "\tspeed: 0.0427s/iter; left time: 198.6012s\n",
      "\titers: 800, epoch: 5 | loss: 0.2109580\n",
      "\tspeed: 0.0427s/iter; left time: 194.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.2433385 Vali Loss: 0.7909078 Test Loss: 1.0188278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:32792920.0, rmse:5726.51025390625, mae:3746.37841796875, rse:0.28518226742744446\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7546027\n",
      "\tspeed: 0.0690s/iter; left time: 606.3974s\n",
      "\titers: 200, epoch: 1 | loss: 0.6000124\n",
      "\tspeed: 0.0432s/iter; left time: 375.2243s\n",
      "\titers: 300, epoch: 1 | loss: 0.6143029\n",
      "\tspeed: 0.0432s/iter; left time: 371.0620s\n",
      "\titers: 400, epoch: 1 | loss: 0.7047151\n",
      "\tspeed: 0.0432s/iter; left time: 366.7900s\n",
      "\titers: 500, epoch: 1 | loss: 0.6804361\n",
      "\tspeed: 0.0432s/iter; left time: 362.6724s\n",
      "\titers: 600, epoch: 1 | loss: 0.5855610\n",
      "\tspeed: 0.0432s/iter; left time: 358.4016s\n",
      "\titers: 700, epoch: 1 | loss: 0.5702372\n",
      "\tspeed: 0.0432s/iter; left time: 353.9674s\n",
      "\titers: 800, epoch: 1 | loss: 0.5958639\n",
      "\tspeed: 0.0431s/iter; left time: 349.1170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 889 | Train Loss: 0.6097435 Vali Loss: 0.6800801 Test Loss: 0.8067515\n",
      "Validation loss decreased (inf --> 0.680080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6113356\n",
      "\tspeed: 0.1553s/iter; left time: 1227.4393s\n",
      "\titers: 200, epoch: 2 | loss: 0.4996085\n",
      "\tspeed: 0.0432s/iter; left time: 337.1159s\n",
      "\titers: 300, epoch: 2 | loss: 0.6496976\n",
      "\tspeed: 0.0432s/iter; left time: 333.0378s\n",
      "\titers: 400, epoch: 2 | loss: 0.5307702\n",
      "\tspeed: 0.0432s/iter; left time: 328.1566s\n",
      "\titers: 500, epoch: 2 | loss: 0.5256283\n",
      "\tspeed: 0.0432s/iter; left time: 323.9362s\n",
      "\titers: 600, epoch: 2 | loss: 0.5327381\n",
      "\tspeed: 0.0432s/iter; left time: 319.5398s\n",
      "\titers: 700, epoch: 2 | loss: 0.4570733\n",
      "\tspeed: 0.0432s/iter; left time: 315.2962s\n",
      "\titers: 800, epoch: 2 | loss: 0.5451870\n",
      "\tspeed: 0.0432s/iter; left time: 311.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.5431589 Vali Loss: 0.6531566 Test Loss: 0.8226323\n",
      "Validation loss decreased (0.680080 --> 0.653157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4712646\n",
      "\tspeed: 0.1644s/iter; left time: 1153.2159s\n",
      "\titers: 200, epoch: 3 | loss: 0.4011992\n",
      "\tspeed: 0.0432s/iter; left time: 298.5916s\n",
      "\titers: 300, epoch: 3 | loss: 0.4421045\n",
      "\tspeed: 0.0432s/iter; left time: 294.1764s\n",
      "\titers: 400, epoch: 3 | loss: 0.4903741\n",
      "\tspeed: 0.0432s/iter; left time: 289.8698s\n",
      "\titers: 500, epoch: 3 | loss: 0.4915803\n",
      "\tspeed: 0.0432s/iter; left time: 285.7334s\n",
      "\titers: 600, epoch: 3 | loss: 0.4369896\n",
      "\tspeed: 0.0432s/iter; left time: 281.6726s\n",
      "\titers: 700, epoch: 3 | loss: 0.4332677\n",
      "\tspeed: 0.0432s/iter; left time: 276.8767s\n",
      "\titers: 800, epoch: 3 | loss: 0.3947041\n",
      "\tspeed: 0.0431s/iter; left time: 272.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 889 | Train Loss: 0.4362630 Vali Loss: 0.7709182 Test Loss: 1.0190653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3152215\n",
      "\tspeed: 0.1509s/iter; left time: 924.3689s\n",
      "\titers: 200, epoch: 4 | loss: 0.3043053\n",
      "\tspeed: 0.0432s/iter; left time: 260.0197s\n",
      "\titers: 300, epoch: 4 | loss: 0.3607482\n",
      "\tspeed: 0.0432s/iter; left time: 255.6936s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158475\n",
      "\tspeed: 0.0432s/iter; left time: 251.3149s\n",
      "\titers: 500, epoch: 4 | loss: 0.3114798\n",
      "\tspeed: 0.0431s/iter; left time: 246.9297s\n",
      "\titers: 600, epoch: 4 | loss: 0.2569940\n",
      "\tspeed: 0.0432s/iter; left time: 242.7388s\n",
      "\titers: 700, epoch: 4 | loss: 0.2990108\n",
      "\tspeed: 0.0431s/iter; left time: 238.2784s\n",
      "\titers: 800, epoch: 4 | loss: 0.2757485\n",
      "\tspeed: 0.0432s/iter; left time: 234.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.3139915 Vali Loss: 0.8249027 Test Loss: 1.1139140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653311\n",
      "\tspeed: 0.1518s/iter; left time: 794.4124s\n",
      "\titers: 200, epoch: 5 | loss: 0.2252893\n",
      "\tspeed: 0.0431s/iter; left time: 221.4687s\n",
      "\titers: 300, epoch: 5 | loss: 0.2340532\n",
      "\tspeed: 0.0432s/iter; left time: 217.3944s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358732\n",
      "\tspeed: 0.0432s/iter; left time: 213.1391s\n",
      "\titers: 500, epoch: 5 | loss: 0.2421527\n",
      "\tspeed: 0.0431s/iter; left time: 208.6254s\n",
      "\titers: 600, epoch: 5 | loss: 0.2229267\n",
      "\tspeed: 0.0431s/iter; left time: 204.3053s\n",
      "\titers: 700, epoch: 5 | loss: 0.2323525\n",
      "\tspeed: 0.0432s/iter; left time: 200.0533s\n",
      "\titers: 800, epoch: 5 | loss: 0.1996585\n",
      "\tspeed: 0.0432s/iter; left time: 195.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 889 | Train Loss: 0.2229739 Vali Loss: 0.8824634 Test Loss: 1.1303844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:35247892.0, rmse:5936.99365234375, mae:3905.610107421875, rse:0.2958095371723175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7979063\n",
      "\tspeed: 0.0451s/iter; left time: 396.9049s\n",
      "\titers: 200, epoch: 1 | loss: 0.6841452\n",
      "\tspeed: 0.0432s/iter; left time: 375.2146s\n",
      "\titers: 300, epoch: 1 | loss: 0.7397766\n",
      "\tspeed: 0.0431s/iter; left time: 370.6080s\n",
      "\titers: 400, epoch: 1 | loss: 0.6866934\n",
      "\tspeed: 0.0432s/iter; left time: 366.6330s\n",
      "\titers: 500, epoch: 1 | loss: 0.6043772\n",
      "\tspeed: 0.0431s/iter; left time: 361.9685s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847449\n",
      "\tspeed: 0.0431s/iter; left time: 357.6827s\n",
      "\titers: 700, epoch: 1 | loss: 0.5677136\n",
      "\tspeed: 0.0431s/iter; left time: 353.2485s\n",
      "\titers: 800, epoch: 1 | loss: 0.5065239\n",
      "\tspeed: 0.0432s/iter; left time: 349.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.6112015 Vali Loss: 0.6771722 Test Loss: 0.8046841\n",
      "Validation loss decreased (inf --> 0.677172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6040920\n",
      "\tspeed: 0.1552s/iter; left time: 1226.0203s\n",
      "\titers: 200, epoch: 2 | loss: 0.5640650\n",
      "\tspeed: 0.0432s/iter; left time: 336.9136s\n",
      "\titers: 300, epoch: 2 | loss: 0.5824279\n",
      "\tspeed: 0.0432s/iter; left time: 332.4278s\n",
      "\titers: 400, epoch: 2 | loss: 0.5516443\n",
      "\tspeed: 0.0431s/iter; left time: 328.0069s\n",
      "\titers: 500, epoch: 2 | loss: 0.5464745\n",
      "\tspeed: 0.0432s/iter; left time: 323.9975s\n",
      "\titers: 600, epoch: 2 | loss: 0.5696195\n",
      "\tspeed: 0.0432s/iter; left time: 319.4132s\n",
      "\titers: 700, epoch: 2 | loss: 0.4997825\n",
      "\tspeed: 0.0432s/iter; left time: 315.2885s\n",
      "\titers: 800, epoch: 2 | loss: 0.4807952\n",
      "\tspeed: 0.0432s/iter; left time: 311.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 889 | Train Loss: 0.5430961 Vali Loss: 0.6961910 Test Loss: 0.8720690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4384274\n",
      "\tspeed: 0.1524s/iter; left time: 1069.0469s\n",
      "\titers: 200, epoch: 3 | loss: 0.4003488\n",
      "\tspeed: 0.0432s/iter; left time: 298.5622s\n",
      "\titers: 300, epoch: 3 | loss: 0.5147206\n",
      "\tspeed: 0.0432s/iter; left time: 294.1334s\n",
      "\titers: 400, epoch: 3 | loss: 0.5407557\n",
      "\tspeed: 0.0432s/iter; left time: 289.6955s\n",
      "\titers: 500, epoch: 3 | loss: 0.4383535\n",
      "\tspeed: 0.0432s/iter; left time: 285.5857s\n",
      "\titers: 600, epoch: 3 | loss: 0.4661134\n",
      "\tspeed: 0.0431s/iter; left time: 280.9522s\n",
      "\titers: 700, epoch: 3 | loss: 0.4150949\n",
      "\tspeed: 0.0432s/iter; left time: 276.7786s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085022\n",
      "\tspeed: 0.0432s/iter; left time: 272.5468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 889 | Train Loss: 0.4439213 Vali Loss: 0.7267453 Test Loss: 0.9541050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3798918\n",
      "\tspeed: 0.1530s/iter; left time: 936.9462s\n",
      "\titers: 200, epoch: 4 | loss: 0.3046944\n",
      "\tspeed: 0.0432s/iter; left time: 260.1615s\n",
      "\titers: 300, epoch: 4 | loss: 0.3279685\n",
      "\tspeed: 0.0432s/iter; left time: 255.7042s\n",
      "\titers: 400, epoch: 4 | loss: 0.3203649\n",
      "\tspeed: 0.0432s/iter; left time: 251.4046s\n",
      "\titers: 500, epoch: 4 | loss: 0.3229451\n",
      "\tspeed: 0.0432s/iter; left time: 247.1428s\n",
      "\titers: 600, epoch: 4 | loss: 0.2853895\n",
      "\tspeed: 0.0432s/iter; left time: 242.8093s\n",
      "\titers: 700, epoch: 4 | loss: 0.3258071\n",
      "\tspeed: 0.0432s/iter; left time: 238.5574s\n",
      "\titers: 800, epoch: 4 | loss: 0.3050725\n",
      "\tspeed: 0.0432s/iter; left time: 234.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 889 | Train Loss: 0.3247702 Vali Loss: 0.8104095 Test Loss: 1.0395817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:34226872.0, rmse:5850.37353515625, mae:3899.109619140625, rse:0.2914937138557434\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6304526\n",
      "\tspeed: 0.0706s/iter; left time: 623.2846s\n",
      "\titers: 200, epoch: 1 | loss: 0.6647899\n",
      "\tspeed: 0.0425s/iter; left time: 371.0343s\n",
      "\titers: 300, epoch: 1 | loss: 0.5844824\n",
      "\tspeed: 0.0424s/iter; left time: 365.8184s\n",
      "\titers: 400, epoch: 1 | loss: 0.6426585\n",
      "\tspeed: 0.0424s/iter; left time: 361.3789s\n",
      "\titers: 500, epoch: 1 | loss: 0.6155174\n",
      "\tspeed: 0.0424s/iter; left time: 357.1771s\n",
      "\titers: 600, epoch: 1 | loss: 0.6662328\n",
      "\tspeed: 0.0423s/iter; left time: 352.7093s\n",
      "\titers: 700, epoch: 1 | loss: 0.5895321\n",
      "\tspeed: 0.0425s/iter; left time: 349.6382s\n",
      "\titers: 800, epoch: 1 | loss: 0.5740807\n",
      "\tspeed: 0.0425s/iter; left time: 345.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 893 | Train Loss: 0.6036704 Vali Loss: 0.4339436 Test Loss: 0.4720358\n",
      "Validation loss decreased (inf --> 0.433944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6498488\n",
      "\tspeed: 0.1513s/iter; left time: 1201.1835s\n",
      "\titers: 200, epoch: 2 | loss: 0.6380902\n",
      "\tspeed: 0.0424s/iter; left time: 332.0893s\n",
      "\titers: 300, epoch: 2 | loss: 0.5367553\n",
      "\tspeed: 0.0424s/iter; left time: 327.7206s\n",
      "\titers: 400, epoch: 2 | loss: 0.5489156\n",
      "\tspeed: 0.0423s/iter; left time: 323.4689s\n",
      "\titers: 500, epoch: 2 | loss: 0.5260842\n",
      "\tspeed: 0.0425s/iter; left time: 320.2092s\n",
      "\titers: 600, epoch: 2 | loss: 0.5337558\n",
      "\tspeed: 0.0425s/iter; left time: 315.8699s\n",
      "\titers: 700, epoch: 2 | loss: 0.5897491\n",
      "\tspeed: 0.0424s/iter; left time: 311.1954s\n",
      "\titers: 800, epoch: 2 | loss: 0.5088241\n",
      "\tspeed: 0.0423s/iter; left time: 306.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.5554133 Vali Loss: 0.4260295 Test Loss: 0.4780068\n",
      "Validation loss decreased (0.433944 --> 0.426029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309910\n",
      "\tspeed: 0.1524s/iter; left time: 1073.7943s\n",
      "\titers: 200, epoch: 3 | loss: 0.5291359\n",
      "\tspeed: 0.0423s/iter; left time: 294.0824s\n",
      "\titers: 300, epoch: 3 | loss: 0.4883050\n",
      "\tspeed: 0.0424s/iter; left time: 290.3338s\n",
      "\titers: 400, epoch: 3 | loss: 0.4879614\n",
      "\tspeed: 0.0423s/iter; left time: 285.6142s\n",
      "\titers: 500, epoch: 3 | loss: 0.4847891\n",
      "\tspeed: 0.0423s/iter; left time: 281.1734s\n",
      "\titers: 600, epoch: 3 | loss: 0.5293490\n",
      "\tspeed: 0.0423s/iter; left time: 276.9576s\n",
      "\titers: 700, epoch: 3 | loss: 0.4065211\n",
      "\tspeed: 0.0424s/iter; left time: 272.9843s\n",
      "\titers: 800, epoch: 3 | loss: 0.5855716\n",
      "\tspeed: 0.0424s/iter; left time: 268.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.5231845 Vali Loss: 0.4079853 Test Loss: 0.4513101\n",
      "Validation loss decreased (0.426029 --> 0.407985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5018351\n",
      "\tspeed: 0.1518s/iter; left time: 933.9789s\n",
      "\titers: 200, epoch: 4 | loss: 0.4895697\n",
      "\tspeed: 0.0423s/iter; left time: 256.2566s\n",
      "\titers: 300, epoch: 4 | loss: 0.5145022\n",
      "\tspeed: 0.0423s/iter; left time: 251.7126s\n",
      "\titers: 400, epoch: 4 | loss: 0.4483052\n",
      "\tspeed: 0.0423s/iter; left time: 247.4875s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109250\n",
      "\tspeed: 0.0423s/iter; left time: 243.5019s\n",
      "\titers: 600, epoch: 4 | loss: 0.4802767\n",
      "\tspeed: 0.0423s/iter; left time: 239.2972s\n",
      "\titers: 700, epoch: 4 | loss: 0.5246813\n",
      "\tspeed: 0.0423s/iter; left time: 234.9643s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321484\n",
      "\tspeed: 0.0425s/iter; left time: 231.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.5150838 Vali Loss: 0.4270419 Test Loss: 0.4700336\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4871208\n",
      "\tspeed: 0.1494s/iter; left time: 785.5422s\n",
      "\titers: 200, epoch: 5 | loss: 0.4352125\n",
      "\tspeed: 0.0425s/iter; left time: 219.0526s\n",
      "\titers: 300, epoch: 5 | loss: 0.5049165\n",
      "\tspeed: 0.0425s/iter; left time: 214.9037s\n",
      "\titers: 400, epoch: 5 | loss: 0.4666814\n",
      "\tspeed: 0.0425s/iter; left time: 210.7108s\n",
      "\titers: 500, epoch: 5 | loss: 0.5018875\n",
      "\tspeed: 0.0424s/iter; left time: 205.7988s\n",
      "\titers: 600, epoch: 5 | loss: 0.4701836\n",
      "\tspeed: 0.0423s/iter; left time: 201.4717s\n",
      "\titers: 700, epoch: 5 | loss: 0.5009473\n",
      "\tspeed: 0.0423s/iter; left time: 197.2731s\n",
      "\titers: 800, epoch: 5 | loss: 0.4748931\n",
      "\tspeed: 0.0424s/iter; left time: 193.2816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.5074182 Vali Loss: 0.4152391 Test Loss: 0.4634299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4203286\n",
      "\tspeed: 0.1499s/iter; left time: 654.4878s\n",
      "\titers: 200, epoch: 6 | loss: 0.5329765\n",
      "\tspeed: 0.0423s/iter; left time: 180.6103s\n",
      "\titers: 300, epoch: 6 | loss: 0.4321128\n",
      "\tspeed: 0.0423s/iter; left time: 176.1512s\n",
      "\titers: 400, epoch: 6 | loss: 0.4385991\n",
      "\tspeed: 0.0423s/iter; left time: 172.0865s\n",
      "\titers: 500, epoch: 6 | loss: 0.4512403\n",
      "\tspeed: 0.0424s/iter; left time: 168.0925s\n",
      "\titers: 600, epoch: 6 | loss: 0.4838388\n",
      "\tspeed: 0.0424s/iter; left time: 163.8362s\n",
      "\titers: 700, epoch: 6 | loss: 0.4213574\n",
      "\tspeed: 0.0423s/iter; left time: 159.4068s\n",
      "\titers: 800, epoch: 6 | loss: 0.4768175\n",
      "\tspeed: 0.0423s/iter; left time: 155.2414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 893 | Train Loss: 0.4807680 Vali Loss: 0.4451250 Test Loss: 0.4856848\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:17305828.0, rmse:4160.02734375, mae:2609.172119140625, rse:0.20684495568275452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7208875\n",
      "\tspeed: 0.0438s/iter; left time: 387.1542s\n",
      "\titers: 200, epoch: 1 | loss: 0.5653324\n",
      "\tspeed: 0.0424s/iter; left time: 370.3747s\n",
      "\titers: 300, epoch: 1 | loss: 0.5747016\n",
      "\tspeed: 0.0424s/iter; left time: 365.5856s\n",
      "\titers: 400, epoch: 1 | loss: 0.5493563\n",
      "\tspeed: 0.0423s/iter; left time: 360.8889s\n",
      "\titers: 500, epoch: 1 | loss: 0.5951235\n",
      "\tspeed: 0.0423s/iter; left time: 357.0504s\n",
      "\titers: 600, epoch: 1 | loss: 0.5839962\n",
      "\tspeed: 0.0423s/iter; left time: 352.7276s\n",
      "\titers: 700, epoch: 1 | loss: 0.5883811\n",
      "\tspeed: 0.0423s/iter; left time: 348.4941s\n",
      "\titers: 800, epoch: 1 | loss: 0.6175978\n",
      "\tspeed: 0.0423s/iter; left time: 344.1174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.6029870 Vali Loss: 0.4296014 Test Loss: 0.4724245\n",
      "Validation loss decreased (inf --> 0.429601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5956693\n",
      "\tspeed: 0.1526s/iter; left time: 1211.1616s\n",
      "\titers: 200, epoch: 2 | loss: 0.6147557\n",
      "\tspeed: 0.0424s/iter; left time: 332.2744s\n",
      "\titers: 300, epoch: 2 | loss: 0.5424049\n",
      "\tspeed: 0.0423s/iter; left time: 327.4965s\n",
      "\titers: 400, epoch: 2 | loss: 0.5658551\n",
      "\tspeed: 0.0424s/iter; left time: 324.1444s\n",
      "\titers: 500, epoch: 2 | loss: 0.5137780\n",
      "\tspeed: 0.0424s/iter; left time: 319.9489s\n",
      "\titers: 600, epoch: 2 | loss: 0.5194274\n",
      "\tspeed: 0.0424s/iter; left time: 315.6562s\n",
      "\titers: 700, epoch: 2 | loss: 0.4312453\n",
      "\tspeed: 0.0424s/iter; left time: 310.9124s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377391\n",
      "\tspeed: 0.0424s/iter; left time: 306.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5573271 Vali Loss: 0.4067231 Test Loss: 0.4517895\n",
      "Validation loss decreased (0.429601 --> 0.406723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4817174\n",
      "\tspeed: 0.1524s/iter; left time: 1073.4299s\n",
      "\titers: 200, epoch: 3 | loss: 0.5098557\n",
      "\tspeed: 0.0424s/iter; left time: 294.2378s\n",
      "\titers: 300, epoch: 3 | loss: 0.4692909\n",
      "\tspeed: 0.0424s/iter; left time: 289.9353s\n",
      "\titers: 400, epoch: 3 | loss: 0.4773871\n",
      "\tspeed: 0.0423s/iter; left time: 285.5656s\n",
      "\titers: 500, epoch: 3 | loss: 0.5546513\n",
      "\tspeed: 0.0423s/iter; left time: 281.2398s\n",
      "\titers: 600, epoch: 3 | loss: 0.5032052\n",
      "\tspeed: 0.0423s/iter; left time: 277.0583s\n",
      "\titers: 700, epoch: 3 | loss: 0.4395917\n",
      "\tspeed: 0.0423s/iter; left time: 272.8988s\n",
      "\titers: 800, epoch: 3 | loss: 0.5026121\n",
      "\tspeed: 0.0423s/iter; left time: 268.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.5239807 Vali Loss: 0.4195922 Test Loss: 0.4513127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5083061\n",
      "\tspeed: 0.1505s/iter; left time: 925.5743s\n",
      "\titers: 200, epoch: 4 | loss: 0.4650363\n",
      "\tspeed: 0.0423s/iter; left time: 256.1207s\n",
      "\titers: 300, epoch: 4 | loss: 0.4765425\n",
      "\tspeed: 0.0423s/iter; left time: 251.8715s\n",
      "\titers: 400, epoch: 4 | loss: 0.5530409\n",
      "\tspeed: 0.0423s/iter; left time: 247.6818s\n",
      "\titers: 500, epoch: 4 | loss: 0.5370450\n",
      "\tspeed: 0.0423s/iter; left time: 243.4690s\n",
      "\titers: 600, epoch: 4 | loss: 0.6664306\n",
      "\tspeed: 0.0424s/iter; left time: 239.7459s\n",
      "\titers: 700, epoch: 4 | loss: 0.4789167\n",
      "\tspeed: 0.0425s/iter; left time: 236.1213s\n",
      "\titers: 800, epoch: 4 | loss: 0.5579545\n",
      "\tspeed: 0.0425s/iter; left time: 231.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.5211855 Vali Loss: 0.4197213 Test Loss: 0.4598895\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4809563\n",
      "\tspeed: 0.1516s/iter; left time: 797.5165s\n",
      "\titers: 200, epoch: 5 | loss: 0.4911440\n",
      "\tspeed: 0.0425s/iter; left time: 219.2813s\n",
      "\titers: 300, epoch: 5 | loss: 0.4891045\n",
      "\tspeed: 0.0425s/iter; left time: 215.0462s\n",
      "\titers: 400, epoch: 5 | loss: 0.5189811\n",
      "\tspeed: 0.0425s/iter; left time: 210.6191s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235159\n",
      "\tspeed: 0.0425s/iter; left time: 206.2739s\n",
      "\titers: 600, epoch: 5 | loss: 0.5044044\n",
      "\tspeed: 0.0424s/iter; left time: 201.8796s\n",
      "\titers: 700, epoch: 5 | loss: 0.4964522\n",
      "\tspeed: 0.0424s/iter; left time: 197.4530s\n",
      "\titers: 800, epoch: 5 | loss: 0.5055836\n",
      "\tspeed: 0.0425s/iter; left time: 193.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.4999788 Vali Loss: 0.4229821 Test Loss: 0.4707361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:17345650.0, rmse:4164.81103515625, mae:2657.558349609375, rse:0.20708277821540833\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8564085\n",
      "\tspeed: 0.0687s/iter; left time: 605.4060s\n",
      "\titers: 200, epoch: 1 | loss: 0.7276816\n",
      "\tspeed: 0.0427s/iter; left time: 371.8089s\n",
      "\titers: 300, epoch: 1 | loss: 0.7469753\n",
      "\tspeed: 0.0427s/iter; left time: 367.5191s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862437\n",
      "\tspeed: 0.0427s/iter; left time: 363.6300s\n",
      "\titers: 500, epoch: 1 | loss: 0.7447299\n",
      "\tspeed: 0.0427s/iter; left time: 359.2574s\n",
      "\titers: 600, epoch: 1 | loss: 0.6932904\n",
      "\tspeed: 0.0427s/iter; left time: 354.7141s\n",
      "\titers: 700, epoch: 1 | loss: 0.7336010\n",
      "\tspeed: 0.0426s/iter; left time: 350.1915s\n",
      "\titers: 800, epoch: 1 | loss: 0.7876992\n",
      "\tspeed: 0.0427s/iter; left time: 346.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 891 | Train Loss: 0.7489301 Vali Loss: 0.6496119 Test Loss: 0.7595298\n",
      "Validation loss decreased (inf --> 0.649612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7455665\n",
      "\tspeed: 0.1515s/iter; left time: 1199.9315s\n",
      "\titers: 200, epoch: 2 | loss: 0.6923752\n",
      "\tspeed: 0.0428s/iter; left time: 334.3957s\n",
      "\titers: 300, epoch: 2 | loss: 0.6735732\n",
      "\tspeed: 0.0427s/iter; left time: 329.6379s\n",
      "\titers: 400, epoch: 2 | loss: 0.7412770\n",
      "\tspeed: 0.0427s/iter; left time: 325.3271s\n",
      "\titers: 500, epoch: 2 | loss: 0.6404418\n",
      "\tspeed: 0.0427s/iter; left time: 321.1410s\n",
      "\titers: 600, epoch: 2 | loss: 0.6246042\n",
      "\tspeed: 0.0427s/iter; left time: 316.6256s\n",
      "\titers: 700, epoch: 2 | loss: 0.6204208\n",
      "\tspeed: 0.0427s/iter; left time: 312.5002s\n",
      "\titers: 800, epoch: 2 | loss: 0.7364731\n",
      "\tspeed: 0.0427s/iter; left time: 308.5517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.7072706 Vali Loss: 0.6384751 Test Loss: 0.7534525\n",
      "Validation loss decreased (0.649612 --> 0.638475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6394007\n",
      "\tspeed: 0.1536s/iter; left time: 1079.3841s\n",
      "\titers: 200, epoch: 3 | loss: 0.6838906\n",
      "\tspeed: 0.0428s/iter; left time: 296.8593s\n",
      "\titers: 300, epoch: 3 | loss: 0.6923274\n",
      "\tspeed: 0.0429s/iter; left time: 292.8292s\n",
      "\titers: 400, epoch: 3 | loss: 0.6940130\n",
      "\tspeed: 0.0429s/iter; left time: 288.5041s\n",
      "\titers: 500, epoch: 3 | loss: 0.6825750\n",
      "\tspeed: 0.0428s/iter; left time: 283.8479s\n",
      "\titers: 600, epoch: 3 | loss: 0.6074114\n",
      "\tspeed: 0.0428s/iter; left time: 279.3034s\n",
      "\titers: 700, epoch: 3 | loss: 0.6975672\n",
      "\tspeed: 0.0427s/iter; left time: 274.8253s\n",
      "\titers: 800, epoch: 3 | loss: 0.5953272\n",
      "\tspeed: 0.0428s/iter; left time: 270.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.6643052 Vali Loss: 0.6965610 Test Loss: 0.8775428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6318092\n",
      "\tspeed: 0.1506s/iter; left time: 924.5618s\n",
      "\titers: 200, epoch: 4 | loss: 0.6489524\n",
      "\tspeed: 0.0427s/iter; left time: 257.7699s\n",
      "\titers: 300, epoch: 4 | loss: 0.6114253\n",
      "\tspeed: 0.0427s/iter; left time: 253.6007s\n",
      "\titers: 400, epoch: 4 | loss: 0.6083454\n",
      "\tspeed: 0.0427s/iter; left time: 249.2446s\n",
      "\titers: 500, epoch: 4 | loss: 0.5923827\n",
      "\tspeed: 0.0427s/iter; left time: 245.2596s\n",
      "\titers: 600, epoch: 4 | loss: 0.6142623\n",
      "\tspeed: 0.0427s/iter; left time: 240.7580s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633094\n",
      "\tspeed: 0.0427s/iter; left time: 236.3639s\n",
      "\titers: 800, epoch: 4 | loss: 0.5035748\n",
      "\tspeed: 0.0427s/iter; left time: 232.1718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.5925956 Vali Loss: 0.7727130 Test Loss: 0.9328302\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5578295\n",
      "\tspeed: 0.1505s/iter; left time: 789.6784s\n",
      "\titers: 200, epoch: 5 | loss: 0.5414807\n",
      "\tspeed: 0.0427s/iter; left time: 219.8761s\n",
      "\titers: 300, epoch: 5 | loss: 0.5636502\n",
      "\tspeed: 0.0427s/iter; left time: 215.3783s\n",
      "\titers: 400, epoch: 5 | loss: 0.5362424\n",
      "\tspeed: 0.0427s/iter; left time: 211.3712s\n",
      "\titers: 500, epoch: 5 | loss: 0.4829004\n",
      "\tspeed: 0.0427s/iter; left time: 207.0363s\n",
      "\titers: 600, epoch: 5 | loss: 0.4771944\n",
      "\tspeed: 0.0427s/iter; left time: 202.7627s\n",
      "\titers: 700, epoch: 5 | loss: 0.4571800\n",
      "\tspeed: 0.0427s/iter; left time: 198.4456s\n",
      "\titers: 800, epoch: 5 | loss: 0.4408690\n",
      "\tspeed: 0.0427s/iter; left time: 194.2335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 891 | Train Loss: 0.5061452 Vali Loss: 0.8498826 Test Loss: 0.9658751\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:31262294.0, rmse:5591.26953125, mae:3673.384033203125, rse:0.2784472107887268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7373669\n",
      "\tspeed: 0.0441s/iter; left time: 389.0044s\n",
      "\titers: 200, epoch: 1 | loss: 0.6961303\n",
      "\tspeed: 0.0427s/iter; left time: 372.0321s\n",
      "\titers: 300, epoch: 1 | loss: 0.8107926\n",
      "\tspeed: 0.0427s/iter; left time: 367.6373s\n",
      "\titers: 400, epoch: 1 | loss: 0.8115740\n",
      "\tspeed: 0.0427s/iter; left time: 363.1624s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878027\n",
      "\tspeed: 0.0427s/iter; left time: 359.5055s\n",
      "\titers: 600, epoch: 1 | loss: 0.7807432\n",
      "\tspeed: 0.0428s/iter; left time: 355.8652s\n",
      "\titers: 700, epoch: 1 | loss: 0.7302145\n",
      "\tspeed: 0.0428s/iter; left time: 351.7673s\n",
      "\titers: 800, epoch: 1 | loss: 0.7058792\n",
      "\tspeed: 0.0428s/iter; left time: 347.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.7482038 Vali Loss: 0.6501760 Test Loss: 0.7607240\n",
      "Validation loss decreased (inf --> 0.650176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7201242\n",
      "\tspeed: 0.1537s/iter; left time: 1217.6296s\n",
      "\titers: 200, epoch: 2 | loss: 0.6755181\n",
      "\tspeed: 0.0427s/iter; left time: 333.5853s\n",
      "\titers: 300, epoch: 2 | loss: 0.7100089\n",
      "\tspeed: 0.0427s/iter; left time: 329.6820s\n",
      "\titers: 400, epoch: 2 | loss: 0.6997021\n",
      "\tspeed: 0.0427s/iter; left time: 325.1664s\n",
      "\titers: 500, epoch: 2 | loss: 0.6204954\n",
      "\tspeed: 0.0427s/iter; left time: 321.1890s\n",
      "\titers: 600, epoch: 2 | loss: 0.6984884\n",
      "\tspeed: 0.0428s/iter; left time: 317.2929s\n",
      "\titers: 700, epoch: 2 | loss: 0.7466449\n",
      "\tspeed: 0.0427s/iter; left time: 312.8027s\n",
      "\titers: 800, epoch: 2 | loss: 0.6878006\n",
      "\tspeed: 0.0427s/iter; left time: 308.3614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.7087464 Vali Loss: 0.6216077 Test Loss: 0.7755335\n",
      "Validation loss decreased (0.650176 --> 0.621608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7080504\n",
      "\tspeed: 0.1541s/iter; left time: 1083.3224s\n",
      "\titers: 200, epoch: 3 | loss: 0.6345065\n",
      "\tspeed: 0.0427s/iter; left time: 295.9227s\n",
      "\titers: 300, epoch: 3 | loss: 0.6015949\n",
      "\tspeed: 0.0427s/iter; left time: 291.5802s\n",
      "\titers: 400, epoch: 3 | loss: 0.6569807\n",
      "\tspeed: 0.0427s/iter; left time: 287.1297s\n",
      "\titers: 500, epoch: 3 | loss: 0.6287000\n",
      "\tspeed: 0.0427s/iter; left time: 283.0195s\n",
      "\titers: 600, epoch: 3 | loss: 0.6277207\n",
      "\tspeed: 0.0427s/iter; left time: 278.5428s\n",
      "\titers: 700, epoch: 3 | loss: 0.6814144\n",
      "\tspeed: 0.0427s/iter; left time: 274.2504s\n",
      "\titers: 800, epoch: 3 | loss: 0.6294596\n",
      "\tspeed: 0.0427s/iter; left time: 270.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.6558177 Vali Loss: 0.6887955 Test Loss: 0.8492430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6006249\n",
      "\tspeed: 0.1509s/iter; left time: 926.0301s\n",
      "\titers: 200, epoch: 4 | loss: 0.5826002\n",
      "\tspeed: 0.0427s/iter; left time: 257.6886s\n",
      "\titers: 300, epoch: 4 | loss: 0.5727263\n",
      "\tspeed: 0.0427s/iter; left time: 253.2981s\n",
      "\titers: 400, epoch: 4 | loss: 0.5923206\n",
      "\tspeed: 0.0427s/iter; left time: 249.1525s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391967\n",
      "\tspeed: 0.0427s/iter; left time: 244.8063s\n",
      "\titers: 600, epoch: 4 | loss: 0.5598037\n",
      "\tspeed: 0.0427s/iter; left time: 240.6634s\n",
      "\titers: 700, epoch: 4 | loss: 0.5872183\n",
      "\tspeed: 0.0427s/iter; left time: 236.4627s\n",
      "\titers: 800, epoch: 4 | loss: 0.5201843\n",
      "\tspeed: 0.0427s/iter; left time: 232.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.5749528 Vali Loss: 0.7418606 Test Loss: 0.9283234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5154231\n",
      "\tspeed: 0.1517s/iter; left time: 795.9297s\n",
      "\titers: 200, epoch: 5 | loss: 0.4713488\n",
      "\tspeed: 0.0427s/iter; left time: 219.7567s\n",
      "\titers: 300, epoch: 5 | loss: 0.4894331\n",
      "\tspeed: 0.0427s/iter; left time: 215.3591s\n",
      "\titers: 400, epoch: 5 | loss: 0.4998905\n",
      "\tspeed: 0.0427s/iter; left time: 211.1446s\n",
      "\titers: 500, epoch: 5 | loss: 0.4573486\n",
      "\tspeed: 0.0427s/iter; left time: 207.0175s\n",
      "\titers: 600, epoch: 5 | loss: 0.4486329\n",
      "\tspeed: 0.0427s/iter; left time: 202.6676s\n",
      "\titers: 700, epoch: 5 | loss: 0.4750489\n",
      "\tspeed: 0.0427s/iter; left time: 198.4308s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578401\n",
      "\tspeed: 0.0427s/iter; left time: 194.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4898551 Vali Loss: 0.7914582 Test Loss: 0.9788902\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:33044252.0, rmse:5748.4130859375, mae:3757.29541015625, rse:0.2862730324268341\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8679006\n",
      "\tspeed: 0.0683s/iter; left time: 600.6023s\n",
      "\titers: 200, epoch: 1 | loss: 0.7743645\n",
      "\tspeed: 0.0432s/iter; left time: 375.6474s\n",
      "\titers: 300, epoch: 1 | loss: 0.7822117\n",
      "\tspeed: 0.0432s/iter; left time: 371.2187s\n",
      "\titers: 400, epoch: 1 | loss: 0.8378281\n",
      "\tspeed: 0.0432s/iter; left time: 366.5664s\n",
      "\titers: 500, epoch: 1 | loss: 0.8232630\n",
      "\tspeed: 0.0432s/iter; left time: 362.8011s\n",
      "\titers: 600, epoch: 1 | loss: 0.7636237\n",
      "\tspeed: 0.0432s/iter; left time: 358.0541s\n",
      "\titers: 700, epoch: 1 | loss: 0.7548945\n",
      "\tspeed: 0.0432s/iter; left time: 353.5607s\n",
      "\titers: 800, epoch: 1 | loss: 0.7713766\n",
      "\tspeed: 0.0432s/iter; left time: 349.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 889 | Train Loss: 0.7772274 Vali Loss: 0.6790550 Test Loss: 0.8057779\n",
      "Validation loss decreased (inf --> 0.679055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7821077\n",
      "\tspeed: 0.1542s/iter; left time: 1218.8475s\n",
      "\titers: 200, epoch: 2 | loss: 0.7020079\n",
      "\tspeed: 0.0432s/iter; left time: 336.9298s\n",
      "\titers: 300, epoch: 2 | loss: 0.8012208\n",
      "\tspeed: 0.0433s/iter; left time: 333.2259s\n",
      "\titers: 400, epoch: 2 | loss: 0.7271333\n",
      "\tspeed: 0.0433s/iter; left time: 328.9338s\n",
      "\titers: 500, epoch: 2 | loss: 0.7285502\n",
      "\tspeed: 0.0432s/iter; left time: 324.0713s\n",
      "\titers: 600, epoch: 2 | loss: 0.7326428\n",
      "\tspeed: 0.0432s/iter; left time: 319.8952s\n",
      "\titers: 700, epoch: 2 | loss: 0.6793472\n",
      "\tspeed: 0.0432s/iter; left time: 315.4515s\n",
      "\titers: 800, epoch: 2 | loss: 0.7332686\n",
      "\tspeed: 0.0432s/iter; left time: 311.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 889 | Train Loss: 0.7356485 Vali Loss: 0.6576813 Test Loss: 0.8276157\n",
      "Validation loss decreased (0.679055 --> 0.657681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6861941\n",
      "\tspeed: 0.1546s/iter; left time: 1084.3016s\n",
      "\titers: 200, epoch: 3 | loss: 0.6369764\n",
      "\tspeed: 0.0432s/iter; left time: 298.8567s\n",
      "\titers: 300, epoch: 3 | loss: 0.6813426\n",
      "\tspeed: 0.0432s/iter; left time: 294.4233s\n",
      "\titers: 400, epoch: 3 | loss: 0.6887080\n",
      "\tspeed: 0.0432s/iter; left time: 289.9058s\n",
      "\titers: 500, epoch: 3 | loss: 0.7160903\n",
      "\tspeed: 0.0432s/iter; left time: 285.4743s\n",
      "\titers: 600, epoch: 3 | loss: 0.6524235\n",
      "\tspeed: 0.0432s/iter; left time: 281.0624s\n",
      "\titers: 700, epoch: 3 | loss: 0.6551255\n",
      "\tspeed: 0.0432s/iter; left time: 276.9010s\n",
      "\titers: 800, epoch: 3 | loss: 0.6208397\n",
      "\tspeed: 0.0432s/iter; left time: 272.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 889 | Train Loss: 0.6604352 Vali Loss: 0.7732214 Test Loss: 0.9868738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5560720\n",
      "\tspeed: 0.1527s/iter; left time: 934.9018s\n",
      "\titers: 200, epoch: 4 | loss: 0.5402793\n",
      "\tspeed: 0.0432s/iter; left time: 260.3191s\n",
      "\titers: 300, epoch: 4 | loss: 0.6283324\n",
      "\tspeed: 0.0432s/iter; left time: 255.8999s\n",
      "\titers: 400, epoch: 4 | loss: 0.5678048\n",
      "\tspeed: 0.0433s/iter; left time: 251.9057s\n",
      "\titers: 500, epoch: 4 | loss: 0.5673718\n",
      "\tspeed: 0.0432s/iter; left time: 247.2866s\n",
      "\titers: 600, epoch: 4 | loss: 0.5018236\n",
      "\tspeed: 0.0432s/iter; left time: 242.8347s\n",
      "\titers: 700, epoch: 4 | loss: 0.5377899\n",
      "\tspeed: 0.0432s/iter; left time: 238.5908s\n",
      "\titers: 800, epoch: 4 | loss: 0.5352262\n",
      "\tspeed: 0.0432s/iter; left time: 234.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 889 | Train Loss: 0.5602547 Vali Loss: 0.7991609 Test Loss: 1.1161594\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5087005\n",
      "\tspeed: 0.1509s/iter; left time: 789.8248s\n",
      "\titers: 200, epoch: 5 | loss: 0.4705424\n",
      "\tspeed: 0.0432s/iter; left time: 221.9007s\n",
      "\titers: 300, epoch: 5 | loss: 0.4730842\n",
      "\tspeed: 0.0432s/iter; left time: 217.5780s\n",
      "\titers: 400, epoch: 5 | loss: 0.4877660\n",
      "\tspeed: 0.0432s/iter; left time: 213.3764s\n",
      "\titers: 500, epoch: 5 | loss: 0.4700000\n",
      "\tspeed: 0.0432s/iter; left time: 209.0086s\n",
      "\titers: 600, epoch: 5 | loss: 0.4700326\n",
      "\tspeed: 0.0433s/iter; left time: 204.8575s\n",
      "\titers: 700, epoch: 5 | loss: 0.4628400\n",
      "\tspeed: 0.0432s/iter; left time: 200.4115s\n",
      "\titers: 800, epoch: 5 | loss: 0.4603879\n",
      "\tspeed: 0.0432s/iter; left time: 196.0388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 889 | Train Loss: 0.4696992 Vali Loss: 0.8641824 Test Loss: 1.1385818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:35287100.0, rmse:5940.29443359375, mae:3912.64697265625, rse:0.2959740161895752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919598\n",
      "\tspeed: 0.0449s/iter; left time: 395.0978s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255026\n",
      "\tspeed: 0.0435s/iter; left time: 378.1619s\n",
      "\titers: 300, epoch: 1 | loss: 0.8588480\n",
      "\tspeed: 0.0433s/iter; left time: 372.3526s\n",
      "\titers: 400, epoch: 1 | loss: 0.8268682\n",
      "\tspeed: 0.0433s/iter; left time: 367.7582s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757027\n",
      "\tspeed: 0.0433s/iter; left time: 362.9782s\n",
      "\titers: 600, epoch: 1 | loss: 0.6946961\n",
      "\tspeed: 0.0432s/iter; left time: 358.5043s\n",
      "\titers: 700, epoch: 1 | loss: 0.7522021\n",
      "\tspeed: 0.0432s/iter; left time: 354.1527s\n",
      "\titers: 800, epoch: 1 | loss: 0.7110764\n",
      "\tspeed: 0.0432s/iter; left time: 349.9136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.7784579 Vali Loss: 0.6762899 Test Loss: 0.8039310\n",
      "Validation loss decreased (inf --> 0.676290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7776949\n",
      "\tspeed: 0.1549s/iter; left time: 1224.0055s\n",
      "\titers: 200, epoch: 2 | loss: 0.7495913\n",
      "\tspeed: 0.0432s/iter; left time: 337.3337s\n",
      "\titers: 300, epoch: 2 | loss: 0.7632322\n",
      "\tspeed: 0.0432s/iter; left time: 333.0472s\n",
      "\titers: 400, epoch: 2 | loss: 0.7406695\n",
      "\tspeed: 0.0432s/iter; left time: 328.5177s\n",
      "\titers: 500, epoch: 2 | loss: 0.7516730\n",
      "\tspeed: 0.0432s/iter; left time: 324.0646s\n",
      "\titers: 600, epoch: 2 | loss: 0.7519017\n",
      "\tspeed: 0.0432s/iter; left time: 319.8534s\n",
      "\titers: 700, epoch: 2 | loss: 0.7013571\n",
      "\tspeed: 0.0432s/iter; left time: 315.6464s\n",
      "\titers: 800, epoch: 2 | loss: 0.6977748\n",
      "\tspeed: 0.0432s/iter; left time: 311.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.7361888 Vali Loss: 0.6949371 Test Loss: 0.8629977\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6662261\n",
      "\tspeed: 0.1527s/iter; left time: 1071.0055s\n",
      "\titers: 200, epoch: 3 | loss: 0.6339747\n",
      "\tspeed: 0.0432s/iter; left time: 298.7505s\n",
      "\titers: 300, epoch: 3 | loss: 0.7117482\n",
      "\tspeed: 0.0432s/iter; left time: 294.5166s\n",
      "\titers: 400, epoch: 3 | loss: 0.7264873\n",
      "\tspeed: 0.0432s/iter; left time: 289.8961s\n",
      "\titers: 500, epoch: 3 | loss: 0.6518920\n",
      "\tspeed: 0.0432s/iter; left time: 285.4952s\n",
      "\titers: 600, epoch: 3 | loss: 0.6870541\n",
      "\tspeed: 0.0432s/iter; left time: 281.6136s\n",
      "\titers: 700, epoch: 3 | loss: 0.6374604\n",
      "\tspeed: 0.0432s/iter; left time: 276.9444s\n",
      "\titers: 800, epoch: 3 | loss: 0.6561266\n",
      "\tspeed: 0.0432s/iter; left time: 272.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 889 | Train Loss: 0.6618887 Vali Loss: 0.7081003 Test Loss: 0.9726987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6204436\n",
      "\tspeed: 0.1524s/iter; left time: 933.2324s\n",
      "\titers: 200, epoch: 4 | loss: 0.5560814\n",
      "\tspeed: 0.0432s/iter; left time: 260.4092s\n",
      "\titers: 300, epoch: 4 | loss: 0.5717813\n",
      "\tspeed: 0.0432s/iter; left time: 256.0169s\n",
      "\titers: 400, epoch: 4 | loss: 0.5512108\n",
      "\tspeed: 0.0432s/iter; left time: 251.6596s\n",
      "\titers: 500, epoch: 4 | loss: 0.5558363\n",
      "\tspeed: 0.0432s/iter; left time: 247.5310s\n",
      "\titers: 600, epoch: 4 | loss: 0.5101167\n",
      "\tspeed: 0.0432s/iter; left time: 243.0827s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733330\n",
      "\tspeed: 0.0432s/iter; left time: 238.5310s\n",
      "\titers: 800, epoch: 4 | loss: 0.5397598\n",
      "\tspeed: 0.0432s/iter; left time: 234.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.5612400 Vali Loss: 0.7595485 Test Loss: 1.0782422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:34170808.0, rmse:5845.580078125, mae:3891.957763671875, rse:0.2912548780441284\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4695036\n",
      "\tspeed: 0.0697s/iter; left time: 615.2904s\n",
      "\titers: 200, epoch: 1 | loss: 0.4849952\n",
      "\tspeed: 0.0425s/iter; left time: 370.8313s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187118\n",
      "\tspeed: 0.0424s/iter; left time: 365.5846s\n",
      "\titers: 400, epoch: 1 | loss: 0.4342759\n",
      "\tspeed: 0.0423s/iter; left time: 361.2657s\n",
      "\titers: 500, epoch: 1 | loss: 0.4137512\n",
      "\tspeed: 0.0425s/iter; left time: 358.3220s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539363\n",
      "\tspeed: 0.0425s/iter; left time: 354.0961s\n",
      "\titers: 700, epoch: 1 | loss: 0.4049172\n",
      "\tspeed: 0.0425s/iter; left time: 349.5979s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974779\n",
      "\tspeed: 0.0425s/iter; left time: 345.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 893 | Train Loss: 0.4296926 Vali Loss: 0.4422245 Test Loss: 0.4514492\n",
      "Validation loss decreased (inf --> 0.442224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4751551\n",
      "\tspeed: 0.1531s/iter; left time: 1215.1228s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530021\n",
      "\tspeed: 0.0423s/iter; left time: 331.7378s\n",
      "\titers: 300, epoch: 2 | loss: 0.3882786\n",
      "\tspeed: 0.0424s/iter; left time: 327.7603s\n",
      "\titers: 400, epoch: 2 | loss: 0.4140501\n",
      "\tspeed: 0.0424s/iter; left time: 323.5763s\n",
      "\titers: 500, epoch: 2 | loss: 0.3746513\n",
      "\tspeed: 0.0424s/iter; left time: 319.3081s\n",
      "\titers: 600, epoch: 2 | loss: 0.3730287\n",
      "\tspeed: 0.0424s/iter; left time: 315.1699s\n",
      "\titers: 700, epoch: 2 | loss: 0.4009704\n",
      "\tspeed: 0.0424s/iter; left time: 310.9456s\n",
      "\titers: 800, epoch: 2 | loss: 0.3358727\n",
      "\tspeed: 0.0424s/iter; left time: 307.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3956892 Vali Loss: 0.4311240 Test Loss: 0.4466510\n",
      "Validation loss decreased (0.442224 --> 0.431124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2904167\n",
      "\tspeed: 0.1515s/iter; left time: 1067.2528s\n",
      "\titers: 200, epoch: 3 | loss: 0.3576709\n",
      "\tspeed: 0.0425s/iter; left time: 295.0384s\n",
      "\titers: 300, epoch: 3 | loss: 0.3403774\n",
      "\tspeed: 0.0425s/iter; left time: 291.0615s\n",
      "\titers: 400, epoch: 3 | loss: 0.3329291\n",
      "\tspeed: 0.0425s/iter; left time: 286.6579s\n",
      "\titers: 500, epoch: 3 | loss: 0.3230645\n",
      "\tspeed: 0.0425s/iter; left time: 282.3690s\n",
      "\titers: 600, epoch: 3 | loss: 0.3635491\n",
      "\tspeed: 0.0425s/iter; left time: 278.1800s\n",
      "\titers: 700, epoch: 3 | loss: 0.2835732\n",
      "\tspeed: 0.0424s/iter; left time: 273.5474s\n",
      "\titers: 800, epoch: 3 | loss: 0.3851331\n",
      "\tspeed: 0.0424s/iter; left time: 269.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.3495539 Vali Loss: 0.4219367 Test Loss: 0.4352997\n",
      "Validation loss decreased (0.431124 --> 0.421937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3447823\n",
      "\tspeed: 0.1519s/iter; left time: 934.3858s\n",
      "\titers: 200, epoch: 4 | loss: 0.3190766\n",
      "\tspeed: 0.0426s/iter; left time: 257.5507s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549941\n",
      "\tspeed: 0.0424s/iter; left time: 252.5220s\n",
      "\titers: 400, epoch: 4 | loss: 0.2950929\n",
      "\tspeed: 0.0425s/iter; left time: 248.4279s\n",
      "\titers: 500, epoch: 4 | loss: 0.4276862\n",
      "\tspeed: 0.0425s/iter; left time: 244.2109s\n",
      "\titers: 600, epoch: 4 | loss: 0.3246305\n",
      "\tspeed: 0.0425s/iter; left time: 240.0189s\n",
      "\titers: 700, epoch: 4 | loss: 0.3205589\n",
      "\tspeed: 0.0425s/iter; left time: 235.8116s\n",
      "\titers: 800, epoch: 4 | loss: 0.3858584\n",
      "\tspeed: 0.0425s/iter; left time: 231.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.3416200 Vali Loss: 0.4134573 Test Loss: 0.4247172\n",
      "Validation loss decreased (0.421937 --> 0.413457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3319281\n",
      "\tspeed: 0.1529s/iter; left time: 803.8689s\n",
      "\titers: 200, epoch: 5 | loss: 0.2934890\n",
      "\tspeed: 0.0425s/iter; left time: 219.1244s\n",
      "\titers: 300, epoch: 5 | loss: 0.3355778\n",
      "\tspeed: 0.0424s/iter; left time: 214.6815s\n",
      "\titers: 400, epoch: 5 | loss: 0.3117720\n",
      "\tspeed: 0.0425s/iter; left time: 210.7057s\n",
      "\titers: 500, epoch: 5 | loss: 0.3203244\n",
      "\tspeed: 0.0425s/iter; left time: 206.3100s\n",
      "\titers: 600, epoch: 5 | loss: 0.2914104\n",
      "\tspeed: 0.0425s/iter; left time: 202.0619s\n",
      "\titers: 700, epoch: 5 | loss: 0.3308161\n",
      "\tspeed: 0.0424s/iter; left time: 197.6357s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173711\n",
      "\tspeed: 0.0424s/iter; left time: 193.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3343107 Vali Loss: 0.4109769 Test Loss: 0.4230208\n",
      "Validation loss decreased (0.413457 --> 0.410977).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2896678\n",
      "\tspeed: 0.1518s/iter; left time: 662.5889s\n",
      "\titers: 200, epoch: 6 | loss: 0.3515523\n",
      "\tspeed: 0.0425s/iter; left time: 181.1912s\n",
      "\titers: 300, epoch: 6 | loss: 0.3070067\n",
      "\tspeed: 0.0426s/iter; left time: 177.3666s\n",
      "\titers: 400, epoch: 6 | loss: 0.2854919\n",
      "\tspeed: 0.0425s/iter; left time: 172.9339s\n",
      "\titers: 500, epoch: 6 | loss: 0.3352777\n",
      "\tspeed: 0.0425s/iter; left time: 168.5926s\n",
      "\titers: 600, epoch: 6 | loss: 0.3287666\n",
      "\tspeed: 0.0425s/iter; left time: 164.2455s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857096\n",
      "\tspeed: 0.0425s/iter; left time: 159.9476s\n",
      "\titers: 800, epoch: 6 | loss: 0.3255485\n",
      "\tspeed: 0.0425s/iter; left time: 155.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3294495 Vali Loss: 0.4255356 Test Loss: 0.4324502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3365586\n",
      "\tspeed: 0.1502s/iter; left time: 521.5952s\n",
      "\titers: 200, epoch: 7 | loss: 0.3124640\n",
      "\tspeed: 0.0424s/iter; left time: 142.8652s\n",
      "\titers: 300, epoch: 7 | loss: 0.3412698\n",
      "\tspeed: 0.0424s/iter; left time: 138.6347s\n",
      "\titers: 400, epoch: 7 | loss: 0.3270743\n",
      "\tspeed: 0.0424s/iter; left time: 134.3780s\n",
      "\titers: 500, epoch: 7 | loss: 0.3453423\n",
      "\tspeed: 0.0422s/iter; left time: 129.8145s\n",
      "\titers: 600, epoch: 7 | loss: 0.3201989\n",
      "\tspeed: 0.0427s/iter; left time: 126.9313s\n",
      "\titers: 700, epoch: 7 | loss: 0.2999701\n",
      "\tspeed: 0.0427s/iter; left time: 122.7044s\n",
      "\titers: 800, epoch: 7 | loss: 0.3040497\n",
      "\tspeed: 0.0425s/iter; left time: 117.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3237632 Vali Loss: 0.4205632 Test Loss: 0.4347714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3042686\n",
      "\tspeed: 0.1495s/iter; left time: 385.7048s\n",
      "\titers: 200, epoch: 8 | loss: 0.3169928\n",
      "\tspeed: 0.0425s/iter; left time: 105.4377s\n",
      "\titers: 300, epoch: 8 | loss: 0.2797357\n",
      "\tspeed: 0.0424s/iter; left time: 101.0073s\n",
      "\titers: 400, epoch: 8 | loss: 0.3393894\n",
      "\tspeed: 0.0425s/iter; left time: 96.8225s\n",
      "\titers: 500, epoch: 8 | loss: 0.3562687\n",
      "\tspeed: 0.0425s/iter; left time: 92.5743s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649100\n",
      "\tspeed: 0.0424s/iter; left time: 88.2899s\n",
      "\titers: 700, epoch: 8 | loss: 0.3125881\n",
      "\tspeed: 0.0425s/iter; left time: 84.1377s\n",
      "\titers: 800, epoch: 8 | loss: 0.3596777\n",
      "\tspeed: 0.0425s/iter; left time: 79.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3133540 Vali Loss: 0.4209787 Test Loss: 0.4364639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:17183404.0, rmse:4145.287109375, mae:2456.189453125, rse:0.20611201226711273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4739339\n",
      "\tspeed: 0.0441s/iter; left time: 389.5447s\n",
      "\titers: 200, epoch: 1 | loss: 0.4540531\n",
      "\tspeed: 0.0424s/iter; left time: 370.4908s\n",
      "\titers: 300, epoch: 1 | loss: 0.3691141\n",
      "\tspeed: 0.0425s/iter; left time: 366.5145s\n",
      "\titers: 400, epoch: 1 | loss: 0.3733300\n",
      "\tspeed: 0.0425s/iter; left time: 362.2957s\n",
      "\titers: 500, epoch: 1 | loss: 0.3640547\n",
      "\tspeed: 0.0425s/iter; left time: 358.0648s\n",
      "\titers: 600, epoch: 1 | loss: 0.3699769\n",
      "\tspeed: 0.0424s/iter; left time: 353.3170s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467535\n",
      "\tspeed: 0.0424s/iter; left time: 349.3035s\n",
      "\titers: 800, epoch: 1 | loss: 0.3464169\n",
      "\tspeed: 0.0424s/iter; left time: 344.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.4279929 Vali Loss: 0.4427081 Test Loss: 0.4532785\n",
      "Validation loss decreased (inf --> 0.442708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4089020\n",
      "\tspeed: 0.1527s/iter; left time: 1212.2900s\n",
      "\titers: 200, epoch: 2 | loss: 0.3849083\n",
      "\tspeed: 0.0425s/iter; left time: 332.8996s\n",
      "\titers: 300, epoch: 2 | loss: 0.3607240\n",
      "\tspeed: 0.0425s/iter; left time: 329.0818s\n",
      "\titers: 400, epoch: 2 | loss: 0.4332860\n",
      "\tspeed: 0.0425s/iter; left time: 324.6467s\n",
      "\titers: 500, epoch: 2 | loss: 0.3553748\n",
      "\tspeed: 0.0425s/iter; left time: 320.5110s\n",
      "\titers: 600, epoch: 2 | loss: 0.3558212\n",
      "\tspeed: 0.0425s/iter; left time: 315.9846s\n",
      "\titers: 700, epoch: 2 | loss: 0.3483924\n",
      "\tspeed: 0.0425s/iter; left time: 311.5645s\n",
      "\titers: 800, epoch: 2 | loss: 0.3718648\n",
      "\tspeed: 0.0424s/iter; left time: 307.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3910895 Vali Loss: 0.4320702 Test Loss: 0.4399559\n",
      "Validation loss decreased (0.442708 --> 0.432070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3337142\n",
      "\tspeed: 0.1574s/iter; left time: 1109.1144s\n",
      "\titers: 200, epoch: 3 | loss: 0.3450969\n",
      "\tspeed: 0.0425s/iter; left time: 295.2261s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313186\n",
      "\tspeed: 0.0426s/iter; left time: 291.5750s\n",
      "\titers: 400, epoch: 3 | loss: 0.3627611\n",
      "\tspeed: 0.0426s/iter; left time: 287.5179s\n",
      "\titers: 500, epoch: 3 | loss: 0.3072940\n",
      "\tspeed: 0.0426s/iter; left time: 283.3966s\n",
      "\titers: 600, epoch: 3 | loss: 0.3159499\n",
      "\tspeed: 0.0427s/iter; left time: 279.4149s\n",
      "\titers: 700, epoch: 3 | loss: 0.3433414\n",
      "\tspeed: 0.0427s/iter; left time: 275.2375s\n",
      "\titers: 800, epoch: 3 | loss: 0.3504495\n",
      "\tspeed: 0.0426s/iter; left time: 270.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 893 | Train Loss: 0.3478101 Vali Loss: 0.4106736 Test Loss: 0.4247069\n",
      "Validation loss decreased (0.432070 --> 0.410674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664916\n",
      "\tspeed: 0.1535s/iter; left time: 944.1809s\n",
      "\titers: 200, epoch: 4 | loss: 0.3556045\n",
      "\tspeed: 0.0425s/iter; left time: 257.2515s\n",
      "\titers: 300, epoch: 4 | loss: 0.3436058\n",
      "\tspeed: 0.0425s/iter; left time: 252.8880s\n",
      "\titers: 400, epoch: 4 | loss: 0.3065186\n",
      "\tspeed: 0.0427s/iter; left time: 249.9928s\n",
      "\titers: 500, epoch: 4 | loss: 0.3289182\n",
      "\tspeed: 0.0424s/iter; left time: 243.6402s\n",
      "\titers: 600, epoch: 4 | loss: 0.3316960\n",
      "\tspeed: 0.0424s/iter; left time: 239.3920s\n",
      "\titers: 700, epoch: 4 | loss: 0.3341659\n",
      "\tspeed: 0.0423s/iter; left time: 235.0668s\n",
      "\titers: 800, epoch: 4 | loss: 0.2980278\n",
      "\tspeed: 0.0425s/iter; left time: 231.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3400171 Vali Loss: 0.4142010 Test Loss: 0.4281743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3242514\n",
      "\tspeed: 0.1513s/iter; left time: 795.6441s\n",
      "\titers: 200, epoch: 5 | loss: 0.3074272\n",
      "\tspeed: 0.0427s/iter; left time: 220.0656s\n",
      "\titers: 300, epoch: 5 | loss: 0.3388836\n",
      "\tspeed: 0.0427s/iter; left time: 216.1939s\n",
      "\titers: 400, epoch: 5 | loss: 0.3729826\n",
      "\tspeed: 0.0427s/iter; left time: 211.5128s\n",
      "\titers: 500, epoch: 5 | loss: 0.4128991\n",
      "\tspeed: 0.0427s/iter; left time: 207.6761s\n",
      "\titers: 600, epoch: 5 | loss: 0.3496001\n",
      "\tspeed: 0.0423s/iter; left time: 201.4039s\n",
      "\titers: 700, epoch: 5 | loss: 0.3578146\n",
      "\tspeed: 0.0423s/iter; left time: 197.0739s\n",
      "\titers: 800, epoch: 5 | loss: 0.3022088\n",
      "\tspeed: 0.0425s/iter; left time: 193.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.3320721 Vali Loss: 0.4036397 Test Loss: 0.4186656\n",
      "Validation loss decreased (0.410674 --> 0.403640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3790839\n",
      "\tspeed: 0.1522s/iter; left time: 664.6101s\n",
      "\titers: 200, epoch: 6 | loss: 0.2824487\n",
      "\tspeed: 0.0424s/iter; left time: 180.8449s\n",
      "\titers: 300, epoch: 6 | loss: 0.3130301\n",
      "\tspeed: 0.0423s/iter; left time: 176.3249s\n",
      "\titers: 400, epoch: 6 | loss: 0.3765152\n",
      "\tspeed: 0.0427s/iter; left time: 173.5416s\n",
      "\titers: 500, epoch: 6 | loss: 0.2899759\n",
      "\tspeed: 0.0426s/iter; left time: 169.1110s\n",
      "\titers: 600, epoch: 6 | loss: 0.3341354\n",
      "\tspeed: 0.0427s/iter; left time: 165.1618s\n",
      "\titers: 700, epoch: 6 | loss: 0.3467826\n",
      "\tspeed: 0.0426s/iter; left time: 160.2672s\n",
      "\titers: 800, epoch: 6 | loss: 0.3329554\n",
      "\tspeed: 0.0423s/iter; left time: 155.2495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3288571 Vali Loss: 0.4075786 Test Loss: 0.4223005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471135\n",
      "\tspeed: 0.1518s/iter; left time: 527.0865s\n",
      "\titers: 200, epoch: 7 | loss: 0.3624613\n",
      "\tspeed: 0.0426s/iter; left time: 143.6072s\n",
      "\titers: 300, epoch: 7 | loss: 0.3461682\n",
      "\tspeed: 0.0425s/iter; left time: 139.0432s\n",
      "\titers: 400, epoch: 7 | loss: 0.3192582\n",
      "\tspeed: 0.0425s/iter; left time: 135.0034s\n",
      "\titers: 500, epoch: 7 | loss: 0.2862870\n",
      "\tspeed: 0.0426s/iter; left time: 130.7717s\n",
      "\titers: 600, epoch: 7 | loss: 0.3154697\n",
      "\tspeed: 0.0424s/iter; left time: 126.0293s\n",
      "\titers: 700, epoch: 7 | loss: 0.3064333\n",
      "\tspeed: 0.0424s/iter; left time: 121.7827s\n",
      "\titers: 800, epoch: 7 | loss: 0.3354075\n",
      "\tspeed: 0.0426s/iter; left time: 118.0323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.3221708 Vali Loss: 0.4098179 Test Loss: 0.4235730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2890800\n",
      "\tspeed: 0.1508s/iter; left time: 388.9926s\n",
      "\titers: 200, epoch: 8 | loss: 0.3243214\n",
      "\tspeed: 0.0424s/iter; left time: 105.1022s\n",
      "\titers: 300, epoch: 8 | loss: 0.2589266\n",
      "\tspeed: 0.0426s/iter; left time: 101.4863s\n",
      "\titers: 400, epoch: 8 | loss: 0.3333530\n",
      "\tspeed: 0.0427s/iter; left time: 97.3608s\n",
      "\titers: 500, epoch: 8 | loss: 0.2846834\n",
      "\tspeed: 0.0427s/iter; left time: 93.0912s\n",
      "\titers: 600, epoch: 8 | loss: 0.3179591\n",
      "\tspeed: 0.0427s/iter; left time: 88.8227s\n",
      "\titers: 700, epoch: 8 | loss: 0.3226090\n",
      "\tspeed: 0.0427s/iter; left time: 84.5180s\n",
      "\titers: 800, epoch: 8 | loss: 0.3119867\n",
      "\tspeed: 0.0427s/iter; left time: 80.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 893 | Train Loss: 0.3134166 Vali Loss: 0.4092242 Test Loss: 0.4205885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "mse:16678795.0, rmse:4083.968017578125, mae:2431.303955078125, rse:0.20306311547756195\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6374813\n",
      "\tspeed: 0.0700s/iter; left time: 616.6438s\n",
      "\titers: 200, epoch: 1 | loss: 0.5262504\n",
      "\tspeed: 0.0427s/iter; left time: 371.9602s\n",
      "\titers: 300, epoch: 1 | loss: 0.5496212\n",
      "\tspeed: 0.0428s/iter; left time: 368.2575s\n",
      "\titers: 400, epoch: 1 | loss: 0.4834964\n",
      "\tspeed: 0.0429s/iter; left time: 365.1157s\n",
      "\titers: 500, epoch: 1 | loss: 0.5325756\n",
      "\tspeed: 0.0428s/iter; left time: 360.3059s\n",
      "\titers: 600, epoch: 1 | loss: 0.4872109\n",
      "\tspeed: 0.0428s/iter; left time: 355.9074s\n",
      "\titers: 700, epoch: 1 | loss: 0.5237520\n",
      "\tspeed: 0.0428s/iter; left time: 351.5119s\n",
      "\titers: 800, epoch: 1 | loss: 0.5554903\n",
      "\tspeed: 0.0428s/iter; left time: 347.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 891 | Train Loss: 0.5397429 Vali Loss: 0.5700328 Test Loss: 0.6036903\n",
      "Validation loss decreased (inf --> 0.570033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5374577\n",
      "\tspeed: 0.1523s/iter; left time: 1206.0015s\n",
      "\titers: 200, epoch: 2 | loss: 0.5270962\n",
      "\tspeed: 0.0428s/iter; left time: 334.8108s\n",
      "\titers: 300, epoch: 2 | loss: 0.4995303\n",
      "\tspeed: 0.0429s/iter; left time: 330.9407s\n",
      "\titers: 400, epoch: 2 | loss: 0.5156381\n",
      "\tspeed: 0.0428s/iter; left time: 326.5028s\n",
      "\titers: 500, epoch: 2 | loss: 0.4754504\n",
      "\tspeed: 0.0428s/iter; left time: 321.6030s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311262\n",
      "\tspeed: 0.0428s/iter; left time: 317.5611s\n",
      "\titers: 700, epoch: 2 | loss: 0.4329669\n",
      "\tspeed: 0.0427s/iter; left time: 312.9252s\n",
      "\titers: 800, epoch: 2 | loss: 0.5162832\n",
      "\tspeed: 0.0428s/iter; left time: 309.1032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.5097087 Vali Loss: 0.5559564 Test Loss: 0.5963426\n",
      "Validation loss decreased (0.570033 --> 0.555956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4553922\n",
      "\tspeed: 0.1524s/iter; left time: 1071.0419s\n",
      "\titers: 200, epoch: 3 | loss: 0.4781276\n",
      "\tspeed: 0.0428s/iter; left time: 296.4583s\n",
      "\titers: 300, epoch: 3 | loss: 0.5148327\n",
      "\tspeed: 0.0428s/iter; left time: 292.3861s\n",
      "\titers: 400, epoch: 3 | loss: 0.4678192\n",
      "\tspeed: 0.0428s/iter; left time: 287.9147s\n",
      "\titers: 500, epoch: 3 | loss: 0.4578561\n",
      "\tspeed: 0.0427s/iter; left time: 283.2720s\n",
      "\titers: 600, epoch: 3 | loss: 0.4424357\n",
      "\tspeed: 0.0428s/iter; left time: 279.2077s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751456\n",
      "\tspeed: 0.0428s/iter; left time: 274.9730s\n",
      "\titers: 800, epoch: 3 | loss: 0.4236996\n",
      "\tspeed: 0.0427s/iter; left time: 270.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4665015 Vali Loss: 0.5722540 Test Loss: 0.6234865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4868843\n",
      "\tspeed: 0.1498s/iter; left time: 919.6686s\n",
      "\titers: 200, epoch: 4 | loss: 0.4776935\n",
      "\tspeed: 0.0428s/iter; left time: 258.1940s\n",
      "\titers: 300, epoch: 4 | loss: 0.4831240\n",
      "\tspeed: 0.0428s/iter; left time: 253.8846s\n",
      "\titers: 400, epoch: 4 | loss: 0.4405861\n",
      "\tspeed: 0.0428s/iter; left time: 249.5942s\n",
      "\titers: 500, epoch: 4 | loss: 0.4349448\n",
      "\tspeed: 0.0427s/iter; left time: 245.2233s\n",
      "\titers: 600, epoch: 4 | loss: 0.4479438\n",
      "\tspeed: 0.0427s/iter; left time: 240.9683s\n",
      "\titers: 700, epoch: 4 | loss: 0.4399997\n",
      "\tspeed: 0.0428s/iter; left time: 236.9848s\n",
      "\titers: 800, epoch: 4 | loss: 0.3783943\n",
      "\tspeed: 0.0427s/iter; left time: 232.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4382588 Vali Loss: 0.5783772 Test Loss: 0.6318021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4318333\n",
      "\tspeed: 0.1505s/iter; left time: 789.7706s\n",
      "\titers: 200, epoch: 5 | loss: 0.3880471\n",
      "\tspeed: 0.0427s/iter; left time: 219.9383s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674024\n",
      "\tspeed: 0.0431s/iter; left time: 217.7448s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704361\n",
      "\tspeed: 0.0429s/iter; left time: 212.0775s\n",
      "\titers: 500, epoch: 5 | loss: 0.3912926\n",
      "\tspeed: 0.0428s/iter; left time: 207.2726s\n",
      "\titers: 600, epoch: 5 | loss: 0.3840115\n",
      "\tspeed: 0.0427s/iter; left time: 202.8442s\n",
      "\titers: 700, epoch: 5 | loss: 0.3629414\n",
      "\tspeed: 0.0428s/iter; left time: 198.9454s\n",
      "\titers: 800, epoch: 5 | loss: 0.3453966\n",
      "\tspeed: 0.0428s/iter; left time: 194.7034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3968851 Vali Loss: 0.5949938 Test Loss: 0.6539372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:31555720.0, rmse:5617.44775390625, mae:3527.80322265625, rse:0.27975091338157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5567461\n",
      "\tspeed: 0.0444s/iter; left time: 390.8982s\n",
      "\titers: 200, epoch: 1 | loss: 0.5131473\n",
      "\tspeed: 0.0427s/iter; left time: 371.7648s\n",
      "\titers: 300, epoch: 1 | loss: 0.5688336\n",
      "\tspeed: 0.0429s/iter; left time: 369.7850s\n",
      "\titers: 400, epoch: 1 | loss: 0.5851882\n",
      "\tspeed: 0.0430s/iter; left time: 365.5800s\n",
      "\titers: 500, epoch: 1 | loss: 0.4940234\n",
      "\tspeed: 0.0430s/iter; left time: 361.8584s\n",
      "\titers: 600, epoch: 1 | loss: 0.5569887\n",
      "\tspeed: 0.0430s/iter; left time: 357.0433s\n",
      "\titers: 700, epoch: 1 | loss: 0.5020673\n",
      "\tspeed: 0.0430s/iter; left time: 352.8796s\n",
      "\titers: 800, epoch: 1 | loss: 0.5009230\n",
      "\tspeed: 0.0428s/iter; left time: 346.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 891 | Train Loss: 0.5401562 Vali Loss: 0.5691482 Test Loss: 0.6024293\n",
      "Validation loss decreased (inf --> 0.569148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5425625\n",
      "\tspeed: 0.1551s/iter; left time: 1228.0807s\n",
      "\titers: 200, epoch: 2 | loss: 0.5092666\n",
      "\tspeed: 0.0428s/iter; left time: 334.5522s\n",
      "\titers: 300, epoch: 2 | loss: 0.5347412\n",
      "\tspeed: 0.0427s/iter; left time: 329.9630s\n",
      "\titers: 400, epoch: 2 | loss: 0.5148687\n",
      "\tspeed: 0.0427s/iter; left time: 325.5986s\n",
      "\titers: 500, epoch: 2 | loss: 0.4511907\n",
      "\tspeed: 0.0430s/iter; left time: 322.9937s\n",
      "\titers: 600, epoch: 2 | loss: 0.4812346\n",
      "\tspeed: 0.0429s/iter; left time: 317.9929s\n",
      "\titers: 700, epoch: 2 | loss: 0.5175083\n",
      "\tspeed: 0.0429s/iter; left time: 314.1196s\n",
      "\titers: 800, epoch: 2 | loss: 0.4783387\n",
      "\tspeed: 0.0431s/iter; left time: 310.8903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.5104276 Vali Loss: 0.5632515 Test Loss: 0.6076972\n",
      "Validation loss decreased (0.569148 --> 0.563251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4891643\n",
      "\tspeed: 0.1554s/iter; left time: 1092.1750s\n",
      "\titers: 200, epoch: 3 | loss: 0.4391293\n",
      "\tspeed: 0.0430s/iter; left time: 297.8711s\n",
      "\titers: 300, epoch: 3 | loss: 0.4282694\n",
      "\tspeed: 0.0428s/iter; left time: 292.3008s\n",
      "\titers: 400, epoch: 3 | loss: 0.4537349\n",
      "\tspeed: 0.0429s/iter; left time: 288.9873s\n",
      "\titers: 500, epoch: 3 | loss: 0.4212231\n",
      "\tspeed: 0.0431s/iter; left time: 285.8837s\n",
      "\titers: 600, epoch: 3 | loss: 0.4614433\n",
      "\tspeed: 0.0430s/iter; left time: 280.8610s\n",
      "\titers: 700, epoch: 3 | loss: 0.5231907\n",
      "\tspeed: 0.0428s/iter; left time: 274.9463s\n",
      "\titers: 800, epoch: 3 | loss: 0.4524678\n",
      "\tspeed: 0.0428s/iter; left time: 270.6528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 891 | Train Loss: 0.4641792 Vali Loss: 0.5592130 Test Loss: 0.6112368\n",
      "Validation loss decreased (0.563251 --> 0.559213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4562828\n",
      "\tspeed: 0.1540s/iter; left time: 945.0982s\n",
      "\titers: 200, epoch: 4 | loss: 0.4032119\n",
      "\tspeed: 0.0428s/iter; left time: 258.1533s\n",
      "\titers: 300, epoch: 4 | loss: 0.4174506\n",
      "\tspeed: 0.0427s/iter; left time: 253.7718s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366000\n",
      "\tspeed: 0.0427s/iter; left time: 249.4053s\n",
      "\titers: 500, epoch: 4 | loss: 0.3799008\n",
      "\tspeed: 0.0427s/iter; left time: 245.2448s\n",
      "\titers: 600, epoch: 4 | loss: 0.4402491\n",
      "\tspeed: 0.0427s/iter; left time: 240.8650s\n",
      "\titers: 700, epoch: 4 | loss: 0.4542446\n",
      "\tspeed: 0.0428s/iter; left time: 237.0867s\n",
      "\titers: 800, epoch: 4 | loss: 0.4093605\n",
      "\tspeed: 0.0427s/iter; left time: 232.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.4341894 Vali Loss: 0.5747357 Test Loss: 0.6246487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3754254\n",
      "\tspeed: 0.1511s/iter; left time: 793.0360s\n",
      "\titers: 200, epoch: 5 | loss: 0.3966073\n",
      "\tspeed: 0.0427s/iter; left time: 219.9439s\n",
      "\titers: 300, epoch: 5 | loss: 0.3927452\n",
      "\tspeed: 0.0429s/iter; left time: 216.7191s\n",
      "\titers: 400, epoch: 5 | loss: 0.4006265\n",
      "\tspeed: 0.0431s/iter; left time: 213.1588s\n",
      "\titers: 500, epoch: 5 | loss: 0.3565641\n",
      "\tspeed: 0.0431s/iter; left time: 208.7492s\n",
      "\titers: 600, epoch: 5 | loss: 0.3645180\n",
      "\tspeed: 0.0430s/iter; left time: 204.0449s\n",
      "\titers: 700, epoch: 5 | loss: 0.3615814\n",
      "\tspeed: 0.0429s/iter; left time: 199.5618s\n",
      "\titers: 800, epoch: 5 | loss: 0.3716194\n",
      "\tspeed: 0.0430s/iter; left time: 195.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 891 | Train Loss: 0.3956859 Vali Loss: 0.5881065 Test Loss: 0.6395448\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3419645\n",
      "\tspeed: 0.1524s/iter; left time: 663.6646s\n",
      "\titers: 200, epoch: 6 | loss: 0.3649749\n",
      "\tspeed: 0.0429s/iter; left time: 182.3883s\n",
      "\titers: 300, epoch: 6 | loss: 0.3397926\n",
      "\tspeed: 0.0429s/iter; left time: 178.1272s\n",
      "\titers: 400, epoch: 6 | loss: 0.3800455\n",
      "\tspeed: 0.0428s/iter; left time: 173.6780s\n",
      "\titers: 500, epoch: 6 | loss: 0.3381722\n",
      "\tspeed: 0.0431s/iter; left time: 170.6138s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673343\n",
      "\tspeed: 0.0431s/iter; left time: 166.2986s\n",
      "\titers: 700, epoch: 6 | loss: 0.3715284\n",
      "\tspeed: 0.0431s/iter; left time: 161.8672s\n",
      "\titers: 800, epoch: 6 | loss: 0.3510702\n",
      "\tspeed: 0.0431s/iter; left time: 157.6611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 891 | Train Loss: 0.3557695 Vali Loss: 0.5995966 Test Loss: 0.6508650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "mse:34537172.0, rmse:5876.83349609375, mae:3631.940673828125, rse:0.2926684021949768\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454177\n",
      "\tspeed: 0.0705s/iter; left time: 619.8695s\n",
      "\titers: 200, epoch: 1 | loss: 0.5544594\n",
      "\tspeed: 0.0433s/iter; left time: 376.6225s\n",
      "\titers: 300, epoch: 1 | loss: 0.5635941\n",
      "\tspeed: 0.0433s/iter; left time: 372.3177s\n",
      "\titers: 400, epoch: 1 | loss: 0.6180624\n",
      "\tspeed: 0.0433s/iter; left time: 368.0360s\n",
      "\titers: 500, epoch: 1 | loss: 0.5999923\n",
      "\tspeed: 0.0434s/iter; left time: 363.9416s\n",
      "\titers: 600, epoch: 1 | loss: 0.5538129\n",
      "\tspeed: 0.0434s/iter; left time: 359.4201s\n",
      "\titers: 700, epoch: 1 | loss: 0.5393959\n",
      "\tspeed: 0.0432s/iter; left time: 353.7348s\n",
      "\titers: 800, epoch: 1 | loss: 0.5381173\n",
      "\tspeed: 0.0432s/iter; left time: 349.2362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 889 | Train Loss: 0.5633903 Vali Loss: 0.5876741 Test Loss: 0.6291287\n",
      "Validation loss decreased (inf --> 0.587674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5834135\n",
      "\tspeed: 0.1533s/iter; left time: 1211.2908s\n",
      "\titers: 200, epoch: 2 | loss: 0.5220478\n",
      "\tspeed: 0.0433s/iter; left time: 338.0296s\n",
      "\titers: 300, epoch: 2 | loss: 0.5758332\n",
      "\tspeed: 0.0433s/iter; left time: 333.7176s\n",
      "\titers: 400, epoch: 2 | loss: 0.5207759\n",
      "\tspeed: 0.0433s/iter; left time: 329.4743s\n",
      "\titers: 500, epoch: 2 | loss: 0.5079741\n",
      "\tspeed: 0.0432s/iter; left time: 323.8823s\n",
      "\titers: 600, epoch: 2 | loss: 0.5090077\n",
      "\tspeed: 0.0432s/iter; left time: 319.6692s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622243\n",
      "\tspeed: 0.0432s/iter; left time: 315.1888s\n",
      "\titers: 800, epoch: 2 | loss: 0.5246297\n",
      "\tspeed: 0.0432s/iter; left time: 310.9166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.5286044 Vali Loss: 0.5791647 Test Loss: 0.6255860\n",
      "Validation loss decreased (0.587674 --> 0.579165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951027\n",
      "\tspeed: 0.1539s/iter; left time: 1079.2572s\n",
      "\titers: 200, epoch: 3 | loss: 0.4212805\n",
      "\tspeed: 0.0434s/iter; left time: 299.8473s\n",
      "\titers: 300, epoch: 3 | loss: 0.4809437\n",
      "\tspeed: 0.0433s/iter; left time: 295.1965s\n",
      "\titers: 400, epoch: 3 | loss: 0.5490001\n",
      "\tspeed: 0.0433s/iter; left time: 290.5263s\n",
      "\titers: 500, epoch: 3 | loss: 0.5272199\n",
      "\tspeed: 0.0432s/iter; left time: 285.9593s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973647\n",
      "\tspeed: 0.0433s/iter; left time: 281.7098s\n",
      "\titers: 700, epoch: 3 | loss: 0.4791625\n",
      "\tspeed: 0.0433s/iter; left time: 277.5539s\n",
      "\titers: 800, epoch: 3 | loss: 0.4444051\n",
      "\tspeed: 0.0433s/iter; left time: 273.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.4811308 Vali Loss: 0.5916529 Test Loss: 0.6518676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4643247\n",
      "\tspeed: 0.1503s/iter; left time: 920.4299s\n",
      "\titers: 200, epoch: 4 | loss: 0.4047467\n",
      "\tspeed: 0.0433s/iter; left time: 260.6602s\n",
      "\titers: 300, epoch: 4 | loss: 0.5270584\n",
      "\tspeed: 0.0432s/iter; left time: 256.0048s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366706\n",
      "\tspeed: 0.0434s/iter; left time: 252.6209s\n",
      "\titers: 500, epoch: 4 | loss: 0.4361570\n",
      "\tspeed: 0.0433s/iter; left time: 247.9236s\n",
      "\titers: 600, epoch: 4 | loss: 0.3978770\n",
      "\tspeed: 0.0433s/iter; left time: 243.4224s\n",
      "\titers: 700, epoch: 4 | loss: 0.4258873\n",
      "\tspeed: 0.0433s/iter; left time: 239.1998s\n",
      "\titers: 800, epoch: 4 | loss: 0.4317477\n",
      "\tspeed: 0.0433s/iter; left time: 234.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4384420 Vali Loss: 0.5988257 Test Loss: 0.6685336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3967570\n",
      "\tspeed: 0.1510s/iter; left time: 790.7030s\n",
      "\titers: 200, epoch: 5 | loss: 0.3766952\n",
      "\tspeed: 0.0433s/iter; left time: 222.3262s\n",
      "\titers: 300, epoch: 5 | loss: 0.3889566\n",
      "\tspeed: 0.0432s/iter; left time: 217.7584s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054741\n",
      "\tspeed: 0.0433s/iter; left time: 213.5191s\n",
      "\titers: 500, epoch: 5 | loss: 0.4088733\n",
      "\tspeed: 0.0432s/iter; left time: 209.0976s\n",
      "\titers: 600, epoch: 5 | loss: 0.3773878\n",
      "\tspeed: 0.0433s/iter; left time: 204.8259s\n",
      "\titers: 700, epoch: 5 | loss: 0.3832667\n",
      "\tspeed: 0.0433s/iter; left time: 200.5206s\n",
      "\titers: 800, epoch: 5 | loss: 0.3715691\n",
      "\tspeed: 0.0433s/iter; left time: 196.3094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.3870841 Vali Loss: 0.6039886 Test Loss: 0.6716257\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:35018344.0, rmse:5917.6298828125, mae:3745.188720703125, rse:0.29484474658966064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6611432\n",
      "\tspeed: 0.0452s/iter; left time: 397.7577s\n",
      "\titers: 200, epoch: 1 | loss: 0.5944821\n",
      "\tspeed: 0.0433s/iter; left time: 376.1018s\n",
      "\titers: 300, epoch: 1 | loss: 0.6297670\n",
      "\tspeed: 0.0432s/iter; left time: 371.4201s\n",
      "\titers: 400, epoch: 1 | loss: 0.6077808\n",
      "\tspeed: 0.0432s/iter; left time: 366.9029s\n",
      "\titers: 500, epoch: 1 | loss: 0.5648095\n",
      "\tspeed: 0.0432s/iter; left time: 362.6188s\n",
      "\titers: 600, epoch: 1 | loss: 0.4902555\n",
      "\tspeed: 0.0432s/iter; left time: 357.9935s\n",
      "\titers: 700, epoch: 1 | loss: 0.5395623\n",
      "\tspeed: 0.0432s/iter; left time: 353.6061s\n",
      "\titers: 800, epoch: 1 | loss: 0.5115961\n",
      "\tspeed: 0.0432s/iter; left time: 349.3375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5642094 Vali Loss: 0.5857942 Test Loss: 0.6274691\n",
      "Validation loss decreased (inf --> 0.585794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5886168\n",
      "\tspeed: 0.1544s/iter; left time: 1219.7969s\n",
      "\titers: 200, epoch: 2 | loss: 0.5624777\n",
      "\tspeed: 0.0434s/iter; left time: 338.4911s\n",
      "\titers: 300, epoch: 2 | loss: 0.5613257\n",
      "\tspeed: 0.0433s/iter; left time: 333.6724s\n",
      "\titers: 400, epoch: 2 | loss: 0.5375162\n",
      "\tspeed: 0.0433s/iter; left time: 329.2492s\n",
      "\titers: 500, epoch: 2 | loss: 0.5497366\n",
      "\tspeed: 0.0433s/iter; left time: 325.0094s\n",
      "\titers: 600, epoch: 2 | loss: 0.5392722\n",
      "\tspeed: 0.0433s/iter; left time: 320.4313s\n",
      "\titers: 700, epoch: 2 | loss: 0.4927635\n",
      "\tspeed: 0.0434s/iter; left time: 317.1355s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971849\n",
      "\tspeed: 0.0434s/iter; left time: 312.5289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5316510 Vali Loss: 0.5887495 Test Loss: 0.6355409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4743690\n",
      "\tspeed: 0.1528s/iter; left time: 1071.6913s\n",
      "\titers: 200, epoch: 3 | loss: 0.4684273\n",
      "\tspeed: 0.0434s/iter; left time: 300.1187s\n",
      "\titers: 300, epoch: 3 | loss: 0.5384349\n",
      "\tspeed: 0.0433s/iter; left time: 294.8290s\n",
      "\titers: 400, epoch: 3 | loss: 0.5281529\n",
      "\tspeed: 0.0432s/iter; left time: 290.1084s\n",
      "\titers: 500, epoch: 3 | loss: 0.4912407\n",
      "\tspeed: 0.0434s/iter; left time: 287.1009s\n",
      "\titers: 600, epoch: 3 | loss: 0.5095457\n",
      "\tspeed: 0.0434s/iter; left time: 282.9271s\n",
      "\titers: 700, epoch: 3 | loss: 0.4622054\n",
      "\tspeed: 0.0434s/iter; left time: 278.4783s\n",
      "\titers: 800, epoch: 3 | loss: 0.4754922\n",
      "\tspeed: 0.0434s/iter; left time: 273.9170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.78s\n",
      "Steps: 889 | Train Loss: 0.4833817 Vali Loss: 0.5937650 Test Loss: 0.6408314\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4836038\n",
      "\tspeed: 0.1523s/iter; left time: 932.4658s\n",
      "\titers: 200, epoch: 4 | loss: 0.4296790\n",
      "\tspeed: 0.0433s/iter; left time: 260.7802s\n",
      "\titers: 300, epoch: 4 | loss: 0.4317384\n",
      "\tspeed: 0.0432s/iter; left time: 255.9211s\n",
      "\titers: 400, epoch: 4 | loss: 0.3970349\n",
      "\tspeed: 0.0432s/iter; left time: 251.6957s\n",
      "\titers: 500, epoch: 4 | loss: 0.4507579\n",
      "\tspeed: 0.0433s/iter; left time: 247.5788s\n",
      "\titers: 600, epoch: 4 | loss: 0.4092776\n",
      "\tspeed: 0.0433s/iter; left time: 243.2961s\n",
      "\titers: 700, epoch: 4 | loss: 0.4983984\n",
      "\tspeed: 0.0432s/iter; left time: 238.8920s\n",
      "\titers: 800, epoch: 4 | loss: 0.4482481\n",
      "\tspeed: 0.0432s/iter; left time: 234.5388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.4415455 Vali Loss: 0.6122530 Test Loss: 0.6604525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "mse:33935912.0, rmse:5825.45361328125, mae:3740.77783203125, rse:0.29025208950042725\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results = []\n",
    "\n",
    "# Example usage: running the subprocess and capturing the output\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Run command with --itr 2 to ensure 2 iterations are handled internally\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --inverse \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Combine the output into a single string for easier pattern matching\n",
    "            output_str = \"\".join(output)\n",
    "\n",
    "            # Extract metrics for each iteration from the captured output\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, metrics in enumerate(iteration_metrics, start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"MSE: {metrics[0]}, RMSE: {metrics[1]}, MAE: {metrics[2]}, RSE: {metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the patchtst_results list\n",
    "                patchtst_results.append({\n",
    "                    'Loss_function': loss,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': metrics[0],\n",
    "                    'RMSE': metrics[1],\n",
    "                    'MAE': metrics[2],\n",
    "                    'RSE': metrics[3]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17261680.0</td>\n",
       "      <td>4154.7178</td>\n",
       "      <td>2581.1782</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17762658.0</td>\n",
       "      <td>4214.5767</td>\n",
       "      <td>2639.2039</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30875704.0</td>\n",
       "      <td>5556.5908</td>\n",
       "      <td>3633.8970</td>\n",
       "      <td>0.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32792920.0</td>\n",
       "      <td>5726.5103</td>\n",
       "      <td>3746.3784</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35247892.0</td>\n",
       "      <td>5936.9937</td>\n",
       "      <td>3905.6101</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34226872.0</td>\n",
       "      <td>5850.3735</td>\n",
       "      <td>3899.1096</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17305828.0</td>\n",
       "      <td>4160.0273</td>\n",
       "      <td>2609.1721</td>\n",
       "      <td>0.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17345650.0</td>\n",
       "      <td>4164.8110</td>\n",
       "      <td>2657.5583</td>\n",
       "      <td>0.2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31262294.0</td>\n",
       "      <td>5591.2695</td>\n",
       "      <td>3673.3840</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33044252.0</td>\n",
       "      <td>5748.4131</td>\n",
       "      <td>3757.2954</td>\n",
       "      <td>0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35287100.0</td>\n",
       "      <td>5940.2944</td>\n",
       "      <td>3912.6470</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34170808.0</td>\n",
       "      <td>5845.5801</td>\n",
       "      <td>3891.9578</td>\n",
       "      <td>0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17183404.0</td>\n",
       "      <td>4145.2871</td>\n",
       "      <td>2456.1895</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16678795.0</td>\n",
       "      <td>4083.9680</td>\n",
       "      <td>2431.3040</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31555720.0</td>\n",
       "      <td>5617.4478</td>\n",
       "      <td>3527.8032</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34537172.0</td>\n",
       "      <td>5876.8335</td>\n",
       "      <td>3631.9407</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35018344.0</td>\n",
       "      <td>5917.6299</td>\n",
       "      <td>3745.1887</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33935912.0</td>\n",
       "      <td>5825.4536</td>\n",
       "      <td>3740.7778</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17261680.0  4154.7178  2581.1782  0.2066\n",
       "              2         24        17762658.0  4214.5767  2639.2039  0.2096\n",
       "              1         96        30875704.0  5556.5908  3633.8970  0.2767\n",
       "              2         96        32792920.0  5726.5103  3746.3784  0.2852\n",
       "              1         168       35247892.0  5936.9937  3905.6101  0.2958\n",
       "              2         168       34226872.0  5850.3735  3899.1096  0.2915\n",
       "RMSE          1         24        17305828.0  4160.0273  2609.1721  0.2068\n",
       "              2         24        17345650.0  4164.8110  2657.5583  0.2071\n",
       "              1         96        31262294.0  5591.2695  3673.3840  0.2784\n",
       "              2         96        33044252.0  5748.4131  3757.2954  0.2863\n",
       "              1         168       35287100.0  5940.2944  3912.6470  0.2960\n",
       "              2         168       34170808.0  5845.5801  3891.9578  0.2913\n",
       "MAE           1         24        17183404.0  4145.2871  2456.1895  0.2061\n",
       "              2         24        16678795.0  4083.9680  2431.3040  0.2031\n",
       "              1         96        31555720.0  5617.4478  3527.8032  0.2798\n",
       "              2         96        34537172.0  5876.8335  3631.9407  0.2927\n",
       "              1         168       35018344.0  5917.6299  3745.1887  0.2948\n",
       "              2         168       33935912.0  5825.4536  3740.7778  0.2903"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df = convert_results_into_df(patchtst_results, path_dir, csv_name)\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MAE</th>\n",
       "      <th>24</th>\n",
       "      <td>16931099.5</td>\n",
       "      <td>4114.6276</td>\n",
       "      <td>2443.7467</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33046446.0</td>\n",
       "      <td>5747.1406</td>\n",
       "      <td>3579.8719</td>\n",
       "      <td>0.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>34477128.0</td>\n",
       "      <td>5871.5417</td>\n",
       "      <td>3742.9833</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MSE</th>\n",
       "      <th>24</th>\n",
       "      <td>17512169.0</td>\n",
       "      <td>4184.6472</td>\n",
       "      <td>2610.1910</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>31834312.0</td>\n",
       "      <td>5641.5505</td>\n",
       "      <td>3690.1377</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>34737382.0</td>\n",
       "      <td>5893.6836</td>\n",
       "      <td>3902.3599</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RMSE</th>\n",
       "      <th>24</th>\n",
       "      <td>17325739.0</td>\n",
       "      <td>4162.4192</td>\n",
       "      <td>2633.3652</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>32153273.0</td>\n",
       "      <td>5669.8413</td>\n",
       "      <td>3715.3397</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>34728954.0</td>\n",
       "      <td>5892.9373</td>\n",
       "      <td>3902.3024</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Loss_function Pred_len                                          \n",
       "MAE           24        16931099.5  4114.6276  2443.7467  0.2046\n",
       "              96        33046446.0  5747.1406  3579.8719  0.2862\n",
       "              168       34477128.0  5871.5417  3742.9833  0.2925\n",
       "MSE           24        17512169.0  4184.6472  2610.1910  0.2081\n",
       "              96        31834312.0  5641.5505  3690.1377  0.2810\n",
       "              168       34737382.0  5893.6836  3902.3599  0.2937\n",
       "RMSE          24        17325739.0  4162.4192  2633.3652  0.2070\n",
       "              96        32153273.0  5669.8413  3715.3397  0.2824\n",
       "              168       34728954.0  5892.9373  3902.3024  0.2936"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_res_scaled = pd.read_csv(os.path.join(path_dir, csv_name))\n",
    "ptst_res_scaled = ptst_res_scaled.groupby(['Loss_function', 'Pred_len']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Informer errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    path = \"/vol/cs-hu/riabchuv/my_work/results/DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0\"\n",
    "    pred = np.load(path + \"/pred.npy\")[:, :, i]\n",
    "    true = np.load(path + \"/true.npy\")[:, :, i]\n",
    "    errors = np.abs(pred - true)\n",
    "    plt.hist(errors, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.3662000e+04, 7.6419637e-05, 3.2353000e+04, 5.6700000e+03,\n",
       "         2.6683002e+04],\n",
       "        [5.1976000e+04, 7.6419637e-05, 3.4308000e+04, 5.6310000e+03,\n",
       "         2.8677000e+04],\n",
       "        [5.0545000e+04, 7.6419637e-05, 3.6105000e+04, 5.7270000e+03,\n",
       "         3.0378000e+04],\n",
       "        ...,\n",
       "        [6.4737000e+04, 7.6419637e-05, 3.9865000e+04, 3.7310000e+03,\n",
       "         3.6134000e+04],\n",
       "        [6.0686000e+04, 7.6419637e-05, 3.8528000e+04, 3.8740000e+03,\n",
       "         3.4654000e+04],\n",
       "        [5.6290000e+04, 7.6419637e-05, 3.8944000e+04, 4.0290000e+03,\n",
       "         3.4914000e+04]],\n",
       "\n",
       "       [[5.1976000e+04, 7.6419637e-05, 3.4308000e+04, 5.6310000e+03,\n",
       "         2.8677000e+04],\n",
       "        [5.0545000e+04, 7.6419637e-05, 3.6105000e+04, 5.7270000e+03,\n",
       "         3.0378000e+04],\n",
       "        [5.1018000e+04, 7.6419637e-05, 3.7279000e+04, 5.7960000e+03,\n",
       "         3.1483002e+04],\n",
       "        ...,\n",
       "        [6.0686000e+04, 7.6419637e-05, 3.8528000e+04, 3.8740000e+03,\n",
       "         3.4654000e+04],\n",
       "        [5.6290000e+04, 7.6419637e-05, 3.8944000e+04, 4.0290000e+03,\n",
       "         3.4914000e+04],\n",
       "        [5.3087000e+04, 7.6419637e-05, 3.8384000e+04, 4.0680000e+03,\n",
       "         3.4317000e+04]],\n",
       "\n",
       "       [[5.0545000e+04, 7.6419637e-05, 3.6105000e+04, 5.7270000e+03,\n",
       "         3.0378000e+04],\n",
       "        [5.1018000e+04, 7.6419637e-05, 3.7279000e+04, 5.7960000e+03,\n",
       "         3.1483002e+04],\n",
       "        [5.2543000e+04, 7.6419637e-05, 3.7523000e+04, 5.7570000e+03,\n",
       "         3.1766000e+04],\n",
       "        ...,\n",
       "        [5.6290000e+04, 7.6419637e-05, 3.8944000e+04, 4.0290000e+03,\n",
       "         3.4914000e+04],\n",
       "        [5.3087000e+04, 7.6419637e-05, 3.8384000e+04, 4.0680000e+03,\n",
       "         3.4317000e+04],\n",
       "        [5.0095000e+04, 7.6419637e-05, 3.7604000e+04, 4.0960000e+03,\n",
       "         3.3508000e+04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[6.5568000e+04, 1.6887000e+04, 2.6239998e+03, 3.9199994e+02,\n",
       "         2.2310000e+03],\n",
       "        [6.4527000e+04, 1.4201000e+04, 2.4139998e+03, 2.5799994e+02,\n",
       "         2.1550000e+03],\n",
       "        [6.2485000e+04, 1.0628000e+04, 2.3880007e+03, 1.8000006e+02,\n",
       "         2.2070000e+03],\n",
       "        ...,\n",
       "        [6.6008000e+04, 9.4120000e+03, 3.2499998e+03, 1.1940000e+03,\n",
       "         2.0560000e+03],\n",
       "        [6.7478000e+04, 1.1923000e+04, 3.4499998e+03, 1.4150000e+03,\n",
       "         2.0350000e+03],\n",
       "        [6.7574000e+04, 1.2996000e+04, 3.5969998e+03, 1.4570000e+03,\n",
       "         2.1400000e+03]],\n",
       "\n",
       "       [[6.4527000e+04, 1.4201000e+04, 2.4139998e+03, 2.5799994e+02,\n",
       "         2.1550000e+03],\n",
       "        [6.2485000e+04, 1.0628000e+04, 2.3880007e+03, 1.8000006e+02,\n",
       "         2.2070000e+03],\n",
       "        [6.1300000e+04, 7.1240000e+03, 2.3939998e+03, 1.6900006e+02,\n",
       "         2.2240000e+03],\n",
       "        ...,\n",
       "        [6.7478000e+04, 1.1923000e+04, 3.4499998e+03, 1.4150000e+03,\n",
       "         2.0350000e+03],\n",
       "        [6.7574000e+04, 1.2996000e+04, 3.5969998e+03, 1.4570000e+03,\n",
       "         2.1400000e+03],\n",
       "        [6.6534000e+04, 1.3293000e+04, 3.6700002e+03, 1.2830000e+03,\n",
       "         2.3870000e+03]],\n",
       "\n",
       "       [[6.2485000e+04, 1.0628000e+04, 2.3880007e+03, 1.8000006e+02,\n",
       "         2.2070000e+03],\n",
       "        [6.1300000e+04, 7.1240000e+03, 2.3939998e+03, 1.6900006e+02,\n",
       "         2.2240000e+03],\n",
       "        [6.1369000e+04, 3.5380000e+03, 2.3330007e+03, 2.8800006e+02,\n",
       "         2.0450000e+03],\n",
       "        ...,\n",
       "        [6.7574000e+04, 1.2996000e+04, 3.5969998e+03, 1.4570000e+03,\n",
       "         2.1400000e+03],\n",
       "        [6.6534000e+04, 1.3293000e+04, 3.6700002e+03, 1.2830000e+03,\n",
       "         2.3870000e+03],\n",
       "        [6.5415000e+04, 1.2267000e+04, 3.8230002e+03, 1.2860000e+03,\n",
       "         2.5370000e+03]]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = \"/vol/cs-hu/riabchuv/my_work/results/DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0\"\n",
    "np.load(path + \"/true.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2],\n",
       "        [ 3,  4]],\n",
       "\n",
       "       [[ 5,  6],\n",
       "        [ 7,  8]],\n",
       "\n",
       "       [[ 9, 10],\n",
       "        [11, 12]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 1\n",
    "a[0, 0, 0]\n",
    "# Feature 2\n",
    "a[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = a.shape\n",
    "shape\n",
    "# B=3, L=2, C=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 3,  4],\n",
       "       [ 5,  6],\n",
       "       [ 7,  8],\n",
       "       [ 9, 10],\n",
       "       [11, 12]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(shape[0] * shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2],\n",
       "        [ 3,  4]],\n",
       "\n",
       "       [[ 5,  6],\n",
       "        [ 7,  8]],\n",
       "\n",
       "       [[ 9, 10],\n",
       "        [11, 12]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(shape[0] * shape[1], -1).reshape(shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
