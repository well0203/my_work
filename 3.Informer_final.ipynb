{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to CUDA Grünau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I tried out Google Colab, but it did not work out.\n",
    "Even after fixing all not working things (that work everywhere else except colab), its capacity is too limited and they actually do not write after how many hours they interrupt process (\"because everytime it is different\").\n",
    "\n",
    "So, if you are not going to use CUDA Grünau, skip this part.\n",
    "\n",
    "If you are interested, which code is working in Colab, it is in Appendix. It runs only on small datasets (that processes are not interrupted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For gruenau: For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Nov__3_17:16:49_PDT_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.103\n",
      "Build cuda_12.3.r12.3/compiler.33492891_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 19 16:50:42 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             35W /  250W |     819MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-32GB           Off |   00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             35W /  250W |     353MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                Off |   00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             55W /  250W |     206MiB /  23040MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    0   N/A  N/A     12665      C   /usr/bin/python3                              804MiB |\n",
      "|    1   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    1   N/A  N/A     12665      C   /usr/bin/python3                              342MiB |\n",
      "|    2   N/A  N/A      6987      G   /usr/bin/X                                      4MiB |\n",
      "|    2   N/A  N/A     12665      C   /usr/bin/python3                              198MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "gpu_index = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder named \"datasets\" if it doesn't exist\n",
    "folder_name = \"datasets\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "df = pd.read_csv(\"top_5_countries.csv\", index_col=0, parse_dates=True)\n",
    "# Reset index for Data Loader\n",
    "df.reset_index(inplace=True)\n",
    "df = df.iloc[:,:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "\n",
    "# Split and save the datasets\n",
    "for country_prefix in top_5_countries:\n",
    "    # Filter columns with the specified prefix\n",
    "    country_columns = [col for col in df.columns if col.startswith(country_prefix)]\n",
    "    \n",
    "    # Insert the date column at the beginning of every dataset\n",
    "    country_columns.insert(0,\"date\")\n",
    "    country_df = df[country_columns]\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_name = f\"datasets/{country_prefix}_data.csv\"\n",
    "    country_df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1rv2rKwQqgoHDNjXtRoAEWZ2ATz0gGAKu?usp=sharing#scrollTo=yu6zzic9t_Cz\n",
    "# Popen: https://colab.research.google.com/github/aviadr1/learn-python/blob/master/content/13_multiprocessing/notebooks/os_system_subprocess.ipynb\n",
    "import subprocess\n",
    "import os\n",
    "# parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_to_run_file = \"/vol/cs-hu/riabchuv/hu-home/my_work/TSLibrary/run.py\"\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Execute the script and capture the output\n",
    "        command = [\"python\", \"-u\", path_to_run_file] + model_arguments\n",
    "        output = subprocess.check_output(command, universal_newlines=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output  \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import subprocess\n",
    "import os\n",
    "# parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_to_run_file = \"/content/my_work/TSLibrary/run.py\"\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Define command and options wanted\n",
    "        command = \"python\"\n",
    "        options = \"-u\"\n",
    "        # Run the shell command directly in Colab\n",
    "        output = !{command} {options} {path_to_run_file} {model_arguments}\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output\n",
    "\n",
    "    return output\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Execute the script using the %run magic command\n",
    "        output = %run -i {path_to_run_file} {model_arguments}\n",
    "\n",
    "    except Exception as e:\n",
    "        output = str(e)\n",
    "\n",
    "    return output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to work in colab\n",
    "import subprocess\n",
    "\n",
    "def run_output(path_to_run_file, model_arguments):\n",
    "    try:\n",
    "        # Construct the command to execute the script with required and model arguments\n",
    "        command = [\"python\", \"-u\", path_to_run_file] + model_arguments\n",
    "        # Execute the script and capture the output\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "        # Check if there's any error in the process\n",
    "        if process.returncode != 0:\n",
    "            output = stderr.decode(\"utf-8\")\n",
    "        else:\n",
    "            output = stdout.decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        output = str(e)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/well0203/my_work.git\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r /content/my_work/TSLibrary/requirements.txt\n",
    "#!pip install sktime\n",
    "#!pip install reformer-pytorch==1.4.4\n",
    "# Drive python version 3.10.6, therefore torch==1.7.1 does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.5979588\n",
      "\tspeed: 0.1078s/iter; left time: 1003.5939s\n",
      "\titers: 200, epoch: 1 | loss: 0.3988746\n",
      "\tspeed: 0.0981s/iter; left time: 903.5919s\n",
      "\titers: 300, epoch: 1 | loss: 0.4951838\n",
      "\tspeed: 0.0980s/iter; left time: 892.9673s\n",
      "\titers: 400, epoch: 1 | loss: 0.3251971\n",
      "\tspeed: 0.0979s/iter; left time: 882.0710s\n",
      "\titers: 500, epoch: 1 | loss: 0.2972392\n",
      "\tspeed: 0.0979s/iter; left time: 872.1553s\n",
      "\titers: 600, epoch: 1 | loss: 0.3141234\n",
      "\tspeed: 0.0983s/iter; left time: 865.7961s\n",
      "\titers: 700, epoch: 1 | loss: 0.3582392\n",
      "\tspeed: 0.0980s/iter; left time: 853.8956s\n",
      "\titers: 800, epoch: 1 | loss: 0.3090230\n",
      "\tspeed: 0.0979s/iter; left time: 842.9842s\n",
      "\titers: 900, epoch: 1 | loss: 0.2600375\n",
      "\tspeed: 0.0980s/iter; left time: 833.7338s\n",
      "Epoch: 1 running time: 1.5546314120292664 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3885667 Vali Loss: 0.3599150 Test Loss: 0.5413693\n",
      "Validation loss decreased (inf --> 0.359915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2532829\n",
      "\tspeed: 0.2840s/iter; left time: 2377.0272s\n",
      "\titers: 200, epoch: 2 | loss: 0.2295953\n",
      "\tspeed: 0.0978s/iter; left time: 809.0253s\n",
      "\titers: 300, epoch: 2 | loss: 0.1922673\n",
      "\tspeed: 0.0976s/iter; left time: 797.2087s\n",
      "\titers: 400, epoch: 2 | loss: 0.4123895\n",
      "\tspeed: 0.0978s/iter; left time: 788.9432s\n",
      "\titers: 500, epoch: 2 | loss: 0.2371316\n",
      "\tspeed: 0.0983s/iter; left time: 783.2757s\n",
      "\titers: 600, epoch: 2 | loss: 0.3011464\n",
      "\tspeed: 0.0982s/iter; left time: 772.5010s\n",
      "\titers: 700, epoch: 2 | loss: 0.2392187\n",
      "\tspeed: 0.0980s/iter; left time: 761.5209s\n",
      "\titers: 800, epoch: 2 | loss: 0.2716683\n",
      "\tspeed: 0.0976s/iter; left time: 748.2816s\n",
      "\titers: 900, epoch: 2 | loss: 0.2080009\n",
      "\tspeed: 0.0977s/iter; left time: 739.3383s\n",
      "Epoch: 2 running time: 1.5396055936813355 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.2747000 Vali Loss: 0.3615359 Test Loss: 0.5790962\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3574236\n",
      "\tspeed: 0.2801s/iter; left time: 2081.2302s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763731\n",
      "\tspeed: 0.0978s/iter; left time: 716.7625s\n",
      "\titers: 300, epoch: 3 | loss: 0.2299239\n",
      "\tspeed: 0.0976s/iter; left time: 705.4228s\n",
      "\titers: 400, epoch: 3 | loss: 0.2516459\n",
      "\tspeed: 0.0977s/iter; left time: 696.3497s\n",
      "\titers: 500, epoch: 3 | loss: 0.2625080\n",
      "\tspeed: 0.0978s/iter; left time: 687.0868s\n",
      "\titers: 600, epoch: 3 | loss: 0.2179623\n",
      "\tspeed: 0.0977s/iter; left time: 676.7548s\n",
      "\titers: 700, epoch: 3 | loss: 0.2282525\n",
      "\tspeed: 0.0975s/iter; left time: 665.8238s\n",
      "\titers: 800, epoch: 3 | loss: 0.3034237\n",
      "\tspeed: 0.0975s/iter; left time: 656.3987s\n",
      "\titers: 900, epoch: 3 | loss: 0.3019572\n",
      "\tspeed: 0.0977s/iter; left time: 647.6157s\n",
      "Epoch: 3 running time: 1.5372791488965352 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.2638785 Vali Loss: 0.3499245 Test Loss: 0.5233747\n",
      "Validation loss decreased (0.359915 --> 0.349925).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2404048\n",
      "\tspeed: 0.2853s/iter; left time: 1850.7819s\n",
      "\titers: 200, epoch: 4 | loss: 0.2120794\n",
      "\tspeed: 0.0979s/iter; left time: 625.5544s\n",
      "\titers: 300, epoch: 4 | loss: 0.2520547\n",
      "\tspeed: 0.0976s/iter; left time: 613.7269s\n",
      "\titers: 400, epoch: 4 | loss: 0.2569040\n",
      "\tspeed: 0.0978s/iter; left time: 605.3048s\n",
      "\titers: 500, epoch: 4 | loss: 0.1980895\n",
      "\tspeed: 0.0977s/iter; left time: 595.0931s\n",
      "\titers: 600, epoch: 4 | loss: 0.2096463\n",
      "\tspeed: 0.0975s/iter; left time: 584.0573s\n",
      "\titers: 700, epoch: 4 | loss: 0.2016285\n",
      "\tspeed: 0.0977s/iter; left time: 575.0260s\n",
      "\titers: 800, epoch: 4 | loss: 0.1970884\n",
      "\tspeed: 0.0975s/iter; left time: 564.5929s\n",
      "\titers: 900, epoch: 4 | loss: 0.2034923\n",
      "\tspeed: 0.0975s/iter; left time: 554.6836s\n",
      "Epoch: 4 running time: 1.5379542350769042 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.2285615 Vali Loss: 0.3327911 Test Loss: 0.5450918\n",
      "Validation loss decreased (0.349925 --> 0.332791).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1831390\n",
      "\tspeed: 0.2850s/iter; left time: 1580.6327s\n",
      "\titers: 200, epoch: 5 | loss: 0.2395813\n",
      "\tspeed: 0.0973s/iter; left time: 530.2214s\n",
      "\titers: 300, epoch: 5 | loss: 0.1956781\n",
      "\tspeed: 0.0973s/iter; left time: 520.5293s\n",
      "\titers: 400, epoch: 5 | loss: 0.2888322\n",
      "\tspeed: 0.0975s/iter; left time: 511.7390s\n",
      "\titers: 500, epoch: 5 | loss: 0.1966490\n",
      "\tspeed: 0.0974s/iter; left time: 501.3349s\n",
      "\titers: 600, epoch: 5 | loss: 0.1773667\n",
      "\tspeed: 0.0976s/iter; left time: 492.3736s\n",
      "\titers: 700, epoch: 5 | loss: 0.1866304\n",
      "\tspeed: 0.0975s/iter; left time: 482.3317s\n",
      "\titers: 800, epoch: 5 | loss: 0.1474601\n",
      "\tspeed: 0.0973s/iter; left time: 471.8175s\n",
      "\titers: 900, epoch: 5 | loss: 0.2766321\n",
      "\tspeed: 0.0974s/iter; left time: 462.2471s\n",
      "Epoch: 5 running time: 1.533496336142222 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.2052569 Vali Loss: 0.3558107 Test Loss: 0.5533416\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1901380\n",
      "\tspeed: 0.2782s/iter; left time: 1281.4157s\n",
      "\titers: 200, epoch: 6 | loss: 0.1638627\n",
      "\tspeed: 0.0975s/iter; left time: 439.1547s\n",
      "\titers: 300, epoch: 6 | loss: 0.2496205\n",
      "\tspeed: 0.0974s/iter; left time: 428.9254s\n",
      "\titers: 400, epoch: 6 | loss: 0.2062164\n",
      "\tspeed: 0.0975s/iter; left time: 420.0256s\n",
      "\titers: 500, epoch: 6 | loss: 0.2275229\n",
      "\tspeed: 0.0977s/iter; left time: 410.7234s\n",
      "\titers: 600, epoch: 6 | loss: 0.1896032\n",
      "\tspeed: 0.0975s/iter; left time: 400.2688s\n",
      "\titers: 700, epoch: 6 | loss: 0.1997263\n",
      "\tspeed: 0.0975s/iter; left time: 390.4182s\n",
      "\titers: 800, epoch: 6 | loss: 0.2681848\n",
      "\tspeed: 0.0975s/iter; left time: 380.8619s\n",
      "\titers: 900, epoch: 6 | loss: 0.2032136\n",
      "\tspeed: 0.0973s/iter; left time: 370.5132s\n",
      "Epoch: 6 running time: 1.5333383083343506 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.2041673 Vali Loss: 0.3364544 Test Loss: 0.5421493\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1747950\n",
      "\tspeed: 0.2787s/iter; left time: 1021.2745s\n",
      "\titers: 200, epoch: 7 | loss: 0.2300793\n",
      "\tspeed: 0.0976s/iter; left time: 347.9793s\n",
      "\titers: 300, epoch: 7 | loss: 0.1680039\n",
      "\tspeed: 0.0976s/iter; left time: 338.2595s\n",
      "\titers: 400, epoch: 7 | loss: 0.2118735\n",
      "\tspeed: 0.0978s/iter; left time: 329.1586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1732029\n",
      "\tspeed: 0.0978s/iter; left time: 319.2355s\n",
      "\titers: 600, epoch: 7 | loss: 0.1689785\n",
      "\tspeed: 0.0977s/iter; left time: 309.1045s\n",
      "\titers: 700, epoch: 7 | loss: 0.2123212\n",
      "\tspeed: 0.0974s/iter; left time: 298.5726s\n",
      "\titers: 800, epoch: 7 | loss: 0.2141715\n",
      "\tspeed: 0.0975s/iter; left time: 289.2073s\n",
      "\titers: 900, epoch: 7 | loss: 0.1998224\n",
      "\tspeed: 0.0976s/iter; left time: 279.6204s\n",
      "Epoch: 7 running time: 1.5368539373079935 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.2040884 Vali Loss: 0.3359562 Test Loss: 0.5423290\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 5) (269, 32, 24, 5)\n",
      "test shape: (8608, 24, 5) (8608, 24, 5)\n",
      "mse:0.542351484298706, mae:0.49271532893180847\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.5885839\n",
      "\tspeed: 0.0911s/iter; left time: 848.3252s\n",
      "\titers: 200, epoch: 1 | loss: 0.4808174\n",
      "\tspeed: 0.0983s/iter; left time: 905.3794s\n",
      "\titers: 300, epoch: 1 | loss: 0.3567823\n",
      "\tspeed: 0.0987s/iter; left time: 899.4436s\n",
      "\titers: 400, epoch: 1 | loss: 0.3922084\n",
      "\tspeed: 0.0992s/iter; left time: 894.3320s\n",
      "\titers: 500, epoch: 1 | loss: 0.3549460\n",
      "\tspeed: 0.0982s/iter; left time: 874.8667s\n",
      "\titers: 600, epoch: 1 | loss: 0.4167266\n",
      "\tspeed: 0.0980s/iter; left time: 863.8790s\n",
      "\titers: 700, epoch: 1 | loss: 0.3898646\n",
      "\tspeed: 0.0958s/iter; left time: 834.3015s\n",
      "\titers: 800, epoch: 1 | loss: 0.2914270\n",
      "\tspeed: 0.0983s/iter; left time: 846.5094s\n",
      "\titers: 900, epoch: 1 | loss: 0.2078680\n",
      "\tspeed: 0.0986s/iter; left time: 838.8358s\n",
      "Epoch: 1 running time: 1.52977428038915 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3939400 Vali Loss: 0.3607067 Test Loss: 0.5616335\n",
      "Validation loss decreased (inf --> 0.360707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2776674\n",
      "\tspeed: 0.2878s/iter; left time: 2409.1260s\n",
      "\titers: 200, epoch: 2 | loss: 0.2421905\n",
      "\tspeed: 0.0982s/iter; left time: 811.8457s\n",
      "\titers: 300, epoch: 2 | loss: 0.3501032\n",
      "\tspeed: 0.0979s/iter; left time: 799.7434s\n",
      "\titers: 400, epoch: 2 | loss: 0.2221153\n",
      "\tspeed: 0.0980s/iter; left time: 791.1889s\n",
      "\titers: 500, epoch: 2 | loss: 0.3621227\n",
      "\tspeed: 0.0978s/iter; left time: 779.6867s\n",
      "\titers: 600, epoch: 2 | loss: 0.3243517\n",
      "\tspeed: 0.0979s/iter; left time: 770.5618s\n",
      "\titers: 700, epoch: 2 | loss: 0.3431254\n",
      "\tspeed: 0.0978s/iter; left time: 759.9195s\n",
      "\titers: 800, epoch: 2 | loss: 0.2447850\n",
      "\tspeed: 0.0979s/iter; left time: 751.0887s\n",
      "\titers: 900, epoch: 2 | loss: 0.2354745\n",
      "\tspeed: 0.0979s/iter; left time: 740.9177s\n",
      "Epoch: 2 running time: 1.5421267906824747 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.2753468 Vali Loss: 0.3552379 Test Loss: 0.5603691\n",
      "Validation loss decreased (0.360707 --> 0.355238).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2077665\n",
      "\tspeed: 0.2863s/iter; left time: 2126.7015s\n",
      "\titers: 200, epoch: 3 | loss: 0.2024092\n",
      "\tspeed: 0.0977s/iter; left time: 716.3017s\n",
      "\titers: 300, epoch: 3 | loss: 0.2525340\n",
      "\tspeed: 0.0977s/iter; left time: 706.2460s\n",
      "\titers: 400, epoch: 3 | loss: 0.2007055\n",
      "\tspeed: 0.0982s/iter; left time: 699.9823s\n",
      "\titers: 500, epoch: 3 | loss: 0.2679331\n",
      "\tspeed: 0.0989s/iter; left time: 695.2980s\n",
      "\titers: 600, epoch: 3 | loss: 0.1978059\n",
      "\tspeed: 0.0991s/iter; left time: 686.6898s\n",
      "\titers: 700, epoch: 3 | loss: 0.1983410\n",
      "\tspeed: 0.0987s/iter; left time: 674.1259s\n",
      "\titers: 800, epoch: 3 | loss: 0.2749475\n",
      "\tspeed: 0.0981s/iter; left time: 660.0698s\n",
      "\titers: 900, epoch: 3 | loss: 0.2155552\n",
      "\tspeed: 0.0982s/iter; left time: 650.6816s\n",
      "Epoch: 3 running time: 1.5467728972434998 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.2296516 Vali Loss: 0.3449344 Test Loss: 0.5333540\n",
      "Validation loss decreased (0.355238 --> 0.344934).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1944146\n",
      "\tspeed: 0.2881s/iter; left time: 1869.2917s\n",
      "\titers: 200, epoch: 4 | loss: 0.2291458\n",
      "\tspeed: 0.0977s/iter; left time: 624.0008s\n",
      "\titers: 300, epoch: 4 | loss: 0.1660754\n",
      "\tspeed: 0.0978s/iter; left time: 614.6755s\n",
      "\titers: 400, epoch: 4 | loss: 0.1500978\n",
      "\tspeed: 0.0977s/iter; left time: 604.4314s\n",
      "\titers: 500, epoch: 4 | loss: 0.2157296\n",
      "\tspeed: 0.0976s/iter; left time: 593.9782s\n",
      "\titers: 600, epoch: 4 | loss: 0.1963040\n",
      "\tspeed: 0.0978s/iter; left time: 585.5368s\n",
      "\titers: 700, epoch: 4 | loss: 0.2547735\n",
      "\tspeed: 0.0977s/iter; left time: 575.1413s\n",
      "\titers: 800, epoch: 4 | loss: 0.1726060\n",
      "\tspeed: 0.0977s/iter; left time: 565.3300s\n",
      "\titers: 900, epoch: 4 | loss: 0.1798732\n",
      "\tspeed: 0.0975s/iter; left time: 554.5946s\n",
      "Epoch: 4 running time: 1.5375561753908793 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1954855 Vali Loss: 0.3462040 Test Loss: 0.5407835\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1592964\n",
      "\tspeed: 0.2801s/iter; left time: 1553.5432s\n",
      "\titers: 200, epoch: 5 | loss: 0.1947924\n",
      "\tspeed: 0.0982s/iter; left time: 535.0782s\n",
      "\titers: 300, epoch: 5 | loss: 0.1617831\n",
      "\tspeed: 0.0981s/iter; left time: 524.6174s\n",
      "\titers: 400, epoch: 5 | loss: 0.2011821\n",
      "\tspeed: 0.0980s/iter; left time: 514.0995s\n",
      "\titers: 500, epoch: 5 | loss: 0.2041656\n",
      "\tspeed: 0.0975s/iter; left time: 501.5775s\n",
      "\titers: 600, epoch: 5 | loss: 0.1855498\n",
      "\tspeed: 0.0976s/iter; left time: 492.3413s\n",
      "\titers: 700, epoch: 5 | loss: 0.1450996\n",
      "\tspeed: 0.0975s/iter; left time: 482.4622s\n",
      "\titers: 800, epoch: 5 | loss: 0.1926186\n",
      "\tspeed: 0.0979s/iter; left time: 474.4031s\n",
      "\titers: 900, epoch: 5 | loss: 0.2197612\n",
      "\tspeed: 0.0980s/iter; left time: 465.3897s\n",
      "Epoch: 5 running time: 1.5406445781389873 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1928436 Vali Loss: 0.3556490 Test Loss: 0.5593730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2385069\n",
      "\tspeed: 0.2796s/iter; left time: 1287.8641s\n",
      "\titers: 200, epoch: 6 | loss: 0.2327145\n",
      "\tspeed: 0.0978s/iter; left time: 440.4635s\n",
      "\titers: 300, epoch: 6 | loss: 0.2079315\n",
      "\tspeed: 0.0978s/iter; left time: 430.9414s\n",
      "\titers: 400, epoch: 6 | loss: 0.1807522\n",
      "\tspeed: 0.0976s/iter; left time: 420.3452s\n",
      "\titers: 500, epoch: 6 | loss: 0.2193317\n",
      "\tspeed: 0.0978s/iter; left time: 411.4552s\n",
      "\titers: 600, epoch: 6 | loss: 0.1836175\n",
      "\tspeed: 0.0977s/iter; left time: 401.0777s\n",
      "\titers: 700, epoch: 6 | loss: 0.2200144\n",
      "\tspeed: 0.0976s/iter; left time: 390.8376s\n",
      "\titers: 800, epoch: 6 | loss: 0.2055064\n",
      "\tspeed: 0.0976s/iter; left time: 381.2572s\n",
      "\titers: 900, epoch: 6 | loss: 0.2023076\n",
      "\tspeed: 0.0978s/iter; left time: 372.2206s\n",
      "Epoch: 6 running time: 1.5379039565722148 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1931179 Vali Loss: 0.3452641 Test Loss: 0.5490345\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 5) (269, 32, 24, 5)\n",
      "test shape: (8608, 24, 5) (8608, 24, 5)\n",
      "mse:0.5488144755363464, mae:0.4969179332256317\n",
      "\n",
      "Time intermediate for DE dataset: 23.553507006168367 min.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4583763\n",
      "\tspeed: 0.1078s/iter; left time: 1003.8090s\n",
      "\titers: 200, epoch: 1 | loss: 0.3878897\n",
      "\tspeed: 0.0979s/iter; left time: 901.8856s\n",
      "\titers: 300, epoch: 1 | loss: 0.3311236\n",
      "\tspeed: 0.0977s/iter; left time: 890.4963s\n",
      "\titers: 400, epoch: 1 | loss: 0.3112401\n",
      "\tspeed: 0.0979s/iter; left time: 881.7811s\n",
      "\titers: 500, epoch: 1 | loss: 0.2713794\n",
      "\tspeed: 0.0980s/iter; left time: 873.5798s\n",
      "\titers: 600, epoch: 1 | loss: 0.3417489\n",
      "\tspeed: 0.0981s/iter; left time: 864.7337s\n",
      "\titers: 700, epoch: 1 | loss: 0.4003856\n",
      "\tspeed: 0.0980s/iter; left time: 853.8352s\n",
      "\titers: 800, epoch: 1 | loss: 0.2808123\n",
      "\tspeed: 0.0981s/iter; left time: 844.3268s\n",
      "\titers: 900, epoch: 1 | loss: 0.2576330\n",
      "\tspeed: 0.0980s/iter; left time: 833.8802s\n",
      "Epoch: 1 running time: 1.5542073210080465 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.4064409 Vali Loss: 0.4122250 Test Loss: 0.7646125\n",
      "Validation loss decreased (inf --> 0.412225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3067522\n",
      "\tspeed: 0.2851s/iter; left time: 2385.9309s\n",
      "\titers: 200, epoch: 2 | loss: 0.2744507\n",
      "\tspeed: 0.0981s/iter; left time: 810.9219s\n",
      "\titers: 300, epoch: 2 | loss: 0.3486772\n",
      "\tspeed: 0.0976s/iter; left time: 797.1353s\n",
      "\titers: 400, epoch: 2 | loss: 0.3093699\n",
      "\tspeed: 0.0979s/iter; left time: 790.0474s\n",
      "\titers: 500, epoch: 2 | loss: 0.2064186\n",
      "\tspeed: 0.0979s/iter; left time: 780.3782s\n",
      "\titers: 600, epoch: 2 | loss: 0.2748952\n",
      "\tspeed: 0.0976s/iter; left time: 768.4677s\n",
      "\titers: 700, epoch: 2 | loss: 0.2839590\n",
      "\tspeed: 0.0978s/iter; left time: 760.1446s\n",
      "\titers: 800, epoch: 2 | loss: 0.2919414\n",
      "\tspeed: 0.0979s/iter; left time: 750.7189s\n",
      "\titers: 900, epoch: 2 | loss: 0.2487071\n",
      "\tspeed: 0.0976s/iter; left time: 738.7067s\n",
      "Epoch: 2 running time: 1.5410709222157797 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.3065783 Vali Loss: 0.3944587 Test Loss: 0.6807294\n",
      "Validation loss decreased (0.412225 --> 0.394459).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2702128\n",
      "\tspeed: 0.2877s/iter; left time: 2137.5545s\n",
      "\titers: 200, epoch: 3 | loss: 0.3190711\n",
      "\tspeed: 0.0979s/iter; left time: 717.7133s\n",
      "\titers: 300, epoch: 3 | loss: 0.2532526\n",
      "\tspeed: 0.0982s/iter; left time: 709.7745s\n",
      "\titers: 400, epoch: 3 | loss: 0.2061189\n",
      "\tspeed: 0.0976s/iter; left time: 696.1377s\n",
      "\titers: 500, epoch: 3 | loss: 0.1977401\n",
      "\tspeed: 0.0977s/iter; left time: 686.5519s\n",
      "\titers: 600, epoch: 3 | loss: 0.2680047\n",
      "\tspeed: 0.0978s/iter; left time: 677.4644s\n",
      "\titers: 700, epoch: 3 | loss: 0.2145547\n",
      "\tspeed: 0.0874s/iter; left time: 597.0928s\n",
      "\titers: 800, epoch: 3 | loss: 0.2101406\n",
      "\tspeed: 0.0809s/iter; left time: 544.3271s\n",
      "\titers: 900, epoch: 3 | loss: 0.3406821\n",
      "\tspeed: 0.0809s/iter; left time: 536.2867s\n",
      "Epoch: 3 running time: 1.4540736556053162 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.2630870 Vali Loss: 0.4008739 Test Loss: 0.7279691\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2422981\n",
      "\tspeed: 0.2724s/iter; left time: 1767.1854s\n",
      "\titers: 200, epoch: 4 | loss: 0.1884126\n",
      "\tspeed: 0.0978s/iter; left time: 624.4336s\n",
      "\titers: 300, epoch: 4 | loss: 0.2599521\n",
      "\tspeed: 0.0975s/iter; left time: 613.1612s\n",
      "\titers: 400, epoch: 4 | loss: 0.2694383\n",
      "\tspeed: 0.0977s/iter; left time: 604.5321s\n",
      "\titers: 500, epoch: 4 | loss: 0.2439736\n",
      "\tspeed: 0.0974s/iter; left time: 593.0381s\n",
      "\titers: 600, epoch: 4 | loss: 0.2632573\n",
      "\tspeed: 0.0974s/iter; left time: 583.4135s\n",
      "\titers: 700, epoch: 4 | loss: 0.2553389\n",
      "\tspeed: 0.0975s/iter; left time: 574.0162s\n",
      "\titers: 800, epoch: 4 | loss: 0.2767370\n",
      "\tspeed: 0.0975s/iter; left time: 564.1970s\n",
      "\titers: 900, epoch: 4 | loss: 0.2517391\n",
      "\tspeed: 0.0977s/iter; left time: 555.8763s\n",
      "Epoch: 4 running time: 1.5366331458091735 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.2589726 Vali Loss: 0.3914911 Test Loss: 0.6960634\n",
      "Validation loss decreased (0.394459 --> 0.391491).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2741575\n",
      "\tspeed: 0.2861s/iter; left time: 1586.9365s\n",
      "\titers: 200, epoch: 5 | loss: 0.2336923\n",
      "\tspeed: 0.0975s/iter; left time: 531.2220s\n",
      "\titers: 300, epoch: 5 | loss: 0.2015684\n",
      "\tspeed: 0.0974s/iter; left time: 521.0125s\n",
      "\titers: 400, epoch: 5 | loss: 0.2283741\n",
      "\tspeed: 0.0975s/iter; left time: 511.6482s\n",
      "\titers: 500, epoch: 5 | loss: 0.2496907\n",
      "\tspeed: 0.0976s/iter; left time: 502.3256s\n",
      "\titers: 600, epoch: 5 | loss: 0.2165726\n",
      "\tspeed: 0.0978s/iter; left time: 493.7778s\n",
      "\titers: 700, epoch: 5 | loss: 0.2022953\n",
      "\tspeed: 0.0978s/iter; left time: 483.6539s\n",
      "\titers: 800, epoch: 5 | loss: 0.2490409\n",
      "\tspeed: 0.0978s/iter; left time: 474.0028s\n",
      "\titers: 900, epoch: 5 | loss: 0.2817516\n",
      "\tspeed: 0.0975s/iter; left time: 462.9715s\n",
      "Epoch: 5 running time: 1.5363385915756225 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.2380383 Vali Loss: 0.3972078 Test Loss: 0.7027150\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1886821\n",
      "\tspeed: 0.2781s/iter; left time: 1281.1298s\n",
      "\titers: 200, epoch: 6 | loss: 0.2433284\n",
      "\tspeed: 0.0976s/iter; left time: 439.8831s\n",
      "\titers: 300, epoch: 6 | loss: 0.2376238\n",
      "\tspeed: 0.0975s/iter; left time: 429.6387s\n",
      "\titers: 400, epoch: 6 | loss: 0.2259449\n",
      "\tspeed: 0.0977s/iter; left time: 420.5388s\n",
      "\titers: 500, epoch: 6 | loss: 0.2131033\n",
      "\tspeed: 0.0979s/iter; left time: 411.7965s\n",
      "\titers: 600, epoch: 6 | loss: 0.2139467\n",
      "\tspeed: 0.0979s/iter; left time: 401.8017s\n",
      "\titers: 700, epoch: 6 | loss: 0.2462851\n",
      "\tspeed: 0.0978s/iter; left time: 391.9464s\n",
      "\titers: 800, epoch: 6 | loss: 0.2430781\n",
      "\tspeed: 0.0980s/iter; left time: 382.7134s\n",
      "\titers: 900, epoch: 6 | loss: 0.1916809\n",
      "\tspeed: 0.0979s/iter; left time: 372.7594s\n",
      "Epoch: 6 running time: 1.5383511741956075 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.2370810 Vali Loss: 0.4012877 Test Loss: 0.7130616\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2536033\n",
      "\tspeed: 0.2795s/iter; left time: 1024.3367s\n",
      "\titers: 200, epoch: 7 | loss: 0.2663393\n",
      "\tspeed: 0.0976s/iter; left time: 347.8432s\n",
      "\titers: 300, epoch: 7 | loss: 0.2347079\n",
      "\tspeed: 0.0978s/iter; left time: 338.7855s\n",
      "\titers: 400, epoch: 7 | loss: 0.2837873\n",
      "\tspeed: 0.0977s/iter; left time: 328.8627s\n",
      "\titers: 500, epoch: 7 | loss: 0.1881218\n",
      "\tspeed: 0.0978s/iter; left time: 319.2112s\n",
      "\titers: 600, epoch: 7 | loss: 0.2129756\n",
      "\tspeed: 0.0976s/iter; left time: 308.9672s\n",
      "\titers: 700, epoch: 7 | loss: 0.2155947\n",
      "\tspeed: 0.0975s/iter; left time: 298.7364s\n",
      "\titers: 800, epoch: 7 | loss: 0.2029046\n",
      "\tspeed: 0.0974s/iter; left time: 288.8096s\n",
      "\titers: 900, epoch: 7 | loss: 0.2018593\n",
      "\tspeed: 0.0977s/iter; left time: 279.7914s\n",
      "Epoch: 7 running time: 1.5372508883476257 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.2374023 Vali Loss: 0.3983790 Test Loss: 0.7232236\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 5) (269, 32, 24, 5)\n",
      "test shape: (8608, 24, 5) (8608, 24, 5)\n",
      "mse:0.7234761118888855, mae:0.5841315388679504\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.5943394\n",
      "\tspeed: 0.1022s/iter; left time: 951.5721s\n",
      "\titers: 200, epoch: 1 | loss: 0.4951172\n",
      "\tspeed: 0.0989s/iter; left time: 911.3668s\n",
      "\titers: 300, epoch: 1 | loss: 0.4118982\n",
      "\tspeed: 0.0991s/iter; left time: 902.8581s\n",
      "\titers: 400, epoch: 1 | loss: 0.3952385\n",
      "\tspeed: 0.0993s/iter; left time: 894.4173s\n",
      "\titers: 500, epoch: 1 | loss: 0.3432862\n",
      "\tspeed: 0.0991s/iter; left time: 883.3927s\n",
      "\titers: 600, epoch: 1 | loss: 0.3879800\n",
      "\tspeed: 0.0986s/iter; left time: 868.4864s\n",
      "\titers: 700, epoch: 1 | loss: 0.5058795\n",
      "\tspeed: 0.0994s/iter; left time: 866.2208s\n",
      "\titers: 800, epoch: 1 | loss: 0.2738970\n",
      "\tspeed: 0.0992s/iter; left time: 854.0643s\n",
      "\titers: 900, epoch: 1 | loss: 0.2377400\n",
      "\tspeed: 0.0987s/iter; left time: 839.8687s\n",
      "Epoch: 1 running time: 1.560698135693868 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.4166347 Vali Loss: 0.4075450 Test Loss: 0.6658818\n",
      "Validation loss decreased (inf --> 0.407545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2869742\n",
      "\tspeed: 0.2890s/iter; left time: 2418.7386s\n",
      "\titers: 200, epoch: 2 | loss: 0.2624056\n",
      "\tspeed: 0.0983s/iter; left time: 812.5547s\n",
      "\titers: 300, epoch: 2 | loss: 0.3053213\n",
      "\tspeed: 0.0981s/iter; left time: 801.7064s\n",
      "\titers: 400, epoch: 2 | loss: 0.2667679\n",
      "\tspeed: 0.0976s/iter; left time: 787.6466s\n",
      "\titers: 500, epoch: 2 | loss: 0.3287040\n",
      "\tspeed: 0.0979s/iter; left time: 780.6480s\n",
      "\titers: 600, epoch: 2 | loss: 0.3694022\n",
      "\tspeed: 0.0978s/iter; left time: 769.3081s\n",
      "\titers: 700, epoch: 2 | loss: 0.2779715\n",
      "\tspeed: 0.0978s/iter; left time: 759.9436s\n",
      "\titers: 800, epoch: 2 | loss: 0.2777001\n",
      "\tspeed: 0.0978s/iter; left time: 749.8622s\n",
      "\titers: 900, epoch: 2 | loss: 0.2957426\n",
      "\tspeed: 0.0981s/iter; left time: 742.3073s\n",
      "Epoch: 2 running time: 1.5421652674674988 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.3094313 Vali Loss: 0.4175729 Test Loss: 0.6661352\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2607539\n",
      "\tspeed: 0.2653s/iter; left time: 1971.0595s\n",
      "\titers: 200, epoch: 3 | loss: 0.3359609\n",
      "\tspeed: 0.0898s/iter; left time: 658.3817s\n",
      "\titers: 300, epoch: 3 | loss: 0.3067381\n",
      "\tspeed: 0.0984s/iter; left time: 711.6286s\n",
      "\titers: 400, epoch: 3 | loss: 0.3878072\n",
      "\tspeed: 0.0981s/iter; left time: 699.5963s\n",
      "\titers: 500, epoch: 3 | loss: 0.2739624\n",
      "\tspeed: 0.0984s/iter; left time: 691.4417s\n",
      "\titers: 600, epoch: 3 | loss: 0.2888962\n",
      "\tspeed: 0.0910s/iter; left time: 630.6627s\n",
      "\titers: 700, epoch: 3 | loss: 0.3805921\n",
      "\tspeed: 0.0809s/iter; left time: 552.2846s\n",
      "\titers: 800, epoch: 3 | loss: 0.2942919\n",
      "\tspeed: 0.0810s/iter; left time: 544.9244s\n",
      "\titers: 900, epoch: 3 | loss: 0.2940906\n",
      "\tspeed: 0.0967s/iter; left time: 640.8422s\n",
      "Epoch: 3 running time: 1.4228740453720092 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.3010982 Vali Loss: 0.4082417 Test Loss: 0.7074066\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3284783\n",
      "\tspeed: 0.2752s/iter; left time: 1785.5537s\n",
      "\titers: 200, epoch: 4 | loss: 0.2637954\n",
      "\tspeed: 0.0978s/iter; left time: 624.7798s\n",
      "\titers: 300, epoch: 4 | loss: 0.3258612\n",
      "\tspeed: 0.0978s/iter; left time: 615.0151s\n",
      "\titers: 400, epoch: 4 | loss: 0.2646027\n",
      "\tspeed: 0.0982s/iter; left time: 607.9364s\n",
      "\titers: 500, epoch: 4 | loss: 0.3703732\n",
      "\tspeed: 0.0977s/iter; left time: 594.5776s\n",
      "\titers: 600, epoch: 4 | loss: 0.3313794\n",
      "\tspeed: 0.0978s/iter; left time: 585.5359s\n",
      "\titers: 700, epoch: 4 | loss: 0.3470367\n",
      "\tspeed: 0.0979s/iter; left time: 576.4887s\n",
      "\titers: 800, epoch: 4 | loss: 0.2665585\n",
      "\tspeed: 0.0980s/iter; left time: 567.3158s\n",
      "\titers: 900, epoch: 4 | loss: 0.2471944\n",
      "\tspeed: 0.0983s/iter; left time: 558.8526s\n",
      "Epoch: 4 running time: 1.542477059364319 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.2977920 Vali Loss: 0.3883834 Test Loss: 0.6649781\n",
      "Validation loss decreased (0.407545 --> 0.388383).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2147296\n",
      "\tspeed: 0.2881s/iter; left time: 1597.8585s\n",
      "\titers: 200, epoch: 5 | loss: 0.2421745\n",
      "\tspeed: 0.0985s/iter; left time: 536.2651s\n",
      "\titers: 300, epoch: 5 | loss: 0.2301781\n",
      "\tspeed: 0.0986s/iter; left time: 527.1485s\n",
      "\titers: 400, epoch: 5 | loss: 0.2338233\n",
      "\tspeed: 0.0987s/iter; left time: 518.0345s\n",
      "\titers: 500, epoch: 5 | loss: 0.2931637\n",
      "\tspeed: 0.0985s/iter; left time: 506.8242s\n",
      "\titers: 600, epoch: 5 | loss: 0.3693731\n",
      "\tspeed: 0.0987s/iter; left time: 497.9164s\n",
      "\titers: 700, epoch: 5 | loss: 0.2314854\n",
      "\tspeed: 0.0984s/iter; left time: 486.5726s\n",
      "\titers: 800, epoch: 5 | loss: 0.3689868\n",
      "\tspeed: 0.0985s/iter; left time: 477.3464s\n",
      "\titers: 900, epoch: 5 | loss: 0.2607145\n",
      "\tspeed: 0.0982s/iter; left time: 466.3733s\n",
      "Epoch: 5 running time: 1.551684522628784 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.2765266 Vali Loss: 0.3792059 Test Loss: 0.6425338\n",
      "Validation loss decreased (0.388383 --> 0.379206).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1965883\n",
      "\tspeed: 0.2883s/iter; left time: 1327.8715s\n",
      "\titers: 200, epoch: 6 | loss: 0.2588012\n",
      "\tspeed: 0.0979s/iter; left time: 441.2202s\n",
      "\titers: 300, epoch: 6 | loss: 0.2251538\n",
      "\tspeed: 0.0978s/iter; left time: 430.9883s\n",
      "\titers: 400, epoch: 6 | loss: 0.2345210\n",
      "\tspeed: 0.0982s/iter; left time: 422.9801s\n",
      "\titers: 500, epoch: 6 | loss: 0.2129091\n",
      "\tspeed: 0.0981s/iter; left time: 412.5801s\n",
      "\titers: 600, epoch: 6 | loss: 0.2210598\n",
      "\tspeed: 0.0981s/iter; left time: 402.7707s\n",
      "\titers: 700, epoch: 6 | loss: 0.2509040\n",
      "\tspeed: 0.0980s/iter; left time: 392.6660s\n",
      "\titers: 800, epoch: 6 | loss: 0.2515513\n",
      "\tspeed: 0.0980s/iter; left time: 382.8037s\n",
      "\titers: 900, epoch: 6 | loss: 0.3001803\n",
      "\tspeed: 0.0984s/iter; left time: 374.4913s\n",
      "Epoch: 6 running time: 1.5439664721488953 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.2621217 Vali Loss: 0.3838913 Test Loss: 0.6670998\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2747995\n",
      "\tspeed: 0.2812s/iter; left time: 1030.4218s\n",
      "\titers: 200, epoch: 7 | loss: 0.3177167\n",
      "\tspeed: 0.0982s/iter; left time: 350.1239s\n",
      "\titers: 300, epoch: 7 | loss: 0.2049908\n",
      "\tspeed: 0.0982s/iter; left time: 340.3733s\n",
      "\titers: 400, epoch: 7 | loss: 0.2936099\n",
      "\tspeed: 0.0983s/iter; left time: 330.9056s\n",
      "\titers: 500, epoch: 7 | loss: 0.2532768\n",
      "\tspeed: 0.0980s/iter; left time: 320.1151s\n",
      "\titers: 600, epoch: 7 | loss: 0.2556626\n",
      "\tspeed: 0.0981s/iter; left time: 310.4543s\n",
      "\titers: 700, epoch: 7 | loss: 0.2591571\n",
      "\tspeed: 0.0984s/iter; left time: 301.6442s\n",
      "\titers: 800, epoch: 7 | loss: 0.2360556\n",
      "\tspeed: 0.0983s/iter; left time: 291.3749s\n",
      "\titers: 900, epoch: 7 | loss: 0.2521653\n",
      "\tspeed: 0.0984s/iter; left time: 281.9666s\n",
      "Epoch: 7 running time: 1.5469970226287841 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.2620220 Vali Loss: 0.3817948 Test Loss: 0.6543524\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2943222\n",
      "\tspeed: 0.2819s/iter; left time: 767.9045s\n",
      "\titers: 200, epoch: 8 | loss: 0.2702481\n",
      "\tspeed: 0.0989s/iter; left time: 259.4857s\n",
      "\titers: 300, epoch: 8 | loss: 0.2870710\n",
      "\tspeed: 0.0987s/iter; left time: 248.9951s\n",
      "\titers: 400, epoch: 8 | loss: 0.2909333\n",
      "\tspeed: 0.0980s/iter; left time: 237.6063s\n",
      "\titers: 500, epoch: 8 | loss: 0.3105505\n",
      "\tspeed: 0.0983s/iter; left time: 228.3404s\n",
      "\titers: 600, epoch: 8 | loss: 0.2014252\n",
      "\tspeed: 0.0981s/iter; left time: 218.2501s\n",
      "\titers: 700, epoch: 8 | loss: 0.3274187\n",
      "\tspeed: 0.0982s/iter; left time: 208.5026s\n",
      "\titers: 800, epoch: 8 | loss: 0.2913635\n",
      "\tspeed: 0.0980s/iter; left time: 198.2944s\n",
      "\titers: 900, epoch: 8 | loss: 0.2628719\n",
      "\tspeed: 0.0978s/iter; left time: 188.2189s\n",
      "Epoch: 8 running time: 1.5476595918337503 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.2621921 Vali Loss: 0.3789827 Test Loss: 0.6548730\n",
      "Validation loss decreased (0.379206 --> 0.378983).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2330881\n",
      "\tspeed: 0.2707s/iter; left time: 482.5948s\n",
      "\titers: 200, epoch: 9 | loss: 0.3100449\n",
      "\tspeed: 0.0926s/iter; left time: 155.8765s\n",
      "\titers: 300, epoch: 9 | loss: 0.3230477\n",
      "\tspeed: 0.0983s/iter; left time: 155.5689s\n",
      "\titers: 400, epoch: 9 | loss: 0.2439216\n",
      "\tspeed: 0.0983s/iter; left time: 145.7318s\n",
      "\titers: 500, epoch: 9 | loss: 0.1571486\n",
      "\tspeed: 0.0983s/iter; left time: 136.0101s\n",
      "\titers: 600, epoch: 9 | loss: 0.2126698\n",
      "\tspeed: 0.0982s/iter; left time: 126.0013s\n",
      "\titers: 700, epoch: 9 | loss: 0.2150868\n",
      "\tspeed: 0.0981s/iter; left time: 116.0861s\n",
      "\titers: 800, epoch: 9 | loss: 0.2607985\n",
      "\tspeed: 0.0882s/iter; left time: 95.4774s\n",
      "\titers: 900, epoch: 9 | loss: 0.2161590\n",
      "\tspeed: 0.0812s/iter; left time: 79.8587s\n",
      "Epoch: 9 running time: 1.4526338895161948 min.\n",
      "Epoch: 9, Steps: 941 | Train Loss: 0.2588452 Vali Loss: 0.3799818 Test Loss: 0.6566387\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3090481\n",
      "\tspeed: 0.2756s/iter; left time: 232.0299s\n",
      "\titers: 200, epoch: 10 | loss: 0.2841766\n",
      "\tspeed: 0.0981s/iter; left time: 72.8058s\n",
      "\titers: 300, epoch: 10 | loss: 0.2535132\n",
      "\tspeed: 0.0982s/iter; left time: 63.0232s\n",
      "\titers: 400, epoch: 10 | loss: 0.2925140\n",
      "\tspeed: 0.0981s/iter; left time: 53.1847s\n",
      "\titers: 500, epoch: 10 | loss: 0.2265480\n",
      "\tspeed: 0.0983s/iter; left time: 43.4432s\n",
      "\titers: 600, epoch: 10 | loss: 0.2891370\n",
      "\tspeed: 0.0983s/iter; left time: 33.6099s\n",
      "\titers: 700, epoch: 10 | loss: 0.2668970\n",
      "\tspeed: 0.0982s/iter; left time: 23.7603s\n",
      "\titers: 800, epoch: 10 | loss: 0.2983802\n",
      "\tspeed: 0.0982s/iter; left time: 13.9401s\n",
      "\titers: 900, epoch: 10 | loss: 0.2642350\n",
      "\tspeed: 0.0982s/iter; left time: 4.1245s\n",
      "Epoch: 10 running time: 1.5469300587972006 min.\n",
      "Epoch: 10, Steps: 941 | Train Loss: 0.2590863 Vali Loss: 0.3810705 Test Loss: 0.6588838\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 5) (269, 32, 24, 5)\n",
      "test shape: (8608, 24, 5) (8608, 24, 5)\n",
      "mse:0.6564114093780518, mae:0.5621141195297241\n",
      "\n",
      "Time intermediate for GB dataset: 30.468563119570415 min.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4183913\n",
      "\tspeed: 0.1072s/iter; left time: 997.7440s\n",
      "\titers: 200, epoch: 1 | loss: 0.3176747\n",
      "\tspeed: 0.0978s/iter; left time: 900.8986s\n",
      "\titers: 300, epoch: 1 | loss: 0.2389105\n",
      "\tspeed: 0.0982s/iter; left time: 894.4722s\n",
      "\titers: 400, epoch: 1 | loss: 0.2031928\n",
      "\tspeed: 0.0982s/iter; left time: 885.2418s\n",
      "\titers: 500, epoch: 1 | loss: 0.3285361\n",
      "\tspeed: 0.0981s/iter; left time: 874.1403s\n",
      "\titers: 600, epoch: 1 | loss: 0.2553721\n",
      "\tspeed: 0.0977s/iter; left time: 860.4383s\n",
      "\titers: 700, epoch: 1 | loss: 0.1943906\n",
      "\tspeed: 0.0980s/iter; left time: 854.0919s\n",
      "\titers: 800, epoch: 1 | loss: 0.1912926\n",
      "\tspeed: 0.0978s/iter; left time: 842.5617s\n",
      "\titers: 900, epoch: 1 | loss: 0.2323324\n",
      "\tspeed: 0.0977s/iter; left time: 831.6367s\n",
      "Epoch: 1 running time: 1.5527711788813272 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3024487 Vali Loss: 0.1919765 Test Loss: 0.3718269\n",
      "Validation loss decreased (inf --> 0.191977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2539674\n",
      "\tspeed: 0.2869s/iter; left time: 2401.2293s\n",
      "\titers: 200, epoch: 2 | loss: 0.2502235\n",
      "\tspeed: 0.0978s/iter; left time: 808.7327s\n",
      "\titers: 300, epoch: 2 | loss: 0.1820616\n",
      "\tspeed: 0.0978s/iter; left time: 799.0027s\n",
      "\titers: 400, epoch: 2 | loss: 0.1761179\n",
      "\tspeed: 0.0978s/iter; left time: 789.2069s\n",
      "\titers: 500, epoch: 2 | loss: 0.2026360\n",
      "\tspeed: 0.0985s/iter; left time: 784.7859s\n",
      "\titers: 600, epoch: 2 | loss: 0.1865350\n",
      "\tspeed: 0.0982s/iter; left time: 772.8608s\n",
      "\titers: 700, epoch: 2 | loss: 0.1284744\n",
      "\tspeed: 0.0983s/iter; left time: 763.4893s\n",
      "\titers: 800, epoch: 2 | loss: 0.1330113\n",
      "\tspeed: 0.0979s/iter; left time: 750.7078s\n",
      "\titers: 900, epoch: 2 | loss: 0.1531144\n",
      "\tspeed: 0.0978s/iter; left time: 740.2682s\n",
      "Epoch: 2 running time: 1.5425472497940063 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1868798 Vali Loss: 0.1877339 Test Loss: 0.4226499\n",
      "Validation loss decreased (0.191977 --> 0.187734).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1913545\n",
      "\tspeed: 0.2875s/iter; left time: 2135.7922s\n",
      "\titers: 200, epoch: 3 | loss: 0.1383831\n",
      "\tspeed: 0.0984s/iter; left time: 721.3151s\n",
      "\titers: 300, epoch: 3 | loss: 0.1247306\n",
      "\tspeed: 0.0984s/iter; left time: 711.3806s\n",
      "\titers: 400, epoch: 3 | loss: 0.1372115\n",
      "\tspeed: 0.0978s/iter; left time: 697.1526s\n",
      "\titers: 500, epoch: 3 | loss: 0.1255482\n",
      "\tspeed: 0.0976s/iter; left time: 685.7565s\n",
      "\titers: 600, epoch: 3 | loss: 0.1160520\n",
      "\tspeed: 0.0976s/iter; left time: 676.5837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1767505\n",
      "\tspeed: 0.0976s/iter; left time: 666.4980s\n",
      "\titers: 800, epoch: 3 | loss: 0.1513874\n",
      "\tspeed: 0.0976s/iter; left time: 656.8225s\n",
      "\titers: 900, epoch: 3 | loss: 0.1642675\n",
      "\tspeed: 0.0976s/iter; left time: 647.1322s\n",
      "Epoch: 3 running time: 1.5413131872812906 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1582189 Vali Loss: 0.1863528 Test Loss: 0.4277900\n",
      "Validation loss decreased (0.187734 --> 0.186353).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1476804\n",
      "\tspeed: 0.2858s/iter; left time: 1854.4157s\n",
      "\titers: 200, epoch: 4 | loss: 0.1471415\n",
      "\tspeed: 0.0978s/iter; left time: 624.6770s\n",
      "\titers: 300, epoch: 4 | loss: 0.1413845\n",
      "\tspeed: 0.0978s/iter; left time: 614.6736s\n",
      "\titers: 400, epoch: 4 | loss: 0.1490542\n",
      "\tspeed: 0.0981s/iter; left time: 606.8956s\n",
      "\titers: 500, epoch: 4 | loss: 0.1359551\n",
      "\tspeed: 0.0983s/iter; left time: 598.2066s\n",
      "\titers: 600, epoch: 4 | loss: 0.1420367\n",
      "\tspeed: 0.0976s/iter; left time: 584.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.1456454\n",
      "\tspeed: 0.0975s/iter; left time: 574.0613s\n",
      "\titers: 800, epoch: 4 | loss: 0.1749017\n",
      "\tspeed: 0.0975s/iter; left time: 564.4226s\n",
      "\titers: 900, epoch: 4 | loss: 0.1734580\n",
      "\tspeed: 0.0978s/iter; left time: 556.1529s\n",
      "Epoch: 4 running time: 1.539186914761861 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1428258 Vali Loss: 0.1726202 Test Loss: 0.3963655\n",
      "Validation loss decreased (0.186353 --> 0.172620).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1538869\n",
      "\tspeed: 0.2862s/iter; left time: 1587.6994s\n",
      "\titers: 200, epoch: 5 | loss: 0.1421568\n",
      "\tspeed: 0.0976s/iter; left time: 531.4726s\n",
      "\titers: 300, epoch: 5 | loss: 0.1535484\n",
      "\tspeed: 0.0976s/iter; left time: 521.8218s\n",
      "\titers: 400, epoch: 5 | loss: 0.0991839\n",
      "\tspeed: 0.0974s/iter; left time: 510.9178s\n",
      "\titers: 500, epoch: 5 | loss: 0.1206037\n",
      "\tspeed: 0.0976s/iter; left time: 502.4609s\n",
      "\titers: 600, epoch: 5 | loss: 0.1114162\n",
      "\tspeed: 0.0975s/iter; left time: 491.8379s\n",
      "\titers: 700, epoch: 5 | loss: 0.1209668\n",
      "\tspeed: 0.0974s/iter; left time: 481.6596s\n",
      "\titers: 800, epoch: 5 | loss: 0.1229157\n",
      "\tspeed: 0.0975s/iter; left time: 472.7072s\n",
      "\titers: 900, epoch: 5 | loss: 0.1002003\n",
      "\tspeed: 0.0981s/iter; left time: 465.8038s\n",
      "Epoch: 5 running time: 1.537100859483083 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1325181 Vali Loss: 0.1755163 Test Loss: 0.4312892\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1051527\n",
      "\tspeed: 0.2787s/iter; left time: 1283.5629s\n",
      "\titers: 200, epoch: 6 | loss: 0.1434750\n",
      "\tspeed: 0.0975s/iter; left time: 439.2067s\n",
      "\titers: 300, epoch: 6 | loss: 0.1429069\n",
      "\tspeed: 0.0975s/iter; left time: 429.7380s\n",
      "\titers: 400, epoch: 6 | loss: 0.1395658\n",
      "\tspeed: 0.0973s/iter; left time: 419.0939s\n",
      "\titers: 500, epoch: 6 | loss: 0.1126466\n",
      "\tspeed: 0.0975s/iter; left time: 410.1389s\n",
      "\titers: 600, epoch: 6 | loss: 0.0956490\n",
      "\tspeed: 0.0976s/iter; left time: 400.6408s\n",
      "\titers: 700, epoch: 6 | loss: 0.1260535\n",
      "\tspeed: 0.0975s/iter; left time: 390.5135s\n",
      "\titers: 800, epoch: 6 | loss: 0.1255859\n",
      "\tspeed: 0.0972s/iter; left time: 379.5172s\n",
      "\titers: 900, epoch: 6 | loss: 0.1606035\n",
      "\tspeed: 0.0974s/iter; left time: 370.5261s\n",
      "Epoch: 6 running time: 1.5332700729370117 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1315052 Vali Loss: 0.1704435 Test Loss: 0.4157898\n",
      "Validation loss decreased (0.172620 --> 0.170444).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1184536\n",
      "\tspeed: 0.2840s/iter; left time: 1040.9181s\n",
      "\titers: 200, epoch: 7 | loss: 0.1058492\n",
      "\tspeed: 0.0980s/iter; left time: 349.2116s\n",
      "\titers: 300, epoch: 7 | loss: 0.1113770\n",
      "\tspeed: 0.0981s/iter; left time: 339.7681s\n",
      "\titers: 400, epoch: 7 | loss: 0.1360071\n",
      "\tspeed: 0.0978s/iter; left time: 328.9867s\n",
      "\titers: 500, epoch: 7 | loss: 0.1233190\n",
      "\tspeed: 0.0977s/iter; left time: 318.8432s\n",
      "\titers: 600, epoch: 7 | loss: 0.1102490\n",
      "\tspeed: 0.0975s/iter; left time: 308.5809s\n",
      "\titers: 700, epoch: 7 | loss: 0.1098698\n",
      "\tspeed: 0.0976s/iter; left time: 299.1463s\n",
      "\titers: 800, epoch: 7 | loss: 0.0954850\n",
      "\tspeed: 0.0976s/iter; left time: 289.5034s\n",
      "\titers: 900, epoch: 7 | loss: 0.1111772\n",
      "\tspeed: 0.0977s/iter; left time: 279.8117s\n",
      "Epoch: 7 running time: 1.5388555566469828 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1274667 Vali Loss: 0.1747580 Test Loss: 0.4195948\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1401287\n",
      "\tspeed: 0.2791s/iter; left time: 760.1574s\n",
      "\titers: 200, epoch: 8 | loss: 0.1006209\n",
      "\tspeed: 0.0980s/iter; left time: 257.1423s\n",
      "\titers: 300, epoch: 8 | loss: 0.1409823\n",
      "\tspeed: 0.0980s/iter; left time: 247.3329s\n",
      "\titers: 400, epoch: 8 | loss: 0.1357944\n",
      "\tspeed: 0.0980s/iter; left time: 237.6313s\n",
      "\titers: 500, epoch: 8 | loss: 0.0975027\n",
      "\tspeed: 0.0982s/iter; left time: 228.1614s\n",
      "\titers: 600, epoch: 8 | loss: 0.1578860\n",
      "\tspeed: 0.0977s/iter; left time: 217.2455s\n",
      "\titers: 700, epoch: 8 | loss: 0.1083857\n",
      "\tspeed: 0.0976s/iter; left time: 207.3591s\n",
      "\titers: 800, epoch: 8 | loss: 0.1733156\n",
      "\tspeed: 0.0977s/iter; left time: 197.7911s\n",
      "\titers: 900, epoch: 8 | loss: 0.1274520\n",
      "\tspeed: 0.0980s/iter; left time: 188.5411s\n",
      "Epoch: 8 running time: 1.5404897371927897 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1269825 Vali Loss: 0.1702255 Test Loss: 0.4147992\n",
      "Validation loss decreased (0.170444 --> 0.170226).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1236518\n",
      "\tspeed: 0.2837s/iter; left time: 505.8556s\n",
      "\titers: 200, epoch: 9 | loss: 0.1474202\n",
      "\tspeed: 0.0977s/iter; left time: 164.4516s\n",
      "\titers: 300, epoch: 9 | loss: 0.1326301\n",
      "\tspeed: 0.0977s/iter; left time: 154.7009s\n",
      "\titers: 400, epoch: 9 | loss: 0.1410056\n",
      "\tspeed: 0.0977s/iter; left time: 144.8837s\n",
      "\titers: 500, epoch: 9 | loss: 0.1886584\n",
      "\tspeed: 0.0977s/iter; left time: 135.1679s\n",
      "\titers: 600, epoch: 9 | loss: 0.1180006\n",
      "\tspeed: 0.0978s/iter; left time: 125.4362s\n",
      "\titers: 700, epoch: 9 | loss: 0.1217441\n",
      "\tspeed: 0.0978s/iter; left time: 115.6728s\n",
      "\titers: 800, epoch: 9 | loss: 0.1094521\n",
      "\tspeed: 0.0978s/iter; left time: 105.9416s\n",
      "\titers: 900, epoch: 9 | loss: 0.1150863\n",
      "\tspeed: 0.0977s/iter; left time: 96.0801s\n",
      "Epoch: 9 running time: 1.5383431275685628 min.\n",
      "Epoch: 9, Steps: 941 | Train Loss: 0.1260302 Vali Loss: 0.1710989 Test Loss: 0.4079327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0950374\n",
      "\tspeed: 0.2780s/iter; left time: 234.0744s\n",
      "\titers: 200, epoch: 10 | loss: 0.1361429\n",
      "\tspeed: 0.0977s/iter; left time: 72.4586s\n",
      "\titers: 300, epoch: 10 | loss: 0.1148399\n",
      "\tspeed: 0.0975s/iter; left time: 62.5860s\n",
      "\titers: 400, epoch: 10 | loss: 0.1340534\n",
      "\tspeed: 0.0854s/iter; left time: 46.2878s\n",
      "\titers: 500, epoch: 10 | loss: 0.1267132\n",
      "\tspeed: 0.0809s/iter; left time: 35.7678s\n",
      "\titers: 600, epoch: 10 | loss: 0.1358077\n",
      "\tspeed: 0.0925s/iter; left time: 31.6383s\n",
      "\titers: 700, epoch: 10 | loss: 0.1198425\n",
      "\tspeed: 0.0810s/iter; left time: 19.6036s\n",
      "\titers: 800, epoch: 10 | loss: 0.2074506\n",
      "\tspeed: 0.0809s/iter; left time: 11.4930s\n",
      "\titers: 900, epoch: 10 | loss: 0.1105775\n",
      "\tspeed: 0.0809s/iter; left time: 3.3985s\n",
      "Epoch: 10 running time: 1.3840091983477274 min.\n",
      "Epoch: 10, Steps: 941 | Train Loss: 0.1258493 Vali Loss: 0.1716152 Test Loss: 0.4135497\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.4149816930294037, mae:0.4109726548194885\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.3302637\n",
      "\tspeed: 0.1006s/iter; left time: 936.4050s\n",
      "\titers: 200, epoch: 1 | loss: 0.3151070\n",
      "\tspeed: 0.0982s/iter; left time: 904.5968s\n",
      "\titers: 300, epoch: 1 | loss: 0.2623212\n",
      "\tspeed: 0.0982s/iter; left time: 894.3453s\n",
      "\titers: 400, epoch: 1 | loss: 0.2294310\n",
      "\tspeed: 0.0980s/iter; left time: 883.0982s\n",
      "\titers: 500, epoch: 1 | loss: 0.2054772\n",
      "\tspeed: 0.0980s/iter; left time: 873.2886s\n",
      "\titers: 600, epoch: 1 | loss: 0.2432472\n",
      "\tspeed: 0.0981s/iter; left time: 864.3074s\n",
      "\titers: 700, epoch: 1 | loss: 0.2112736\n",
      "\tspeed: 0.0981s/iter; left time: 854.8301s\n",
      "\titers: 800, epoch: 1 | loss: 0.2934595\n",
      "\tspeed: 0.0984s/iter; left time: 847.4383s\n",
      "\titers: 900, epoch: 1 | loss: 0.2331795\n",
      "\tspeed: 0.0982s/iter; left time: 835.8786s\n",
      "Epoch: 1 running time: 1.5455976327260335 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.3063375 Vali Loss: 0.2056014 Test Loss: 0.3703719\n",
      "Validation loss decreased (inf --> 0.205601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2075216\n",
      "\tspeed: 0.2866s/iter; left time: 2398.4506s\n",
      "\titers: 200, epoch: 2 | loss: 0.1935526\n",
      "\tspeed: 0.0977s/iter; left time: 807.7090s\n",
      "\titers: 300, epoch: 2 | loss: 0.1708436\n",
      "\tspeed: 0.0975s/iter; left time: 796.9012s\n",
      "\titers: 400, epoch: 2 | loss: 0.1765831\n",
      "\tspeed: 0.0976s/iter; left time: 787.6118s\n",
      "\titers: 500, epoch: 2 | loss: 0.2278909\n",
      "\tspeed: 0.0976s/iter; left time: 778.0649s\n",
      "\titers: 600, epoch: 2 | loss: 0.1893847\n",
      "\tspeed: 0.0977s/iter; left time: 768.6612s\n",
      "\titers: 700, epoch: 2 | loss: 0.1558357\n",
      "\tspeed: 0.0978s/iter; left time: 759.6271s\n",
      "\titers: 800, epoch: 2 | loss: 0.1449818\n",
      "\tspeed: 0.0978s/iter; left time: 749.8155s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376279\n",
      "\tspeed: 0.0976s/iter; left time: 739.0294s\n",
      "Epoch: 2 running time: 1.5377209385236104 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1848781 Vali Loss: 0.1817326 Test Loss: 0.3549186\n",
      "Validation loss decreased (0.205601 --> 0.181733).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1394800\n",
      "\tspeed: 0.2872s/iter; left time: 2133.8337s\n",
      "\titers: 200, epoch: 3 | loss: 0.1271416\n",
      "\tspeed: 0.0979s/iter; left time: 717.8706s\n",
      "\titers: 300, epoch: 3 | loss: 0.1655629\n",
      "\tspeed: 0.0977s/iter; left time: 706.4635s\n",
      "\titers: 400, epoch: 3 | loss: 0.1368292\n",
      "\tspeed: 0.0980s/iter; left time: 698.5540s\n",
      "\titers: 500, epoch: 3 | loss: 0.1455152\n",
      "\tspeed: 0.0974s/iter; left time: 684.4711s\n",
      "\titers: 600, epoch: 3 | loss: 0.1904377\n",
      "\tspeed: 0.0975s/iter; left time: 675.7959s\n",
      "\titers: 700, epoch: 3 | loss: 0.2081547\n",
      "\tspeed: 0.0976s/iter; left time: 666.3756s\n",
      "\titers: 800, epoch: 3 | loss: 0.1410057\n",
      "\tspeed: 0.0976s/iter; left time: 656.6885s\n",
      "\titers: 900, epoch: 3 | loss: 0.1790302\n",
      "\tspeed: 0.0976s/iter; left time: 646.7100s\n",
      "Epoch: 3 running time: 1.5385660449663798 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1583684 Vali Loss: 0.1737744 Test Loss: 0.3850651\n",
      "Validation loss decreased (0.181733 --> 0.173774).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1106178\n",
      "\tspeed: 0.2862s/iter; left time: 1857.0656s\n",
      "\titers: 200, epoch: 4 | loss: 0.1032562\n",
      "\tspeed: 0.0980s/iter; left time: 626.1459s\n",
      "\titers: 300, epoch: 4 | loss: 0.1630179\n",
      "\tspeed: 0.0976s/iter; left time: 613.5937s\n",
      "\titers: 400, epoch: 4 | loss: 0.1381390\n",
      "\tspeed: 0.0977s/iter; left time: 604.7695s\n",
      "\titers: 500, epoch: 4 | loss: 0.1481630\n",
      "\tspeed: 0.0978s/iter; left time: 595.3543s\n",
      "\titers: 600, epoch: 4 | loss: 0.1578198\n",
      "\tspeed: 0.0977s/iter; left time: 584.7553s\n",
      "\titers: 700, epoch: 4 | loss: 0.1212454\n",
      "\tspeed: 0.0977s/iter; left time: 575.2874s\n",
      "\titers: 800, epoch: 4 | loss: 0.1387872\n",
      "\tspeed: 0.0976s/iter; left time: 565.0239s\n",
      "\titers: 900, epoch: 4 | loss: 0.0989111\n",
      "\tspeed: 0.0976s/iter; left time: 555.3796s\n",
      "Epoch: 4 running time: 1.5385752638181052 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1416687 Vali Loss: 0.1775134 Test Loss: 0.4505916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1332261\n",
      "\tspeed: 0.2798s/iter; left time: 1551.8333s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178803\n",
      "\tspeed: 0.0977s/iter; left time: 532.1037s\n",
      "\titers: 300, epoch: 5 | loss: 0.1324545\n",
      "\tspeed: 0.0977s/iter; left time: 522.6032s\n",
      "\titers: 400, epoch: 5 | loss: 0.1655561\n",
      "\tspeed: 0.0980s/iter; left time: 514.4260s\n",
      "\titers: 500, epoch: 5 | loss: 0.1961126\n",
      "\tspeed: 0.0980s/iter; left time: 504.5302s\n",
      "\titers: 600, epoch: 5 | loss: 0.1407264\n",
      "\tspeed: 0.0981s/iter; left time: 494.8663s\n",
      "\titers: 700, epoch: 5 | loss: 0.1143082\n",
      "\tspeed: 0.0983s/iter; left time: 486.0738s\n",
      "\titers: 800, epoch: 5 | loss: 0.1553129\n",
      "\tspeed: 0.0982s/iter; left time: 475.8228s\n",
      "\titers: 900, epoch: 5 | loss: 0.1202482\n",
      "\tspeed: 0.0981s/iter; left time: 465.5710s\n",
      "Epoch: 5 running time: 1.534405815601349 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1385942 Vali Loss: 0.1720676 Test Loss: 0.4219375\n",
      "Validation loss decreased (0.173774 --> 0.172068).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1157490\n",
      "\tspeed: 0.2818s/iter; left time: 1298.0999s\n",
      "\titers: 200, epoch: 6 | loss: 0.1406169\n",
      "\tspeed: 0.0975s/iter; left time: 439.4475s\n",
      "\titers: 300, epoch: 6 | loss: 0.1372459\n",
      "\tspeed: 0.0975s/iter; left time: 429.3841s\n",
      "\titers: 400, epoch: 6 | loss: 0.1087425\n",
      "\tspeed: 0.0979s/iter; left time: 421.6321s\n",
      "\titers: 500, epoch: 6 | loss: 0.1378059\n",
      "\tspeed: 0.0979s/iter; left time: 411.8105s\n",
      "\titers: 600, epoch: 6 | loss: 0.1528922\n",
      "\tspeed: 0.0980s/iter; left time: 402.2005s\n",
      "\titers: 700, epoch: 6 | loss: 0.1253271\n",
      "\tspeed: 0.0981s/iter; left time: 392.8542s\n",
      "\titers: 800, epoch: 6 | loss: 0.1130694\n",
      "\tspeed: 0.0980s/iter; left time: 382.8259s\n",
      "\titers: 900, epoch: 6 | loss: 0.1053836\n",
      "\tspeed: 0.0977s/iter; left time: 371.7387s\n",
      "Epoch: 6 running time: 1.5394508878389994 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1311712 Vali Loss: 0.1755019 Test Loss: 0.4397382\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1171806\n",
      "\tspeed: 0.2819s/iter; left time: 1033.3229s\n",
      "\titers: 200, epoch: 7 | loss: 0.1571493\n",
      "\tspeed: 0.0986s/iter; left time: 351.6177s\n",
      "\titers: 300, epoch: 7 | loss: 0.1066693\n",
      "\tspeed: 0.0985s/iter; left time: 341.1681s\n",
      "\titers: 400, epoch: 7 | loss: 0.1229019\n",
      "\tspeed: 0.0985s/iter; left time: 331.5692s\n",
      "\titers: 500, epoch: 7 | loss: 0.1200267\n",
      "\tspeed: 0.0983s/iter; left time: 320.7892s\n",
      "\titers: 600, epoch: 7 | loss: 0.1354899\n",
      "\tspeed: 0.0977s/iter; left time: 309.3551s\n",
      "\titers: 700, epoch: 7 | loss: 0.1273839\n",
      "\tspeed: 0.0977s/iter; left time: 299.3756s\n",
      "\titers: 800, epoch: 7 | loss: 0.1198170\n",
      "\tspeed: 0.0977s/iter; left time: 289.8079s\n",
      "\titers: 900, epoch: 7 | loss: 0.1362952\n",
      "\tspeed: 0.0979s/iter; left time: 280.5158s\n",
      "Epoch: 7 running time: 1.5471929033597311 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1305958 Vali Loss: 0.1727828 Test Loss: 0.4353591\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1495225\n",
      "\tspeed: 0.2801s/iter; left time: 762.9073s\n",
      "\titers: 200, epoch: 8 | loss: 0.1441906\n",
      "\tspeed: 0.0978s/iter; left time: 256.5227s\n",
      "\titers: 300, epoch: 8 | loss: 0.1668217\n",
      "\tspeed: 0.0977s/iter; left time: 246.6713s\n",
      "\titers: 400, epoch: 8 | loss: 0.1325599\n",
      "\tspeed: 0.0977s/iter; left time: 236.7391s\n",
      "\titers: 500, epoch: 8 | loss: 0.1169434\n",
      "\tspeed: 0.0977s/iter; left time: 227.1326s\n",
      "\titers: 600, epoch: 8 | loss: 0.1312203\n",
      "\tspeed: 0.0973s/iter; left time: 216.3205s\n",
      "\titers: 700, epoch: 8 | loss: 0.1789077\n",
      "\tspeed: 0.0976s/iter; left time: 207.4015s\n",
      "\titers: 800, epoch: 8 | loss: 0.1233529\n",
      "\tspeed: 0.0979s/iter; left time: 198.1780s\n",
      "\titers: 900, epoch: 8 | loss: 0.1030344\n",
      "\tspeed: 0.0977s/iter; left time: 187.8853s\n",
      "Epoch: 8 running time: 1.5382991472880045 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1308838 Vali Loss: 0.1731599 Test Loss: 0.4241140\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.423806756734848, mae:0.4119410812854767\n",
      "\n",
      "Time intermediate for ES dataset: 32.3044050971667 min.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.3871442\n",
      "\tspeed: 0.1069s/iter; left time: 995.4311s\n",
      "\titers: 200, epoch: 1 | loss: 0.2673644\n",
      "\tspeed: 0.0890s/iter; left time: 819.9429s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006789\n",
      "\tspeed: 0.0837s/iter; left time: 762.3904s\n",
      "\titers: 400, epoch: 1 | loss: 0.1515370\n",
      "\tspeed: 0.0981s/iter; left time: 883.9953s\n",
      "\titers: 500, epoch: 1 | loss: 0.2455160\n",
      "\tspeed: 0.0981s/iter; left time: 873.8359s\n",
      "\titers: 600, epoch: 1 | loss: 0.2780952\n",
      "\tspeed: 0.0978s/iter; left time: 861.7338s\n",
      "\titers: 700, epoch: 1 | loss: 0.2736951\n",
      "\tspeed: 0.0979s/iter; left time: 853.0327s\n",
      "\titers: 800, epoch: 1 | loss: 0.2647220\n",
      "\tspeed: 0.0979s/iter; left time: 842.8808s\n",
      "\titers: 900, epoch: 1 | loss: 0.1626280\n",
      "\tspeed: 0.0979s/iter; left time: 833.1405s\n",
      "Epoch: 1 running time: 1.5138357957204183 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2831952 Vali Loss: 0.2616880 Test Loss: 0.4787354\n",
      "Validation loss decreased (inf --> 0.261688).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1852047\n",
      "\tspeed: 0.2854s/iter; left time: 2389.1435s\n",
      "\titers: 200, epoch: 2 | loss: 0.1698483\n",
      "\tspeed: 0.0973s/iter; left time: 804.8258s\n",
      "\titers: 300, epoch: 2 | loss: 0.2079634\n",
      "\tspeed: 0.0974s/iter; left time: 795.3713s\n",
      "\titers: 400, epoch: 2 | loss: 0.1993060\n",
      "\tspeed: 0.0974s/iter; left time: 786.0162s\n",
      "\titers: 500, epoch: 2 | loss: 0.2143207\n",
      "\tspeed: 0.0974s/iter; left time: 776.5000s\n",
      "\titers: 600, epoch: 2 | loss: 0.1892886\n",
      "\tspeed: 0.0974s/iter; left time: 766.3956s\n",
      "\titers: 700, epoch: 2 | loss: 0.1499426\n",
      "\tspeed: 0.0974s/iter; left time: 756.9036s\n",
      "\titers: 800, epoch: 2 | loss: 0.1230438\n",
      "\tspeed: 0.0974s/iter; left time: 746.8013s\n",
      "\titers: 900, epoch: 2 | loss: 0.2164897\n",
      "\tspeed: 0.0974s/iter; left time: 737.3784s\n",
      "Epoch: 2 running time: 1.5335353374481202 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1828118 Vali Loss: 0.2568518 Test Loss: 0.4131241\n",
      "Validation loss decreased (0.261688 --> 0.256852).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1794982\n",
      "\tspeed: 0.2868s/iter; left time: 2130.9892s\n",
      "\titers: 200, epoch: 3 | loss: 0.1258878\n",
      "\tspeed: 0.0983s/iter; left time: 720.4389s\n",
      "\titers: 300, epoch: 3 | loss: 0.1473013\n",
      "\tspeed: 0.0980s/iter; left time: 708.3873s\n",
      "\titers: 400, epoch: 3 | loss: 0.1278618\n",
      "\tspeed: 0.0981s/iter; left time: 699.1794s\n",
      "\titers: 500, epoch: 3 | loss: 0.1277567\n",
      "\tspeed: 0.0981s/iter; left time: 689.2351s\n",
      "\titers: 600, epoch: 3 | loss: 0.1196522\n",
      "\tspeed: 0.0981s/iter; left time: 679.5763s\n",
      "\titers: 700, epoch: 3 | loss: 0.1161006\n",
      "\tspeed: 0.0978s/iter; left time: 667.7730s\n",
      "\titers: 800, epoch: 3 | loss: 0.2125789\n",
      "\tspeed: 0.0977s/iter; left time: 657.7221s\n",
      "\titers: 900, epoch: 3 | loss: 0.1116768\n",
      "\tspeed: 0.0978s/iter; left time: 648.4570s\n",
      "Epoch: 3 running time: 1.5419822017351785 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1522176 Vali Loss: 0.2416414 Test Loss: 0.3996641\n",
      "Validation loss decreased (0.256852 --> 0.241641).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1334140\n",
      "\tspeed: 0.2861s/iter; left time: 1856.2962s\n",
      "\titers: 200, epoch: 4 | loss: 0.1624571\n",
      "\tspeed: 0.0980s/iter; left time: 626.0158s\n",
      "\titers: 300, epoch: 4 | loss: 0.1250404\n",
      "\tspeed: 0.0979s/iter; left time: 615.6574s\n",
      "\titers: 400, epoch: 4 | loss: 0.1235920\n",
      "\tspeed: 0.0979s/iter; left time: 605.8320s\n",
      "\titers: 500, epoch: 4 | loss: 0.1108047\n",
      "\tspeed: 0.0980s/iter; left time: 596.4108s\n",
      "\titers: 600, epoch: 4 | loss: 0.1781396\n",
      "\tspeed: 0.0978s/iter; left time: 585.7715s\n",
      "\titers: 700, epoch: 4 | loss: 0.1164244\n",
      "\tspeed: 0.0979s/iter; left time: 576.5792s\n",
      "\titers: 800, epoch: 4 | loss: 0.1635794\n",
      "\tspeed: 0.0980s/iter; left time: 567.1916s\n",
      "\titers: 900, epoch: 4 | loss: 0.0831978\n",
      "\tspeed: 0.0953s/iter; left time: 542.1088s\n",
      "Epoch: 4 running time: 1.531578799088796 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1316964 Vali Loss: 0.2272363 Test Loss: 0.4058791\n",
      "Validation loss decreased (0.241641 --> 0.227236).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1401690\n",
      "\tspeed: 0.2901s/iter; left time: 1609.3889s\n",
      "\titers: 200, epoch: 5 | loss: 0.2141778\n",
      "\tspeed: 0.0982s/iter; left time: 534.6809s\n",
      "\titers: 300, epoch: 5 | loss: 0.0976685\n",
      "\tspeed: 0.0981s/iter; left time: 524.3869s\n",
      "\titers: 400, epoch: 5 | loss: 0.1276522\n",
      "\tspeed: 0.0980s/iter; left time: 514.1479s\n",
      "\titers: 500, epoch: 5 | loss: 0.0873264\n",
      "\tspeed: 0.0979s/iter; left time: 504.1038s\n",
      "\titers: 600, epoch: 5 | loss: 0.0939021\n",
      "\tspeed: 0.0982s/iter; left time: 495.5769s\n",
      "\titers: 700, epoch: 5 | loss: 0.1109263\n",
      "\tspeed: 0.0981s/iter; left time: 485.2249s\n",
      "\titers: 800, epoch: 5 | loss: 0.1041656\n",
      "\tspeed: 0.0978s/iter; left time: 473.8629s\n",
      "\titers: 900, epoch: 5 | loss: 0.1287480\n",
      "\tspeed: 0.0983s/iter; left time: 466.8228s\n",
      "Epoch: 5 running time: 1.5440135836601256 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1180394 Vali Loss: 0.2291849 Test Loss: 0.4162515\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0720225\n",
      "\tspeed: 0.2793s/iter; left time: 1286.4110s\n",
      "\titers: 200, epoch: 6 | loss: 0.1116268\n",
      "\tspeed: 0.0979s/iter; left time: 440.9537s\n",
      "\titers: 300, epoch: 6 | loss: 0.1110815\n",
      "\tspeed: 0.0938s/iter; left time: 413.1271s\n",
      "\titers: 400, epoch: 6 | loss: 0.0973093\n",
      "\tspeed: 0.0976s/iter; left time: 420.2059s\n",
      "\titers: 500, epoch: 6 | loss: 0.0811179\n",
      "\tspeed: 0.0977s/iter; left time: 411.0745s\n",
      "\titers: 600, epoch: 6 | loss: 0.1062097\n",
      "\tspeed: 0.0979s/iter; left time: 401.8598s\n",
      "\titers: 700, epoch: 6 | loss: 0.1420697\n",
      "\tspeed: 0.0981s/iter; left time: 392.8887s\n",
      "\titers: 800, epoch: 6 | loss: 0.1018597\n",
      "\tspeed: 0.0980s/iter; left time: 382.7114s\n",
      "\titers: 900, epoch: 6 | loss: 0.1084752\n",
      "\tspeed: 0.0978s/iter; left time: 372.1815s\n",
      "Epoch: 6 running time: 1.5343475143114726 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1172928 Vali Loss: 0.2305413 Test Loss: 0.4107639\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0814674\n",
      "\tspeed: 0.2799s/iter; left time: 1025.9080s\n",
      "\titers: 200, epoch: 7 | loss: 0.0873558\n",
      "\tspeed: 0.0980s/iter; left time: 349.4500s\n",
      "\titers: 300, epoch: 7 | loss: 0.0967285\n",
      "\tspeed: 0.0979s/iter; left time: 339.3697s\n",
      "\titers: 400, epoch: 7 | loss: 0.1214434\n",
      "\tspeed: 0.0976s/iter; left time: 328.4567s\n",
      "\titers: 500, epoch: 7 | loss: 0.1131551\n",
      "\tspeed: 0.0975s/iter; left time: 318.1933s\n",
      "\titers: 600, epoch: 7 | loss: 0.1573701\n",
      "\tspeed: 0.0980s/iter; left time: 310.0173s\n",
      "\titers: 700, epoch: 7 | loss: 0.1066053\n",
      "\tspeed: 0.0978s/iter; left time: 299.7031s\n",
      "\titers: 800, epoch: 7 | loss: 0.1340960\n",
      "\tspeed: 0.0977s/iter; left time: 289.7749s\n",
      "\titers: 900, epoch: 7 | loss: 0.1279623\n",
      "\tspeed: 0.0975s/iter; left time: 279.4537s\n",
      "Epoch: 7 running time: 1.5399282574653625 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1167402 Vali Loss: 0.2287699 Test Loss: 0.4122698\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.40965697169303894, mae:0.35750654339790344\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4186364\n",
      "\tspeed: 0.1010s/iter; left time: 940.0655s\n",
      "\titers: 200, epoch: 1 | loss: 0.3263134\n",
      "\tspeed: 0.0982s/iter; left time: 904.9285s\n",
      "\titers: 300, epoch: 1 | loss: 0.2293927\n",
      "\tspeed: 0.0981s/iter; left time: 894.0635s\n",
      "\titers: 400, epoch: 1 | loss: 0.1484141\n",
      "\tspeed: 0.0984s/iter; left time: 886.4984s\n",
      "\titers: 500, epoch: 1 | loss: 0.1641806\n",
      "\tspeed: 0.0984s/iter; left time: 876.7438s\n",
      "\titers: 600, epoch: 1 | loss: 0.1693609\n",
      "\tspeed: 0.0981s/iter; left time: 864.5007s\n",
      "\titers: 700, epoch: 1 | loss: 0.1987397\n",
      "\tspeed: 0.0986s/iter; left time: 858.7678s\n",
      "\titers: 800, epoch: 1 | loss: 0.1767388\n",
      "\tspeed: 0.0981s/iter; left time: 844.9249s\n",
      "\titers: 900, epoch: 1 | loss: 0.2046778\n",
      "\tspeed: 0.0982s/iter; left time: 835.8932s\n",
      "Epoch: 1 running time: 1.5474209944407145 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2850537 Vali Loss: 0.2336705 Test Loss: 0.4041315\n",
      "Validation loss decreased (inf --> 0.233671).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1910070\n",
      "\tspeed: 0.2886s/iter; left time: 2415.7236s\n",
      "\titers: 200, epoch: 2 | loss: 0.2027248\n",
      "\tspeed: 0.0978s/iter; left time: 809.1651s\n",
      "\titers: 300, epoch: 2 | loss: 0.1684840\n",
      "\tspeed: 0.0978s/iter; left time: 798.7959s\n",
      "\titers: 400, epoch: 2 | loss: 0.1411078\n",
      "\tspeed: 0.0977s/iter; left time: 788.2662s\n",
      "\titers: 500, epoch: 2 | loss: 0.1941990\n",
      "\tspeed: 0.0976s/iter; left time: 778.2225s\n",
      "\titers: 600, epoch: 2 | loss: 0.1813835\n",
      "\tspeed: 0.0978s/iter; left time: 769.3898s\n",
      "\titers: 700, epoch: 2 | loss: 0.1679413\n",
      "\tspeed: 0.0978s/iter; left time: 760.2324s\n",
      "\titers: 800, epoch: 2 | loss: 0.1534651\n",
      "\tspeed: 0.0977s/iter; left time: 749.5613s\n",
      "\titers: 900, epoch: 2 | loss: 0.2049218\n",
      "\tspeed: 0.0976s/iter; left time: 739.1731s\n",
      "Epoch: 2 running time: 1.5386431614557903 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1826428 Vali Loss: 0.2532248 Test Loss: 0.4527559\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2628095\n",
      "\tspeed: 0.2792s/iter; left time: 2074.0601s\n",
      "\titers: 200, epoch: 3 | loss: 0.2365825\n",
      "\tspeed: 0.0976s/iter; left time: 715.6503s\n",
      "\titers: 300, epoch: 3 | loss: 0.1906161\n",
      "\tspeed: 0.0979s/iter; left time: 707.6222s\n",
      "\titers: 400, epoch: 3 | loss: 0.1980529\n",
      "\tspeed: 0.0979s/iter; left time: 697.9331s\n",
      "\titers: 500, epoch: 3 | loss: 0.1365095\n",
      "\tspeed: 0.0980s/iter; left time: 688.8696s\n",
      "\titers: 600, epoch: 3 | loss: 0.1684517\n",
      "\tspeed: 0.0980s/iter; left time: 679.3249s\n",
      "\titers: 700, epoch: 3 | loss: 0.3296774\n",
      "\tspeed: 0.0982s/iter; left time: 670.5298s\n",
      "\titers: 800, epoch: 3 | loss: 0.1282694\n",
      "\tspeed: 0.0981s/iter; left time: 660.0982s\n",
      "\titers: 900, epoch: 3 | loss: 0.1457012\n",
      "\tspeed: 0.0981s/iter; left time: 650.3731s\n",
      "Epoch: 3 running time: 1.5414589126904805 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1762556 Vali Loss: 0.2430529 Test Loss: 0.3964816\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1606507\n",
      "\tspeed: 0.2662s/iter; left time: 1726.8307s\n",
      "\titers: 200, epoch: 4 | loss: 0.1244453\n",
      "\tspeed: 0.0978s/iter; left time: 624.9634s\n",
      "\titers: 300, epoch: 4 | loss: 0.2576856\n",
      "\tspeed: 0.0978s/iter; left time: 615.0768s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086918\n",
      "\tspeed: 0.0978s/iter; left time: 605.3667s\n",
      "\titers: 500, epoch: 4 | loss: 0.1658135\n",
      "\tspeed: 0.0978s/iter; left time: 595.4880s\n",
      "\titers: 600, epoch: 4 | loss: 0.1352087\n",
      "\tspeed: 0.0976s/iter; left time: 584.5615s\n",
      "\titers: 700, epoch: 4 | loss: 0.1375851\n",
      "\tspeed: 0.0977s/iter; left time: 575.1545s\n",
      "\titers: 800, epoch: 4 | loss: 0.1459120\n",
      "\tspeed: 0.0977s/iter; left time: 565.6086s\n",
      "\titers: 900, epoch: 4 | loss: 0.1659870\n",
      "\tspeed: 0.0976s/iter; left time: 555.1267s\n",
      "Epoch: 4 running time: 1.5165399193763733 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1710265 Vali Loss: 0.2365344 Test Loss: 0.3860765\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.3855854570865631, mae:0.3636378049850464\n",
      "\n",
      "Time intermediate for FR dataset: 19.977133317788443 min.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.4839092\n",
      "\tspeed: 0.1066s/iter; left time: 992.9850s\n",
      "\titers: 200, epoch: 1 | loss: 0.2879023\n",
      "\tspeed: 0.0973s/iter; left time: 896.5701s\n",
      "\titers: 300, epoch: 1 | loss: 0.1979710\n",
      "\tspeed: 0.0976s/iter; left time: 888.8603s\n",
      "\titers: 400, epoch: 1 | loss: 0.2898935\n",
      "\tspeed: 0.0974s/iter; left time: 878.1138s\n",
      "\titers: 500, epoch: 1 | loss: 0.2302311\n",
      "\tspeed: 0.0975s/iter; left time: 868.8615s\n",
      "\titers: 600, epoch: 1 | loss: 0.1686959\n",
      "\tspeed: 0.0975s/iter; left time: 858.6793s\n",
      "\titers: 700, epoch: 1 | loss: 0.1522209\n",
      "\tspeed: 0.0974s/iter; left time: 848.2631s\n",
      "\titers: 800, epoch: 1 | loss: 0.1437175\n",
      "\tspeed: 0.0976s/iter; left time: 840.4306s\n",
      "\titers: 900, epoch: 1 | loss: 0.1686486\n",
      "\tspeed: 0.0975s/iter; left time: 829.4021s\n",
      "Epoch: 1 running time: 1.5453044414520263 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2949341 Vali Loss: 0.1825299 Test Loss: 0.2419658\n",
      "Validation loss decreased (inf --> 0.182530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2636757\n",
      "\tspeed: 0.2838s/iter; left time: 2375.5902s\n",
      "\titers: 200, epoch: 2 | loss: 0.1816243\n",
      "\tspeed: 0.0976s/iter; left time: 807.4244s\n",
      "\titers: 300, epoch: 2 | loss: 0.1623272\n",
      "\tspeed: 0.0975s/iter; left time: 796.4880s\n",
      "\titers: 400, epoch: 2 | loss: 0.1740752\n",
      "\tspeed: 0.0974s/iter; left time: 786.0349s\n",
      "\titers: 500, epoch: 2 | loss: 0.1692941\n",
      "\tspeed: 0.0976s/iter; left time: 778.0605s\n",
      "\titers: 600, epoch: 2 | loss: 0.1518331\n",
      "\tspeed: 0.0975s/iter; left time: 767.6252s\n",
      "\titers: 700, epoch: 2 | loss: 0.1923162\n",
      "\tspeed: 0.0974s/iter; left time: 756.9518s\n",
      "\titers: 800, epoch: 2 | loss: 0.1279732\n",
      "\tspeed: 0.0974s/iter; left time: 746.6892s\n",
      "\titers: 900, epoch: 2 | loss: 0.1602855\n",
      "\tspeed: 0.0973s/iter; left time: 736.8447s\n",
      "Epoch: 2 running time: 1.5341623226801555 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1825944 Vali Loss: 0.1623728 Test Loss: 0.2211493\n",
      "Validation loss decreased (0.182530 --> 0.162373).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2162754\n",
      "\tspeed: 0.2838s/iter; left time: 2108.5827s\n",
      "\titers: 200, epoch: 3 | loss: 0.1780417\n",
      "\tspeed: 0.0974s/iter; left time: 714.0807s\n",
      "\titers: 300, epoch: 3 | loss: 0.1844170\n",
      "\tspeed: 0.0974s/iter; left time: 704.1188s\n",
      "\titers: 400, epoch: 3 | loss: 0.2321048\n",
      "\tspeed: 0.0974s/iter; left time: 694.1767s\n",
      "\titers: 500, epoch: 3 | loss: 0.1619159\n",
      "\tspeed: 0.0974s/iter; left time: 684.3971s\n",
      "\titers: 600, epoch: 3 | loss: 0.2035481\n",
      "\tspeed: 0.0973s/iter; left time: 674.3872s\n",
      "\titers: 700, epoch: 3 | loss: 0.1415086\n",
      "\tspeed: 0.0974s/iter; left time: 665.2122s\n",
      "\titers: 800, epoch: 3 | loss: 0.1461832\n",
      "\tspeed: 0.0975s/iter; left time: 656.0179s\n",
      "\titers: 900, epoch: 3 | loss: 0.1757724\n",
      "\tspeed: 0.0975s/iter; left time: 646.6506s\n",
      "Epoch: 3 running time: 1.5335398634274802 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1551666 Vali Loss: 0.1509909 Test Loss: 0.2212254\n",
      "Validation loss decreased (0.162373 --> 0.150991).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1292468\n",
      "\tspeed: 0.2858s/iter; left time: 1854.2312s\n",
      "\titers: 200, epoch: 4 | loss: 0.1385312\n",
      "\tspeed: 0.0979s/iter; left time: 625.6877s\n",
      "\titers: 300, epoch: 4 | loss: 0.1528608\n",
      "\tspeed: 0.0977s/iter; left time: 614.1243s\n",
      "\titers: 400, epoch: 4 | loss: 0.1385029\n",
      "\tspeed: 0.0976s/iter; left time: 603.7465s\n",
      "\titers: 500, epoch: 4 | loss: 0.1575158\n",
      "\tspeed: 0.0976s/iter; left time: 594.1274s\n",
      "\titers: 600, epoch: 4 | loss: 0.1237735\n",
      "\tspeed: 0.0977s/iter; left time: 585.1954s\n",
      "\titers: 700, epoch: 4 | loss: 0.1452523\n",
      "\tspeed: 0.0978s/iter; left time: 575.6677s\n",
      "\titers: 800, epoch: 4 | loss: 0.1854530\n",
      "\tspeed: 0.0977s/iter; left time: 565.4985s\n",
      "\titers: 900, epoch: 4 | loss: 0.1564882\n",
      "\tspeed: 0.0976s/iter; left time: 555.1507s\n",
      "Epoch: 4 running time: 1.5377938310305277 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1399588 Vali Loss: 0.1468418 Test Loss: 0.2187929\n",
      "Validation loss decreased (0.150991 --> 0.146842).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1530052\n",
      "\tspeed: 0.2846s/iter; left time: 1578.4834s\n",
      "\titers: 200, epoch: 5 | loss: 0.1308514\n",
      "\tspeed: 0.0972s/iter; left time: 529.5762s\n",
      "\titers: 300, epoch: 5 | loss: 0.1466258\n",
      "\tspeed: 0.0973s/iter; left time: 520.4438s\n",
      "\titers: 400, epoch: 5 | loss: 0.1345804\n",
      "\tspeed: 0.0975s/iter; left time: 511.4472s\n",
      "\titers: 500, epoch: 5 | loss: 0.1079054\n",
      "\tspeed: 0.0974s/iter; left time: 501.4257s\n",
      "\titers: 600, epoch: 5 | loss: 0.1301066\n",
      "\tspeed: 0.0973s/iter; left time: 491.1329s\n",
      "\titers: 700, epoch: 5 | loss: 0.1477804\n",
      "\tspeed: 0.0972s/iter; left time: 481.0689s\n",
      "\titers: 800, epoch: 5 | loss: 0.1133912\n",
      "\tspeed: 0.0976s/iter; left time: 472.8656s\n",
      "\titers: 900, epoch: 5 | loss: 0.1090341\n",
      "\tspeed: 0.0977s/iter; left time: 463.8174s\n",
      "Epoch: 5 running time: 1.5345877250035604 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1297619 Vali Loss: 0.1458476 Test Loss: 0.2184652\n",
      "Validation loss decreased (0.146842 --> 0.145848).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1200157\n",
      "\tspeed: 0.2862s/iter; left time: 1318.1616s\n",
      "\titers: 200, epoch: 6 | loss: 0.1132532\n",
      "\tspeed: 0.0979s/iter; left time: 441.1880s\n",
      "\titers: 300, epoch: 6 | loss: 0.1247416\n",
      "\tspeed: 0.0975s/iter; left time: 429.7224s\n",
      "\titers: 400, epoch: 6 | loss: 0.1308755\n",
      "\tspeed: 0.0974s/iter; left time: 419.2142s\n",
      "\titers: 500, epoch: 6 | loss: 0.1172737\n",
      "\tspeed: 0.0976s/iter; left time: 410.4727s\n",
      "\titers: 600, epoch: 6 | loss: 0.1246800\n",
      "\tspeed: 0.0973s/iter; left time: 399.3930s\n",
      "\titers: 700, epoch: 6 | loss: 0.1159766\n",
      "\tspeed: 0.0976s/iter; left time: 390.8258s\n",
      "\titers: 800, epoch: 6 | loss: 0.1150436\n",
      "\tspeed: 0.0980s/iter; left time: 382.7629s\n",
      "\titers: 900, epoch: 6 | loss: 0.1527046\n",
      "\tspeed: 0.0977s/iter; left time: 371.9833s\n",
      "Epoch: 6 running time: 1.537830646832784 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1229240 Vali Loss: 0.1457663 Test Loss: 0.2212498\n",
      "Validation loss decreased (0.145848 --> 0.145766).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1354768\n",
      "\tspeed: 0.2848s/iter; left time: 1043.8545s\n",
      "\titers: 200, epoch: 7 | loss: 0.1053292\n",
      "\tspeed: 0.0971s/iter; left time: 346.3194s\n",
      "\titers: 300, epoch: 7 | loss: 0.1470087\n",
      "\tspeed: 0.0975s/iter; left time: 337.7739s\n",
      "\titers: 400, epoch: 7 | loss: 0.1179281\n",
      "\tspeed: 0.0974s/iter; left time: 327.8276s\n",
      "\titers: 500, epoch: 7 | loss: 0.1284748\n",
      "\tspeed: 0.0976s/iter; left time: 318.7656s\n",
      "\titers: 600, epoch: 7 | loss: 0.0976006\n",
      "\tspeed: 0.0974s/iter; left time: 308.2349s\n",
      "\titers: 700, epoch: 7 | loss: 0.1113579\n",
      "\tspeed: 0.0973s/iter; left time: 298.0942s\n",
      "\titers: 800, epoch: 7 | loss: 0.1444205\n",
      "\tspeed: 0.0976s/iter; left time: 289.2410s\n",
      "\titers: 900, epoch: 7 | loss: 0.1121703\n",
      "\tspeed: 0.0977s/iter; left time: 279.9088s\n",
      "Epoch: 7 running time: 1.5341106096903483 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1188808 Vali Loss: 0.1469098 Test Loss: 0.2276276\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1236797\n",
      "\tspeed: 0.2797s/iter; left time: 761.8005s\n",
      "\titers: 200, epoch: 8 | loss: 0.1208407\n",
      "\tspeed: 0.0977s/iter; left time: 256.3200s\n",
      "\titers: 300, epoch: 8 | loss: 0.0918566\n",
      "\tspeed: 0.0976s/iter; left time: 246.2813s\n",
      "\titers: 400, epoch: 8 | loss: 0.1157172\n",
      "\tspeed: 0.0975s/iter; left time: 236.3369s\n",
      "\titers: 500, epoch: 8 | loss: 0.1351758\n",
      "\tspeed: 0.0973s/iter; left time: 226.0756s\n",
      "\titers: 600, epoch: 8 | loss: 0.1347238\n",
      "\tspeed: 0.0976s/iter; left time: 216.9753s\n",
      "\titers: 700, epoch: 8 | loss: 0.1363690\n",
      "\tspeed: 0.0973s/iter; left time: 206.6648s\n",
      "\titers: 800, epoch: 8 | loss: 0.1204014\n",
      "\tspeed: 0.0973s/iter; left time: 196.8978s\n",
      "\titers: 900, epoch: 8 | loss: 0.1477749\n",
      "\tspeed: 0.0973s/iter; left time: 187.2952s\n",
      "Epoch: 8 running time: 1.5349057833353679 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1187568 Vali Loss: 0.1480086 Test Loss: 0.2246380\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1125018\n",
      "\tspeed: 0.2789s/iter; left time: 497.2608s\n",
      "\titers: 200, epoch: 9 | loss: 0.1158750\n",
      "\tspeed: 0.0973s/iter; left time: 163.8118s\n",
      "\titers: 300, epoch: 9 | loss: 0.0744595\n",
      "\tspeed: 0.0971s/iter; left time: 153.6721s\n",
      "\titers: 400, epoch: 9 | loss: 0.1645487\n",
      "\tspeed: 0.0971s/iter; left time: 144.0459s\n",
      "\titers: 500, epoch: 9 | loss: 0.1351148\n",
      "\tspeed: 0.0972s/iter; left time: 134.4204s\n",
      "\titers: 600, epoch: 9 | loss: 0.1294514\n",
      "\tspeed: 0.0974s/iter; left time: 124.9993s\n",
      "\titers: 700, epoch: 9 | loss: 0.1100625\n",
      "\tspeed: 0.0978s/iter; left time: 115.7038s\n",
      "\titers: 800, epoch: 9 | loss: 0.0923413\n",
      "\tspeed: 0.0973s/iter; left time: 105.4079s\n",
      "\titers: 900, epoch: 9 | loss: 0.1044033\n",
      "\tspeed: 0.0976s/iter; left time: 95.9670s\n",
      "Epoch: 9 running time: 1.5329768737157186 min.\n",
      "Epoch: 9, Steps: 941 | Train Loss: 0.1184515 Vali Loss: 0.1479403 Test Loss: 0.2238555\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.22542472183704376, mae:0.28379637002944946\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30121\n",
      "val 4321\n",
      "test 8617\n",
      "\titers: 100, epoch: 1 | loss: 0.5664268\n",
      "\tspeed: 0.1015s/iter; left time: 945.3234s\n",
      "\titers: 200, epoch: 1 | loss: 0.2526940\n",
      "\tspeed: 0.0982s/iter; left time: 904.5285s\n",
      "\titers: 300, epoch: 1 | loss: 0.2292914\n",
      "\tspeed: 0.0979s/iter; left time: 892.0578s\n",
      "\titers: 400, epoch: 1 | loss: 0.2790347\n",
      "\tspeed: 0.0977s/iter; left time: 880.2624s\n",
      "\titers: 500, epoch: 1 | loss: 0.2430350\n",
      "\tspeed: 0.0978s/iter; left time: 871.8664s\n",
      "\titers: 600, epoch: 1 | loss: 0.1929865\n",
      "\tspeed: 0.0979s/iter; left time: 862.9822s\n",
      "\titers: 700, epoch: 1 | loss: 0.2642112\n",
      "\tspeed: 0.0978s/iter; left time: 851.8589s\n",
      "\titers: 800, epoch: 1 | loss: 0.2145494\n",
      "\tspeed: 0.0988s/iter; left time: 850.7168s\n",
      "\titers: 900, epoch: 1 | loss: 0.2589278\n",
      "\tspeed: 0.0979s/iter; left time: 833.5124s\n",
      "Epoch: 1 running time: 1.54476105372111 min.\n",
      "Epoch: 1, Steps: 941 | Train Loss: 0.2910090 Vali Loss: 0.1831906 Test Loss: 0.2378062\n",
      "Validation loss decreased (inf --> 0.183191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1635738\n",
      "\tspeed: 0.2865s/iter; left time: 2397.9939s\n",
      "\titers: 200, epoch: 2 | loss: 0.1695694\n",
      "\tspeed: 0.0980s/iter; left time: 810.1318s\n",
      "\titers: 300, epoch: 2 | loss: 0.2019649\n",
      "\tspeed: 0.0977s/iter; left time: 798.4613s\n",
      "\titers: 400, epoch: 2 | loss: 0.1792056\n",
      "\tspeed: 0.0976s/iter; left time: 787.4753s\n",
      "\titers: 500, epoch: 2 | loss: 0.1652687\n",
      "\tspeed: 0.0977s/iter; left time: 778.5259s\n",
      "\titers: 600, epoch: 2 | loss: 0.2338050\n",
      "\tspeed: 0.0977s/iter; left time: 768.5250s\n",
      "\titers: 700, epoch: 2 | loss: 0.1457106\n",
      "\tspeed: 0.0978s/iter; left time: 760.1506s\n",
      "\titers: 800, epoch: 2 | loss: 0.2114065\n",
      "\tspeed: 0.0978s/iter; left time: 750.1098s\n",
      "\titers: 900, epoch: 2 | loss: 0.1232173\n",
      "\tspeed: 0.0976s/iter; left time: 738.8120s\n",
      "Epoch: 2 running time: 1.53813587029775 min.\n",
      "Epoch: 2, Steps: 941 | Train Loss: 0.1803521 Vali Loss: 0.1595277 Test Loss: 0.2245688\n",
      "Validation loss decreased (0.183191 --> 0.159528).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1655260\n",
      "\tspeed: 0.2837s/iter; left time: 2107.4144s\n",
      "\titers: 200, epoch: 3 | loss: 0.1260740\n",
      "\tspeed: 0.0977s/iter; left time: 715.9353s\n",
      "\titers: 300, epoch: 3 | loss: 0.1393616\n",
      "\tspeed: 0.0975s/iter; left time: 705.0829s\n",
      "\titers: 400, epoch: 3 | loss: 0.2075959\n",
      "\tspeed: 0.0978s/iter; left time: 697.2631s\n",
      "\titers: 500, epoch: 3 | loss: 0.1714134\n",
      "\tspeed: 0.0975s/iter; left time: 685.3577s\n",
      "\titers: 600, epoch: 3 | loss: 0.1982437\n",
      "\tspeed: 0.0977s/iter; left time: 676.8993s\n",
      "\titers: 700, epoch: 3 | loss: 0.1601679\n",
      "\tspeed: 0.0976s/iter; left time: 666.7277s\n",
      "\titers: 800, epoch: 3 | loss: 0.1601529\n",
      "\tspeed: 0.0981s/iter; left time: 659.8929s\n",
      "\titers: 900, epoch: 3 | loss: 0.1533434\n",
      "\tspeed: 0.0979s/iter; left time: 648.9327s\n",
      "Epoch: 3 running time: 1.5359195987383525 min.\n",
      "Epoch: 3, Steps: 941 | Train Loss: 0.1536249 Vali Loss: 0.1533358 Test Loss: 0.2164915\n",
      "Validation loss decreased (0.159528 --> 0.153336).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1581352\n",
      "\tspeed: 0.2850s/iter; left time: 1849.0780s\n",
      "\titers: 200, epoch: 4 | loss: 0.1934823\n",
      "\tspeed: 0.0979s/iter; left time: 625.3818s\n",
      "\titers: 300, epoch: 4 | loss: 0.1746560\n",
      "\tspeed: 0.0977s/iter; left time: 614.4730s\n",
      "\titers: 400, epoch: 4 | loss: 0.1177440\n",
      "\tspeed: 0.0978s/iter; left time: 605.3739s\n",
      "\titers: 500, epoch: 4 | loss: 0.1525689\n",
      "\tspeed: 0.0979s/iter; left time: 595.9054s\n",
      "\titers: 600, epoch: 4 | loss: 0.1305330\n",
      "\tspeed: 0.0981s/iter; left time: 587.4081s\n",
      "\titers: 700, epoch: 4 | loss: 0.1843030\n",
      "\tspeed: 0.0990s/iter; left time: 583.0748s\n",
      "\titers: 800, epoch: 4 | loss: 0.0997227\n",
      "\tspeed: 0.0983s/iter; left time: 569.1900s\n",
      "\titers: 900, epoch: 4 | loss: 0.1070071\n",
      "\tspeed: 0.0976s/iter; left time: 555.1758s\n",
      "Epoch: 4 running time: 1.542645013332367 min.\n",
      "Epoch: 4, Steps: 941 | Train Loss: 0.1371581 Vali Loss: 0.1579345 Test Loss: 0.2233839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2039691\n",
      "\tspeed: 0.2791s/iter; left time: 1548.3095s\n",
      "\titers: 200, epoch: 5 | loss: 0.1556967\n",
      "\tspeed: 0.0974s/iter; left time: 530.3643s\n",
      "\titers: 300, epoch: 5 | loss: 0.0973489\n",
      "\tspeed: 0.0979s/iter; left time: 523.2324s\n",
      "\titers: 400, epoch: 5 | loss: 0.1531475\n",
      "\tspeed: 0.0978s/iter; left time: 513.4027s\n",
      "\titers: 500, epoch: 5 | loss: 0.1251926\n",
      "\tspeed: 0.0978s/iter; left time: 503.6290s\n",
      "\titers: 600, epoch: 5 | loss: 0.1437106\n",
      "\tspeed: 0.0979s/iter; left time: 493.9730s\n",
      "\titers: 700, epoch: 5 | loss: 0.1226156\n",
      "\tspeed: 0.0982s/iter; left time: 485.8401s\n",
      "\titers: 800, epoch: 5 | loss: 0.1796097\n",
      "\tspeed: 0.0983s/iter; left time: 476.2434s\n",
      "\titers: 900, epoch: 5 | loss: 0.1031976\n",
      "\tspeed: 0.0982s/iter; left time: 466.3618s\n",
      "Epoch: 5 running time: 1.5422874291737874 min.\n",
      "Epoch: 5, Steps: 941 | Train Loss: 0.1345451 Vali Loss: 0.1518466 Test Loss: 0.2202574\n",
      "Validation loss decreased (0.153336 --> 0.151847).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1445282\n",
      "\tspeed: 0.2845s/iter; left time: 1310.2221s\n",
      "\titers: 200, epoch: 6 | loss: 0.1143389\n",
      "\tspeed: 0.0977s/iter; left time: 440.1757s\n",
      "\titers: 300, epoch: 6 | loss: 0.1190768\n",
      "\tspeed: 0.0976s/iter; left time: 430.0741s\n",
      "\titers: 400, epoch: 6 | loss: 0.1352780\n",
      "\tspeed: 0.0976s/iter; left time: 420.4648s\n",
      "\titers: 500, epoch: 6 | loss: 0.1314371\n",
      "\tspeed: 0.0987s/iter; left time: 415.2133s\n",
      "\titers: 600, epoch: 6 | loss: 0.1066968\n",
      "\tspeed: 0.0980s/iter; left time: 402.2130s\n",
      "\titers: 700, epoch: 6 | loss: 0.1378544\n",
      "\tspeed: 0.0980s/iter; left time: 392.4402s\n",
      "\titers: 800, epoch: 6 | loss: 0.0896610\n",
      "\tspeed: 0.0980s/iter; left time: 382.8143s\n",
      "\titers: 900, epoch: 6 | loss: 0.1284886\n",
      "\tspeed: 0.0978s/iter; left time: 372.4146s\n",
      "Epoch: 6 running time: 1.542008380095164 min.\n",
      "Epoch: 6, Steps: 941 | Train Loss: 0.1270434 Vali Loss: 0.1534718 Test Loss: 0.2216068\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1149424\n",
      "\tspeed: 0.2793s/iter; left time: 1023.6423s\n",
      "\titers: 200, epoch: 7 | loss: 0.1310254\n",
      "\tspeed: 0.0971s/iter; left time: 346.2150s\n",
      "\titers: 300, epoch: 7 | loss: 0.1674199\n",
      "\tspeed: 0.0974s/iter; left time: 337.3509s\n",
      "\titers: 400, epoch: 7 | loss: 0.1332274\n",
      "\tspeed: 0.0974s/iter; left time: 327.8453s\n",
      "\titers: 500, epoch: 7 | loss: 0.0768914\n",
      "\tspeed: 0.0974s/iter; left time: 317.9397s\n",
      "\titers: 600, epoch: 7 | loss: 0.1472603\n",
      "\tspeed: 0.0971s/iter; left time: 307.4626s\n",
      "\titers: 700, epoch: 7 | loss: 0.1242801\n",
      "\tspeed: 0.0971s/iter; left time: 297.7126s\n",
      "\titers: 800, epoch: 7 | loss: 0.1110313\n",
      "\tspeed: 0.0971s/iter; left time: 287.8902s\n",
      "\titers: 900, epoch: 7 | loss: 0.1239939\n",
      "\tspeed: 0.0971s/iter; left time: 278.0831s\n",
      "Epoch: 7 running time: 1.5312985539436341 min.\n",
      "Epoch: 7, Steps: 941 | Train Loss: 0.1262259 Vali Loss: 0.1533842 Test Loss: 0.2228643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1185199\n",
      "\tspeed: 0.2770s/iter; left time: 754.5685s\n",
      "\titers: 200, epoch: 8 | loss: 0.1375734\n",
      "\tspeed: 0.0974s/iter; left time: 255.5432s\n",
      "\titers: 300, epoch: 8 | loss: 0.1466773\n",
      "\tspeed: 0.0973s/iter; left time: 245.7113s\n",
      "\titers: 400, epoch: 8 | loss: 0.1268446\n",
      "\tspeed: 0.0973s/iter; left time: 235.9252s\n",
      "\titers: 500, epoch: 8 | loss: 0.1191575\n",
      "\tspeed: 0.0974s/iter; left time: 226.2573s\n",
      "\titers: 600, epoch: 8 | loss: 0.1166207\n",
      "\tspeed: 0.0973s/iter; left time: 216.3031s\n",
      "\titers: 700, epoch: 8 | loss: 0.1127195\n",
      "\tspeed: 0.0975s/iter; left time: 207.0986s\n",
      "\titers: 800, epoch: 8 | loss: 0.1257366\n",
      "\tspeed: 0.0974s/iter; left time: 197.2305s\n",
      "\titers: 900, epoch: 8 | loss: 0.1132852\n",
      "\tspeed: 0.0976s/iter; left time: 187.7518s\n",
      "Epoch: 8 running time: 1.5325612545013427 min.\n",
      "Epoch: 8, Steps: 941 | Train Loss: 0.1262816 Vali Loss: 0.1506053 Test Loss: 0.2187933\n",
      "Validation loss decreased (0.151847 --> 0.150605).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1213355\n",
      "\tspeed: 0.2844s/iter; left time: 507.1089s\n",
      "\titers: 200, epoch: 9 | loss: 0.1153753\n",
      "\tspeed: 0.0977s/iter; left time: 164.4755s\n",
      "\titers: 300, epoch: 9 | loss: 0.1769007\n",
      "\tspeed: 0.0976s/iter; left time: 154.5795s\n",
      "\titers: 400, epoch: 9 | loss: 0.0931088\n",
      "\tspeed: 0.0972s/iter; left time: 144.2051s\n",
      "\titers: 500, epoch: 9 | loss: 0.1505617\n",
      "\tspeed: 0.0975s/iter; left time: 134.8129s\n",
      "\titers: 600, epoch: 9 | loss: 0.0891185\n",
      "\tspeed: 0.0975s/iter; left time: 125.0980s\n",
      "\titers: 700, epoch: 9 | loss: 0.1516637\n",
      "\tspeed: 0.0977s/iter; left time: 115.5484s\n",
      "\titers: 800, epoch: 9 | loss: 0.1149239\n",
      "\tspeed: 0.0976s/iter; left time: 105.6957s\n",
      "\titers: 900, epoch: 9 | loss: 0.1068046\n",
      "\tspeed: 0.0977s/iter; left time: 96.0086s\n",
      "Epoch: 9 running time: 1.5352671146392822 min.\n",
      "Epoch: 9, Steps: 941 | Train Loss: 0.1247482 Vali Loss: 0.1516108 Test Loss: 0.2206672\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1710355\n",
      "\tspeed: 0.2782s/iter; left time: 234.2491s\n",
      "\titers: 200, epoch: 10 | loss: 0.0977202\n",
      "\tspeed: 0.0977s/iter; left time: 72.5232s\n",
      "\titers: 300, epoch: 10 | loss: 0.1131416\n",
      "\tspeed: 0.0978s/iter; left time: 62.7592s\n",
      "\titers: 400, epoch: 10 | loss: 0.0992893\n",
      "\tspeed: 0.0978s/iter; left time: 52.9885s\n",
      "\titers: 500, epoch: 10 | loss: 0.1500777\n",
      "\tspeed: 0.0976s/iter; left time: 43.1232s\n",
      "\titers: 600, epoch: 10 | loss: 0.1034379\n",
      "\tspeed: 0.0977s/iter; left time: 33.4155s\n",
      "\titers: 700, epoch: 10 | loss: 0.1288431\n",
      "\tspeed: 0.0977s/iter; left time: 23.6381s\n",
      "\titers: 800, epoch: 10 | loss: 0.0905820\n",
      "\tspeed: 0.0976s/iter; left time: 13.8616s\n",
      "\titers: 900, epoch: 10 | loss: 0.1386539\n",
      "\tspeed: 0.0976s/iter; left time: 4.1007s\n",
      "Epoch: 10 running time: 1.5367359081904093 min.\n",
      "Epoch: 10, Steps: 941 | Train Loss: 0.1242712 Vali Loss: 0.1508001 Test Loss: 0.2190831\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8617\n",
      "test shape: (269, 32, 24, 3) (269, 32, 24, 3)\n",
      "test shape: (8608, 24, 3) (8608, 24, 3)\n",
      "mse:0.21892176568508148, mae:0.2853127717971802\n",
      "\n",
      "Time intermediate for IT dataset: 34.16802665392558 min.\n",
      "Total time: 140.47173579136532 min.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "datasets = ['DE_data.csv', 'GB_data.csv', 'ES_data.csv', 'FR_data.csv', 'IT_data.csv']\n",
    "num_cols = [\"5\", \"5\", \"3\", \"3\", \"3\"]\n",
    "pred_len = \"24\"\n",
    "model = \"Informer\"\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    model_id = f\"_{pred_len}_{dataset[:2]}\"  # Create the model_id\n",
    "    model_arguments = [\n",
    "                \"--task_name\", \"long_term_forecast\",\n",
    "                \"--is_training\", \"1\", #True\n",
    "                \"--root_path\", current_path,\n",
    "                \"--data_path\", dataset,\n",
    "                # \"--train_epochs\", \"1\",\n",
    "                \"--model_id\", model_id,\n",
    "                \"--model\", model,\n",
    "                \"--data\", \"custom\", # Use a custom dataloader (same data preparation as in ARIMA)\n",
    "                \"--features\", \"M\", # Multivariate\n",
    "                \"--seq_len\", \"96\",\n",
    "                \"--label_len\", \"48\",\n",
    "                \"--pred_len\", pred_len,\n",
    "                \"--e_layers\", \"2\", \n",
    "                \"--d_layers\", \"5\",\n",
    "                \"--factor\", \"5\",\n",
    "                \"--enc_in\", num_cols[i], \n",
    "                \"--dec_in\", num_cols[i], \n",
    "                \"--c_out\", num_cols[i],\n",
    "                \"--des\", \"Exp\",\n",
    "                \"--itr\", \"2\",\n",
    "            ]\n",
    "\n",
    "    int_start = time.time()\n",
    "\n",
    "    model_output = run_output(path_to_run_file, model_arguments)\n",
    "\n",
    "    #folder_path = f'/content/drive/MyDrive/Masterarbeit/results/{model}/'\n",
    "    folder_path = f'/vol/cs-hu/riabchuv/hu-home/my_work/results/{model}/'\n",
    "\n",
    "    # Write model output into txt file\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    result_file_path = os.path.join(folder_path, 'stored_model_output.txt')\n",
    "    with open(result_file_path, 'a') as f:\n",
    "\n",
    "        f.write(model_output + \"  \\n\")\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "    int_end = time.time()\n",
    "    print(model_output)\n",
    "    print(f\"Time intermediate for {dataset[:2]} dataset:\", (int_end - int_start)/60, \"min.\")\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp='GB_data_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/vol/cs-hu/riabchuv/hu-home/my_work/datasets/GB_data_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/vol/cs-hu/riabchuv/hu-home/my_work/datasets/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GB_UKM_load_actual_entsoe_transparency</th>\n",
       "      <th>GB_UKM_solar_generation_actual</th>\n",
       "      <th>GB_UKM_wind_generation_actual</th>\n",
       "      <th>GB_UKM_wind_offshore_generation_actual</th>\n",
       "      <th>GB_UKM_wind_onshore_generation_actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-26 00:00:00</th>\n",
       "      <td>30680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5348.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>3463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-26 01:00:00</th>\n",
       "      <td>29218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5194.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-26 02:00:00</th>\n",
       "      <td>28016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>2633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-26 03:00:00</th>\n",
       "      <td>27402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>3417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-26 04:00:00</th>\n",
       "      <td>27490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5206.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04 19:00:00</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04 20:00:00</th>\n",
       "      <td>46550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04 21:00:00</th>\n",
       "      <td>42752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04 22:00:00</th>\n",
       "      <td>38984.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04 23:00:00</th>\n",
       "      <td>34184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GB_UKM_load_actual_entsoe_transparency  \\\n",
       "date                                                          \n",
       "2015-10-26 00:00:00                                 30680.0   \n",
       "2015-10-26 01:00:00                                 29218.0   \n",
       "2015-10-26 02:00:00                                 28016.0   \n",
       "2015-10-26 03:00:00                                 27402.0   \n",
       "2015-10-26 04:00:00                                 27490.0   \n",
       "...                                                     ...   \n",
       "2015-11-04 19:00:00                                 49595.0   \n",
       "2015-11-04 20:00:00                                 46550.0   \n",
       "2015-11-04 21:00:00                                 42752.0   \n",
       "2015-11-04 22:00:00                                 38984.0   \n",
       "2015-11-04 23:00:00                                 34184.0   \n",
       "\n",
       "                     GB_UKM_solar_generation_actual  \\\n",
       "date                                                  \n",
       "2015-10-26 00:00:00                             0.0   \n",
       "2015-10-26 01:00:00                             0.0   \n",
       "2015-10-26 02:00:00                             0.0   \n",
       "2015-10-26 03:00:00                             0.0   \n",
       "2015-10-26 04:00:00                             0.0   \n",
       "...                                             ...   \n",
       "2015-11-04 19:00:00                             0.0   \n",
       "2015-11-04 20:00:00                             0.0   \n",
       "2015-11-04 21:00:00                             0.0   \n",
       "2015-11-04 22:00:00                             0.0   \n",
       "2015-11-04 23:00:00                             0.0   \n",
       "\n",
       "                     GB_UKM_wind_generation_actual  \\\n",
       "date                                                 \n",
       "2015-10-26 00:00:00                         5348.0   \n",
       "2015-10-26 01:00:00                         5194.0   \n",
       "2015-10-26 02:00:00                         4389.0   \n",
       "2015-10-26 03:00:00                         5104.0   \n",
       "2015-10-26 04:00:00                         5206.0   \n",
       "...                                            ...   \n",
       "2015-11-04 19:00:00                         1012.0   \n",
       "2015-11-04 20:00:00                         1246.0   \n",
       "2015-11-04 21:00:00                         1441.0   \n",
       "2015-11-04 22:00:00                         1430.0   \n",
       "2015-11-04 23:00:00                         1400.0   \n",
       "\n",
       "                     GB_UKM_wind_offshore_generation_actual  \\\n",
       "date                                                          \n",
       "2015-10-26 00:00:00                                  1885.0   \n",
       "2015-10-26 01:00:00                                  1810.0   \n",
       "2015-10-26 02:00:00                                  1756.0   \n",
       "2015-10-26 03:00:00                                  1687.0   \n",
       "2015-10-26 04:00:00                                  1749.0   \n",
       "...                                                     ...   \n",
       "2015-11-04 19:00:00                                   584.0   \n",
       "2015-11-04 20:00:00                                   792.0   \n",
       "2015-11-04 21:00:00                                   915.0   \n",
       "2015-11-04 22:00:00                                   912.0   \n",
       "2015-11-04 23:00:00                                   875.0   \n",
       "\n",
       "                     GB_UKM_wind_onshore_generation_actual  \n",
       "date                                                        \n",
       "2015-10-26 00:00:00                                 3463.0  \n",
       "2015-10-26 01:00:00                                 3383.0  \n",
       "2015-10-26 02:00:00                                 2633.0  \n",
       "2015-10-26 03:00:00                                 3417.0  \n",
       "2015-10-26 04:00:00                                 3456.0  \n",
       "...                                                    ...  \n",
       "2015-11-04 19:00:00                                  429.0  \n",
       "2015-11-04 20:00:00                                  455.0  \n",
       "2015-11-04 21:00:00                                  526.0  \n",
       "2015-11-04 22:00:00                                  518.0  \n",
       "2015-11-04 23:00:00                                  525.0  \n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(current_path, dp), index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 149\n",
      "val 15\n",
      "test 39\n",
      "Epoch: 1 running time: 0.039925122261047365 min.\n",
      "Epoch: 1, Steps: 4 | Train Loss: 1.0024538 Vali Loss: nan Test Loss: 1.2172809\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 running time: 0.01469890276590983 min.\n",
      "Epoch: 2, Steps: 4 | Train Loss: 0.6911948 Vali Loss: nan Test Loss: 1.4431949\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 running time: 0.014795935153961182 min.\n",
      "Epoch: 3, Steps: 4 | Train Loss: 0.5788186 Vali Loss: nan Test Loss: 1.0701528\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 running time: 0.015081985791524252 min.\n",
      "Epoch: 4, Steps: 4 | Train Loss: 0.5235551 Vali Loss: nan Test Loss: 0.9722701\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 running time: 0.014554961522420248 min.\n",
      "Epoch: 5, Steps: 4 | Train Loss: 0.5137975 Vali Loss: nan Test Loss: 0.9586014\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 running time: 0.01539984146753947 min.\n",
      "Epoch: 6, Steps: 4 | Train Loss: 0.4784191 Vali Loss: nan Test Loss: 0.9611190\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 running time: 0.013930594921112061 min.\n",
      "Epoch: 7, Steps: 4 | Train Loss: 0.4814504 Vali Loss: nan Test Loss: 1.0199240\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 running time: 0.014625775814056396 min.\n",
      "Epoch: 8, Steps: 4 | Train Loss: 0.4706157 Vali Loss: nan Test Loss: 0.9661508\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 running time: 0.015251608689626057 min.\n",
      "Epoch: 9, Steps: 4 | Train Loss: 0.4747935 Vali Loss: nan Test Loss: 0.9857954\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 running time: 0.014180195331573487 min.\n",
      "Epoch: 10, Steps: 4 | Train Loss: 0.4762641 Vali Loss: nan Test Loss: 1.0232698\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 39\n",
      "test shape: (1, 32, 10, 5) (1, 32, 10, 5)\n",
      "test shape: (32, 10, 5) (32, 10, 5)\n",
      "mse:0.985942542552948, mae:0.7991647124290466\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 149\n",
      "val 15\n",
      "test 39\n",
      "Epoch: 1 running time: 0.014746411641438802 min.\n",
      "Epoch: 1, Steps: 4 | Train Loss: 1.0295902 Vali Loss: nan Test Loss: 1.0363106\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 running time: 0.015388592084248861 min.\n",
      "Epoch: 2, Steps: 4 | Train Loss: 0.6777777 Vali Loss: nan Test Loss: 1.3939192\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 running time: 0.014550344149271647 min.\n",
      "Epoch: 3, Steps: 4 | Train Loss: 0.5698880 Vali Loss: nan Test Loss: 0.9854409\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 running time: 0.014660712083180745 min.\n",
      "Epoch: 4, Steps: 4 | Train Loss: 0.5290706 Vali Loss: nan Test Loss: 0.8179453\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 running time: 0.015316299597422282 min.\n",
      "Epoch: 5, Steps: 4 | Train Loss: 0.4899310 Vali Loss: nan Test Loss: 0.8191302\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 running time: 0.014206993579864501 min.\n",
      "Epoch: 6, Steps: 4 | Train Loss: 0.4454456 Vali Loss: nan Test Loss: 0.8206318\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 running time: 0.014676713943481445 min.\n",
      "Epoch: 7, Steps: 4 | Train Loss: 0.4726178 Vali Loss: nan Test Loss: 0.8455051\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 running time: 0.014798065026601156 min.\n",
      "Epoch: 8, Steps: 4 | Train Loss: 0.4536124 Vali Loss: nan Test Loss: 0.8689371\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 running time: 0.014613501230875651 min.\n",
      "Epoch: 9, Steps: 4 | Train Loss: 0.4576709 Vali Loss: nan Test Loss: 0.9006981\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 running time: 0.014256656169891357 min.\n",
      "Epoch: 10, Steps: 4 | Train Loss: 0.4339121 Vali Loss: nan Test Loss: 0.8823724\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 39\n",
      "test shape: (1, 32, 10, 5) (1, 32, 10, 5)\n",
      "test shape: (32, 10, 5) (32, 10, 5)\n",
      "mse:0.8921732306480408, mae:0.7604851722717285\n",
      "\n",
      "Time intermediate for GB dataset: 0.9230153759320577 min.\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 149\n",
      "val 15\n",
      "test 39\n",
      "Epoch: 1 running time: 0.0379722277323405 min.\n",
      "Epoch: 1, Steps: 4 | Train Loss: 1.0133409 Vali Loss: nan Test Loss: 1.1593016\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 running time: 0.014988048871358236 min.\n",
      "Epoch: 2, Steps: 4 | Train Loss: 0.6685318 Vali Loss: nan Test Loss: 1.5033898\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 running time: 0.015134803454081218 min.\n",
      "Epoch: 3, Steps: 4 | Train Loss: 0.5853137 Vali Loss: nan Test Loss: 1.0170285\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 running time: 0.015229304631551107 min.\n",
      "Epoch: 4, Steps: 4 | Train Loss: 0.5230797 Vali Loss: nan Test Loss: 0.9165366\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 running time: 0.01482845942179362 min.\n",
      "Epoch: 5, Steps: 4 | Train Loss: 0.5061147 Vali Loss: nan Test Loss: 0.9382831\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 running time: 0.014434333642323811 min.\n",
      "Epoch: 6, Steps: 4 | Train Loss: 0.4742088 Vali Loss: nan Test Loss: 0.9203134\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 running time: 0.014867182572682698 min.\n",
      "Epoch: 7, Steps: 4 | Train Loss: 0.4816395 Vali Loss: nan Test Loss: 0.9207461\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 running time: 0.014206230640411377 min.\n",
      "Epoch: 8, Steps: 4 | Train Loss: 0.4701661 Vali Loss: nan Test Loss: 0.9398845\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 running time: 0.014715186754862468 min.\n",
      "Epoch: 9, Steps: 4 | Train Loss: 0.4746773 Vali Loss: nan Test Loss: 0.9466402\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 running time: 0.014221092065175375 min.\n",
      "Epoch: 10, Steps: 4 | Train Loss: 0.4755139 Vali Loss: nan Test Loss: 0.9503284\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 39\n",
      "test shape: (1, 32, 10, 5) (1, 32, 10, 5)\n",
      "test shape: (32, 10, 5) (32, 10, 5)\n",
      "mse:0.9485630989074707, mae:0.7849948406219482\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 149\n",
      "val 15\n",
      "test 39\n",
      "Epoch: 1 running time: 0.014317051569620768 min.\n",
      "Epoch: 1, Steps: 4 | Train Loss: 1.0192896 Vali Loss: nan Test Loss: 1.0006683\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 running time: 0.016005825996398926 min.\n",
      "Epoch: 2, Steps: 4 | Train Loss: 0.6856293 Vali Loss: nan Test Loss: 1.3917358\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 running time: 0.015333712100982666 min.\n",
      "Epoch: 3, Steps: 4 | Train Loss: 0.5695837 Vali Loss: nan Test Loss: 1.0196233\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 running time: 0.014633981386820476 min.\n",
      "Epoch: 4, Steps: 4 | Train Loss: 0.5196934 Vali Loss: nan Test Loss: 0.8472352\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 running time: 0.015336012840270996 min.\n",
      "Epoch: 5, Steps: 4 | Train Loss: 0.4939889 Vali Loss: nan Test Loss: 0.8318195\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 running time: 0.01478735605875651 min.\n",
      "Epoch: 6, Steps: 4 | Train Loss: 0.4583812 Vali Loss: nan Test Loss: 0.8314679\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 running time: 0.01449210246404012 min.\n",
      "Epoch: 7, Steps: 4 | Train Loss: 0.4641255 Vali Loss: nan Test Loss: 0.8144280\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 running time: 0.014517529805501302 min.\n",
      "Epoch: 8, Steps: 4 | Train Loss: 0.4530064 Vali Loss: nan Test Loss: 0.8637968\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 running time: 0.014745950698852539 min.\n",
      "Epoch: 9, Steps: 4 | Train Loss: 0.4684971 Vali Loss: nan Test Loss: 0.8901826\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 running time: 0.015699354807535808 min.\n",
      "Epoch: 10, Steps: 4 | Train Loss: 0.4408530 Vali Loss: nan Test Loss: 0.9042748\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__10_GB_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 39\n",
      "test shape: (1, 32, 10, 5) (1, 32, 10, 5)\n",
      "test shape: (32, 10, 5) (32, 10, 5)\n",
      "mse:0.944560706615448, mae:0.7830029129981995\n",
      "\n",
      "Time intermediate for GB dataset: 0.935037616888682 min.\n",
      "Total time: 1.8580724199612935 min.\n"
     ]
    }
   ],
   "source": [
    "# 5.413828869660695 min. without test\n",
    "# 6.30 min with test\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "current_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "datasets = ['GB_data_small.csv', 'GB_data_small.csv']\n",
    "num_cols = [\"5\", \"5\"]\n",
    "pred_len = \"10\"\n",
    "model = \"Informer\"\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    model_id = f\"_{pred_len}_{dataset[:2]}\"  # Create the model_id\n",
    "    model_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\", #True\n",
    "            \"--root_path\", current_path, #\"/content/my_work/datasets/\",\n",
    "            \"--data_path\", dataset,\n",
    "            #\"--train_epochs\", \"1\",\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", model,\n",
    "            \"--data\", \"custom\", # This ensures a 70%,10%,20% train,val,test split see data_provider/data_loader.py\n",
    "            \"--features\", \"M\", # Multivariate\n",
    "            \"--seq_len\", \"10\",\n",
    "            \"--label_len\", \"5\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"3\", # Hyperparameters as in original model\n",
    "            \"--d_layers\", \"2\",\n",
    "            \"--factor\", \"3\",\n",
    "            #\"--gpu\", gpu_index,\n",
    "            # '--use_multi_gpu', \n",
    "            \"--enc_in\", num_cols[i],\n",
    "            \"--dec_in\", num_cols[i],\n",
    "            \"--c_out\", num_cols[i],\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\",\n",
    "        ]\n",
    "    int_start = time.time()\n",
    "    model_output = run_output(path_to_run_file, model_arguments)\n",
    "\n",
    "    # folder_path = f'/content/drive/MyDrive/Masterarbeit/results/{model}/'\n",
    "    folder_path = f'/vol/cs-hu/riabchuv/hu-home/my_work/results/{model}/'\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    result_file_path = os.path.join(folder_path, 'stored_model_output.txt')\n",
    "    with open(result_file_path, 'a') as f:\n",
    "\n",
    "        f.write(model_output + \"  \\n\")\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "    int_end = time.time()\n",
    "    print(model_output)\n",
    "    print(f\"Time intermediate for {dataset[:2]} dataset:\", (int_end - int_start)/60, \"min.\")\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Total time:\", (end - start)/60, \"min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.86847895,   1.1777946 ,   1.0852624 ,   3.2318454 ,\n",
       "       769.5208    ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "np.load(\"/Users/valentyna/Documents/Master_thesis_new/results/long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 10, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds\n",
    "np.load(\"/Users/valentyna/Documents/Master_thesis_new/results/long_term_forecast_1_Informer_custom_ftM_sl10_ll5_pl10_dm512_nh8_el3_dl2_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
