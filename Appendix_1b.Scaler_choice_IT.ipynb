{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax Scaler Informer](#3-minmax-scaler-informer)\n",
    "- [4. MinMax Scaler PatchTST](#4-minmax-scaler-patchtst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on **Italy** dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison_IT\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0540478\n",
      "\tspeed: 0.0982s/iter; left time: 1768.9729s\n",
      "\titers: 200, epoch: 1 | loss: 0.9153090\n",
      "\tspeed: 0.0788s/iter; left time: 1412.6550s\n",
      "\titers: 300, epoch: 1 | loss: 0.8429894\n",
      "\tspeed: 0.0804s/iter; left time: 1433.4085s\n",
      "\titers: 400, epoch: 1 | loss: 0.8058295\n",
      "\tspeed: 0.0852s/iter; left time: 1510.5374s\n",
      "\titers: 500, epoch: 1 | loss: 0.6219770\n",
      "\tspeed: 0.0752s/iter; left time: 1325.5851s\n",
      "\titers: 600, epoch: 1 | loss: 0.6275427\n",
      "\tspeed: 0.0721s/iter; left time: 1262.5673s\n",
      "\titers: 700, epoch: 1 | loss: 0.4450749\n",
      "\tspeed: 0.0778s/iter; left time: 1355.8930s\n",
      "\titers: 800, epoch: 1 | loss: 0.4949049\n",
      "\tspeed: 0.0776s/iter; left time: 1343.8295s\n",
      "\titers: 900, epoch: 1 | loss: 0.5304269\n",
      "\tspeed: 0.0792s/iter; left time: 1363.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:11.69s\n",
      "Steps: 906 | Train Loss: 0.7265440 Vali Loss: 0.4574048 Test Loss: 0.5257113\n",
      "Validation loss decreased (inf --> 0.457405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3764636\n",
      "\tspeed: 0.2613s/iter; left time: 4472.4389s\n",
      "\titers: 200, epoch: 2 | loss: 0.3195201\n",
      "\tspeed: 0.0830s/iter; left time: 1411.3990s\n",
      "\titers: 300, epoch: 2 | loss: 0.2134913\n",
      "\tspeed: 0.0765s/iter; left time: 1293.8124s\n",
      "\titers: 400, epoch: 2 | loss: 0.2357923\n",
      "\tspeed: 0.0788s/iter; left time: 1324.6719s\n",
      "\titers: 500, epoch: 2 | loss: 0.2196806\n",
      "\tspeed: 0.0739s/iter; left time: 1235.9836s\n",
      "\titers: 600, epoch: 2 | loss: 0.3155931\n",
      "\tspeed: 0.0752s/iter; left time: 1248.9617s\n",
      "\titers: 700, epoch: 2 | loss: 0.2434423\n",
      "\tspeed: 0.0842s/iter; left time: 1390.4888s\n",
      "\titers: 800, epoch: 2 | loss: 0.2666329\n",
      "\tspeed: 0.0837s/iter; left time: 1374.6920s\n",
      "\titers: 900, epoch: 2 | loss: 0.2429739\n",
      "\tspeed: 0.0871s/iter; left time: 1420.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:13.97s\n",
      "Steps: 906 | Train Loss: 0.2815159 Vali Loss: 0.2208134 Test Loss: 0.2582075\n",
      "Validation loss decreased (0.457405 --> 0.220813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1852619\n",
      "\tspeed: 0.2777s/iter; left time: 4501.5248s\n",
      "\titers: 200, epoch: 3 | loss: 0.1875897\n",
      "\tspeed: 0.0893s/iter; left time: 1438.4236s\n",
      "\titers: 300, epoch: 3 | loss: 0.2217554\n",
      "\tspeed: 0.0856s/iter; left time: 1370.4591s\n",
      "\titers: 400, epoch: 3 | loss: 0.1683290\n",
      "\tspeed: 0.0797s/iter; left time: 1268.2449s\n",
      "\titers: 500, epoch: 3 | loss: 0.1889182\n",
      "\tspeed: 0.0663s/iter; left time: 1047.8444s\n",
      "\titers: 600, epoch: 3 | loss: 0.2246941\n",
      "\tspeed: 0.0880s/iter; left time: 1382.6069s\n",
      "\titers: 700, epoch: 3 | loss: 0.2290846\n",
      "\tspeed: 0.0903s/iter; left time: 1410.1409s\n",
      "\titers: 800, epoch: 3 | loss: 0.2323068\n",
      "\tspeed: 0.0861s/iter; left time: 1335.1440s\n",
      "\titers: 900, epoch: 3 | loss: 0.1806189\n",
      "\tspeed: 0.0809s/iter; left time: 1246.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:17.28s\n",
      "Steps: 906 | Train Loss: 0.2086492 Vali Loss: 0.2033166 Test Loss: 0.2356976\n",
      "Validation loss decreased (0.220813 --> 0.203317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2145737\n",
      "\tspeed: 0.2635s/iter; left time: 4031.9891s\n",
      "\titers: 200, epoch: 4 | loss: 0.1708093\n",
      "\tspeed: 0.0837s/iter; left time: 1272.8401s\n",
      "\titers: 300, epoch: 4 | loss: 0.1718170\n",
      "\tspeed: 0.0679s/iter; left time: 1026.0821s\n",
      "\titers: 400, epoch: 4 | loss: 0.2295583\n",
      "\tspeed: 0.0602s/iter; left time: 902.9105s\n",
      "\titers: 500, epoch: 4 | loss: 0.1832784\n",
      "\tspeed: 0.0670s/iter; left time: 998.6915s\n",
      "\titers: 600, epoch: 4 | loss: 0.1669848\n",
      "\tspeed: 0.0729s/iter; left time: 1079.5861s\n",
      "\titers: 700, epoch: 4 | loss: 0.1514449\n",
      "\tspeed: 0.0791s/iter; left time: 1163.3184s\n",
      "\titers: 800, epoch: 4 | loss: 0.2148971\n",
      "\tspeed: 0.0827s/iter; left time: 1207.4640s\n",
      "\titers: 900, epoch: 4 | loss: 0.2118274\n",
      "\tspeed: 0.0882s/iter; left time: 1279.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:09.82s\n",
      "Steps: 906 | Train Loss: 0.1889342 Vali Loss: 0.2083600 Test Loss: 0.2344809\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1576099\n",
      "\tspeed: 0.2596s/iter; left time: 3736.9992s\n",
      "\titers: 200, epoch: 5 | loss: 0.2121112\n",
      "\tspeed: 0.0855s/iter; left time: 1221.9868s\n",
      "\titers: 300, epoch: 5 | loss: 0.2169540\n",
      "\tspeed: 0.0719s/iter; left time: 1021.4199s\n",
      "\titers: 400, epoch: 5 | loss: 0.1525394\n",
      "\tspeed: 0.0677s/iter; left time: 954.2083s\n",
      "\titers: 500, epoch: 5 | loss: 0.1820139\n",
      "\tspeed: 0.0597s/iter; left time: 836.0104s\n",
      "\titers: 600, epoch: 5 | loss: 0.1504566\n",
      "\tspeed: 0.0795s/iter; left time: 1105.3340s\n",
      "\titers: 700, epoch: 5 | loss: 0.2446505\n",
      "\tspeed: 0.0794s/iter; left time: 1094.9038s\n",
      "\titers: 800, epoch: 5 | loss: 0.1254637\n",
      "\tspeed: 0.0862s/iter; left time: 1180.9421s\n",
      "\titers: 900, epoch: 5 | loss: 0.1803807\n",
      "\tspeed: 0.0854s/iter; left time: 1161.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:11.64s\n",
      "Steps: 906 | Train Loss: 0.1708312 Vali Loss: 0.1955078 Test Loss: 0.2296074\n",
      "Validation loss decreased (0.203317 --> 0.195508).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1846139\n",
      "\tspeed: 0.2279s/iter; left time: 3073.9781s\n",
      "\titers: 200, epoch: 6 | loss: 0.1722455\n",
      "\tspeed: 0.0805s/iter; left time: 1077.6688s\n",
      "\titers: 300, epoch: 6 | loss: 0.2310300\n",
      "\tspeed: 0.0827s/iter; left time: 1098.9190s\n",
      "\titers: 400, epoch: 6 | loss: 0.1269245\n",
      "\tspeed: 0.0749s/iter; left time: 987.9868s\n",
      "\titers: 500, epoch: 6 | loss: 0.1063417\n",
      "\tspeed: 0.0665s/iter; left time: 871.0522s\n",
      "\titers: 600, epoch: 6 | loss: 0.1812683\n",
      "\tspeed: 0.0672s/iter; left time: 873.2779s\n",
      "\titers: 700, epoch: 6 | loss: 0.1852386\n",
      "\tspeed: 0.0786s/iter; left time: 1012.6636s\n",
      "\titers: 800, epoch: 6 | loss: 0.1476646\n",
      "\tspeed: 0.0729s/iter; left time: 932.4385s\n",
      "\titers: 900, epoch: 6 | loss: 0.1587566\n",
      "\tspeed: 0.0765s/iter; left time: 970.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:09.20s\n",
      "Steps: 906 | Train Loss: 0.1590144 Vali Loss: 0.2043321 Test Loss: 0.2411343\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1352675\n",
      "\tspeed: 0.2343s/iter; left time: 2948.4269s\n",
      "\titers: 200, epoch: 7 | loss: 0.1627438\n",
      "\tspeed: 0.0761s/iter; left time: 950.4799s\n",
      "\titers: 300, epoch: 7 | loss: 0.1156907\n",
      "\tspeed: 0.0804s/iter; left time: 995.3610s\n",
      "\titers: 400, epoch: 7 | loss: 0.1625920\n",
      "\tspeed: 0.0857s/iter; left time: 1053.1148s\n",
      "\titers: 500, epoch: 7 | loss: 0.1321968\n",
      "\tspeed: 0.0757s/iter; left time: 922.7462s\n",
      "\titers: 600, epoch: 7 | loss: 0.1077994\n",
      "\tspeed: 0.0749s/iter; left time: 904.7960s\n",
      "\titers: 700, epoch: 7 | loss: 0.1447192\n",
      "\tspeed: 0.0773s/iter; left time: 926.8377s\n",
      "\titers: 800, epoch: 7 | loss: 0.1756337\n",
      "\tspeed: 0.0838s/iter; left time: 995.5436s\n",
      "\titers: 900, epoch: 7 | loss: 0.1215010\n",
      "\tspeed: 0.0908s/iter; left time: 1069.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:13.40s\n",
      "Steps: 906 | Train Loss: 0.1477633 Vali Loss: 0.2041572 Test Loss: 0.2336134\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1111282\n",
      "\tspeed: 0.2816s/iter; left time: 3289.1157s\n",
      "\titers: 200, epoch: 8 | loss: 0.1068844\n",
      "\tspeed: 0.0912s/iter; left time: 1056.3497s\n",
      "\titers: 300, epoch: 8 | loss: 0.1055387\n",
      "\tspeed: 0.0892s/iter; left time: 1024.0691s\n",
      "\titers: 400, epoch: 8 | loss: 0.1470238\n",
      "\tspeed: 0.0942s/iter; left time: 1072.0751s\n",
      "\titers: 500, epoch: 8 | loss: 0.1490873\n",
      "\tspeed: 0.0888s/iter; left time: 1001.0832s\n",
      "\titers: 600, epoch: 8 | loss: 0.1532466\n",
      "\tspeed: 0.0952s/iter; left time: 1064.6606s\n",
      "\titers: 700, epoch: 8 | loss: 0.1089281\n",
      "\tspeed: 0.0990s/iter; left time: 1096.5851s\n",
      "\titers: 800, epoch: 8 | loss: 0.1422896\n",
      "\tspeed: 0.0893s/iter; left time: 980.2327s\n",
      "\titers: 900, epoch: 8 | loss: 0.1379985\n",
      "\tspeed: 0.0919s/iter; left time: 1000.2935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:24.10s\n",
      "Steps: 906 | Train Loss: 0.1374779 Vali Loss: 0.1994571 Test Loss: 0.2437572\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822107\n",
      "\tspeed: 0.2537s/iter; left time: 2732.9604s\n",
      "\titers: 200, epoch: 9 | loss: 0.1357385\n",
      "\tspeed: 0.0653s/iter; left time: 696.8217s\n",
      "\titers: 300, epoch: 9 | loss: 0.1498955\n",
      "\tspeed: 0.0667s/iter; left time: 705.7041s\n",
      "\titers: 400, epoch: 9 | loss: 0.1061970\n",
      "\tspeed: 0.0770s/iter; left time: 806.9380s\n",
      "\titers: 500, epoch: 9 | loss: 0.1025095\n",
      "\tspeed: 0.0907s/iter; left time: 940.8725s\n",
      "\titers: 600, epoch: 9 | loss: 0.1716437\n",
      "\tspeed: 0.0811s/iter; left time: 833.6225s\n",
      "\titers: 700, epoch: 9 | loss: 0.1352835\n",
      "\tspeed: 0.0872s/iter; left time: 887.1146s\n",
      "\titers: 800, epoch: 9 | loss: 0.1026693\n",
      "\tspeed: 0.0824s/iter; left time: 830.0046s\n",
      "\titers: 900, epoch: 9 | loss: 0.1031473\n",
      "\tspeed: 0.0836s/iter; left time: 833.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:12.26s\n",
      "Steps: 906 | Train Loss: 0.1258401 Vali Loss: 0.2275282 Test Loss: 0.2585810\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1361745\n",
      "\tspeed: 0.2650s/iter; left time: 2614.8793s\n",
      "\titers: 200, epoch: 10 | loss: 0.1269473\n",
      "\tspeed: 0.0700s/iter; left time: 683.3920s\n",
      "\titers: 300, epoch: 10 | loss: 0.1197023\n",
      "\tspeed: 0.0839s/iter; left time: 811.2071s\n",
      "\titers: 400, epoch: 10 | loss: 0.1149063\n",
      "\tspeed: 0.0931s/iter; left time: 890.4211s\n",
      "\titers: 500, epoch: 10 | loss: 0.0795734\n",
      "\tspeed: 0.0860s/iter; left time: 814.0923s\n",
      "\titers: 600, epoch: 10 | loss: 0.1153909\n",
      "\tspeed: 0.0889s/iter; left time: 832.3374s\n",
      "\titers: 700, epoch: 10 | loss: 0.1106908\n",
      "\tspeed: 0.0860s/iter; left time: 796.9243s\n",
      "\titers: 800, epoch: 10 | loss: 0.1213849\n",
      "\tspeed: 0.0809s/iter; left time: 741.3276s\n",
      "\titers: 900, epoch: 10 | loss: 0.1078778\n",
      "\tspeed: 0.0851s/iter; left time: 771.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:17.59s\n",
      "Steps: 906 | Train Loss: 0.1160288 Vali Loss: 0.2128404 Test Loss: 0.2476691\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22933387756347656, rmse:0.4788881540298462, mae:0.3071345090866089, rse:0.4385837912559509\n",
      "Original data scale mse:2136431.5, rmse:1461.6536865234375, mae:947.5726928710938, rse:0.10271384567022324\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0110964\n",
      "\tspeed: 0.0977s/iter; left time: 1760.2456s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255223\n",
      "\tspeed: 0.0753s/iter; left time: 1348.7211s\n",
      "\titers: 300, epoch: 1 | loss: 0.8716780\n",
      "\tspeed: 0.0813s/iter; left time: 1449.5870s\n",
      "\titers: 400, epoch: 1 | loss: 0.7424500\n",
      "\tspeed: 0.0845s/iter; left time: 1497.1241s\n",
      "\titers: 500, epoch: 1 | loss: 0.5756359\n",
      "\tspeed: 0.0823s/iter; left time: 1450.1393s\n",
      "\titers: 600, epoch: 1 | loss: 0.5612029\n",
      "\tspeed: 0.0820s/iter; left time: 1436.2863s\n",
      "\titers: 700, epoch: 1 | loss: 0.5945213\n",
      "\tspeed: 0.0906s/iter; left time: 1578.4655s\n",
      "\titers: 800, epoch: 1 | loss: 0.5661271\n",
      "\tspeed: 0.0872s/iter; left time: 1510.6823s\n",
      "\titers: 900, epoch: 1 | loss: 0.4744344\n",
      "\tspeed: 0.0748s/iter; left time: 1287.3609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:16.11s\n",
      "Steps: 906 | Train Loss: 0.7331715 Vali Loss: 0.4576765 Test Loss: 0.5196525\n",
      "Validation loss decreased (inf --> 0.457677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4004549\n",
      "\tspeed: 0.2534s/iter; left time: 4336.9626s\n",
      "\titers: 200, epoch: 2 | loss: 0.3324803\n",
      "\tspeed: 0.0846s/iter; left time: 1439.4751s\n",
      "\titers: 300, epoch: 2 | loss: 0.2399531\n",
      "\tspeed: 0.0834s/iter; left time: 1410.3830s\n",
      "\titers: 400, epoch: 2 | loss: 0.2108331\n",
      "\tspeed: 0.0830s/iter; left time: 1394.8427s\n",
      "\titers: 500, epoch: 2 | loss: 0.2416867\n",
      "\tspeed: 0.0846s/iter; left time: 1413.9373s\n",
      "\titers: 600, epoch: 2 | loss: 0.1909854\n",
      "\tspeed: 0.0823s/iter; left time: 1367.1191s\n",
      "\titers: 700, epoch: 2 | loss: 0.2561404\n",
      "\tspeed: 0.0798s/iter; left time: 1317.1891s\n",
      "\titers: 800, epoch: 2 | loss: 0.2384087\n",
      "\tspeed: 0.0791s/iter; left time: 1299.0802s\n",
      "\titers: 900, epoch: 2 | loss: 0.2788672\n",
      "\tspeed: 0.0693s/iter; left time: 1130.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:14.95s\n",
      "Steps: 906 | Train Loss: 0.2808930 Vali Loss: 0.2271793 Test Loss: 0.2518363\n",
      "Validation loss decreased (0.457677 --> 0.227179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2000737\n",
      "\tspeed: 0.2478s/iter; left time: 4016.1614s\n",
      "\titers: 200, epoch: 3 | loss: 0.2064884\n",
      "\tspeed: 0.0855s/iter; left time: 1377.3643s\n",
      "\titers: 300, epoch: 3 | loss: 0.2256097\n",
      "\tspeed: 0.0792s/iter; left time: 1267.8164s\n",
      "\titers: 400, epoch: 3 | loss: 0.1799943\n",
      "\tspeed: 0.0769s/iter; left time: 1223.5494s\n",
      "\titers: 500, epoch: 3 | loss: 0.1743587\n",
      "\tspeed: 0.0884s/iter; left time: 1396.9555s\n",
      "\titers: 600, epoch: 3 | loss: 0.1895953\n",
      "\tspeed: 0.0875s/iter; left time: 1374.3038s\n",
      "\titers: 700, epoch: 3 | loss: 0.2045630\n",
      "\tspeed: 0.0859s/iter; left time: 1341.4107s\n",
      "\titers: 800, epoch: 3 | loss: 0.1650593\n",
      "\tspeed: 0.0756s/iter; left time: 1172.4250s\n",
      "\titers: 900, epoch: 3 | loss: 0.1540406\n",
      "\tspeed: 0.0824s/iter; left time: 1269.9262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:15.83s\n",
      "Steps: 906 | Train Loss: 0.2065787 Vali Loss: 0.2056104 Test Loss: 0.2384753\n",
      "Validation loss decreased (0.227179 --> 0.205610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1556263\n",
      "\tspeed: 0.1451s/iter; left time: 2220.5225s\n",
      "\titers: 200, epoch: 4 | loss: 0.1958848\n",
      "\tspeed: 0.0428s/iter; left time: 650.2460s\n",
      "\titers: 300, epoch: 4 | loss: 0.1944859\n",
      "\tspeed: 0.0406s/iter; left time: 613.1434s\n",
      "\titers: 400, epoch: 4 | loss: 0.1832495\n",
      "\tspeed: 0.0410s/iter; left time: 615.7479s\n",
      "\titers: 500, epoch: 4 | loss: 0.1719584\n",
      "\tspeed: 0.0410s/iter; left time: 611.1930s\n",
      "\titers: 600, epoch: 4 | loss: 0.2236012\n",
      "\tspeed: 0.0408s/iter; left time: 603.6445s\n",
      "\titers: 700, epoch: 4 | loss: 0.1815878\n",
      "\tspeed: 0.0405s/iter; left time: 594.8376s\n",
      "\titers: 800, epoch: 4 | loss: 0.1719698\n",
      "\tspeed: 0.0409s/iter; left time: 597.8594s\n",
      "\titers: 900, epoch: 4 | loss: 0.1419669\n",
      "\tspeed: 0.0412s/iter; left time: 597.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 906 | Train Loss: 0.1845571 Vali Loss: 0.1923019 Test Loss: 0.2291569\n",
      "Validation loss decreased (0.205610 --> 0.192302).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1599094\n",
      "\tspeed: 0.1311s/iter; left time: 1887.9387s\n",
      "\titers: 200, epoch: 5 | loss: 0.1774687\n",
      "\tspeed: 0.0407s/iter; left time: 582.3665s\n",
      "\titers: 300, epoch: 5 | loss: 0.1778492\n",
      "\tspeed: 0.0405s/iter; left time: 575.2827s\n",
      "\titers: 400, epoch: 5 | loss: 0.2010385\n",
      "\tspeed: 0.0421s/iter; left time: 593.4097s\n",
      "\titers: 500, epoch: 5 | loss: 0.1888134\n",
      "\tspeed: 0.0407s/iter; left time: 569.5660s\n",
      "\titers: 600, epoch: 5 | loss: 0.2223522\n",
      "\tspeed: 0.0409s/iter; left time: 569.0600s\n",
      "\titers: 700, epoch: 5 | loss: 0.1476538\n",
      "\tspeed: 0.0407s/iter; left time: 560.9319s\n",
      "\titers: 800, epoch: 5 | loss: 0.1757735\n",
      "\tspeed: 0.0406s/iter; left time: 556.4934s\n",
      "\titers: 900, epoch: 5 | loss: 0.1359860\n",
      "\tspeed: 0.0409s/iter; left time: 556.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 906 | Train Loss: 0.1681147 Vali Loss: 0.2021536 Test Loss: 0.2376099\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1336145\n",
      "\tspeed: 0.1232s/iter; left time: 1662.2735s\n",
      "\titers: 200, epoch: 6 | loss: 0.1949365\n",
      "\tspeed: 0.0408s/iter; left time: 545.7895s\n",
      "\titers: 300, epoch: 6 | loss: 0.1197943\n",
      "\tspeed: 0.0407s/iter; left time: 540.4000s\n",
      "\titers: 400, epoch: 6 | loss: 0.1242415\n",
      "\tspeed: 0.0411s/iter; left time: 542.8039s\n",
      "\titers: 500, epoch: 6 | loss: 0.1565760\n",
      "\tspeed: 0.0407s/iter; left time: 532.3433s\n",
      "\titers: 600, epoch: 6 | loss: 0.1301359\n",
      "\tspeed: 0.0406s/iter; left time: 527.7633s\n",
      "\titers: 700, epoch: 6 | loss: 0.1173154\n",
      "\tspeed: 0.0413s/iter; left time: 532.7699s\n",
      "\titers: 800, epoch: 6 | loss: 0.1403409\n",
      "\tspeed: 0.0407s/iter; left time: 520.6954s\n",
      "\titers: 900, epoch: 6 | loss: 0.1429634\n",
      "\tspeed: 0.0411s/iter; left time: 521.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.63s\n",
      "Steps: 906 | Train Loss: 0.1561661 Vali Loss: 0.2016599 Test Loss: 0.2415381\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1524837\n",
      "\tspeed: 0.1330s/iter; left time: 1673.2285s\n",
      "\titers: 200, epoch: 7 | loss: 0.1349531\n",
      "\tspeed: 0.0407s/iter; left time: 507.7318s\n",
      "\titers: 300, epoch: 7 | loss: 0.1599021\n",
      "\tspeed: 0.0409s/iter; left time: 506.5852s\n",
      "\titers: 400, epoch: 7 | loss: 0.1414544\n",
      "\tspeed: 0.0408s/iter; left time: 501.5290s\n",
      "\titers: 500, epoch: 7 | loss: 0.1353801\n",
      "\tspeed: 0.0404s/iter; left time: 492.6389s\n",
      "\titers: 600, epoch: 7 | loss: 0.1558456\n",
      "\tspeed: 0.0406s/iter; left time: 490.8927s\n",
      "\titers: 700, epoch: 7 | loss: 0.1264177\n",
      "\tspeed: 0.0406s/iter; left time: 486.4371s\n",
      "\titers: 800, epoch: 7 | loss: 0.1490112\n",
      "\tspeed: 0.0409s/iter; left time: 485.6541s\n",
      "\titers: 900, epoch: 7 | loss: 0.1526244\n",
      "\tspeed: 0.0403s/iter; left time: 475.4814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.44s\n",
      "Steps: 906 | Train Loss: 0.1436993 Vali Loss: 0.2125715 Test Loss: 0.2444334\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1365401\n",
      "\tspeed: 0.1253s/iter; left time: 1463.8880s\n",
      "\titers: 200, epoch: 8 | loss: 0.1415621\n",
      "\tspeed: 0.0406s/iter; left time: 470.3061s\n",
      "\titers: 300, epoch: 8 | loss: 0.1359778\n",
      "\tspeed: 0.0407s/iter; left time: 467.4224s\n",
      "\titers: 400, epoch: 8 | loss: 0.1739831\n",
      "\tspeed: 0.0403s/iter; left time: 458.6421s\n",
      "\titers: 500, epoch: 8 | loss: 0.1222738\n",
      "\tspeed: 0.0402s/iter; left time: 453.3057s\n",
      "\titers: 600, epoch: 8 | loss: 0.1543238\n",
      "\tspeed: 0.0400s/iter; left time: 447.6077s\n",
      "\titers: 700, epoch: 8 | loss: 0.1497450\n",
      "\tspeed: 0.0403s/iter; left time: 446.5725s\n",
      "\titers: 800, epoch: 8 | loss: 0.1366047\n",
      "\tspeed: 0.0407s/iter; left time: 446.3940s\n",
      "\titers: 900, epoch: 8 | loss: 0.1546357\n",
      "\tspeed: 0.0402s/iter; left time: 437.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.40s\n",
      "Steps: 906 | Train Loss: 0.1315071 Vali Loss: 0.1978554 Test Loss: 0.2367776\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1567157\n",
      "\tspeed: 0.1254s/iter; left time: 1350.6010s\n",
      "\titers: 200, epoch: 9 | loss: 0.1268193\n",
      "\tspeed: 0.0407s/iter; left time: 434.3322s\n",
      "\titers: 300, epoch: 9 | loss: 0.1183200\n",
      "\tspeed: 0.0405s/iter; left time: 428.3645s\n",
      "\titers: 400, epoch: 9 | loss: 0.1604439\n",
      "\tspeed: 0.0406s/iter; left time: 425.2989s\n",
      "\titers: 500, epoch: 9 | loss: 0.1234356\n",
      "\tspeed: 0.0407s/iter; left time: 421.9621s\n",
      "\titers: 600, epoch: 9 | loss: 0.1050128\n",
      "\tspeed: 0.0406s/iter; left time: 416.8695s\n",
      "\titers: 700, epoch: 9 | loss: 0.1173194\n",
      "\tspeed: 0.0404s/iter; left time: 410.5372s\n",
      "\titers: 800, epoch: 9 | loss: 0.0929318\n",
      "\tspeed: 0.0406s/iter; left time: 408.6880s\n",
      "\titers: 900, epoch: 9 | loss: 0.0960175\n",
      "\tspeed: 0.0409s/iter; left time: 407.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.61s\n",
      "Steps: 906 | Train Loss: 0.1205104 Vali Loss: 0.2186041 Test Loss: 0.2435271\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2293320894241333, rmse:0.47888630628585815, mae:0.3048325479030609, rse:0.43858206272125244\n",
      "Original data scale mse:2031066.875, rmse:1425.155029296875, mae:935.1376953125, rse:0.100149005651474\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0823917\n",
      "\tspeed: 0.0813s/iter; left time: 1462.2146s\n",
      "\titers: 200, epoch: 1 | loss: 1.0069790\n",
      "\tspeed: 0.0475s/iter; left time: 849.1077s\n",
      "\titers: 300, epoch: 1 | loss: 0.8770661\n",
      "\tspeed: 0.0476s/iter; left time: 847.0834s\n",
      "\titers: 400, epoch: 1 | loss: 0.8745096\n",
      "\tspeed: 0.0473s/iter; left time: 836.6563s\n",
      "\titers: 500, epoch: 1 | loss: 0.8725150\n",
      "\tspeed: 0.0477s/iter; left time: 838.7603s\n",
      "\titers: 600, epoch: 1 | loss: 0.7874011\n",
      "\tspeed: 0.0477s/iter; left time: 833.3078s\n",
      "\titers: 700, epoch: 1 | loss: 0.7588439\n",
      "\tspeed: 0.0475s/iter; left time: 826.2946s\n",
      "\titers: 800, epoch: 1 | loss: 0.7350141\n",
      "\tspeed: 0.0474s/iter; left time: 818.8665s\n",
      "\titers: 900, epoch: 1 | loss: 0.7707536\n",
      "\tspeed: 0.0471s/iter; left time: 808.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 904 | Train Loss: 0.8740950 Vali Loss: 0.6789001 Test Loss: 0.7786553\n",
      "Validation loss decreased (inf --> 0.678900).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6533060\n",
      "\tspeed: 0.1480s/iter; left time: 2527.0500s\n",
      "\titers: 200, epoch: 2 | loss: 0.5544503\n",
      "\tspeed: 0.0477s/iter; left time: 810.2277s\n",
      "\titers: 300, epoch: 2 | loss: 0.5280406\n",
      "\tspeed: 0.0479s/iter; left time: 808.2490s\n",
      "\titers: 400, epoch: 2 | loss: 0.4869804\n",
      "\tspeed: 0.0476s/iter; left time: 799.2359s\n",
      "\titers: 500, epoch: 2 | loss: 0.4556633\n",
      "\tspeed: 0.0475s/iter; left time: 792.2121s\n",
      "\titers: 600, epoch: 2 | loss: 0.3752886\n",
      "\tspeed: 0.0475s/iter; left time: 787.8799s\n",
      "\titers: 700, epoch: 2 | loss: 0.4069628\n",
      "\tspeed: 0.0473s/iter; left time: 779.7388s\n",
      "\titers: 800, epoch: 2 | loss: 0.3496157\n",
      "\tspeed: 0.0482s/iter; left time: 789.9550s\n",
      "\titers: 900, epoch: 2 | loss: 0.3377945\n",
      "\tspeed: 0.0474s/iter; left time: 771.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.76s\n",
      "Steps: 904 | Train Loss: 0.4734246 Vali Loss: 0.3552743 Test Loss: 0.4045528\n",
      "Validation loss decreased (0.678900 --> 0.355274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3399955\n",
      "\tspeed: 0.1485s/iter; left time: 2401.5469s\n",
      "\titers: 200, epoch: 3 | loss: 0.3415433\n",
      "\tspeed: 0.0480s/iter; left time: 770.8098s\n",
      "\titers: 300, epoch: 3 | loss: 0.3483469\n",
      "\tspeed: 0.0475s/iter; left time: 758.6708s\n",
      "\titers: 400, epoch: 3 | loss: 0.3354156\n",
      "\tspeed: 0.0472s/iter; left time: 749.0777s\n",
      "\titers: 500, epoch: 3 | loss: 0.2989469\n",
      "\tspeed: 0.0475s/iter; left time: 749.4018s\n",
      "\titers: 600, epoch: 3 | loss: 0.3285864\n",
      "\tspeed: 0.0477s/iter; left time: 747.4769s\n",
      "\titers: 700, epoch: 3 | loss: 0.2761757\n",
      "\tspeed: 0.0475s/iter; left time: 740.1494s\n",
      "\titers: 800, epoch: 3 | loss: 0.3313439\n",
      "\tspeed: 0.0474s/iter; left time: 733.7644s\n",
      "\titers: 900, epoch: 3 | loss: 0.2659835\n",
      "\tspeed: 0.0476s/iter; left time: 731.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.81s\n",
      "Steps: 904 | Train Loss: 0.3279033 Vali Loss: 0.3359104 Test Loss: 0.3869711\n",
      "Validation loss decreased (0.355274 --> 0.335910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2956022\n",
      "\tspeed: 0.1520s/iter; left time: 2320.7446s\n",
      "\titers: 200, epoch: 4 | loss: 0.3269606\n",
      "\tspeed: 0.0475s/iter; left time: 720.5606s\n",
      "\titers: 300, epoch: 4 | loss: 0.3368034\n",
      "\tspeed: 0.0474s/iter; left time: 714.7358s\n",
      "\titers: 400, epoch: 4 | loss: 0.2822587\n",
      "\tspeed: 0.0475s/iter; left time: 710.7849s\n",
      "\titers: 500, epoch: 4 | loss: 0.2596902\n",
      "\tspeed: 0.0477s/iter; left time: 709.8108s\n",
      "\titers: 600, epoch: 4 | loss: 0.2594452\n",
      "\tspeed: 0.0477s/iter; left time: 705.1963s\n",
      "\titers: 700, epoch: 4 | loss: 0.3265277\n",
      "\tspeed: 0.0483s/iter; left time: 708.1212s\n",
      "\titers: 800, epoch: 4 | loss: 0.2563006\n",
      "\tspeed: 0.0478s/iter; left time: 696.8023s\n",
      "\titers: 900, epoch: 4 | loss: 0.2921928\n",
      "\tspeed: 0.0478s/iter; left time: 691.2518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.79s\n",
      "Steps: 904 | Train Loss: 0.2961516 Vali Loss: 0.3256589 Test Loss: 0.3825296\n",
      "Validation loss decreased (0.335910 --> 0.325659).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2959335\n",
      "\tspeed: 0.1517s/iter; left time: 2178.6791s\n",
      "\titers: 200, epoch: 5 | loss: 0.2480375\n",
      "\tspeed: 0.0482s/iter; left time: 687.4251s\n",
      "\titers: 300, epoch: 5 | loss: 0.2720532\n",
      "\tspeed: 0.0476s/iter; left time: 673.8661s\n",
      "\titers: 400, epoch: 5 | loss: 0.2820179\n",
      "\tspeed: 0.0475s/iter; left time: 667.9536s\n",
      "\titers: 500, epoch: 5 | loss: 0.2456066\n",
      "\tspeed: 0.0477s/iter; left time: 665.7466s\n",
      "\titers: 600, epoch: 5 | loss: 0.2962483\n",
      "\tspeed: 0.0474s/iter; left time: 657.8916s\n",
      "\titers: 700, epoch: 5 | loss: 0.2628937\n",
      "\tspeed: 0.0479s/iter; left time: 659.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.2792138\n",
      "\tspeed: 0.0476s/iter; left time: 650.0712s\n",
      "\titers: 900, epoch: 5 | loss: 0.2771539\n",
      "\tspeed: 0.0477s/iter; left time: 647.1879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.97s\n",
      "Steps: 904 | Train Loss: 0.2698367 Vali Loss: 0.3413826 Test Loss: 0.3988329\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3155553\n",
      "\tspeed: 0.1490s/iter; left time: 2006.2814s\n",
      "\titers: 200, epoch: 6 | loss: 0.2553471\n",
      "\tspeed: 0.0473s/iter; left time: 631.6626s\n",
      "\titers: 300, epoch: 6 | loss: 0.2625495\n",
      "\tspeed: 0.0473s/iter; left time: 627.5963s\n",
      "\titers: 400, epoch: 6 | loss: 0.2358810\n",
      "\tspeed: 0.0474s/iter; left time: 623.4009s\n",
      "\titers: 500, epoch: 6 | loss: 0.2251849\n",
      "\tspeed: 0.0476s/iter; left time: 621.4982s\n",
      "\titers: 600, epoch: 6 | loss: 0.2006454\n",
      "\tspeed: 0.0476s/iter; left time: 617.4110s\n",
      "\titers: 700, epoch: 6 | loss: 0.2535985\n",
      "\tspeed: 0.0476s/iter; left time: 612.6578s\n",
      "\titers: 800, epoch: 6 | loss: 0.2246123\n",
      "\tspeed: 0.0476s/iter; left time: 607.4379s\n",
      "\titers: 900, epoch: 6 | loss: 0.2213723\n",
      "\tspeed: 0.0476s/iter; left time: 602.9361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.69s\n",
      "Steps: 904 | Train Loss: 0.2445648 Vali Loss: 0.3798327 Test Loss: 0.4200766\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2194687\n",
      "\tspeed: 0.1526s/iter; left time: 1916.3301s\n",
      "\titers: 200, epoch: 7 | loss: 0.2384607\n",
      "\tspeed: 0.0475s/iter; left time: 591.1514s\n",
      "\titers: 300, epoch: 7 | loss: 0.2158869\n",
      "\tspeed: 0.0474s/iter; left time: 586.0565s\n",
      "\titers: 400, epoch: 7 | loss: 0.1956223\n",
      "\tspeed: 0.0476s/iter; left time: 583.7095s\n",
      "\titers: 500, epoch: 7 | loss: 0.1990148\n",
      "\tspeed: 0.0475s/iter; left time: 576.9787s\n",
      "\titers: 600, epoch: 7 | loss: 0.1659363\n",
      "\tspeed: 0.0474s/iter; left time: 571.8580s\n",
      "\titers: 700, epoch: 7 | loss: 0.2366100\n",
      "\tspeed: 0.0475s/iter; left time: 567.7721s\n",
      "\titers: 800, epoch: 7 | loss: 0.1669879\n",
      "\tspeed: 0.0473s/iter; left time: 561.2006s\n",
      "\titers: 900, epoch: 7 | loss: 0.2389710\n",
      "\tspeed: 0.0478s/iter; left time: 562.2804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.90s\n",
      "Steps: 904 | Train Loss: 0.2189238 Vali Loss: 0.3766761 Test Loss: 0.4400035\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2045034\n",
      "\tspeed: 0.1493s/iter; left time: 1739.6754s\n",
      "\titers: 200, epoch: 8 | loss: 0.2278801\n",
      "\tspeed: 0.0471s/iter; left time: 544.3177s\n",
      "\titers: 300, epoch: 8 | loss: 0.2085162\n",
      "\tspeed: 0.0471s/iter; left time: 539.4153s\n",
      "\titers: 400, epoch: 8 | loss: 0.1808843\n",
      "\tspeed: 0.0473s/iter; left time: 537.4339s\n",
      "\titers: 500, epoch: 8 | loss: 0.2082619\n",
      "\tspeed: 0.0479s/iter; left time: 538.5340s\n",
      "\titers: 600, epoch: 8 | loss: 0.1899046\n",
      "\tspeed: 0.0479s/iter; left time: 533.8192s\n",
      "\titers: 700, epoch: 8 | loss: 0.1899607\n",
      "\tspeed: 0.0485s/iter; left time: 535.8266s\n",
      "\titers: 800, epoch: 8 | loss: 0.1780602\n",
      "\tspeed: 0.0480s/iter; left time: 525.8255s\n",
      "\titers: 900, epoch: 8 | loss: 0.1735122\n",
      "\tspeed: 0.0480s/iter; left time: 520.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.02s\n",
      "Steps: 904 | Train Loss: 0.1941823 Vali Loss: 0.3748443 Test Loss: 0.4469492\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1875593\n",
      "\tspeed: 0.1485s/iter; left time: 1596.2560s\n",
      "\titers: 200, epoch: 9 | loss: 0.1995312\n",
      "\tspeed: 0.0491s/iter; left time: 522.3696s\n",
      "\titers: 300, epoch: 9 | loss: 0.1751804\n",
      "\tspeed: 0.0477s/iter; left time: 502.9455s\n",
      "\titers: 400, epoch: 9 | loss: 0.1571854\n",
      "\tspeed: 0.0476s/iter; left time: 497.7210s\n",
      "\titers: 500, epoch: 9 | loss: 0.1898574\n",
      "\tspeed: 0.0479s/iter; left time: 495.3734s\n",
      "\titers: 600, epoch: 9 | loss: 0.1513159\n",
      "\tspeed: 0.0479s/iter; left time: 490.4460s\n",
      "\titers: 700, epoch: 9 | loss: 0.1552747\n",
      "\tspeed: 0.0480s/iter; left time: 486.8965s\n",
      "\titers: 800, epoch: 9 | loss: 0.1557277\n",
      "\tspeed: 0.0478s/iter; left time: 480.4551s\n",
      "\titers: 900, epoch: 9 | loss: 0.1749375\n",
      "\tspeed: 0.0477s/iter; left time: 474.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.18s\n",
      "Steps: 904 | Train Loss: 0.1735136 Vali Loss: 0.4083863 Test Loss: 0.4595780\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.38296183943748474, rmse:0.6188390851020813, mae:0.410003662109375, rse:0.5666120052337646\n",
      "Original data scale mse:3882534.5, rmse:1970.414794921875, mae:1288.4697265625, rse:0.13866613805294037\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0470481\n",
      "\tspeed: 0.0551s/iter; left time: 990.6963s\n",
      "\titers: 200, epoch: 1 | loss: 0.9543929\n",
      "\tspeed: 0.0491s/iter; left time: 878.5613s\n",
      "\titers: 300, epoch: 1 | loss: 0.9334467\n",
      "\tspeed: 0.0480s/iter; left time: 854.0078s\n",
      "\titers: 400, epoch: 1 | loss: 0.9310876\n",
      "\tspeed: 0.0480s/iter; left time: 849.4641s\n",
      "\titers: 500, epoch: 1 | loss: 0.8907044\n",
      "\tspeed: 0.0476s/iter; left time: 836.4878s\n",
      "\titers: 600, epoch: 1 | loss: 0.8326557\n",
      "\tspeed: 0.0475s/iter; left time: 829.9400s\n",
      "\titers: 700, epoch: 1 | loss: 0.8296362\n",
      "\tspeed: 0.0478s/iter; left time: 830.7113s\n",
      "\titers: 800, epoch: 1 | loss: 0.7868129\n",
      "\tspeed: 0.0477s/iter; left time: 823.7405s\n",
      "\titers: 900, epoch: 1 | loss: 0.7149656\n",
      "\tspeed: 0.0481s/iter; left time: 826.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 904 | Train Loss: 0.8881518 Vali Loss: 0.6904503 Test Loss: 0.7891228\n",
      "Validation loss decreased (inf --> 0.690450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6433607\n",
      "\tspeed: 0.1530s/iter; left time: 2612.0195s\n",
      "\titers: 200, epoch: 2 | loss: 0.6184612\n",
      "\tspeed: 0.0482s/iter; left time: 818.2955s\n",
      "\titers: 300, epoch: 2 | loss: 0.4711223\n",
      "\tspeed: 0.0477s/iter; left time: 804.6018s\n",
      "\titers: 400, epoch: 2 | loss: 0.4671873\n",
      "\tspeed: 0.0476s/iter; left time: 798.2591s\n",
      "\titers: 500, epoch: 2 | loss: 0.4238615\n",
      "\tspeed: 0.0477s/iter; left time: 795.5822s\n",
      "\titers: 600, epoch: 2 | loss: 0.3641039\n",
      "\tspeed: 0.0479s/iter; left time: 794.3459s\n",
      "\titers: 700, epoch: 2 | loss: 0.3377725\n",
      "\tspeed: 0.0479s/iter; left time: 788.6843s\n",
      "\titers: 800, epoch: 2 | loss: 0.3637824\n",
      "\tspeed: 0.0477s/iter; left time: 781.1355s\n",
      "\titers: 900, epoch: 2 | loss: 0.3360992\n",
      "\tspeed: 0.0479s/iter; left time: 779.7320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.94s\n",
      "Steps: 904 | Train Loss: 0.4749946 Vali Loss: 0.3382266 Test Loss: 0.3807494\n",
      "Validation loss decreased (0.690450 --> 0.338227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3231165\n",
      "\tspeed: 0.1529s/iter; left time: 2472.3970s\n",
      "\titers: 200, epoch: 3 | loss: 0.2788155\n",
      "\tspeed: 0.0477s/iter; left time: 766.3548s\n",
      "\titers: 300, epoch: 3 | loss: 0.3233666\n",
      "\tspeed: 0.0475s/iter; left time: 759.3740s\n",
      "\titers: 400, epoch: 3 | loss: 0.3401326\n",
      "\tspeed: 0.0479s/iter; left time: 760.3754s\n",
      "\titers: 500, epoch: 3 | loss: 0.3626771\n",
      "\tspeed: 0.0474s/iter; left time: 748.1611s\n",
      "\titers: 600, epoch: 3 | loss: 0.3228456\n",
      "\tspeed: 0.0475s/iter; left time: 745.0680s\n",
      "\titers: 700, epoch: 3 | loss: 0.3208282\n",
      "\tspeed: 0.0479s/iter; left time: 746.2665s\n",
      "\titers: 800, epoch: 3 | loss: 0.3472467\n",
      "\tspeed: 0.0477s/iter; left time: 737.9338s\n",
      "\titers: 900, epoch: 3 | loss: 0.3377291\n",
      "\tspeed: 0.0476s/iter; left time: 731.4584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.98s\n",
      "Steps: 904 | Train Loss: 0.3259160 Vali Loss: 0.3281991 Test Loss: 0.3659314\n",
      "Validation loss decreased (0.338227 --> 0.328199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2992444\n",
      "\tspeed: 0.1514s/iter; left time: 2311.4993s\n",
      "\titers: 200, epoch: 4 | loss: 0.2816119\n",
      "\tspeed: 0.0481s/iter; left time: 729.6876s\n",
      "\titers: 300, epoch: 4 | loss: 0.3738590\n",
      "\tspeed: 0.0479s/iter; left time: 722.4867s\n",
      "\titers: 400, epoch: 4 | loss: 0.2896416\n",
      "\tspeed: 0.0482s/iter; left time: 720.8889s\n",
      "\titers: 500, epoch: 4 | loss: 0.3069442\n",
      "\tspeed: 0.0482s/iter; left time: 716.8138s\n",
      "\titers: 600, epoch: 4 | loss: 0.2621520\n",
      "\tspeed: 0.0495s/iter; left time: 730.5487s\n",
      "\titers: 700, epoch: 4 | loss: 0.2959616\n",
      "\tspeed: 0.0483s/iter; left time: 708.8704s\n",
      "\titers: 800, epoch: 4 | loss: 0.2830916\n",
      "\tspeed: 0.0478s/iter; left time: 696.0038s\n",
      "\titers: 900, epoch: 4 | loss: 0.2998120\n",
      "\tspeed: 0.0481s/iter; left time: 695.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.47s\n",
      "Steps: 904 | Train Loss: 0.2975396 Vali Loss: 0.3396604 Test Loss: 0.3869184\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2264378\n",
      "\tspeed: 0.1470s/iter; left time: 2111.2823s\n",
      "\titers: 200, epoch: 5 | loss: 0.2410927\n",
      "\tspeed: 0.0478s/iter; left time: 681.3444s\n",
      "\titers: 300, epoch: 5 | loss: 0.2527874\n",
      "\tspeed: 0.0473s/iter; left time: 670.3577s\n",
      "\titers: 400, epoch: 5 | loss: 0.2568575\n",
      "\tspeed: 0.0470s/iter; left time: 661.5125s\n",
      "\titers: 500, epoch: 5 | loss: 0.3120755\n",
      "\tspeed: 0.0471s/iter; left time: 657.5129s\n",
      "\titers: 600, epoch: 5 | loss: 0.2397982\n",
      "\tspeed: 0.0471s/iter; left time: 653.6977s\n",
      "\titers: 700, epoch: 5 | loss: 0.2557956\n",
      "\tspeed: 0.0474s/iter; left time: 652.2687s\n",
      "\titers: 800, epoch: 5 | loss: 0.2021513\n",
      "\tspeed: 0.0474s/iter; left time: 648.1403s\n",
      "\titers: 900, epoch: 5 | loss: 0.2515710\n",
      "\tspeed: 0.0477s/iter; left time: 646.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.65s\n",
      "Steps: 904 | Train Loss: 0.2714087 Vali Loss: 0.3417945 Test Loss: 0.3864014\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2480191\n",
      "\tspeed: 0.1457s/iter; left time: 1961.1548s\n",
      "\titers: 200, epoch: 6 | loss: 0.2979158\n",
      "\tspeed: 0.0477s/iter; left time: 637.1093s\n",
      "\titers: 300, epoch: 6 | loss: 0.2502322\n",
      "\tspeed: 0.0474s/iter; left time: 628.6414s\n",
      "\titers: 400, epoch: 6 | loss: 0.2639868\n",
      "\tspeed: 0.0479s/iter; left time: 630.3845s\n",
      "\titers: 500, epoch: 6 | loss: 0.2306353\n",
      "\tspeed: 0.0479s/iter; left time: 626.0783s\n",
      "\titers: 600, epoch: 6 | loss: 0.2576678\n",
      "\tspeed: 0.0482s/iter; left time: 624.6034s\n",
      "\titers: 700, epoch: 6 | loss: 0.2697546\n",
      "\tspeed: 0.0479s/iter; left time: 616.4874s\n",
      "\titers: 800, epoch: 6 | loss: 0.2373158\n",
      "\tspeed: 0.0477s/iter; left time: 608.4527s\n",
      "\titers: 900, epoch: 6 | loss: 0.2503975\n",
      "\tspeed: 0.0481s/iter; left time: 608.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.04s\n",
      "Steps: 904 | Train Loss: 0.2467986 Vali Loss: 0.3595337 Test Loss: 0.3939228\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1730573\n",
      "\tspeed: 0.1509s/iter; left time: 1894.2580s\n",
      "\titers: 200, epoch: 7 | loss: 0.2202345\n",
      "\tspeed: 0.0475s/iter; left time: 592.0097s\n",
      "\titers: 300, epoch: 7 | loss: 0.2813601\n",
      "\tspeed: 0.0482s/iter; left time: 595.9787s\n",
      "\titers: 400, epoch: 7 | loss: 0.2682171\n",
      "\tspeed: 0.0478s/iter; left time: 585.3541s\n",
      "\titers: 500, epoch: 7 | loss: 0.2098832\n",
      "\tspeed: 0.0478s/iter; left time: 581.3815s\n",
      "\titers: 600, epoch: 7 | loss: 0.2466746\n",
      "\tspeed: 0.0480s/iter; left time: 578.8736s\n",
      "\titers: 700, epoch: 7 | loss: 0.2373047\n",
      "\tspeed: 0.0476s/iter; left time: 568.6580s\n",
      "\titers: 800, epoch: 7 | loss: 0.2163522\n",
      "\tspeed: 0.0478s/iter; left time: 567.0017s\n",
      "\titers: 900, epoch: 7 | loss: 0.2477254\n",
      "\tspeed: 0.0481s/iter; left time: 565.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.09s\n",
      "Steps: 904 | Train Loss: 0.2204815 Vali Loss: 0.3812579 Test Loss: 0.4208291\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1627568\n",
      "\tspeed: 0.1501s/iter; left time: 1748.6014s\n",
      "\titers: 200, epoch: 8 | loss: 0.2246100\n",
      "\tspeed: 0.0479s/iter; left time: 553.9102s\n",
      "\titers: 300, epoch: 8 | loss: 0.1925653\n",
      "\tspeed: 0.0479s/iter; left time: 548.0955s\n",
      "\titers: 400, epoch: 8 | loss: 0.2056562\n",
      "\tspeed: 0.0482s/iter; left time: 547.3016s\n",
      "\titers: 500, epoch: 8 | loss: 0.1954454\n",
      "\tspeed: 0.0482s/iter; left time: 542.1129s\n",
      "\titers: 600, epoch: 8 | loss: 0.2126897\n",
      "\tspeed: 0.0479s/iter; left time: 533.7858s\n",
      "\titers: 700, epoch: 8 | loss: 0.1981904\n",
      "\tspeed: 0.0480s/iter; left time: 530.4742s\n",
      "\titers: 800, epoch: 8 | loss: 0.1959238\n",
      "\tspeed: 0.0477s/iter; left time: 522.3389s\n",
      "\titers: 900, epoch: 8 | loss: 0.1860708\n",
      "\tspeed: 0.0486s/iter; left time: 527.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.22s\n",
      "Steps: 904 | Train Loss: 0.1968404 Vali Loss: 0.3949544 Test Loss: 0.4424962\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3659231960773468, rmse:0.6049158573150635, mae:0.406237930059433, rse:0.5538637638092041\n",
      "Original data scale mse:3475395.25, rmse:1864.2412109375, mae:1267.4959716796875, rse:0.13119427859783173\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0556426\n",
      "\tspeed: 0.1188s/iter; left time: 2130.7638s\n",
      "\titers: 200, epoch: 1 | loss: 0.9117105\n",
      "\tspeed: 0.0945s/iter; left time: 1685.6999s\n",
      "\titers: 300, epoch: 1 | loss: 0.9929752\n",
      "\tspeed: 0.0921s/iter; left time: 1633.5515s\n",
      "\titers: 400, epoch: 1 | loss: 0.9440226\n",
      "\tspeed: 0.0930s/iter; left time: 1641.2080s\n",
      "\titers: 500, epoch: 1 | loss: 0.9021465\n",
      "\tspeed: 0.0913s/iter; left time: 1601.2219s\n",
      "\titers: 600, epoch: 1 | loss: 0.8881038\n",
      "\tspeed: 0.0962s/iter; left time: 1677.8503s\n",
      "\titers: 700, epoch: 1 | loss: 0.8366055\n",
      "\tspeed: 0.0897s/iter; left time: 1555.9234s\n",
      "\titers: 800, epoch: 1 | loss: 0.9370977\n",
      "\tspeed: 0.0866s/iter; left time: 1493.6238s\n",
      "\titers: 900, epoch: 1 | loss: 0.8078213\n",
      "\tspeed: 0.0962s/iter; left time: 1648.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:24.06s\n",
      "Steps: 902 | Train Loss: 0.9143684 Vali Loss: 0.7948772 Test Loss: 0.8949615\n",
      "Validation loss decreased (inf --> 0.794877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7399679\n",
      "\tspeed: 0.3519s/iter; left time: 5996.3574s\n",
      "\titers: 200, epoch: 2 | loss: 0.7218238\n",
      "\tspeed: 0.0933s/iter; left time: 1579.7071s\n",
      "\titers: 300, epoch: 2 | loss: 0.6376406\n",
      "\tspeed: 0.0935s/iter; left time: 1574.7034s\n",
      "\titers: 400, epoch: 2 | loss: 0.6239727\n",
      "\tspeed: 0.0951s/iter; left time: 1591.8893s\n",
      "\titers: 500, epoch: 2 | loss: 0.4921079\n",
      "\tspeed: 0.0968s/iter; left time: 1610.9414s\n",
      "\titers: 600, epoch: 2 | loss: 0.4553659\n",
      "\tspeed: 0.0953s/iter; left time: 1575.8175s\n",
      "\titers: 700, epoch: 2 | loss: 0.4282715\n",
      "\tspeed: 0.0928s/iter; left time: 1526.1764s\n",
      "\titers: 800, epoch: 2 | loss: 0.4115283\n",
      "\tspeed: 0.0935s/iter; left time: 1527.3089s\n",
      "\titers: 900, epoch: 2 | loss: 0.4112552\n",
      "\tspeed: 0.0976s/iter; left time: 1585.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:26.39s\n",
      "Steps: 902 | Train Loss: 0.5735561 Vali Loss: 0.4007534 Test Loss: 0.4643753\n",
      "Validation loss decreased (0.794877 --> 0.400753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309239\n",
      "\tspeed: 0.3646s/iter; left time: 5884.1689s\n",
      "\titers: 200, epoch: 3 | loss: 0.3999682\n",
      "\tspeed: 0.0939s/iter; left time: 1506.0260s\n",
      "\titers: 300, epoch: 3 | loss: 0.3883238\n",
      "\tspeed: 0.0923s/iter; left time: 1470.3735s\n",
      "\titers: 400, epoch: 3 | loss: 0.3137305\n",
      "\tspeed: 0.0963s/iter; left time: 1524.6450s\n",
      "\titers: 500, epoch: 3 | loss: 0.3651032\n",
      "\tspeed: 0.0921s/iter; left time: 1448.8278s\n",
      "\titers: 600, epoch: 3 | loss: 0.3883449\n",
      "\tspeed: 0.0950s/iter; left time: 1485.0157s\n",
      "\titers: 700, epoch: 3 | loss: 0.3385204\n",
      "\tspeed: 0.0960s/iter; left time: 1490.8391s\n",
      "\titers: 800, epoch: 3 | loss: 0.3292853\n",
      "\tspeed: 0.0976s/iter; left time: 1507.3031s\n",
      "\titers: 900, epoch: 3 | loss: 0.3590758\n",
      "\tspeed: 0.0907s/iter; left time: 1391.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.56s\n",
      "Steps: 902 | Train Loss: 0.3716947 Vali Loss: 0.3766966 Test Loss: 0.3999118\n",
      "Validation loss decreased (0.400753 --> 0.376697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3448939\n",
      "\tspeed: 0.3676s/iter; left time: 5600.5288s\n",
      "\titers: 200, epoch: 4 | loss: 0.3133757\n",
      "\tspeed: 0.0989s/iter; left time: 1497.5949s\n",
      "\titers: 300, epoch: 4 | loss: 0.3378096\n",
      "\tspeed: 0.0940s/iter; left time: 1413.1286s\n",
      "\titers: 400, epoch: 4 | loss: 0.3230149\n",
      "\tspeed: 0.0964s/iter; left time: 1439.5692s\n",
      "\titers: 500, epoch: 4 | loss: 0.3331124\n",
      "\tspeed: 0.0925s/iter; left time: 1372.0149s\n",
      "\titers: 600, epoch: 4 | loss: 0.3050267\n",
      "\tspeed: 0.0950s/iter; left time: 1399.6747s\n",
      "\titers: 700, epoch: 4 | loss: 0.3381920\n",
      "\tspeed: 0.0931s/iter; left time: 1361.8182s\n",
      "\titers: 800, epoch: 4 | loss: 0.3273350\n",
      "\tspeed: 0.0901s/iter; left time: 1310.3226s\n",
      "\titers: 900, epoch: 4 | loss: 0.3315594\n",
      "\tspeed: 0.0942s/iter; left time: 1359.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:26.15s\n",
      "Steps: 902 | Train Loss: 0.3301617 Vali Loss: 0.3842070 Test Loss: 0.4093729\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3113647\n",
      "\tspeed: 0.3531s/iter; left time: 5060.9864s\n",
      "\titers: 200, epoch: 5 | loss: 0.2885664\n",
      "\tspeed: 0.0935s/iter; left time: 1331.0736s\n",
      "\titers: 300, epoch: 5 | loss: 0.3129171\n",
      "\tspeed: 0.0971s/iter; left time: 1371.9017s\n",
      "\titers: 400, epoch: 5 | loss: 0.3288687\n",
      "\tspeed: 0.0933s/iter; left time: 1309.3048s\n",
      "\titers: 500, epoch: 5 | loss: 0.2751628\n",
      "\tspeed: 0.0900s/iter; left time: 1254.2726s\n",
      "\titers: 600, epoch: 5 | loss: 0.3331985\n",
      "\tspeed: 0.0916s/iter; left time: 1267.2533s\n",
      "\titers: 700, epoch: 5 | loss: 0.3149088\n",
      "\tspeed: 0.0909s/iter; left time: 1247.8416s\n",
      "\titers: 800, epoch: 5 | loss: 0.2863960\n",
      "\tspeed: 0.0996s/iter; left time: 1357.9155s\n",
      "\titers: 900, epoch: 5 | loss: 0.3237554\n",
      "\tspeed: 0.1005s/iter; left time: 1359.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.38s\n",
      "Steps: 902 | Train Loss: 0.2971241 Vali Loss: 0.3780274 Test Loss: 0.4311398\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2890690\n",
      "\tspeed: 0.3643s/iter; left time: 4892.7245s\n",
      "\titers: 200, epoch: 6 | loss: 0.2955357\n",
      "\tspeed: 0.0967s/iter; left time: 1289.0879s\n",
      "\titers: 300, epoch: 6 | loss: 0.3013394\n",
      "\tspeed: 0.0962s/iter; left time: 1272.6038s\n",
      "\titers: 400, epoch: 6 | loss: 0.2360921\n",
      "\tspeed: 0.0940s/iter; left time: 1234.2476s\n",
      "\titers: 500, epoch: 6 | loss: 0.2670588\n",
      "\tspeed: 0.0944s/iter; left time: 1229.8773s\n",
      "\titers: 600, epoch: 6 | loss: 0.2733375\n",
      "\tspeed: 0.0917s/iter; left time: 1185.4225s\n",
      "\titers: 700, epoch: 6 | loss: 0.2506110\n",
      "\tspeed: 0.0953s/iter; left time: 1222.3635s\n",
      "\titers: 800, epoch: 6 | loss: 0.2834331\n",
      "\tspeed: 0.0979s/iter; left time: 1245.7625s\n",
      "\titers: 900, epoch: 6 | loss: 0.2546576\n",
      "\tspeed: 0.0948s/iter; left time: 1197.7584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:26.53s\n",
      "Steps: 902 | Train Loss: 0.2621344 Vali Loss: 0.3932323 Test Loss: 0.4348716\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2665659\n",
      "\tspeed: 0.3515s/iter; left time: 4404.5472s\n",
      "\titers: 200, epoch: 7 | loss: 0.2441754\n",
      "\tspeed: 0.0942s/iter; left time: 1171.0819s\n",
      "\titers: 300, epoch: 7 | loss: 0.2507175\n",
      "\tspeed: 0.0981s/iter; left time: 1209.7165s\n",
      "\titers: 400, epoch: 7 | loss: 0.2488033\n",
      "\tspeed: 0.0973s/iter; left time: 1189.9416s\n",
      "\titers: 500, epoch: 7 | loss: 0.2215162\n",
      "\tspeed: 0.0948s/iter; left time: 1149.9086s\n",
      "\titers: 600, epoch: 7 | loss: 0.2286867\n",
      "\tspeed: 0.0958s/iter; left time: 1152.3245s\n",
      "\titers: 700, epoch: 7 | loss: 0.2000321\n",
      "\tspeed: 0.0926s/iter; left time: 1105.0824s\n",
      "\titers: 800, epoch: 7 | loss: 0.2168674\n",
      "\tspeed: 0.0907s/iter; left time: 1072.7297s\n",
      "\titers: 900, epoch: 7 | loss: 0.2452890\n",
      "\tspeed: 0.0950s/iter; left time: 1114.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:26.23s\n",
      "Steps: 902 | Train Loss: 0.2302652 Vali Loss: 0.4079715 Test Loss: 0.4594448\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2193322\n",
      "\tspeed: 0.3492s/iter; left time: 4060.2528s\n",
      "\titers: 200, epoch: 8 | loss: 0.2082115\n",
      "\tspeed: 0.0920s/iter; left time: 1060.6946s\n",
      "\titers: 300, epoch: 8 | loss: 0.2178346\n",
      "\tspeed: 0.0917s/iter; left time: 1047.5522s\n",
      "\titers: 400, epoch: 8 | loss: 0.1852731\n",
      "\tspeed: 0.0922s/iter; left time: 1044.1118s\n",
      "\titers: 500, epoch: 8 | loss: 0.2082866\n",
      "\tspeed: 0.0939s/iter; left time: 1053.8222s\n",
      "\titers: 600, epoch: 8 | loss: 0.1931727\n",
      "\tspeed: 0.0951s/iter; left time: 1057.7620s\n",
      "\titers: 700, epoch: 8 | loss: 0.1895335\n",
      "\tspeed: 0.0932s/iter; left time: 1027.7534s\n",
      "\titers: 800, epoch: 8 | loss: 0.1931735\n",
      "\tspeed: 0.0948s/iter; left time: 1035.9573s\n",
      "\titers: 900, epoch: 8 | loss: 0.1819656\n",
      "\tspeed: 0.0908s/iter; left time: 982.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:24.70s\n",
      "Steps: 902 | Train Loss: 0.2030460 Vali Loss: 0.4450221 Test Loss: 0.4838283\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4002043604850769, rmse:0.6326170563697815, mae:0.43345174193382263, rse:0.5793997645378113\n",
      "Original data scale mse:4282493.5, rmse:2069.418701171875, mae:1388.617919921875, rse:0.14577020704746246\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9747837\n",
      "\tspeed: 0.1030s/iter; left time: 1848.5759s\n",
      "\titers: 200, epoch: 1 | loss: 0.9371972\n",
      "\tspeed: 0.0923s/iter; left time: 1646.7005s\n",
      "\titers: 300, epoch: 1 | loss: 0.8888125\n",
      "\tspeed: 0.0928s/iter; left time: 1645.9891s\n",
      "\titers: 400, epoch: 1 | loss: 0.9089000\n",
      "\tspeed: 0.0967s/iter; left time: 1706.3721s\n",
      "\titers: 500, epoch: 1 | loss: 0.8934722\n",
      "\tspeed: 0.0957s/iter; left time: 1679.2390s\n",
      "\titers: 600, epoch: 1 | loss: 0.8779312\n",
      "\tspeed: 0.0909s/iter; left time: 1586.0167s\n",
      "\titers: 700, epoch: 1 | loss: 0.8866318\n",
      "\tspeed: 0.0945s/iter; left time: 1639.4819s\n",
      "\titers: 800, epoch: 1 | loss: 0.8219113\n",
      "\tspeed: 0.0944s/iter; left time: 1627.0051s\n",
      "\titers: 900, epoch: 1 | loss: 0.8559791\n",
      "\tspeed: 0.0897s/iter; left time: 1538.0811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:25.32s\n",
      "Steps: 902 | Train Loss: 0.9065261 Vali Loss: 0.7829705 Test Loss: 0.8851123\n",
      "Validation loss decreased (inf --> 0.782971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7547203\n",
      "\tspeed: 0.3599s/iter; left time: 6132.2163s\n",
      "\titers: 200, epoch: 2 | loss: 0.7775635\n",
      "\tspeed: 0.0963s/iter; left time: 1630.8189s\n",
      "\titers: 300, epoch: 2 | loss: 0.6786218\n",
      "\tspeed: 0.0964s/iter; left time: 1623.9671s\n",
      "\titers: 400, epoch: 2 | loss: 0.6330407\n",
      "\tspeed: 0.0938s/iter; left time: 1569.9950s\n",
      "\titers: 500, epoch: 2 | loss: 0.4857193\n",
      "\tspeed: 0.0885s/iter; left time: 1472.5262s\n",
      "\titers: 600, epoch: 2 | loss: 0.4721341\n",
      "\tspeed: 0.0942s/iter; left time: 1558.0740s\n",
      "\titers: 700, epoch: 2 | loss: 0.4378839\n",
      "\tspeed: 0.0975s/iter; left time: 1603.4459s\n",
      "\titers: 800, epoch: 2 | loss: 0.3838536\n",
      "\tspeed: 0.0969s/iter; left time: 1583.3560s\n",
      "\titers: 900, epoch: 2 | loss: 0.4112867\n",
      "\tspeed: 0.0942s/iter; left time: 1530.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:26.38s\n",
      "Steps: 902 | Train Loss: 0.5779578 Vali Loss: 0.3862142 Test Loss: 0.4410709\n",
      "Validation loss decreased (0.782971 --> 0.386214).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3923575\n",
      "\tspeed: 0.3543s/iter; left time: 5718.0101s\n",
      "\titers: 200, epoch: 3 | loss: 0.3581985\n",
      "\tspeed: 0.0989s/iter; left time: 1585.3910s\n",
      "\titers: 300, epoch: 3 | loss: 0.3779914\n",
      "\tspeed: 0.0934s/iter; left time: 1487.7378s\n",
      "\titers: 400, epoch: 3 | loss: 0.3910858\n",
      "\tspeed: 0.0927s/iter; left time: 1468.4800s\n",
      "\titers: 500, epoch: 3 | loss: 0.3264660\n",
      "\tspeed: 0.0940s/iter; left time: 1479.2762s\n",
      "\titers: 600, epoch: 3 | loss: 0.4066662\n",
      "\tspeed: 0.0912s/iter; left time: 1425.7527s\n",
      "\titers: 700, epoch: 3 | loss: 0.3683693\n",
      "\tspeed: 0.0949s/iter; left time: 1474.2456s\n",
      "\titers: 800, epoch: 3 | loss: 0.3681506\n",
      "\tspeed: 0.0937s/iter; left time: 1446.4743s\n",
      "\titers: 900, epoch: 3 | loss: 0.3775008\n",
      "\tspeed: 0.0902s/iter; left time: 1383.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.75s\n",
      "Steps: 902 | Train Loss: 0.3717640 Vali Loss: 0.3603804 Test Loss: 0.4174464\n",
      "Validation loss decreased (0.386214 --> 0.360380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3318378\n",
      "\tspeed: 0.3676s/iter; left time: 5599.7159s\n",
      "\titers: 200, epoch: 4 | loss: 0.3698566\n",
      "\tspeed: 0.0946s/iter; left time: 1431.8452s\n",
      "\titers: 300, epoch: 4 | loss: 0.3150576\n",
      "\tspeed: 0.0961s/iter; left time: 1445.4086s\n",
      "\titers: 400, epoch: 4 | loss: 0.3293356\n",
      "\tspeed: 0.0958s/iter; left time: 1431.1163s\n",
      "\titers: 500, epoch: 4 | loss: 0.3294253\n",
      "\tspeed: 0.0984s/iter; left time: 1460.3010s\n",
      "\titers: 600, epoch: 4 | loss: 0.3051562\n",
      "\tspeed: 0.0943s/iter; left time: 1388.7989s\n",
      "\titers: 700, epoch: 4 | loss: 0.3229181\n",
      "\tspeed: 0.0962s/iter; left time: 1407.6557s\n",
      "\titers: 800, epoch: 4 | loss: 0.3119358\n",
      "\tspeed: 0.0975s/iter; left time: 1416.8187s\n",
      "\titers: 900, epoch: 4 | loss: 0.3702855\n",
      "\tspeed: 0.0936s/iter; left time: 1351.6174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:27.11s\n",
      "Steps: 902 | Train Loss: 0.3310084 Vali Loss: 0.3841996 Test Loss: 0.4059642\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2815675\n",
      "\tspeed: 0.3545s/iter; left time: 5080.3857s\n",
      "\titers: 200, epoch: 5 | loss: 0.3349283\n",
      "\tspeed: 0.0935s/iter; left time: 1330.7211s\n",
      "\titers: 300, epoch: 5 | loss: 0.3080087\n",
      "\tspeed: 0.0978s/iter; left time: 1382.3007s\n",
      "\titers: 400, epoch: 5 | loss: 0.3181481\n",
      "\tspeed: 0.0977s/iter; left time: 1371.5525s\n",
      "\titers: 500, epoch: 5 | loss: 0.3063115\n",
      "\tspeed: 0.0954s/iter; left time: 1329.8389s\n",
      "\titers: 600, epoch: 5 | loss: 0.2769427\n",
      "\tspeed: 0.0951s/iter; left time: 1315.9505s\n",
      "\titers: 700, epoch: 5 | loss: 0.3076919\n",
      "\tspeed: 0.0975s/iter; left time: 1338.5620s\n",
      "\titers: 800, epoch: 5 | loss: 0.2910819\n",
      "\tspeed: 0.0990s/iter; left time: 1349.0296s\n",
      "\titers: 900, epoch: 5 | loss: 0.2972264\n",
      "\tspeed: 0.0893s/iter; left time: 1208.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.54s\n",
      "Steps: 902 | Train Loss: 0.2978728 Vali Loss: 0.3776934 Test Loss: 0.4558210\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2968060\n",
      "\tspeed: 0.2320s/iter; left time: 3115.5255s\n",
      "\titers: 200, epoch: 6 | loss: 0.2741509\n",
      "\tspeed: 0.0634s/iter; left time: 845.3393s\n",
      "\titers: 300, epoch: 6 | loss: 0.3015133\n",
      "\tspeed: 0.0648s/iter; left time: 857.1501s\n",
      "\titers: 400, epoch: 6 | loss: 0.2727470\n",
      "\tspeed: 0.0636s/iter; left time: 835.1539s\n",
      "\titers: 500, epoch: 6 | loss: 0.2934584\n",
      "\tspeed: 0.0609s/iter; left time: 793.8143s\n",
      "\titers: 600, epoch: 6 | loss: 0.2593384\n",
      "\tspeed: 0.0580s/iter; left time: 750.2482s\n",
      "\titers: 700, epoch: 6 | loss: 0.2557577\n",
      "\tspeed: 0.0553s/iter; left time: 709.9239s\n",
      "\titers: 800, epoch: 6 | loss: 0.2905982\n",
      "\tspeed: 0.0525s/iter; left time: 667.8428s\n",
      "\titers: 900, epoch: 6 | loss: 0.2469835\n",
      "\tspeed: 0.0523s/iter; left time: 660.6584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:54.38s\n",
      "Steps: 902 | Train Loss: 0.2627956 Vali Loss: 0.4065648 Test Loss: 0.4417315\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2572851\n",
      "\tspeed: 0.1450s/iter; left time: 1816.4322s\n",
      "\titers: 200, epoch: 7 | loss: 0.2664468\n",
      "\tspeed: 0.0512s/iter; left time: 635.9251s\n",
      "\titers: 300, epoch: 7 | loss: 0.1962448\n",
      "\tspeed: 0.0510s/iter; left time: 629.3145s\n",
      "\titers: 400, epoch: 7 | loss: 0.2291983\n",
      "\tspeed: 0.0510s/iter; left time: 623.8883s\n",
      "\titers: 500, epoch: 7 | loss: 0.2450765\n",
      "\tspeed: 0.0510s/iter; left time: 618.9567s\n",
      "\titers: 600, epoch: 7 | loss: 0.2339267\n",
      "\tspeed: 0.0510s/iter; left time: 613.3720s\n",
      "\titers: 700, epoch: 7 | loss: 0.2440784\n",
      "\tspeed: 0.0510s/iter; left time: 607.9986s\n",
      "\titers: 800, epoch: 7 | loss: 0.2014966\n",
      "\tspeed: 0.0510s/iter; left time: 602.8806s\n",
      "\titers: 900, epoch: 7 | loss: 0.2223980\n",
      "\tspeed: 0.0509s/iter; left time: 596.8789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.45s\n",
      "Steps: 902 | Train Loss: 0.2321533 Vali Loss: 0.4167455 Test Loss: 0.5029176\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1995281\n",
      "\tspeed: 0.1407s/iter; left time: 1636.3571s\n",
      "\titers: 200, epoch: 8 | loss: 0.2176139\n",
      "\tspeed: 0.0508s/iter; left time: 585.3368s\n",
      "\titers: 300, epoch: 8 | loss: 0.2021720\n",
      "\tspeed: 0.0508s/iter; left time: 581.0146s\n",
      "\titers: 400, epoch: 8 | loss: 0.1923164\n",
      "\tspeed: 0.0508s/iter; left time: 575.8502s\n",
      "\titers: 500, epoch: 8 | loss: 0.1643226\n",
      "\tspeed: 0.0508s/iter; left time: 570.7276s\n",
      "\titers: 600, epoch: 8 | loss: 0.1779020\n",
      "\tspeed: 0.0507s/iter; left time: 563.9814s\n",
      "\titers: 700, epoch: 8 | loss: 0.1975900\n",
      "\tspeed: 0.0509s/iter; left time: 561.0388s\n",
      "\titers: 800, epoch: 8 | loss: 0.2043637\n",
      "\tspeed: 0.0509s/iter; left time: 555.6844s\n",
      "\titers: 900, epoch: 8 | loss: 0.1913625\n",
      "\tspeed: 0.0509s/iter; left time: 550.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.18s\n",
      "Steps: 902 | Train Loss: 0.2071828 Vali Loss: 0.4340174 Test Loss: 0.4944167\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4175257086753845, rmse:0.6461622714996338, mae:0.4400014877319336, rse:0.5918055176734924\n",
      "Original data scale mse:4567560.0, rmse:2137.18505859375, mae:1427.0869140625, rse:0.150543674826622\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8411770\n",
      "\tspeed: 0.0546s/iter; left time: 983.6089s\n",
      "\titers: 200, epoch: 1 | loss: 0.7745342\n",
      "\tspeed: 0.0343s/iter; left time: 614.0218s\n",
      "\titers: 300, epoch: 1 | loss: 0.7407349\n",
      "\tspeed: 0.0344s/iter; left time: 613.0428s\n",
      "\titers: 400, epoch: 1 | loss: 0.7152467\n",
      "\tspeed: 0.0344s/iter; left time: 609.4629s\n",
      "\titers: 500, epoch: 1 | loss: 0.6182094\n",
      "\tspeed: 0.0344s/iter; left time: 605.7407s\n",
      "\titers: 600, epoch: 1 | loss: 0.6193296\n",
      "\tspeed: 0.0343s/iter; left time: 601.5752s\n",
      "\titers: 700, epoch: 1 | loss: 0.5257676\n",
      "\tspeed: 0.0343s/iter; left time: 598.0644s\n",
      "\titers: 800, epoch: 1 | loss: 0.5669288\n",
      "\tspeed: 0.0343s/iter; left time: 594.1285s\n",
      "\titers: 900, epoch: 1 | loss: 0.5658205\n",
      "\tspeed: 0.0344s/iter; left time: 591.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.6742649 Vali Loss: 0.5281730 Test Loss: 0.5781866\n",
      "Validation loss decreased (inf --> 0.528173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4614405\n",
      "\tspeed: 0.0993s/iter; left time: 1698.7083s\n",
      "\titers: 200, epoch: 2 | loss: 0.3836004\n",
      "\tspeed: 0.0344s/iter; left time: 585.9156s\n",
      "\titers: 300, epoch: 2 | loss: 0.3471265\n",
      "\tspeed: 0.0343s/iter; left time: 581.0248s\n",
      "\titers: 400, epoch: 2 | loss: 0.3198166\n",
      "\tspeed: 0.0345s/iter; left time: 579.4325s\n",
      "\titers: 500, epoch: 2 | loss: 0.3381199\n",
      "\tspeed: 0.0343s/iter; left time: 573.4610s\n",
      "\titers: 600, epoch: 2 | loss: 0.3900046\n",
      "\tspeed: 0.0343s/iter; left time: 569.7810s\n",
      "\titers: 700, epoch: 2 | loss: 0.3232814\n",
      "\tspeed: 0.0343s/iter; left time: 566.1692s\n",
      "\titers: 800, epoch: 2 | loss: 0.3243355\n",
      "\tspeed: 0.0343s/iter; left time: 563.2472s\n",
      "\titers: 900, epoch: 2 | loss: 0.3131627\n",
      "\tspeed: 0.0343s/iter; left time: 559.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.44s\n",
      "Steps: 906 | Train Loss: 0.3677958 Vali Loss: 0.3103438 Test Loss: 0.3360346\n",
      "Validation loss decreased (0.528173 --> 0.310344).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2890518\n",
      "\tspeed: 0.1101s/iter; left time: 1784.1786s\n",
      "\titers: 200, epoch: 3 | loss: 0.2875691\n",
      "\tspeed: 0.0351s/iter; left time: 565.9072s\n",
      "\titers: 300, epoch: 3 | loss: 0.3093425\n",
      "\tspeed: 0.0342s/iter; left time: 547.9931s\n",
      "\titers: 400, epoch: 3 | loss: 0.2636827\n",
      "\tspeed: 0.0342s/iter; left time: 544.8093s\n",
      "\titers: 500, epoch: 3 | loss: 0.2666644\n",
      "\tspeed: 0.0342s/iter; left time: 541.1275s\n",
      "\titers: 600, epoch: 3 | loss: 0.2905198\n",
      "\tspeed: 0.0343s/iter; left time: 538.6536s\n",
      "\titers: 700, epoch: 3 | loss: 0.2983588\n",
      "\tspeed: 0.0342s/iter; left time: 533.6803s\n",
      "\titers: 800, epoch: 3 | loss: 0.3214429\n",
      "\tspeed: 0.0341s/iter; left time: 529.3278s\n",
      "\titers: 900, epoch: 3 | loss: 0.2782020\n",
      "\tspeed: 0.0342s/iter; left time: 526.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.42s\n",
      "Steps: 906 | Train Loss: 0.2944343 Vali Loss: 0.2901719 Test Loss: 0.3135786\n",
      "Validation loss decreased (0.310344 --> 0.290172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2989853\n",
      "\tspeed: 0.0971s/iter; left time: 1486.0726s\n",
      "\titers: 200, epoch: 4 | loss: 0.2600982\n",
      "\tspeed: 0.0341s/iter; left time: 518.5922s\n",
      "\titers: 300, epoch: 4 | loss: 0.2654146\n",
      "\tspeed: 0.0341s/iter; left time: 515.2943s\n",
      "\titers: 400, epoch: 4 | loss: 0.2787250\n",
      "\tspeed: 0.0341s/iter; left time: 511.3534s\n",
      "\titers: 500, epoch: 4 | loss: 0.2626924\n",
      "\tspeed: 0.0341s/iter; left time: 508.0179s\n",
      "\titers: 600, epoch: 4 | loss: 0.2561714\n",
      "\tspeed: 0.0341s/iter; left time: 504.9236s\n",
      "\titers: 700, epoch: 4 | loss: 0.2497951\n",
      "\tspeed: 0.0341s/iter; left time: 501.7299s\n",
      "\titers: 800, epoch: 4 | loss: 0.2617155\n",
      "\tspeed: 0.0341s/iter; left time: 497.9856s\n",
      "\titers: 900, epoch: 4 | loss: 0.2790179\n",
      "\tspeed: 0.0341s/iter; left time: 494.0507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 906 | Train Loss: 0.2692863 Vali Loss: 0.2692709 Test Loss: 0.2923602\n",
      "Validation loss decreased (0.290172 --> 0.269271).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2376451\n",
      "\tspeed: 0.0981s/iter; left time: 1411.7252s\n",
      "\titers: 200, epoch: 5 | loss: 0.2833542\n",
      "\tspeed: 0.0341s/iter; left time: 487.3623s\n",
      "\titers: 300, epoch: 5 | loss: 0.2473220\n",
      "\tspeed: 0.0341s/iter; left time: 484.2184s\n",
      "\titers: 400, epoch: 5 | loss: 0.2552013\n",
      "\tspeed: 0.0341s/iter; left time: 481.0722s\n",
      "\titers: 500, epoch: 5 | loss: 0.2591802\n",
      "\tspeed: 0.0341s/iter; left time: 477.5511s\n",
      "\titers: 600, epoch: 5 | loss: 0.2459600\n",
      "\tspeed: 0.0342s/iter; left time: 474.8154s\n",
      "\titers: 700, epoch: 5 | loss: 0.2923307\n",
      "\tspeed: 0.0342s/iter; left time: 471.3275s\n",
      "\titers: 800, epoch: 5 | loss: 0.2101649\n",
      "\tspeed: 0.0342s/iter; left time: 468.0915s\n",
      "\titers: 900, epoch: 5 | loss: 0.2528723\n",
      "\tspeed: 0.0342s/iter; left time: 464.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.22s\n",
      "Steps: 906 | Train Loss: 0.2524206 Vali Loss: 0.2669539 Test Loss: 0.2847308\n",
      "Validation loss decreased (0.269271 --> 0.266954).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2606908\n",
      "\tspeed: 0.0973s/iter; left time: 1313.1340s\n",
      "\titers: 200, epoch: 6 | loss: 0.2518609\n",
      "\tspeed: 0.0342s/iter; left time: 457.4668s\n",
      "\titers: 300, epoch: 6 | loss: 0.2905905\n",
      "\tspeed: 0.0342s/iter; left time: 454.9258s\n",
      "\titers: 400, epoch: 6 | loss: 0.2300878\n",
      "\tspeed: 0.0342s/iter; left time: 450.5036s\n",
      "\titers: 500, epoch: 6 | loss: 0.2021091\n",
      "\tspeed: 0.0341s/iter; left time: 446.1007s\n",
      "\titers: 600, epoch: 6 | loss: 0.2486252\n",
      "\tspeed: 0.0340s/iter; left time: 441.7329s\n",
      "\titers: 700, epoch: 6 | loss: 0.2424658\n",
      "\tspeed: 0.0341s/iter; left time: 439.3447s\n",
      "\titers: 800, epoch: 6 | loss: 0.2303610\n",
      "\tspeed: 0.0340s/iter; left time: 435.1983s\n",
      "\titers: 900, epoch: 6 | loss: 0.2460460\n",
      "\tspeed: 0.0341s/iter; left time: 432.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.2433822 Vali Loss: 0.2584088 Test Loss: 0.2837469\n",
      "Validation loss decreased (0.266954 --> 0.258409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2173903\n",
      "\tspeed: 0.0972s/iter; left time: 1222.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.2375101\n",
      "\tspeed: 0.0340s/iter; left time: 424.1934s\n",
      "\titers: 300, epoch: 7 | loss: 0.2392208\n",
      "\tspeed: 0.0340s/iter; left time: 420.7770s\n",
      "\titers: 400, epoch: 7 | loss: 0.2547496\n",
      "\tspeed: 0.0340s/iter; left time: 418.2401s\n",
      "\titers: 500, epoch: 7 | loss: 0.2392133\n",
      "\tspeed: 0.0340s/iter; left time: 414.6173s\n",
      "\titers: 600, epoch: 7 | loss: 0.2109084\n",
      "\tspeed: 0.0340s/iter; left time: 411.2057s\n",
      "\titers: 700, epoch: 7 | loss: 0.2216385\n",
      "\tspeed: 0.0340s/iter; left time: 407.8480s\n",
      "\titers: 800, epoch: 7 | loss: 0.2573618\n",
      "\tspeed: 0.0340s/iter; left time: 404.1493s\n",
      "\titers: 900, epoch: 7 | loss: 0.2284708\n",
      "\tspeed: 0.0341s/iter; left time: 401.3301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.2356746 Vali Loss: 0.2558953 Test Loss: 0.2790517\n",
      "Validation loss decreased (0.258409 --> 0.255895).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2140437\n",
      "\tspeed: 0.0965s/iter; left time: 1126.6664s\n",
      "\titers: 200, epoch: 8 | loss: 0.2016622\n",
      "\tspeed: 0.0340s/iter; left time: 393.6213s\n",
      "\titers: 300, epoch: 8 | loss: 0.2018867\n",
      "\tspeed: 0.0340s/iter; left time: 389.9711s\n",
      "\titers: 400, epoch: 8 | loss: 0.2442360\n",
      "\tspeed: 0.0340s/iter; left time: 387.2099s\n",
      "\titers: 500, epoch: 8 | loss: 0.2157539\n",
      "\tspeed: 0.0340s/iter; left time: 383.5329s\n",
      "\titers: 600, epoch: 8 | loss: 0.2315607\n",
      "\tspeed: 0.0340s/iter; left time: 380.0997s\n",
      "\titers: 700, epoch: 8 | loss: 0.2120043\n",
      "\tspeed: 0.0340s/iter; left time: 377.2111s\n",
      "\titers: 800, epoch: 8 | loss: 0.2329711\n",
      "\tspeed: 0.0340s/iter; left time: 373.3450s\n",
      "\titers: 900, epoch: 8 | loss: 0.2265757\n",
      "\tspeed: 0.0340s/iter; left time: 370.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.2281220 Vali Loss: 0.2527170 Test Loss: 0.2789706\n",
      "Validation loss decreased (0.255895 --> 0.252717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1879019\n",
      "\tspeed: 0.0982s/iter; left time: 1057.6186s\n",
      "\titers: 200, epoch: 9 | loss: 0.2141432\n",
      "\tspeed: 0.0341s/iter; left time: 363.6471s\n",
      "\titers: 300, epoch: 9 | loss: 0.2638787\n",
      "\tspeed: 0.0340s/iter; left time: 359.3496s\n",
      "\titers: 400, epoch: 9 | loss: 0.2146314\n",
      "\tspeed: 0.0340s/iter; left time: 356.0114s\n",
      "\titers: 500, epoch: 9 | loss: 0.2156431\n",
      "\tspeed: 0.0340s/iter; left time: 353.0642s\n",
      "\titers: 600, epoch: 9 | loss: 0.2396468\n",
      "\tspeed: 0.0341s/iter; left time: 349.9263s\n",
      "\titers: 700, epoch: 9 | loss: 0.2192348\n",
      "\tspeed: 0.0341s/iter; left time: 346.4532s\n",
      "\titers: 800, epoch: 9 | loss: 0.2079794\n",
      "\tspeed: 0.0341s/iter; left time: 343.2992s\n",
      "\titers: 900, epoch: 9 | loss: 0.1921019\n",
      "\tspeed: 0.0341s/iter; left time: 340.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.2208886 Vali Loss: 0.2622219 Test Loss: 0.2803758\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2312745\n",
      "\tspeed: 0.0942s/iter; left time: 929.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.2174579\n",
      "\tspeed: 0.0340s/iter; left time: 332.0349s\n",
      "\titers: 300, epoch: 10 | loss: 0.2237587\n",
      "\tspeed: 0.0340s/iter; left time: 328.7292s\n",
      "\titers: 400, epoch: 10 | loss: 0.2094203\n",
      "\tspeed: 0.0340s/iter; left time: 325.4902s\n",
      "\titers: 500, epoch: 10 | loss: 0.1876347\n",
      "\tspeed: 0.0340s/iter; left time: 321.5713s\n",
      "\titers: 600, epoch: 10 | loss: 0.2394806\n",
      "\tspeed: 0.0340s/iter; left time: 318.1141s\n",
      "\titers: 700, epoch: 10 | loss: 0.2000000\n",
      "\tspeed: 0.0340s/iter; left time: 314.9858s\n",
      "\titers: 800, epoch: 10 | loss: 0.2090933\n",
      "\tspeed: 0.0340s/iter; left time: 311.6979s\n",
      "\titers: 900, epoch: 10 | loss: 0.2035800\n",
      "\tspeed: 0.0340s/iter; left time: 308.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.2154244 Vali Loss: 0.2508209 Test Loss: 0.2797393\n",
      "Validation loss decreased (0.252717 --> 0.250821).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2151257\n",
      "\tspeed: 0.0981s/iter; left time: 878.7352s\n",
      "\titers: 200, epoch: 11 | loss: 0.1943919\n",
      "\tspeed: 0.0340s/iter; left time: 301.3879s\n",
      "\titers: 300, epoch: 11 | loss: 0.2094940\n",
      "\tspeed: 0.0340s/iter; left time: 298.0085s\n",
      "\titers: 400, epoch: 11 | loss: 0.2048209\n",
      "\tspeed: 0.0341s/iter; left time: 295.1152s\n",
      "\titers: 500, epoch: 11 | loss: 0.2262991\n",
      "\tspeed: 0.0340s/iter; left time: 291.1486s\n",
      "\titers: 600, epoch: 11 | loss: 0.2307932\n",
      "\tspeed: 0.0340s/iter; left time: 287.7586s\n",
      "\titers: 700, epoch: 11 | loss: 0.2144143\n",
      "\tspeed: 0.0340s/iter; left time: 284.1160s\n",
      "\titers: 800, epoch: 11 | loss: 0.2046956\n",
      "\tspeed: 0.0340s/iter; left time: 281.1499s\n",
      "\titers: 900, epoch: 11 | loss: 0.1806045\n",
      "\tspeed: 0.0340s/iter; left time: 277.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.2089683 Vali Loss: 0.2539987 Test Loss: 0.2821126\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1806721\n",
      "\tspeed: 0.0962s/iter; left time: 774.5291s\n",
      "\titers: 200, epoch: 12 | loss: 0.2172497\n",
      "\tspeed: 0.0340s/iter; left time: 270.1683s\n",
      "\titers: 300, epoch: 12 | loss: 0.1952600\n",
      "\tspeed: 0.0340s/iter; left time: 266.7297s\n",
      "\titers: 400, epoch: 12 | loss: 0.2288413\n",
      "\tspeed: 0.0340s/iter; left time: 263.2973s\n",
      "\titers: 500, epoch: 12 | loss: 0.2269492\n",
      "\tspeed: 0.0340s/iter; left time: 260.5484s\n",
      "\titers: 600, epoch: 12 | loss: 0.1990089\n",
      "\tspeed: 0.0423s/iter; left time: 319.8856s\n",
      "\titers: 700, epoch: 12 | loss: 0.1827129\n",
      "\tspeed: 0.0470s/iter; left time: 350.5050s\n",
      "\titers: 800, epoch: 12 | loss: 0.1978636\n",
      "\tspeed: 0.0454s/iter; left time: 334.0682s\n",
      "\titers: 900, epoch: 12 | loss: 0.1905783\n",
      "\tspeed: 0.0433s/iter; left time: 314.1405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:35.31s\n",
      "Steps: 906 | Train Loss: 0.2036647 Vali Loss: 0.2599432 Test Loss: 0.2882704\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1821626\n",
      "\tspeed: 0.1217s/iter; left time: 870.0211s\n",
      "\titers: 200, epoch: 13 | loss: 0.2159093\n",
      "\tspeed: 0.0371s/iter; left time: 261.8030s\n",
      "\titers: 300, epoch: 13 | loss: 0.1790218\n",
      "\tspeed: 0.0347s/iter; left time: 241.3918s\n",
      "\titers: 400, epoch: 13 | loss: 0.2139450\n",
      "\tspeed: 0.0341s/iter; left time: 233.5252s\n",
      "\titers: 500, epoch: 13 | loss: 0.1919719\n",
      "\tspeed: 0.0341s/iter; left time: 230.0651s\n",
      "\titers: 600, epoch: 13 | loss: 0.1989628\n",
      "\tspeed: 0.0340s/iter; left time: 226.0849s\n",
      "\titers: 700, epoch: 13 | loss: 0.1965910\n",
      "\tspeed: 0.0341s/iter; left time: 223.1947s\n",
      "\titers: 800, epoch: 13 | loss: 0.2086673\n",
      "\tspeed: 0.0341s/iter; left time: 219.6678s\n",
      "\titers: 900, epoch: 13 | loss: 0.2093980\n",
      "\tspeed: 0.0341s/iter; left time: 216.3357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.57s\n",
      "Steps: 906 | Train Loss: 0.1992896 Vali Loss: 0.2614796 Test Loss: 0.2805483\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2100765\n",
      "\tspeed: 0.0947s/iter; left time: 590.9807s\n",
      "\titers: 200, epoch: 14 | loss: 0.1944530\n",
      "\tspeed: 0.0350s/iter; left time: 214.7293s\n",
      "\titers: 300, epoch: 14 | loss: 0.1905202\n",
      "\tspeed: 0.0345s/iter; left time: 208.7289s\n",
      "\titers: 400, epoch: 14 | loss: 0.1586809\n",
      "\tspeed: 0.0384s/iter; left time: 228.4087s\n",
      "\titers: 500, epoch: 14 | loss: 0.2017929\n",
      "\tspeed: 0.0433s/iter; left time: 253.0654s\n",
      "\titers: 600, epoch: 14 | loss: 0.1999441\n",
      "\tspeed: 0.0345s/iter; left time: 198.0100s\n",
      "\titers: 700, epoch: 14 | loss: 0.1662549\n",
      "\tspeed: 0.0342s/iter; left time: 193.0894s\n",
      "\titers: 800, epoch: 14 | loss: 0.1981561\n",
      "\tspeed: 0.0341s/iter; left time: 189.2479s\n",
      "\titers: 900, epoch: 14 | loss: 0.1688969\n",
      "\tspeed: 0.0341s/iter; left time: 185.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 906 | Train Loss: 0.1947704 Vali Loss: 0.2558390 Test Loss: 0.2804028\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1902671\n",
      "\tspeed: 0.0976s/iter; left time: 520.7751s\n",
      "\titers: 200, epoch: 15 | loss: 0.1765103\n",
      "\tspeed: 0.0345s/iter; left time: 180.6411s\n",
      "\titers: 300, epoch: 15 | loss: 0.1776880\n",
      "\tspeed: 0.0373s/iter; left time: 191.6877s\n",
      "\titers: 400, epoch: 15 | loss: 0.1895667\n",
      "\tspeed: 0.0348s/iter; left time: 175.2228s\n",
      "\titers: 500, epoch: 15 | loss: 0.2077346\n",
      "\tspeed: 0.0345s/iter; left time: 170.2877s\n",
      "\titers: 600, epoch: 15 | loss: 0.1875344\n",
      "\tspeed: 0.0344s/iter; left time: 166.4864s\n",
      "\titers: 700, epoch: 15 | loss: 0.2073652\n",
      "\tspeed: 0.0346s/iter; left time: 163.6827s\n",
      "\titers: 800, epoch: 15 | loss: 0.1587146\n",
      "\tspeed: 0.0344s/iter; left time: 159.5544s\n",
      "\titers: 900, epoch: 15 | loss: 0.1983586\n",
      "\tspeed: 0.0343s/iter; left time: 155.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.89s\n",
      "Steps: 906 | Train Loss: 0.1906758 Vali Loss: 0.2590738 Test Loss: 0.2859502\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23617036640644073, rmse:0.48597362637519836, mae:0.2798229455947876, rse:0.44507288932800293\n",
      "Original data scale mse:1555223.5, rmse:1247.0860595703125, mae:786.8115844726562, rse:0.08763567358255386\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7694200\n",
      "\tspeed: 0.0380s/iter; left time: 684.4883s\n",
      "\titers: 200, epoch: 1 | loss: 0.7489529\n",
      "\tspeed: 0.0347s/iter; left time: 621.4524s\n",
      "\titers: 300, epoch: 1 | loss: 0.6756072\n",
      "\tspeed: 0.0349s/iter; left time: 622.4403s\n",
      "\titers: 400, epoch: 1 | loss: 0.6246179\n",
      "\tspeed: 0.0347s/iter; left time: 615.4590s\n",
      "\titers: 500, epoch: 1 | loss: 0.6153286\n",
      "\tspeed: 0.0346s/iter; left time: 610.2412s\n",
      "\titers: 600, epoch: 1 | loss: 0.5925941\n",
      "\tspeed: 0.0347s/iter; left time: 608.2892s\n",
      "\titers: 700, epoch: 1 | loss: 0.5516424\n",
      "\tspeed: 0.0348s/iter; left time: 606.6683s\n",
      "\titers: 800, epoch: 1 | loss: 0.5349961\n",
      "\tspeed: 0.0346s/iter; left time: 599.5044s\n",
      "\titers: 900, epoch: 1 | loss: 0.5636827\n",
      "\tspeed: 0.0354s/iter; left time: 609.7200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.93s\n",
      "Steps: 906 | Train Loss: 0.6626053 Vali Loss: 0.5115619 Test Loss: 0.5503395\n",
      "Validation loss decreased (inf --> 0.511562).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4275939\n",
      "\tspeed: 0.1003s/iter; left time: 1717.1463s\n",
      "\titers: 200, epoch: 2 | loss: 0.3919958\n",
      "\tspeed: 0.0347s/iter; left time: 590.5853s\n",
      "\titers: 300, epoch: 2 | loss: 0.3693000\n",
      "\tspeed: 0.0358s/iter; left time: 606.2037s\n",
      "\titers: 400, epoch: 2 | loss: 0.3371732\n",
      "\tspeed: 0.0418s/iter; left time: 703.0737s\n",
      "\titers: 500, epoch: 2 | loss: 0.3470794\n",
      "\tspeed: 0.0348s/iter; left time: 580.8652s\n",
      "\titers: 600, epoch: 2 | loss: 0.3676890\n",
      "\tspeed: 0.0350s/iter; left time: 580.8746s\n",
      "\titers: 700, epoch: 2 | loss: 0.2924747\n",
      "\tspeed: 0.0349s/iter; left time: 575.7767s\n",
      "\titers: 800, epoch: 2 | loss: 0.3209592\n",
      "\tspeed: 0.0345s/iter; left time: 566.6559s\n",
      "\titers: 900, epoch: 2 | loss: 0.3165509\n",
      "\tspeed: 0.0349s/iter; left time: 569.2166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.64s\n",
      "Steps: 906 | Train Loss: 0.3686991 Vali Loss: 0.3131087 Test Loss: 0.3270348\n",
      "Validation loss decreased (0.511562 --> 0.313109).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3248578\n",
      "\tspeed: 0.1001s/iter; left time: 1621.7600s\n",
      "\titers: 200, epoch: 3 | loss: 0.3104042\n",
      "\tspeed: 0.0349s/iter; left time: 561.4313s\n",
      "\titers: 300, epoch: 3 | loss: 0.3376182\n",
      "\tspeed: 0.0341s/iter; left time: 545.5953s\n",
      "\titers: 400, epoch: 3 | loss: 0.3394467\n",
      "\tspeed: 0.0343s/iter; left time: 545.5419s\n",
      "\titers: 500, epoch: 3 | loss: 0.2990822\n",
      "\tspeed: 0.0339s/iter; left time: 536.5187s\n",
      "\titers: 600, epoch: 3 | loss: 0.3042310\n",
      "\tspeed: 0.0339s/iter; left time: 532.0965s\n",
      "\titers: 700, epoch: 3 | loss: 0.3323969\n",
      "\tspeed: 0.0342s/iter; left time: 534.5836s\n",
      "\titers: 800, epoch: 3 | loss: 0.3035555\n",
      "\tspeed: 0.0339s/iter; left time: 525.6814s\n",
      "\titers: 900, epoch: 3 | loss: 0.3116626\n",
      "\tspeed: 0.0339s/iter; left time: 521.6583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 906 | Train Loss: 0.2947043 Vali Loss: 0.2940332 Test Loss: 0.3160464\n",
      "Validation loss decreased (0.313109 --> 0.294033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2995817\n",
      "\tspeed: 0.0997s/iter; left time: 1526.2637s\n",
      "\titers: 200, epoch: 4 | loss: 0.2934629\n",
      "\tspeed: 0.0339s/iter; left time: 514.8744s\n",
      "\titers: 300, epoch: 4 | loss: 0.2882073\n",
      "\tspeed: 0.0339s/iter; left time: 511.8393s\n",
      "\titers: 400, epoch: 4 | loss: 0.3170375\n",
      "\tspeed: 0.0339s/iter; left time: 508.3991s\n",
      "\titers: 500, epoch: 4 | loss: 0.2726417\n",
      "\tspeed: 0.0339s/iter; left time: 505.0925s\n",
      "\titers: 600, epoch: 4 | loss: 0.2414161\n",
      "\tspeed: 0.0338s/iter; left time: 500.6393s\n",
      "\titers: 700, epoch: 4 | loss: 0.2557601\n",
      "\tspeed: 0.0338s/iter; left time: 497.5288s\n",
      "\titers: 800, epoch: 4 | loss: 0.2488077\n",
      "\tspeed: 0.0339s/iter; left time: 494.5333s\n",
      "\titers: 900, epoch: 4 | loss: 0.2443915\n",
      "\tspeed: 0.0338s/iter; left time: 490.6099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.2716590 Vali Loss: 0.2789083 Test Loss: 0.2936148\n",
      "Validation loss decreased (0.294033 --> 0.278908).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2684618\n",
      "\tspeed: 0.1069s/iter; left time: 1538.9919s\n",
      "\titers: 200, epoch: 5 | loss: 0.2672735\n",
      "\tspeed: 0.0340s/iter; left time: 485.7885s\n",
      "\titers: 300, epoch: 5 | loss: 0.2425468\n",
      "\tspeed: 0.0340s/iter; left time: 482.7028s\n",
      "\titers: 400, epoch: 5 | loss: 0.2533128\n",
      "\tspeed: 0.0340s/iter; left time: 479.0694s\n",
      "\titers: 500, epoch: 5 | loss: 0.2253986\n",
      "\tspeed: 0.0340s/iter; left time: 475.4910s\n",
      "\titers: 600, epoch: 5 | loss: 0.2379989\n",
      "\tspeed: 0.0340s/iter; left time: 471.8871s\n",
      "\titers: 700, epoch: 5 | loss: 0.2820895\n",
      "\tspeed: 0.0341s/iter; left time: 470.4363s\n",
      "\titers: 800, epoch: 5 | loss: 0.2459406\n",
      "\tspeed: 0.0341s/iter; left time: 466.4493s\n",
      "\titers: 900, epoch: 5 | loss: 0.2406927\n",
      "\tspeed: 0.0340s/iter; left time: 462.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.25s\n",
      "Steps: 906 | Train Loss: 0.2536611 Vali Loss: 0.2668717 Test Loss: 0.2931617\n",
      "Validation loss decreased (0.278908 --> 0.266872).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2555949\n",
      "\tspeed: 0.1015s/iter; left time: 1369.7105s\n",
      "\titers: 200, epoch: 6 | loss: 0.2747200\n",
      "\tspeed: 0.0343s/iter; left time: 458.7016s\n",
      "\titers: 300, epoch: 6 | loss: 0.2372826\n",
      "\tspeed: 0.0346s/iter; left time: 459.5398s\n",
      "\titers: 400, epoch: 6 | loss: 0.2450917\n",
      "\tspeed: 0.0405s/iter; left time: 534.4399s\n",
      "\titers: 500, epoch: 6 | loss: 0.2472010\n",
      "\tspeed: 0.0354s/iter; left time: 463.7898s\n",
      "\titers: 600, epoch: 6 | loss: 0.2732914\n",
      "\tspeed: 0.0345s/iter; left time: 448.5591s\n",
      "\titers: 700, epoch: 6 | loss: 0.2402885\n",
      "\tspeed: 0.0345s/iter; left time: 444.8679s\n",
      "\titers: 800, epoch: 6 | loss: 0.2672409\n",
      "\tspeed: 0.0344s/iter; left time: 439.5768s\n",
      "\titers: 900, epoch: 6 | loss: 0.2654998\n",
      "\tspeed: 0.0351s/iter; left time: 446.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.39s\n",
      "Steps: 906 | Train Loss: 0.2429160 Vali Loss: 0.2640632 Test Loss: 0.2889231\n",
      "Validation loss decreased (0.266872 --> 0.264063).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2346262\n",
      "\tspeed: 0.1027s/iter; left time: 1292.1836s\n",
      "\titers: 200, epoch: 7 | loss: 0.2617931\n",
      "\tspeed: 0.0349s/iter; left time: 435.6158s\n",
      "\titers: 300, epoch: 7 | loss: 0.2259984\n",
      "\tspeed: 0.0346s/iter; left time: 428.5175s\n",
      "\titers: 400, epoch: 7 | loss: 0.2281683\n",
      "\tspeed: 0.0343s/iter; left time: 421.1534s\n",
      "\titers: 500, epoch: 7 | loss: 0.2626810\n",
      "\tspeed: 0.0342s/iter; left time: 416.5905s\n",
      "\titers: 600, epoch: 7 | loss: 0.2366604\n",
      "\tspeed: 0.0342s/iter; left time: 413.6787s\n",
      "\titers: 700, epoch: 7 | loss: 0.2192871\n",
      "\tspeed: 0.0342s/iter; left time: 410.4622s\n",
      "\titers: 800, epoch: 7 | loss: 0.2370833\n",
      "\tspeed: 0.0344s/iter; left time: 409.4300s\n",
      "\titers: 900, epoch: 7 | loss: 0.2349571\n",
      "\tspeed: 0.0345s/iter; left time: 406.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.2354462 Vali Loss: 0.2644266 Test Loss: 0.2913823\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1830552\n",
      "\tspeed: 0.0973s/iter; left time: 1136.8483s\n",
      "\titers: 200, epoch: 8 | loss: 0.2538224\n",
      "\tspeed: 0.0341s/iter; left time: 394.9485s\n",
      "\titers: 300, epoch: 8 | loss: 0.2418500\n",
      "\tspeed: 0.0340s/iter; left time: 389.9094s\n",
      "\titers: 400, epoch: 8 | loss: 0.2386716\n",
      "\tspeed: 0.0340s/iter; left time: 386.4850s\n",
      "\titers: 500, epoch: 8 | loss: 0.1947086\n",
      "\tspeed: 0.0340s/iter; left time: 383.0922s\n",
      "\titers: 600, epoch: 8 | loss: 0.2320862\n",
      "\tspeed: 0.0339s/iter; left time: 379.2164s\n",
      "\titers: 700, epoch: 8 | loss: 0.2298824\n",
      "\tspeed: 0.0339s/iter; left time: 375.9651s\n",
      "\titers: 800, epoch: 8 | loss: 0.1883690\n",
      "\tspeed: 0.0339s/iter; left time: 372.6312s\n",
      "\titers: 900, epoch: 8 | loss: 0.2138232\n",
      "\tspeed: 0.0339s/iter; left time: 369.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 906 | Train Loss: 0.2271026 Vali Loss: 0.2587540 Test Loss: 0.2875906\n",
      "Validation loss decreased (0.264063 --> 0.258754).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2176123\n",
      "\tspeed: 0.0988s/iter; left time: 1064.1211s\n",
      "\titers: 200, epoch: 9 | loss: 0.2035575\n",
      "\tspeed: 0.0363s/iter; left time: 387.4000s\n",
      "\titers: 300, epoch: 9 | loss: 0.2226921\n",
      "\tspeed: 0.0351s/iter; left time: 370.8285s\n",
      "\titers: 400, epoch: 9 | loss: 0.2053939\n",
      "\tspeed: 0.0341s/iter; left time: 356.8931s\n",
      "\titers: 500, epoch: 9 | loss: 0.1981095\n",
      "\tspeed: 0.0340s/iter; left time: 352.7794s\n",
      "\titers: 600, epoch: 9 | loss: 0.1822217\n",
      "\tspeed: 0.0340s/iter; left time: 349.1357s\n",
      "\titers: 700, epoch: 9 | loss: 0.2238019\n",
      "\tspeed: 0.0340s/iter; left time: 345.8724s\n",
      "\titers: 800, epoch: 9 | loss: 0.1825190\n",
      "\tspeed: 0.0341s/iter; left time: 343.0124s\n",
      "\titers: 900, epoch: 9 | loss: 0.2395900\n",
      "\tspeed: 0.0341s/iter; left time: 340.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.53s\n",
      "Steps: 906 | Train Loss: 0.2214897 Vali Loss: 0.2593712 Test Loss: 0.2963578\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2218790\n",
      "\tspeed: 0.0977s/iter; left time: 963.9511s\n",
      "\titers: 200, epoch: 10 | loss: 0.2058903\n",
      "\tspeed: 0.0341s/iter; left time: 332.8205s\n",
      "\titers: 300, epoch: 10 | loss: 0.2067299\n",
      "\tspeed: 0.0340s/iter; left time: 328.8268s\n",
      "\titers: 400, epoch: 10 | loss: 0.2327244\n",
      "\tspeed: 0.0340s/iter; left time: 325.4464s\n",
      "\titers: 500, epoch: 10 | loss: 0.2417444\n",
      "\tspeed: 0.0340s/iter; left time: 322.2776s\n",
      "\titers: 600, epoch: 10 | loss: 0.2235382\n",
      "\tspeed: 0.0346s/iter; left time: 323.6664s\n",
      "\titers: 700, epoch: 10 | loss: 0.2144483\n",
      "\tspeed: 0.0365s/iter; left time: 338.3524s\n",
      "\titers: 800, epoch: 10 | loss: 0.2096810\n",
      "\tspeed: 0.0340s/iter; left time: 311.8697s\n",
      "\titers: 900, epoch: 10 | loss: 0.2171047\n",
      "\tspeed: 0.0341s/iter; left time: 309.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.2153846 Vali Loss: 0.2574945 Test Loss: 0.2927481\n",
      "Validation loss decreased (0.258754 --> 0.257495).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2301479\n",
      "\tspeed: 0.1007s/iter; left time: 902.1748s\n",
      "\titers: 200, epoch: 11 | loss: 0.2008647\n",
      "\tspeed: 0.0341s/iter; left time: 301.8751s\n",
      "\titers: 300, epoch: 11 | loss: 0.2157522\n",
      "\tspeed: 0.0339s/iter; left time: 297.3087s\n",
      "\titers: 400, epoch: 11 | loss: 0.1913736\n",
      "\tspeed: 0.0340s/iter; left time: 294.0454s\n",
      "\titers: 500, epoch: 11 | loss: 0.2268346\n",
      "\tspeed: 0.0343s/iter; left time: 293.4995s\n",
      "\titers: 600, epoch: 11 | loss: 0.1990576\n",
      "\tspeed: 0.0348s/iter; left time: 294.5993s\n",
      "\titers: 700, epoch: 11 | loss: 0.2172936\n",
      "\tspeed: 0.0341s/iter; left time: 284.9891s\n",
      "\titers: 800, epoch: 11 | loss: 0.2108305\n",
      "\tspeed: 0.0342s/iter; left time: 282.2253s\n",
      "\titers: 900, epoch: 11 | loss: 0.1954345\n",
      "\tspeed: 0.0340s/iter; left time: 277.1427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.2085312 Vali Loss: 0.2502166 Test Loss: 0.2874845\n",
      "Validation loss decreased (0.257495 --> 0.250217).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2229073\n",
      "\tspeed: 0.0992s/iter; left time: 799.2608s\n",
      "\titers: 200, epoch: 12 | loss: 0.1990273\n",
      "\tspeed: 0.0339s/iter; left time: 269.3741s\n",
      "\titers: 300, epoch: 12 | loss: 0.1712727\n",
      "\tspeed: 0.0339s/iter; left time: 266.3533s\n",
      "\titers: 400, epoch: 12 | loss: 0.2289443\n",
      "\tspeed: 0.0339s/iter; left time: 262.9226s\n",
      "\titers: 500, epoch: 12 | loss: 0.1975065\n",
      "\tspeed: 0.0339s/iter; left time: 259.6297s\n",
      "\titers: 600, epoch: 12 | loss: 0.1841236\n",
      "\tspeed: 0.0338s/iter; left time: 255.7116s\n",
      "\titers: 700, epoch: 12 | loss: 0.2272553\n",
      "\tspeed: 0.0338s/iter; left time: 252.3420s\n",
      "\titers: 800, epoch: 12 | loss: 0.2318992\n",
      "\tspeed: 0.0339s/iter; left time: 249.0035s\n",
      "\titers: 900, epoch: 12 | loss: 0.2339026\n",
      "\tspeed: 0.0339s/iter; left time: 245.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.2034071 Vali Loss: 0.2586461 Test Loss: 0.2955900\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2241617\n",
      "\tspeed: 0.0966s/iter; left time: 690.6865s\n",
      "\titers: 200, epoch: 13 | loss: 0.1947532\n",
      "\tspeed: 0.0338s/iter; left time: 238.4275s\n",
      "\titers: 300, epoch: 13 | loss: 0.2012825\n",
      "\tspeed: 0.0338s/iter; left time: 235.1463s\n",
      "\titers: 400, epoch: 13 | loss: 0.1966165\n",
      "\tspeed: 0.0338s/iter; left time: 231.7203s\n",
      "\titers: 500, epoch: 13 | loss: 0.1795271\n",
      "\tspeed: 0.0339s/iter; left time: 228.7104s\n",
      "\titers: 600, epoch: 13 | loss: 0.2057489\n",
      "\tspeed: 0.0339s/iter; left time: 225.5134s\n",
      "\titers: 700, epoch: 13 | loss: 0.1910412\n",
      "\tspeed: 0.0339s/iter; left time: 222.2113s\n",
      "\titers: 800, epoch: 13 | loss: 0.2234772\n",
      "\tspeed: 0.0339s/iter; left time: 218.8476s\n",
      "\titers: 900, epoch: 13 | loss: 0.2019629\n",
      "\tspeed: 0.0339s/iter; left time: 215.2721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.1983099 Vali Loss: 0.2533231 Test Loss: 0.2934811\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1884299\n",
      "\tspeed: 0.0980s/iter; left time: 612.1124s\n",
      "\titers: 200, epoch: 14 | loss: 0.1966136\n",
      "\tspeed: 0.0346s/iter; left time: 212.2784s\n",
      "\titers: 300, epoch: 14 | loss: 0.1892714\n",
      "\tspeed: 0.0343s/iter; left time: 207.1072s\n",
      "\titers: 400, epoch: 14 | loss: 0.2000536\n",
      "\tspeed: 0.0340s/iter; left time: 202.0620s\n",
      "\titers: 500, epoch: 14 | loss: 0.1841666\n",
      "\tspeed: 0.0340s/iter; left time: 198.7659s\n",
      "\titers: 600, epoch: 14 | loss: 0.1922470\n",
      "\tspeed: 0.0340s/iter; left time: 195.4203s\n",
      "\titers: 700, epoch: 14 | loss: 0.1614933\n",
      "\tspeed: 0.0344s/iter; left time: 194.1109s\n",
      "\titers: 800, epoch: 14 | loss: 0.1737023\n",
      "\tspeed: 0.0341s/iter; left time: 188.9061s\n",
      "\titers: 900, epoch: 14 | loss: 0.1729180\n",
      "\tspeed: 0.0340s/iter; left time: 184.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 906 | Train Loss: 0.1931991 Vali Loss: 0.2533685 Test Loss: 0.2941910\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1858988\n",
      "\tspeed: 0.0983s/iter; left time: 524.3804s\n",
      "\titers: 200, epoch: 15 | loss: 0.1837891\n",
      "\tspeed: 0.0340s/iter; left time: 178.1682s\n",
      "\titers: 300, epoch: 15 | loss: 0.1667529\n",
      "\tspeed: 0.0339s/iter; left time: 174.2987s\n",
      "\titers: 400, epoch: 15 | loss: 0.1838070\n",
      "\tspeed: 0.0340s/iter; left time: 171.2412s\n",
      "\titers: 500, epoch: 15 | loss: 0.1899248\n",
      "\tspeed: 0.0340s/iter; left time: 167.9039s\n",
      "\titers: 600, epoch: 15 | loss: 0.1748391\n",
      "\tspeed: 0.0340s/iter; left time: 164.2237s\n",
      "\titers: 700, epoch: 15 | loss: 0.1809646\n",
      "\tspeed: 0.0339s/iter; left time: 160.6359s\n",
      "\titers: 800, epoch: 15 | loss: 0.1861439\n",
      "\tspeed: 0.0339s/iter; left time: 157.2535s\n",
      "\titers: 900, epoch: 15 | loss: 0.2107728\n",
      "\tspeed: 0.0339s/iter; left time: 153.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.1893874 Vali Loss: 0.2593920 Test Loss: 0.2968885\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1857413\n",
      "\tspeed: 0.0976s/iter; left time: 432.3789s\n",
      "\titers: 200, epoch: 16 | loss: 0.1785059\n",
      "\tspeed: 0.0340s/iter; left time: 147.1792s\n",
      "\titers: 300, epoch: 16 | loss: 0.1736346\n",
      "\tspeed: 0.0340s/iter; left time: 143.8004s\n",
      "\titers: 400, epoch: 16 | loss: 0.1825679\n",
      "\tspeed: 0.0340s/iter; left time: 140.3153s\n",
      "\titers: 500, epoch: 16 | loss: 0.2179714\n",
      "\tspeed: 0.0340s/iter; left time: 136.9408s\n",
      "\titers: 600, epoch: 16 | loss: 0.2274287\n",
      "\tspeed: 0.0343s/iter; left time: 134.7662s\n",
      "\titers: 700, epoch: 16 | loss: 0.1838266\n",
      "\tspeed: 0.0347s/iter; left time: 132.7623s\n",
      "\titers: 800, epoch: 16 | loss: 0.1999750\n",
      "\tspeed: 0.0344s/iter; left time: 128.3766s\n",
      "\titers: 900, epoch: 16 | loss: 0.1783324\n",
      "\tspeed: 0.0343s/iter; left time: 124.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 906 | Train Loss: 0.1851401 Vali Loss: 0.2566799 Test Loss: 0.2909570\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.24686580896377563, rmse:0.4968559145927429, mae:0.28736209869384766, rse:0.4550393223762512\n",
      "Original data scale mse:1826092.875, rmse:1351.330078125, mae:822.8323974609375, rse:0.09496114403009415\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8383211\n",
      "\tspeed: 0.0653s/iter; left time: 1173.5769s\n",
      "\titers: 200, epoch: 1 | loss: 0.8108377\n",
      "\tspeed: 0.0418s/iter; left time: 747.4243s\n",
      "\titers: 300, epoch: 1 | loss: 0.7487994\n",
      "\tspeed: 0.0418s/iter; left time: 743.0861s\n",
      "\titers: 400, epoch: 1 | loss: 0.7525495\n",
      "\tspeed: 0.0418s/iter; left time: 739.4470s\n",
      "\titers: 500, epoch: 1 | loss: 0.7426373\n",
      "\tspeed: 0.0418s/iter; left time: 735.2429s\n",
      "\titers: 600, epoch: 1 | loss: 0.7099434\n",
      "\tspeed: 0.0419s/iter; left time: 732.3205s\n",
      "\titers: 700, epoch: 1 | loss: 0.6974299\n",
      "\tspeed: 0.0417s/iter; left time: 724.8062s\n",
      "\titers: 800, epoch: 1 | loss: 0.6691788\n",
      "\tspeed: 0.0419s/iter; left time: 724.5198s\n",
      "\titers: 900, epoch: 1 | loss: 0.6981372\n",
      "\tspeed: 0.0415s/iter; left time: 712.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 904 | Train Loss: 0.7464296 Vali Loss: 0.6469953 Test Loss: 0.7045324\n",
      "Validation loss decreased (inf --> 0.646995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6251701\n",
      "\tspeed: 0.1176s/iter; left time: 2008.2574s\n",
      "\titers: 200, epoch: 2 | loss: 0.5603802\n",
      "\tspeed: 0.0414s/iter; left time: 702.3192s\n",
      "\titers: 300, epoch: 2 | loss: 0.5274128\n",
      "\tspeed: 0.0415s/iter; left time: 699.9229s\n",
      "\titers: 400, epoch: 2 | loss: 0.5067791\n",
      "\tspeed: 0.0414s/iter; left time: 693.8739s\n",
      "\titers: 500, epoch: 2 | loss: 0.4797787\n",
      "\tspeed: 0.0417s/iter; left time: 695.0364s\n",
      "\titers: 600, epoch: 2 | loss: 0.4395908\n",
      "\tspeed: 0.0413s/iter; left time: 685.4032s\n",
      "\titers: 700, epoch: 2 | loss: 0.4545476\n",
      "\tspeed: 0.0417s/iter; left time: 687.8523s\n",
      "\titers: 800, epoch: 2 | loss: 0.3988128\n",
      "\tspeed: 0.0414s/iter; left time: 678.6129s\n",
      "\titers: 900, epoch: 2 | loss: 0.3793740\n",
      "\tspeed: 0.0414s/iter; left time: 673.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.4918764 Vali Loss: 0.3900858 Test Loss: 0.4283516\n",
      "Validation loss decreased (0.646995 --> 0.390086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3864315\n",
      "\tspeed: 0.1185s/iter; left time: 1917.1204s\n",
      "\titers: 200, epoch: 3 | loss: 0.3820163\n",
      "\tspeed: 0.0413s/iter; left time: 664.2274s\n",
      "\titers: 300, epoch: 3 | loss: 0.3891534\n",
      "\tspeed: 0.0413s/iter; left time: 659.8139s\n",
      "\titers: 400, epoch: 3 | loss: 0.3794254\n",
      "\tspeed: 0.0414s/iter; left time: 656.4923s\n",
      "\titers: 500, epoch: 3 | loss: 0.3649262\n",
      "\tspeed: 0.0413s/iter; left time: 651.9179s\n",
      "\titers: 600, epoch: 3 | loss: 0.3812293\n",
      "\tspeed: 0.0414s/iter; left time: 648.5767s\n",
      "\titers: 700, epoch: 3 | loss: 0.3435830\n",
      "\tspeed: 0.0414s/iter; left time: 645.1559s\n",
      "\titers: 800, epoch: 3 | loss: 0.3802772\n",
      "\tspeed: 0.0415s/iter; left time: 642.1754s\n",
      "\titers: 900, epoch: 3 | loss: 0.3358185\n",
      "\tspeed: 0.0414s/iter; left time: 636.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 904 | Train Loss: 0.3763502 Vali Loss: 0.3668233 Test Loss: 0.4086022\n",
      "Validation loss decreased (0.390086 --> 0.366823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3388253\n",
      "\tspeed: 0.1183s/iter; left time: 1805.7707s\n",
      "\titers: 200, epoch: 4 | loss: 0.3721622\n",
      "\tspeed: 0.0414s/iter; left time: 627.9257s\n",
      "\titers: 300, epoch: 4 | loss: 0.3599882\n",
      "\tspeed: 0.0415s/iter; left time: 625.8189s\n",
      "\titers: 400, epoch: 4 | loss: 0.3544451\n",
      "\tspeed: 0.0420s/iter; left time: 628.7361s\n",
      "\titers: 500, epoch: 4 | loss: 0.3182427\n",
      "\tspeed: 0.0414s/iter; left time: 615.1228s\n",
      "\titers: 600, epoch: 4 | loss: 0.3322238\n",
      "\tspeed: 0.0414s/iter; left time: 611.8646s\n",
      "\titers: 700, epoch: 4 | loss: 0.3566774\n",
      "\tspeed: 0.0415s/iter; left time: 608.6212s\n",
      "\titers: 800, epoch: 4 | loss: 0.3220068\n",
      "\tspeed: 0.0413s/iter; left time: 602.2258s\n",
      "\titers: 900, epoch: 4 | loss: 0.3489531\n",
      "\tspeed: 0.0414s/iter; left time: 598.7028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.3491607 Vali Loss: 0.3521785 Test Loss: 0.3988023\n",
      "Validation loss decreased (0.366823 --> 0.352178).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3495132\n",
      "\tspeed: 0.1209s/iter; left time: 1736.9198s\n",
      "\titers: 200, epoch: 5 | loss: 0.3170395\n",
      "\tspeed: 0.0418s/iter; left time: 596.8157s\n",
      "\titers: 300, epoch: 5 | loss: 0.3389655\n",
      "\tspeed: 0.0414s/iter; left time: 585.9318s\n",
      "\titers: 400, epoch: 5 | loss: 0.3256942\n",
      "\tspeed: 0.0413s/iter; left time: 581.3119s\n",
      "\titers: 500, epoch: 5 | loss: 0.3274678\n",
      "\tspeed: 0.0414s/iter; left time: 577.5585s\n",
      "\titers: 600, epoch: 5 | loss: 0.3450095\n",
      "\tspeed: 0.0414s/iter; left time: 573.4128s\n",
      "\titers: 700, epoch: 5 | loss: 0.3169552\n",
      "\tspeed: 0.0414s/iter; left time: 569.5539s\n",
      "\titers: 800, epoch: 5 | loss: 0.3412271\n",
      "\tspeed: 0.0413s/iter; left time: 565.0259s\n",
      "\titers: 900, epoch: 5 | loss: 0.3274842\n",
      "\tspeed: 0.0414s/iter; left time: 561.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.3309019 Vali Loss: 0.3555303 Test Loss: 0.4009160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3440494\n",
      "\tspeed: 0.1167s/iter; left time: 1570.7932s\n",
      "\titers: 200, epoch: 6 | loss: 0.3232962\n",
      "\tspeed: 0.0416s/iter; left time: 555.1984s\n",
      "\titers: 300, epoch: 6 | loss: 0.3273665\n",
      "\tspeed: 0.0414s/iter; left time: 549.3115s\n",
      "\titers: 400, epoch: 6 | loss: 0.3051603\n",
      "\tspeed: 0.0414s/iter; left time: 544.9936s\n",
      "\titers: 500, epoch: 6 | loss: 0.3102055\n",
      "\tspeed: 0.0416s/iter; left time: 543.6539s\n",
      "\titers: 600, epoch: 6 | loss: 0.2952942\n",
      "\tspeed: 0.0414s/iter; left time: 536.4586s\n",
      "\titers: 700, epoch: 6 | loss: 0.3103990\n",
      "\tspeed: 0.0414s/iter; left time: 531.8843s\n",
      "\titers: 800, epoch: 6 | loss: 0.3272519\n",
      "\tspeed: 0.0414s/iter; left time: 527.9191s\n",
      "\titers: 900, epoch: 6 | loss: 0.3103123\n",
      "\tspeed: 0.0414s/iter; left time: 524.4814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.3164206 Vali Loss: 0.3586283 Test Loss: 0.4085577\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3052976\n",
      "\tspeed: 0.1152s/iter; left time: 1446.7449s\n",
      "\titers: 200, epoch: 7 | loss: 0.3133456\n",
      "\tspeed: 0.0419s/iter; left time: 522.3375s\n",
      "\titers: 300, epoch: 7 | loss: 0.3072406\n",
      "\tspeed: 0.0419s/iter; left time: 517.8110s\n",
      "\titers: 400, epoch: 7 | loss: 0.2910472\n",
      "\tspeed: 0.0419s/iter; left time: 513.1108s\n",
      "\titers: 500, epoch: 7 | loss: 0.2922503\n",
      "\tspeed: 0.0419s/iter; left time: 509.2162s\n",
      "\titers: 600, epoch: 7 | loss: 0.2615238\n",
      "\tspeed: 0.0419s/iter; left time: 505.1930s\n",
      "\titers: 700, epoch: 7 | loss: 0.3093769\n",
      "\tspeed: 0.0419s/iter; left time: 501.0696s\n",
      "\titers: 800, epoch: 7 | loss: 0.2548462\n",
      "\tspeed: 0.0416s/iter; left time: 492.9135s\n",
      "\titers: 900, epoch: 7 | loss: 0.3276073\n",
      "\tspeed: 0.0414s/iter; left time: 486.7703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 904 | Train Loss: 0.3029163 Vali Loss: 0.3588283 Test Loss: 0.4076912\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3191033\n",
      "\tspeed: 0.1179s/iter; left time: 1373.4849s\n",
      "\titers: 200, epoch: 8 | loss: 0.3188753\n",
      "\tspeed: 0.0448s/iter; left time: 517.9081s\n",
      "\titers: 300, epoch: 8 | loss: 0.2980711\n",
      "\tspeed: 0.0415s/iter; left time: 475.0162s\n",
      "\titers: 400, epoch: 8 | loss: 0.2810050\n",
      "\tspeed: 0.0415s/iter; left time: 471.6157s\n",
      "\titers: 500, epoch: 8 | loss: 0.2956309\n",
      "\tspeed: 0.0414s/iter; left time: 465.3324s\n",
      "\titers: 600, epoch: 8 | loss: 0.2984770\n",
      "\tspeed: 0.0414s/iter; left time: 461.9350s\n",
      "\titers: 700, epoch: 8 | loss: 0.2803625\n",
      "\tspeed: 0.0414s/iter; left time: 457.2869s\n",
      "\titers: 800, epoch: 8 | loss: 0.2877884\n",
      "\tspeed: 0.0414s/iter; left time: 453.3284s\n",
      "\titers: 900, epoch: 8 | loss: 0.2755170\n",
      "\tspeed: 0.0414s/iter; left time: 449.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 904 | Train Loss: 0.2898394 Vali Loss: 0.3649037 Test Loss: 0.3977068\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2967520\n",
      "\tspeed: 0.1168s/iter; left time: 1255.3196s\n",
      "\titers: 200, epoch: 9 | loss: 0.2913543\n",
      "\tspeed: 0.0422s/iter; left time: 448.8681s\n",
      "\titers: 300, epoch: 9 | loss: 0.2876630\n",
      "\tspeed: 0.0420s/iter; left time: 443.1619s\n",
      "\titers: 400, epoch: 9 | loss: 0.2570240\n",
      "\tspeed: 0.0420s/iter; left time: 438.6263s\n",
      "\titers: 500, epoch: 9 | loss: 0.2957726\n",
      "\tspeed: 0.0420s/iter; left time: 434.7415s\n",
      "\titers: 600, epoch: 9 | loss: 0.2651407\n",
      "\tspeed: 0.0420s/iter; left time: 430.7348s\n",
      "\titers: 700, epoch: 9 | loss: 0.2553186\n",
      "\tspeed: 0.0420s/iter; left time: 426.4505s\n",
      "\titers: 800, epoch: 9 | loss: 0.2675749\n",
      "\tspeed: 0.0420s/iter; left time: 422.2663s\n",
      "\titers: 900, epoch: 9 | loss: 0.2746369\n",
      "\tspeed: 0.0420s/iter; left time: 418.1130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 904 | Train Loss: 0.2770038 Vali Loss: 0.3703353 Test Loss: 0.4194131\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.39344221353530884, rmse:0.6272497177124023, mae:0.39856094121932983, rse:0.5743128061294556\n",
      "Original data scale mse:3858870.0, rmse:1964.400634765625, mae:1243.5869140625, rse:0.1382429003715515\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8199379\n",
      "\tspeed: 0.0451s/iter; left time: 810.3872s\n",
      "\titers: 200, epoch: 1 | loss: 0.7898332\n",
      "\tspeed: 0.0420s/iter; left time: 750.8199s\n",
      "\titers: 300, epoch: 1 | loss: 0.7722702\n",
      "\tspeed: 0.0420s/iter; left time: 746.1721s\n",
      "\titers: 400, epoch: 1 | loss: 0.7732224\n",
      "\tspeed: 0.0420s/iter; left time: 741.7882s\n",
      "\titers: 500, epoch: 1 | loss: 0.7614213\n",
      "\tspeed: 0.0419s/iter; left time: 737.4261s\n",
      "\titers: 600, epoch: 1 | loss: 0.7319801\n",
      "\tspeed: 0.0420s/iter; left time: 733.4683s\n",
      "\titers: 700, epoch: 1 | loss: 0.7263533\n",
      "\tspeed: 0.0420s/iter; left time: 729.3916s\n",
      "\titers: 800, epoch: 1 | loss: 0.7189401\n",
      "\tspeed: 0.0419s/iter; left time: 724.9246s\n",
      "\titers: 900, epoch: 1 | loss: 0.6666726\n",
      "\tspeed: 0.0420s/iter; left time: 721.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 904 | Train Loss: 0.7548866 Vali Loss: 0.6545018 Test Loss: 0.7125702\n",
      "Validation loss decreased (inf --> 0.654502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6054710\n",
      "\tspeed: 0.1185s/iter; left time: 2022.8524s\n",
      "\titers: 200, epoch: 2 | loss: 0.5566018\n",
      "\tspeed: 0.0419s/iter; left time: 712.1550s\n",
      "\titers: 300, epoch: 2 | loss: 0.5130304\n",
      "\tspeed: 0.0419s/iter; left time: 707.1542s\n",
      "\titers: 400, epoch: 2 | loss: 0.4923959\n",
      "\tspeed: 0.0420s/iter; left time: 703.8537s\n",
      "\titers: 500, epoch: 2 | loss: 0.4707674\n",
      "\tspeed: 0.0420s/iter; left time: 700.2026s\n",
      "\titers: 600, epoch: 2 | loss: 0.4113571\n",
      "\tspeed: 0.0420s/iter; left time: 695.4649s\n",
      "\titers: 700, epoch: 2 | loss: 0.4029533\n",
      "\tspeed: 0.0420s/iter; left time: 692.2469s\n",
      "\titers: 800, epoch: 2 | loss: 0.3971385\n",
      "\tspeed: 0.0420s/iter; left time: 688.1749s\n",
      "\titers: 900, epoch: 2 | loss: 0.3858475\n",
      "\tspeed: 0.0420s/iter; left time: 684.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 904 | Train Loss: 0.4896726 Vali Loss: 0.3844998 Test Loss: 0.4152546\n",
      "Validation loss decreased (0.654502 --> 0.384500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3695807\n",
      "\tspeed: 0.1198s/iter; left time: 1938.2225s\n",
      "\titers: 200, epoch: 3 | loss: 0.3475830\n",
      "\tspeed: 0.0419s/iter; left time: 673.6783s\n",
      "\titers: 300, epoch: 3 | loss: 0.3649749\n",
      "\tspeed: 0.0420s/iter; left time: 671.6463s\n",
      "\titers: 400, epoch: 3 | loss: 0.3863128\n",
      "\tspeed: 0.0420s/iter; left time: 666.6130s\n",
      "\titers: 500, epoch: 3 | loss: 0.3991944\n",
      "\tspeed: 0.0420s/iter; left time: 662.7440s\n",
      "\titers: 600, epoch: 3 | loss: 0.3809673\n",
      "\tspeed: 0.0420s/iter; left time: 657.9608s\n",
      "\titers: 700, epoch: 3 | loss: 0.3624242\n",
      "\tspeed: 0.0420s/iter; left time: 653.7211s\n",
      "\titers: 800, epoch: 3 | loss: 0.3671079\n",
      "\tspeed: 0.0420s/iter; left time: 649.9965s\n",
      "\titers: 900, epoch: 3 | loss: 0.3738058\n",
      "\tspeed: 0.0420s/iter; left time: 646.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.3742228 Vali Loss: 0.3571097 Test Loss: 0.3996230\n",
      "Validation loss decreased (0.384500 --> 0.357110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664512\n",
      "\tspeed: 0.1198s/iter; left time: 1829.0188s\n",
      "\titers: 200, epoch: 4 | loss: 0.3314773\n",
      "\tspeed: 0.0420s/iter; left time: 636.4837s\n",
      "\titers: 300, epoch: 4 | loss: 0.3966455\n",
      "\tspeed: 0.0420s/iter; left time: 632.1969s\n",
      "\titers: 400, epoch: 4 | loss: 0.3476718\n",
      "\tspeed: 0.0420s/iter; left time: 628.4780s\n",
      "\titers: 500, epoch: 4 | loss: 0.3586818\n",
      "\tspeed: 0.0420s/iter; left time: 624.5701s\n",
      "\titers: 600, epoch: 4 | loss: 0.3437766\n",
      "\tspeed: 0.0420s/iter; left time: 619.9781s\n",
      "\titers: 700, epoch: 4 | loss: 0.3398677\n",
      "\tspeed: 0.0420s/iter; left time: 616.2251s\n",
      "\titers: 800, epoch: 4 | loss: 0.3371063\n",
      "\tspeed: 0.0420s/iter; left time: 612.1260s\n",
      "\titers: 900, epoch: 4 | loss: 0.3668114\n",
      "\tspeed: 0.0421s/iter; left time: 608.6679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 904 | Train Loss: 0.3487260 Vali Loss: 0.3569884 Test Loss: 0.3957511\n",
      "Validation loss decreased (0.357110 --> 0.356988).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2999336\n",
      "\tspeed: 0.1202s/iter; left time: 1726.1044s\n",
      "\titers: 200, epoch: 5 | loss: 0.3082600\n",
      "\tspeed: 0.0419s/iter; left time: 598.2346s\n",
      "\titers: 300, epoch: 5 | loss: 0.3240241\n",
      "\tspeed: 0.0420s/iter; left time: 594.2748s\n",
      "\titers: 400, epoch: 5 | loss: 0.3353963\n",
      "\tspeed: 0.0420s/iter; left time: 590.1750s\n",
      "\titers: 500, epoch: 5 | loss: 0.3540320\n",
      "\tspeed: 0.0420s/iter; left time: 585.8330s\n",
      "\titers: 600, epoch: 5 | loss: 0.3242840\n",
      "\tspeed: 0.0419s/iter; left time: 581.4963s\n",
      "\titers: 700, epoch: 5 | loss: 0.3317428\n",
      "\tspeed: 0.0420s/iter; left time: 577.8069s\n",
      "\titers: 800, epoch: 5 | loss: 0.2974713\n",
      "\tspeed: 0.0420s/iter; left time: 573.4944s\n",
      "\titers: 900, epoch: 5 | loss: 0.3152562\n",
      "\tspeed: 0.0420s/iter; left time: 569.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.3308475 Vali Loss: 0.3496060 Test Loss: 0.3909149\n",
      "Validation loss decreased (0.356988 --> 0.349606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3116693\n",
      "\tspeed: 0.1207s/iter; left time: 1625.2660s\n",
      "\titers: 200, epoch: 6 | loss: 0.3399734\n",
      "\tspeed: 0.0419s/iter; left time: 559.7541s\n",
      "\titers: 300, epoch: 6 | loss: 0.3279870\n",
      "\tspeed: 0.0418s/iter; left time: 554.5090s\n",
      "\titers: 400, epoch: 6 | loss: 0.3133242\n",
      "\tspeed: 0.0414s/iter; left time: 544.5402s\n",
      "\titers: 500, epoch: 6 | loss: 0.3107831\n",
      "\tspeed: 0.0414s/iter; left time: 540.9897s\n",
      "\titers: 600, epoch: 6 | loss: 0.3219745\n",
      "\tspeed: 0.0415s/iter; left time: 537.7276s\n",
      "\titers: 700, epoch: 6 | loss: 0.3320111\n",
      "\tspeed: 0.0420s/iter; left time: 539.7526s\n",
      "\titers: 800, epoch: 6 | loss: 0.3236458\n",
      "\tspeed: 0.0420s/iter; left time: 535.7631s\n",
      "\titers: 900, epoch: 6 | loss: 0.3211843\n",
      "\tspeed: 0.0420s/iter; left time: 531.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 904 | Train Loss: 0.3172246 Vali Loss: 0.3559603 Test Loss: 0.4093479\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2828401\n",
      "\tspeed: 0.1149s/iter; left time: 1442.6600s\n",
      "\titers: 200, epoch: 7 | loss: 0.3029595\n",
      "\tspeed: 0.0420s/iter; left time: 523.1839s\n",
      "\titers: 300, epoch: 7 | loss: 0.3417799\n",
      "\tspeed: 0.0419s/iter; left time: 518.1028s\n",
      "\titers: 400, epoch: 7 | loss: 0.3438331\n",
      "\tspeed: 0.0420s/iter; left time: 514.9294s\n",
      "\titers: 500, epoch: 7 | loss: 0.3004263\n",
      "\tspeed: 0.0420s/iter; left time: 510.7581s\n",
      "\titers: 600, epoch: 7 | loss: 0.3186526\n",
      "\tspeed: 0.0420s/iter; left time: 506.8755s\n",
      "\titers: 700, epoch: 7 | loss: 0.3164782\n",
      "\tspeed: 0.0421s/iter; left time: 502.8578s\n",
      "\titers: 800, epoch: 7 | loss: 0.2901645\n",
      "\tspeed: 0.0420s/iter; left time: 498.2287s\n",
      "\titers: 900, epoch: 7 | loss: 0.3178932\n",
      "\tspeed: 0.0420s/iter; left time: 493.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 904 | Train Loss: 0.3042319 Vali Loss: 0.3581361 Test Loss: 0.3988625\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2602415\n",
      "\tspeed: 0.1155s/iter; left time: 1346.0426s\n",
      "\titers: 200, epoch: 8 | loss: 0.3170430\n",
      "\tspeed: 0.0420s/iter; left time: 484.7356s\n",
      "\titers: 300, epoch: 8 | loss: 0.2990391\n",
      "\tspeed: 0.0419s/iter; left time: 480.1860s\n",
      "\titers: 400, epoch: 8 | loss: 0.2823302\n",
      "\tspeed: 0.0420s/iter; left time: 476.3871s\n",
      "\titers: 500, epoch: 8 | loss: 0.2873409\n",
      "\tspeed: 0.0420s/iter; left time: 472.5069s\n",
      "\titers: 600, epoch: 8 | loss: 0.3031415\n",
      "\tspeed: 0.0420s/iter; left time: 468.6277s\n",
      "\titers: 700, epoch: 8 | loss: 0.2788299\n",
      "\tspeed: 0.0420s/iter; left time: 463.8403s\n",
      "\titers: 800, epoch: 8 | loss: 0.3087998\n",
      "\tspeed: 0.0420s/iter; left time: 459.5585s\n",
      "\titers: 900, epoch: 8 | loss: 0.2930878\n",
      "\tspeed: 0.0420s/iter; left time: 455.7069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 904 | Train Loss: 0.2919248 Vali Loss: 0.3591549 Test Loss: 0.4059212\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2556845\n",
      "\tspeed: 0.1149s/iter; left time: 1234.6983s\n",
      "\titers: 200, epoch: 9 | loss: 0.2650858\n",
      "\tspeed: 0.0417s/iter; left time: 444.5129s\n",
      "\titers: 300, epoch: 9 | loss: 0.2971595\n",
      "\tspeed: 0.0414s/iter; left time: 436.8628s\n",
      "\titers: 400, epoch: 9 | loss: 0.2512358\n",
      "\tspeed: 0.0417s/iter; left time: 436.1034s\n",
      "\titers: 500, epoch: 9 | loss: 0.2582754\n",
      "\tspeed: 0.0420s/iter; left time: 434.5903s\n",
      "\titers: 600, epoch: 9 | loss: 0.2680587\n",
      "\tspeed: 0.0420s/iter; left time: 430.2534s\n",
      "\titers: 700, epoch: 9 | loss: 0.2813241\n",
      "\tspeed: 0.0420s/iter; left time: 426.1757s\n",
      "\titers: 800, epoch: 9 | loss: 0.2732314\n",
      "\tspeed: 0.0420s/iter; left time: 422.0506s\n",
      "\titers: 900, epoch: 9 | loss: 0.2794602\n",
      "\tspeed: 0.0420s/iter; left time: 417.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 904 | Train Loss: 0.2796464 Vali Loss: 0.3686695 Test Loss: 0.4075675\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2603008\n",
      "\tspeed: 0.1149s/iter; left time: 1131.2135s\n",
      "\titers: 200, epoch: 10 | loss: 0.2586304\n",
      "\tspeed: 0.0420s/iter; left time: 409.1810s\n",
      "\titers: 300, epoch: 10 | loss: 0.2475962\n",
      "\tspeed: 0.0420s/iter; left time: 404.9118s\n",
      "\titers: 400, epoch: 10 | loss: 0.2669277\n",
      "\tspeed: 0.0420s/iter; left time: 400.9216s\n",
      "\titers: 500, epoch: 10 | loss: 0.2635143\n",
      "\tspeed: 0.0420s/iter; left time: 396.4880s\n",
      "\titers: 600, epoch: 10 | loss: 0.2986886\n",
      "\tspeed: 0.0420s/iter; left time: 392.3622s\n",
      "\titers: 700, epoch: 10 | loss: 0.2711323\n",
      "\tspeed: 0.0419s/iter; left time: 387.6187s\n",
      "\titers: 800, epoch: 10 | loss: 0.2517428\n",
      "\tspeed: 0.0419s/iter; left time: 383.2466s\n",
      "\titers: 900, epoch: 10 | loss: 0.2493394\n",
      "\tspeed: 0.0419s/iter; left time: 379.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.2685284 Vali Loss: 0.3674309 Test Loss: 0.4092806\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3954135477542877, rmse:0.6288191676139832, mae:0.39091774821281433, rse:0.5757498145103455\n",
      "Original data scale mse:3485771.25, rmse:1867.02197265625, mae:1180.413330078125, rse:0.13138996064662933\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8386888\n",
      "\tspeed: 0.0737s/iter; left time: 1321.7439s\n",
      "\titers: 200, epoch: 1 | loss: 0.7767119\n",
      "\tspeed: 0.0503s/iter; left time: 898.2134s\n",
      "\titers: 300, epoch: 1 | loss: 0.7999508\n",
      "\tspeed: 0.0504s/iter; left time: 893.7354s\n",
      "\titers: 400, epoch: 1 | loss: 0.7861756\n",
      "\tspeed: 0.0504s/iter; left time: 889.0640s\n",
      "\titers: 500, epoch: 1 | loss: 0.7626040\n",
      "\tspeed: 0.0504s/iter; left time: 884.7954s\n",
      "\titers: 600, epoch: 1 | loss: 0.7519255\n",
      "\tspeed: 0.0504s/iter; left time: 879.6041s\n",
      "\titers: 700, epoch: 1 | loss: 0.7320267\n",
      "\tspeed: 0.0505s/iter; left time: 874.9660s\n",
      "\titers: 800, epoch: 1 | loss: 0.7758175\n",
      "\tspeed: 0.0504s/iter; left time: 868.7405s\n",
      "\titers: 900, epoch: 1 | loss: 0.7158955\n",
      "\tspeed: 0.0505s/iter; left time: 865.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.18s\n",
      "Steps: 902 | Train Loss: 0.7664375 Vali Loss: 0.7075323 Test Loss: 0.7662670\n",
      "Validation loss decreased (inf --> 0.707532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6732107\n",
      "\tspeed: 0.1480s/iter; left time: 2521.9480s\n",
      "\titers: 200, epoch: 2 | loss: 0.6401315\n",
      "\tspeed: 0.0503s/iter; left time: 852.6989s\n",
      "\titers: 300, epoch: 2 | loss: 0.5777587\n",
      "\tspeed: 0.0503s/iter; left time: 847.6461s\n",
      "\titers: 400, epoch: 2 | loss: 0.5630979\n",
      "\tspeed: 0.0504s/iter; left time: 843.2710s\n",
      "\titers: 500, epoch: 2 | loss: 0.5167372\n",
      "\tspeed: 0.0504s/iter; left time: 838.0846s\n",
      "\titers: 600, epoch: 2 | loss: 0.4862550\n",
      "\tspeed: 0.0505s/iter; left time: 835.7801s\n",
      "\titers: 700, epoch: 2 | loss: 0.4620817\n",
      "\tspeed: 0.0505s/iter; left time: 829.3643s\n",
      "\titers: 800, epoch: 2 | loss: 0.4662473\n",
      "\tspeed: 0.0903s/iter; left time: 1474.8053s\n",
      "\titers: 900, epoch: 2 | loss: 0.4515149\n",
      "\tspeed: 0.0971s/iter; left time: 1576.7761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.65s\n",
      "Steps: 902 | Train Loss: 0.5536267 Vali Loss: 0.4260731 Test Loss: 0.4729285\n",
      "Validation loss decreased (0.707532 --> 0.426073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4396802\n",
      "\tspeed: 0.3528s/iter; left time: 5692.5780s\n",
      "\titers: 200, epoch: 3 | loss: 0.4173806\n",
      "\tspeed: 0.0514s/iter; left time: 824.3908s\n",
      "\titers: 300, epoch: 3 | loss: 0.4329699\n",
      "\tspeed: 0.0506s/iter; left time: 806.2272s\n",
      "\titers: 400, epoch: 3 | loss: 0.3772545\n",
      "\tspeed: 0.0509s/iter; left time: 805.5093s\n",
      "\titers: 500, epoch: 3 | loss: 0.4004540\n",
      "\tspeed: 0.0507s/iter; left time: 798.2453s\n",
      "\titers: 600, epoch: 3 | loss: 0.4173917\n",
      "\tspeed: 0.0503s/iter; left time: 786.7062s\n",
      "\titers: 700, epoch: 3 | loss: 0.4052222\n",
      "\tspeed: 0.0527s/iter; left time: 818.6487s\n",
      "\titers: 800, epoch: 3 | loss: 0.3826870\n",
      "\tspeed: 0.0940s/iter; left time: 1451.4205s\n",
      "\titers: 900, epoch: 3 | loss: 0.3948156\n",
      "\tspeed: 0.0950s/iter; left time: 1456.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:58.60s\n",
      "Steps: 902 | Train Loss: 0.4100614 Vali Loss: 0.3957162 Test Loss: 0.4352207\n",
      "Validation loss decreased (0.426073 --> 0.395716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3968251\n",
      "\tspeed: 0.3672s/iter; left time: 5594.1470s\n",
      "\titers: 200, epoch: 4 | loss: 0.3642872\n",
      "\tspeed: 0.0950s/iter; left time: 1438.5138s\n",
      "\titers: 300, epoch: 4 | loss: 0.3635365\n",
      "\tspeed: 0.0970s/iter; left time: 1458.0387s\n",
      "\titers: 400, epoch: 4 | loss: 0.3788294\n",
      "\tspeed: 0.0998s/iter; left time: 1490.7562s\n",
      "\titers: 500, epoch: 4 | loss: 0.3811561\n",
      "\tspeed: 0.1001s/iter; left time: 1485.1001s\n",
      "\titers: 600, epoch: 4 | loss: 0.3664599\n",
      "\tspeed: 0.0969s/iter; left time: 1427.6830s\n",
      "\titers: 700, epoch: 4 | loss: 0.3789595\n",
      "\tspeed: 0.0902s/iter; left time: 1319.8983s\n",
      "\titers: 800, epoch: 4 | loss: 0.3853952\n",
      "\tspeed: 0.0961s/iter; left time: 1396.6801s\n",
      "\titers: 900, epoch: 4 | loss: 0.3681802\n",
      "\tspeed: 0.0939s/iter; left time: 1354.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:27.92s\n",
      "Steps: 902 | Train Loss: 0.3784169 Vali Loss: 0.3868374 Test Loss: 0.4306439\n",
      "Validation loss decreased (0.395716 --> 0.386837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3649633\n",
      "\tspeed: 0.3705s/iter; left time: 5310.3815s\n",
      "\titers: 200, epoch: 5 | loss: 0.3490350\n",
      "\tspeed: 0.0956s/iter; left time: 1360.0486s\n",
      "\titers: 300, epoch: 5 | loss: 0.3636412\n",
      "\tspeed: 0.0960s/iter; left time: 1356.8245s\n",
      "\titers: 400, epoch: 5 | loss: 0.3641450\n",
      "\tspeed: 0.0948s/iter; left time: 1330.6610s\n",
      "\titers: 500, epoch: 5 | loss: 0.3341307\n",
      "\tspeed: 0.0936s/iter; left time: 1304.7714s\n",
      "\titers: 600, epoch: 5 | loss: 0.3797001\n",
      "\tspeed: 0.0967s/iter; left time: 1338.0155s\n",
      "\titers: 700, epoch: 5 | loss: 0.3485563\n",
      "\tspeed: 0.0952s/iter; left time: 1306.9669s\n",
      "\titers: 800, epoch: 5 | loss: 0.3388476\n",
      "\tspeed: 0.0961s/iter; left time: 1310.4828s\n",
      "\titers: 900, epoch: 5 | loss: 0.3723890\n",
      "\tspeed: 0.0930s/iter; left time: 1259.1508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.54s\n",
      "Steps: 902 | Train Loss: 0.3559481 Vali Loss: 0.3831001 Test Loss: 0.4196117\n",
      "Validation loss decreased (0.386837 --> 0.383100).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3469072\n",
      "\tspeed: 0.3543s/iter; left time: 4758.9186s\n",
      "\titers: 200, epoch: 6 | loss: 0.3737783\n",
      "\tspeed: 0.0935s/iter; left time: 1246.6893s\n",
      "\titers: 300, epoch: 6 | loss: 0.3646350\n",
      "\tspeed: 0.0955s/iter; left time: 1264.0707s\n",
      "\titers: 400, epoch: 6 | loss: 0.3260672\n",
      "\tspeed: 0.0942s/iter; left time: 1236.4866s\n",
      "\titers: 500, epoch: 6 | loss: 0.3435634\n",
      "\tspeed: 0.0983s/iter; left time: 1281.1962s\n",
      "\titers: 600, epoch: 6 | loss: 0.3408191\n",
      "\tspeed: 0.0987s/iter; left time: 1276.2365s\n",
      "\titers: 700, epoch: 6 | loss: 0.3294426\n",
      "\tspeed: 0.0980s/iter; left time: 1257.0874s\n",
      "\titers: 800, epoch: 6 | loss: 0.3630858\n",
      "\tspeed: 0.0951s/iter; left time: 1210.4843s\n",
      "\titers: 900, epoch: 6 | loss: 0.3402916\n",
      "\tspeed: 0.0925s/iter; left time: 1167.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:26.97s\n",
      "Steps: 902 | Train Loss: 0.3385338 Vali Loss: 0.3904967 Test Loss: 0.4167734\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3501703\n",
      "\tspeed: 0.3517s/iter; left time: 4406.9442s\n",
      "\titers: 200, epoch: 7 | loss: 0.3279740\n",
      "\tspeed: 0.1008s/iter; left time: 1252.8903s\n",
      "\titers: 300, epoch: 7 | loss: 0.3352202\n",
      "\tspeed: 0.0969s/iter; left time: 1194.8648s\n",
      "\titers: 400, epoch: 7 | loss: 0.3362536\n",
      "\tspeed: 0.0949s/iter; left time: 1160.2402s\n",
      "\titers: 500, epoch: 7 | loss: 0.3103307\n",
      "\tspeed: 0.0956s/iter; left time: 1159.0318s\n",
      "\titers: 600, epoch: 7 | loss: 0.3217272\n",
      "\tspeed: 0.0921s/iter; left time: 1108.2988s\n",
      "\titers: 700, epoch: 7 | loss: 0.2977997\n",
      "\tspeed: 0.0962s/iter; left time: 1147.7861s\n",
      "\titers: 800, epoch: 7 | loss: 0.3214873\n",
      "\tspeed: 0.0950s/iter; left time: 1123.5579s\n",
      "\titers: 900, epoch: 7 | loss: 0.3186432\n",
      "\tspeed: 0.0961s/iter; left time: 1127.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:27.39s\n",
      "Steps: 902 | Train Loss: 0.3220662 Vali Loss: 0.3914173 Test Loss: 0.4247347\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3205020\n",
      "\tspeed: 0.3635s/iter; left time: 4226.2578s\n",
      "\titers: 200, epoch: 8 | loss: 0.2960532\n",
      "\tspeed: 0.0962s/iter; left time: 1108.4759s\n",
      "\titers: 300, epoch: 8 | loss: 0.3353393\n",
      "\tspeed: 0.0925s/iter; left time: 1057.1800s\n",
      "\titers: 400, epoch: 8 | loss: 0.3150680\n",
      "\tspeed: 0.0936s/iter; left time: 1059.6877s\n",
      "\titers: 500, epoch: 8 | loss: 0.3207355\n",
      "\tspeed: 0.0959s/iter; left time: 1076.4467s\n",
      "\titers: 600, epoch: 8 | loss: 0.2978328\n",
      "\tspeed: 0.0975s/iter; left time: 1084.7598s\n",
      "\titers: 700, epoch: 8 | loss: 0.2973359\n",
      "\tspeed: 0.0904s/iter; left time: 996.3454s\n",
      "\titers: 800, epoch: 8 | loss: 0.3122501\n",
      "\tspeed: 0.0962s/iter; left time: 1050.9030s\n",
      "\titers: 900, epoch: 8 | loss: 0.2944843\n",
      "\tspeed: 0.0943s/iter; left time: 1021.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:26.63s\n",
      "Steps: 902 | Train Loss: 0.3073783 Vali Loss: 0.3943148 Test Loss: 0.4265362\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3039705\n",
      "\tspeed: 0.3696s/iter; left time: 3964.4607s\n",
      "\titers: 200, epoch: 9 | loss: 0.2958698\n",
      "\tspeed: 0.0962s/iter; left time: 1022.4470s\n",
      "\titers: 300, epoch: 9 | loss: 0.2885737\n",
      "\tspeed: 0.0914s/iter; left time: 962.0960s\n",
      "\titers: 400, epoch: 9 | loss: 0.2778230\n",
      "\tspeed: 0.0900s/iter; left time: 937.7901s\n",
      "\titers: 500, epoch: 9 | loss: 0.3009877\n",
      "\tspeed: 0.0944s/iter; left time: 974.6969s\n",
      "\titers: 600, epoch: 9 | loss: 0.2928385\n",
      "\tspeed: 0.0942s/iter; left time: 962.9409s\n",
      "\titers: 700, epoch: 9 | loss: 0.2911485\n",
      "\tspeed: 0.0971s/iter; left time: 982.8803s\n",
      "\titers: 800, epoch: 9 | loss: 0.2844459\n",
      "\tspeed: 0.0888s/iter; left time: 890.6502s\n",
      "\titers: 900, epoch: 9 | loss: 0.2819162\n",
      "\tspeed: 0.0915s/iter; left time: 907.8452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:25.08s\n",
      "Steps: 902 | Train Loss: 0.2932442 Vali Loss: 0.4037877 Test Loss: 0.4310252\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2766879\n",
      "\tspeed: 0.3546s/iter; left time: 3483.6437s\n",
      "\titers: 200, epoch: 10 | loss: 0.2959476\n",
      "\tspeed: 0.0971s/iter; left time: 944.5602s\n",
      "\titers: 300, epoch: 10 | loss: 0.2839685\n",
      "\tspeed: 0.0959s/iter; left time: 922.8257s\n",
      "\titers: 400, epoch: 10 | loss: 0.3043902\n",
      "\tspeed: 0.0988s/iter; left time: 940.8969s\n",
      "\titers: 500, epoch: 10 | loss: 0.2702967\n",
      "\tspeed: 0.0959s/iter; left time: 903.6966s\n",
      "\titers: 600, epoch: 10 | loss: 0.2772617\n",
      "\tspeed: 0.0940s/iter; left time: 876.7332s\n",
      "\titers: 700, epoch: 10 | loss: 0.2687672\n",
      "\tspeed: 0.0976s/iter; left time: 900.5011s\n",
      "\titers: 800, epoch: 10 | loss: 0.2917846\n",
      "\tspeed: 0.0956s/iter; left time: 872.5963s\n",
      "\titers: 900, epoch: 10 | loss: 0.2776245\n",
      "\tspeed: 0.0941s/iter; left time: 848.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:27.64s\n",
      "Steps: 902 | Train Loss: 0.2815167 Vali Loss: 0.3986365 Test Loss: 0.4349182\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4413832128047943, rmse:0.6643667817115784, mae:0.4195317327976227, rse:0.6084785461425781\n",
      "Original data scale mse:4175248.25, rmse:2043.3424072265625, mae:1301.3748779296875, rse:0.14393338561058044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7784766\n",
      "\tspeed: 0.1051s/iter; left time: 1886.4063s\n",
      "\titers: 200, epoch: 1 | loss: 0.7896916\n",
      "\tspeed: 0.0985s/iter; left time: 1757.2987s\n",
      "\titers: 300, epoch: 1 | loss: 0.7902033\n",
      "\tspeed: 0.0918s/iter; left time: 1628.6403s\n",
      "\titers: 400, epoch: 1 | loss: 0.7624885\n",
      "\tspeed: 0.0934s/iter; left time: 1647.3134s\n",
      "\titers: 500, epoch: 1 | loss: 0.7278655\n",
      "\tspeed: 0.0971s/iter; left time: 1702.8483s\n",
      "\titers: 600, epoch: 1 | loss: 0.7528731\n",
      "\tspeed: 0.0967s/iter; left time: 1686.4463s\n",
      "\titers: 700, epoch: 1 | loss: 0.7531111\n",
      "\tspeed: 0.0953s/iter; left time: 1652.6144s\n",
      "\titers: 800, epoch: 1 | loss: 0.7535094\n",
      "\tspeed: 0.0969s/iter; left time: 1671.2150s\n",
      "\titers: 900, epoch: 1 | loss: 0.7525874\n",
      "\tspeed: 0.0938s/iter; left time: 1607.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:27.20s\n",
      "Steps: 902 | Train Loss: 0.7659186 Vali Loss: 0.7060944 Test Loss: 0.7726647\n",
      "Validation loss decreased (inf --> 0.706094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6644260\n",
      "\tspeed: 0.3701s/iter; left time: 6306.7343s\n",
      "\titers: 200, epoch: 2 | loss: 0.6645716\n",
      "\tspeed: 0.0960s/iter; left time: 1626.5797s\n",
      "\titers: 300, epoch: 2 | loss: 0.6093845\n",
      "\tspeed: 0.1012s/iter; left time: 1703.8912s\n",
      "\titers: 400, epoch: 2 | loss: 0.5595481\n",
      "\tspeed: 0.0945s/iter; left time: 1581.6255s\n",
      "\titers: 500, epoch: 2 | loss: 0.5193203\n",
      "\tspeed: 0.0986s/iter; left time: 1639.8059s\n",
      "\titers: 600, epoch: 2 | loss: 0.4908947\n",
      "\tspeed: 0.0959s/iter; left time: 1586.0806s\n",
      "\titers: 700, epoch: 2 | loss: 0.4567055\n",
      "\tspeed: 0.0940s/iter; left time: 1544.4917s\n",
      "\titers: 800, epoch: 2 | loss: 0.4364720\n",
      "\tspeed: 0.0959s/iter; left time: 1566.4186s\n",
      "\titers: 900, epoch: 2 | loss: 0.4684008\n",
      "\tspeed: 0.0981s/iter; left time: 1593.2633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:27.80s\n",
      "Steps: 902 | Train Loss: 0.5568550 Vali Loss: 0.4213049 Test Loss: 0.4606712\n",
      "Validation loss decreased (0.706094 --> 0.421305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4066563\n",
      "\tspeed: 0.3577s/iter; left time: 5772.6383s\n",
      "\titers: 200, epoch: 3 | loss: 0.4342634\n",
      "\tspeed: 0.0849s/iter; left time: 1362.0426s\n",
      "\titers: 300, epoch: 3 | loss: 0.4141377\n",
      "\tspeed: 0.0970s/iter; left time: 1546.5807s\n",
      "\titers: 400, epoch: 3 | loss: 0.4156282\n",
      "\tspeed: 0.0958s/iter; left time: 1517.1146s\n",
      "\titers: 500, epoch: 3 | loss: 0.4311102\n",
      "\tspeed: 0.0964s/iter; left time: 1517.0737s\n",
      "\titers: 600, epoch: 3 | loss: 0.3911020\n",
      "\tspeed: 0.0961s/iter; left time: 1502.0571s\n",
      "\titers: 700, epoch: 3 | loss: 0.4083531\n",
      "\tspeed: 0.0940s/iter; left time: 1459.9208s\n",
      "\titers: 800, epoch: 3 | loss: 0.3869530\n",
      "\tspeed: 0.0937s/iter; left time: 1446.9170s\n",
      "\titers: 900, epoch: 3 | loss: 0.3895103\n",
      "\tspeed: 0.0936s/iter; left time: 1435.9621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.54s\n",
      "Steps: 902 | Train Loss: 0.4085787 Vali Loss: 0.3838962 Test Loss: 0.4258295\n",
      "Validation loss decreased (0.421305 --> 0.383896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4069133\n",
      "\tspeed: 0.3629s/iter; left time: 5529.0718s\n",
      "\titers: 200, epoch: 4 | loss: 0.3769518\n",
      "\tspeed: 0.0960s/iter; left time: 1453.6039s\n",
      "\titers: 300, epoch: 4 | loss: 0.3721721\n",
      "\tspeed: 0.0969s/iter; left time: 1457.1595s\n",
      "\titers: 400, epoch: 4 | loss: 0.3945597\n",
      "\tspeed: 0.0968s/iter; left time: 1445.8503s\n",
      "\titers: 500, epoch: 4 | loss: 0.4018272\n",
      "\tspeed: 0.0917s/iter; left time: 1360.2011s\n",
      "\titers: 600, epoch: 4 | loss: 0.3798145\n",
      "\tspeed: 0.0942s/iter; left time: 1388.3952s\n",
      "\titers: 700, epoch: 4 | loss: 0.3586749\n",
      "\tspeed: 0.0944s/iter; left time: 1382.2292s\n",
      "\titers: 800, epoch: 4 | loss: 0.3999881\n",
      "\tspeed: 0.0932s/iter; left time: 1354.5316s\n",
      "\titers: 900, epoch: 4 | loss: 0.3595868\n",
      "\tspeed: 0.0765s/iter; left time: 1103.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:24.92s\n",
      "Steps: 902 | Train Loss: 0.3765813 Vali Loss: 0.3696744 Test Loss: 0.4335620\n",
      "Validation loss decreased (0.383896 --> 0.369674).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3584996\n",
      "\tspeed: 0.1695s/iter; left time: 2429.2121s\n",
      "\titers: 200, epoch: 5 | loss: 0.3942734\n",
      "\tspeed: 0.0518s/iter; left time: 736.8605s\n",
      "\titers: 300, epoch: 5 | loss: 0.3189113\n",
      "\tspeed: 0.0517s/iter; left time: 730.4166s\n",
      "\titers: 400, epoch: 5 | loss: 0.3716736\n",
      "\tspeed: 0.0520s/iter; left time: 729.0283s\n",
      "\titers: 500, epoch: 5 | loss: 0.3558914\n",
      "\tspeed: 0.0515s/iter; left time: 717.1827s\n",
      "\titers: 600, epoch: 5 | loss: 0.3578681\n",
      "\tspeed: 0.0513s/iter; left time: 709.4234s\n",
      "\titers: 700, epoch: 5 | loss: 0.3609993\n",
      "\tspeed: 0.0514s/iter; left time: 706.3061s\n",
      "\titers: 800, epoch: 5 | loss: 0.3498127\n",
      "\tspeed: 0.0510s/iter; left time: 695.3890s\n",
      "\titers: 900, epoch: 5 | loss: 0.3380445\n",
      "\tspeed: 0.0508s/iter; left time: 687.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 902 | Train Loss: 0.3555974 Vali Loss: 0.3689196 Test Loss: 0.4241121\n",
      "Validation loss decreased (0.369674 --> 0.368920).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3308814\n",
      "\tspeed: 0.1436s/iter; left time: 1928.7144s\n",
      "\titers: 200, epoch: 6 | loss: 0.3624016\n",
      "\tspeed: 0.0506s/iter; left time: 674.6436s\n",
      "\titers: 300, epoch: 6 | loss: 0.3388534\n",
      "\tspeed: 0.0505s/iter; left time: 667.6522s\n",
      "\titers: 400, epoch: 6 | loss: 0.3292622\n",
      "\tspeed: 0.0506s/iter; left time: 664.0940s\n",
      "\titers: 500, epoch: 6 | loss: 0.3135133\n",
      "\tspeed: 0.0506s/iter; left time: 658.7464s\n",
      "\titers: 600, epoch: 6 | loss: 0.3277523\n",
      "\tspeed: 0.0506s/iter; left time: 653.8791s\n",
      "\titers: 700, epoch: 6 | loss: 0.3218856\n",
      "\tspeed: 0.0506s/iter; left time: 649.6861s\n",
      "\titers: 800, epoch: 6 | loss: 0.3477128\n",
      "\tspeed: 0.0508s/iter; left time: 646.2640s\n",
      "\titers: 900, epoch: 6 | loss: 0.3251559\n",
      "\tspeed: 0.0512s/iter; left time: 646.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 902 | Train Loss: 0.3378051 Vali Loss: 0.3864999 Test Loss: 0.4209988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3213096\n",
      "\tspeed: 0.1409s/iter; left time: 1764.9373s\n",
      "\titers: 200, epoch: 7 | loss: 0.3277854\n",
      "\tspeed: 0.0512s/iter; left time: 636.3361s\n",
      "\titers: 300, epoch: 7 | loss: 0.3504425\n",
      "\tspeed: 0.0512s/iter; left time: 631.4382s\n",
      "\titers: 400, epoch: 7 | loss: 0.3230827\n",
      "\tspeed: 0.0506s/iter; left time: 619.2494s\n",
      "\titers: 500, epoch: 7 | loss: 0.3219839\n",
      "\tspeed: 0.0506s/iter; left time: 614.3312s\n",
      "\titers: 600, epoch: 7 | loss: 0.3191775\n",
      "\tspeed: 0.0507s/iter; left time: 609.6221s\n",
      "\titers: 700, epoch: 7 | loss: 0.3067741\n",
      "\tspeed: 0.0510s/iter; left time: 608.1257s\n",
      "\titers: 800, epoch: 7 | loss: 0.3174631\n",
      "\tspeed: 0.0505s/iter; left time: 597.3072s\n",
      "\titers: 900, epoch: 7 | loss: 0.3218798\n",
      "\tspeed: 0.0504s/iter; left time: 591.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.19s\n",
      "Steps: 902 | Train Loss: 0.3207150 Vali Loss: 0.3786936 Test Loss: 0.4395137\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3099540\n",
      "\tspeed: 0.1850s/iter; left time: 2150.9786s\n",
      "\titers: 200, epoch: 8 | loss: 0.3024824\n",
      "\tspeed: 0.0506s/iter; left time: 582.8781s\n",
      "\titers: 300, epoch: 8 | loss: 0.3356878\n",
      "\tspeed: 0.0517s/iter; left time: 590.7068s\n",
      "\titers: 400, epoch: 8 | loss: 0.3148562\n",
      "\tspeed: 0.0567s/iter; left time: 642.2518s\n",
      "\titers: 500, epoch: 8 | loss: 0.3248895\n",
      "\tspeed: 0.0973s/iter; left time: 1092.8244s\n",
      "\titers: 600, epoch: 8 | loss: 0.2834164\n",
      "\tspeed: 0.0998s/iter; left time: 1110.0374s\n",
      "\titers: 700, epoch: 8 | loss: 0.2879775\n",
      "\tspeed: 0.0975s/iter; left time: 1075.1337s\n",
      "\titers: 800, epoch: 8 | loss: 0.3145868\n",
      "\tspeed: 0.1002s/iter; left time: 1095.3309s\n",
      "\titers: 900, epoch: 8 | loss: 0.2965819\n",
      "\tspeed: 0.0986s/iter; left time: 1067.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:11.04s\n",
      "Steps: 902 | Train Loss: 0.3046712 Vali Loss: 0.3944697 Test Loss: 0.4373064\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3136235\n",
      "\tspeed: 0.2780s/iter; left time: 2981.8389s\n",
      "\titers: 200, epoch: 9 | loss: 0.3017030\n",
      "\tspeed: 0.0519s/iter; left time: 551.6666s\n",
      "\titers: 300, epoch: 9 | loss: 0.3062738\n",
      "\tspeed: 0.0517s/iter; left time: 543.8089s\n",
      "\titers: 400, epoch: 9 | loss: 0.2847587\n",
      "\tspeed: 0.0511s/iter; left time: 533.0222s\n",
      "\titers: 500, epoch: 9 | loss: 0.3027622\n",
      "\tspeed: 0.0505s/iter; left time: 521.6443s\n",
      "\titers: 600, epoch: 9 | loss: 0.2812096\n",
      "\tspeed: 0.0505s/iter; left time: 516.6459s\n",
      "\titers: 700, epoch: 9 | loss: 0.3068925\n",
      "\tspeed: 0.0507s/iter; left time: 513.8338s\n",
      "\titers: 800, epoch: 9 | loss: 0.2990059\n",
      "\tspeed: 0.0505s/iter; left time: 506.7153s\n",
      "\titers: 900, epoch: 9 | loss: 0.2652038\n",
      "\tspeed: 0.0505s/iter; left time: 501.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.80s\n",
      "Steps: 902 | Train Loss: 0.2904989 Vali Loss: 0.3927657 Test Loss: 0.4323270\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2634344\n",
      "\tspeed: 0.1401s/iter; left time: 1376.1698s\n",
      "\titers: 200, epoch: 10 | loss: 0.2858311\n",
      "\tspeed: 0.0503s/iter; left time: 489.1498s\n",
      "\titers: 300, epoch: 10 | loss: 0.2868459\n",
      "\tspeed: 0.0505s/iter; left time: 485.9858s\n",
      "\titers: 400, epoch: 10 | loss: 0.2833558\n",
      "\tspeed: 0.0505s/iter; left time: 481.2469s\n",
      "\titers: 500, epoch: 10 | loss: 0.2761339\n",
      "\tspeed: 0.0505s/iter; left time: 475.6725s\n",
      "\titers: 600, epoch: 10 | loss: 0.2689979\n",
      "\tspeed: 0.0504s/iter; left time: 470.2296s\n",
      "\titers: 700, epoch: 10 | loss: 0.2578939\n",
      "\tspeed: 0.0504s/iter; left time: 465.2354s\n",
      "\titers: 800, epoch: 10 | loss: 0.2566439\n",
      "\tspeed: 0.0505s/iter; left time: 460.5028s\n",
      "\titers: 900, epoch: 10 | loss: 0.2717198\n",
      "\tspeed: 0.0504s/iter; left time: 455.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 902 | Train Loss: 0.2772423 Vali Loss: 0.3942379 Test Loss: 0.4387051\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.44157662987709045, rmse:0.6645123362541199, mae:0.4240509569644928, rse:0.6086118817329407\n",
      "Original data scale mse:4408365.5, rmse:2099.61083984375, mae:1332.4801025390625, rse:0.14789694547653198\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>0.4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.5666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.5539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4002</td>\n",
       "      <td>0.6326</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>0.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4175</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.4860</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2469</td>\n",
       "      <td>0.4969</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.5743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3954</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.4195</td>\n",
       "      <td>0.6085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.4241</td>\n",
       "      <td>0.6086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2293  0.4789  0.3071  0.4386\n",
       "              2         24        0.2293  0.4789  0.3048  0.4386\n",
       "              1         96        0.3830  0.6188  0.4100  0.5666\n",
       "              2         96        0.3659  0.6049  0.4062  0.5539\n",
       "              1         168       0.4002  0.6326  0.4335  0.5794\n",
       "              2         168       0.4175  0.6462  0.4400  0.5918\n",
       "MAE           1         24        0.2362  0.4860  0.2798  0.4451\n",
       "              2         24        0.2469  0.4969  0.2874  0.4550\n",
       "              1         96        0.3934  0.6272  0.3986  0.5743\n",
       "              2         96        0.3954  0.6288  0.3909  0.5757\n",
       "              1         168       0.4414  0.6644  0.4195  0.6085\n",
       "              2         168       0.4416  0.6645  0.4241  0.6086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT_default.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT_default.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>2136431.500</td>\n",
       "      <td>1461.6537</td>\n",
       "      <td>947.5727</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>2031066.875</td>\n",
       "      <td>1425.1550</td>\n",
       "      <td>935.1377</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3882534.500</td>\n",
       "      <td>1970.4148</td>\n",
       "      <td>1288.4697</td>\n",
       "      <td>0.1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3475395.250</td>\n",
       "      <td>1864.2412</td>\n",
       "      <td>1267.4960</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4282493.500</td>\n",
       "      <td>2069.4187</td>\n",
       "      <td>1388.6179</td>\n",
       "      <td>0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4567560.000</td>\n",
       "      <td>2137.1851</td>\n",
       "      <td>1427.0869</td>\n",
       "      <td>0.1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1555223.500</td>\n",
       "      <td>1247.0861</td>\n",
       "      <td>786.8116</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1826092.875</td>\n",
       "      <td>1351.3301</td>\n",
       "      <td>822.8324</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3858870.000</td>\n",
       "      <td>1964.4006</td>\n",
       "      <td>1243.5869</td>\n",
       "      <td>0.1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3485771.250</td>\n",
       "      <td>1867.0220</td>\n",
       "      <td>1180.4133</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4175248.250</td>\n",
       "      <td>2043.3424</td>\n",
       "      <td>1301.3749</td>\n",
       "      <td>0.1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4408365.500</td>\n",
       "      <td>2099.6108</td>\n",
       "      <td>1332.4801</td>\n",
       "      <td>0.1479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        2136431.500  1461.6537   947.5727  0.1027\n",
       "              2         24        2031066.875  1425.1550   935.1377  0.1001\n",
       "              1         96        3882534.500  1970.4148  1288.4697  0.1387\n",
       "              2         96        3475395.250  1864.2412  1267.4960  0.1312\n",
       "              1         168       4282493.500  2069.4187  1388.6179  0.1458\n",
       "              2         168       4567560.000  2137.1851  1427.0869  0.1505\n",
       "MAE           1         24        1555223.500  1247.0861   786.8116  0.0876\n",
       "              2         24        1826092.875  1351.3301   822.8324  0.0950\n",
       "              1         96        3858870.000  1964.4006  1243.5869  0.1382\n",
       "              2         96        3485771.250  1867.0220  1180.4133  0.1314\n",
       "              1         168       4175248.250  2043.3424  1301.3749  0.1439\n",
       "              2         168       4408365.500  2099.6108  1332.4801  0.1479"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3944</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.5602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4415</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.6085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.6394</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>0.5856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2415  0.4914  0.2836  0.4501\n",
       "         MSE            0.2293  0.4789  0.3060  0.4386\n",
       "96       MAE            0.3944  0.6280  0.3947  0.5750\n",
       "         MSE            0.3744  0.6119  0.4081  0.5602\n",
       "168      MAE            0.4415  0.6644  0.4218  0.6085\n",
       "         MSE            0.4089  0.6394  0.4367  0.5856"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.690658e+06</td>\n",
       "      <td>1299.2081</td>\n",
       "      <td>804.8220</td>\n",
       "      <td>0.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.083749e+06</td>\n",
       "      <td>1443.4044</td>\n",
       "      <td>941.3552</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.672321e+06</td>\n",
       "      <td>1915.7113</td>\n",
       "      <td>1212.0001</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.678965e+06</td>\n",
       "      <td>1917.3280</td>\n",
       "      <td>1277.9828</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.291807e+06</td>\n",
       "      <td>2071.4766</td>\n",
       "      <td>1316.9275</td>\n",
       "      <td>0.1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.425027e+06</td>\n",
       "      <td>2103.3019</td>\n",
       "      <td>1407.8524</td>\n",
       "      <td>0.1482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.690658e+06  1299.2081   804.8220  0.0913\n",
       "         MSE            2.083749e+06  1443.4044   941.3552  0.1014\n",
       "96       MAE            3.672321e+06  1915.7113  1212.0001  0.1348\n",
       "         MSE            3.678965e+06  1917.3280  1277.9828  0.1349\n",
       "168      MAE            4.291807e+06  2071.4766  1316.9275  0.1459\n",
       "         MSE            4.425027e+06  2103.3019  1407.8524  0.1482"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7835768\n",
      "\tspeed: 0.0278s/iter; left time: 496.7842s\n",
      "\titers: 200, epoch: 1 | loss: 0.8247158\n",
      "\tspeed: 0.0083s/iter; left time: 148.4237s\n",
      "\titers: 300, epoch: 1 | loss: 0.5668569\n",
      "\tspeed: 0.0083s/iter; left time: 147.1950s\n",
      "\titers: 400, epoch: 1 | loss: 0.5366505\n",
      "\tspeed: 0.0089s/iter; left time: 156.5683s\n",
      "\titers: 500, epoch: 1 | loss: 0.4378085\n",
      "\tspeed: 0.0095s/iter; left time: 165.9866s\n",
      "\titers: 600, epoch: 1 | loss: 0.4385815\n",
      "\tspeed: 0.0094s/iter; left time: 163.4744s\n",
      "\titers: 700, epoch: 1 | loss: 0.3150007\n",
      "\tspeed: 0.0093s/iter; left time: 160.5376s\n",
      "\titers: 800, epoch: 1 | loss: 0.3513808\n",
      "\tspeed: 0.0092s/iter; left time: 158.5484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 899 | Train Loss: 0.5657614 Vali Loss: 0.3030852 Test Loss: 0.3195856\n",
      "Validation loss decreased (inf --> 0.303085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2811377\n",
      "\tspeed: 0.0416s/iter; left time: 706.2950s\n",
      "\titers: 200, epoch: 2 | loss: 0.2245053\n",
      "\tspeed: 0.0094s/iter; left time: 159.4483s\n",
      "\titers: 300, epoch: 2 | loss: 0.2280752\n",
      "\tspeed: 0.0093s/iter; left time: 155.5515s\n",
      "\titers: 400, epoch: 2 | loss: 0.2516705\n",
      "\tspeed: 0.0089s/iter; left time: 148.5306s\n",
      "\titers: 500, epoch: 2 | loss: 0.2207813\n",
      "\tspeed: 0.0084s/iter; left time: 139.1800s\n",
      "\titers: 600, epoch: 2 | loss: 0.1988525\n",
      "\tspeed: 0.0084s/iter; left time: 138.3000s\n",
      "\titers: 700, epoch: 2 | loss: 0.2861122\n",
      "\tspeed: 0.0084s/iter; left time: 138.1030s\n",
      "\titers: 800, epoch: 2 | loss: 0.2351522\n",
      "\tspeed: 0.0084s/iter; left time: 137.2752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 899 | Train Loss: 0.2414951 Vali Loss: 0.1957187 Test Loss: 0.2181529\n",
      "Validation loss decreased (0.303085 --> 0.195719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1944644\n",
      "\tspeed: 0.0391s/iter; left time: 629.2548s\n",
      "\titers: 200, epoch: 3 | loss: 0.1543076\n",
      "\tspeed: 0.0083s/iter; left time: 132.7732s\n",
      "\titers: 300, epoch: 3 | loss: 0.2332987\n",
      "\tspeed: 0.0085s/iter; left time: 134.4245s\n",
      "\titers: 400, epoch: 3 | loss: 0.1939734\n",
      "\tspeed: 0.0083s/iter; left time: 131.6022s\n",
      "\titers: 500, epoch: 3 | loss: 0.2383235\n",
      "\tspeed: 0.0083s/iter; left time: 130.0864s\n",
      "\titers: 600, epoch: 3 | loss: 0.2310721\n",
      "\tspeed: 0.0083s/iter; left time: 129.0243s\n",
      "\titers: 700, epoch: 3 | loss: 0.2077278\n",
      "\tspeed: 0.0083s/iter; left time: 128.0568s\n",
      "\titers: 800, epoch: 3 | loss: 0.2553486\n",
      "\tspeed: 0.0083s/iter; left time: 127.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 899 | Train Loss: 0.2042339 Vali Loss: 0.1872622 Test Loss: 0.2086066\n",
      "Validation loss decreased (0.195719 --> 0.187262).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1480566\n",
      "\tspeed: 0.0395s/iter; left time: 600.1554s\n",
      "\titers: 200, epoch: 4 | loss: 0.1447536\n",
      "\tspeed: 0.0115s/iter; left time: 172.9255s\n",
      "\titers: 300, epoch: 4 | loss: 0.1823268\n",
      "\tspeed: 0.0085s/iter; left time: 127.4606s\n",
      "\titers: 400, epoch: 4 | loss: 0.1727345\n",
      "\tspeed: 0.0085s/iter; left time: 127.0449s\n",
      "\titers: 500, epoch: 4 | loss: 0.2184692\n",
      "\tspeed: 0.0085s/iter; left time: 125.1010s\n",
      "\titers: 600, epoch: 4 | loss: 0.1834781\n",
      "\tspeed: 0.0328s/iter; left time: 482.1626s\n",
      "\titers: 700, epoch: 4 | loss: 0.2177958\n",
      "\tspeed: 0.0345s/iter; left time: 502.8820s\n",
      "\titers: 800, epoch: 4 | loss: 0.1443295\n",
      "\tspeed: 0.0257s/iter; left time: 371.5439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.47s\n",
      "Steps: 899 | Train Loss: 0.1937971 Vali Loss: 0.1854279 Test Loss: 0.2061511\n",
      "Validation loss decreased (0.187262 --> 0.185428).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1993442\n",
      "\tspeed: 0.1050s/iter; left time: 1500.5725s\n",
      "\titers: 200, epoch: 5 | loss: 0.1535800\n",
      "\tspeed: 0.0189s/iter; left time: 268.1962s\n",
      "\titers: 300, epoch: 5 | loss: 0.1693922\n",
      "\tspeed: 0.0303s/iter; left time: 427.2405s\n",
      "\titers: 400, epoch: 5 | loss: 0.2449587\n",
      "\tspeed: 0.0531s/iter; left time: 741.9841s\n",
      "\titers: 500, epoch: 5 | loss: 0.1867730\n",
      "\tspeed: 0.0522s/iter; left time: 725.4142s\n",
      "\titers: 600, epoch: 5 | loss: 0.2548683\n",
      "\tspeed: 0.0589s/iter; left time: 811.5928s\n",
      "\titers: 700, epoch: 5 | loss: 0.1702230\n",
      "\tspeed: 0.0539s/iter; left time: 737.7262s\n",
      "\titers: 800, epoch: 5 | loss: 0.2071832\n",
      "\tspeed: 0.0555s/iter; left time: 753.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.19s\n",
      "Steps: 899 | Train Loss: 0.1860370 Vali Loss: 0.1832404 Test Loss: 0.2085929\n",
      "Validation loss decreased (0.185428 --> 0.183240).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1399768\n",
      "\tspeed: 0.3109s/iter; left time: 4161.1398s\n",
      "\titers: 200, epoch: 6 | loss: 0.1780338\n",
      "\tspeed: 0.0507s/iter; left time: 674.0914s\n",
      "\titers: 300, epoch: 6 | loss: 0.1449556\n",
      "\tspeed: 0.0558s/iter; left time: 735.4998s\n",
      "\titers: 400, epoch: 6 | loss: 0.1494177\n",
      "\tspeed: 0.0501s/iter; left time: 655.9032s\n",
      "\titers: 500, epoch: 6 | loss: 0.1471770\n",
      "\tspeed: 0.0527s/iter; left time: 684.3773s\n",
      "\titers: 600, epoch: 6 | loss: 0.1971005\n",
      "\tspeed: 0.0567s/iter; left time: 730.8950s\n",
      "\titers: 700, epoch: 6 | loss: 0.1737435\n",
      "\tspeed: 0.0608s/iter; left time: 776.9017s\n",
      "\titers: 800, epoch: 6 | loss: 0.1661763\n",
      "\tspeed: 0.0495s/iter; left time: 628.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.23s\n",
      "Steps: 899 | Train Loss: 0.1809803 Vali Loss: 0.1768590 Test Loss: 0.2005989\n",
      "Validation loss decreased (0.183240 --> 0.176859).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1630883\n",
      "\tspeed: 0.2961s/iter; left time: 3697.4934s\n",
      "\titers: 200, epoch: 7 | loss: 0.1172076\n",
      "\tspeed: 0.0584s/iter; left time: 723.9225s\n",
      "\titers: 300, epoch: 7 | loss: 0.2078372\n",
      "\tspeed: 0.0527s/iter; left time: 648.0797s\n",
      "\titers: 400, epoch: 7 | loss: 0.1424408\n",
      "\tspeed: 0.0634s/iter; left time: 772.6041s\n",
      "\titers: 500, epoch: 7 | loss: 0.2104602\n",
      "\tspeed: 0.0532s/iter; left time: 642.8058s\n",
      "\titers: 600, epoch: 7 | loss: 0.1793768\n",
      "\tspeed: 0.0545s/iter; left time: 653.0571s\n",
      "\titers: 700, epoch: 7 | loss: 0.1528571\n",
      "\tspeed: 0.0557s/iter; left time: 661.7821s\n",
      "\titers: 800, epoch: 7 | loss: 0.1644259\n",
      "\tspeed: 0.0522s/iter; left time: 615.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.44s\n",
      "Steps: 899 | Train Loss: 0.1764016 Vali Loss: 0.1763669 Test Loss: 0.2002481\n",
      "Validation loss decreased (0.176859 --> 0.176367).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1853698\n",
      "\tspeed: 0.3151s/iter; left time: 3650.9301s\n",
      "\titers: 200, epoch: 8 | loss: 0.1907266\n",
      "\tspeed: 0.0559s/iter; left time: 641.7120s\n",
      "\titers: 300, epoch: 8 | loss: 0.1670296\n",
      "\tspeed: 0.0535s/iter; left time: 609.2343s\n",
      "\titers: 400, epoch: 8 | loss: 0.1700782\n",
      "\tspeed: 0.0554s/iter; left time: 625.7145s\n",
      "\titers: 500, epoch: 8 | loss: 0.2030462\n",
      "\tspeed: 0.0561s/iter; left time: 627.1916s\n",
      "\titers: 600, epoch: 8 | loss: 0.1936078\n",
      "\tspeed: 0.0655s/iter; left time: 726.1061s\n",
      "\titers: 700, epoch: 8 | loss: 0.1747425\n",
      "\tspeed: 0.0499s/iter; left time: 548.5171s\n",
      "\titers: 800, epoch: 8 | loss: 0.1744118\n",
      "\tspeed: 0.0520s/iter; left time: 566.6822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.38s\n",
      "Steps: 899 | Train Loss: 0.1729777 Vali Loss: 0.1740513 Test Loss: 0.1998474\n",
      "Validation loss decreased (0.176367 --> 0.174051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1632505\n",
      "\tspeed: 0.3141s/iter; left time: 3357.3884s\n",
      "\titers: 200, epoch: 9 | loss: 0.2057525\n",
      "\tspeed: 0.0572s/iter; left time: 605.7902s\n",
      "\titers: 300, epoch: 9 | loss: 0.1876450\n",
      "\tspeed: 0.0555s/iter; left time: 581.6318s\n",
      "\titers: 400, epoch: 9 | loss: 0.1695710\n",
      "\tspeed: 0.0529s/iter; left time: 549.5782s\n",
      "\titers: 500, epoch: 9 | loss: 0.1715747\n",
      "\tspeed: 0.0542s/iter; left time: 557.8436s\n",
      "\titers: 600, epoch: 9 | loss: 0.1842579\n",
      "\tspeed: 0.0486s/iter; left time: 495.4311s\n",
      "\titers: 700, epoch: 9 | loss: 0.1539045\n",
      "\tspeed: 0.0551s/iter; left time: 556.1390s\n",
      "\titers: 800, epoch: 9 | loss: 0.2464554\n",
      "\tspeed: 0.0532s/iter; left time: 531.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.79s\n",
      "Steps: 899 | Train Loss: 0.1696618 Vali Loss: 0.1752442 Test Loss: 0.2006885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1284842\n",
      "\tspeed: 0.3220s/iter; left time: 3152.7751s\n",
      "\titers: 200, epoch: 10 | loss: 0.1929909\n",
      "\tspeed: 0.0581s/iter; left time: 563.2926s\n",
      "\titers: 300, epoch: 10 | loss: 0.1720825\n",
      "\tspeed: 0.0522s/iter; left time: 500.7769s\n",
      "\titers: 400, epoch: 10 | loss: 0.1903719\n",
      "\tspeed: 0.0539s/iter; left time: 511.1767s\n",
      "\titers: 500, epoch: 10 | loss: 0.1997257\n",
      "\tspeed: 0.0498s/iter; left time: 467.4013s\n",
      "\titers: 600, epoch: 10 | loss: 0.1246307\n",
      "\tspeed: 0.0568s/iter; left time: 527.4383s\n",
      "\titers: 700, epoch: 10 | loss: 0.1725681\n",
      "\tspeed: 0.0574s/iter; left time: 527.8164s\n",
      "\titers: 800, epoch: 10 | loss: 0.1906681\n",
      "\tspeed: 0.0523s/iter; left time: 475.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:51.07s\n",
      "Steps: 899 | Train Loss: 0.1669421 Vali Loss: 0.1744406 Test Loss: 0.2016439\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1477170\n",
      "\tspeed: 0.3253s/iter; left time: 2892.5006s\n",
      "\titers: 200, epoch: 11 | loss: 0.1646312\n",
      "\tspeed: 0.0521s/iter; left time: 458.1431s\n",
      "\titers: 300, epoch: 11 | loss: 0.1340601\n",
      "\tspeed: 0.0581s/iter; left time: 504.7293s\n",
      "\titers: 400, epoch: 11 | loss: 0.1878843\n",
      "\tspeed: 0.0570s/iter; left time: 489.5221s\n",
      "\titers: 500, epoch: 11 | loss: 0.1579571\n",
      "\tspeed: 0.0550s/iter; left time: 466.7581s\n",
      "\titers: 600, epoch: 11 | loss: 0.1387180\n",
      "\tspeed: 0.0505s/iter; left time: 423.7220s\n",
      "\titers: 700, epoch: 11 | loss: 0.1574380\n",
      "\tspeed: 0.0555s/iter; left time: 460.4920s\n",
      "\titers: 800, epoch: 11 | loss: 0.1558878\n",
      "\tspeed: 0.0522s/iter; left time: 427.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.68s\n",
      "Steps: 899 | Train Loss: 0.1644945 Vali Loss: 0.1733127 Test Loss: 0.2025027\n",
      "Validation loss decreased (0.174051 --> 0.173313).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1747763\n",
      "\tspeed: 0.3034s/iter; left time: 2424.9867s\n",
      "\titers: 200, epoch: 12 | loss: 0.1798991\n",
      "\tspeed: 0.0501s/iter; left time: 395.7514s\n",
      "\titers: 300, epoch: 12 | loss: 0.1872625\n",
      "\tspeed: 0.0559s/iter; left time: 435.3132s\n",
      "\titers: 400, epoch: 12 | loss: 0.1446878\n",
      "\tspeed: 0.0551s/iter; left time: 423.9105s\n",
      "\titers: 500, epoch: 12 | loss: 0.1905347\n",
      "\tspeed: 0.0561s/iter; left time: 426.0344s\n",
      "\titers: 600, epoch: 12 | loss: 0.2089496\n",
      "\tspeed: 0.0580s/iter; left time: 434.6529s\n",
      "\titers: 700, epoch: 12 | loss: 0.1779407\n",
      "\tspeed: 0.0492s/iter; left time: 363.3320s\n",
      "\titers: 800, epoch: 12 | loss: 0.1710578\n",
      "\tspeed: 0.0518s/iter; left time: 377.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:49.50s\n",
      "Steps: 899 | Train Loss: 0.1622358 Vali Loss: 0.1716515 Test Loss: 0.2008850\n",
      "Validation loss decreased (0.173313 --> 0.171651).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1689993\n",
      "\tspeed: 0.2992s/iter; left time: 2122.3671s\n",
      "\titers: 200, epoch: 13 | loss: 0.1818331\n",
      "\tspeed: 0.0542s/iter; left time: 379.2669s\n",
      "\titers: 300, epoch: 13 | loss: 0.1252291\n",
      "\tspeed: 0.0549s/iter; left time: 378.7050s\n",
      "\titers: 400, epoch: 13 | loss: 0.1777937\n",
      "\tspeed: 0.0541s/iter; left time: 367.4810s\n",
      "\titers: 500, epoch: 13 | loss: 0.2506722\n",
      "\tspeed: 0.0551s/iter; left time: 369.1177s\n",
      "\titers: 600, epoch: 13 | loss: 0.1345320\n",
      "\tspeed: 0.0505s/iter; left time: 332.9466s\n",
      "\titers: 700, epoch: 13 | loss: 0.1778658\n",
      "\tspeed: 0.0595s/iter; left time: 386.1021s\n",
      "\titers: 800, epoch: 13 | loss: 0.2238196\n",
      "\tspeed: 0.0558s/iter; left time: 356.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:50.18s\n",
      "Steps: 899 | Train Loss: 0.1602487 Vali Loss: 0.1712440 Test Loss: 0.2016205\n",
      "Validation loss decreased (0.171651 --> 0.171244).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2442018\n",
      "\tspeed: 0.3063s/iter; left time: 1897.1468s\n",
      "\titers: 200, epoch: 14 | loss: 0.1464531\n",
      "\tspeed: 0.0558s/iter; left time: 339.7807s\n",
      "\titers: 300, epoch: 14 | loss: 0.1778194\n",
      "\tspeed: 0.0513s/iter; left time: 307.3956s\n",
      "\titers: 400, epoch: 14 | loss: 0.1627585\n",
      "\tspeed: 0.0642s/iter; left time: 378.1539s\n",
      "\titers: 500, epoch: 14 | loss: 0.1943819\n",
      "\tspeed: 0.0509s/iter; left time: 294.9219s\n",
      "\titers: 600, epoch: 14 | loss: 0.2355634\n",
      "\tspeed: 0.0537s/iter; left time: 305.5374s\n",
      "\titers: 700, epoch: 14 | loss: 0.1658423\n",
      "\tspeed: 0.0582s/iter; left time: 325.4646s\n",
      "\titers: 800, epoch: 14 | loss: 0.1710691\n",
      "\tspeed: 0.0578s/iter; left time: 317.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:51.39s\n",
      "Steps: 899 | Train Loss: 0.1583827 Vali Loss: 0.1719172 Test Loss: 0.2036489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1797957\n",
      "\tspeed: 0.3105s/iter; left time: 1644.0760s\n",
      "\titers: 200, epoch: 15 | loss: 0.1562801\n",
      "\tspeed: 0.0532s/iter; left time: 276.3456s\n",
      "\titers: 300, epoch: 15 | loss: 0.1201042\n",
      "\tspeed: 0.0533s/iter; left time: 271.4683s\n",
      "\titers: 400, epoch: 15 | loss: 0.1427457\n",
      "\tspeed: 0.0499s/iter; left time: 249.3056s\n",
      "\titers: 500, epoch: 15 | loss: 0.1213190\n",
      "\tspeed: 0.0540s/iter; left time: 264.3482s\n",
      "\titers: 600, epoch: 15 | loss: 0.1619885\n",
      "\tspeed: 0.0520s/iter; left time: 249.5020s\n",
      "\titers: 700, epoch: 15 | loss: 0.1667436\n",
      "\tspeed: 0.0534s/iter; left time: 250.6369s\n",
      "\titers: 800, epoch: 15 | loss: 0.1192563\n",
      "\tspeed: 0.0583s/iter; left time: 267.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:48.86s\n",
      "Steps: 899 | Train Loss: 0.1565270 Vali Loss: 0.1728543 Test Loss: 0.2048685\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.2316392\n",
      "\tspeed: 0.3076s/iter; left time: 1352.1606s\n",
      "\titers: 200, epoch: 16 | loss: 0.1556645\n",
      "\tspeed: 0.0607s/iter; left time: 260.6348s\n",
      "\titers: 300, epoch: 16 | loss: 0.1374122\n",
      "\tspeed: 0.0512s/iter; left time: 214.7937s\n",
      "\titers: 400, epoch: 16 | loss: 0.1514346\n",
      "\tspeed: 0.0511s/iter; left time: 209.4569s\n",
      "\titers: 500, epoch: 16 | loss: 0.1509137\n",
      "\tspeed: 0.0581s/iter; left time: 232.3450s\n",
      "\titers: 600, epoch: 16 | loss: 0.1117469\n",
      "\tspeed: 0.0570s/iter; left time: 222.2365s\n",
      "\titers: 700, epoch: 16 | loss: 0.1502796\n",
      "\tspeed: 0.0509s/iter; left time: 193.0514s\n",
      "\titers: 800, epoch: 16 | loss: 0.1709494\n",
      "\tspeed: 0.0488s/iter; left time: 180.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:48.95s\n",
      "Steps: 899 | Train Loss: 0.1554063 Vali Loss: 0.1732487 Test Loss: 0.2034004\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1779117\n",
      "\tspeed: 0.3098s/iter; left time: 1083.2228s\n",
      "\titers: 200, epoch: 17 | loss: 0.1515591\n",
      "\tspeed: 0.0505s/iter; left time: 171.6725s\n",
      "\titers: 300, epoch: 17 | loss: 0.1311705\n",
      "\tspeed: 0.0537s/iter; left time: 177.0764s\n",
      "\titers: 400, epoch: 17 | loss: 0.1984616\n",
      "\tspeed: 0.0539s/iter; left time: 172.4779s\n",
      "\titers: 500, epoch: 17 | loss: 0.1769482\n",
      "\tspeed: 0.0585s/iter; left time: 181.3148s\n",
      "\titers: 600, epoch: 17 | loss: 0.2197677\n",
      "\tspeed: 0.0534s/iter; left time: 159.9323s\n",
      "\titers: 700, epoch: 17 | loss: 0.0951977\n",
      "\tspeed: 0.0486s/iter; left time: 140.6496s\n",
      "\titers: 800, epoch: 17 | loss: 0.1690862\n",
      "\tspeed: 0.0509s/iter; left time: 142.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 899 | Train Loss: 0.1536552 Vali Loss: 0.1726733 Test Loss: 0.2033207\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1568015\n",
      "\tspeed: 0.3023s/iter; left time: 785.3435s\n",
      "\titers: 200, epoch: 18 | loss: 0.2056298\n",
      "\tspeed: 0.0505s/iter; left time: 126.0983s\n",
      "\titers: 300, epoch: 18 | loss: 0.1615719\n",
      "\tspeed: 0.0482s/iter; left time: 115.5681s\n",
      "\titers: 400, epoch: 18 | loss: 0.1186625\n",
      "\tspeed: 0.0470s/iter; left time: 107.9541s\n",
      "\titers: 500, epoch: 18 | loss: 0.1271502\n",
      "\tspeed: 0.0539s/iter; left time: 118.3638s\n",
      "\titers: 600, epoch: 18 | loss: 0.1760904\n",
      "\tspeed: 0.0548s/iter; left time: 114.9969s\n",
      "\titers: 700, epoch: 18 | loss: 0.1818802\n",
      "\tspeed: 0.0530s/iter; left time: 105.8034s\n",
      "\titers: 800, epoch: 18 | loss: 0.1591147\n",
      "\tspeed: 0.0591s/iter; left time: 112.1642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 899 | Train Loss: 0.1525800 Vali Loss: 0.1729590 Test Loss: 0.2042684\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20162047445774078, rmse:0.44902169704437256, mae:0.2636471688747406, rse:0.4112309217453003\n",
      "Original data scale mse:1205259.875, rmse:1097.84326171875, mae:717.048095703125, rse:0.07714803516864777\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7725865\n",
      "\tspeed: 0.0603s/iter; left time: 1077.9925s\n",
      "\titers: 200, epoch: 1 | loss: 0.6833057\n",
      "\tspeed: 0.0618s/iter; left time: 1098.3127s\n",
      "\titers: 300, epoch: 1 | loss: 0.4966044\n",
      "\tspeed: 0.0552s/iter; left time: 975.2339s\n",
      "\titers: 400, epoch: 1 | loss: 0.6127493\n",
      "\tspeed: 0.0484s/iter; left time: 850.1665s\n",
      "\titers: 500, epoch: 1 | loss: 0.4756226\n",
      "\tspeed: 0.0528s/iter; left time: 923.8076s\n",
      "\titers: 600, epoch: 1 | loss: 0.4483727\n",
      "\tspeed: 0.0528s/iter; left time: 917.3721s\n",
      "\titers: 700, epoch: 1 | loss: 0.4262236\n",
      "\tspeed: 0.0522s/iter; left time: 902.3904s\n",
      "\titers: 800, epoch: 1 | loss: 0.3367139\n",
      "\tspeed: 0.0539s/iter; left time: 925.7519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.34s\n",
      "Steps: 899 | Train Loss: 0.5326795 Vali Loss: 0.2936419 Test Loss: 0.3113503\n",
      "Validation loss decreased (inf --> 0.293642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2904617\n",
      "\tspeed: 0.3113s/iter; left time: 5286.9655s\n",
      "\titers: 200, epoch: 2 | loss: 0.3001018\n",
      "\tspeed: 0.0574s/iter; left time: 969.1165s\n",
      "\titers: 300, epoch: 2 | loss: 0.2747088\n",
      "\tspeed: 0.0599s/iter; left time: 1004.6355s\n",
      "\titers: 400, epoch: 2 | loss: 0.3097885\n",
      "\tspeed: 0.0574s/iter; left time: 957.4899s\n",
      "\titers: 500, epoch: 2 | loss: 0.2737598\n",
      "\tspeed: 0.0487s/iter; left time: 807.9825s\n",
      "\titers: 600, epoch: 2 | loss: 0.2177521\n",
      "\tspeed: 0.0543s/iter; left time: 895.1412s\n",
      "\titers: 700, epoch: 2 | loss: 0.2075630\n",
      "\tspeed: 0.0527s/iter; left time: 863.1028s\n",
      "\titers: 800, epoch: 2 | loss: 0.2651642\n",
      "\tspeed: 0.0460s/iter; left time: 749.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.44s\n",
      "Steps: 899 | Train Loss: 0.2395176 Vali Loss: 0.1925280 Test Loss: 0.2147795\n",
      "Validation loss decreased (0.293642 --> 0.192528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3059070\n",
      "\tspeed: 0.3048s/iter; left time: 4902.3750s\n",
      "\titers: 200, epoch: 3 | loss: 0.2246386\n",
      "\tspeed: 0.0517s/iter; left time: 826.8915s\n",
      "\titers: 300, epoch: 3 | loss: 0.1968952\n",
      "\tspeed: 0.0519s/iter; left time: 824.7796s\n",
      "\titers: 400, epoch: 3 | loss: 0.2077367\n",
      "\tspeed: 0.0520s/iter; left time: 820.5465s\n",
      "\titers: 500, epoch: 3 | loss: 0.1968109\n",
      "\tspeed: 0.0493s/iter; left time: 773.8015s\n",
      "\titers: 600, epoch: 3 | loss: 0.2248035\n",
      "\tspeed: 0.0533s/iter; left time: 830.7991s\n",
      "\titers: 700, epoch: 3 | loss: 0.1950904\n",
      "\tspeed: 0.0564s/iter; left time: 872.6111s\n",
      "\titers: 800, epoch: 3 | loss: 0.2330257\n",
      "\tspeed: 0.0495s/iter; left time: 761.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.91s\n",
      "Steps: 899 | Train Loss: 0.2025505 Vali Loss: 0.1877191 Test Loss: 0.2111579\n",
      "Validation loss decreased (0.192528 --> 0.187719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537986\n",
      "\tspeed: 0.2992s/iter; left time: 4542.7640s\n",
      "\titers: 200, epoch: 4 | loss: 0.1772013\n",
      "\tspeed: 0.0519s/iter; left time: 783.1615s\n",
      "\titers: 300, epoch: 4 | loss: 0.2245910\n",
      "\tspeed: 0.0559s/iter; left time: 837.5834s\n",
      "\titers: 400, epoch: 4 | loss: 0.1456292\n",
      "\tspeed: 0.0544s/iter; left time: 809.7152s\n",
      "\titers: 500, epoch: 4 | loss: 0.1757441\n",
      "\tspeed: 0.0519s/iter; left time: 767.7354s\n",
      "\titers: 600, epoch: 4 | loss: 0.2402209\n",
      "\tspeed: 0.0504s/iter; left time: 739.7435s\n",
      "\titers: 700, epoch: 4 | loss: 0.1843475\n",
      "\tspeed: 0.0526s/iter; left time: 767.6778s\n",
      "\titers: 800, epoch: 4 | loss: 0.2044414\n",
      "\tspeed: 0.0529s/iter; left time: 766.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.86s\n",
      "Steps: 899 | Train Loss: 0.1920715 Vali Loss: 0.1826302 Test Loss: 0.2061761\n",
      "Validation loss decreased (0.187719 --> 0.182630).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1853246\n",
      "\tspeed: 0.3095s/iter; left time: 4421.4282s\n",
      "\titers: 200, epoch: 5 | loss: 0.1525272\n",
      "\tspeed: 0.0606s/iter; left time: 860.1354s\n",
      "\titers: 300, epoch: 5 | loss: 0.1735278\n",
      "\tspeed: 0.0504s/iter; left time: 709.3274s\n",
      "\titers: 400, epoch: 5 | loss: 0.1450142\n",
      "\tspeed: 0.0537s/iter; left time: 751.1680s\n",
      "\titers: 500, epoch: 5 | loss: 0.1375235\n",
      "\tspeed: 0.0465s/iter; left time: 645.6727s\n",
      "\titers: 600, epoch: 5 | loss: 0.1848067\n",
      "\tspeed: 0.0523s/iter; left time: 721.0078s\n",
      "\titers: 700, epoch: 5 | loss: 0.2138237\n",
      "\tspeed: 0.0465s/iter; left time: 636.6096s\n",
      "\titers: 800, epoch: 5 | loss: 0.1744363\n",
      "\tspeed: 0.0455s/iter; left time: 617.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 899 | Train Loss: 0.1847066 Vali Loss: 0.1820181 Test Loss: 0.2065089\n",
      "Validation loss decreased (0.182630 --> 0.182018).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1777489\n",
      "\tspeed: 0.2952s/iter; left time: 3951.7078s\n",
      "\titers: 200, epoch: 6 | loss: 0.1778791\n",
      "\tspeed: 0.0523s/iter; left time: 694.2345s\n",
      "\titers: 300, epoch: 6 | loss: 0.1232323\n",
      "\tspeed: 0.0587s/iter; left time: 773.9486s\n",
      "\titers: 400, epoch: 6 | loss: 0.1789007\n",
      "\tspeed: 0.0626s/iter; left time: 818.6075s\n",
      "\titers: 500, epoch: 6 | loss: 0.1866260\n",
      "\tspeed: 0.0446s/iter; left time: 578.6724s\n",
      "\titers: 600, epoch: 6 | loss: 0.1396412\n",
      "\tspeed: 0.0189s/iter; left time: 243.9072s\n",
      "\titers: 700, epoch: 6 | loss: 0.1856884\n",
      "\tspeed: 0.0401s/iter; left time: 512.7419s\n",
      "\titers: 800, epoch: 6 | loss: 0.1585015\n",
      "\tspeed: 0.0531s/iter; left time: 673.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.14s\n",
      "Steps: 899 | Train Loss: 0.1794414 Vali Loss: 0.1797417 Test Loss: 0.2012473\n",
      "Validation loss decreased (0.182018 --> 0.179742).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1680326\n",
      "\tspeed: 0.2963s/iter; left time: 3700.1886s\n",
      "\titers: 200, epoch: 7 | loss: 0.1770180\n",
      "\tspeed: 0.0535s/iter; left time: 662.4665s\n",
      "\titers: 300, epoch: 7 | loss: 0.2275322\n",
      "\tspeed: 0.0508s/iter; left time: 624.2051s\n",
      "\titers: 400, epoch: 7 | loss: 0.2171821\n",
      "\tspeed: 0.0499s/iter; left time: 607.5432s\n",
      "\titers: 500, epoch: 7 | loss: 0.1867231\n",
      "\tspeed: 0.0523s/iter; left time: 632.3544s\n",
      "\titers: 600, epoch: 7 | loss: 0.2203903\n",
      "\tspeed: 0.0539s/iter; left time: 646.1548s\n",
      "\titers: 700, epoch: 7 | loss: 0.2059330\n",
      "\tspeed: 0.0558s/iter; left time: 662.9720s\n",
      "\titers: 800, epoch: 7 | loss: 0.1694414\n",
      "\tspeed: 0.0573s/iter; left time: 675.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 899 | Train Loss: 0.1755654 Vali Loss: 0.1794925 Test Loss: 0.2016378\n",
      "Validation loss decreased (0.179742 --> 0.179493).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1808263\n",
      "\tspeed: 0.3059s/iter; left time: 3544.3540s\n",
      "\titers: 200, epoch: 8 | loss: 0.1297457\n",
      "\tspeed: 0.0503s/iter; left time: 578.0863s\n",
      "\titers: 300, epoch: 8 | loss: 0.1868977\n",
      "\tspeed: 0.0486s/iter; left time: 553.2957s\n",
      "\titers: 400, epoch: 8 | loss: 0.2619369\n",
      "\tspeed: 0.0497s/iter; left time: 561.1470s\n",
      "\titers: 500, epoch: 8 | loss: 0.1199670\n",
      "\tspeed: 0.0595s/iter; left time: 665.1861s\n",
      "\titers: 600, epoch: 8 | loss: 0.2039896\n",
      "\tspeed: 0.0474s/iter; left time: 525.0726s\n",
      "\titers: 700, epoch: 8 | loss: 0.2157608\n",
      "\tspeed: 0.0525s/iter; left time: 577.1936s\n",
      "\titers: 800, epoch: 8 | loss: 0.2136256\n",
      "\tspeed: 0.0545s/iter; left time: 593.4917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.30s\n",
      "Steps: 899 | Train Loss: 0.1717362 Vali Loss: 0.1780235 Test Loss: 0.2035691\n",
      "Validation loss decreased (0.179493 --> 0.178023).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1750274\n",
      "\tspeed: 0.3005s/iter; left time: 3212.4146s\n",
      "\titers: 200, epoch: 9 | loss: 0.1530153\n",
      "\tspeed: 0.0582s/iter; left time: 616.3047s\n",
      "\titers: 300, epoch: 9 | loss: 0.1595897\n",
      "\tspeed: 0.0515s/iter; left time: 540.2457s\n",
      "\titers: 400, epoch: 9 | loss: 0.1842402\n",
      "\tspeed: 0.0495s/iter; left time: 513.9621s\n",
      "\titers: 500, epoch: 9 | loss: 0.1553181\n",
      "\tspeed: 0.0504s/iter; left time: 519.0779s\n",
      "\titers: 600, epoch: 9 | loss: 0.1271841\n",
      "\tspeed: 0.0544s/iter; left time: 554.3092s\n",
      "\titers: 700, epoch: 9 | loss: 0.1570895\n",
      "\tspeed: 0.0540s/iter; left time: 544.4484s\n",
      "\titers: 800, epoch: 9 | loss: 0.1590267\n",
      "\tspeed: 0.0503s/iter; left time: 502.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.08s\n",
      "Steps: 899 | Train Loss: 0.1683953 Vali Loss: 0.1743404 Test Loss: 0.2021225\n",
      "Validation loss decreased (0.178023 --> 0.174340).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2743678\n",
      "\tspeed: 0.3304s/iter; left time: 3234.7025s\n",
      "\titers: 200, epoch: 10 | loss: 0.1181822\n",
      "\tspeed: 0.0512s/iter; left time: 495.8382s\n",
      "\titers: 300, epoch: 10 | loss: 0.1561307\n",
      "\tspeed: 0.0499s/iter; left time: 478.4133s\n",
      "\titers: 400, epoch: 10 | loss: 0.1397250\n",
      "\tspeed: 0.0520s/iter; left time: 493.7157s\n",
      "\titers: 500, epoch: 10 | loss: 0.1683225\n",
      "\tspeed: 0.0518s/iter; left time: 486.7879s\n",
      "\titers: 600, epoch: 10 | loss: 0.1768161\n",
      "\tspeed: 0.0481s/iter; left time: 447.1699s\n",
      "\titers: 700, epoch: 10 | loss: 0.1857192\n",
      "\tspeed: 0.0453s/iter; left time: 416.6517s\n",
      "\titers: 800, epoch: 10 | loss: 0.1156062\n",
      "\tspeed: 0.0522s/iter; left time: 474.6728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.70s\n",
      "Steps: 899 | Train Loss: 0.1657122 Vali Loss: 0.1773219 Test Loss: 0.2007642\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1770701\n",
      "\tspeed: 0.3065s/iter; left time: 2725.1018s\n",
      "\titers: 200, epoch: 11 | loss: 0.1241990\n",
      "\tspeed: 0.0580s/iter; left time: 510.0181s\n",
      "\titers: 300, epoch: 11 | loss: 0.1098084\n",
      "\tspeed: 0.0520s/iter; left time: 452.2027s\n",
      "\titers: 400, epoch: 11 | loss: 0.1386573\n",
      "\tspeed: 0.0548s/iter; left time: 470.4621s\n",
      "\titers: 500, epoch: 11 | loss: 0.1621366\n",
      "\tspeed: 0.0595s/iter; left time: 504.9681s\n",
      "\titers: 600, epoch: 11 | loss: 0.1835429\n",
      "\tspeed: 0.0587s/iter; left time: 492.2419s\n",
      "\titers: 700, epoch: 11 | loss: 0.1095438\n",
      "\tspeed: 0.0609s/iter; left time: 504.9944s\n",
      "\titers: 800, epoch: 11 | loss: 0.1446120\n",
      "\tspeed: 0.0559s/iter; left time: 457.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.13s\n",
      "Steps: 899 | Train Loss: 0.1624647 Vali Loss: 0.1740125 Test Loss: 0.2016218\n",
      "Validation loss decreased (0.174340 --> 0.174013).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1762031\n",
      "\tspeed: 0.3181s/iter; left time: 2542.4072s\n",
      "\titers: 200, epoch: 12 | loss: 0.1270645\n",
      "\tspeed: 0.0524s/iter; left time: 413.6664s\n",
      "\titers: 300, epoch: 12 | loss: 0.1512506\n",
      "\tspeed: 0.0580s/iter; left time: 452.3183s\n",
      "\titers: 400, epoch: 12 | loss: 0.2055338\n",
      "\tspeed: 0.0527s/iter; left time: 405.1143s\n",
      "\titers: 500, epoch: 12 | loss: 0.2040396\n",
      "\tspeed: 0.0550s/iter; left time: 417.5014s\n",
      "\titers: 600, epoch: 12 | loss: 0.1265583\n",
      "\tspeed: 0.0565s/iter; left time: 423.4282s\n",
      "\titers: 700, epoch: 12 | loss: 0.1134985\n",
      "\tspeed: 0.0553s/iter; left time: 408.6930s\n",
      "\titers: 800, epoch: 12 | loss: 0.1905216\n",
      "\tspeed: 0.0523s/iter; left time: 381.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:50.12s\n",
      "Steps: 899 | Train Loss: 0.1611636 Vali Loss: 0.1747293 Test Loss: 0.2021780\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1508626\n",
      "\tspeed: 0.3057s/iter; left time: 2168.3729s\n",
      "\titers: 200, epoch: 13 | loss: 0.1480462\n",
      "\tspeed: 0.0500s/iter; left time: 349.6396s\n",
      "\titers: 300, epoch: 13 | loss: 0.2254022\n",
      "\tspeed: 0.0551s/iter; left time: 379.9810s\n",
      "\titers: 400, epoch: 13 | loss: 0.1629598\n",
      "\tspeed: 0.0543s/iter; left time: 368.5373s\n",
      "\titers: 500, epoch: 13 | loss: 0.1601937\n",
      "\tspeed: 0.0489s/iter; left time: 327.5868s\n",
      "\titers: 600, epoch: 13 | loss: 0.1615871\n",
      "\tspeed: 0.0506s/iter; left time: 333.3392s\n",
      "\titers: 700, epoch: 13 | loss: 0.1202649\n",
      "\tspeed: 0.0491s/iter; left time: 318.8951s\n",
      "\titers: 800, epoch: 13 | loss: 0.1575193\n",
      "\tspeed: 0.0471s/iter; left time: 300.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 899 | Train Loss: 0.1591607 Vali Loss: 0.1755999 Test Loss: 0.2019623\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1517907\n",
      "\tspeed: 0.2850s/iter; left time: 1765.3141s\n",
      "\titers: 200, epoch: 14 | loss: 0.1203807\n",
      "\tspeed: 0.0290s/iter; left time: 176.5248s\n",
      "\titers: 300, epoch: 14 | loss: 0.1182542\n",
      "\tspeed: 0.0574s/iter; left time: 343.7788s\n",
      "\titers: 400, epoch: 14 | loss: 0.1122303\n",
      "\tspeed: 0.0594s/iter; left time: 350.3612s\n",
      "\titers: 500, epoch: 14 | loss: 0.1240817\n",
      "\tspeed: 0.0499s/iter; left time: 289.1801s\n",
      "\titers: 600, epoch: 14 | loss: 0.1866452\n",
      "\tspeed: 0.0546s/iter; left time: 310.6556s\n",
      "\titers: 700, epoch: 14 | loss: 0.1255808\n",
      "\tspeed: 0.0481s/iter; left time: 269.3304s\n",
      "\titers: 800, epoch: 14 | loss: 0.1513176\n",
      "\tspeed: 0.0486s/iter; left time: 267.1667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:43.97s\n",
      "Steps: 899 | Train Loss: 0.1571160 Vali Loss: 0.1737460 Test Loss: 0.2021376\n",
      "Validation loss decreased (0.174013 --> 0.173746).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2035314\n",
      "\tspeed: 0.3007s/iter; left time: 1591.9579s\n",
      "\titers: 200, epoch: 15 | loss: 0.1704706\n",
      "\tspeed: 0.0565s/iter; left time: 293.5217s\n",
      "\titers: 300, epoch: 15 | loss: 0.1309569\n",
      "\tspeed: 0.0481s/iter; left time: 245.0545s\n",
      "\titers: 400, epoch: 15 | loss: 0.1219474\n",
      "\tspeed: 0.0471s/iter; left time: 235.2226s\n",
      "\titers: 500, epoch: 15 | loss: 0.2026114\n",
      "\tspeed: 0.0491s/iter; left time: 240.3929s\n",
      "\titers: 600, epoch: 15 | loss: 0.1685250\n",
      "\tspeed: 0.0486s/iter; left time: 232.9041s\n",
      "\titers: 700, epoch: 15 | loss: 0.2032798\n",
      "\tspeed: 0.0527s/iter; left time: 247.2526s\n",
      "\titers: 800, epoch: 15 | loss: 0.1484709\n",
      "\tspeed: 0.0525s/iter; left time: 241.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.24s\n",
      "Steps: 899 | Train Loss: 0.1559366 Vali Loss: 0.1734128 Test Loss: 0.2025272\n",
      "Validation loss decreased (0.173746 --> 0.173413).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1326342\n",
      "\tspeed: 0.3155s/iter; left time: 1386.7721s\n",
      "\titers: 200, epoch: 16 | loss: 0.1496808\n",
      "\tspeed: 0.0481s/iter; left time: 206.4489s\n",
      "\titers: 300, epoch: 16 | loss: 0.1100202\n",
      "\tspeed: 0.0395s/iter; left time: 165.7936s\n",
      "\titers: 400, epoch: 16 | loss: 0.1080719\n",
      "\tspeed: 0.0334s/iter; left time: 136.7696s\n",
      "\titers: 500, epoch: 16 | loss: 0.1434888\n",
      "\tspeed: 0.0292s/iter; left time: 116.6839s\n",
      "\titers: 600, epoch: 16 | loss: 0.1269533\n",
      "\tspeed: 0.0301s/iter; left time: 117.3100s\n",
      "\titers: 700, epoch: 16 | loss: 0.1689320\n",
      "\tspeed: 0.0218s/iter; left time: 82.8143s\n",
      "\titers: 800, epoch: 16 | loss: 0.1111811\n",
      "\tspeed: 0.0198s/iter; left time: 73.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.71s\n",
      "Steps: 899 | Train Loss: 0.1539463 Vali Loss: 0.1757859 Test Loss: 0.2043217\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1447350\n",
      "\tspeed: 0.0944s/iter; left time: 330.0668s\n",
      "\titers: 200, epoch: 17 | loss: 0.1815556\n",
      "\tspeed: 0.0185s/iter; left time: 62.9181s\n",
      "\titers: 300, epoch: 17 | loss: 0.1619833\n",
      "\tspeed: 0.0180s/iter; left time: 59.3501s\n",
      "\titers: 400, epoch: 17 | loss: 0.1515302\n",
      "\tspeed: 0.0179s/iter; left time: 57.0907s\n",
      "\titers: 500, epoch: 17 | loss: 0.1541683\n",
      "\tspeed: 0.0169s/iter; left time: 52.2694s\n",
      "\titers: 600, epoch: 17 | loss: 0.1192075\n",
      "\tspeed: 0.0142s/iter; left time: 42.5976s\n",
      "\titers: 700, epoch: 17 | loss: 0.1629592\n",
      "\tspeed: 0.0116s/iter; left time: 33.6153s\n",
      "\titers: 800, epoch: 17 | loss: 0.1591187\n",
      "\tspeed: 0.0118s/iter; left time: 32.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.38s\n",
      "Steps: 899 | Train Loss: 0.1531382 Vali Loss: 0.1745626 Test Loss: 0.2040336\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1607784\n",
      "\tspeed: 0.0519s/iter; left time: 134.8362s\n",
      "\titers: 200, epoch: 18 | loss: 0.1634651\n",
      "\tspeed: 0.0108s/iter; left time: 26.9739s\n",
      "\titers: 300, epoch: 18 | loss: 0.2124223\n",
      "\tspeed: 0.0105s/iter; left time: 25.1023s\n",
      "\titers: 400, epoch: 18 | loss: 0.1667200\n",
      "\tspeed: 0.0104s/iter; left time: 23.9760s\n",
      "\titers: 500, epoch: 18 | loss: 0.1123230\n",
      "\tspeed: 0.0122s/iter; left time: 26.7297s\n",
      "\titers: 600, epoch: 18 | loss: 0.1122164\n",
      "\tspeed: 0.0108s/iter; left time: 22.6566s\n",
      "\titers: 700, epoch: 18 | loss: 0.1468484\n",
      "\tspeed: 0.0105s/iter; left time: 21.0742s\n",
      "\titers: 800, epoch: 18 | loss: 0.1418234\n",
      "\tspeed: 0.0101s/iter; left time: 19.1412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 899 | Train Loss: 0.1519652 Vali Loss: 0.1756739 Test Loss: 0.2048890\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1506396\n",
      "\tspeed: 0.0502s/iter; left time: 85.3547s\n",
      "\titers: 200, epoch: 19 | loss: 0.1325819\n",
      "\tspeed: 0.0106s/iter; left time: 16.9049s\n",
      "\titers: 300, epoch: 19 | loss: 0.1626580\n",
      "\tspeed: 0.0108s/iter; left time: 16.1192s\n",
      "\titers: 400, epoch: 19 | loss: 0.1799445\n",
      "\tspeed: 0.0112s/iter; left time: 15.6656s\n",
      "\titers: 500, epoch: 19 | loss: 0.1741313\n",
      "\tspeed: 0.0107s/iter; left time: 13.8682s\n",
      "\titers: 600, epoch: 19 | loss: 0.1584232\n",
      "\tspeed: 0.0107s/iter; left time: 12.8221s\n",
      "\titers: 700, epoch: 19 | loss: 0.1279612\n",
      "\tspeed: 0.0107s/iter; left time: 11.7531s\n",
      "\titers: 800, epoch: 19 | loss: 0.1158247\n",
      "\tspeed: 0.0102s/iter; left time: 10.1883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 899 | Train Loss: 0.1508698 Vali Loss: 0.1745520 Test Loss: 0.2032585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1795754\n",
      "\tspeed: 0.0483s/iter; left time: 38.6735s\n",
      "\titers: 200, epoch: 20 | loss: 0.1521554\n",
      "\tspeed: 0.0095s/iter; left time: 6.6735s\n",
      "\titers: 300, epoch: 20 | loss: 0.1934522\n",
      "\tspeed: 0.0099s/iter; left time: 5.9298s\n",
      "\titers: 400, epoch: 20 | loss: 0.1108449\n",
      "\tspeed: 0.0098s/iter; left time: 4.8878s\n",
      "\titers: 500, epoch: 20 | loss: 0.1611713\n",
      "\tspeed: 0.0098s/iter; left time: 3.9324s\n",
      "\titers: 600, epoch: 20 | loss: 0.1532575\n",
      "\tspeed: 0.0102s/iter; left time: 3.0487s\n",
      "\titers: 700, epoch: 20 | loss: 0.1145113\n",
      "\tspeed: 0.0096s/iter; left time: 1.9152s\n",
      "\titers: 800, epoch: 20 | loss: 0.1155148\n",
      "\tspeed: 0.0095s/iter; left time: 0.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.09s\n",
      "Steps: 899 | Train Loss: 0.1498911 Vali Loss: 0.1750316 Test Loss: 0.2044495\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20252715051174164, rmse:0.4500301778316498, mae:0.26186490058898926, rse:0.41215452551841736\n",
      "Original data scale mse:1178370.25, rmse:1085.527587890625, mae:706.22900390625, rse:0.07628258317708969\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9023709\n",
      "\tspeed: 0.0282s/iter; left time: 503.1490s\n",
      "\titers: 200, epoch: 1 | loss: 0.7118683\n",
      "\tspeed: 0.0098s/iter; left time: 173.5451s\n",
      "\titers: 300, epoch: 1 | loss: 0.6303343\n",
      "\tspeed: 0.0098s/iter; left time: 172.5990s\n",
      "\titers: 400, epoch: 1 | loss: 0.5885646\n",
      "\tspeed: 0.0098s/iter; left time: 171.9060s\n",
      "\titers: 500, epoch: 1 | loss: 0.5786479\n",
      "\tspeed: 0.0097s/iter; left time: 168.3732s\n",
      "\titers: 600, epoch: 1 | loss: 0.5647266\n",
      "\tspeed: 0.0092s/iter; left time: 159.4035s\n",
      "\titers: 700, epoch: 1 | loss: 0.5192021\n",
      "\tspeed: 0.0092s/iter; left time: 157.9376s\n",
      "\titers: 800, epoch: 1 | loss: 0.6190587\n",
      "\tspeed: 0.0089s/iter; left time: 152.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 897 | Train Loss: 0.6541967 Vali Loss: 0.4185980 Test Loss: 0.4427737\n",
      "Validation loss decreased (inf --> 0.418598).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4385380\n",
      "\tspeed: 0.0439s/iter; left time: 744.0321s\n",
      "\titers: 200, epoch: 2 | loss: 0.3624427\n",
      "\tspeed: 0.0091s/iter; left time: 152.8820s\n",
      "\titers: 300, epoch: 2 | loss: 0.3435023\n",
      "\tspeed: 0.0088s/iter; left time: 147.9554s\n",
      "\titers: 400, epoch: 2 | loss: 0.3864345\n",
      "\tspeed: 0.0088s/iter; left time: 146.6755s\n",
      "\titers: 500, epoch: 2 | loss: 0.3963156\n",
      "\tspeed: 0.0088s/iter; left time: 146.1709s\n",
      "\titers: 600, epoch: 2 | loss: 0.3259863\n",
      "\tspeed: 0.0090s/iter; left time: 147.6111s\n",
      "\titers: 700, epoch: 2 | loss: 0.2913958\n",
      "\tspeed: 0.0091s/iter; left time: 148.1030s\n",
      "\titers: 800, epoch: 2 | loss: 0.3540556\n",
      "\tspeed: 0.0091s/iter; left time: 147.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 897 | Train Loss: 0.3849244 Vali Loss: 0.3303383 Test Loss: 0.3639398\n",
      "Validation loss decreased (0.418598 --> 0.330338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3262998\n",
      "\tspeed: 0.0440s/iter; left time: 706.1828s\n",
      "\titers: 200, epoch: 3 | loss: 0.3514427\n",
      "\tspeed: 0.0112s/iter; left time: 177.9090s\n",
      "\titers: 300, epoch: 3 | loss: 0.2741455\n",
      "\tspeed: 0.0112s/iter; left time: 177.1670s\n",
      "\titers: 400, epoch: 3 | loss: 0.3516659\n",
      "\tspeed: 0.0111s/iter; left time: 174.2606s\n",
      "\titers: 500, epoch: 3 | loss: 0.2425122\n",
      "\tspeed: 0.0111s/iter; left time: 174.2947s\n",
      "\titers: 600, epoch: 3 | loss: 0.4527805\n",
      "\tspeed: 0.0111s/iter; left time: 172.4975s\n",
      "\titers: 700, epoch: 3 | loss: 0.3176483\n",
      "\tspeed: 0.0111s/iter; left time: 171.5747s\n",
      "\titers: 800, epoch: 3 | loss: 0.3269887\n",
      "\tspeed: 0.0111s/iter; left time: 170.9929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 897 | Train Loss: 0.3451432 Vali Loss: 0.3255730 Test Loss: 0.3585122\n",
      "Validation loss decreased (0.330338 --> 0.325573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3540097\n",
      "\tspeed: 0.0461s/iter; left time: 698.8238s\n",
      "\titers: 200, epoch: 4 | loss: 0.3148625\n",
      "\tspeed: 0.0099s/iter; left time: 149.0388s\n",
      "\titers: 300, epoch: 4 | loss: 0.3411119\n",
      "\tspeed: 0.0099s/iter; left time: 147.7772s\n",
      "\titers: 400, epoch: 4 | loss: 0.3427646\n",
      "\tspeed: 0.0099s/iter; left time: 147.1675s\n",
      "\titers: 500, epoch: 4 | loss: 0.2876420\n",
      "\tspeed: 0.0098s/iter; left time: 145.0203s\n",
      "\titers: 600, epoch: 4 | loss: 0.2727350\n",
      "\tspeed: 0.0095s/iter; left time: 138.7818s\n",
      "\titers: 700, epoch: 4 | loss: 0.4078430\n",
      "\tspeed: 0.0087s/iter; left time: 126.9253s\n",
      "\titers: 800, epoch: 4 | loss: 0.3040746\n",
      "\tspeed: 0.0087s/iter; left time: 125.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 897 | Train Loss: 0.3291367 Vali Loss: 0.3248031 Test Loss: 0.3559823\n",
      "Validation loss decreased (0.325573 --> 0.324803).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2959689\n",
      "\tspeed: 0.0434s/iter; left time: 619.2751s\n",
      "\titers: 200, epoch: 5 | loss: 0.2718244\n",
      "\tspeed: 0.0096s/iter; left time: 135.7537s\n",
      "\titers: 300, epoch: 5 | loss: 0.3076138\n",
      "\tspeed: 0.0098s/iter; left time: 137.2085s\n",
      "\titers: 400, epoch: 5 | loss: 0.3788649\n",
      "\tspeed: 0.0104s/iter; left time: 145.0328s\n",
      "\titers: 500, epoch: 5 | loss: 0.3968827\n",
      "\tspeed: 0.0107s/iter; left time: 147.8127s\n",
      "\titers: 600, epoch: 5 | loss: 0.2708218\n",
      "\tspeed: 0.0108s/iter; left time: 148.6984s\n",
      "\titers: 700, epoch: 5 | loss: 0.3091637\n",
      "\tspeed: 0.0110s/iter; left time: 149.5799s\n",
      "\titers: 800, epoch: 5 | loss: 0.4585109\n",
      "\tspeed: 0.0106s/iter; left time: 143.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 897 | Train Loss: 0.3149863 Vali Loss: 0.3256806 Test Loss: 0.3516513\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2811923\n",
      "\tspeed: 0.0441s/iter; left time: 589.4835s\n",
      "\titers: 200, epoch: 6 | loss: 0.2290090\n",
      "\tspeed: 0.0099s/iter; left time: 131.7363s\n",
      "\titers: 300, epoch: 6 | loss: 0.2880462\n",
      "\tspeed: 0.0099s/iter; left time: 130.5700s\n",
      "\titers: 400, epoch: 6 | loss: 0.2915324\n",
      "\tspeed: 0.0100s/iter; left time: 129.9936s\n",
      "\titers: 500, epoch: 6 | loss: 0.2910326\n",
      "\tspeed: 0.0099s/iter; left time: 128.3905s\n",
      "\titers: 600, epoch: 6 | loss: 0.2661616\n",
      "\tspeed: 0.0099s/iter; left time: 127.3850s\n",
      "\titers: 700, epoch: 6 | loss: 0.3336972\n",
      "\tspeed: 0.0099s/iter; left time: 126.3451s\n",
      "\titers: 800, epoch: 6 | loss: 0.2644136\n",
      "\tspeed: 0.0099s/iter; left time: 125.4576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 897 | Train Loss: 0.3013755 Vali Loss: 0.3219759 Test Loss: 0.3569717\n",
      "Validation loss decreased (0.324803 --> 0.321976).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3189336\n",
      "\tspeed: 0.0439s/iter; left time: 547.4992s\n",
      "\titers: 200, epoch: 7 | loss: 0.2478523\n",
      "\tspeed: 0.0099s/iter; left time: 122.6009s\n",
      "\titers: 300, epoch: 7 | loss: 0.2523442\n",
      "\tspeed: 0.0100s/iter; left time: 122.4377s\n",
      "\titers: 400, epoch: 7 | loss: 0.2517710\n",
      "\tspeed: 0.0098s/iter; left time: 119.6278s\n",
      "\titers: 500, epoch: 7 | loss: 0.2363069\n",
      "\tspeed: 0.0097s/iter; left time: 116.8907s\n",
      "\titers: 600, epoch: 7 | loss: 0.3667543\n",
      "\tspeed: 0.0097s/iter; left time: 115.8728s\n",
      "\titers: 700, epoch: 7 | loss: 0.3155922\n",
      "\tspeed: 0.0096s/iter; left time: 114.4098s\n",
      "\titers: 800, epoch: 7 | loss: 0.3187827\n",
      "\tspeed: 0.0097s/iter; left time: 113.5488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 897 | Train Loss: 0.2899064 Vali Loss: 0.3252428 Test Loss: 0.3613099\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2368941\n",
      "\tspeed: 0.0410s/iter; left time: 474.5322s\n",
      "\titers: 200, epoch: 8 | loss: 0.3146277\n",
      "\tspeed: 0.0088s/iter; left time: 100.3525s\n",
      "\titers: 300, epoch: 8 | loss: 0.3341261\n",
      "\tspeed: 0.0088s/iter; left time: 99.5307s\n",
      "\titers: 400, epoch: 8 | loss: 0.2582113\n",
      "\tspeed: 0.0087s/iter; left time: 97.8464s\n",
      "\titers: 500, epoch: 8 | loss: 0.2317291\n",
      "\tspeed: 0.0086s/iter; left time: 96.2395s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649657\n",
      "\tspeed: 0.0085s/iter; left time: 94.4907s\n",
      "\titers: 700, epoch: 8 | loss: 0.2541209\n",
      "\tspeed: 0.0085s/iter; left time: 92.7784s\n",
      "\titers: 800, epoch: 8 | loss: 0.3090145\n",
      "\tspeed: 0.0085s/iter; left time: 92.3328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 897 | Train Loss: 0.2788857 Vali Loss: 0.3274610 Test Loss: 0.3629384\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3449124\n",
      "\tspeed: 0.0419s/iter; left time: 447.3623s\n",
      "\titers: 200, epoch: 9 | loss: 0.2904998\n",
      "\tspeed: 0.0094s/iter; left time: 99.7299s\n",
      "\titers: 300, epoch: 9 | loss: 0.3058091\n",
      "\tspeed: 0.0086s/iter; left time: 89.7378s\n",
      "\titers: 400, epoch: 9 | loss: 0.2911087\n",
      "\tspeed: 0.0086s/iter; left time: 88.7701s\n",
      "\titers: 500, epoch: 9 | loss: 0.2553002\n",
      "\tspeed: 0.0085s/iter; left time: 87.6438s\n",
      "\titers: 600, epoch: 9 | loss: 0.2559891\n",
      "\tspeed: 0.0085s/iter; left time: 86.6768s\n",
      "\titers: 700, epoch: 9 | loss: 0.2762527\n",
      "\tspeed: 0.0085s/iter; left time: 85.7415s\n",
      "\titers: 800, epoch: 9 | loss: 0.2218111\n",
      "\tspeed: 0.0085s/iter; left time: 84.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 897 | Train Loss: 0.2698051 Vali Loss: 0.3284274 Test Loss: 0.3625137\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1887778\n",
      "\tspeed: 0.0401s/iter; left time: 391.3520s\n",
      "\titers: 200, epoch: 10 | loss: 0.2676644\n",
      "\tspeed: 0.0086s/iter; left time: 83.6129s\n",
      "\titers: 300, epoch: 10 | loss: 0.2241254\n",
      "\tspeed: 0.0088s/iter; left time: 84.1405s\n",
      "\titers: 400, epoch: 10 | loss: 0.3112211\n",
      "\tspeed: 0.0088s/iter; left time: 83.3881s\n",
      "\titers: 500, epoch: 10 | loss: 0.3208842\n",
      "\tspeed: 0.0088s/iter; left time: 82.3660s\n",
      "\titers: 600, epoch: 10 | loss: 0.2711429\n",
      "\tspeed: 0.0089s/iter; left time: 82.7702s\n",
      "\titers: 700, epoch: 10 | loss: 0.2398466\n",
      "\tspeed: 0.0090s/iter; left time: 82.7740s\n",
      "\titers: 800, epoch: 10 | loss: 0.2387672\n",
      "\tspeed: 0.0095s/iter; left time: 86.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 897 | Train Loss: 0.2630368 Vali Loss: 0.3263260 Test Loss: 0.3640893\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2824947\n",
      "\tspeed: 0.0412s/iter; left time: 365.3706s\n",
      "\titers: 200, epoch: 11 | loss: 0.3002585\n",
      "\tspeed: 0.0093s/iter; left time: 82.0047s\n",
      "\titers: 300, epoch: 11 | loss: 0.2524710\n",
      "\tspeed: 0.0097s/iter; left time: 83.7694s\n",
      "\titers: 400, epoch: 11 | loss: 0.2440666\n",
      "\tspeed: 0.0096s/iter; left time: 82.1302s\n",
      "\titers: 500, epoch: 11 | loss: 0.2958998\n",
      "\tspeed: 0.0087s/iter; left time: 73.3834s\n",
      "\titers: 600, epoch: 11 | loss: 0.2014191\n",
      "\tspeed: 0.0086s/iter; left time: 71.7001s\n",
      "\titers: 700, epoch: 11 | loss: 0.3180931\n",
      "\tspeed: 0.0087s/iter; left time: 71.7007s\n",
      "\titers: 800, epoch: 11 | loss: 0.2397275\n",
      "\tspeed: 0.0088s/iter; left time: 71.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 897 | Train Loss: 0.2553044 Vali Loss: 0.3318979 Test Loss: 0.3675163\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3569716811180115, rmse:0.5974710583686829, mae:0.3740488588809967, rse:0.5470473170280457\n",
      "Original data scale mse:2492006.0, rmse:1578.60888671875, mae:1051.84912109375, rse:0.11109315603971481\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8629879\n",
      "\tspeed: 0.0113s/iter; left time: 201.8682s\n",
      "\titers: 200, epoch: 1 | loss: 0.6752549\n",
      "\tspeed: 0.0087s/iter; left time: 154.4018s\n",
      "\titers: 300, epoch: 1 | loss: 0.6488466\n",
      "\tspeed: 0.0087s/iter; left time: 153.5738s\n",
      "\titers: 400, epoch: 1 | loss: 0.5567740\n",
      "\tspeed: 0.0087s/iter; left time: 152.7643s\n",
      "\titers: 500, epoch: 1 | loss: 0.5716978\n",
      "\tspeed: 0.0087s/iter; left time: 151.5409s\n",
      "\titers: 600, epoch: 1 | loss: 0.5107291\n",
      "\tspeed: 0.0085s/iter; left time: 147.4614s\n",
      "\titers: 700, epoch: 1 | loss: 0.4878373\n",
      "\tspeed: 0.0085s/iter; left time: 146.9255s\n",
      "\titers: 800, epoch: 1 | loss: 0.5672198\n",
      "\tspeed: 0.0085s/iter; left time: 145.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 897 | Train Loss: 0.6482735 Vali Loss: 0.4182647 Test Loss: 0.4421777\n",
      "Validation loss decreased (inf --> 0.418265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4571468\n",
      "\tspeed: 0.0409s/iter; left time: 692.8786s\n",
      "\titers: 200, epoch: 2 | loss: 0.3971057\n",
      "\tspeed: 0.0088s/iter; left time: 148.8949s\n",
      "\titers: 300, epoch: 2 | loss: 0.3772953\n",
      "\tspeed: 0.0090s/iter; left time: 150.2652s\n",
      "\titers: 400, epoch: 2 | loss: 0.3412876\n",
      "\tspeed: 0.0087s/iter; left time: 145.1766s\n",
      "\titers: 500, epoch: 2 | loss: 0.3738047\n",
      "\tspeed: 0.0087s/iter; left time: 144.1822s\n",
      "\titers: 600, epoch: 2 | loss: 0.3636101\n",
      "\tspeed: 0.0087s/iter; left time: 143.6296s\n",
      "\titers: 700, epoch: 2 | loss: 0.3916110\n",
      "\tspeed: 0.0087s/iter; left time: 142.9536s\n",
      "\titers: 800, epoch: 2 | loss: 0.3499900\n",
      "\tspeed: 0.0088s/iter; left time: 142.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 897 | Train Loss: 0.3853006 Vali Loss: 0.3266637 Test Loss: 0.3616928\n",
      "Validation loss decreased (0.418265 --> 0.326664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2935314\n",
      "\tspeed: 0.0413s/iter; left time: 662.3994s\n",
      "\titers: 200, epoch: 3 | loss: 0.3492098\n",
      "\tspeed: 0.0087s/iter; left time: 139.2570s\n",
      "\titers: 300, epoch: 3 | loss: 0.3493505\n",
      "\tspeed: 0.0087s/iter; left time: 138.0737s\n",
      "\titers: 400, epoch: 3 | loss: 0.3928383\n",
      "\tspeed: 0.0087s/iter; left time: 137.3829s\n",
      "\titers: 500, epoch: 3 | loss: 0.3266641\n",
      "\tspeed: 0.0087s/iter; left time: 136.5291s\n",
      "\titers: 600, epoch: 3 | loss: 0.3293491\n",
      "\tspeed: 0.0087s/iter; left time: 135.3267s\n",
      "\titers: 700, epoch: 3 | loss: 0.3059039\n",
      "\tspeed: 0.0087s/iter; left time: 134.8201s\n",
      "\titers: 800, epoch: 3 | loss: 0.3485625\n",
      "\tspeed: 0.0087s/iter; left time: 133.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 897 | Train Loss: 0.3450314 Vali Loss: 0.3225645 Test Loss: 0.3597109\n",
      "Validation loss decreased (0.326664 --> 0.322564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3226652\n",
      "\tspeed: 0.0412s/iter; left time: 623.8748s\n",
      "\titers: 200, epoch: 4 | loss: 0.2863240\n",
      "\tspeed: 0.0085s/iter; left time: 128.2373s\n",
      "\titers: 300, epoch: 4 | loss: 0.3070149\n",
      "\tspeed: 0.0085s/iter; left time: 127.3782s\n",
      "\titers: 400, epoch: 4 | loss: 0.4306839\n",
      "\tspeed: 0.0085s/iter; left time: 126.5066s\n",
      "\titers: 500, epoch: 4 | loss: 0.3510099\n",
      "\tspeed: 0.0085s/iter; left time: 126.0857s\n",
      "\titers: 600, epoch: 4 | loss: 0.3462639\n",
      "\tspeed: 0.0085s/iter; left time: 124.6492s\n",
      "\titers: 700, epoch: 4 | loss: 0.2953328\n",
      "\tspeed: 0.0085s/iter; left time: 123.5705s\n",
      "\titers: 800, epoch: 4 | loss: 0.3172990\n",
      "\tspeed: 0.0085s/iter; left time: 122.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 897 | Train Loss: 0.3306733 Vali Loss: 0.3261314 Test Loss: 0.3599828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3422692\n",
      "\tspeed: 0.0415s/iter; left time: 592.0276s\n",
      "\titers: 200, epoch: 5 | loss: 0.3456689\n",
      "\tspeed: 0.0094s/iter; left time: 133.6041s\n",
      "\titers: 300, epoch: 5 | loss: 0.2650091\n",
      "\tspeed: 0.0094s/iter; left time: 132.7772s\n",
      "\titers: 400, epoch: 5 | loss: 0.3323134\n",
      "\tspeed: 0.0095s/iter; left time: 132.0405s\n",
      "\titers: 500, epoch: 5 | loss: 0.2816601\n",
      "\tspeed: 0.0095s/iter; left time: 131.7769s\n",
      "\titers: 600, epoch: 5 | loss: 0.3381370\n",
      "\tspeed: 0.0093s/iter; left time: 127.7407s\n",
      "\titers: 700, epoch: 5 | loss: 0.2926513\n",
      "\tspeed: 0.0089s/iter; left time: 121.7503s\n",
      "\titers: 800, epoch: 5 | loss: 0.3868202\n",
      "\tspeed: 0.0089s/iter; left time: 120.9035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 897 | Train Loss: 0.3180861 Vali Loss: 0.3273807 Test Loss: 0.3581979\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3938394\n",
      "\tspeed: 0.0409s/iter; left time: 546.4599s\n",
      "\titers: 200, epoch: 6 | loss: 0.3244178\n",
      "\tspeed: 0.0086s/iter; left time: 114.4280s\n",
      "\titers: 300, epoch: 6 | loss: 0.2895657\n",
      "\tspeed: 0.0086s/iter; left time: 113.5985s\n",
      "\titers: 400, epoch: 6 | loss: 0.3295440\n",
      "\tspeed: 0.0087s/iter; left time: 113.1087s\n",
      "\titers: 500, epoch: 6 | loss: 0.3089418\n",
      "\tspeed: 0.0087s/iter; left time: 112.0812s\n",
      "\titers: 600, epoch: 6 | loss: 0.2791779\n",
      "\tspeed: 0.0086s/iter; left time: 110.7398s\n",
      "\titers: 700, epoch: 6 | loss: 0.2838320\n",
      "\tspeed: 0.0086s/iter; left time: 110.0153s\n",
      "\titers: 800, epoch: 6 | loss: 0.2849742\n",
      "\tspeed: 0.0086s/iter; left time: 109.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 897 | Train Loss: 0.3049860 Vali Loss: 0.3268445 Test Loss: 0.3606200\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3585132\n",
      "\tspeed: 0.0397s/iter; left time: 494.5472s\n",
      "\titers: 200, epoch: 7 | loss: 0.3335386\n",
      "\tspeed: 0.0086s/iter; left time: 105.8707s\n",
      "\titers: 300, epoch: 7 | loss: 0.2367492\n",
      "\tspeed: 0.0085s/iter; left time: 103.9122s\n",
      "\titers: 400, epoch: 7 | loss: 0.2773902\n",
      "\tspeed: 0.0085s/iter; left time: 102.8646s\n",
      "\titers: 500, epoch: 7 | loss: 0.3344440\n",
      "\tspeed: 0.0085s/iter; left time: 102.0768s\n",
      "\titers: 600, epoch: 7 | loss: 0.2715367\n",
      "\tspeed: 0.0084s/iter; left time: 100.9791s\n",
      "\titers: 700, epoch: 7 | loss: 0.3438804\n",
      "\tspeed: 0.0084s/iter; left time: 100.1994s\n",
      "\titers: 800, epoch: 7 | loss: 0.2747950\n",
      "\tspeed: 0.0085s/iter; left time: 99.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 897 | Train Loss: 0.2923166 Vali Loss: 0.3298374 Test Loss: 0.3664121\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2708820\n",
      "\tspeed: 0.0397s/iter; left time: 458.8616s\n",
      "\titers: 200, epoch: 8 | loss: 0.2638570\n",
      "\tspeed: 0.0088s/iter; left time: 101.0449s\n",
      "\titers: 300, epoch: 8 | loss: 0.2747504\n",
      "\tspeed: 0.0088s/iter; left time: 100.2951s\n",
      "\titers: 400, epoch: 8 | loss: 0.2798580\n",
      "\tspeed: 0.0088s/iter; left time: 99.4373s\n",
      "\titers: 500, epoch: 8 | loss: 0.2573391\n",
      "\tspeed: 0.0088s/iter; left time: 98.5950s\n",
      "\titers: 600, epoch: 8 | loss: 0.2728603\n",
      "\tspeed: 0.0088s/iter; left time: 97.4456s\n",
      "\titers: 700, epoch: 8 | loss: 0.2540934\n",
      "\tspeed: 0.0087s/iter; left time: 95.6914s\n",
      "\titers: 800, epoch: 8 | loss: 0.3003016\n",
      "\tspeed: 0.0085s/iter; left time: 92.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 897 | Train Loss: 0.2811039 Vali Loss: 0.3277870 Test Loss: 0.3645265\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.35971105098724365, rmse:0.5997591614723206, mae:0.38184961676597595, rse:0.5491423010826111\n",
      "Original data scale mse:2693139.25, rmse:1641.0787353515625, mae:1101.3221435546875, rse:0.1154894083738327\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8650291\n",
      "\tspeed: 0.0279s/iter; left time: 496.9369s\n",
      "\titers: 200, epoch: 1 | loss: 0.7120326\n",
      "\tspeed: 0.0099s/iter; left time: 175.3667s\n",
      "\titers: 300, epoch: 1 | loss: 0.6896478\n",
      "\tspeed: 0.0099s/iter; left time: 174.1692s\n",
      "\titers: 400, epoch: 1 | loss: 0.5948638\n",
      "\tspeed: 0.0098s/iter; left time: 171.5536s\n",
      "\titers: 500, epoch: 1 | loss: 0.6314639\n",
      "\tspeed: 0.0095s/iter; left time: 165.4157s\n",
      "\titers: 600, epoch: 1 | loss: 0.5181844\n",
      "\tspeed: 0.0095s/iter; left time: 163.7991s\n",
      "\titers: 700, epoch: 1 | loss: 0.5106045\n",
      "\tspeed: 0.0097s/iter; left time: 166.4458s\n",
      "\titers: 800, epoch: 1 | loss: 0.4941662\n",
      "\tspeed: 0.0098s/iter; left time: 168.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.17s\n",
      "Steps: 894 | Train Loss: 0.6732572 Vali Loss: 0.4426865 Test Loss: 0.4611520\n",
      "Validation loss decreased (inf --> 0.442687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4362513\n",
      "\tspeed: 0.0529s/iter; left time: 893.6151s\n",
      "\titers: 200, epoch: 2 | loss: 0.4604670\n",
      "\tspeed: 0.0098s/iter; left time: 164.6085s\n",
      "\titers: 300, epoch: 2 | loss: 0.4379824\n",
      "\tspeed: 0.0097s/iter; left time: 161.3915s\n",
      "\titers: 400, epoch: 2 | loss: 0.4900250\n",
      "\tspeed: 0.0087s/iter; left time: 145.1321s\n",
      "\titers: 500, epoch: 2 | loss: 0.4331226\n",
      "\tspeed: 0.0087s/iter; left time: 143.8991s\n",
      "\titers: 600, epoch: 2 | loss: 0.4699836\n",
      "\tspeed: 0.0087s/iter; left time: 142.9936s\n",
      "\titers: 700, epoch: 2 | loss: 0.4339241\n",
      "\tspeed: 0.0087s/iter; left time: 142.0913s\n",
      "\titers: 800, epoch: 2 | loss: 0.4113488\n",
      "\tspeed: 0.0087s/iter; left time: 141.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 894 | Train Loss: 0.4139376 Vali Loss: 0.3605645 Test Loss: 0.3889714\n",
      "Validation loss decreased (0.442687 --> 0.360565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4390221\n",
      "\tspeed: 0.0419s/iter; left time: 669.9696s\n",
      "\titers: 200, epoch: 3 | loss: 0.3950980\n",
      "\tspeed: 0.0095s/iter; left time: 151.2390s\n",
      "\titers: 300, epoch: 3 | loss: 0.3587230\n",
      "\tspeed: 0.0094s/iter; left time: 149.0659s\n",
      "\titers: 400, epoch: 3 | loss: 0.4357815\n",
      "\tspeed: 0.0095s/iter; left time: 148.5139s\n",
      "\titers: 500, epoch: 3 | loss: 0.3138253\n",
      "\tspeed: 0.0095s/iter; left time: 147.5424s\n",
      "\titers: 600, epoch: 3 | loss: 0.4150011\n",
      "\tspeed: 0.0094s/iter; left time: 146.2974s\n",
      "\titers: 700, epoch: 3 | loss: 0.4086972\n",
      "\tspeed: 0.0094s/iter; left time: 145.4562s\n",
      "\titers: 800, epoch: 3 | loss: 0.4099678\n",
      "\tspeed: 0.0095s/iter; left time: 145.6648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 894 | Train Loss: 0.3723422 Vali Loss: 0.3634326 Test Loss: 0.3940627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4114258\n",
      "\tspeed: 0.1169s/iter; left time: 1765.4316s\n",
      "\titers: 200, epoch: 4 | loss: 0.3320698\n",
      "\tspeed: 0.0101s/iter; left time: 151.7917s\n",
      "\titers: 300, epoch: 4 | loss: 0.3516684\n",
      "\tspeed: 0.0099s/iter; left time: 148.1813s\n",
      "\titers: 400, epoch: 4 | loss: 0.3376744\n",
      "\tspeed: 0.0101s/iter; left time: 149.2491s\n",
      "\titers: 500, epoch: 4 | loss: 0.3431910\n",
      "\tspeed: 0.0101s/iter; left time: 148.5560s\n",
      "\titers: 600, epoch: 4 | loss: 0.3279227\n",
      "\tspeed: 0.0092s/iter; left time: 134.3854s\n",
      "\titers: 700, epoch: 4 | loss: 0.3676272\n",
      "\tspeed: 0.0089s/iter; left time: 129.2975s\n",
      "\titers: 800, epoch: 4 | loss: 0.3017296\n",
      "\tspeed: 0.0090s/iter; left time: 130.2814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 894 | Train Loss: 0.3569012 Vali Loss: 0.3639124 Test Loss: 0.3991316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3147646\n",
      "\tspeed: 0.0430s/iter; left time: 610.5645s\n",
      "\titers: 200, epoch: 5 | loss: 0.3286140\n",
      "\tspeed: 0.0090s/iter; left time: 126.9229s\n",
      "\titers: 300, epoch: 5 | loss: 0.3863384\n",
      "\tspeed: 0.0090s/iter; left time: 126.2358s\n",
      "\titers: 400, epoch: 5 | loss: 0.3734428\n",
      "\tspeed: 0.0089s/iter; left time: 124.1230s\n",
      "\titers: 500, epoch: 5 | loss: 0.3287988\n",
      "\tspeed: 0.0089s/iter; left time: 122.8669s\n",
      "\titers: 600, epoch: 5 | loss: 0.3638388\n",
      "\tspeed: 0.0089s/iter; left time: 122.0865s\n",
      "\titers: 700, epoch: 5 | loss: 0.3051259\n",
      "\tspeed: 0.0089s/iter; left time: 121.3409s\n",
      "\titers: 800, epoch: 5 | loss: 0.3753051\n",
      "\tspeed: 0.0089s/iter; left time: 120.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 894 | Train Loss: 0.3395032 Vali Loss: 0.3558247 Test Loss: 0.3989559\n",
      "Validation loss decreased (0.360565 --> 0.355825).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3599760\n",
      "\tspeed: 0.0426s/iter; left time: 567.1500s\n",
      "\titers: 200, epoch: 6 | loss: 0.2798906\n",
      "\tspeed: 0.0089s/iter; left time: 117.8680s\n",
      "\titers: 300, epoch: 6 | loss: 0.3275054\n",
      "\tspeed: 0.0088s/iter; left time: 115.1580s\n",
      "\titers: 400, epoch: 6 | loss: 0.3468530\n",
      "\tspeed: 0.0087s/iter; left time: 113.3045s\n",
      "\titers: 500, epoch: 6 | loss: 0.3237377\n",
      "\tspeed: 0.0087s/iter; left time: 112.5037s\n",
      "\titers: 600, epoch: 6 | loss: 0.3374587\n",
      "\tspeed: 0.0087s/iter; left time: 111.6039s\n",
      "\titers: 700, epoch: 6 | loss: 0.3852836\n",
      "\tspeed: 0.0087s/iter; left time: 110.6774s\n",
      "\titers: 800, epoch: 6 | loss: 0.2672887\n",
      "\tspeed: 0.0087s/iter; left time: 109.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 894 | Train Loss: 0.3226182 Vali Loss: 0.3672323 Test Loss: 0.3909459\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3234253\n",
      "\tspeed: 0.0403s/iter; left time: 500.4227s\n",
      "\titers: 200, epoch: 7 | loss: 0.2744628\n",
      "\tspeed: 0.0085s/iter; left time: 105.0953s\n",
      "\titers: 300, epoch: 7 | loss: 0.3141358\n",
      "\tspeed: 0.0085s/iter; left time: 104.3614s\n",
      "\titers: 400, epoch: 7 | loss: 0.3097932\n",
      "\tspeed: 0.0086s/iter; left time: 103.8241s\n",
      "\titers: 500, epoch: 7 | loss: 0.3496243\n",
      "\tspeed: 0.0086s/iter; left time: 102.7672s\n",
      "\titers: 600, epoch: 7 | loss: 0.3043375\n",
      "\tspeed: 0.0089s/iter; left time: 105.7182s\n",
      "\titers: 700, epoch: 7 | loss: 0.2879458\n",
      "\tspeed: 0.0087s/iter; left time: 103.3687s\n",
      "\titers: 800, epoch: 7 | loss: 0.2752822\n",
      "\tspeed: 0.0087s/iter; left time: 101.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 894 | Train Loss: 0.3074871 Vali Loss: 0.3651821 Test Loss: 0.4005122\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2724565\n",
      "\tspeed: 0.0399s/iter; left time: 459.7613s\n",
      "\titers: 200, epoch: 8 | loss: 0.2505352\n",
      "\tspeed: 0.0087s/iter; left time: 99.5239s\n",
      "\titers: 300, epoch: 8 | loss: 0.2884567\n",
      "\tspeed: 0.0087s/iter; left time: 98.6576s\n",
      "\titers: 400, epoch: 8 | loss: 0.2649095\n",
      "\tspeed: 0.0087s/iter; left time: 98.0513s\n",
      "\titers: 500, epoch: 8 | loss: 0.2546944\n",
      "\tspeed: 0.0092s/iter; left time: 102.6023s\n",
      "\titers: 600, epoch: 8 | loss: 0.2343189\n",
      "\tspeed: 0.0118s/iter; left time: 130.5350s\n",
      "\titers: 700, epoch: 8 | loss: 0.3500673\n",
      "\tspeed: 0.0094s/iter; left time: 103.1629s\n",
      "\titers: 800, epoch: 8 | loss: 0.2790954\n",
      "\tspeed: 0.0097s/iter; left time: 104.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 894 | Train Loss: 0.2940368 Vali Loss: 0.3688686 Test Loss: 0.4052595\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2922402\n",
      "\tspeed: 0.0717s/iter; left time: 761.6287s\n",
      "\titers: 200, epoch: 9 | loss: 0.3136761\n",
      "\tspeed: 0.0574s/iter; left time: 604.4345s\n",
      "\titers: 300, epoch: 9 | loss: 0.2904491\n",
      "\tspeed: 0.0577s/iter; left time: 602.2715s\n",
      "\titers: 400, epoch: 9 | loss: 0.2847520\n",
      "\tspeed: 0.0591s/iter; left time: 610.3531s\n",
      "\titers: 500, epoch: 9 | loss: 0.2848399\n",
      "\tspeed: 0.0656s/iter; left time: 670.5793s\n",
      "\titers: 600, epoch: 9 | loss: 0.2818712\n",
      "\tspeed: 0.0578s/iter; left time: 585.5562s\n",
      "\titers: 700, epoch: 9 | loss: 0.2508163\n",
      "\tspeed: 0.0539s/iter; left time: 540.8591s\n",
      "\titers: 800, epoch: 9 | loss: 0.3206994\n",
      "\tspeed: 0.0600s/iter; left time: 595.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.64s\n",
      "Steps: 894 | Train Loss: 0.2835710 Vali Loss: 0.3636105 Test Loss: 0.4030739\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2489856\n",
      "\tspeed: 0.3131s/iter; left time: 3048.4808s\n",
      "\titers: 200, epoch: 10 | loss: 0.2740938\n",
      "\tspeed: 0.0643s/iter; left time: 619.8657s\n",
      "\titers: 300, epoch: 10 | loss: 0.2727333\n",
      "\tspeed: 0.0468s/iter; left time: 446.6015s\n",
      "\titers: 400, epoch: 10 | loss: 0.2735113\n",
      "\tspeed: 0.0230s/iter; left time: 216.6768s\n",
      "\titers: 500, epoch: 10 | loss: 0.2991241\n",
      "\tspeed: 0.0209s/iter; left time: 195.3285s\n",
      "\titers: 600, epoch: 10 | loss: 0.2883359\n",
      "\tspeed: 0.0131s/iter; left time: 121.0787s\n",
      "\titers: 700, epoch: 10 | loss: 0.2580786\n",
      "\tspeed: 0.0111s/iter; left time: 101.1842s\n",
      "\titers: 800, epoch: 10 | loss: 0.2442745\n",
      "\tspeed: 0.0108s/iter; left time: 97.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.66s\n",
      "Steps: 894 | Train Loss: 0.2748904 Vali Loss: 0.3624854 Test Loss: 0.4079892\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.39895567297935486, rmse:0.6316294074058533, mae:0.40674835443496704, rse:0.5784950852394104\n",
      "Original data scale mse:3082198.25, rmse:1755.6190185546875, mae:1179.6866455078125, rse:0.12366610765457153\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8846574\n",
      "\tspeed: 0.0117s/iter; left time: 208.5651s\n",
      "\titers: 200, epoch: 1 | loss: 0.6947731\n",
      "\tspeed: 0.0093s/iter; left time: 164.9085s\n",
      "\titers: 300, epoch: 1 | loss: 0.6757308\n",
      "\tspeed: 0.0093s/iter; left time: 164.3083s\n",
      "\titers: 400, epoch: 1 | loss: 0.5790245\n",
      "\tspeed: 0.0093s/iter; left time: 162.7282s\n",
      "\titers: 500, epoch: 1 | loss: 0.5771477\n",
      "\tspeed: 0.0093s/iter; left time: 162.3445s\n",
      "\titers: 600, epoch: 1 | loss: 0.4772144\n",
      "\tspeed: 0.0093s/iter; left time: 161.4430s\n",
      "\titers: 700, epoch: 1 | loss: 0.5087042\n",
      "\tspeed: 0.0093s/iter; left time: 160.2462s\n",
      "\titers: 800, epoch: 1 | loss: 0.5628862\n",
      "\tspeed: 0.0093s/iter; left time: 159.2894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 894 | Train Loss: 0.6736087 Vali Loss: 0.4425660 Test Loss: 0.4604475\n",
      "Validation loss decreased (inf --> 0.442566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3914026\n",
      "\tspeed: 0.0428s/iter; left time: 723.0734s\n",
      "\titers: 200, epoch: 2 | loss: 0.4341299\n",
      "\tspeed: 0.0088s/iter; left time: 147.5977s\n",
      "\titers: 300, epoch: 2 | loss: 0.3785777\n",
      "\tspeed: 0.0092s/iter; left time: 154.3034s\n",
      "\titers: 400, epoch: 2 | loss: 0.3786357\n",
      "\tspeed: 0.0093s/iter; left time: 154.6911s\n",
      "\titers: 500, epoch: 2 | loss: 0.4005822\n",
      "\tspeed: 0.0093s/iter; left time: 153.2813s\n",
      "\titers: 600, epoch: 2 | loss: 0.3660025\n",
      "\tspeed: 0.0093s/iter; left time: 152.8009s\n",
      "\titers: 700, epoch: 2 | loss: 0.3596464\n",
      "\tspeed: 0.0093s/iter; left time: 152.2501s\n",
      "\titers: 800, epoch: 2 | loss: 0.4002900\n",
      "\tspeed: 0.0093s/iter; left time: 150.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 894 | Train Loss: 0.4136689 Vali Loss: 0.3602259 Test Loss: 0.3907548\n",
      "Validation loss decreased (0.442566 --> 0.360226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3682706\n",
      "\tspeed: 0.0425s/iter; left time: 680.1460s\n",
      "\titers: 200, epoch: 3 | loss: 0.3699563\n",
      "\tspeed: 0.0086s/iter; left time: 137.2417s\n",
      "\titers: 300, epoch: 3 | loss: 0.3253953\n",
      "\tspeed: 0.0086s/iter; left time: 136.5476s\n",
      "\titers: 400, epoch: 3 | loss: 0.3792088\n",
      "\tspeed: 0.0086s/iter; left time: 135.4630s\n",
      "\titers: 500, epoch: 3 | loss: 0.4250415\n",
      "\tspeed: 0.0085s/iter; left time: 132.4088s\n",
      "\titers: 600, epoch: 3 | loss: 0.3295353\n",
      "\tspeed: 0.0085s/iter; left time: 132.2107s\n",
      "\titers: 700, epoch: 3 | loss: 0.3875653\n",
      "\tspeed: 0.0086s/iter; left time: 132.5009s\n",
      "\titers: 800, epoch: 3 | loss: 0.3400064\n",
      "\tspeed: 0.0086s/iter; left time: 131.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 894 | Train Loss: 0.3731053 Vali Loss: 0.3556686 Test Loss: 0.3850469\n",
      "Validation loss decreased (0.360226 --> 0.355669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3374731\n",
      "\tspeed: 0.0408s/iter; left time: 616.4966s\n",
      "\titers: 200, epoch: 4 | loss: 0.3161117\n",
      "\tspeed: 0.0090s/iter; left time: 134.2695s\n",
      "\titers: 300, epoch: 4 | loss: 0.3617721\n",
      "\tspeed: 0.0090s/iter; left time: 133.4156s\n",
      "\titers: 400, epoch: 4 | loss: 0.3677353\n",
      "\tspeed: 0.0090s/iter; left time: 132.5247s\n",
      "\titers: 500, epoch: 4 | loss: 0.3795101\n",
      "\tspeed: 0.0090s/iter; left time: 131.8898s\n",
      "\titers: 600, epoch: 4 | loss: 0.3474153\n",
      "\tspeed: 0.0090s/iter; left time: 132.0017s\n",
      "\titers: 700, epoch: 4 | loss: 0.3643577\n",
      "\tspeed: 0.0089s/iter; left time: 129.7599s\n",
      "\titers: 800, epoch: 4 | loss: 0.3665947\n",
      "\tspeed: 0.0088s/iter; left time: 126.6475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 894 | Train Loss: 0.3567274 Vali Loss: 0.3588086 Test Loss: 0.3878742\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3281340\n",
      "\tspeed: 0.0421s/iter; left time: 597.3398s\n",
      "\titers: 200, epoch: 5 | loss: 0.3816561\n",
      "\tspeed: 0.0100s/iter; left time: 141.0653s\n",
      "\titers: 300, epoch: 5 | loss: 0.3013256\n",
      "\tspeed: 0.0100s/iter; left time: 139.4497s\n",
      "\titers: 400, epoch: 5 | loss: 0.3661686\n",
      "\tspeed: 0.0100s/iter; left time: 138.5766s\n",
      "\titers: 500, epoch: 5 | loss: 0.3384695\n",
      "\tspeed: 0.0100s/iter; left time: 137.6568s\n",
      "\titers: 600, epoch: 5 | loss: 0.3144844\n",
      "\tspeed: 0.0100s/iter; left time: 136.6418s\n",
      "\titers: 700, epoch: 5 | loss: 0.3790110\n",
      "\tspeed: 0.0099s/iter; left time: 135.3358s\n",
      "\titers: 800, epoch: 5 | loss: 0.3176265\n",
      "\tspeed: 0.0100s/iter; left time: 134.4245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 894 | Train Loss: 0.3395184 Vali Loss: 0.3624209 Test Loss: 0.4011379\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2693781\n",
      "\tspeed: 0.0416s/iter; left time: 553.6599s\n",
      "\titers: 200, epoch: 6 | loss: 0.3325165\n",
      "\tspeed: 0.0087s/iter; left time: 115.2449s\n",
      "\titers: 300, epoch: 6 | loss: 0.3099601\n",
      "\tspeed: 0.0088s/iter; left time: 114.7558s\n",
      "\titers: 400, epoch: 6 | loss: 0.2975692\n",
      "\tspeed: 0.0088s/iter; left time: 114.1780s\n",
      "\titers: 500, epoch: 6 | loss: 0.3659286\n",
      "\tspeed: 0.0087s/iter; left time: 112.2327s\n",
      "\titers: 600, epoch: 6 | loss: 0.3293519\n",
      "\tspeed: 0.0116s/iter; left time: 149.1788s\n",
      "\titers: 700, epoch: 6 | loss: 0.2891266\n",
      "\tspeed: 0.0088s/iter; left time: 112.3737s\n",
      "\titers: 800, epoch: 6 | loss: 0.2944975\n",
      "\tspeed: 0.0095s/iter; left time: 120.3586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 894 | Train Loss: 0.3228436 Vali Loss: 0.3646999 Test Loss: 0.4026258\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4004287\n",
      "\tspeed: 0.2563s/iter; left time: 3182.4027s\n",
      "\titers: 200, epoch: 7 | loss: 0.2570741\n",
      "\tspeed: 0.0594s/iter; left time: 731.8568s\n",
      "\titers: 300, epoch: 7 | loss: 0.3329300\n",
      "\tspeed: 0.0569s/iter; left time: 695.7519s\n",
      "\titers: 400, epoch: 7 | loss: 0.3312670\n",
      "\tspeed: 0.0548s/iter; left time: 663.7514s\n",
      "\titers: 500, epoch: 7 | loss: 0.3504340\n",
      "\tspeed: 0.0562s/iter; left time: 675.9112s\n",
      "\titers: 600, epoch: 7 | loss: 0.3200604\n",
      "\tspeed: 0.0579s/iter; left time: 690.1701s\n",
      "\titers: 700, epoch: 7 | loss: 0.3151236\n",
      "\tspeed: 0.0524s/iter; left time: 619.1796s\n",
      "\titers: 800, epoch: 7 | loss: 0.2665381\n",
      "\tspeed: 0.0582s/iter; left time: 681.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.38s\n",
      "Steps: 894 | Train Loss: 0.3080992 Vali Loss: 0.3690492 Test Loss: 0.4084581\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2982433\n",
      "\tspeed: 0.2918s/iter; left time: 3362.3717s\n",
      "\titers: 200, epoch: 8 | loss: 0.3278830\n",
      "\tspeed: 0.0514s/iter; left time: 586.8805s\n",
      "\titers: 300, epoch: 8 | loss: 0.2621333\n",
      "\tspeed: 0.0522s/iter; left time: 591.4328s\n",
      "\titers: 400, epoch: 8 | loss: 0.2531180\n",
      "\tspeed: 0.0526s/iter; left time: 590.1098s\n",
      "\titers: 500, epoch: 8 | loss: 0.2748438\n",
      "\tspeed: 0.0498s/iter; left time: 553.7580s\n",
      "\titers: 600, epoch: 8 | loss: 0.2857252\n",
      "\tspeed: 0.0499s/iter; left time: 549.5881s\n",
      "\titers: 700, epoch: 8 | loss: 0.3164103\n",
      "\tspeed: 0.0533s/iter; left time: 582.6702s\n",
      "\titers: 800, epoch: 8 | loss: 0.2866903\n",
      "\tspeed: 0.0571s/iter; left time: 617.7716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.50s\n",
      "Steps: 894 | Train Loss: 0.2947745 Vali Loss: 0.3644419 Test Loss: 0.4173954\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38504692912101746, rmse:0.6205214858055115, mae:0.4034557640552521, rse:0.5683216452598572\n",
      "Original data scale mse:3154101.0, rmse:1775.9788818359375, mae:1187.391357421875, rse:0.1251002550125122\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7039745\n",
      "\tspeed: 0.0832s/iter; left time: 1487.4620s\n",
      "\titers: 200, epoch: 1 | loss: 0.6760503\n",
      "\tspeed: 0.0518s/iter; left time: 920.8366s\n",
      "\titers: 300, epoch: 1 | loss: 0.5769762\n",
      "\tspeed: 0.0564s/iter; left time: 997.8336s\n",
      "\titers: 400, epoch: 1 | loss: 0.5438560\n",
      "\tspeed: 0.0553s/iter; left time: 972.9675s\n",
      "\titers: 500, epoch: 1 | loss: 0.4997446\n",
      "\tspeed: 0.0580s/iter; left time: 1013.0469s\n",
      "\titers: 600, epoch: 1 | loss: 0.5052770\n",
      "\tspeed: 0.0556s/iter; left time: 966.6429s\n",
      "\titers: 700, epoch: 1 | loss: 0.4249678\n",
      "\tspeed: 0.0609s/iter; left time: 1052.1609s\n",
      "\titers: 800, epoch: 1 | loss: 0.4422143\n",
      "\tspeed: 0.0619s/iter; left time: 1063.7415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:52.70s\n",
      "Steps: 899 | Train Loss: 0.5623283 Vali Loss: 0.3817038 Test Loss: 0.3911321\n",
      "Validation loss decreased (inf --> 0.381704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3715000\n",
      "\tspeed: 0.3186s/iter; left time: 5411.0518s\n",
      "\titers: 200, epoch: 2 | loss: 0.3361026\n",
      "\tspeed: 0.0556s/iter; left time: 938.7104s\n",
      "\titers: 300, epoch: 2 | loss: 0.3275023\n",
      "\tspeed: 0.0549s/iter; left time: 921.3412s\n",
      "\titers: 400, epoch: 2 | loss: 0.3223957\n",
      "\tspeed: 0.0514s/iter; left time: 857.2075s\n",
      "\titers: 500, epoch: 2 | loss: 0.3182891\n",
      "\tspeed: 0.0596s/iter; left time: 988.2517s\n",
      "\titers: 600, epoch: 2 | loss: 0.2891975\n",
      "\tspeed: 0.0415s/iter; left time: 683.4656s\n",
      "\titers: 700, epoch: 2 | loss: 0.3300719\n",
      "\tspeed: 0.0393s/iter; left time: 643.4247s\n",
      "\titers: 800, epoch: 2 | loss: 0.3067408\n",
      "\tspeed: 0.0392s/iter; left time: 639.0404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 899 | Train Loss: 0.3281605 Vali Loss: 0.2781286 Test Loss: 0.2893726\n",
      "Validation loss decreased (0.381704 --> 0.278129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2958922\n",
      "\tspeed: 0.2931s/iter; left time: 4713.2175s\n",
      "\titers: 200, epoch: 3 | loss: 0.2573656\n",
      "\tspeed: 0.0515s/iter; left time: 823.2169s\n",
      "\titers: 300, epoch: 3 | loss: 0.3162041\n",
      "\tspeed: 0.0561s/iter; left time: 890.9803s\n",
      "\titers: 400, epoch: 3 | loss: 0.2730342\n",
      "\tspeed: 0.0524s/iter; left time: 826.4021s\n",
      "\titers: 500, epoch: 3 | loss: 0.2932071\n",
      "\tspeed: 0.0531s/iter; left time: 832.9258s\n",
      "\titers: 600, epoch: 3 | loss: 0.2931563\n",
      "\tspeed: 0.0561s/iter; left time: 874.0437s\n",
      "\titers: 700, epoch: 3 | loss: 0.2827891\n",
      "\tspeed: 0.0503s/iter; left time: 778.7384s\n",
      "\titers: 800, epoch: 3 | loss: 0.3198387\n",
      "\tspeed: 0.0540s/iter; left time: 831.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.21s\n",
      "Steps: 899 | Train Loss: 0.2885656 Vali Loss: 0.2646529 Test Loss: 0.2770855\n",
      "Validation loss decreased (0.278129 --> 0.264653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2518093\n",
      "\tspeed: 0.3143s/iter; left time: 4771.9809s\n",
      "\titers: 200, epoch: 4 | loss: 0.2440773\n",
      "\tspeed: 0.0534s/iter; left time: 804.9017s\n",
      "\titers: 300, epoch: 4 | loss: 0.2706414\n",
      "\tspeed: 0.0555s/iter; left time: 832.2840s\n",
      "\titers: 400, epoch: 4 | loss: 0.2626098\n",
      "\tspeed: 0.0582s/iter; left time: 866.7038s\n",
      "\titers: 500, epoch: 4 | loss: 0.2882425\n",
      "\tspeed: 0.0576s/iter; left time: 851.3685s\n",
      "\titers: 600, epoch: 4 | loss: 0.2608938\n",
      "\tspeed: 0.0558s/iter; left time: 819.0227s\n",
      "\titers: 700, epoch: 4 | loss: 0.2896950\n",
      "\tspeed: 0.0548s/iter; left time: 799.6327s\n",
      "\titers: 800, epoch: 4 | loss: 0.2291579\n",
      "\tspeed: 0.0598s/iter; left time: 866.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:50.81s\n",
      "Steps: 899 | Train Loss: 0.2760553 Vali Loss: 0.2617239 Test Loss: 0.2744921\n",
      "Validation loss decreased (0.264653 --> 0.261724).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2716433\n",
      "\tspeed: 0.3079s/iter; left time: 4398.4936s\n",
      "\titers: 200, epoch: 5 | loss: 0.2439845\n",
      "\tspeed: 0.0511s/iter; left time: 725.2242s\n",
      "\titers: 300, epoch: 5 | loss: 0.2699315\n",
      "\tspeed: 0.0547s/iter; left time: 770.7152s\n",
      "\titers: 400, epoch: 5 | loss: 0.2958869\n",
      "\tspeed: 0.0553s/iter; left time: 772.7156s\n",
      "\titers: 500, epoch: 5 | loss: 0.2710647\n",
      "\tspeed: 0.0583s/iter; left time: 809.0963s\n",
      "\titers: 600, epoch: 5 | loss: 0.2964389\n",
      "\tspeed: 0.0525s/iter; left time: 723.5575s\n",
      "\titers: 700, epoch: 5 | loss: 0.2555974\n",
      "\tspeed: 0.0562s/iter; left time: 769.2518s\n",
      "\titers: 800, epoch: 5 | loss: 0.2672661\n",
      "\tspeed: 0.0568s/iter; left time: 772.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.04s\n",
      "Steps: 899 | Train Loss: 0.2678480 Vali Loss: 0.2547817 Test Loss: 0.2689230\n",
      "Validation loss decreased (0.261724 --> 0.254782).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2324864\n",
      "\tspeed: 0.3294s/iter; left time: 4409.3813s\n",
      "\titers: 200, epoch: 6 | loss: 0.2690727\n",
      "\tspeed: 0.0546s/iter; left time: 725.0910s\n",
      "\titers: 300, epoch: 6 | loss: 0.2388979\n",
      "\tspeed: 0.0558s/iter; left time: 735.2739s\n",
      "\titers: 400, epoch: 6 | loss: 0.2572960\n",
      "\tspeed: 0.0547s/iter; left time: 715.5569s\n",
      "\titers: 500, epoch: 6 | loss: 0.2363383\n",
      "\tspeed: 0.0514s/iter; left time: 667.5804s\n",
      "\titers: 600, epoch: 6 | loss: 0.2585189\n",
      "\tspeed: 0.0515s/iter; left time: 663.4963s\n",
      "\titers: 700, epoch: 6 | loss: 0.2663635\n",
      "\tspeed: 0.0506s/iter; left time: 647.5243s\n",
      "\titers: 800, epoch: 6 | loss: 0.2526423\n",
      "\tspeed: 0.0509s/iter; left time: 646.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.37s\n",
      "Steps: 899 | Train Loss: 0.2620297 Vali Loss: 0.2523579 Test Loss: 0.2654966\n",
      "Validation loss decreased (0.254782 --> 0.252358).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2589698\n",
      "\tspeed: 0.3045s/iter; left time: 3802.1309s\n",
      "\titers: 200, epoch: 7 | loss: 0.2202278\n",
      "\tspeed: 0.0480s/iter; left time: 594.1232s\n",
      "\titers: 300, epoch: 7 | loss: 0.2904449\n",
      "\tspeed: 0.0509s/iter; left time: 625.2284s\n",
      "\titers: 400, epoch: 7 | loss: 0.2422497\n",
      "\tspeed: 0.0572s/iter; left time: 696.8539s\n",
      "\titers: 500, epoch: 7 | loss: 0.2844310\n",
      "\tspeed: 0.0498s/iter; left time: 601.4078s\n",
      "\titers: 600, epoch: 7 | loss: 0.2758683\n",
      "\tspeed: 0.0556s/iter; left time: 665.8903s\n",
      "\titers: 700, epoch: 7 | loss: 0.2387815\n",
      "\tspeed: 0.0519s/iter; left time: 617.2815s\n",
      "\titers: 800, epoch: 7 | loss: 0.2530876\n",
      "\tspeed: 0.0503s/iter; left time: 592.4161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.49s\n",
      "Steps: 899 | Train Loss: 0.2578069 Vali Loss: 0.2489519 Test Loss: 0.2606864\n",
      "Validation loss decreased (0.252358 --> 0.248952).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2654280\n",
      "\tspeed: 0.2987s/iter; left time: 3461.2272s\n",
      "\titers: 200, epoch: 8 | loss: 0.2725436\n",
      "\tspeed: 0.0543s/iter; left time: 623.5891s\n",
      "\titers: 300, epoch: 8 | loss: 0.2371408\n",
      "\tspeed: 0.0569s/iter; left time: 647.6335s\n",
      "\titers: 400, epoch: 8 | loss: 0.2522988\n",
      "\tspeed: 0.0546s/iter; left time: 616.1819s\n",
      "\titers: 500, epoch: 8 | loss: 0.2867152\n",
      "\tspeed: 0.0564s/iter; left time: 631.4783s\n",
      "\titers: 600, epoch: 8 | loss: 0.2569876\n",
      "\tspeed: 0.0546s/iter; left time: 605.9404s\n",
      "\titers: 700, epoch: 8 | loss: 0.2657411\n",
      "\tspeed: 0.0540s/iter; left time: 593.6516s\n",
      "\titers: 800, epoch: 8 | loss: 0.2587411\n",
      "\tspeed: 0.0586s/iter; left time: 638.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.61s\n",
      "Steps: 899 | Train Loss: 0.2543712 Vali Loss: 0.2478848 Test Loss: 0.2599342\n",
      "Validation loss decreased (0.248952 --> 0.247885).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2433625\n",
      "\tspeed: 0.3086s/iter; left time: 3299.0074s\n",
      "\titers: 200, epoch: 9 | loss: 0.2587861\n",
      "\tspeed: 0.0580s/iter; left time: 613.6545s\n",
      "\titers: 300, epoch: 9 | loss: 0.2762177\n",
      "\tspeed: 0.0508s/iter; left time: 532.8836s\n",
      "\titers: 400, epoch: 9 | loss: 0.2570926\n",
      "\tspeed: 0.0535s/iter; left time: 556.2119s\n",
      "\titers: 500, epoch: 9 | loss: 0.2503490\n",
      "\tspeed: 0.0548s/iter; left time: 563.4998s\n",
      "\titers: 600, epoch: 9 | loss: 0.2601032\n",
      "\tspeed: 0.0567s/iter; left time: 577.6368s\n",
      "\titers: 700, epoch: 9 | loss: 0.2266045\n",
      "\tspeed: 0.0556s/iter; left time: 561.1535s\n",
      "\titers: 800, epoch: 9 | loss: 0.2913128\n",
      "\tspeed: 0.0523s/iter; left time: 522.5498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.86s\n",
      "Steps: 899 | Train Loss: 0.2516291 Vali Loss: 0.2472994 Test Loss: 0.2578833\n",
      "Validation loss decreased (0.247885 --> 0.247299).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2175469\n",
      "\tspeed: 0.3064s/iter; left time: 2999.8594s\n",
      "\titers: 200, epoch: 10 | loss: 0.2673032\n",
      "\tspeed: 0.0574s/iter; left time: 556.6342s\n",
      "\titers: 300, epoch: 10 | loss: 0.2496804\n",
      "\tspeed: 0.0506s/iter; left time: 485.1354s\n",
      "\titers: 400, epoch: 10 | loss: 0.2658059\n",
      "\tspeed: 0.0484s/iter; left time: 459.3479s\n",
      "\titers: 500, epoch: 10 | loss: 0.2663919\n",
      "\tspeed: 0.0600s/iter; left time: 562.9408s\n",
      "\titers: 600, epoch: 10 | loss: 0.2236724\n",
      "\tspeed: 0.0634s/iter; left time: 588.9778s\n",
      "\titers: 700, epoch: 10 | loss: 0.2661968\n",
      "\tspeed: 0.0576s/iter; left time: 529.7167s\n",
      "\titers: 800, epoch: 10 | loss: 0.2484617\n",
      "\tspeed: 0.0580s/iter; left time: 527.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.89s\n",
      "Steps: 899 | Train Loss: 0.2492819 Vali Loss: 0.2465337 Test Loss: 0.2582311\n",
      "Validation loss decreased (0.247299 --> 0.246534).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2484395\n",
      "\tspeed: 0.3055s/iter; left time: 2716.3297s\n",
      "\titers: 200, epoch: 11 | loss: 0.2488783\n",
      "\tspeed: 0.0521s/iter; left time: 458.3026s\n",
      "\titers: 300, epoch: 11 | loss: 0.2190044\n",
      "\tspeed: 0.0524s/iter; left time: 455.5706s\n",
      "\titers: 400, epoch: 11 | loss: 0.2643448\n",
      "\tspeed: 0.0584s/iter; left time: 501.7799s\n",
      "\titers: 500, epoch: 11 | loss: 0.2366973\n",
      "\tspeed: 0.0542s/iter; left time: 459.8852s\n",
      "\titers: 600, epoch: 11 | loss: 0.2391401\n",
      "\tspeed: 0.0476s/iter; left time: 399.8248s\n",
      "\titers: 700, epoch: 11 | loss: 0.2348218\n",
      "\tspeed: 0.0514s/iter; left time: 426.2374s\n",
      "\titers: 800, epoch: 11 | loss: 0.2441367\n",
      "\tspeed: 0.0496s/iter; left time: 405.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:49.32s\n",
      "Steps: 899 | Train Loss: 0.2475720 Vali Loss: 0.2438932 Test Loss: 0.2562939\n",
      "Validation loss decreased (0.246534 --> 0.243893).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2565231\n",
      "\tspeed: 0.3114s/iter; left time: 2488.7156s\n",
      "\titers: 200, epoch: 12 | loss: 0.2591335\n",
      "\tspeed: 0.0539s/iter; left time: 425.5293s\n",
      "\titers: 300, epoch: 12 | loss: 0.2625164\n",
      "\tspeed: 0.0506s/iter; left time: 393.9181s\n",
      "\titers: 400, epoch: 12 | loss: 0.2382481\n",
      "\tspeed: 0.0556s/iter; left time: 427.6567s\n",
      "\titers: 500, epoch: 12 | loss: 0.2594301\n",
      "\tspeed: 0.0585s/iter; left time: 444.1620s\n",
      "\titers: 600, epoch: 12 | loss: 0.2726392\n",
      "\tspeed: 0.0498s/iter; left time: 372.8871s\n",
      "\titers: 700, epoch: 12 | loss: 0.2561722\n",
      "\tspeed: 0.0601s/iter; left time: 444.3559s\n",
      "\titers: 800, epoch: 12 | loss: 0.2491858\n",
      "\tspeed: 0.0576s/iter; left time: 420.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:50.28s\n",
      "Steps: 899 | Train Loss: 0.2459942 Vali Loss: 0.2437636 Test Loss: 0.2572545\n",
      "Validation loss decreased (0.243893 --> 0.243764).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2528438\n",
      "\tspeed: 0.3124s/iter; left time: 2216.1901s\n",
      "\titers: 200, epoch: 13 | loss: 0.2621691\n",
      "\tspeed: 0.0536s/iter; left time: 374.5630s\n",
      "\titers: 300, epoch: 13 | loss: 0.2199807\n",
      "\tspeed: 0.0484s/iter; left time: 333.3708s\n",
      "\titers: 400, epoch: 13 | loss: 0.2508169\n",
      "\tspeed: 0.0562s/iter; left time: 381.4865s\n",
      "\titers: 500, epoch: 13 | loss: 0.2908570\n",
      "\tspeed: 0.0612s/iter; left time: 409.3473s\n",
      "\titers: 600, epoch: 13 | loss: 0.2188197\n",
      "\tspeed: 0.0587s/iter; left time: 386.9332s\n",
      "\titers: 700, epoch: 13 | loss: 0.2633851\n",
      "\tspeed: 0.0508s/iter; left time: 329.5953s\n",
      "\titers: 800, epoch: 13 | loss: 0.3014452\n",
      "\tspeed: 0.0543s/iter; left time: 347.1345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 899 | Train Loss: 0.2440878 Vali Loss: 0.2420737 Test Loss: 0.2542738\n",
      "Validation loss decreased (0.243764 --> 0.242074).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2931103\n",
      "\tspeed: 0.3350s/iter; left time: 2075.2989s\n",
      "\titers: 200, epoch: 14 | loss: 0.2301111\n",
      "\tspeed: 0.0536s/iter; left time: 326.3844s\n",
      "\titers: 300, epoch: 14 | loss: 0.2495896\n",
      "\tspeed: 0.0614s/iter; left time: 368.0986s\n",
      "\titers: 400, epoch: 14 | loss: 0.2671365\n",
      "\tspeed: 0.0531s/iter; left time: 313.1950s\n",
      "\titers: 500, epoch: 14 | loss: 0.2615140\n",
      "\tspeed: 0.0516s/iter; left time: 299.2462s\n",
      "\titers: 600, epoch: 14 | loss: 0.3179057\n",
      "\tspeed: 0.0528s/iter; left time: 300.8188s\n",
      "\titers: 700, epoch: 14 | loss: 0.2397571\n",
      "\tspeed: 0.0544s/iter; left time: 304.1881s\n",
      "\titers: 800, epoch: 14 | loss: 0.2408224\n",
      "\tspeed: 0.0511s/iter; left time: 280.8111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:49.33s\n",
      "Steps: 899 | Train Loss: 0.2432441 Vali Loss: 0.2419872 Test Loss: 0.2561926\n",
      "Validation loss decreased (0.242074 --> 0.241987).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2666880\n",
      "\tspeed: 0.3029s/iter; left time: 1604.0541s\n",
      "\titers: 200, epoch: 15 | loss: 0.2343545\n",
      "\tspeed: 0.0617s/iter; left time: 320.6397s\n",
      "\titers: 300, epoch: 15 | loss: 0.2208349\n",
      "\tspeed: 0.0583s/iter; left time: 297.0753s\n",
      "\titers: 400, epoch: 15 | loss: 0.2549978\n",
      "\tspeed: 0.0516s/iter; left time: 257.6421s\n",
      "\titers: 500, epoch: 15 | loss: 0.2127291\n",
      "\tspeed: 0.0511s/iter; left time: 249.9736s\n",
      "\titers: 600, epoch: 15 | loss: 0.2417456\n",
      "\tspeed: 0.0610s/iter; left time: 292.6990s\n",
      "\titers: 700, epoch: 15 | loss: 0.2520313\n",
      "\tspeed: 0.0538s/iter; left time: 252.7433s\n",
      "\titers: 800, epoch: 15 | loss: 0.2044262\n",
      "\tspeed: 0.0560s/iter; left time: 257.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:51.39s\n",
      "Steps: 899 | Train Loss: 0.2419101 Vali Loss: 0.2417017 Test Loss: 0.2545722\n",
      "Validation loss decreased (0.241987 --> 0.241702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.2827860\n",
      "\tspeed: 0.2830s/iter; left time: 1244.1841s\n",
      "\titers: 200, epoch: 16 | loss: 0.2508551\n",
      "\tspeed: 0.0536s/iter; left time: 230.2890s\n",
      "\titers: 300, epoch: 16 | loss: 0.2235140\n",
      "\tspeed: 0.0552s/iter; left time: 231.5139s\n",
      "\titers: 400, epoch: 16 | loss: 0.2434855\n",
      "\tspeed: 0.0590s/iter; left time: 241.4716s\n",
      "\titers: 500, epoch: 16 | loss: 0.2448723\n",
      "\tspeed: 0.0557s/iter; left time: 222.5879s\n",
      "\titers: 600, epoch: 16 | loss: 0.2087096\n",
      "\tspeed: 0.0541s/iter; left time: 210.9136s\n",
      "\titers: 700, epoch: 16 | loss: 0.2504786\n",
      "\tspeed: 0.0525s/iter; left time: 199.1834s\n",
      "\titers: 800, epoch: 16 | loss: 0.2663001\n",
      "\tspeed: 0.0575s/iter; left time: 212.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:49.00s\n",
      "Steps: 899 | Train Loss: 0.2411408 Vali Loss: 0.2413380 Test Loss: 0.2537194\n",
      "Validation loss decreased (0.241702 --> 0.241338).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.2498361\n",
      "\tspeed: 0.2985s/iter; left time: 1043.9995s\n",
      "\titers: 200, epoch: 17 | loss: 0.2628345\n",
      "\tspeed: 0.0595s/iter; left time: 202.2805s\n",
      "\titers: 300, epoch: 17 | loss: 0.2241386\n",
      "\tspeed: 0.0514s/iter; left time: 169.5865s\n",
      "\titers: 400, epoch: 17 | loss: 0.2774626\n",
      "\tspeed: 0.0633s/iter; left time: 202.4668s\n",
      "\titers: 500, epoch: 17 | loss: 0.2663810\n",
      "\tspeed: 0.0602s/iter; left time: 186.4425s\n",
      "\titers: 600, epoch: 17 | loss: 0.2903131\n",
      "\tspeed: 0.0545s/iter; left time: 163.4687s\n",
      "\titers: 700, epoch: 17 | loss: 0.1915403\n",
      "\tspeed: 0.0523s/iter; left time: 151.4081s\n",
      "\titers: 800, epoch: 17 | loss: 0.2487668\n",
      "\tspeed: 0.0522s/iter; left time: 145.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:50.79s\n",
      "Steps: 899 | Train Loss: 0.2402126 Vali Loss: 0.2411277 Test Loss: 0.2534418\n",
      "Validation loss decreased (0.241338 --> 0.241128).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.2475858\n",
      "\tspeed: 0.2960s/iter; left time: 768.9574s\n",
      "\titers: 200, epoch: 18 | loss: 0.2816447\n",
      "\tspeed: 0.0520s/iter; left time: 129.8088s\n",
      "\titers: 300, epoch: 18 | loss: 0.2429577\n",
      "\tspeed: 0.0567s/iter; left time: 136.0668s\n",
      "\titers: 400, epoch: 18 | loss: 0.2282330\n",
      "\tspeed: 0.0522s/iter; left time: 119.9760s\n",
      "\titers: 500, epoch: 18 | loss: 0.2125258\n",
      "\tspeed: 0.0512s/iter; left time: 112.5150s\n",
      "\titers: 600, epoch: 18 | loss: 0.2753126\n",
      "\tspeed: 0.0504s/iter; left time: 105.7516s\n",
      "\titers: 700, epoch: 18 | loss: 0.2639644\n",
      "\tspeed: 0.0504s/iter; left time: 100.6434s\n",
      "\titers: 800, epoch: 18 | loss: 0.2580844\n",
      "\tspeed: 0.0559s/iter; left time: 106.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.87s\n",
      "Steps: 899 | Train Loss: 0.2395852 Vali Loss: 0.2410072 Test Loss: 0.2535525\n",
      "Validation loss decreased (0.241128 --> 0.241007).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.2312118\n",
      "\tspeed: 0.3011s/iter; left time: 511.5980s\n",
      "\titers: 200, epoch: 19 | loss: 0.1895283\n",
      "\tspeed: 0.0470s/iter; left time: 75.1347s\n",
      "\titers: 300, epoch: 19 | loss: 0.2298442\n",
      "\tspeed: 0.0633s/iter; left time: 94.8747s\n",
      "\titers: 400, epoch: 19 | loss: 0.2163697\n",
      "\tspeed: 0.0511s/iter; left time: 71.5201s\n",
      "\titers: 500, epoch: 19 | loss: 0.2415225\n",
      "\tspeed: 0.0597s/iter; left time: 77.6132s\n",
      "\titers: 600, epoch: 19 | loss: 0.2034143\n",
      "\tspeed: 0.0540s/iter; left time: 64.7381s\n",
      "\titers: 700, epoch: 19 | loss: 0.2468459\n",
      "\tspeed: 0.0544s/iter; left time: 59.8353s\n",
      "\titers: 800, epoch: 19 | loss: 0.2035747\n",
      "\tspeed: 0.0546s/iter; left time: 54.5075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:50.22s\n",
      "Steps: 899 | Train Loss: 0.2385571 Vali Loss: 0.2405512 Test Loss: 0.2527005\n",
      "Validation loss decreased (0.241007 --> 0.240551).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2219398\n",
      "\tspeed: 0.3212s/iter; left time: 256.9466s\n",
      "\titers: 200, epoch: 20 | loss: 0.2426859\n",
      "\tspeed: 0.0563s/iter; left time: 39.3921s\n",
      "\titers: 300, epoch: 20 | loss: 0.2319082\n",
      "\tspeed: 0.0509s/iter; left time: 30.5574s\n",
      "\titers: 400, epoch: 20 | loss: 0.2286175\n",
      "\tspeed: 0.0556s/iter; left time: 27.7840s\n",
      "\titers: 500, epoch: 20 | loss: 0.2466527\n",
      "\tspeed: 0.0516s/iter; left time: 20.6267s\n",
      "\titers: 600, epoch: 20 | loss: 0.2026940\n",
      "\tspeed: 0.0577s/iter; left time: 17.3135s\n",
      "\titers: 700, epoch: 20 | loss: 0.2303760\n",
      "\tspeed: 0.0593s/iter; left time: 11.8579s\n",
      "\titers: 800, epoch: 20 | loss: 0.2209584\n",
      "\tspeed: 0.0542s/iter; left time: 5.4198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:50.53s\n",
      "Steps: 899 | Train Loss: 0.2380950 Vali Loss: 0.2401634 Test Loss: 0.2528449\n",
      "Validation loss decreased (0.240551 --> 0.240163).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20293521881103516, rmse:0.4504833221435547, mae:0.2528449594974518, rse:0.412569522857666\n",
      "Original data scale mse:1151100.125, rmse:1072.893310546875, mae:668.9365234375, rse:0.07539474219083786\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7695546\n",
      "\tspeed: 0.0665s/iter; left time: 1189.7432s\n",
      "\titers: 200, epoch: 1 | loss: 0.6173800\n",
      "\tspeed: 0.0513s/iter; left time: 912.5977s\n",
      "\titers: 300, epoch: 1 | loss: 0.5729680\n",
      "\tspeed: 0.0564s/iter; left time: 996.5921s\n",
      "\titers: 400, epoch: 1 | loss: 0.5110341\n",
      "\tspeed: 0.0536s/iter; left time: 942.7170s\n",
      "\titers: 500, epoch: 1 | loss: 0.4687887\n",
      "\tspeed: 0.0526s/iter; left time: 918.9515s\n",
      "\titers: 600, epoch: 1 | loss: 0.5282834\n",
      "\tspeed: 0.0540s/iter; left time: 938.7993s\n",
      "\titers: 700, epoch: 1 | loss: 0.4832329\n",
      "\tspeed: 0.0616s/iter; left time: 1064.2938s\n",
      "\titers: 800, epoch: 1 | loss: 0.4751154\n",
      "\tspeed: 0.0570s/iter; left time: 978.5235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.57s\n",
      "Steps: 899 | Train Loss: 0.5639134 Vali Loss: 0.3825430 Test Loss: 0.3933530\n",
      "Validation loss decreased (inf --> 0.382543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4115085\n",
      "\tspeed: 0.3064s/iter; left time: 5203.2385s\n",
      "\titers: 200, epoch: 2 | loss: 0.3328076\n",
      "\tspeed: 0.0521s/iter; left time: 879.7801s\n",
      "\titers: 300, epoch: 2 | loss: 0.3387829\n",
      "\tspeed: 0.0544s/iter; left time: 912.3913s\n",
      "\titers: 400, epoch: 2 | loss: 0.3111836\n",
      "\tspeed: 0.0466s/iter; left time: 776.7179s\n",
      "\titers: 500, epoch: 2 | loss: 0.3007427\n",
      "\tspeed: 0.0448s/iter; left time: 742.4392s\n",
      "\titers: 600, epoch: 2 | loss: 0.3454388\n",
      "\tspeed: 0.0458s/iter; left time: 754.0946s\n",
      "\titers: 700, epoch: 2 | loss: 0.3003039\n",
      "\tspeed: 0.0545s/iter; left time: 892.8191s\n",
      "\titers: 800, epoch: 2 | loss: 0.3082251\n",
      "\tspeed: 0.0590s/iter; left time: 960.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 899 | Train Loss: 0.3267071 Vali Loss: 0.2760861 Test Loss: 0.2855857\n",
      "Validation loss decreased (0.382543 --> 0.276086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2768325\n",
      "\tspeed: 0.3096s/iter; left time: 4979.3225s\n",
      "\titers: 200, epoch: 3 | loss: 0.2627148\n",
      "\tspeed: 0.0512s/iter; left time: 817.9363s\n",
      "\titers: 300, epoch: 3 | loss: 0.2710491\n",
      "\tspeed: 0.0523s/iter; left time: 830.9561s\n",
      "\titers: 400, epoch: 3 | loss: 0.2762404\n",
      "\tspeed: 0.0533s/iter; left time: 840.7384s\n",
      "\titers: 500, epoch: 3 | loss: 0.2499685\n",
      "\tspeed: 0.0575s/iter; left time: 901.0959s\n",
      "\titers: 600, epoch: 3 | loss: 0.2743557\n",
      "\tspeed: 0.0619s/iter; left time: 964.9539s\n",
      "\titers: 700, epoch: 3 | loss: 0.2905808\n",
      "\tspeed: 0.0476s/iter; left time: 737.0628s\n",
      "\titers: 800, epoch: 3 | loss: 0.2598731\n",
      "\tspeed: 0.0537s/iter; left time: 825.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.14s\n",
      "Steps: 899 | Train Loss: 0.2870589 Vali Loss: 0.2637097 Test Loss: 0.2744557\n",
      "Validation loss decreased (0.276086 --> 0.263710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2905399\n",
      "\tspeed: 0.3040s/iter; left time: 4616.5729s\n",
      "\titers: 200, epoch: 4 | loss: 0.2709951\n",
      "\tspeed: 0.0590s/iter; left time: 890.6044s\n",
      "\titers: 300, epoch: 4 | loss: 0.2263854\n",
      "\tspeed: 0.0510s/iter; left time: 763.5246s\n",
      "\titers: 400, epoch: 4 | loss: 0.2686700\n",
      "\tspeed: 0.0588s/iter; left time: 875.7250s\n",
      "\titers: 500, epoch: 4 | loss: 0.2763354\n",
      "\tspeed: 0.0508s/iter; left time: 750.8689s\n",
      "\titers: 600, epoch: 4 | loss: 0.2507344\n",
      "\tspeed: 0.0538s/iter; left time: 789.9536s\n",
      "\titers: 700, epoch: 4 | loss: 0.2508259\n",
      "\tspeed: 0.0519s/iter; left time: 757.2851s\n",
      "\titers: 800, epoch: 4 | loss: 0.2569146\n",
      "\tspeed: 0.0569s/iter; left time: 823.8102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.09s\n",
      "Steps: 899 | Train Loss: 0.2749023 Vali Loss: 0.2588912 Test Loss: 0.2707531\n",
      "Validation loss decreased (0.263710 --> 0.258891).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2647319\n",
      "\tspeed: 0.3247s/iter; left time: 4637.7188s\n",
      "\titers: 200, epoch: 5 | loss: 0.2517526\n",
      "\tspeed: 0.0564s/iter; left time: 799.5502s\n",
      "\titers: 300, epoch: 5 | loss: 0.3000122\n",
      "\tspeed: 0.0528s/iter; left time: 743.5370s\n",
      "\titers: 400, epoch: 5 | loss: 0.2797507\n",
      "\tspeed: 0.0541s/iter; left time: 757.0611s\n",
      "\titers: 500, epoch: 5 | loss: 0.2727681\n",
      "\tspeed: 0.0519s/iter; left time: 720.0065s\n",
      "\titers: 600, epoch: 5 | loss: 0.2783136\n",
      "\tspeed: 0.0594s/iter; left time: 819.4975s\n",
      "\titers: 700, epoch: 5 | loss: 0.2718383\n",
      "\tspeed: 0.0515s/iter; left time: 704.7716s\n",
      "\titers: 800, epoch: 5 | loss: 0.2641280\n",
      "\tspeed: 0.0527s/iter; left time: 716.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.46s\n",
      "Steps: 899 | Train Loss: 0.2666871 Vali Loss: 0.2546344 Test Loss: 0.2663664\n",
      "Validation loss decreased (0.258891 --> 0.254634).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2592109\n",
      "\tspeed: 0.3197s/iter; left time: 4279.9321s\n",
      "\titers: 200, epoch: 6 | loss: 0.2300086\n",
      "\tspeed: 0.0550s/iter; left time: 730.7754s\n",
      "\titers: 300, epoch: 6 | loss: 0.2619140\n",
      "\tspeed: 0.0538s/iter; left time: 708.8240s\n",
      "\titers: 400, epoch: 6 | loss: 0.2975906\n",
      "\tspeed: 0.0589s/iter; left time: 771.0054s\n",
      "\titers: 500, epoch: 6 | loss: 0.2331565\n",
      "\tspeed: 0.0541s/iter; left time: 703.0158s\n",
      "\titers: 600, epoch: 6 | loss: 0.2936651\n",
      "\tspeed: 0.0558s/iter; left time: 719.5026s\n",
      "\titers: 700, epoch: 6 | loss: 0.2939557\n",
      "\tspeed: 0.0554s/iter; left time: 708.9262s\n",
      "\titers: 800, epoch: 6 | loss: 0.2886554\n",
      "\tspeed: 0.0517s/iter; left time: 655.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.70s\n",
      "Steps: 899 | Train Loss: 0.2612756 Vali Loss: 0.2530807 Test Loss: 0.2669018\n",
      "Validation loss decreased (0.254634 --> 0.253081).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2779230\n",
      "\tspeed: 0.3090s/iter; left time: 3858.0315s\n",
      "\titers: 200, epoch: 7 | loss: 0.2606280\n",
      "\tspeed: 0.0512s/iter; left time: 634.0171s\n",
      "\titers: 300, epoch: 7 | loss: 0.2804795\n",
      "\tspeed: 0.0483s/iter; left time: 594.0696s\n",
      "\titers: 400, epoch: 7 | loss: 0.2722861\n",
      "\tspeed: 0.0566s/iter; left time: 689.3897s\n",
      "\titers: 500, epoch: 7 | loss: 0.2615852\n",
      "\tspeed: 0.0546s/iter; left time: 659.9825s\n",
      "\titers: 600, epoch: 7 | loss: 0.2234846\n",
      "\tspeed: 0.0507s/iter; left time: 607.8107s\n",
      "\titers: 700, epoch: 7 | loss: 0.2435990\n",
      "\tspeed: 0.0555s/iter; left time: 659.4379s\n",
      "\titers: 800, epoch: 7 | loss: 0.2579395\n",
      "\tspeed: 0.0542s/iter; left time: 638.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.26s\n",
      "Steps: 899 | Train Loss: 0.2573602 Vali Loss: 0.2490560 Test Loss: 0.2610407\n",
      "Validation loss decreased (0.253081 --> 0.249056).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3168053\n",
      "\tspeed: 0.2993s/iter; left time: 3467.7268s\n",
      "\titers: 200, epoch: 8 | loss: 0.2282544\n",
      "\tspeed: 0.0539s/iter; left time: 619.5066s\n",
      "\titers: 300, epoch: 8 | loss: 0.2484325\n",
      "\tspeed: 0.0558s/iter; left time: 635.6144s\n",
      "\titers: 400, epoch: 8 | loss: 0.2417875\n",
      "\tspeed: 0.0549s/iter; left time: 619.8025s\n",
      "\titers: 500, epoch: 8 | loss: 0.2530582\n",
      "\tspeed: 0.0617s/iter; left time: 690.6332s\n",
      "\titers: 600, epoch: 8 | loss: 0.2419396\n",
      "\tspeed: 0.0578s/iter; left time: 640.7085s\n",
      "\titers: 700, epoch: 8 | loss: 0.2653764\n",
      "\tspeed: 0.0569s/iter; left time: 625.5578s\n",
      "\titers: 800, epoch: 8 | loss: 0.2283738\n",
      "\tspeed: 0.0589s/iter; left time: 641.2983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.80s\n",
      "Steps: 899 | Train Loss: 0.2540558 Vali Loss: 0.2494585 Test Loss: 0.2612973\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2625990\n",
      "\tspeed: 0.3120s/iter; left time: 3334.6768s\n",
      "\titers: 200, epoch: 9 | loss: 0.2382317\n",
      "\tspeed: 0.0509s/iter; left time: 538.5064s\n",
      "\titers: 300, epoch: 9 | loss: 0.2081661\n",
      "\tspeed: 0.0515s/iter; left time: 539.7889s\n",
      "\titers: 400, epoch: 9 | loss: 0.2372584\n",
      "\tspeed: 0.0536s/iter; left time: 557.2542s\n",
      "\titers: 500, epoch: 9 | loss: 0.2297046\n",
      "\tspeed: 0.0576s/iter; left time: 592.4200s\n",
      "\titers: 600, epoch: 9 | loss: 0.2618764\n",
      "\tspeed: 0.0553s/iter; left time: 563.9190s\n",
      "\titers: 700, epoch: 9 | loss: 0.2229159\n",
      "\tspeed: 0.0512s/iter; left time: 516.8152s\n",
      "\titers: 800, epoch: 9 | loss: 0.2440861\n",
      "\tspeed: 0.0527s/iter; left time: 526.3605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.06s\n",
      "Steps: 899 | Train Loss: 0.2512188 Vali Loss: 0.2466000 Test Loss: 0.2581016\n",
      "Validation loss decreased (0.249056 --> 0.246600).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2594198\n",
      "\tspeed: 0.3091s/iter; left time: 3026.2553s\n",
      "\titers: 200, epoch: 10 | loss: 0.2257122\n",
      "\tspeed: 0.0558s/iter; left time: 540.6447s\n",
      "\titers: 300, epoch: 10 | loss: 0.2494005\n",
      "\tspeed: 0.0551s/iter; left time: 528.3111s\n",
      "\titers: 400, epoch: 10 | loss: 0.2803823\n",
      "\tspeed: 0.0553s/iter; left time: 524.5284s\n",
      "\titers: 500, epoch: 10 | loss: 0.2545181\n",
      "\tspeed: 0.0464s/iter; left time: 435.5846s\n",
      "\titers: 600, epoch: 10 | loss: 0.2226262\n",
      "\tspeed: 0.0549s/iter; left time: 510.0367s\n",
      "\titers: 700, epoch: 10 | loss: 0.2197427\n",
      "\tspeed: 0.0605s/iter; left time: 556.4241s\n",
      "\titers: 800, epoch: 10 | loss: 0.2620440\n",
      "\tspeed: 0.0513s/iter; left time: 466.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.33s\n",
      "Steps: 899 | Train Loss: 0.2486150 Vali Loss: 0.2449316 Test Loss: 0.2592227\n",
      "Validation loss decreased (0.246600 --> 0.244932).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2690663\n",
      "\tspeed: 0.3095s/iter; left time: 2751.3670s\n",
      "\titers: 200, epoch: 11 | loss: 0.2482770\n",
      "\tspeed: 0.0505s/iter; left time: 443.7694s\n",
      "\titers: 300, epoch: 11 | loss: 0.2890701\n",
      "\tspeed: 0.0495s/iter; left time: 430.0119s\n",
      "\titers: 400, epoch: 11 | loss: 0.2480481\n",
      "\tspeed: 0.0544s/iter; left time: 466.9312s\n",
      "\titers: 500, epoch: 11 | loss: 0.2518808\n",
      "\tspeed: 0.0597s/iter; left time: 506.6677s\n",
      "\titers: 600, epoch: 11 | loss: 0.2582714\n",
      "\tspeed: 0.0573s/iter; left time: 480.8528s\n",
      "\titers: 700, epoch: 11 | loss: 0.2243294\n",
      "\tspeed: 0.0555s/iter; left time: 460.2830s\n",
      "\titers: 800, epoch: 11 | loss: 0.2354104\n",
      "\tspeed: 0.0572s/iter; left time: 468.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.08s\n",
      "Steps: 899 | Train Loss: 0.2470543 Vali Loss: 0.2458588 Test Loss: 0.2572478\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2396748\n",
      "\tspeed: 0.3067s/iter; left time: 2451.1463s\n",
      "\titers: 200, epoch: 12 | loss: 0.2174704\n",
      "\tspeed: 0.0636s/iter; left time: 501.9321s\n",
      "\titers: 300, epoch: 12 | loss: 0.2202234\n",
      "\tspeed: 0.0580s/iter; left time: 451.7507s\n",
      "\titers: 400, epoch: 12 | loss: 0.2159050\n",
      "\tspeed: 0.0518s/iter; left time: 398.6365s\n",
      "\titers: 500, epoch: 12 | loss: 0.2007723\n",
      "\tspeed: 0.0544s/iter; left time: 413.0023s\n",
      "\titers: 600, epoch: 12 | loss: 0.2621424\n",
      "\tspeed: 0.0557s/iter; left time: 416.9664s\n",
      "\titers: 700, epoch: 12 | loss: 0.2339609\n",
      "\tspeed: 0.0489s/iter; left time: 361.8165s\n",
      "\titers: 800, epoch: 12 | loss: 0.2493118\n",
      "\tspeed: 0.0504s/iter; left time: 367.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:49.25s\n",
      "Steps: 899 | Train Loss: 0.2452865 Vali Loss: 0.2430472 Test Loss: 0.2562780\n",
      "Validation loss decreased (0.244932 --> 0.243047).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2873349\n",
      "\tspeed: 0.3006s/iter; left time: 2132.2343s\n",
      "\titers: 200, epoch: 13 | loss: 0.2477559\n",
      "\tspeed: 0.0557s/iter; left time: 389.8432s\n",
      "\titers: 300, epoch: 13 | loss: 0.2233341\n",
      "\tspeed: 0.0636s/iter; left time: 438.3448s\n",
      "\titers: 400, epoch: 13 | loss: 0.2210337\n",
      "\tspeed: 0.0613s/iter; left time: 416.6939s\n",
      "\titers: 500, epoch: 13 | loss: 0.2760914\n",
      "\tspeed: 0.0579s/iter; left time: 387.7201s\n",
      "\titers: 600, epoch: 13 | loss: 0.2429633\n",
      "\tspeed: 0.0537s/iter; left time: 354.0992s\n",
      "\titers: 700, epoch: 13 | loss: 0.2801585\n",
      "\tspeed: 0.0530s/iter; left time: 344.1308s\n",
      "\titers: 800, epoch: 13 | loss: 0.2287291\n",
      "\tspeed: 0.0535s/iter; left time: 341.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:51.74s\n",
      "Steps: 899 | Train Loss: 0.2441575 Vali Loss: 0.2418078 Test Loss: 0.2544689\n",
      "Validation loss decreased (0.243047 --> 0.241808).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2188501\n",
      "\tspeed: 0.3220s/iter; left time: 1994.5373s\n",
      "\titers: 200, epoch: 14 | loss: 0.2263617\n",
      "\tspeed: 0.0600s/iter; left time: 365.8821s\n",
      "\titers: 300, epoch: 14 | loss: 0.2007906\n",
      "\tspeed: 0.0500s/iter; left time: 299.6531s\n",
      "\titers: 400, epoch: 14 | loss: 0.1887975\n",
      "\tspeed: 0.0503s/iter; left time: 296.3382s\n",
      "\titers: 500, epoch: 14 | loss: 0.2439729\n",
      "\tspeed: 0.0577s/iter; left time: 334.2265s\n",
      "\titers: 600, epoch: 14 | loss: 0.2388373\n",
      "\tspeed: 0.0500s/iter; left time: 284.9271s\n",
      "\titers: 700, epoch: 14 | loss: 0.2451000\n",
      "\tspeed: 0.0479s/iter; left time: 267.8944s\n",
      "\titers: 800, epoch: 14 | loss: 0.2251633\n",
      "\tspeed: 0.0529s/iter; left time: 290.8247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:49.20s\n",
      "Steps: 899 | Train Loss: 0.2426711 Vali Loss: 0.2423167 Test Loss: 0.2548592\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2447065\n",
      "\tspeed: 0.3018s/iter; left time: 1598.0754s\n",
      "\titers: 200, epoch: 15 | loss: 0.2646659\n",
      "\tspeed: 0.0562s/iter; left time: 292.1035s\n",
      "\titers: 300, epoch: 15 | loss: 0.2499619\n",
      "\tspeed: 0.0534s/iter; left time: 271.8548s\n",
      "\titers: 400, epoch: 15 | loss: 0.2313849\n",
      "\tspeed: 0.0499s/iter; left time: 249.4483s\n",
      "\titers: 500, epoch: 15 | loss: 0.2541708\n",
      "\tspeed: 0.0497s/iter; left time: 243.2347s\n",
      "\titers: 600, epoch: 15 | loss: 0.2312117\n",
      "\tspeed: 0.0578s/iter; left time: 277.0413s\n",
      "\titers: 700, epoch: 15 | loss: 0.2434749\n",
      "\tspeed: 0.0581s/iter; left time: 272.9546s\n",
      "\titers: 800, epoch: 15 | loss: 0.2475857\n",
      "\tspeed: 0.0550s/iter; left time: 252.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:49.38s\n",
      "Steps: 899 | Train Loss: 0.2416384 Vali Loss: 0.2414798 Test Loss: 0.2540885\n",
      "Validation loss decreased (0.241808 --> 0.241480).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.2323370\n",
      "\tspeed: 0.3013s/iter; left time: 1324.3781s\n",
      "\titers: 200, epoch: 16 | loss: 0.2406537\n",
      "\tspeed: 0.0529s/iter; left time: 227.2392s\n",
      "\titers: 300, epoch: 16 | loss: 0.2699856\n",
      "\tspeed: 0.0565s/iter; left time: 237.0349s\n",
      "\titers: 400, epoch: 16 | loss: 0.2467942\n",
      "\tspeed: 0.0565s/iter; left time: 231.5567s\n",
      "\titers: 500, epoch: 16 | loss: 0.2004844\n",
      "\tspeed: 0.0627s/iter; left time: 250.6433s\n",
      "\titers: 600, epoch: 16 | loss: 0.2269980\n",
      "\tspeed: 0.0512s/iter; left time: 199.6162s\n",
      "\titers: 700, epoch: 16 | loss: 0.2346403\n",
      "\tspeed: 0.0595s/iter; left time: 225.9235s\n",
      "\titers: 800, epoch: 16 | loss: 0.2469147\n",
      "\tspeed: 0.0526s/iter; left time: 194.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:50.20s\n",
      "Steps: 899 | Train Loss: 0.2405637 Vali Loss: 0.2413054 Test Loss: 0.2544088\n",
      "Validation loss decreased (0.241480 --> 0.241305).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.2286191\n",
      "\tspeed: 0.2959s/iter; left time: 1034.7256s\n",
      "\titers: 200, epoch: 17 | loss: 0.2413256\n",
      "\tspeed: 0.0583s/iter; left time: 197.9959s\n",
      "\titers: 300, epoch: 17 | loss: 0.2487620\n",
      "\tspeed: 0.0520s/iter; left time: 171.2959s\n",
      "\titers: 400, epoch: 17 | loss: 0.2644491\n",
      "\tspeed: 0.0541s/iter; left time: 172.9515s\n",
      "\titers: 500, epoch: 17 | loss: 0.2627011\n",
      "\tspeed: 0.0534s/iter; left time: 165.2623s\n",
      "\titers: 600, epoch: 17 | loss: 0.2263647\n",
      "\tspeed: 0.0539s/iter; left time: 161.5330s\n",
      "\titers: 700, epoch: 17 | loss: 0.2168738\n",
      "\tspeed: 0.0528s/iter; left time: 152.8305s\n",
      "\titers: 800, epoch: 17 | loss: 0.2127385\n",
      "\tspeed: 0.0477s/iter; left time: 133.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.18s\n",
      "Steps: 899 | Train Loss: 0.2395682 Vali Loss: 0.2404475 Test Loss: 0.2537790\n",
      "Validation loss decreased (0.241305 --> 0.240447).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.2830552\n",
      "\tspeed: 0.3057s/iter; left time: 794.2819s\n",
      "\titers: 200, epoch: 18 | loss: 0.2464019\n",
      "\tspeed: 0.0520s/iter; left time: 129.9988s\n",
      "\titers: 300, epoch: 18 | loss: 0.2699743\n",
      "\tspeed: 0.0520s/iter; left time: 124.8150s\n",
      "\titers: 400, epoch: 18 | loss: 0.2159301\n",
      "\tspeed: 0.0525s/iter; left time: 120.5714s\n",
      "\titers: 500, epoch: 18 | loss: 0.2519426\n",
      "\tspeed: 0.0491s/iter; left time: 107.9319s\n",
      "\titers: 600, epoch: 18 | loss: 0.2290585\n",
      "\tspeed: 0.0501s/iter; left time: 105.0643s\n",
      "\titers: 700, epoch: 18 | loss: 0.1955789\n",
      "\tspeed: 0.0499s/iter; left time: 99.7608s\n",
      "\titers: 800, epoch: 18 | loss: 0.2166403\n",
      "\tspeed: 0.0504s/iter; left time: 95.5905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:48.24s\n",
      "Steps: 899 | Train Loss: 0.2390967 Vali Loss: 0.2406219 Test Loss: 0.2532128\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.2140917\n",
      "\tspeed: 0.3126s/iter; left time: 531.1680s\n",
      "\titers: 200, epoch: 19 | loss: 0.2162102\n",
      "\tspeed: 0.0573s/iter; left time: 91.5998s\n",
      "\titers: 300, epoch: 19 | loss: 0.2284086\n",
      "\tspeed: 0.0509s/iter; left time: 76.2489s\n",
      "\titers: 400, epoch: 19 | loss: 0.2095131\n",
      "\tspeed: 0.0566s/iter; left time: 79.2104s\n",
      "\titers: 500, epoch: 19 | loss: 0.2517149\n",
      "\tspeed: 0.0563s/iter; left time: 73.1663s\n",
      "\titers: 600, epoch: 19 | loss: 0.2364316\n",
      "\tspeed: 0.0516s/iter; left time: 61.8268s\n",
      "\titers: 700, epoch: 19 | loss: 0.2604760\n",
      "\tspeed: 0.0488s/iter; left time: 53.6163s\n",
      "\titers: 800, epoch: 19 | loss: 0.2195623\n",
      "\tspeed: 0.0532s/iter; left time: 53.1136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 899 | Train Loss: 0.2380622 Vali Loss: 0.2401155 Test Loss: 0.2542644\n",
      "Validation loss decreased (0.240447 --> 0.240115).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2351923\n",
      "\tspeed: 0.2963s/iter; left time: 237.0049s\n",
      "\titers: 200, epoch: 20 | loss: 0.2383458\n",
      "\tspeed: 0.0562s/iter; left time: 39.3253s\n",
      "\titers: 300, epoch: 20 | loss: 0.2477112\n",
      "\tspeed: 0.0517s/iter; left time: 31.0201s\n",
      "\titers: 400, epoch: 20 | loss: 0.2344420\n",
      "\tspeed: 0.0488s/iter; left time: 24.3998s\n",
      "\titers: 500, epoch: 20 | loss: 0.2300706\n",
      "\tspeed: 0.0555s/iter; left time: 22.2148s\n",
      "\titers: 600, epoch: 20 | loss: 0.2268675\n",
      "\tspeed: 0.0546s/iter; left time: 16.3808s\n",
      "\titers: 700, epoch: 20 | loss: 0.2377623\n",
      "\tspeed: 0.0561s/iter; left time: 11.2116s\n",
      "\titers: 800, epoch: 20 | loss: 0.2470474\n",
      "\tspeed: 0.0636s/iter; left time: 6.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:50.58s\n",
      "Steps: 899 | Train Loss: 0.2379700 Vali Loss: 0.2397006 Test Loss: 0.2532265\n",
      "Validation loss decreased (0.240115 --> 0.239701).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20464353263378143, rmse:0.4523754417896271, mae:0.2532264292240143, rse:0.41430240869522095\n",
      "Original data scale mse:1154194.75, rmse:1074.3345947265625, mae:667.5917358398438, rse:0.07549601793289185\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7514175\n",
      "\tspeed: 0.0452s/iter; left time: 806.6092s\n",
      "\titers: 200, epoch: 1 | loss: 0.6401502\n",
      "\tspeed: 0.0196s/iter; left time: 348.0579s\n",
      "\titers: 300, epoch: 1 | loss: 0.5905042\n",
      "\tspeed: 0.0202s/iter; left time: 356.2105s\n",
      "\titers: 400, epoch: 1 | loss: 0.5559627\n",
      "\tspeed: 0.0190s/iter; left time: 333.1042s\n",
      "\titers: 500, epoch: 1 | loss: 0.5615612\n",
      "\tspeed: 0.0198s/iter; left time: 346.1790s\n",
      "\titers: 600, epoch: 1 | loss: 0.5411144\n",
      "\tspeed: 0.0160s/iter; left time: 277.8781s\n",
      "\titers: 700, epoch: 1 | loss: 0.5269336\n",
      "\tspeed: 0.0163s/iter; left time: 280.3231s\n",
      "\titers: 800, epoch: 1 | loss: 0.5610789\n",
      "\tspeed: 0.0161s/iter; left time: 275.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.80s\n",
      "Steps: 897 | Train Loss: 0.6034338 Vali Loss: 0.4465244 Test Loss: 0.4596697\n",
      "Validation loss decreased (inf --> 0.446524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4574239\n",
      "\tspeed: 0.0788s/iter; left time: 1334.5901s\n",
      "\titers: 200, epoch: 2 | loss: 0.4118088\n",
      "\tspeed: 0.0172s/iter; left time: 290.2751s\n",
      "\titers: 300, epoch: 2 | loss: 0.4042118\n",
      "\tspeed: 0.0172s/iter; left time: 287.5889s\n",
      "\titers: 400, epoch: 2 | loss: 0.4054114\n",
      "\tspeed: 0.0158s/iter; left time: 263.6779s\n",
      "\titers: 500, epoch: 2 | loss: 0.4072154\n",
      "\tspeed: 0.0130s/iter; left time: 215.1604s\n",
      "\titers: 600, epoch: 2 | loss: 0.3628599\n",
      "\tspeed: 0.0118s/iter; left time: 193.4663s\n",
      "\titers: 700, epoch: 2 | loss: 0.3512259\n",
      "\tspeed: 0.0116s/iter; left time: 189.4558s\n",
      "\titers: 800, epoch: 2 | loss: 0.3882127\n",
      "\tspeed: 0.0125s/iter; left time: 203.5334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.02s\n",
      "Steps: 897 | Train Loss: 0.4099922 Vali Loss: 0.3622923 Test Loss: 0.3820882\n",
      "Validation loss decreased (0.446524 --> 0.362292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3757448\n",
      "\tspeed: 0.0508s/iter; left time: 815.8331s\n",
      "\titers: 200, epoch: 3 | loss: 0.3952562\n",
      "\tspeed: 0.0100s/iter; left time: 159.5964s\n",
      "\titers: 300, epoch: 3 | loss: 0.3404945\n",
      "\tspeed: 0.0096s/iter; left time: 152.4168s\n",
      "\titers: 400, epoch: 3 | loss: 0.3633372\n",
      "\tspeed: 0.0098s/iter; left time: 153.5336s\n",
      "\titers: 500, epoch: 3 | loss: 0.3189395\n",
      "\tspeed: 0.0096s/iter; left time: 149.8215s\n",
      "\titers: 600, epoch: 3 | loss: 0.4049033\n",
      "\tspeed: 0.0091s/iter; left time: 142.1546s\n",
      "\titers: 700, epoch: 3 | loss: 0.3536741\n",
      "\tspeed: 0.0093s/iter; left time: 144.1328s\n",
      "\titers: 800, epoch: 3 | loss: 0.3637585\n",
      "\tspeed: 0.0103s/iter; left time: 158.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.08s\n",
      "Steps: 897 | Train Loss: 0.3739315 Vali Loss: 0.3563556 Test Loss: 0.3764851\n",
      "Validation loss decreased (0.362292 --> 0.356356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3834462\n",
      "\tspeed: 0.0446s/iter; left time: 674.9897s\n",
      "\titers: 200, epoch: 4 | loss: 0.3449820\n",
      "\tspeed: 0.0093s/iter; left time: 140.3516s\n",
      "\titers: 300, epoch: 4 | loss: 0.3723511\n",
      "\tspeed: 0.0091s/iter; left time: 136.5255s\n",
      "\titers: 400, epoch: 4 | loss: 0.3590108\n",
      "\tspeed: 0.0091s/iter; left time: 135.6298s\n",
      "\titers: 500, epoch: 4 | loss: 0.3433250\n",
      "\tspeed: 0.0091s/iter; left time: 134.7009s\n",
      "\titers: 600, epoch: 4 | loss: 0.3422652\n",
      "\tspeed: 0.0091s/iter; left time: 132.6052s\n",
      "\titers: 700, epoch: 4 | loss: 0.4167950\n",
      "\tspeed: 0.0091s/iter; left time: 131.8868s\n",
      "\titers: 800, epoch: 4 | loss: 0.3455127\n",
      "\tspeed: 0.0093s/iter; left time: 134.3304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 897 | Train Loss: 0.3627636 Vali Loss: 0.3508383 Test Loss: 0.3732997\n",
      "Validation loss decreased (0.356356 --> 0.350838).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3535787\n",
      "\tspeed: 0.0444s/iter; left time: 632.3088s\n",
      "\titers: 200, epoch: 5 | loss: 0.3268083\n",
      "\tspeed: 0.0089s/iter; left time: 126.5845s\n",
      "\titers: 300, epoch: 5 | loss: 0.3489236\n",
      "\tspeed: 0.0089s/iter; left time: 125.0394s\n",
      "\titers: 400, epoch: 5 | loss: 0.3800225\n",
      "\tspeed: 0.0092s/iter; left time: 128.4283s\n",
      "\titers: 500, epoch: 5 | loss: 0.3881747\n",
      "\tspeed: 0.0089s/iter; left time: 123.3830s\n",
      "\titers: 600, epoch: 5 | loss: 0.3358921\n",
      "\tspeed: 0.0095s/iter; left time: 130.3837s\n",
      "\titers: 700, epoch: 5 | loss: 0.3620409\n",
      "\tspeed: 0.0089s/iter; left time: 121.9059s\n",
      "\titers: 800, epoch: 5 | loss: 0.4375106\n",
      "\tspeed: 0.0093s/iter; left time: 126.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 897 | Train Loss: 0.3550606 Vali Loss: 0.3485056 Test Loss: 0.3680557\n",
      "Validation loss decreased (0.350838 --> 0.348506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3342156\n",
      "\tspeed: 0.0448s/iter; left time: 598.1053s\n",
      "\titers: 200, epoch: 6 | loss: 0.3105098\n",
      "\tspeed: 0.0097s/iter; left time: 128.9364s\n",
      "\titers: 300, epoch: 6 | loss: 0.3357395\n",
      "\tspeed: 0.0089s/iter; left time: 117.0119s\n",
      "\titers: 400, epoch: 6 | loss: 0.3474275\n",
      "\tspeed: 0.0091s/iter; left time: 118.8607s\n",
      "\titers: 500, epoch: 6 | loss: 0.3354019\n",
      "\tspeed: 0.0090s/iter; left time: 116.0758s\n",
      "\titers: 600, epoch: 6 | loss: 0.3262916\n",
      "\tspeed: 0.0090s/iter; left time: 115.2409s\n",
      "\titers: 700, epoch: 6 | loss: 0.3663172\n",
      "\tspeed: 0.0090s/iter; left time: 114.5897s\n",
      "\titers: 800, epoch: 6 | loss: 0.3063536\n",
      "\tspeed: 0.0091s/iter; left time: 114.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 897 | Train Loss: 0.3487589 Vali Loss: 0.3490477 Test Loss: 0.3676376\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3730701\n",
      "\tspeed: 0.0415s/iter; left time: 516.6484s\n",
      "\titers: 200, epoch: 7 | loss: 0.3361551\n",
      "\tspeed: 0.0091s/iter; left time: 112.8106s\n",
      "\titers: 300, epoch: 7 | loss: 0.3233663\n",
      "\tspeed: 0.0088s/iter; left time: 108.2302s\n",
      "\titers: 400, epoch: 7 | loss: 0.3257569\n",
      "\tspeed: 0.0090s/iter; left time: 109.5441s\n",
      "\titers: 500, epoch: 7 | loss: 0.2971471\n",
      "\tspeed: 0.0088s/iter; left time: 106.3864s\n",
      "\titers: 600, epoch: 7 | loss: 0.3719977\n",
      "\tspeed: 0.0090s/iter; left time: 107.4315s\n",
      "\titers: 700, epoch: 7 | loss: 0.3599455\n",
      "\tspeed: 0.0089s/iter; left time: 105.3786s\n",
      "\titers: 800, epoch: 7 | loss: 0.3505773\n",
      "\tspeed: 0.0089s/iter; left time: 104.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 897 | Train Loss: 0.3434304 Vali Loss: 0.3479084 Test Loss: 0.3659843\n",
      "Validation loss decreased (0.348506 --> 0.347908).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3142720\n",
      "\tspeed: 0.0415s/iter; left time: 480.3257s\n",
      "\titers: 200, epoch: 8 | loss: 0.3610570\n",
      "\tspeed: 0.0093s/iter; left time: 106.8352s\n",
      "\titers: 300, epoch: 8 | loss: 0.3545507\n",
      "\tspeed: 0.0092s/iter; left time: 104.2339s\n",
      "\titers: 400, epoch: 8 | loss: 0.3285860\n",
      "\tspeed: 0.0094s/iter; left time: 106.1157s\n",
      "\titers: 500, epoch: 8 | loss: 0.2896002\n",
      "\tspeed: 0.0089s/iter; left time: 98.8633s\n",
      "\titers: 600, epoch: 8 | loss: 0.3139996\n",
      "\tspeed: 0.0093s/iter; left time: 102.4485s\n",
      "\titers: 700, epoch: 8 | loss: 0.3298711\n",
      "\tspeed: 0.0094s/iter; left time: 102.6222s\n",
      "\titers: 800, epoch: 8 | loss: 0.3476716\n",
      "\tspeed: 0.0089s/iter; left time: 96.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 897 | Train Loss: 0.3384230 Vali Loss: 0.3481841 Test Loss: 0.3652087\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3681039\n",
      "\tspeed: 0.0413s/iter; left time: 440.7781s\n",
      "\titers: 200, epoch: 9 | loss: 0.3442893\n",
      "\tspeed: 0.0090s/iter; left time: 95.1116s\n",
      "\titers: 300, epoch: 9 | loss: 0.3626364\n",
      "\tspeed: 0.0090s/iter; left time: 94.4292s\n",
      "\titers: 400, epoch: 9 | loss: 0.3456548\n",
      "\tspeed: 0.0088s/iter; left time: 90.7303s\n",
      "\titers: 500, epoch: 9 | loss: 0.3173474\n",
      "\tspeed: 0.0085s/iter; left time: 87.7367s\n",
      "\titers: 600, epoch: 9 | loss: 0.3172664\n",
      "\tspeed: 0.0087s/iter; left time: 88.8360s\n",
      "\titers: 700, epoch: 9 | loss: 0.3741704\n",
      "\tspeed: 0.0088s/iter; left time: 88.3675s\n",
      "\titers: 800, epoch: 9 | loss: 0.3217250\n",
      "\tspeed: 0.0088s/iter; left time: 87.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 897 | Train Loss: 0.3340488 Vali Loss: 0.3468455 Test Loss: 0.3638220\n",
      "Validation loss decreased (0.347908 --> 0.346846).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2824495\n",
      "\tspeed: 0.0421s/iter; left time: 410.9004s\n",
      "\titers: 200, epoch: 10 | loss: 0.3181238\n",
      "\tspeed: 0.0088s/iter; left time: 85.2586s\n",
      "\titers: 300, epoch: 10 | loss: 0.3088135\n",
      "\tspeed: 0.0088s/iter; left time: 84.5118s\n",
      "\titers: 400, epoch: 10 | loss: 0.3605276\n",
      "\tspeed: 0.0090s/iter; left time: 84.8143s\n",
      "\titers: 500, epoch: 10 | loss: 0.3768619\n",
      "\tspeed: 0.0090s/iter; left time: 83.8918s\n",
      "\titers: 600, epoch: 10 | loss: 0.3300643\n",
      "\tspeed: 0.0090s/iter; left time: 83.2129s\n",
      "\titers: 700, epoch: 10 | loss: 0.3152975\n",
      "\tspeed: 0.0086s/iter; left time: 78.6755s\n",
      "\titers: 800, epoch: 10 | loss: 0.3564855\n",
      "\tspeed: 0.0086s/iter; left time: 77.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 897 | Train Loss: 0.3310202 Vali Loss: 0.3446736 Test Loss: 0.3637165\n",
      "Validation loss decreased (0.346846 --> 0.344674).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.3347583\n",
      "\tspeed: 0.0414s/iter; left time: 367.6975s\n",
      "\titers: 200, epoch: 11 | loss: 0.3564956\n",
      "\tspeed: 0.0090s/iter; left time: 78.5530s\n",
      "\titers: 300, epoch: 11 | loss: 0.3332903\n",
      "\tspeed: 0.0088s/iter; left time: 76.0178s\n",
      "\titers: 400, epoch: 11 | loss: 0.3258144\n",
      "\tspeed: 0.0088s/iter; left time: 75.2374s\n",
      "\titers: 500, epoch: 11 | loss: 0.3253122\n",
      "\tspeed: 0.0088s/iter; left time: 74.1324s\n",
      "\titers: 600, epoch: 11 | loss: 0.3212380\n",
      "\tspeed: 0.0093s/iter; left time: 77.5979s\n",
      "\titers: 700, epoch: 11 | loss: 0.3763788\n",
      "\tspeed: 0.0088s/iter; left time: 72.7951s\n",
      "\titers: 800, epoch: 11 | loss: 0.3060581\n",
      "\tspeed: 0.0088s/iter; left time: 71.6499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 897 | Train Loss: 0.3273775 Vali Loss: 0.3435466 Test Loss: 0.3630838\n",
      "Validation loss decreased (0.344674 --> 0.343547).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.3171051\n",
      "\tspeed: 0.0418s/iter; left time: 333.6558s\n",
      "\titers: 200, epoch: 12 | loss: 0.3189286\n",
      "\tspeed: 0.0088s/iter; left time: 69.6538s\n",
      "\titers: 300, epoch: 12 | loss: 0.3306416\n",
      "\tspeed: 0.0089s/iter; left time: 68.8071s\n",
      "\titers: 400, epoch: 12 | loss: 0.3251909\n",
      "\tspeed: 0.0089s/iter; left time: 67.9242s\n",
      "\titers: 500, epoch: 12 | loss: 0.3294748\n",
      "\tspeed: 0.0089s/iter; left time: 67.1065s\n",
      "\titers: 600, epoch: 12 | loss: 0.3223368\n",
      "\tspeed: 0.0089s/iter; left time: 66.1510s\n",
      "\titers: 700, epoch: 12 | loss: 0.3156281\n",
      "\tspeed: 0.0089s/iter; left time: 65.8049s\n",
      "\titers: 800, epoch: 12 | loss: 0.3022338\n",
      "\tspeed: 0.0089s/iter; left time: 64.7775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 897 | Train Loss: 0.3243632 Vali Loss: 0.3459126 Test Loss: 0.3606473\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.3290944\n",
      "\tspeed: 0.0410s/iter; left time: 289.8140s\n",
      "\titers: 200, epoch: 13 | loss: 0.3176655\n",
      "\tspeed: 0.0088s/iter; left time: 61.4024s\n",
      "\titers: 300, epoch: 13 | loss: 0.3371607\n",
      "\tspeed: 0.0089s/iter; left time: 61.0615s\n",
      "\titers: 400, epoch: 13 | loss: 0.3279093\n",
      "\tspeed: 0.0089s/iter; left time: 60.3391s\n",
      "\titers: 500, epoch: 13 | loss: 0.2970512\n",
      "\tspeed: 0.0089s/iter; left time: 59.3615s\n",
      "\titers: 600, epoch: 13 | loss: 0.3378543\n",
      "\tspeed: 0.0088s/iter; left time: 58.0869s\n",
      "\titers: 700, epoch: 13 | loss: 0.2967855\n",
      "\tspeed: 0.0088s/iter; left time: 57.2827s\n",
      "\titers: 800, epoch: 13 | loss: 0.3148886\n",
      "\tspeed: 0.0088s/iter; left time: 56.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 897 | Train Loss: 0.3218812 Vali Loss: 0.3444730 Test Loss: 0.3629500\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.3281866\n",
      "\tspeed: 0.0403s/iter; left time: 248.9851s\n",
      "\titers: 200, epoch: 14 | loss: 0.2964166\n",
      "\tspeed: 0.0086s/iter; left time: 52.2600s\n",
      "\titers: 300, epoch: 14 | loss: 0.2841369\n",
      "\tspeed: 0.0086s/iter; left time: 51.1559s\n",
      "\titers: 400, epoch: 14 | loss: 0.3005539\n",
      "\tspeed: 0.0086s/iter; left time: 50.3121s\n",
      "\titers: 500, epoch: 14 | loss: 0.3279144\n",
      "\tspeed: 0.0086s/iter; left time: 49.6982s\n",
      "\titers: 600, epoch: 14 | loss: 0.3484330\n",
      "\tspeed: 0.0088s/iter; left time: 50.1102s\n",
      "\titers: 700, epoch: 14 | loss: 0.3004577\n",
      "\tspeed: 0.0088s/iter; left time: 49.1323s\n",
      "\titers: 800, epoch: 14 | loss: 0.3371571\n",
      "\tspeed: 0.0085s/iter; left time: 46.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 897 | Train Loss: 0.3199465 Vali Loss: 0.3430583 Test Loss: 0.3619661\n",
      "Validation loss decreased (0.343547 --> 0.343058).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.3163303\n",
      "\tspeed: 0.0399s/iter; left time: 210.9834s\n",
      "\titers: 200, epoch: 15 | loss: 0.3020713\n",
      "\tspeed: 0.0086s/iter; left time: 44.6910s\n",
      "\titers: 300, epoch: 15 | loss: 0.3083589\n",
      "\tspeed: 0.0086s/iter; left time: 43.7982s\n",
      "\titers: 400, epoch: 15 | loss: 0.3411031\n",
      "\tspeed: 0.0087s/iter; left time: 43.1537s\n",
      "\titers: 500, epoch: 15 | loss: 0.3179394\n",
      "\tspeed: 0.0086s/iter; left time: 42.2108s\n",
      "\titers: 600, epoch: 15 | loss: 0.3116530\n",
      "\tspeed: 0.0087s/iter; left time: 41.3813s\n",
      "\titers: 700, epoch: 15 | loss: 0.2811683\n",
      "\tspeed: 0.0087s/iter; left time: 40.5665s\n",
      "\titers: 800, epoch: 15 | loss: 0.2827787\n",
      "\tspeed: 0.0088s/iter; left time: 40.3814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 897 | Train Loss: 0.3177625 Vali Loss: 0.3435780 Test Loss: 0.3616664\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.3255170\n",
      "\tspeed: 0.0407s/iter; left time: 178.7257s\n",
      "\titers: 200, epoch: 16 | loss: 0.3085119\n",
      "\tspeed: 0.0087s/iter; left time: 37.3913s\n",
      "\titers: 300, epoch: 16 | loss: 0.3413093\n",
      "\tspeed: 0.0088s/iter; left time: 36.6313s\n",
      "\titers: 400, epoch: 16 | loss: 0.3244358\n",
      "\tspeed: 0.0087s/iter; left time: 35.7279s\n",
      "\titers: 500, epoch: 16 | loss: 0.2900431\n",
      "\tspeed: 0.0087s/iter; left time: 34.8560s\n",
      "\titers: 600, epoch: 16 | loss: 0.3432093\n",
      "\tspeed: 0.0087s/iter; left time: 33.8295s\n",
      "\titers: 700, epoch: 16 | loss: 0.3215046\n",
      "\tspeed: 0.0087s/iter; left time: 32.9995s\n",
      "\titers: 800, epoch: 16 | loss: 0.3611600\n",
      "\tspeed: 0.0087s/iter; left time: 32.0523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 897 | Train Loss: 0.3159378 Vali Loss: 0.3446867 Test Loss: 0.3626323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.3366415\n",
      "\tspeed: 0.0400s/iter; left time: 139.4134s\n",
      "\titers: 200, epoch: 17 | loss: 0.2753668\n",
      "\tspeed: 0.0087s/iter; left time: 29.5371s\n",
      "\titers: 300, epoch: 17 | loss: 0.3375722\n",
      "\tspeed: 0.0087s/iter; left time: 28.7379s\n",
      "\titers: 400, epoch: 17 | loss: 0.3544010\n",
      "\tspeed: 0.0087s/iter; left time: 27.8411s\n",
      "\titers: 500, epoch: 17 | loss: 0.3123714\n",
      "\tspeed: 0.0087s/iter; left time: 26.9107s\n",
      "\titers: 600, epoch: 17 | loss: 0.3189503\n",
      "\tspeed: 0.0090s/iter; left time: 26.8347s\n",
      "\titers: 700, epoch: 17 | loss: 0.3083826\n",
      "\tspeed: 0.0087s/iter; left time: 25.1656s\n",
      "\titers: 800, epoch: 17 | loss: 0.3014234\n",
      "\tspeed: 0.0087s/iter; left time: 24.2995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 897 | Train Loss: 0.3142884 Vali Loss: 0.3429579 Test Loss: 0.3614777\n",
      "Validation loss decreased (0.343058 --> 0.342958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.2661080\n",
      "\tspeed: 0.0408s/iter; left time: 105.6640s\n",
      "\titers: 200, epoch: 18 | loss: 0.2990568\n",
      "\tspeed: 0.0086s/iter; left time: 21.4154s\n",
      "\titers: 300, epoch: 18 | loss: 0.3222444\n",
      "\tspeed: 0.0086s/iter; left time: 20.6688s\n",
      "\titers: 400, epoch: 18 | loss: 0.3054195\n",
      "\tspeed: 0.0086s/iter; left time: 19.8210s\n",
      "\titers: 500, epoch: 18 | loss: 0.2665257\n",
      "\tspeed: 0.0087s/iter; left time: 19.0488s\n",
      "\titers: 600, epoch: 18 | loss: 0.3368691\n",
      "\tspeed: 0.0087s/iter; left time: 18.1916s\n",
      "\titers: 700, epoch: 18 | loss: 0.2991176\n",
      "\tspeed: 0.0087s/iter; left time: 17.3025s\n",
      "\titers: 800, epoch: 18 | loss: 0.2893756\n",
      "\tspeed: 0.0087s/iter; left time: 16.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 897 | Train Loss: 0.3129078 Vali Loss: 0.3435828 Test Loss: 0.3619969\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.3304125\n",
      "\tspeed: 0.0384s/iter; left time: 65.1334s\n",
      "\titers: 200, epoch: 19 | loss: 0.3260545\n",
      "\tspeed: 0.0085s/iter; left time: 13.5040s\n",
      "\titers: 300, epoch: 19 | loss: 0.3390594\n",
      "\tspeed: 0.0093s/iter; left time: 13.9212s\n",
      "\titers: 400, epoch: 19 | loss: 0.3017560\n",
      "\tspeed: 0.0085s/iter; left time: 11.8849s\n",
      "\titers: 500, epoch: 19 | loss: 0.2908346\n",
      "\tspeed: 0.0085s/iter; left time: 10.9937s\n",
      "\titers: 600, epoch: 19 | loss: 0.2753017\n",
      "\tspeed: 0.0085s/iter; left time: 10.1717s\n",
      "\titers: 700, epoch: 19 | loss: 0.2979496\n",
      "\tspeed: 0.0086s/iter; left time: 9.4195s\n",
      "\titers: 800, epoch: 19 | loss: 0.2968192\n",
      "\tspeed: 0.0087s/iter; left time: 8.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 897 | Train Loss: 0.3117750 Vali Loss: 0.3443417 Test Loss: 0.3627943\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.3307122\n",
      "\tspeed: 0.0387s/iter; left time: 30.8705s\n",
      "\titers: 200, epoch: 20 | loss: 0.3025938\n",
      "\tspeed: 0.0087s/iter; left time: 6.0608s\n",
      "\titers: 300, epoch: 20 | loss: 0.3137756\n",
      "\tspeed: 0.0087s/iter; left time: 5.2092s\n",
      "\titers: 400, epoch: 20 | loss: 0.2995884\n",
      "\tspeed: 0.0087s/iter; left time: 4.3266s\n",
      "\titers: 500, epoch: 20 | loss: 0.3448595\n",
      "\tspeed: 0.0087s/iter; left time: 3.4595s\n",
      "\titers: 600, epoch: 20 | loss: 0.3093475\n",
      "\tspeed: 0.0087s/iter; left time: 2.5786s\n",
      "\titers: 700, epoch: 20 | loss: 0.3201503\n",
      "\tspeed: 0.0084s/iter; left time: 1.6656s\n",
      "\titers: 800, epoch: 20 | loss: 0.3182980\n",
      "\tspeed: 0.0084s/iter; left time: 0.8244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 897 | Train Loss: 0.3106752 Vali Loss: 0.3423418 Test Loss: 0.3620897\n",
      "Validation loss decreased (0.342958 --> 0.342342).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.38033607602119446, rmse:0.6167139410972595, mae:0.36208972334861755, rse:0.564666211605072\n",
      "Original data scale mse:2383695.25, rmse:1543.9219970703125, mae:980.0679931640625, rse:0.10865209996700287\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7774693\n",
      "\tspeed: 0.0109s/iter; left time: 193.9124s\n",
      "\titers: 200, epoch: 1 | loss: 0.6751431\n",
      "\tspeed: 0.0088s/iter; left time: 155.8489s\n",
      "\titers: 300, epoch: 1 | loss: 0.6087647\n",
      "\tspeed: 0.0087s/iter; left time: 154.2075s\n",
      "\titers: 400, epoch: 1 | loss: 0.6034860\n",
      "\tspeed: 0.0087s/iter; left time: 152.8976s\n",
      "\titers: 500, epoch: 1 | loss: 0.5404494\n",
      "\tspeed: 0.0087s/iter; left time: 151.0358s\n",
      "\titers: 600, epoch: 1 | loss: 0.5629245\n",
      "\tspeed: 0.0086s/iter; left time: 149.9871s\n",
      "\titers: 700, epoch: 1 | loss: 0.5052282\n",
      "\tspeed: 0.0087s/iter; left time: 149.1689s\n",
      "\titers: 800, epoch: 1 | loss: 0.4954823\n",
      "\tspeed: 0.0087s/iter; left time: 148.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 897 | Train Loss: 0.5995725 Vali Loss: 0.4458747 Test Loss: 0.4591461\n",
      "Validation loss decreased (inf --> 0.445875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4513046\n",
      "\tspeed: 0.0396s/iter; left time: 670.3410s\n",
      "\titers: 200, epoch: 2 | loss: 0.4292589\n",
      "\tspeed: 0.0087s/iter; left time: 146.6718s\n",
      "\titers: 300, epoch: 2 | loss: 0.4000707\n",
      "\tspeed: 0.0087s/iter; left time: 144.9689s\n",
      "\titers: 400, epoch: 2 | loss: 0.4411529\n",
      "\tspeed: 0.0085s/iter; left time: 142.2559s\n",
      "\titers: 500, epoch: 2 | loss: 0.3781196\n",
      "\tspeed: 0.0085s/iter; left time: 141.0019s\n",
      "\titers: 600, epoch: 2 | loss: 0.3513761\n",
      "\tspeed: 0.0085s/iter; left time: 140.4830s\n",
      "\titers: 700, epoch: 2 | loss: 0.3698645\n",
      "\tspeed: 0.0085s/iter; left time: 139.6188s\n",
      "\titers: 800, epoch: 2 | loss: 0.3681866\n",
      "\tspeed: 0.0086s/iter; left time: 139.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 897 | Train Loss: 0.4100288 Vali Loss: 0.3623971 Test Loss: 0.3808250\n",
      "Validation loss decreased (0.445875 --> 0.362397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3657054\n",
      "\tspeed: 0.0405s/iter; left time: 649.9747s\n",
      "\titers: 200, epoch: 3 | loss: 0.3968618\n",
      "\tspeed: 0.0093s/iter; left time: 148.9041s\n",
      "\titers: 300, epoch: 3 | loss: 0.3694086\n",
      "\tspeed: 0.0086s/iter; left time: 136.2068s\n",
      "\titers: 400, epoch: 3 | loss: 0.3849172\n",
      "\tspeed: 0.0086s/iter; left time: 135.5283s\n",
      "\titers: 500, epoch: 3 | loss: 0.3935122\n",
      "\tspeed: 0.0086s/iter; left time: 134.7507s\n",
      "\titers: 600, epoch: 3 | loss: 0.3381604\n",
      "\tspeed: 0.0086s/iter; left time: 133.6106s\n",
      "\titers: 700, epoch: 3 | loss: 0.3651076\n",
      "\tspeed: 0.0086s/iter; left time: 133.2495s\n",
      "\titers: 800, epoch: 3 | loss: 0.3790073\n",
      "\tspeed: 0.0087s/iter; left time: 133.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 897 | Train Loss: 0.3739169 Vali Loss: 0.3553885 Test Loss: 0.3725315\n",
      "Validation loss decreased (0.362397 --> 0.355388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3487389\n",
      "\tspeed: 0.0412s/iter; left time: 624.3304s\n",
      "\titers: 200, epoch: 4 | loss: 0.3676181\n",
      "\tspeed: 0.0088s/iter; left time: 132.0581s\n",
      "\titers: 300, epoch: 4 | loss: 0.3484921\n",
      "\tspeed: 0.0088s/iter; left time: 131.1042s\n",
      "\titers: 400, epoch: 4 | loss: 0.3627521\n",
      "\tspeed: 0.0088s/iter; left time: 130.0990s\n",
      "\titers: 500, epoch: 4 | loss: 0.3417716\n",
      "\tspeed: 0.0087s/iter; left time: 128.2294s\n",
      "\titers: 600, epoch: 4 | loss: 0.3378545\n",
      "\tspeed: 0.0085s/iter; left time: 124.8311s\n",
      "\titers: 700, epoch: 4 | loss: 0.3636090\n",
      "\tspeed: 0.0086s/iter; left time: 124.7620s\n",
      "\titers: 800, epoch: 4 | loss: 0.3373620\n",
      "\tspeed: 0.0086s/iter; left time: 123.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 897 | Train Loss: 0.3630475 Vali Loss: 0.3541304 Test Loss: 0.3710423\n",
      "Validation loss decreased (0.355388 --> 0.354130).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3776742\n",
      "\tspeed: 0.0412s/iter; left time: 587.7750s\n",
      "\titers: 200, epoch: 5 | loss: 0.3508545\n",
      "\tspeed: 0.0093s/iter; left time: 131.1768s\n",
      "\titers: 300, epoch: 5 | loss: 0.3805312\n",
      "\tspeed: 0.0093s/iter; left time: 130.5802s\n",
      "\titers: 400, epoch: 5 | loss: 0.3610172\n",
      "\tspeed: 0.0093s/iter; left time: 129.2326s\n",
      "\titers: 500, epoch: 5 | loss: 0.3989326\n",
      "\tspeed: 0.0093s/iter; left time: 128.5022s\n",
      "\titers: 600, epoch: 5 | loss: 0.3641023\n",
      "\tspeed: 0.0093s/iter; left time: 127.5333s\n",
      "\titers: 700, epoch: 5 | loss: 0.3472407\n",
      "\tspeed: 0.0093s/iter; left time: 126.7883s\n",
      "\titers: 800, epoch: 5 | loss: 0.3726093\n",
      "\tspeed: 0.0102s/iter; left time: 138.4576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 897 | Train Loss: 0.3550299 Vali Loss: 0.3492062 Test Loss: 0.3663684\n",
      "Validation loss decreased (0.354130 --> 0.349206).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3538367\n",
      "\tspeed: 0.0450s/iter; left time: 601.1614s\n",
      "\titers: 200, epoch: 6 | loss: 0.3570811\n",
      "\tspeed: 0.0094s/iter; left time: 123.9892s\n",
      "\titers: 300, epoch: 6 | loss: 0.3274531\n",
      "\tspeed: 0.0092s/iter; left time: 120.7544s\n",
      "\titers: 400, epoch: 6 | loss: 0.3467427\n",
      "\tspeed: 0.0092s/iter; left time: 119.8991s\n",
      "\titers: 500, epoch: 6 | loss: 0.3370582\n",
      "\tspeed: 0.0092s/iter; left time: 119.0991s\n",
      "\titers: 600, epoch: 6 | loss: 0.3740810\n",
      "\tspeed: 0.0092s/iter; left time: 118.1604s\n",
      "\titers: 700, epoch: 6 | loss: 0.3002090\n",
      "\tspeed: 0.0091s/iter; left time: 116.3594s\n",
      "\titers: 800, epoch: 6 | loss: 0.3368007\n",
      "\tspeed: 0.0214s/iter; left time: 270.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 897 | Train Loss: 0.3482373 Vali Loss: 0.3491279 Test Loss: 0.3641592\n",
      "Validation loss decreased (0.349206 --> 0.349128).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3368134\n",
      "\tspeed: 0.0394s/iter; left time: 490.5377s\n",
      "\titers: 200, epoch: 7 | loss: 0.3164519\n",
      "\tspeed: 0.0087s/iter; left time: 107.7075s\n",
      "\titers: 300, epoch: 7 | loss: 0.3280363\n",
      "\tspeed: 0.0087s/iter; left time: 106.7187s\n",
      "\titers: 400, epoch: 7 | loss: 0.3481063\n",
      "\tspeed: 0.0087s/iter; left time: 105.5107s\n",
      "\titers: 500, epoch: 7 | loss: 0.3362916\n",
      "\tspeed: 0.0087s/iter; left time: 104.6394s\n",
      "\titers: 600, epoch: 7 | loss: 0.3141475\n",
      "\tspeed: 0.0093s/iter; left time: 110.8440s\n",
      "\titers: 700, epoch: 7 | loss: 0.3284840\n",
      "\tspeed: 0.0096s/iter; left time: 114.2760s\n",
      "\titers: 800, epoch: 7 | loss: 0.3428023\n",
      "\tspeed: 0.0087s/iter; left time: 102.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 897 | Train Loss: 0.3425291 Vali Loss: 0.3456379 Test Loss: 0.3627672\n",
      "Validation loss decreased (0.349128 --> 0.345638).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3183497\n",
      "\tspeed: 0.0407s/iter; left time: 470.3665s\n",
      "\titers: 200, epoch: 8 | loss: 0.3498324\n",
      "\tspeed: 0.0093s/iter; left time: 106.1164s\n",
      "\titers: 300, epoch: 8 | loss: 0.2768609\n",
      "\tspeed: 0.0093s/iter; left time: 105.1972s\n",
      "\titers: 400, epoch: 8 | loss: 0.3527438\n",
      "\tspeed: 0.0093s/iter; left time: 104.3762s\n",
      "\titers: 500, epoch: 8 | loss: 0.3375866\n",
      "\tspeed: 0.0093s/iter; left time: 103.5365s\n",
      "\titers: 600, epoch: 8 | loss: 0.3273603\n",
      "\tspeed: 0.0093s/iter; left time: 102.4075s\n",
      "\titers: 700, epoch: 8 | loss: 0.3372165\n",
      "\tspeed: 0.0090s/iter; left time: 99.0186s\n",
      "\titers: 800, epoch: 8 | loss: 0.3586134\n",
      "\tspeed: 0.0091s/iter; left time: 98.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 897 | Train Loss: 0.3375707 Vali Loss: 0.3490999 Test Loss: 0.3653992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3484027\n",
      "\tspeed: 0.1185s/iter; left time: 1263.9611s\n",
      "\titers: 200, epoch: 9 | loss: 0.3199206\n",
      "\tspeed: 0.0096s/iter; left time: 101.9222s\n",
      "\titers: 300, epoch: 9 | loss: 0.3186013\n",
      "\tspeed: 0.0093s/iter; left time: 97.1855s\n",
      "\titers: 400, epoch: 9 | loss: 0.3358135\n",
      "\tspeed: 0.0091s/iter; left time: 94.4808s\n",
      "\titers: 500, epoch: 9 | loss: 0.3053004\n",
      "\tspeed: 0.0092s/iter; left time: 94.0211s\n",
      "\titers: 600, epoch: 9 | loss: 0.3521647\n",
      "\tspeed: 0.0093s/iter; left time: 94.4844s\n",
      "\titers: 700, epoch: 9 | loss: 0.3570841\n",
      "\tspeed: 0.0091s/iter; left time: 91.6465s\n",
      "\titers: 800, epoch: 9 | loss: 0.3258080\n",
      "\tspeed: 0.0091s/iter; left time: 90.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 897 | Train Loss: 0.3334605 Vali Loss: 0.3464477 Test Loss: 0.3615061\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.3108127\n",
      "\tspeed: 0.0407s/iter; left time: 397.7850s\n",
      "\titers: 200, epoch: 10 | loss: 0.3208652\n",
      "\tspeed: 0.0089s/iter; left time: 86.0799s\n",
      "\titers: 300, epoch: 10 | loss: 0.3384416\n",
      "\tspeed: 0.0089s/iter; left time: 84.8801s\n",
      "\titers: 400, epoch: 10 | loss: 0.3429913\n",
      "\tspeed: 0.0089s/iter; left time: 84.2386s\n",
      "\titers: 500, epoch: 10 | loss: 0.3694143\n",
      "\tspeed: 0.0088s/iter; left time: 82.2411s\n",
      "\titers: 600, epoch: 10 | loss: 0.3883637\n",
      "\tspeed: 0.0088s/iter; left time: 81.9743s\n",
      "\titers: 700, epoch: 10 | loss: 0.3374763\n",
      "\tspeed: 0.0088s/iter; left time: 80.7232s\n",
      "\titers: 800, epoch: 10 | loss: 0.2939519\n",
      "\tspeed: 0.0088s/iter; left time: 79.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 897 | Train Loss: 0.3296852 Vali Loss: 0.3462023 Test Loss: 0.3615024\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.3120036\n",
      "\tspeed: 0.0419s/iter; left time: 371.8070s\n",
      "\titers: 200, epoch: 11 | loss: 0.3101943\n",
      "\tspeed: 0.0094s/iter; left time: 82.1198s\n",
      "\titers: 300, epoch: 11 | loss: 0.3080224\n",
      "\tspeed: 0.0092s/iter; left time: 80.1846s\n",
      "\titers: 400, epoch: 11 | loss: 0.3623957\n",
      "\tspeed: 0.0093s/iter; left time: 80.0490s\n",
      "\titers: 500, epoch: 11 | loss: 0.3192039\n",
      "\tspeed: 0.0093s/iter; left time: 79.1166s\n",
      "\titers: 600, epoch: 11 | loss: 0.3261977\n",
      "\tspeed: 0.0093s/iter; left time: 78.1336s\n",
      "\titers: 700, epoch: 11 | loss: 0.3347584\n",
      "\tspeed: 0.0101s/iter; left time: 83.5663s\n",
      "\titers: 800, epoch: 11 | loss: 0.3808204\n",
      "\tspeed: 0.0105s/iter; left time: 85.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 897 | Train Loss: 0.3264432 Vali Loss: 0.3459300 Test Loss: 0.3611685\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.3212530\n",
      "\tspeed: 0.0406s/iter; left time: 323.8492s\n",
      "\titers: 200, epoch: 12 | loss: 0.3205430\n",
      "\tspeed: 0.0087s/iter; left time: 68.6105s\n",
      "\titers: 300, epoch: 12 | loss: 0.3026505\n",
      "\tspeed: 0.0087s/iter; left time: 67.5789s\n",
      "\titers: 400, epoch: 12 | loss: 0.3757011\n",
      "\tspeed: 0.0087s/iter; left time: 66.9012s\n",
      "\titers: 500, epoch: 12 | loss: 0.3132679\n",
      "\tspeed: 0.0087s/iter; left time: 65.5773s\n",
      "\titers: 600, epoch: 12 | loss: 0.3185219\n",
      "\tspeed: 0.0087s/iter; left time: 65.0478s\n",
      "\titers: 700, epoch: 12 | loss: 0.3360890\n",
      "\tspeed: 0.0087s/iter; left time: 63.9295s\n",
      "\titers: 800, epoch: 12 | loss: 0.2704958\n",
      "\tspeed: 0.0087s/iter; left time: 63.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 897 | Train Loss: 0.3234286 Vali Loss: 0.3454515 Test Loss: 0.3619297\n",
      "Validation loss decreased (0.345638 --> 0.345451).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.3203055\n",
      "\tspeed: 0.0419s/iter; left time: 296.4703s\n",
      "\titers: 200, epoch: 13 | loss: 0.3404705\n",
      "\tspeed: 0.0088s/iter; left time: 61.3284s\n",
      "\titers: 300, epoch: 13 | loss: 0.3308966\n",
      "\tspeed: 0.0088s/iter; left time: 60.3983s\n",
      "\titers: 400, epoch: 13 | loss: 0.3491787\n",
      "\tspeed: 0.0089s/iter; left time: 60.2759s\n",
      "\titers: 500, epoch: 13 | loss: 0.3531452\n",
      "\tspeed: 0.0088s/iter; left time: 58.6032s\n",
      "\titers: 600, epoch: 13 | loss: 0.2851906\n",
      "\tspeed: 0.0088s/iter; left time: 57.9566s\n",
      "\titers: 700, epoch: 13 | loss: 0.3489001\n",
      "\tspeed: 0.0088s/iter; left time: 56.7725s\n",
      "\titers: 800, epoch: 13 | loss: 0.2888371\n",
      "\tspeed: 0.0088s/iter; left time: 55.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 897 | Train Loss: 0.3206600 Vali Loss: 0.3454894 Test Loss: 0.3627238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.3066975\n",
      "\tspeed: 0.0391s/iter; left time: 241.9212s\n",
      "\titers: 200, epoch: 14 | loss: 0.3062976\n",
      "\tspeed: 0.0087s/iter; left time: 52.9511s\n",
      "\titers: 300, epoch: 14 | loss: 0.3140700\n",
      "\tspeed: 0.0087s/iter; left time: 52.2147s\n",
      "\titers: 400, epoch: 14 | loss: 0.2907820\n",
      "\tspeed: 0.0087s/iter; left time: 51.3365s\n",
      "\titers: 500, epoch: 14 | loss: 0.3251272\n",
      "\tspeed: 0.0087s/iter; left time: 50.5405s\n",
      "\titers: 600, epoch: 14 | loss: 0.3207138\n",
      "\tspeed: 0.0088s/iter; left time: 49.7227s\n",
      "\titers: 700, epoch: 14 | loss: 0.3203254\n",
      "\tspeed: 0.0088s/iter; left time: 49.2024s\n",
      "\titers: 800, epoch: 14 | loss: 0.3507325\n",
      "\tspeed: 0.0087s/iter; left time: 47.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 897 | Train Loss: 0.3179228 Vali Loss: 0.3445534 Test Loss: 0.3622506\n",
      "Validation loss decreased (0.345451 --> 0.344553).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.3122340\n",
      "\tspeed: 0.0391s/iter; left time: 206.6113s\n",
      "\titers: 200, epoch: 15 | loss: 0.3323838\n",
      "\tspeed: 0.0087s/iter; left time: 45.1443s\n",
      "\titers: 300, epoch: 15 | loss: 0.3290726\n",
      "\tspeed: 0.0087s/iter; left time: 44.4201s\n",
      "\titers: 400, epoch: 15 | loss: 0.3269479\n",
      "\tspeed: 0.0086s/iter; left time: 43.0252s\n",
      "\titers: 500, epoch: 15 | loss: 0.3353547\n",
      "\tspeed: 0.0086s/iter; left time: 41.8876s\n",
      "\titers: 600, epoch: 15 | loss: 0.3008175\n",
      "\tspeed: 0.0086s/iter; left time: 41.2408s\n",
      "\titers: 700, epoch: 15 | loss: 0.2934311\n",
      "\tspeed: 0.0086s/iter; left time: 40.1816s\n",
      "\titers: 800, epoch: 15 | loss: 0.3224671\n",
      "\tspeed: 0.0086s/iter; left time: 39.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 897 | Train Loss: 0.3166009 Vali Loss: 0.3448488 Test Loss: 0.3641814\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.3261005\n",
      "\tspeed: 0.0380s/iter; left time: 166.7334s\n",
      "\titers: 200, epoch: 16 | loss: 0.3258140\n",
      "\tspeed: 0.0086s/iter; left time: 36.6696s\n",
      "\titers: 300, epoch: 16 | loss: 0.2868002\n",
      "\tspeed: 0.0085s/iter; left time: 35.7503s\n",
      "\titers: 400, epoch: 16 | loss: 0.3291508\n",
      "\tspeed: 0.0088s/iter; left time: 35.8734s\n",
      "\titers: 500, epoch: 16 | loss: 0.3149005\n",
      "\tspeed: 0.0087s/iter; left time: 34.6861s\n",
      "\titers: 600, epoch: 16 | loss: 0.3096982\n",
      "\tspeed: 0.0086s/iter; left time: 33.5787s\n",
      "\titers: 700, epoch: 16 | loss: 0.2979588\n",
      "\tspeed: 0.0087s/iter; left time: 32.8036s\n",
      "\titers: 800, epoch: 16 | loss: 0.3243422\n",
      "\tspeed: 0.0087s/iter; left time: 31.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 897 | Train Loss: 0.3143067 Vali Loss: 0.3436262 Test Loss: 0.3638674\n",
      "Validation loss decreased (0.344553 --> 0.343626).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.2882833\n",
      "\tspeed: 0.0438s/iter; left time: 152.6981s\n",
      "\titers: 200, epoch: 17 | loss: 0.3036416\n",
      "\tspeed: 0.0086s/iter; left time: 29.1299s\n",
      "\titers: 300, epoch: 17 | loss: 0.2904417\n",
      "\tspeed: 0.0085s/iter; left time: 27.9451s\n",
      "\titers: 400, epoch: 17 | loss: 0.3182327\n",
      "\tspeed: 0.0095s/iter; left time: 30.3524s\n",
      "\titers: 500, epoch: 17 | loss: 0.2774574\n",
      "\tspeed: 0.0087s/iter; left time: 26.7435s\n",
      "\titers: 600, epoch: 17 | loss: 0.3389721\n",
      "\tspeed: 0.0087s/iter; left time: 25.9428s\n",
      "\titers: 700, epoch: 17 | loss: 0.3461413\n",
      "\tspeed: 0.0087s/iter; left time: 25.1112s\n",
      "\titers: 800, epoch: 17 | loss: 0.3306652\n",
      "\tspeed: 0.0087s/iter; left time: 24.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 897 | Train Loss: 0.3125173 Vali Loss: 0.3433429 Test Loss: 0.3637203\n",
      "Validation loss decreased (0.343626 --> 0.343343).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.3331275\n",
      "\tspeed: 0.2806s/iter; left time: 727.3950s\n",
      "\titers: 200, epoch: 18 | loss: 0.3216007\n",
      "\tspeed: 0.0500s/iter; left time: 124.5692s\n",
      "\titers: 300, epoch: 18 | loss: 0.3117593\n",
      "\tspeed: 0.0522s/iter; left time: 124.9102s\n",
      "\titers: 400, epoch: 18 | loss: 0.2743699\n",
      "\tspeed: 0.0590s/iter; left time: 135.2962s\n",
      "\titers: 500, epoch: 18 | loss: 0.3222850\n",
      "\tspeed: 0.0553s/iter; left time: 121.1583s\n",
      "\titers: 600, epoch: 18 | loss: 0.2771661\n",
      "\tspeed: 0.0557s/iter; left time: 116.5510s\n",
      "\titers: 700, epoch: 18 | loss: 0.3060183\n",
      "\tspeed: 0.0558s/iter; left time: 111.0735s\n",
      "\titers: 800, epoch: 18 | loss: 0.2818872\n",
      "\tspeed: 0.0627s/iter; left time: 118.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:51.03s\n",
      "Steps: 897 | Train Loss: 0.3111976 Vali Loss: 0.3450217 Test Loss: 0.3640846\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.2994820\n",
      "\tspeed: 0.2994s/iter; left time: 507.4847s\n",
      "\titers: 200, epoch: 19 | loss: 0.3568630\n",
      "\tspeed: 0.0496s/iter; left time: 79.0495s\n",
      "\titers: 300, epoch: 19 | loss: 0.2891262\n",
      "\tspeed: 0.0538s/iter; left time: 80.4939s\n",
      "\titers: 400, epoch: 19 | loss: 0.3171934\n",
      "\tspeed: 0.0421s/iter; left time: 58.6887s\n",
      "\titers: 500, epoch: 19 | loss: 0.2793809\n",
      "\tspeed: 0.0279s/iter; left time: 36.0870s\n",
      "\titers: 600, epoch: 19 | loss: 0.3038394\n",
      "\tspeed: 0.0213s/iter; left time: 25.4819s\n",
      "\titers: 700, epoch: 19 | loss: 0.3113309\n",
      "\tspeed: 0.0222s/iter; left time: 24.3365s\n",
      "\titers: 800, epoch: 19 | loss: 0.3030738\n",
      "\tspeed: 0.0221s/iter; left time: 21.9622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.17s\n",
      "Steps: 897 | Train Loss: 0.3101808 Vali Loss: 0.3425474 Test Loss: 0.3645630\n",
      "Validation loss decreased (0.343343 --> 0.342547).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2925731\n",
      "\tspeed: 0.0859s/iter; left time: 68.5264s\n",
      "\titers: 200, epoch: 20 | loss: 0.2654369\n",
      "\tspeed: 0.0117s/iter; left time: 8.1498s\n",
      "\titers: 300, epoch: 20 | loss: 0.2985319\n",
      "\tspeed: 0.0116s/iter; left time: 6.9622s\n",
      "\titers: 400, epoch: 20 | loss: 0.3121902\n",
      "\tspeed: 0.0112s/iter; left time: 5.5769s\n",
      "\titers: 500, epoch: 20 | loss: 0.3083813\n",
      "\tspeed: 0.0113s/iter; left time: 4.5151s\n",
      "\titers: 600, epoch: 20 | loss: 0.3238294\n",
      "\tspeed: 0.0112s/iter; left time: 3.3467s\n",
      "\titers: 700, epoch: 20 | loss: 0.3087211\n",
      "\tspeed: 0.0112s/iter; left time: 2.2226s\n",
      "\titers: 800, epoch: 20 | loss: 0.3275436\n",
      "\tspeed: 0.0111s/iter; left time: 1.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.93s\n",
      "Steps: 897 | Train Loss: 0.3086473 Vali Loss: 0.3434329 Test Loss: 0.3636374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.38670042157173157, rmse:0.6218523979187012, mae:0.3645629584789276, rse:0.5693709850311279\n",
      "Original data scale mse:2395718.25, rmse:1547.810791015625, mae:982.5762329101562, rse:0.10892577469348907\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7366505\n",
      "\tspeed: 0.0327s/iter; left time: 581.5329s\n",
      "\titers: 200, epoch: 1 | loss: 0.6479643\n",
      "\tspeed: 0.0115s/iter; left time: 204.0290s\n",
      "\titers: 300, epoch: 1 | loss: 0.6151385\n",
      "\tspeed: 0.0112s/iter; left time: 197.3579s\n",
      "\titers: 400, epoch: 1 | loss: 0.5734547\n",
      "\tspeed: 0.0105s/iter; left time: 183.8238s\n",
      "\titers: 500, epoch: 1 | loss: 0.5883787\n",
      "\tspeed: 0.0102s/iter; left time: 176.9395s\n",
      "\titers: 600, epoch: 1 | loss: 0.5283536\n",
      "\tspeed: 0.0103s/iter; left time: 178.3983s\n",
      "\titers: 700, epoch: 1 | loss: 0.5319592\n",
      "\tspeed: 0.0101s/iter; left time: 173.3018s\n",
      "\titers: 800, epoch: 1 | loss: 0.5144297\n",
      "\tspeed: 0.0101s/iter; left time: 172.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 894 | Train Loss: 0.6120612 Vali Loss: 0.4599707 Test Loss: 0.4716345\n",
      "Validation loss decreased (inf --> 0.459971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4572157\n",
      "\tspeed: 0.0453s/iter; left time: 765.6249s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530738\n",
      "\tspeed: 0.0097s/iter; left time: 162.1094s\n",
      "\titers: 300, epoch: 2 | loss: 0.4448233\n",
      "\tspeed: 0.0095s/iter; left time: 158.7635s\n",
      "\titers: 400, epoch: 2 | loss: 0.4612013\n",
      "\tspeed: 0.0096s/iter; left time: 159.6172s\n",
      "\titers: 500, epoch: 2 | loss: 0.4307253\n",
      "\tspeed: 0.0095s/iter; left time: 156.4601s\n",
      "\titers: 600, epoch: 2 | loss: 0.4569948\n",
      "\tspeed: 0.0097s/iter; left time: 159.0907s\n",
      "\titers: 700, epoch: 2 | loss: 0.4278845\n",
      "\tspeed: 0.0092s/iter; left time: 149.0397s\n",
      "\titers: 800, epoch: 2 | loss: 0.4178460\n",
      "\tspeed: 0.0094s/iter; left time: 152.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 894 | Train Loss: 0.4272809 Vali Loss: 0.3834392 Test Loss: 0.4024604\n",
      "Validation loss decreased (0.459971 --> 0.383439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4186552\n",
      "\tspeed: 0.0449s/iter; left time: 717.3901s\n",
      "\titers: 200, epoch: 3 | loss: 0.4165560\n",
      "\tspeed: 0.0098s/iter; left time: 156.4526s\n",
      "\titers: 300, epoch: 3 | loss: 0.4020907\n",
      "\tspeed: 0.0097s/iter; left time: 152.5224s\n",
      "\titers: 400, epoch: 3 | loss: 0.4213612\n",
      "\tspeed: 0.0097s/iter; left time: 152.0798s\n",
      "\titers: 500, epoch: 3 | loss: 0.3421817\n",
      "\tspeed: 0.0096s/iter; left time: 148.9909s\n",
      "\titers: 600, epoch: 3 | loss: 0.4090547\n",
      "\tspeed: 0.0095s/iter; left time: 146.7001s\n",
      "\titers: 700, epoch: 3 | loss: 0.4059201\n",
      "\tspeed: 0.0094s/iter; left time: 144.4110s\n",
      "\titers: 800, epoch: 3 | loss: 0.4001186\n",
      "\tspeed: 0.0104s/iter; left time: 158.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 894 | Train Loss: 0.3910679 Vali Loss: 0.3768012 Test Loss: 0.3954803\n",
      "Validation loss decreased (0.383439 --> 0.376801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4120415\n",
      "\tspeed: 0.0436s/iter; left time: 657.7917s\n",
      "\titers: 200, epoch: 4 | loss: 0.3708228\n",
      "\tspeed: 0.0095s/iter; left time: 142.0613s\n",
      "\titers: 300, epoch: 4 | loss: 0.3700168\n",
      "\tspeed: 0.0094s/iter; left time: 140.4544s\n",
      "\titers: 400, epoch: 4 | loss: 0.3696789\n",
      "\tspeed: 0.0095s/iter; left time: 140.6681s\n",
      "\titers: 500, epoch: 4 | loss: 0.3704349\n",
      "\tspeed: 0.0096s/iter; left time: 140.9836s\n",
      "\titers: 600, epoch: 4 | loss: 0.3580534\n",
      "\tspeed: 0.0095s/iter; left time: 138.2037s\n",
      "\titers: 700, epoch: 4 | loss: 0.3707525\n",
      "\tspeed: 0.0095s/iter; left time: 138.4131s\n",
      "\titers: 800, epoch: 4 | loss: 0.3454503\n",
      "\tspeed: 0.0095s/iter; left time: 137.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 894 | Train Loss: 0.3802215 Vali Loss: 0.3784407 Test Loss: 0.3944877\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3508845\n",
      "\tspeed: 0.0452s/iter; left time: 642.5983s\n",
      "\titers: 200, epoch: 5 | loss: 0.3809310\n",
      "\tspeed: 0.0110s/iter; left time: 154.8940s\n",
      "\titers: 300, epoch: 5 | loss: 0.3944344\n",
      "\tspeed: 0.0109s/iter; left time: 152.3712s\n",
      "\titers: 400, epoch: 5 | loss: 0.3966805\n",
      "\tspeed: 0.0097s/iter; left time: 134.1856s\n",
      "\titers: 500, epoch: 5 | loss: 0.3770353\n",
      "\tspeed: 0.0094s/iter; left time: 130.4553s\n",
      "\titers: 600, epoch: 5 | loss: 0.3931713\n",
      "\tspeed: 0.0091s/iter; left time: 124.5896s\n",
      "\titers: 700, epoch: 5 | loss: 0.3493163\n",
      "\tspeed: 0.0092s/iter; left time: 124.5244s\n",
      "\titers: 800, epoch: 5 | loss: 0.3842440\n",
      "\tspeed: 0.0091s/iter; left time: 122.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 894 | Train Loss: 0.3724009 Vali Loss: 0.3734277 Test Loss: 0.3924864\n",
      "Validation loss decreased (0.376801 --> 0.373428).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3966673\n",
      "\tspeed: 0.0427s/iter; left time: 568.7187s\n",
      "\titers: 200, epoch: 6 | loss: 0.3558659\n",
      "\tspeed: 0.0091s/iter; left time: 120.6841s\n",
      "\titers: 300, epoch: 6 | loss: 0.3744527\n",
      "\tspeed: 0.0090s/iter; left time: 117.3665s\n",
      "\titers: 400, epoch: 6 | loss: 0.3786902\n",
      "\tspeed: 0.0089s/iter; left time: 116.2690s\n",
      "\titers: 500, epoch: 6 | loss: 0.3561548\n",
      "\tspeed: 0.0091s/iter; left time: 117.3542s\n",
      "\titers: 600, epoch: 6 | loss: 0.3710408\n",
      "\tspeed: 0.0093s/iter; left time: 119.6705s\n",
      "\titers: 700, epoch: 6 | loss: 0.3952173\n",
      "\tspeed: 0.0093s/iter; left time: 118.5046s\n",
      "\titers: 800, epoch: 6 | loss: 0.3412501\n",
      "\tspeed: 0.0093s/iter; left time: 117.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 894 | Train Loss: 0.3650437 Vali Loss: 0.3734994 Test Loss: 0.3879066\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3746090\n",
      "\tspeed: 0.0420s/iter; left time: 521.5554s\n",
      "\titers: 200, epoch: 7 | loss: 0.3318700\n",
      "\tspeed: 0.0091s/iter; left time: 111.5657s\n",
      "\titers: 300, epoch: 7 | loss: 0.3692707\n",
      "\tspeed: 0.0091s/iter; left time: 110.6423s\n",
      "\titers: 400, epoch: 7 | loss: 0.3778376\n",
      "\tspeed: 0.0090s/iter; left time: 109.1847s\n",
      "\titers: 500, epoch: 7 | loss: 0.3813817\n",
      "\tspeed: 0.0090s/iter; left time: 108.2427s\n",
      "\titers: 600, epoch: 7 | loss: 0.3554855\n",
      "\tspeed: 0.0090s/iter; left time: 107.6058s\n",
      "\titers: 700, epoch: 7 | loss: 0.3382915\n",
      "\tspeed: 0.0090s/iter; left time: 106.7217s\n",
      "\titers: 800, epoch: 7 | loss: 0.3599035\n",
      "\tspeed: 0.0090s/iter; left time: 105.9747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 894 | Train Loss: 0.3594682 Vali Loss: 0.3736148 Test Loss: 0.3886037\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3398907\n",
      "\tspeed: 0.0429s/iter; left time: 494.5452s\n",
      "\titers: 200, epoch: 8 | loss: 0.3347653\n",
      "\tspeed: 0.0100s/iter; left time: 114.4621s\n",
      "\titers: 300, epoch: 8 | loss: 0.3559730\n",
      "\tspeed: 0.0095s/iter; left time: 107.0639s\n",
      "\titers: 400, epoch: 8 | loss: 0.3314939\n",
      "\tspeed: 0.0094s/iter; left time: 105.9741s\n",
      "\titers: 500, epoch: 8 | loss: 0.3508800\n",
      "\tspeed: 0.0094s/iter; left time: 104.8701s\n",
      "\titers: 600, epoch: 8 | loss: 0.3124669\n",
      "\tspeed: 0.0094s/iter; left time: 103.9574s\n",
      "\titers: 700, epoch: 8 | loss: 0.3954764\n",
      "\tspeed: 0.0095s/iter; left time: 103.2804s\n",
      "\titers: 800, epoch: 8 | loss: 0.3534641\n",
      "\tspeed: 0.0094s/iter; left time: 102.1550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 894 | Train Loss: 0.3539570 Vali Loss: 0.3754734 Test Loss: 0.3887312\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3465421\n",
      "\tspeed: 0.0418s/iter; left time: 443.7969s\n",
      "\titers: 200, epoch: 9 | loss: 0.3590814\n",
      "\tspeed: 0.0093s/iter; left time: 97.6508s\n",
      "\titers: 300, epoch: 9 | loss: 0.3541987\n",
      "\tspeed: 0.0093s/iter; left time: 96.6384s\n",
      "\titers: 400, epoch: 9 | loss: 0.3536294\n",
      "\tspeed: 0.0093s/iter; left time: 95.7075s\n",
      "\titers: 500, epoch: 9 | loss: 0.3403978\n",
      "\tspeed: 0.0092s/iter; left time: 94.4582s\n",
      "\titers: 600, epoch: 9 | loss: 0.3178267\n",
      "\tspeed: 0.0091s/iter; left time: 91.9120s\n",
      "\titers: 700, epoch: 9 | loss: 0.3399575\n",
      "\tspeed: 0.0091s/iter; left time: 91.0874s\n",
      "\titers: 800, epoch: 9 | loss: 0.3633573\n",
      "\tspeed: 0.0091s/iter; left time: 90.2499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 894 | Train Loss: 0.3495473 Vali Loss: 0.3739317 Test Loss: 0.3846523\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.3240972\n",
      "\tspeed: 0.0419s/iter; left time: 407.4995s\n",
      "\titers: 200, epoch: 10 | loss: 0.3292312\n",
      "\tspeed: 0.0093s/iter; left time: 89.7207s\n",
      "\titers: 300, epoch: 10 | loss: 0.3544411\n",
      "\tspeed: 0.0096s/iter; left time: 91.1897s\n",
      "\titers: 400, epoch: 10 | loss: 0.3440052\n",
      "\tspeed: 0.0093s/iter; left time: 88.1940s\n",
      "\titers: 500, epoch: 10 | loss: 0.3600684\n",
      "\tspeed: 0.0094s/iter; left time: 88.0726s\n",
      "\titers: 600, epoch: 10 | loss: 0.3635264\n",
      "\tspeed: 0.0093s/iter; left time: 86.0916s\n",
      "\titers: 700, epoch: 10 | loss: 0.3340632\n",
      "\tspeed: 0.0093s/iter; left time: 85.4048s\n",
      "\titers: 800, epoch: 10 | loss: 0.3328926\n",
      "\tspeed: 0.0093s/iter; left time: 84.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 894 | Train Loss: 0.3453247 Vali Loss: 0.3736304 Test Loss: 0.3850542\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4169333279132843, rmse:0.6457037329673767, mae:0.39248672127723694, rse:0.591385543346405\n",
      "Original data scale mse:3020437.25, rmse:1737.9405517578125, mae:1113.3966064453125, rse:0.12242083251476288\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7474340\n",
      "\tspeed: 0.0111s/iter; left time: 196.7295s\n",
      "\titers: 200, epoch: 1 | loss: 0.6355537\n",
      "\tspeed: 0.0088s/iter; left time: 155.7306s\n",
      "\titers: 300, epoch: 1 | loss: 0.6089092\n",
      "\tspeed: 0.0091s/iter; left time: 160.5104s\n",
      "\titers: 400, epoch: 1 | loss: 0.5633525\n",
      "\tspeed: 0.0091s/iter; left time: 158.9535s\n",
      "\titers: 500, epoch: 1 | loss: 0.5566725\n",
      "\tspeed: 0.0091s/iter; left time: 157.5360s\n",
      "\titers: 600, epoch: 1 | loss: 0.5191299\n",
      "\tspeed: 0.0091s/iter; left time: 157.3906s\n",
      "\titers: 700, epoch: 1 | loss: 0.5209419\n",
      "\tspeed: 0.0091s/iter; left time: 156.6177s\n",
      "\titers: 800, epoch: 1 | loss: 0.5392749\n",
      "\tspeed: 0.0091s/iter; left time: 156.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 894 | Train Loss: 0.6113821 Vali Loss: 0.4600261 Test Loss: 0.4716002\n",
      "Validation loss decreased (inf --> 0.460026).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4323377\n",
      "\tspeed: 0.0418s/iter; left time: 706.4526s\n",
      "\titers: 200, epoch: 2 | loss: 0.4380670\n",
      "\tspeed: 0.0092s/iter; left time: 153.9955s\n",
      "\titers: 300, epoch: 2 | loss: 0.4069262\n",
      "\tspeed: 0.0090s/iter; left time: 150.5866s\n",
      "\titers: 400, epoch: 2 | loss: 0.4060146\n",
      "\tspeed: 0.0090s/iter; left time: 148.9496s\n",
      "\titers: 500, epoch: 2 | loss: 0.4226371\n",
      "\tspeed: 0.0089s/iter; left time: 146.2006s\n",
      "\titers: 600, epoch: 2 | loss: 0.4023727\n",
      "\tspeed: 0.0090s/iter; left time: 147.3338s\n",
      "\titers: 700, epoch: 2 | loss: 0.3903765\n",
      "\tspeed: 0.0090s/iter; left time: 146.5561s\n",
      "\titers: 800, epoch: 2 | loss: 0.4049474\n",
      "\tspeed: 0.0090s/iter; left time: 145.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 894 | Train Loss: 0.4269410 Vali Loss: 0.3832490 Test Loss: 0.4040817\n",
      "Validation loss decreased (0.460026 --> 0.383249).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3945546\n",
      "\tspeed: 0.0403s/iter; left time: 643.8826s\n",
      "\titers: 200, epoch: 3 | loss: 0.3931334\n",
      "\tspeed: 0.0089s/iter; left time: 141.0509s\n",
      "\titers: 300, epoch: 3 | loss: 0.3742604\n",
      "\tspeed: 0.0089s/iter; left time: 139.8816s\n",
      "\titers: 400, epoch: 3 | loss: 0.4025612\n",
      "\tspeed: 0.0089s/iter; left time: 139.3773s\n",
      "\titers: 500, epoch: 3 | loss: 0.4098895\n",
      "\tspeed: 0.0088s/iter; left time: 137.2342s\n",
      "\titers: 600, epoch: 3 | loss: 0.3673977\n",
      "\tspeed: 0.0088s/iter; left time: 136.2540s\n",
      "\titers: 700, epoch: 3 | loss: 0.4007058\n",
      "\tspeed: 0.0088s/iter; left time: 135.1555s\n",
      "\titers: 800, epoch: 3 | loss: 0.3716867\n",
      "\tspeed: 0.0088s/iter; left time: 134.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 894 | Train Loss: 0.3917959 Vali Loss: 0.3763416 Test Loss: 0.3974220\n",
      "Validation loss decreased (0.383249 --> 0.376342).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3654645\n",
      "\tspeed: 0.0413s/iter; left time: 623.6644s\n",
      "\titers: 200, epoch: 4 | loss: 0.3597856\n",
      "\tspeed: 0.0090s/iter; left time: 135.3053s\n",
      "\titers: 300, epoch: 4 | loss: 0.3836107\n",
      "\tspeed: 0.0087s/iter; left time: 129.7063s\n",
      "\titers: 400, epoch: 4 | loss: 0.3846945\n",
      "\tspeed: 0.0087s/iter; left time: 128.4635s\n",
      "\titers: 500, epoch: 4 | loss: 0.3858984\n",
      "\tspeed: 0.0087s/iter; left time: 127.5240s\n",
      "\titers: 600, epoch: 4 | loss: 0.3641272\n",
      "\tspeed: 0.0087s/iter; left time: 126.9189s\n",
      "\titers: 700, epoch: 4 | loss: 0.3990811\n",
      "\tspeed: 0.0087s/iter; left time: 126.3768s\n",
      "\titers: 800, epoch: 4 | loss: 0.3865961\n",
      "\tspeed: 0.0087s/iter; left time: 125.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 894 | Train Loss: 0.3803333 Vali Loss: 0.3734543 Test Loss: 0.3938187\n",
      "Validation loss decreased (0.376342 --> 0.373454).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3691791\n",
      "\tspeed: 0.0411s/iter; left time: 583.2391s\n",
      "\titers: 200, epoch: 5 | loss: 0.3875010\n",
      "\tspeed: 0.0088s/iter; left time: 124.5999s\n",
      "\titers: 300, epoch: 5 | loss: 0.3336984\n",
      "\tspeed: 0.0088s/iter; left time: 123.4803s\n",
      "\titers: 400, epoch: 5 | loss: 0.3949812\n",
      "\tspeed: 0.0088s/iter; left time: 122.3998s\n",
      "\titers: 500, epoch: 5 | loss: 0.3704691\n",
      "\tspeed: 0.0088s/iter; left time: 121.6669s\n",
      "\titers: 600, epoch: 5 | loss: 0.3623731\n",
      "\tspeed: 0.0088s/iter; left time: 119.9231s\n",
      "\titers: 700, epoch: 5 | loss: 0.3911361\n",
      "\tspeed: 0.0088s/iter; left time: 119.6980s\n",
      "\titers: 800, epoch: 5 | loss: 0.3673284\n",
      "\tspeed: 0.0088s/iter; left time: 118.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 894 | Train Loss: 0.3717504 Vali Loss: 0.3738165 Test Loss: 0.3954064\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3381485\n",
      "\tspeed: 0.0404s/iter; left time: 538.3190s\n",
      "\titers: 200, epoch: 6 | loss: 0.3637605\n",
      "\tspeed: 0.0090s/iter; left time: 118.5763s\n",
      "\titers: 300, epoch: 6 | loss: 0.3601425\n",
      "\tspeed: 0.0090s/iter; left time: 117.6966s\n",
      "\titers: 400, epoch: 6 | loss: 0.3537968\n",
      "\tspeed: 0.0090s/iter; left time: 116.7605s\n",
      "\titers: 500, epoch: 6 | loss: 0.4000482\n",
      "\tspeed: 0.0090s/iter; left time: 115.7238s\n",
      "\titers: 600, epoch: 6 | loss: 0.3715847\n",
      "\tspeed: 0.0089s/iter; left time: 114.6480s\n",
      "\titers: 700, epoch: 6 | loss: 0.3366649\n",
      "\tspeed: 0.0089s/iter; left time: 113.6677s\n",
      "\titers: 800, epoch: 6 | loss: 0.3589806\n",
      "\tspeed: 0.0089s/iter; left time: 112.6991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 894 | Train Loss: 0.3654986 Vali Loss: 0.3756456 Test Loss: 0.3945992\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4201226\n",
      "\tspeed: 0.0409s/iter; left time: 508.2981s\n",
      "\titers: 200, epoch: 7 | loss: 0.3307817\n",
      "\tspeed: 0.0091s/iter; left time: 112.0212s\n",
      "\titers: 300, epoch: 7 | loss: 0.3864700\n",
      "\tspeed: 0.0089s/iter; left time: 109.1924s\n",
      "\titers: 400, epoch: 7 | loss: 0.3921708\n",
      "\tspeed: 0.0089s/iter; left time: 107.4315s\n",
      "\titers: 500, epoch: 7 | loss: 0.3847368\n",
      "\tspeed: 0.0088s/iter; left time: 105.9924s\n",
      "\titers: 600, epoch: 7 | loss: 0.3877086\n",
      "\tspeed: 0.0089s/iter; left time: 105.9505s\n",
      "\titers: 700, epoch: 7 | loss: 0.3741014\n",
      "\tspeed: 0.0088s/iter; left time: 104.2638s\n",
      "\titers: 800, epoch: 7 | loss: 0.3376850\n",
      "\tspeed: 0.0089s/iter; left time: 103.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 894 | Train Loss: 0.3597783 Vali Loss: 0.3750241 Test Loss: 0.3946863\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3523608\n",
      "\tspeed: 0.0404s/iter; left time: 465.0523s\n",
      "\titers: 200, epoch: 8 | loss: 0.3677526\n",
      "\tspeed: 0.0088s/iter; left time: 100.3805s\n",
      "\titers: 300, epoch: 8 | loss: 0.3192852\n",
      "\tspeed: 0.0088s/iter; left time: 99.1887s\n",
      "\titers: 400, epoch: 8 | loss: 0.3398608\n",
      "\tspeed: 0.0088s/iter; left time: 98.5892s\n",
      "\titers: 500, epoch: 8 | loss: 0.3431868\n",
      "\tspeed: 0.0088s/iter; left time: 97.5712s\n",
      "\titers: 600, epoch: 8 | loss: 0.3579680\n",
      "\tspeed: 0.0088s/iter; left time: 96.5813s\n",
      "\titers: 700, epoch: 8 | loss: 0.3458340\n",
      "\tspeed: 0.0088s/iter; left time: 95.6858s\n",
      "\titers: 800, epoch: 8 | loss: 0.3483633\n",
      "\tspeed: 0.0087s/iter; left time: 94.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 894 | Train Loss: 0.3545344 Vali Loss: 0.3728617 Test Loss: 0.3932250\n",
      "Validation loss decreased (0.373454 --> 0.372862).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3401249\n",
      "\tspeed: 0.0413s/iter; left time: 438.6164s\n",
      "\titers: 200, epoch: 9 | loss: 0.3503364\n",
      "\tspeed: 0.0089s/iter; left time: 93.8019s\n",
      "\titers: 300, epoch: 9 | loss: 0.3165112\n",
      "\tspeed: 0.0088s/iter; left time: 92.2882s\n",
      "\titers: 400, epoch: 9 | loss: 0.3751268\n",
      "\tspeed: 0.0089s/iter; left time: 91.5680s\n",
      "\titers: 500, epoch: 9 | loss: 0.3713911\n",
      "\tspeed: 0.0089s/iter; left time: 90.5464s\n",
      "\titers: 600, epoch: 9 | loss: 0.3560998\n",
      "\tspeed: 0.0089s/iter; left time: 90.1796s\n",
      "\titers: 700, epoch: 9 | loss: 0.3369823\n",
      "\tspeed: 0.0091s/iter; left time: 90.8655s\n",
      "\titers: 800, epoch: 9 | loss: 0.3533979\n",
      "\tspeed: 0.0091s/iter; left time: 89.9478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 894 | Train Loss: 0.3500346 Vali Loss: 0.3748201 Test Loss: 0.3940451\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.3712398\n",
      "\tspeed: 0.0433s/iter; left time: 421.7131s\n",
      "\titers: 200, epoch: 10 | loss: 0.3531148\n",
      "\tspeed: 0.0099s/iter; left time: 95.8227s\n",
      "\titers: 300, epoch: 10 | loss: 0.3384618\n",
      "\tspeed: 0.0099s/iter; left time: 94.6126s\n",
      "\titers: 400, epoch: 10 | loss: 0.3184957\n",
      "\tspeed: 0.0099s/iter; left time: 93.3217s\n",
      "\titers: 500, epoch: 10 | loss: 0.3634504\n",
      "\tspeed: 0.0095s/iter; left time: 89.1023s\n",
      "\titers: 600, epoch: 10 | loss: 0.3326967\n",
      "\tspeed: 0.0112s/iter; left time: 103.7021s\n",
      "\titers: 700, epoch: 10 | loss: 0.3714318\n",
      "\tspeed: 0.0103s/iter; left time: 93.9599s\n",
      "\titers: 800, epoch: 10 | loss: 0.3395610\n",
      "\tspeed: 0.0099s/iter; left time: 89.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 894 | Train Loss: 0.3460949 Vali Loss: 0.3734435 Test Loss: 0.3912965\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.3257872\n",
      "\tspeed: 0.0439s/iter; left time: 388.0401s\n",
      "\titers: 200, epoch: 11 | loss: 0.3516488\n",
      "\tspeed: 0.0103s/iter; left time: 90.0905s\n",
      "\titers: 300, epoch: 11 | loss: 0.3352672\n",
      "\tspeed: 0.0103s/iter; left time: 88.7695s\n",
      "\titers: 400, epoch: 11 | loss: 0.3366731\n",
      "\tspeed: 0.0090s/iter; left time: 76.4817s\n",
      "\titers: 500, epoch: 11 | loss: 0.3452054\n",
      "\tspeed: 0.0089s/iter; left time: 75.4997s\n",
      "\titers: 600, epoch: 11 | loss: 0.3537838\n",
      "\tspeed: 0.0091s/iter; left time: 75.5761s\n",
      "\titers: 700, epoch: 11 | loss: 0.3662442\n",
      "\tspeed: 0.0090s/iter; left time: 73.7979s\n",
      "\titers: 800, epoch: 11 | loss: 0.3342824\n",
      "\tspeed: 0.0090s/iter; left time: 73.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 894 | Train Loss: 0.3423273 Vali Loss: 0.3739399 Test Loss: 0.3899401\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.3649893\n",
      "\tspeed: 0.0413s/iter; left time: 328.0171s\n",
      "\titers: 200, epoch: 12 | loss: 0.2991540\n",
      "\tspeed: 0.0089s/iter; left time: 69.4554s\n",
      "\titers: 300, epoch: 12 | loss: 0.3787786\n",
      "\tspeed: 0.0088s/iter; left time: 68.4230s\n",
      "\titers: 400, epoch: 12 | loss: 0.3304369\n",
      "\tspeed: 0.0089s/iter; left time: 67.8232s\n",
      "\titers: 500, epoch: 12 | loss: 0.3176028\n",
      "\tspeed: 0.0088s/iter; left time: 66.7831s\n",
      "\titers: 600, epoch: 12 | loss: 0.3396703\n",
      "\tspeed: 0.0088s/iter; left time: 65.8183s\n",
      "\titers: 700, epoch: 12 | loss: 0.3184816\n",
      "\tspeed: 0.0088s/iter; left time: 64.9335s\n",
      "\titers: 800, epoch: 12 | loss: 0.3279783\n",
      "\tspeed: 0.0088s/iter; left time: 64.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 894 | Train Loss: 0.3392230 Vali Loss: 0.3755046 Test Loss: 0.3898554\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.3355803\n",
      "\tspeed: 0.0414s/iter; left time: 292.2530s\n",
      "\titers: 200, epoch: 13 | loss: 0.3466175\n",
      "\tspeed: 0.0090s/iter; left time: 62.8363s\n",
      "\titers: 300, epoch: 13 | loss: 0.3597040\n",
      "\tspeed: 0.0090s/iter; left time: 61.8836s\n",
      "\titers: 400, epoch: 13 | loss: 0.3271321\n",
      "\tspeed: 0.0091s/iter; left time: 61.3197s\n",
      "\titers: 500, epoch: 13 | loss: 0.3291291\n",
      "\tspeed: 0.0091s/iter; left time: 60.3260s\n",
      "\titers: 600, epoch: 13 | loss: 0.3479301\n",
      "\tspeed: 0.0091s/iter; left time: 59.4723s\n",
      "\titers: 700, epoch: 13 | loss: 0.3613821\n",
      "\tspeed: 0.0091s/iter; left time: 58.5050s\n",
      "\titers: 800, epoch: 13 | loss: 0.3415374\n",
      "\tspeed: 0.0091s/iter; left time: 57.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 894 | Train Loss: 0.3367388 Vali Loss: 0.3721802 Test Loss: 0.3891556\n",
      "Validation loss decreased (0.372862 --> 0.372180).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.3204671\n",
      "\tspeed: 0.0413s/iter; left time: 254.6385s\n",
      "\titers: 200, epoch: 14 | loss: 0.3388022\n",
      "\tspeed: 0.0088s/iter; left time: 53.1291s\n",
      "\titers: 300, epoch: 14 | loss: 0.3285611\n",
      "\tspeed: 0.0088s/iter; left time: 52.2771s\n",
      "\titers: 400, epoch: 14 | loss: 0.3368885\n",
      "\tspeed: 0.0088s/iter; left time: 51.4463s\n",
      "\titers: 500, epoch: 14 | loss: 0.3361987\n",
      "\tspeed: 0.0088s/iter; left time: 50.6093s\n",
      "\titers: 600, epoch: 14 | loss: 0.3519664\n",
      "\tspeed: 0.0088s/iter; left time: 49.7673s\n",
      "\titers: 700, epoch: 14 | loss: 0.3412981\n",
      "\tspeed: 0.0088s/iter; left time: 48.8462s\n",
      "\titers: 800, epoch: 14 | loss: 0.3354294\n",
      "\tspeed: 0.0088s/iter; left time: 47.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 894 | Train Loss: 0.3339849 Vali Loss: 0.3727413 Test Loss: 0.3878030\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.3016567\n",
      "\tspeed: 0.0424s/iter; left time: 223.3360s\n",
      "\titers: 200, epoch: 15 | loss: 0.3179742\n",
      "\tspeed: 0.0092s/iter; left time: 47.4260s\n",
      "\titers: 300, epoch: 15 | loss: 0.3379367\n",
      "\tspeed: 0.0092s/iter; left time: 46.3917s\n",
      "\titers: 400, epoch: 15 | loss: 0.3075408\n",
      "\tspeed: 0.0091s/iter; left time: 45.4058s\n",
      "\titers: 500, epoch: 15 | loss: 0.3251965\n",
      "\tspeed: 0.0091s/iter; left time: 44.0641s\n",
      "\titers: 600, epoch: 15 | loss: 0.4018779\n",
      "\tspeed: 0.0090s/iter; left time: 43.1026s\n",
      "\titers: 700, epoch: 15 | loss: 0.3394886\n",
      "\tspeed: 0.0090s/iter; left time: 42.2054s\n",
      "\titers: 800, epoch: 15 | loss: 0.3534757\n",
      "\tspeed: 0.0090s/iter; left time: 41.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 894 | Train Loss: 0.3318703 Vali Loss: 0.3738452 Test Loss: 0.3881492\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.3330279\n",
      "\tspeed: 0.0407s/iter; left time: 177.9419s\n",
      "\titers: 200, epoch: 16 | loss: 0.3218009\n",
      "\tspeed: 0.0088s/iter; left time: 37.4700s\n",
      "\titers: 300, epoch: 16 | loss: 0.3502965\n",
      "\tspeed: 0.0088s/iter; left time: 36.5924s\n",
      "\titers: 400, epoch: 16 | loss: 0.3117763\n",
      "\tspeed: 0.0088s/iter; left time: 35.7349s\n",
      "\titers: 500, epoch: 16 | loss: 0.3195502\n",
      "\tspeed: 0.0088s/iter; left time: 34.8323s\n",
      "\titers: 600, epoch: 16 | loss: 0.3242238\n",
      "\tspeed: 0.0090s/iter; left time: 34.7163s\n",
      "\titers: 700, epoch: 16 | loss: 0.3178045\n",
      "\tspeed: 0.0091s/iter; left time: 34.2456s\n",
      "\titers: 800, epoch: 16 | loss: 0.3057912\n",
      "\tspeed: 0.0091s/iter; left time: 33.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 894 | Train Loss: 0.3299339 Vali Loss: 0.3751233 Test Loss: 0.3876106\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.3498950\n",
      "\tspeed: 0.0416s/iter; left time: 144.7779s\n",
      "\titers: 200, epoch: 17 | loss: 0.3549408\n",
      "\tspeed: 0.0091s/iter; left time: 30.8034s\n",
      "\titers: 300, epoch: 17 | loss: 0.3097367\n",
      "\tspeed: 0.0090s/iter; left time: 29.4993s\n",
      "\titers: 400, epoch: 17 | loss: 0.3442809\n",
      "\tspeed: 0.0089s/iter; left time: 28.3921s\n",
      "\titers: 500, epoch: 17 | loss: 0.3221650\n",
      "\tspeed: 0.0089s/iter; left time: 27.4620s\n",
      "\titers: 600, epoch: 17 | loss: 0.3345749\n",
      "\tspeed: 0.0089s/iter; left time: 26.5351s\n",
      "\titers: 700, epoch: 17 | loss: 0.3390704\n",
      "\tspeed: 0.0089s/iter; left time: 25.6171s\n",
      "\titers: 800, epoch: 17 | loss: 0.3097121\n",
      "\tspeed: 0.0089s/iter; left time: 24.7556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 894 | Train Loss: 0.3283761 Vali Loss: 0.3761904 Test Loss: 0.3870439\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.3574530\n",
      "\tspeed: 0.0422s/iter; left time: 109.0792s\n",
      "\titers: 200, epoch: 18 | loss: 0.3139735\n",
      "\tspeed: 0.0100s/iter; left time: 24.8034s\n",
      "\titers: 300, epoch: 18 | loss: 0.3384395\n",
      "\tspeed: 0.0100s/iter; left time: 23.7870s\n",
      "\titers: 400, epoch: 18 | loss: 0.3604164\n",
      "\tspeed: 0.0100s/iter; left time: 22.8013s\n",
      "\titers: 500, epoch: 18 | loss: 0.3547573\n",
      "\tspeed: 0.0100s/iter; left time: 21.8214s\n",
      "\titers: 600, epoch: 18 | loss: 0.3237102\n",
      "\tspeed: 0.0100s/iter; left time: 20.7809s\n",
      "\titers: 700, epoch: 18 | loss: 0.3122691\n",
      "\tspeed: 0.0100s/iter; left time: 19.8292s\n",
      "\titers: 800, epoch: 18 | loss: 0.3373485\n",
      "\tspeed: 0.0100s/iter; left time: 18.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 894 | Train Loss: 0.3273500 Vali Loss: 0.3737465 Test Loss: 0.3868445\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4200829565525055, rmse:0.6481380462646484, mae:0.38915538787841797, rse:0.5936150550842285\n",
      "Original data scale mse:2837935.75, rmse:1684.617431640625, mae:1074.3492431640625, rse:0.11866474151611328\n"
     ]
    }
   ],
   "source": [
    "# Dynamic + default variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.4112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.5470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3597</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.5785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.2528</td>\n",
       "      <td>0.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4524</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.5647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4169</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.3925</td>\n",
       "      <td>0.5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4201</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.5936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2016  0.4490  0.2636  0.4112\n",
       "              2         24        0.2025  0.4500  0.2619  0.4122\n",
       "              1         96        0.3570  0.5975  0.3740  0.5470\n",
       "              2         96        0.3597  0.5998  0.3818  0.5491\n",
       "              1         168       0.3990  0.6316  0.4067  0.5785\n",
       "              2         168       0.3850  0.6205  0.4035  0.5683\n",
       "MAE           1         24        0.2029  0.4505  0.2528  0.4126\n",
       "              2         24        0.2046  0.4524  0.2532  0.4143\n",
       "              1         96        0.3803  0.6167  0.3621  0.5647\n",
       "              2         96        0.3867  0.6219  0.3646  0.5694\n",
       "              1         168       0.4169  0.6457  0.3925  0.5914\n",
       "              2         168       0.4201  0.6481  0.3892  0.5936"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT_default.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1205259.875</td>\n",
       "      <td>1097.8433</td>\n",
       "      <td>717.0481</td>\n",
       "      <td>0.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1178370.250</td>\n",
       "      <td>1085.5276</td>\n",
       "      <td>706.2290</td>\n",
       "      <td>0.0763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2492006.000</td>\n",
       "      <td>1578.6089</td>\n",
       "      <td>1051.8491</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2693139.250</td>\n",
       "      <td>1641.0787</td>\n",
       "      <td>1101.3221</td>\n",
       "      <td>0.1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3082198.250</td>\n",
       "      <td>1755.6190</td>\n",
       "      <td>1179.6866</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3154101.000</td>\n",
       "      <td>1775.9789</td>\n",
       "      <td>1187.3914</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1151100.125</td>\n",
       "      <td>1072.8933</td>\n",
       "      <td>668.9365</td>\n",
       "      <td>0.0754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1154194.750</td>\n",
       "      <td>1074.3346</td>\n",
       "      <td>667.5917</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2383695.250</td>\n",
       "      <td>1543.9220</td>\n",
       "      <td>980.0680</td>\n",
       "      <td>0.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2395718.250</td>\n",
       "      <td>1547.8108</td>\n",
       "      <td>982.5762</td>\n",
       "      <td>0.1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3020437.250</td>\n",
       "      <td>1737.9406</td>\n",
       "      <td>1113.3966</td>\n",
       "      <td>0.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>2837935.750</td>\n",
       "      <td>1684.6174</td>\n",
       "      <td>1074.3492</td>\n",
       "      <td>0.1187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1205259.875  1097.8433   717.0481  0.0771\n",
       "              2         24        1178370.250  1085.5276   706.2290  0.0763\n",
       "              1         96        2492006.000  1578.6089  1051.8491  0.1111\n",
       "              2         96        2693139.250  1641.0787  1101.3221  0.1155\n",
       "              1         168       3082198.250  1755.6190  1179.6866  0.1237\n",
       "              2         168       3154101.000  1775.9789  1187.3914  0.1251\n",
       "MAE           1         24        1151100.125  1072.8933   668.9365  0.0754\n",
       "              2         24        1154194.750  1074.3346   667.5917  0.0755\n",
       "              1         96        2383695.250  1543.9220   980.0680  0.1087\n",
       "              2         96        2395718.250  1547.8108   982.5762  0.1089\n",
       "              1         168       3020437.250  1737.9406  1113.3966  0.1224\n",
       "              2         168       2837935.750  1684.6174  1074.3492  0.1187"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.4514</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.4134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.4117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.5670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.5986</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.5481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.3908</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.5734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2038  0.4514  0.2530  0.4134\n",
       "         MSE            0.2021  0.4495  0.2628  0.4117\n",
       "96       MAE            0.3835  0.6193  0.3633  0.5670\n",
       "         MSE            0.3583  0.5986  0.3779  0.5481\n",
       "168      MAE            0.4185  0.6469  0.3908  0.5925\n",
       "         MSE            0.3920  0.6261  0.4051  0.5734"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.152647e+06</td>\n",
       "      <td>1073.6140</td>\n",
       "      <td>668.2641</td>\n",
       "      <td>0.0754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.191815e+06</td>\n",
       "      <td>1091.6854</td>\n",
       "      <td>711.6385</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.389707e+06</td>\n",
       "      <td>1545.8664</td>\n",
       "      <td>981.3221</td>\n",
       "      <td>0.1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.592573e+06</td>\n",
       "      <td>1609.8438</td>\n",
       "      <td>1076.5856</td>\n",
       "      <td>0.1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.929186e+06</td>\n",
       "      <td>1711.2790</td>\n",
       "      <td>1093.8729</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.118150e+06</td>\n",
       "      <td>1765.7990</td>\n",
       "      <td>1183.5390</td>\n",
       "      <td>0.1244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.152647e+06  1073.6140   668.2641  0.0754\n",
       "         MSE            1.191815e+06  1091.6854   711.6385  0.0767\n",
       "96       MAE            2.389707e+06  1545.8664   981.3221  0.1088\n",
       "         MSE            2.592573e+06  1609.8438  1076.5856  0.1133\n",
       "168      MAE            2.929186e+06  1711.2790  1093.8729  0.1205\n",
       "         MSE            3.118150e+06  1765.7990  1183.5390  0.1244"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled_IT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0972284\n",
      "\tspeed: 0.0536s/iter; left time: 966.1672s\n",
      "\titers: 200, epoch: 1 | loss: 0.0881270\n",
      "\tspeed: 0.0342s/iter; left time: 613.4235s\n",
      "\titers: 300, epoch: 1 | loss: 0.0660699\n",
      "\tspeed: 0.0341s/iter; left time: 608.2886s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 400, epoch: 1 | loss: 0.0614750\n",
      "\tspeed: 0.0340s/iter; left time: 602.7891s\n",
      "\titers: 500, epoch: 1 | loss: 0.0473126\n",
      "\tspeed: 0.0339s/iter; left time: 597.8125s\n",
      "\titers: 600, epoch: 1 | loss: 0.0451944\n",
      "\tspeed: 0.0339s/iter; left time: 593.9310s\n",
      "\titers: 700, epoch: 1 | loss: 0.0370400\n",
      "\tspeed: 0.0339s/iter; left time: 590.5924s\n",
      "\titers: 800, epoch: 1 | loss: 0.0355196\n",
      "\tspeed: 0.0339s/iter; left time: 587.0480s\n",
      "\titers: 900, epoch: 1 | loss: 0.0400502\n",
      "\tspeed: 0.0339s/iter; left time: 583.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.55s\n",
      "Steps: 906 | Train Loss: 0.0606730 Vali Loss: 0.0234355 Test Loss: 0.0250223\n",
      "Validation loss decreased (inf --> 0.023436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0261067\n",
      "\tspeed: 0.1125s/iter; left time: 1924.9819s\n",
      "\titers: 200, epoch: 2 | loss: 0.0200592\n",
      "\tspeed: 0.0338s/iter; left time: 575.7650s\n",
      "\titers: 300, epoch: 2 | loss: 0.0135396\n",
      "\tspeed: 0.0338s/iter; left time: 572.3251s\n",
      "\titers: 400, epoch: 2 | loss: 0.0149230\n",
      "\tspeed: 0.0338s/iter; left time: 569.0747s\n",
      "\titers: 500, epoch: 2 | loss: 0.0170563\n",
      "\tspeed: 0.0339s/iter; left time: 566.4360s\n",
      "\titers: 600, epoch: 2 | loss: 0.0198278\n",
      "\tspeed: 0.0339s/iter; left time: 563.1388s\n",
      "\titers: 700, epoch: 2 | loss: 0.0141211\n",
      "\tspeed: 0.0339s/iter; left time: 559.8101s\n",
      "\titers: 800, epoch: 2 | loss: 0.0126595\n",
      "\tspeed: 0.0339s/iter; left time: 557.1424s\n",
      "\titers: 900, epoch: 2 | loss: 0.0124770\n",
      "\tspeed: 0.0339s/iter; left time: 553.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.97s\n",
      "Steps: 906 | Train Loss: 0.0178323 Vali Loss: 0.0126410 Test Loss: 0.0139350\n",
      "Validation loss decreased (0.023436 --> 0.012641).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0115169\n",
      "\tspeed: 0.0977s/iter; left time: 1584.0204s\n",
      "\titers: 200, epoch: 3 | loss: 0.0113969\n",
      "\tspeed: 0.0340s/iter; left time: 547.1095s\n",
      "\titers: 300, epoch: 3 | loss: 0.0122884\n",
      "\tspeed: 0.0340s/iter; left time: 543.8462s\n",
      "\titers: 400, epoch: 3 | loss: 0.0091601\n",
      "\tspeed: 0.0340s/iter; left time: 541.0101s\n",
      "\titers: 500, epoch: 3 | loss: 0.0105911\n",
      "\tspeed: 0.0340s/iter; left time: 537.9233s\n",
      "\titers: 600, epoch: 3 | loss: 0.0134643\n",
      "\tspeed: 0.0340s/iter; left time: 534.0213s\n",
      "\titers: 700, epoch: 3 | loss: 0.0123838\n",
      "\tspeed: 0.0340s/iter; left time: 530.0699s\n",
      "\titers: 800, epoch: 3 | loss: 0.0144936\n",
      "\tspeed: 0.0340s/iter; left time: 528.0502s\n",
      "\titers: 900, epoch: 3 | loss: 0.0104546\n",
      "\tspeed: 0.0340s/iter; left time: 524.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0117578 Vali Loss: 0.0118713 Test Loss: 0.0133946\n",
      "Validation loss decreased (0.012641 --> 0.011871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0126508\n",
      "\tspeed: 0.0957s/iter; left time: 1464.2749s\n",
      "\titers: 200, epoch: 4 | loss: 0.0097992\n",
      "\tspeed: 0.0341s/iter; left time: 517.8578s\n",
      "\titers: 300, epoch: 4 | loss: 0.0106744\n",
      "\tspeed: 0.0341s/iter; left time: 514.7958s\n",
      "\titers: 400, epoch: 4 | loss: 0.0124443\n",
      "\tspeed: 0.0341s/iter; left time: 511.1804s\n",
      "\titers: 500, epoch: 4 | loss: 0.0105432\n",
      "\tspeed: 0.0341s/iter; left time: 507.4604s\n",
      "\titers: 600, epoch: 4 | loss: 0.0091463\n",
      "\tspeed: 0.0341s/iter; left time: 504.3534s\n",
      "\titers: 700, epoch: 4 | loss: 0.0091151\n",
      "\tspeed: 0.0341s/iter; left time: 500.7982s\n",
      "\titers: 800, epoch: 4 | loss: 0.0115890\n",
      "\tspeed: 0.0340s/iter; left time: 497.0697s\n",
      "\titers: 900, epoch: 4 | loss: 0.0114444\n",
      "\tspeed: 0.0341s/iter; left time: 494.2043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0106479 Vali Loss: 0.0109121 Test Loss: 0.0119638\n",
      "Validation loss decreased (0.011871 --> 0.010912).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0093729\n",
      "\tspeed: 0.0960s/iter; left time: 1382.2816s\n",
      "\titers: 200, epoch: 5 | loss: 0.0132099\n",
      "\tspeed: 0.0341s/iter; left time: 487.0891s\n",
      "\titers: 300, epoch: 5 | loss: 0.0109833\n",
      "\tspeed: 0.0341s/iter; left time: 483.5999s\n",
      "\titers: 400, epoch: 5 | loss: 0.0088139\n",
      "\tspeed: 0.0341s/iter; left time: 480.7247s\n",
      "\titers: 500, epoch: 5 | loss: 0.0091402\n",
      "\tspeed: 0.0341s/iter; left time: 477.8466s\n",
      "\titers: 600, epoch: 5 | loss: 0.0087063\n",
      "\tspeed: 0.0341s/iter; left time: 473.4118s\n",
      "\titers: 700, epoch: 5 | loss: 0.0136012\n",
      "\tspeed: 0.0341s/iter; left time: 470.2053s\n",
      "\titers: 800, epoch: 5 | loss: 0.0067761\n",
      "\tspeed: 0.0341s/iter; left time: 466.8037s\n",
      "\titers: 900, epoch: 5 | loss: 0.0103542\n",
      "\tspeed: 0.0341s/iter; left time: 463.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0096692 Vali Loss: 0.0101006 Test Loss: 0.0114337\n",
      "Validation loss decreased (0.010912 --> 0.010101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0084755\n",
      "\tspeed: 0.0979s/iter; left time: 1320.9922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0094736\n",
      "\tspeed: 0.0341s/iter; left time: 456.7171s\n",
      "\titers: 300, epoch: 6 | loss: 0.0119596\n",
      "\tspeed: 0.0341s/iter; left time: 453.2811s\n",
      "\titers: 400, epoch: 6 | loss: 0.0080049\n",
      "\tspeed: 0.0341s/iter; left time: 449.8563s\n",
      "\titers: 500, epoch: 6 | loss: 0.0060297\n",
      "\tspeed: 0.0341s/iter; left time: 446.0368s\n",
      "\titers: 600, epoch: 6 | loss: 0.0095585\n",
      "\tspeed: 0.0341s/iter; left time: 442.6893s\n",
      "\titers: 700, epoch: 6 | loss: 0.0103028\n",
      "\tspeed: 0.0341s/iter; left time: 439.4991s\n",
      "\titers: 800, epoch: 6 | loss: 0.0082057\n",
      "\tspeed: 0.0341s/iter; left time: 435.5695s\n",
      "\titers: 900, epoch: 6 | loss: 0.0073152\n",
      "\tspeed: 0.0340s/iter; left time: 431.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0089187 Vali Loss: 0.0100227 Test Loss: 0.0115355\n",
      "Validation loss decreased (0.010101 --> 0.010023).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0078097\n",
      "\tspeed: 0.0956s/iter; left time: 1203.4684s\n",
      "\titers: 200, epoch: 7 | loss: 0.0098551\n",
      "\tspeed: 0.0340s/iter; left time: 425.0222s\n",
      "\titers: 300, epoch: 7 | loss: 0.0068888\n",
      "\tspeed: 0.0340s/iter; left time: 421.5561s\n",
      "\titers: 400, epoch: 7 | loss: 0.0101782\n",
      "\tspeed: 0.0341s/iter; left time: 418.5162s\n",
      "\titers: 500, epoch: 7 | loss: 0.0082054\n",
      "\tspeed: 0.0340s/iter; left time: 414.5701s\n",
      "\titers: 600, epoch: 7 | loss: 0.0057436\n",
      "\tspeed: 0.0340s/iter; left time: 411.3872s\n",
      "\titers: 700, epoch: 7 | loss: 0.0080928\n",
      "\tspeed: 0.0341s/iter; left time: 408.4066s\n",
      "\titers: 800, epoch: 7 | loss: 0.0097687\n",
      "\tspeed: 0.0341s/iter; left time: 404.9074s\n",
      "\titers: 900, epoch: 7 | loss: 0.0065648\n",
      "\tspeed: 0.0341s/iter; left time: 401.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0083377 Vali Loss: 0.0095675 Test Loss: 0.0110407\n",
      "Validation loss decreased (0.010023 --> 0.009568).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0066216\n",
      "\tspeed: 0.1007s/iter; left time: 1176.4372s\n",
      "\titers: 200, epoch: 8 | loss: 0.0064539\n",
      "\tspeed: 0.0340s/iter; left time: 393.6709s\n",
      "\titers: 300, epoch: 8 | loss: 0.0060218\n",
      "\tspeed: 0.0340s/iter; left time: 390.0610s\n",
      "\titers: 400, epoch: 8 | loss: 0.0077329\n",
      "\tspeed: 0.0340s/iter; left time: 386.6462s\n",
      "\titers: 500, epoch: 8 | loss: 0.0081930\n",
      "\tspeed: 0.0340s/iter; left time: 383.7722s\n",
      "\titers: 600, epoch: 8 | loss: 0.0085409\n",
      "\tspeed: 0.0340s/iter; left time: 380.2440s\n",
      "\titers: 700, epoch: 8 | loss: 0.0067278\n",
      "\tspeed: 0.0340s/iter; left time: 376.6261s\n",
      "\titers: 800, epoch: 8 | loss: 0.0081196\n",
      "\tspeed: 0.0340s/iter; left time: 373.3279s\n",
      "\titers: 900, epoch: 8 | loss: 0.0074904\n",
      "\tspeed: 0.0339s/iter; left time: 369.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0077836 Vali Loss: 0.0094765 Test Loss: 0.0111610\n",
      "Validation loss decreased (0.009568 --> 0.009476).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0052157\n",
      "\tspeed: 0.0960s/iter; left time: 1034.0261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0087680\n",
      "\tspeed: 0.0340s/iter; left time: 362.6165s\n",
      "\titers: 300, epoch: 9 | loss: 0.0094829\n",
      "\tspeed: 0.0340s/iter; left time: 359.9351s\n",
      "\titers: 400, epoch: 9 | loss: 0.0059583\n",
      "\tspeed: 0.0340s/iter; left time: 355.9876s\n",
      "\titers: 500, epoch: 9 | loss: 0.0065391\n",
      "\tspeed: 0.0339s/iter; left time: 352.1177s\n",
      "\titers: 600, epoch: 9 | loss: 0.0079168\n",
      "\tspeed: 0.0340s/iter; left time: 349.1545s\n",
      "\titers: 700, epoch: 9 | loss: 0.0076959\n",
      "\tspeed: 0.0340s/iter; left time: 345.5142s\n",
      "\titers: 800, epoch: 9 | loss: 0.0063940\n",
      "\tspeed: 0.0340s/iter; left time: 342.2727s\n",
      "\titers: 900, epoch: 9 | loss: 0.0064888\n",
      "\tspeed: 0.0340s/iter; left time: 339.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0072910 Vali Loss: 0.0106013 Test Loss: 0.0116490\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0081920\n",
      "\tspeed: 0.0924s/iter; left time: 912.0649s\n",
      "\titers: 200, epoch: 10 | loss: 0.0071812\n",
      "\tspeed: 0.0340s/iter; left time: 331.7457s\n",
      "\titers: 300, epoch: 10 | loss: 0.0080360\n",
      "\tspeed: 0.0340s/iter; left time: 328.7072s\n",
      "\titers: 400, epoch: 10 | loss: 0.0067103\n",
      "\tspeed: 0.0340s/iter; left time: 325.5007s\n",
      "\titers: 500, epoch: 10 | loss: 0.0057465\n",
      "\tspeed: 0.0340s/iter; left time: 322.0288s\n",
      "\titers: 600, epoch: 10 | loss: 0.0076225\n",
      "\tspeed: 0.0340s/iter; left time: 318.1950s\n",
      "\titers: 700, epoch: 10 | loss: 0.0055612\n",
      "\tspeed: 0.0340s/iter; left time: 314.8224s\n",
      "\titers: 800, epoch: 10 | loss: 0.0072454\n",
      "\tspeed: 0.0340s/iter; left time: 311.8976s\n",
      "\titers: 900, epoch: 10 | loss: 0.0064351\n",
      "\tspeed: 0.0340s/iter; left time: 308.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0068866 Vali Loss: 0.0099388 Test Loss: 0.0116837\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0069420\n",
      "\tspeed: 0.0922s/iter; left time: 826.5974s\n",
      "\titers: 200, epoch: 11 | loss: 0.0058681\n",
      "\tspeed: 0.0340s/iter; left time: 301.3443s\n",
      "\titers: 300, epoch: 11 | loss: 0.0074936\n",
      "\tspeed: 0.0340s/iter; left time: 297.8629s\n",
      "\titers: 400, epoch: 11 | loss: 0.0056524\n",
      "\tspeed: 0.0340s/iter; left time: 294.6827s\n",
      "\titers: 500, epoch: 11 | loss: 0.0071056\n",
      "\tspeed: 0.0340s/iter; left time: 291.1001s\n",
      "\titers: 600, epoch: 11 | loss: 0.0073804\n",
      "\tspeed: 0.0340s/iter; left time: 287.7534s\n",
      "\titers: 700, epoch: 11 | loss: 0.0070853\n",
      "\tspeed: 0.0340s/iter; left time: 284.2631s\n",
      "\titers: 800, epoch: 11 | loss: 0.0074142\n",
      "\tspeed: 0.0340s/iter; left time: 281.1463s\n",
      "\titers: 900, epoch: 11 | loss: 0.0059911\n",
      "\tspeed: 0.0340s/iter; left time: 277.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.02s\n",
      "Steps: 906 | Train Loss: 0.0064856 Vali Loss: 0.0105782 Test Loss: 0.0118934\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0053530\n",
      "\tspeed: 0.0928s/iter; left time: 747.8610s\n",
      "\titers: 200, epoch: 12 | loss: 0.0075861\n",
      "\tspeed: 0.0339s/iter; left time: 269.7478s\n",
      "\titers: 300, epoch: 12 | loss: 0.0055364\n",
      "\tspeed: 0.0340s/iter; left time: 267.1719s\n",
      "\titers: 400, epoch: 12 | loss: 0.0068468\n",
      "\tspeed: 0.0340s/iter; left time: 263.6226s\n",
      "\titers: 500, epoch: 12 | loss: 0.0076434\n",
      "\tspeed: 0.0340s/iter; left time: 260.0121s\n",
      "\titers: 600, epoch: 12 | loss: 0.0064606\n",
      "\tspeed: 0.0340s/iter; left time: 256.7812s\n",
      "\titers: 700, epoch: 12 | loss: 0.0058148\n",
      "\tspeed: 0.0340s/iter; left time: 253.6848s\n",
      "\titers: 800, epoch: 12 | loss: 0.0071375\n",
      "\tspeed: 0.0340s/iter; left time: 249.8700s\n",
      "\titers: 900, epoch: 12 | loss: 0.0060761\n",
      "\tspeed: 0.0340s/iter; left time: 246.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0061183 Vali Loss: 0.0104378 Test Loss: 0.0126510\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0053074\n",
      "\tspeed: 0.0930s/iter; left time: 664.6588s\n",
      "\titers: 200, epoch: 13 | loss: 0.0066337\n",
      "\tspeed: 0.0340s/iter; left time: 239.3422s\n",
      "\titers: 300, epoch: 13 | loss: 0.0057878\n",
      "\tspeed: 0.0340s/iter; left time: 236.0683s\n",
      "\titers: 400, epoch: 13 | loss: 0.0048156\n",
      "\tspeed: 0.0340s/iter; left time: 232.6297s\n",
      "\titers: 500, epoch: 13 | loss: 0.0046192\n",
      "\tspeed: 0.0339s/iter; left time: 229.1009s\n",
      "\titers: 600, epoch: 13 | loss: 0.0050266\n",
      "\tspeed: 0.0339s/iter; left time: 225.6425s\n",
      "\titers: 700, epoch: 13 | loss: 0.0063398\n",
      "\tspeed: 0.0340s/iter; left time: 222.6156s\n",
      "\titers: 800, epoch: 13 | loss: 0.0056544\n",
      "\tspeed: 0.0340s/iter; left time: 219.1683s\n",
      "\titers: 900, epoch: 13 | loss: 0.0062224\n",
      "\tspeed: 0.0340s/iter; left time: 215.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0058192 Vali Loss: 0.0104211 Test Loss: 0.0130738\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011139685288071632, rmse:0.10554470866918564, mae:0.06488028168678284, rse:0.3988608121871948\n",
      "Original data scale mse:1800234.625, rmse:1341.728271484375, mae:865.4649047851562, rse:0.09428640455007553\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0946719\n",
      "\tspeed: 0.0364s/iter; left time: 655.2500s\n",
      "\titers: 200, epoch: 1 | loss: 0.0929217\n",
      "\tspeed: 0.0339s/iter; left time: 608.1890s\n",
      "\titers: 300, epoch: 1 | loss: 0.0742790\n",
      "\tspeed: 0.0340s/iter; left time: 605.5886s\n",
      "\titers: 400, epoch: 1 | loss: 0.0651068\n",
      "\tspeed: 0.0340s/iter; left time: 601.9478s\n",
      "\titers: 500, epoch: 1 | loss: 0.0646000\n",
      "\tspeed: 0.0340s/iter; left time: 598.5111s\n",
      "\titers: 600, epoch: 1 | loss: 0.0608652\n",
      "\tspeed: 0.0339s/iter; left time: 594.3870s\n",
      "\titers: 700, epoch: 1 | loss: 0.0580129\n",
      "\tspeed: 0.0340s/iter; left time: 592.0174s\n",
      "\titers: 800, epoch: 1 | loss: 0.0489166\n",
      "\tspeed: 0.0339s/iter; left time: 587.4049s\n",
      "\titers: 900, epoch: 1 | loss: 0.0366947\n",
      "\tspeed: 0.0339s/iter; left time: 584.3648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0725760 Vali Loss: 0.0295805 Test Loss: 0.0328899\n",
      "Validation loss decreased (inf --> 0.029580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0274326\n",
      "\tspeed: 0.0966s/iter; left time: 1653.8839s\n",
      "\titers: 200, epoch: 2 | loss: 0.0216325\n",
      "\tspeed: 0.0340s/iter; left time: 578.6356s\n",
      "\titers: 300, epoch: 2 | loss: 0.0185726\n",
      "\tspeed: 0.0340s/iter; left time: 574.8628s\n",
      "\titers: 400, epoch: 2 | loss: 0.0210525\n",
      "\tspeed: 0.0340s/iter; left time: 571.3170s\n",
      "\titers: 500, epoch: 2 | loss: 0.0165901\n",
      "\tspeed: 0.0340s/iter; left time: 567.7598s\n",
      "\titers: 600, epoch: 2 | loss: 0.0174658\n",
      "\tspeed: 0.0340s/iter; left time: 565.3028s\n",
      "\titers: 700, epoch: 2 | loss: 0.0126684\n",
      "\tspeed: 0.0340s/iter; left time: 561.7988s\n",
      "\titers: 800, epoch: 2 | loss: 0.0152528\n",
      "\tspeed: 0.0340s/iter; left time: 558.3740s\n",
      "\titers: 900, epoch: 2 | loss: 0.0113291\n",
      "\tspeed: 0.0340s/iter; left time: 554.1465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0188265 Vali Loss: 0.0125718 Test Loss: 0.0131998\n",
      "Validation loss decreased (0.029580 --> 0.012572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0108299\n",
      "\tspeed: 0.0963s/iter; left time: 1560.2048s\n",
      "\titers: 200, epoch: 3 | loss: 0.0125845\n",
      "\tspeed: 0.0340s/iter; left time: 548.5016s\n",
      "\titers: 300, epoch: 3 | loss: 0.0093613\n",
      "\tspeed: 0.0340s/iter; left time: 544.3124s\n",
      "\titers: 400, epoch: 3 | loss: 0.0108911\n",
      "\tspeed: 0.0340s/iter; left time: 541.3197s\n",
      "\titers: 500, epoch: 3 | loss: 0.0121867\n",
      "\tspeed: 0.0340s/iter; left time: 538.0183s\n",
      "\titers: 600, epoch: 3 | loss: 0.0101375\n",
      "\tspeed: 0.0340s/iter; left time: 534.4255s\n",
      "\titers: 700, epoch: 3 | loss: 0.0091377\n",
      "\tspeed: 0.0341s/iter; left time: 531.6456s\n",
      "\titers: 800, epoch: 3 | loss: 0.0105136\n",
      "\tspeed: 0.0340s/iter; left time: 527.9341s\n",
      "\titers: 900, epoch: 3 | loss: 0.0100957\n",
      "\tspeed: 0.0340s/iter; left time: 524.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0121599 Vali Loss: 0.0116421 Test Loss: 0.0125670\n",
      "Validation loss decreased (0.012572 --> 0.011642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0097274\n",
      "\tspeed: 0.0957s/iter; left time: 1464.6991s\n",
      "\titers: 200, epoch: 4 | loss: 0.0092834\n",
      "\tspeed: 0.0340s/iter; left time: 517.2461s\n",
      "\titers: 300, epoch: 4 | loss: 0.0118909\n",
      "\tspeed: 0.0340s/iter; left time: 514.0601s\n",
      "\titers: 400, epoch: 4 | loss: 0.0108857\n",
      "\tspeed: 0.0340s/iter; left time: 510.2022s\n",
      "\titers: 500, epoch: 4 | loss: 0.0103518\n",
      "\tspeed: 0.0339s/iter; left time: 505.7799s\n",
      "\titers: 600, epoch: 4 | loss: 0.0116715\n",
      "\tspeed: 0.0340s/iter; left time: 502.6033s\n",
      "\titers: 700, epoch: 4 | loss: 0.0093000\n",
      "\tspeed: 0.0340s/iter; left time: 499.2699s\n",
      "\titers: 800, epoch: 4 | loss: 0.0107670\n",
      "\tspeed: 0.0339s/iter; left time: 495.5604s\n",
      "\titers: 900, epoch: 4 | loss: 0.0110103\n",
      "\tspeed: 0.0340s/iter; left time: 492.5112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0107405 Vali Loss: 0.0104148 Test Loss: 0.0119527\n",
      "Validation loss decreased (0.011642 --> 0.010415).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0099993\n",
      "\tspeed: 0.0961s/iter; left time: 1383.4842s\n",
      "\titers: 200, epoch: 5 | loss: 0.0106571\n",
      "\tspeed: 0.0339s/iter; left time: 484.7378s\n",
      "\titers: 300, epoch: 5 | loss: 0.0106437\n",
      "\tspeed: 0.0339s/iter; left time: 481.3551s\n",
      "\titers: 400, epoch: 5 | loss: 0.0118819\n",
      "\tspeed: 0.0339s/iter; left time: 478.5914s\n",
      "\titers: 500, epoch: 5 | loss: 0.0102038\n",
      "\tspeed: 0.0340s/iter; left time: 475.5587s\n",
      "\titers: 600, epoch: 5 | loss: 0.0104462\n",
      "\tspeed: 0.0340s/iter; left time: 471.9792s\n",
      "\titers: 700, epoch: 5 | loss: 0.0114743\n",
      "\tspeed: 0.0340s/iter; left time: 468.9569s\n",
      "\titers: 800, epoch: 5 | loss: 0.0108274\n",
      "\tspeed: 0.0340s/iter; left time: 465.6280s\n",
      "\titers: 900, epoch: 5 | loss: 0.0099661\n",
      "\tspeed: 0.0340s/iter; left time: 462.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0099865 Vali Loss: 0.0101851 Test Loss: 0.0121074\n",
      "Validation loss decreased (0.010415 --> 0.010185).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0106021\n",
      "\tspeed: 0.0955s/iter; left time: 1288.5754s\n",
      "\titers: 200, epoch: 6 | loss: 0.0106260\n",
      "\tspeed: 0.0340s/iter; left time: 455.1006s\n",
      "\titers: 300, epoch: 6 | loss: 0.0109733\n",
      "\tspeed: 0.0340s/iter; left time: 451.7967s\n",
      "\titers: 400, epoch: 6 | loss: 0.0133107\n",
      "\tspeed: 0.0340s/iter; left time: 448.7293s\n",
      "\titers: 500, epoch: 6 | loss: 0.0114055\n",
      "\tspeed: 0.0340s/iter; left time: 445.7267s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075874\n",
      "\tspeed: 0.0340s/iter; left time: 441.5994s\n",
      "\titers: 700, epoch: 6 | loss: 0.0097217\n",
      "\tspeed: 0.0340s/iter; left time: 438.6970s\n",
      "\titers: 800, epoch: 6 | loss: 0.0075483\n",
      "\tspeed: 0.0340s/iter; left time: 434.8378s\n",
      "\titers: 900, epoch: 6 | loss: 0.0069364\n",
      "\tspeed: 0.0340s/iter; left time: 431.5836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0092689 Vali Loss: 0.0105527 Test Loss: 0.0121766\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0099495\n",
      "\tspeed: 0.0938s/iter; left time: 1180.4143s\n",
      "\titers: 200, epoch: 7 | loss: 0.0088085\n",
      "\tspeed: 0.0341s/iter; left time: 426.2258s\n",
      "\titers: 300, epoch: 7 | loss: 0.0082324\n",
      "\tspeed: 0.0340s/iter; left time: 421.6041s\n",
      "\titers: 400, epoch: 7 | loss: 0.0098417\n",
      "\tspeed: 0.0340s/iter; left time: 418.1880s\n",
      "\titers: 500, epoch: 7 | loss: 0.0068528\n",
      "\tspeed: 0.0341s/iter; left time: 415.3217s\n",
      "\titers: 600, epoch: 7 | loss: 0.0073076\n",
      "\tspeed: 0.0340s/iter; left time: 411.3323s\n",
      "\titers: 700, epoch: 7 | loss: 0.0096363\n",
      "\tspeed: 0.0341s/iter; left time: 408.4615s\n",
      "\titers: 800, epoch: 7 | loss: 0.0079663\n",
      "\tspeed: 0.0340s/iter; left time: 403.6016s\n",
      "\titers: 900, epoch: 7 | loss: 0.0101435\n",
      "\tspeed: 0.0340s/iter; left time: 400.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0087563 Vali Loss: 0.0098878 Test Loss: 0.0116902\n",
      "Validation loss decreased (0.010185 --> 0.009888).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0083788\n",
      "\tspeed: 0.0967s/iter; left time: 1129.1874s\n",
      "\titers: 200, epoch: 8 | loss: 0.0093471\n",
      "\tspeed: 0.0339s/iter; left time: 392.9146s\n",
      "\titers: 300, epoch: 8 | loss: 0.0077939\n",
      "\tspeed: 0.0340s/iter; left time: 389.8273s\n",
      "\titers: 400, epoch: 8 | loss: 0.0077422\n",
      "\tspeed: 0.0339s/iter; left time: 386.2956s\n",
      "\titers: 500, epoch: 8 | loss: 0.0079480\n",
      "\tspeed: 0.0340s/iter; left time: 383.4038s\n",
      "\titers: 600, epoch: 8 | loss: 0.0111170\n",
      "\tspeed: 0.0340s/iter; left time: 379.6807s\n",
      "\titers: 700, epoch: 8 | loss: 0.0080697\n",
      "\tspeed: 0.0339s/iter; left time: 375.7415s\n",
      "\titers: 800, epoch: 8 | loss: 0.0100588\n",
      "\tspeed: 0.0339s/iter; left time: 372.6925s\n",
      "\titers: 900, epoch: 8 | loss: 0.0087991\n",
      "\tspeed: 0.0340s/iter; left time: 369.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0081583 Vali Loss: 0.0097605 Test Loss: 0.0114968\n",
      "Validation loss decreased (0.009888 --> 0.009760).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0079887\n",
      "\tspeed: 0.0968s/iter; left time: 1042.5671s\n",
      "\titers: 200, epoch: 9 | loss: 0.0076844\n",
      "\tspeed: 0.0340s/iter; left time: 362.9627s\n",
      "\titers: 300, epoch: 9 | loss: 0.0073041\n",
      "\tspeed: 0.0340s/iter; left time: 359.6542s\n",
      "\titers: 400, epoch: 9 | loss: 0.0070676\n",
      "\tspeed: 0.0340s/iter; left time: 356.5332s\n",
      "\titers: 500, epoch: 9 | loss: 0.0085628\n",
      "\tspeed: 0.0340s/iter; left time: 352.6650s\n",
      "\titers: 600, epoch: 9 | loss: 0.0063866\n",
      "\tspeed: 0.0340s/iter; left time: 349.4597s\n",
      "\titers: 700, epoch: 9 | loss: 0.0070996\n",
      "\tspeed: 0.0340s/iter; left time: 345.8963s\n",
      "\titers: 800, epoch: 9 | loss: 0.0083093\n",
      "\tspeed: 0.0340s/iter; left time: 342.8567s\n",
      "\titers: 900, epoch: 9 | loss: 0.0069805\n",
      "\tspeed: 0.0340s/iter; left time: 339.0049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0076499 Vali Loss: 0.0097633 Test Loss: 0.0117772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0060302\n",
      "\tspeed: 0.0937s/iter; left time: 924.0546s\n",
      "\titers: 200, epoch: 10 | loss: 0.0093350\n",
      "\tspeed: 0.0340s/iter; left time: 331.6450s\n",
      "\titers: 300, epoch: 10 | loss: 0.0070846\n",
      "\tspeed: 0.0339s/iter; left time: 327.8166s\n",
      "\titers: 400, epoch: 10 | loss: 0.0069731\n",
      "\tspeed: 0.0340s/iter; left time: 324.8613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0060187\n",
      "\tspeed: 0.0340s/iter; left time: 321.5116s\n",
      "\titers: 600, epoch: 10 | loss: 0.0069155\n",
      "\tspeed: 0.0339s/iter; left time: 317.4491s\n",
      "\titers: 700, epoch: 10 | loss: 0.0081655\n",
      "\tspeed: 0.0340s/iter; left time: 315.0145s\n",
      "\titers: 800, epoch: 10 | loss: 0.0055532\n",
      "\tspeed: 0.0340s/iter; left time: 311.4031s\n",
      "\titers: 900, epoch: 10 | loss: 0.0065675\n",
      "\tspeed: 0.0339s/iter; left time: 307.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.02s\n",
      "Steps: 906 | Train Loss: 0.0071673 Vali Loss: 0.0101122 Test Loss: 0.0121082\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0066794\n",
      "\tspeed: 0.0930s/iter; left time: 833.4363s\n",
      "\titers: 200, epoch: 11 | loss: 0.0056569\n",
      "\tspeed: 0.0340s/iter; left time: 301.0403s\n",
      "\titers: 300, epoch: 11 | loss: 0.0075528\n",
      "\tspeed: 0.0339s/iter; left time: 297.2453s\n",
      "\titers: 400, epoch: 11 | loss: 0.0063265\n",
      "\tspeed: 0.0340s/iter; left time: 294.1769s\n",
      "\titers: 500, epoch: 11 | loss: 0.0058926\n",
      "\tspeed: 0.0340s/iter; left time: 290.9720s\n",
      "\titers: 600, epoch: 11 | loss: 0.0044438\n",
      "\tspeed: 0.0340s/iter; left time: 287.7091s\n",
      "\titers: 700, epoch: 11 | loss: 0.0066303\n",
      "\tspeed: 0.0340s/iter; left time: 284.2641s\n",
      "\titers: 800, epoch: 11 | loss: 0.0057136\n",
      "\tspeed: 0.0340s/iter; left time: 280.8560s\n",
      "\titers: 900, epoch: 11 | loss: 0.0089892\n",
      "\tspeed: 0.0344s/iter; left time: 281.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0067194 Vali Loss: 0.0100680 Test Loss: 0.0121831\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0066273\n",
      "\tspeed: 0.1040s/iter; left time: 837.6305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0053922\n",
      "\tspeed: 0.0365s/iter; left time: 290.6183s\n",
      "\titers: 300, epoch: 12 | loss: 0.0060718\n",
      "\tspeed: 0.0359s/iter; left time: 281.6058s\n",
      "\titers: 400, epoch: 12 | loss: 0.0073088\n",
      "\tspeed: 0.0355s/iter; left time: 275.2680s\n",
      "\titers: 500, epoch: 12 | loss: 0.0073975\n",
      "\tspeed: 0.0360s/iter; left time: 275.2791s\n",
      "\titers: 600, epoch: 12 | loss: 0.0072382\n",
      "\tspeed: 0.0355s/iter; left time: 268.5791s\n",
      "\titers: 700, epoch: 12 | loss: 0.0062839\n",
      "\tspeed: 0.0359s/iter; left time: 267.5799s\n",
      "\titers: 800, epoch: 12 | loss: 0.0054433\n",
      "\tspeed: 0.0355s/iter; left time: 261.2184s\n",
      "\titers: 900, epoch: 12 | loss: 0.0057036\n",
      "\tspeed: 0.0363s/iter; left time: 263.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:33.06s\n",
      "Steps: 906 | Train Loss: 0.0063486 Vali Loss: 0.0103845 Test Loss: 0.0123336\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0073871\n",
      "\tspeed: 0.1099s/iter; left time: 785.9836s\n",
      "\titers: 200, epoch: 13 | loss: 0.0051247\n",
      "\tspeed: 0.0444s/iter; left time: 313.1598s\n",
      "\titers: 300, epoch: 13 | loss: 0.0053725\n",
      "\tspeed: 0.0355s/iter; left time: 246.4561s\n",
      "\titers: 400, epoch: 13 | loss: 0.0055240\n",
      "\tspeed: 0.0347s/iter; left time: 237.6544s\n",
      "\titers: 500, epoch: 13 | loss: 0.0064759\n",
      "\tspeed: 0.0345s/iter; left time: 233.1055s\n",
      "\titers: 600, epoch: 13 | loss: 0.0065577\n",
      "\tspeed: 0.0343s/iter; left time: 228.1991s\n",
      "\titers: 700, epoch: 13 | loss: 0.0059091\n",
      "\tspeed: 0.0343s/iter; left time: 224.5556s\n",
      "\titers: 800, epoch: 13 | loss: 0.0059391\n",
      "\tspeed: 0.0342s/iter; left time: 220.6454s\n",
      "\titers: 900, epoch: 13 | loss: 0.0051179\n",
      "\tspeed: 0.0341s/iter; left time: 216.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:33.77s\n",
      "Steps: 906 | Train Loss: 0.0059923 Vali Loss: 0.0098415 Test Loss: 0.0122717\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011506819166243076, rmse:0.10726984590291977, mae:0.06715415418148041, rse:0.4053802192211151\n",
      "Original data scale mse:1954150.75, rmse:1397.909423828125, mae:902.05517578125, rse:0.0982343927025795\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1049265\n",
      "\tspeed: 0.0607s/iter; left time: 1092.1872s\n",
      "\titers: 200, epoch: 1 | loss: 0.0846940\n",
      "\tspeed: 0.0415s/iter; left time: 741.6410s\n",
      "\titers: 300, epoch: 1 | loss: 0.0775601\n",
      "\tspeed: 0.0415s/iter; left time: 737.2690s\n",
      "\titers: 400, epoch: 1 | loss: 0.0718062\n",
      "\tspeed: 0.0414s/iter; left time: 732.8635s\n",
      "\titers: 500, epoch: 1 | loss: 0.0738738\n",
      "\tspeed: 0.0414s/iter; left time: 728.2129s\n",
      "\titers: 600, epoch: 1 | loss: 0.0635841\n",
      "\tspeed: 0.0414s/iter; left time: 724.2041s\n",
      "\titers: 700, epoch: 1 | loss: 0.0610177\n",
      "\tspeed: 0.0414s/iter; left time: 720.0709s\n",
      "\titers: 800, epoch: 1 | loss: 0.0556312\n",
      "\tspeed: 0.0414s/iter; left time: 715.6822s\n",
      "\titers: 900, epoch: 1 | loss: 0.0562442\n",
      "\tspeed: 0.0414s/iter; left time: 711.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 904 | Train Loss: 0.0766098 Vali Loss: 0.0418758 Test Loss: 0.0485719\n",
      "Validation loss decreased (inf --> 0.041876).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0419440\n",
      "\tspeed: 0.1174s/iter; left time: 2004.7477s\n",
      "\titers: 200, epoch: 2 | loss: 0.0319205\n",
      "\tspeed: 0.0424s/iter; left time: 719.3124s\n",
      "\titers: 300, epoch: 2 | loss: 0.0304332\n",
      "\tspeed: 0.0532s/iter; left time: 898.2974s\n",
      "\titers: 400, epoch: 2 | loss: 0.0277296\n",
      "\tspeed: 0.0564s/iter; left time: 946.2585s\n",
      "\titers: 500, epoch: 2 | loss: 0.0251713\n",
      "\tspeed: 0.0595s/iter; left time: 991.6578s\n",
      "\titers: 600, epoch: 2 | loss: 0.0220603\n",
      "\tspeed: 0.0540s/iter; left time: 895.2998s\n",
      "\titers: 700, epoch: 2 | loss: 0.0232078\n",
      "\tspeed: 0.0527s/iter; left time: 869.0406s\n",
      "\titers: 800, epoch: 2 | loss: 0.0204120\n",
      "\tspeed: 0.0527s/iter; left time: 862.9570s\n",
      "\titers: 900, epoch: 2 | loss: 0.0191393\n",
      "\tspeed: 0.0527s/iter; left time: 857.5374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 904 | Train Loss: 0.0283085 Vali Loss: 0.0188907 Test Loss: 0.0211461\n",
      "Validation loss decreased (0.041876 --> 0.018891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0187438\n",
      "\tspeed: 0.1674s/iter; left time: 2707.0198s\n",
      "\titers: 200, epoch: 3 | loss: 0.0197342\n",
      "\tspeed: 0.0533s/iter; left time: 856.1275s\n",
      "\titers: 300, epoch: 3 | loss: 0.0203294\n",
      "\tspeed: 0.0539s/iter; left time: 860.3920s\n",
      "\titers: 400, epoch: 3 | loss: 0.0184877\n",
      "\tspeed: 0.0527s/iter; left time: 837.2661s\n",
      "\titers: 500, epoch: 3 | loss: 0.0159188\n",
      "\tspeed: 0.0532s/iter; left time: 838.7748s\n",
      "\titers: 600, epoch: 3 | loss: 0.0180105\n",
      "\tspeed: 0.0529s/iter; left time: 828.9039s\n",
      "\titers: 700, epoch: 3 | loss: 0.0156782\n",
      "\tspeed: 0.0528s/iter; left time: 822.8708s\n",
      "\titers: 800, epoch: 3 | loss: 0.0193025\n",
      "\tspeed: 0.0529s/iter; left time: 819.1714s\n",
      "\titers: 900, epoch: 3 | loss: 0.0151986\n",
      "\tspeed: 0.0531s/iter; left time: 815.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 904 | Train Loss: 0.0183987 Vali Loss: 0.0166293 Test Loss: 0.0188253\n",
      "Validation loss decreased (0.018891 --> 0.016629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0159682\n",
      "\tspeed: 0.1674s/iter; left time: 2555.8749s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178815\n",
      "\tspeed: 0.0534s/iter; left time: 809.7267s\n",
      "\titers: 300, epoch: 4 | loss: 0.0170291\n",
      "\tspeed: 0.0533s/iter; left time: 803.3239s\n",
      "\titers: 400, epoch: 4 | loss: 0.0162365\n",
      "\tspeed: 0.0556s/iter; left time: 832.3580s\n",
      "\titers: 500, epoch: 4 | loss: 0.0143917\n",
      "\tspeed: 0.0540s/iter; left time: 803.4717s\n",
      "\titers: 600, epoch: 4 | loss: 0.0142564\n",
      "\tspeed: 0.0529s/iter; left time: 781.9514s\n",
      "\titers: 700, epoch: 4 | loss: 0.0178271\n",
      "\tspeed: 0.0532s/iter; left time: 780.2451s\n",
      "\titers: 800, epoch: 4 | loss: 0.0143080\n",
      "\tspeed: 0.0539s/iter; left time: 785.2239s\n",
      "\titers: 900, epoch: 4 | loss: 0.0154388\n",
      "\tspeed: 0.0535s/iter; left time: 773.4466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.19s\n",
      "Steps: 904 | Train Loss: 0.0166150 Vali Loss: 0.0166704 Test Loss: 0.0182467\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0165838\n",
      "\tspeed: 0.1648s/iter; left time: 2367.6710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0141575\n",
      "\tspeed: 0.0526s/iter; left time: 750.2102s\n",
      "\titers: 300, epoch: 5 | loss: 0.0159495\n",
      "\tspeed: 0.0533s/iter; left time: 755.4581s\n",
      "\titers: 400, epoch: 5 | loss: 0.0164002\n",
      "\tspeed: 0.0533s/iter; left time: 748.9939s\n",
      "\titers: 500, epoch: 5 | loss: 0.0142062\n",
      "\tspeed: 0.0531s/iter; left time: 741.9294s\n",
      "\titers: 600, epoch: 5 | loss: 0.0154078\n",
      "\tspeed: 0.0539s/iter; left time: 747.3516s\n",
      "\titers: 700, epoch: 5 | loss: 0.0143207\n",
      "\tspeed: 0.0532s/iter; left time: 732.2056s\n",
      "\titers: 800, epoch: 5 | loss: 0.0149392\n",
      "\tspeed: 0.0531s/iter; left time: 725.5975s\n",
      "\titers: 900, epoch: 5 | loss: 0.0159033\n",
      "\tspeed: 0.0530s/iter; left time: 718.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.00s\n",
      "Steps: 904 | Train Loss: 0.0152258 Vali Loss: 0.0165378 Test Loss: 0.0194802\n",
      "Validation loss decreased (0.016629 --> 0.016538).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0166436\n",
      "\tspeed: 0.1697s/iter; left time: 2284.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0146428\n",
      "\tspeed: 0.0544s/iter; left time: 726.9341s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157662\n",
      "\tspeed: 0.0543s/iter; left time: 719.9059s\n",
      "\titers: 400, epoch: 6 | loss: 0.0138133\n",
      "\tspeed: 0.0535s/iter; left time: 704.2182s\n",
      "\titers: 500, epoch: 6 | loss: 0.0142254\n",
      "\tspeed: 0.0536s/iter; left time: 700.0674s\n",
      "\titers: 600, epoch: 6 | loss: 0.0132052\n",
      "\tspeed: 0.0535s/iter; left time: 693.3678s\n",
      "\titers: 700, epoch: 6 | loss: 0.0143211\n",
      "\tspeed: 0.0534s/iter; left time: 686.8834s\n",
      "\titers: 800, epoch: 6 | loss: 0.0126709\n",
      "\tspeed: 0.0529s/iter; left time: 674.8693s\n",
      "\titers: 900, epoch: 6 | loss: 0.0125704\n",
      "\tspeed: 0.0532s/iter; left time: 673.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.30s\n",
      "Steps: 904 | Train Loss: 0.0140307 Vali Loss: 0.0180145 Test Loss: 0.0204602\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0126386\n",
      "\tspeed: 0.1683s/iter; left time: 2113.4941s\n",
      "\titers: 200, epoch: 7 | loss: 0.0133538\n",
      "\tspeed: 0.0540s/iter; left time: 672.5232s\n",
      "\titers: 300, epoch: 7 | loss: 0.0133844\n",
      "\tspeed: 0.0546s/iter; left time: 675.1542s\n",
      "\titers: 400, epoch: 7 | loss: 0.0124519\n",
      "\tspeed: 0.0547s/iter; left time: 670.7335s\n",
      "\titers: 500, epoch: 7 | loss: 0.0129995\n",
      "\tspeed: 0.0521s/iter; left time: 633.1811s\n",
      "\titers: 600, epoch: 7 | loss: 0.0107722\n",
      "\tspeed: 0.0464s/iter; left time: 559.8365s\n",
      "\titers: 700, epoch: 7 | loss: 0.0119335\n",
      "\tspeed: 0.0447s/iter; left time: 534.0714s\n",
      "\titers: 800, epoch: 7 | loss: 0.0103852\n",
      "\tspeed: 0.0450s/iter; left time: 533.7265s\n",
      "\titers: 900, epoch: 7 | loss: 0.0142198\n",
      "\tspeed: 0.0447s/iter; left time: 525.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.23s\n",
      "Steps: 904 | Train Loss: 0.0128629 Vali Loss: 0.0177987 Test Loss: 0.0203428\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0135118\n",
      "\tspeed: 0.1235s/iter; left time: 1439.4967s\n",
      "\titers: 200, epoch: 8 | loss: 0.0121883\n",
      "\tspeed: 0.0431s/iter; left time: 497.4859s\n",
      "\titers: 300, epoch: 8 | loss: 0.0131335\n",
      "\tspeed: 0.0430s/iter; left time: 492.6867s\n",
      "\titers: 400, epoch: 8 | loss: 0.0103409\n",
      "\tspeed: 0.0430s/iter; left time: 488.4876s\n",
      "\titers: 500, epoch: 8 | loss: 0.0116575\n",
      "\tspeed: 0.0431s/iter; left time: 484.5180s\n",
      "\titers: 600, epoch: 8 | loss: 0.0120145\n",
      "\tspeed: 0.0430s/iter; left time: 479.7410s\n",
      "\titers: 700, epoch: 8 | loss: 0.0120938\n",
      "\tspeed: 0.0431s/iter; left time: 475.8528s\n",
      "\titers: 800, epoch: 8 | loss: 0.0120940\n",
      "\tspeed: 0.0440s/iter; left time: 481.8987s\n",
      "\titers: 900, epoch: 8 | loss: 0.0107168\n",
      "\tspeed: 0.0439s/iter; left time: 476.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 904 | Train Loss: 0.0118077 Vali Loss: 0.0179464 Test Loss: 0.0215799\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0109323\n",
      "\tspeed: 0.1226s/iter; left time: 1317.6650s\n",
      "\titers: 200, epoch: 9 | loss: 0.0112944\n",
      "\tspeed: 0.0434s/iter; left time: 461.7670s\n",
      "\titers: 300, epoch: 9 | loss: 0.0106901\n",
      "\tspeed: 0.0435s/iter; left time: 458.5771s\n",
      "\titers: 400, epoch: 9 | loss: 0.0096885\n",
      "\tspeed: 0.0433s/iter; left time: 452.8120s\n",
      "\titers: 500, epoch: 9 | loss: 0.0116936\n",
      "\tspeed: 0.0432s/iter; left time: 447.2979s\n",
      "\titers: 600, epoch: 9 | loss: 0.0094251\n",
      "\tspeed: 0.0433s/iter; left time: 443.2965s\n",
      "\titers: 700, epoch: 9 | loss: 0.0082147\n",
      "\tspeed: 0.0432s/iter; left time: 438.8344s\n",
      "\titers: 800, epoch: 9 | loss: 0.0106462\n",
      "\tspeed: 0.0433s/iter; left time: 435.0709s\n",
      "\titers: 900, epoch: 9 | loss: 0.0098766\n",
      "\tspeed: 0.0434s/iter; left time: 431.8735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.53s\n",
      "Steps: 904 | Train Loss: 0.0107340 Vali Loss: 0.0186820 Test Loss: 0.0224837\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0115943\n",
      "\tspeed: 0.1215s/iter; left time: 1196.5460s\n",
      "\titers: 200, epoch: 10 | loss: 0.0096779\n",
      "\tspeed: 0.0431s/iter; left time: 420.3857s\n",
      "\titers: 300, epoch: 10 | loss: 0.0088626\n",
      "\tspeed: 0.0432s/iter; left time: 416.3585s\n",
      "\titers: 400, epoch: 10 | loss: 0.0084990\n",
      "\tspeed: 0.0433s/iter; left time: 412.8813s\n",
      "\titers: 500, epoch: 10 | loss: 0.0103513\n",
      "\tspeed: 0.0432s/iter; left time: 408.2939s\n",
      "\titers: 600, epoch: 10 | loss: 0.0088736\n",
      "\tspeed: 0.0429s/iter; left time: 400.8461s\n",
      "\titers: 700, epoch: 10 | loss: 0.0096829\n",
      "\tspeed: 0.0424s/iter; left time: 391.7970s\n",
      "\titers: 800, epoch: 10 | loss: 0.0093004\n",
      "\tspeed: 0.0422s/iter; left time: 386.0505s\n",
      "\titers: 900, epoch: 10 | loss: 0.0105206\n",
      "\tspeed: 0.0420s/iter; left time: 380.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.07s\n",
      "Steps: 904 | Train Loss: 0.0097450 Vali Loss: 0.0187195 Test Loss: 0.0226919\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019469980150461197, rmse:0.1395348757505417, mae:0.0925842821598053, rse:0.5275964140892029\n",
      "Original data scale mse:4252090.5, rmse:2062.059814453125, mae:1342.6978759765625, rse:0.14511555433273315\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1188145\n",
      "\tspeed: 0.0447s/iter; left time: 804.3235s\n",
      "\titers: 200, epoch: 1 | loss: 0.0895602\n",
      "\tspeed: 0.0419s/iter; left time: 749.0011s\n",
      "\titers: 300, epoch: 1 | loss: 0.0841904\n",
      "\tspeed: 0.0418s/iter; left time: 743.0178s\n",
      "\titers: 400, epoch: 1 | loss: 0.0788894\n",
      "\tspeed: 0.0418s/iter; left time: 739.1143s\n",
      "\titers: 500, epoch: 1 | loss: 0.0712075\n",
      "\tspeed: 0.0418s/iter; left time: 735.0515s\n",
      "\titers: 600, epoch: 1 | loss: 0.0662194\n",
      "\tspeed: 0.0418s/iter; left time: 730.4560s\n",
      "\titers: 700, epoch: 1 | loss: 0.0625979\n",
      "\tspeed: 0.0418s/iter; left time: 726.6581s\n",
      "\titers: 800, epoch: 1 | loss: 0.0646832\n",
      "\tspeed: 0.0418s/iter; left time: 721.6061s\n",
      "\titers: 900, epoch: 1 | loss: 0.0580059\n",
      "\tspeed: 0.0418s/iter; left time: 717.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 904 | Train Loss: 0.0848243 Vali Loss: 0.0437767 Test Loss: 0.0507185\n",
      "Validation loss decreased (inf --> 0.043777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0419231\n",
      "\tspeed: 0.1185s/iter; left time: 2022.8678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0348182\n",
      "\tspeed: 0.0418s/iter; left time: 709.6629s\n",
      "\titers: 300, epoch: 2 | loss: 0.0337430\n",
      "\tspeed: 0.0418s/iter; left time: 704.6591s\n",
      "\titers: 400, epoch: 2 | loss: 0.0276726\n",
      "\tspeed: 0.0418s/iter; left time: 700.9713s\n",
      "\titers: 500, epoch: 2 | loss: 0.0261824\n",
      "\tspeed: 0.0418s/iter; left time: 696.3883s\n",
      "\titers: 600, epoch: 2 | loss: 0.0223262\n",
      "\tspeed: 0.0417s/iter; left time: 691.9626s\n",
      "\titers: 700, epoch: 2 | loss: 0.0221144\n",
      "\tspeed: 0.0417s/iter; left time: 687.3417s\n",
      "\titers: 800, epoch: 2 | loss: 0.0235434\n",
      "\tspeed: 0.0417s/iter; left time: 683.5103s\n",
      "\titers: 900, epoch: 2 | loss: 0.0199030\n",
      "\tspeed: 0.0417s/iter; left time: 679.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 904 | Train Loss: 0.0300192 Vali Loss: 0.0186070 Test Loss: 0.0201987\n",
      "Validation loss decreased (0.043777 --> 0.018607).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0220435\n",
      "\tspeed: 0.1204s/iter; left time: 1946.8453s\n",
      "\titers: 200, epoch: 3 | loss: 0.0185804\n",
      "\tspeed: 0.0416s/iter; left time: 668.5496s\n",
      "\titers: 300, epoch: 3 | loss: 0.0224635\n",
      "\tspeed: 0.0416s/iter; left time: 665.1535s\n",
      "\titers: 400, epoch: 3 | loss: 0.0182236\n",
      "\tspeed: 0.0416s/iter; left time: 660.3865s\n",
      "\titers: 500, epoch: 3 | loss: 0.0184334\n",
      "\tspeed: 0.0416s/iter; left time: 656.7100s\n",
      "\titers: 600, epoch: 3 | loss: 0.0173897\n",
      "\tspeed: 0.0416s/iter; left time: 652.5666s\n",
      "\titers: 700, epoch: 3 | loss: 0.0187687\n",
      "\tspeed: 0.0416s/iter; left time: 648.0779s\n",
      "\titers: 800, epoch: 3 | loss: 0.0163097\n",
      "\tspeed: 0.0416s/iter; left time: 643.3917s\n",
      "\titers: 900, epoch: 3 | loss: 0.0201210\n",
      "\tspeed: 0.0416s/iter; left time: 639.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0187056 Vali Loss: 0.0173176 Test Loss: 0.0189823\n",
      "Validation loss decreased (0.018607 --> 0.017318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0144917\n",
      "\tspeed: 0.1180s/iter; left time: 1801.6745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0155436\n",
      "\tspeed: 0.0415s/iter; left time: 630.2428s\n",
      "\titers: 300, epoch: 4 | loss: 0.0161402\n",
      "\tspeed: 0.0415s/iter; left time: 626.0061s\n",
      "\titers: 400, epoch: 4 | loss: 0.0169928\n",
      "\tspeed: 0.0415s/iter; left time: 621.7141s\n",
      "\titers: 500, epoch: 4 | loss: 0.0170970\n",
      "\tspeed: 0.0416s/iter; left time: 618.2207s\n",
      "\titers: 600, epoch: 4 | loss: 0.0154074\n",
      "\tspeed: 0.0415s/iter; left time: 613.6160s\n",
      "\titers: 700, epoch: 4 | loss: 0.0159156\n",
      "\tspeed: 0.0416s/iter; left time: 609.6295s\n",
      "\titers: 800, epoch: 4 | loss: 0.0133574\n",
      "\tspeed: 0.0416s/iter; left time: 605.4293s\n",
      "\titers: 900, epoch: 4 | loss: 0.0152945\n",
      "\tspeed: 0.0416s/iter; left time: 601.7694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0167078 Vali Loss: 0.0166588 Test Loss: 0.0186600\n",
      "Validation loss decreased (0.017318 --> 0.016659).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0153981\n",
      "\tspeed: 0.1183s/iter; left time: 1699.1464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0178646\n",
      "\tspeed: 0.0415s/iter; left time: 592.6832s\n",
      "\titers: 300, epoch: 5 | loss: 0.0161108\n",
      "\tspeed: 0.0416s/iter; left time: 588.6116s\n",
      "\titers: 400, epoch: 5 | loss: 0.0161433\n",
      "\tspeed: 0.0416s/iter; left time: 585.3525s\n",
      "\titers: 500, epoch: 5 | loss: 0.0140053\n",
      "\tspeed: 0.0416s/iter; left time: 580.6463s\n",
      "\titers: 600, epoch: 5 | loss: 0.0154303\n",
      "\tspeed: 0.0416s/iter; left time: 576.9176s\n",
      "\titers: 700, epoch: 5 | loss: 0.0164928\n",
      "\tspeed: 0.0416s/iter; left time: 572.4771s\n",
      "\titers: 800, epoch: 5 | loss: 0.0140502\n",
      "\tspeed: 0.0416s/iter; left time: 568.0646s\n",
      "\titers: 900, epoch: 5 | loss: 0.0171279\n",
      "\tspeed: 0.0416s/iter; left time: 564.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0154135 Vali Loss: 0.0172233 Test Loss: 0.0202088\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0115788\n",
      "\tspeed: 0.1155s/iter; left time: 1555.1758s\n",
      "\titers: 200, epoch: 6 | loss: 0.0148507\n",
      "\tspeed: 0.0416s/iter; left time: 555.7257s\n",
      "\titers: 300, epoch: 6 | loss: 0.0161882\n",
      "\tspeed: 0.0416s/iter; left time: 551.6425s\n",
      "\titers: 400, epoch: 6 | loss: 0.0178210\n",
      "\tspeed: 0.0416s/iter; left time: 546.9586s\n",
      "\titers: 500, epoch: 6 | loss: 0.0141026\n",
      "\tspeed: 0.0416s/iter; left time: 542.7646s\n",
      "\titers: 600, epoch: 6 | loss: 0.0153834\n",
      "\tspeed: 0.0415s/iter; left time: 538.4952s\n",
      "\titers: 700, epoch: 6 | loss: 0.0159608\n",
      "\tspeed: 0.0415s/iter; left time: 534.1593s\n",
      "\titers: 800, epoch: 6 | loss: 0.0149545\n",
      "\tspeed: 0.0416s/iter; left time: 530.5532s\n",
      "\titers: 900, epoch: 6 | loss: 0.0159737\n",
      "\tspeed: 0.0416s/iter; left time: 526.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0141988 Vali Loss: 0.0176414 Test Loss: 0.0199413\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0107467\n",
      "\tspeed: 0.1155s/iter; left time: 1450.3939s\n",
      "\titers: 200, epoch: 7 | loss: 0.0162226\n",
      "\tspeed: 0.0417s/iter; left time: 518.9944s\n",
      "\titers: 300, epoch: 7 | loss: 0.0132818\n",
      "\tspeed: 0.0416s/iter; left time: 514.4507s\n",
      "\titers: 400, epoch: 7 | loss: 0.0117365\n",
      "\tspeed: 0.0416s/iter; left time: 509.7889s\n",
      "\titers: 500, epoch: 7 | loss: 0.0134289\n",
      "\tspeed: 0.0416s/iter; left time: 505.7472s\n",
      "\titers: 600, epoch: 7 | loss: 0.0136149\n",
      "\tspeed: 0.0416s/iter; left time: 501.9396s\n",
      "\titers: 700, epoch: 7 | loss: 0.0113703\n",
      "\tspeed: 0.0416s/iter; left time: 497.6530s\n",
      "\titers: 800, epoch: 7 | loss: 0.0135708\n",
      "\tspeed: 0.0417s/iter; left time: 494.2570s\n",
      "\titers: 900, epoch: 7 | loss: 0.0130386\n",
      "\tspeed: 0.0416s/iter; left time: 489.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 904 | Train Loss: 0.0132573 Vali Loss: 0.0190168 Test Loss: 0.0217226\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0109275\n",
      "\tspeed: 0.1148s/iter; left time: 1337.9031s\n",
      "\titers: 200, epoch: 8 | loss: 0.0107192\n",
      "\tspeed: 0.0416s/iter; left time: 481.0936s\n",
      "\titers: 300, epoch: 8 | loss: 0.0152382\n",
      "\tspeed: 0.0416s/iter; left time: 476.9342s\n",
      "\titers: 400, epoch: 8 | loss: 0.0101954\n",
      "\tspeed: 0.0416s/iter; left time: 472.7591s\n",
      "\titers: 500, epoch: 8 | loss: 0.0121182\n",
      "\tspeed: 0.0417s/iter; left time: 469.0132s\n",
      "\titers: 600, epoch: 8 | loss: 0.0124160\n",
      "\tspeed: 0.0417s/iter; left time: 465.0637s\n",
      "\titers: 700, epoch: 8 | loss: 0.0121680\n",
      "\tspeed: 0.0417s/iter; left time: 460.6849s\n",
      "\titers: 800, epoch: 8 | loss: 0.0120201\n",
      "\tspeed: 0.0417s/iter; left time: 456.8240s\n",
      "\titers: 900, epoch: 8 | loss: 0.0105643\n",
      "\tspeed: 0.0417s/iter; left time: 452.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0120862 Vali Loss: 0.0178637 Test Loss: 0.0204340\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0107147\n",
      "\tspeed: 0.1151s/iter; left time: 1236.8307s\n",
      "\titers: 200, epoch: 9 | loss: 0.0107479\n",
      "\tspeed: 0.0417s/iter; left time: 444.0111s\n",
      "\titers: 300, epoch: 9 | loss: 0.0091522\n",
      "\tspeed: 0.0417s/iter; left time: 439.7855s\n",
      "\titers: 400, epoch: 9 | loss: 0.0114802\n",
      "\tspeed: 0.0417s/iter; left time: 435.5504s\n",
      "\titers: 500, epoch: 9 | loss: 0.0108412\n",
      "\tspeed: 0.0417s/iter; left time: 431.8752s\n",
      "\titers: 600, epoch: 9 | loss: 0.0123784\n",
      "\tspeed: 0.0416s/iter; left time: 426.5394s\n",
      "\titers: 700, epoch: 9 | loss: 0.0099401\n",
      "\tspeed: 0.0416s/iter; left time: 422.1139s\n",
      "\titers: 800, epoch: 9 | loss: 0.0091135\n",
      "\tspeed: 0.0415s/iter; left time: 417.1378s\n",
      "\titers: 900, epoch: 9 | loss: 0.0097398\n",
      "\tspeed: 0.0415s/iter; left time: 413.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0110619 Vali Loss: 0.0181419 Test Loss: 0.0215314\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01865767501294613, rmse:0.13659310340881348, mae:0.09037815779447556, rse:0.5164732336997986\n",
      "Original data scale mse:3400539.25, rmse:1844.0550537109375, mae:1237.254150390625, rse:0.12977369129657745\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1085400\n",
      "\tspeed: 0.0697s/iter; left time: 1250.9350s\n",
      "\titers: 200, epoch: 1 | loss: 0.0816883\n",
      "\tspeed: 0.0505s/iter; left time: 900.3890s\n",
      "\titers: 300, epoch: 1 | loss: 0.0842634\n",
      "\tspeed: 0.0504s/iter; left time: 894.5641s\n",
      "\titers: 400, epoch: 1 | loss: 0.0737756\n",
      "\tspeed: 0.0504s/iter; left time: 889.7256s\n",
      "\titers: 500, epoch: 1 | loss: 0.0733426\n",
      "\tspeed: 0.0505s/iter; left time: 885.9905s\n",
      "\titers: 600, epoch: 1 | loss: 0.0697691\n",
      "\tspeed: 0.0504s/iter; left time: 879.2263s\n",
      "\titers: 700, epoch: 1 | loss: 0.0659135\n",
      "\tspeed: 0.0504s/iter; left time: 874.5820s\n",
      "\titers: 800, epoch: 1 | loss: 0.0656875\n",
      "\tspeed: 0.0505s/iter; left time: 870.3694s\n",
      "\titers: 900, epoch: 1 | loss: 0.0628677\n",
      "\tspeed: 0.0504s/iter; left time: 863.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 902 | Train Loss: 0.0788118 Vali Loss: 0.0499987 Test Loss: 0.0585373\n",
      "Validation loss decreased (inf --> 0.049999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0473542\n",
      "\tspeed: 0.1406s/iter; left time: 2394.9686s\n",
      "\titers: 200, epoch: 2 | loss: 0.0424444\n",
      "\tspeed: 0.0504s/iter; left time: 853.5207s\n",
      "\titers: 300, epoch: 2 | loss: 0.0378179\n",
      "\tspeed: 0.0504s/iter; left time: 848.7462s\n",
      "\titers: 400, epoch: 2 | loss: 0.0354004\n",
      "\tspeed: 0.0504s/iter; left time: 843.7869s\n",
      "\titers: 500, epoch: 2 | loss: 0.0290515\n",
      "\tspeed: 0.0504s/iter; left time: 838.6282s\n",
      "\titers: 600, epoch: 2 | loss: 0.0255628\n",
      "\tspeed: 0.0504s/iter; left time: 833.8755s\n",
      "\titers: 700, epoch: 2 | loss: 0.0224540\n",
      "\tspeed: 0.0504s/iter; left time: 828.5267s\n",
      "\titers: 800, epoch: 2 | loss: 0.0219169\n",
      "\tspeed: 0.0506s/iter; left time: 826.2668s\n",
      "\titers: 900, epoch: 2 | loss: 0.0214847\n",
      "\tspeed: 0.0505s/iter; left time: 819.4119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0335635 Vali Loss: 0.0189745 Test Loss: 0.0212966\n",
      "Validation loss decreased (0.049999 --> 0.018974).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0235515\n",
      "\tspeed: 0.1402s/iter; left time: 2262.3782s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204115\n",
      "\tspeed: 0.0503s/iter; left time: 807.2532s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205418\n",
      "\tspeed: 0.0504s/iter; left time: 803.0996s\n",
      "\titers: 400, epoch: 3 | loss: 0.0176324\n",
      "\tspeed: 0.0505s/iter; left time: 799.1270s\n",
      "\titers: 500, epoch: 3 | loss: 0.0200714\n",
      "\tspeed: 0.0505s/iter; left time: 794.1898s\n",
      "\titers: 600, epoch: 3 | loss: 0.0202698\n",
      "\tspeed: 0.0505s/iter; left time: 789.4579s\n",
      "\titers: 700, epoch: 3 | loss: 0.0186561\n",
      "\tspeed: 0.0505s/iter; left time: 784.2378s\n",
      "\titers: 800, epoch: 3 | loss: 0.0182578\n",
      "\tspeed: 0.0504s/iter; left time: 778.3410s\n",
      "\titers: 900, epoch: 3 | loss: 0.0199967\n",
      "\tspeed: 0.0504s/iter; left time: 772.8519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0200834 Vali Loss: 0.0190667 Test Loss: 0.0209968\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0193595\n",
      "\tspeed: 0.1366s/iter; left time: 2081.0988s\n",
      "\titers: 200, epoch: 4 | loss: 0.0170491\n",
      "\tspeed: 0.0503s/iter; left time: 761.4699s\n",
      "\titers: 300, epoch: 4 | loss: 0.0187636\n",
      "\tspeed: 0.0504s/iter; left time: 757.7046s\n",
      "\titers: 400, epoch: 4 | loss: 0.0182095\n",
      "\tspeed: 0.0504s/iter; left time: 752.4597s\n",
      "\titers: 500, epoch: 4 | loss: 0.0184221\n",
      "\tspeed: 0.0503s/iter; left time: 746.7746s\n",
      "\titers: 600, epoch: 4 | loss: 0.0173221\n",
      "\tspeed: 0.0504s/iter; left time: 742.7025s\n",
      "\titers: 700, epoch: 4 | loss: 0.0179912\n",
      "\tspeed: 0.0504s/iter; left time: 737.2832s\n",
      "\titers: 800, epoch: 4 | loss: 0.0189602\n",
      "\tspeed: 0.0504s/iter; left time: 732.3357s\n",
      "\titers: 900, epoch: 4 | loss: 0.0181465\n",
      "\tspeed: 0.0504s/iter; left time: 727.2644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.65s\n",
      "Steps: 902 | Train Loss: 0.0183140 Vali Loss: 0.0184400 Test Loss: 0.0211830\n",
      "Validation loss decreased (0.018974 --> 0.018440).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0170493\n",
      "\tspeed: 0.1398s/iter; left time: 2003.7152s\n",
      "\titers: 200, epoch: 5 | loss: 0.0163401\n",
      "\tspeed: 0.0504s/iter; left time: 716.6871s\n",
      "\titers: 300, epoch: 5 | loss: 0.0172979\n",
      "\tspeed: 0.0504s/iter; left time: 712.2541s\n",
      "\titers: 400, epoch: 5 | loss: 0.0170552\n",
      "\tspeed: 0.0505s/iter; left time: 708.7722s\n",
      "\titers: 500, epoch: 5 | loss: 0.0159546\n",
      "\tspeed: 0.0505s/iter; left time: 703.1248s\n",
      "\titers: 600, epoch: 5 | loss: 0.0179998\n",
      "\tspeed: 0.0505s/iter; left time: 698.4075s\n",
      "\titers: 700, epoch: 5 | loss: 0.0170143\n",
      "\tspeed: 0.0503s/iter; left time: 691.3856s\n",
      "\titers: 800, epoch: 5 | loss: 0.0153025\n",
      "\tspeed: 0.0504s/iter; left time: 686.9005s\n",
      "\titers: 900, epoch: 5 | loss: 0.0177909\n",
      "\tspeed: 0.0504s/iter; left time: 681.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0167801 Vali Loss: 0.0190931 Test Loss: 0.0210882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0168719\n",
      "\tspeed: 0.1371s/iter; left time: 1840.8245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0183581\n",
      "\tspeed: 0.0504s/iter; left time: 671.8229s\n",
      "\titers: 300, epoch: 6 | loss: 0.0161392\n",
      "\tspeed: 0.0504s/iter; left time: 666.4302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0146639\n",
      "\tspeed: 0.0505s/iter; left time: 662.8648s\n",
      "\titers: 500, epoch: 6 | loss: 0.0147155\n",
      "\tspeed: 0.0504s/iter; left time: 656.6532s\n",
      "\titers: 600, epoch: 6 | loss: 0.0146213\n",
      "\tspeed: 0.0504s/iter; left time: 651.1786s\n",
      "\titers: 700, epoch: 6 | loss: 0.0153003\n",
      "\tspeed: 0.0505s/iter; left time: 647.9012s\n",
      "\titers: 800, epoch: 6 | loss: 0.0174402\n",
      "\tspeed: 0.0505s/iter; left time: 642.3031s\n",
      "\titers: 900, epoch: 6 | loss: 0.0154924\n",
      "\tspeed: 0.0504s/iter; left time: 636.3953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0152655 Vali Loss: 0.0186443 Test Loss: 0.0209225\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0171572\n",
      "\tspeed: 0.1380s/iter; left time: 1729.2695s\n",
      "\titers: 200, epoch: 7 | loss: 0.0150322\n",
      "\tspeed: 0.0504s/iter; left time: 626.3312s\n",
      "\titers: 300, epoch: 7 | loss: 0.0145275\n",
      "\tspeed: 0.0504s/iter; left time: 621.1622s\n",
      "\titers: 400, epoch: 7 | loss: 0.0152736\n",
      "\tspeed: 0.0504s/iter; left time: 616.4084s\n",
      "\titers: 500, epoch: 7 | loss: 0.0124688\n",
      "\tspeed: 0.0504s/iter; left time: 611.6776s\n",
      "\titers: 600, epoch: 7 | loss: 0.0142438\n",
      "\tspeed: 0.0505s/iter; left time: 607.5710s\n",
      "\titers: 700, epoch: 7 | loss: 0.0118809\n",
      "\tspeed: 0.0505s/iter; left time: 602.1007s\n",
      "\titers: 800, epoch: 7 | loss: 0.0129951\n",
      "\tspeed: 0.0506s/iter; left time: 597.9871s\n",
      "\titers: 900, epoch: 7 | loss: 0.0129787\n",
      "\tspeed: 0.0504s/iter; left time: 591.1747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0139308 Vali Loss: 0.0198808 Test Loss: 0.0221280\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132050\n",
      "\tspeed: 0.1375s/iter; left time: 1598.8070s\n",
      "\titers: 200, epoch: 8 | loss: 0.0124671\n",
      "\tspeed: 0.0504s/iter; left time: 580.5713s\n",
      "\titers: 300, epoch: 8 | loss: 0.0145717\n",
      "\tspeed: 0.0504s/iter; left time: 576.0552s\n",
      "\titers: 400, epoch: 8 | loss: 0.0130775\n",
      "\tspeed: 0.0504s/iter; left time: 570.8247s\n",
      "\titers: 500, epoch: 8 | loss: 0.0132061\n",
      "\tspeed: 0.0504s/iter; left time: 565.6927s\n",
      "\titers: 600, epoch: 8 | loss: 0.0130485\n",
      "\tspeed: 0.0504s/iter; left time: 561.2924s\n",
      "\titers: 700, epoch: 8 | loss: 0.0142619\n",
      "\tspeed: 0.0503s/iter; left time: 555.0997s\n",
      "\titers: 800, epoch: 8 | loss: 0.0127802\n",
      "\tspeed: 0.0505s/iter; left time: 551.5882s\n",
      "\titers: 900, epoch: 8 | loss: 0.0116429\n",
      "\tspeed: 0.0504s/iter; left time: 546.1321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0126203 Vali Loss: 0.0205238 Test Loss: 0.0220269\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0107108\n",
      "\tspeed: 0.1369s/iter; left time: 1467.8649s\n",
      "\titers: 200, epoch: 9 | loss: 0.0120930\n",
      "\tspeed: 0.0504s/iter; left time: 535.5691s\n",
      "\titers: 300, epoch: 9 | loss: 0.0129282\n",
      "\tspeed: 0.0504s/iter; left time: 530.5359s\n",
      "\titers: 400, epoch: 9 | loss: 0.0113463\n",
      "\tspeed: 0.0504s/iter; left time: 525.4851s\n",
      "\titers: 500, epoch: 9 | loss: 0.0122018\n",
      "\tspeed: 0.0504s/iter; left time: 520.4735s\n",
      "\titers: 600, epoch: 9 | loss: 0.0119361\n",
      "\tspeed: 0.0504s/iter; left time: 515.1971s\n",
      "\titers: 700, epoch: 9 | loss: 0.0110174\n",
      "\tspeed: 0.0504s/iter; left time: 510.7152s\n",
      "\titers: 800, epoch: 9 | loss: 0.0113841\n",
      "\tspeed: 0.0505s/iter; left time: 506.5025s\n",
      "\titers: 900, epoch: 9 | loss: 0.0112757\n",
      "\tspeed: 0.0505s/iter; left time: 501.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0114438 Vali Loss: 0.0220248 Test Loss: 0.0233626\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021184653043746948, rmse:0.1455494910478592, mae:0.09746020287275314, rse:0.5507185459136963\n",
      "Original data scale mse:4480882.5, rmse:2116.8095703125, mae:1392.976318359375, rse:0.149108424782753\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1019148\n",
      "\tspeed: 0.0526s/iter; left time: 944.3682s\n",
      "\titers: 200, epoch: 1 | loss: 0.0971051\n",
      "\tspeed: 0.0504s/iter; left time: 898.3083s\n",
      "\titers: 300, epoch: 1 | loss: 0.0842349\n",
      "\tspeed: 0.0504s/iter; left time: 894.0588s\n",
      "\titers: 400, epoch: 1 | loss: 0.0804336\n",
      "\tspeed: 0.0504s/iter; left time: 889.5991s\n",
      "\titers: 500, epoch: 1 | loss: 0.0757676\n",
      "\tspeed: 0.0504s/iter; left time: 883.8320s\n",
      "\titers: 600, epoch: 1 | loss: 0.0732939\n",
      "\tspeed: 0.0504s/iter; left time: 878.8875s\n",
      "\titers: 700, epoch: 1 | loss: 0.0695650\n",
      "\tspeed: 0.0504s/iter; left time: 874.3043s\n",
      "\titers: 800, epoch: 1 | loss: 0.0631033\n",
      "\tspeed: 0.0504s/iter; left time: 869.1836s\n",
      "\titers: 900, epoch: 1 | loss: 0.0608767\n",
      "\tspeed: 0.0504s/iter; left time: 864.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0810947 Vali Loss: 0.0496574 Test Loss: 0.0587924\n",
      "Validation loss decreased (inf --> 0.049657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0457406\n",
      "\tspeed: 0.1415s/iter; left time: 2411.4615s\n",
      "\titers: 200, epoch: 2 | loss: 0.0414700\n",
      "\tspeed: 0.0504s/iter; left time: 853.9498s\n",
      "\titers: 300, epoch: 2 | loss: 0.0416473\n",
      "\tspeed: 0.0504s/iter; left time: 848.6696s\n",
      "\titers: 400, epoch: 2 | loss: 0.0360631\n",
      "\tspeed: 0.0504s/iter; left time: 843.8794s\n",
      "\titers: 500, epoch: 2 | loss: 0.0260347\n",
      "\tspeed: 0.0504s/iter; left time: 839.3970s\n",
      "\titers: 600, epoch: 2 | loss: 0.0260261\n",
      "\tspeed: 0.0504s/iter; left time: 833.9215s\n",
      "\titers: 700, epoch: 2 | loss: 0.0235522\n",
      "\tspeed: 0.0505s/iter; left time: 829.4308s\n",
      "\titers: 800, epoch: 2 | loss: 0.0238006\n",
      "\tspeed: 0.0504s/iter; left time: 823.1763s\n",
      "\titers: 900, epoch: 2 | loss: 0.0225498\n",
      "\tspeed: 0.0504s/iter; left time: 818.6855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0333600 Vali Loss: 0.0196942 Test Loss: 0.0227760\n",
      "Validation loss decreased (0.049657 --> 0.019694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0205507\n",
      "\tspeed: 0.1442s/iter; left time: 2326.5165s\n",
      "\titers: 200, epoch: 3 | loss: 0.0212225\n",
      "\tspeed: 0.0505s/iter; left time: 809.6008s\n",
      "\titers: 300, epoch: 3 | loss: 0.0184537\n",
      "\tspeed: 0.0505s/iter; left time: 804.5555s\n",
      "\titers: 400, epoch: 3 | loss: 0.0189279\n",
      "\tspeed: 0.0504s/iter; left time: 798.2155s\n",
      "\titers: 500, epoch: 3 | loss: 0.0200594\n",
      "\tspeed: 0.0504s/iter; left time: 793.7653s\n",
      "\titers: 600, epoch: 3 | loss: 0.0195526\n",
      "\tspeed: 0.0504s/iter; left time: 788.6567s\n",
      "\titers: 700, epoch: 3 | loss: 0.0186151\n",
      "\tspeed: 0.0504s/iter; left time: 783.8307s\n",
      "\titers: 800, epoch: 3 | loss: 0.0191913\n",
      "\tspeed: 0.0504s/iter; left time: 778.1420s\n",
      "\titers: 900, epoch: 3 | loss: 0.0220613\n",
      "\tspeed: 0.0504s/iter; left time: 773.3089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.80s\n",
      "Steps: 902 | Train Loss: 0.0201075 Vali Loss: 0.0190689 Test Loss: 0.0200431\n",
      "Validation loss decreased (0.019694 --> 0.019069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0171240\n",
      "\tspeed: 0.1422s/iter; left time: 2166.5491s\n",
      "\titers: 200, epoch: 4 | loss: 0.0206921\n",
      "\tspeed: 0.0504s/iter; left time: 762.9619s\n",
      "\titers: 300, epoch: 4 | loss: 0.0182534\n",
      "\tspeed: 0.0520s/iter; left time: 782.1456s\n",
      "\titers: 400, epoch: 4 | loss: 0.0190155\n",
      "\tspeed: 0.0723s/iter; left time: 1080.1645s\n",
      "\titers: 500, epoch: 4 | loss: 0.0201484\n",
      "\tspeed: 0.0667s/iter; left time: 989.8799s\n",
      "\titers: 600, epoch: 4 | loss: 0.0165982\n",
      "\tspeed: 0.0785s/iter; left time: 1157.0690s\n",
      "\titers: 700, epoch: 4 | loss: 0.0193496\n",
      "\tspeed: 0.0804s/iter; left time: 1176.0266s\n",
      "\titers: 800, epoch: 4 | loss: 0.0172085\n",
      "\tspeed: 0.0844s/iter; left time: 1226.0731s\n",
      "\titers: 900, epoch: 4 | loss: 0.0173498\n",
      "\tspeed: 0.0813s/iter; left time: 1173.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:02.13s\n",
      "Steps: 902 | Train Loss: 0.0183315 Vali Loss: 0.0183397 Test Loss: 0.0207560\n",
      "Validation loss decreased (0.019069 --> 0.018340).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0187501\n",
      "\tspeed: 0.2563s/iter; left time: 3673.2631s\n",
      "\titers: 200, epoch: 5 | loss: 0.0163279\n",
      "\tspeed: 0.0880s/iter; left time: 1252.0913s\n",
      "\titers: 300, epoch: 5 | loss: 0.0170697\n",
      "\tspeed: 0.0672s/iter; left time: 949.6596s\n",
      "\titers: 400, epoch: 5 | loss: 0.0180755\n",
      "\tspeed: 0.0547s/iter; left time: 768.2341s\n",
      "\titers: 500, epoch: 5 | loss: 0.0187004\n",
      "\tspeed: 0.0525s/iter; left time: 731.2108s\n",
      "\titers: 600, epoch: 5 | loss: 0.0161837\n",
      "\tspeed: 0.0533s/iter; left time: 736.9585s\n",
      "\titers: 700, epoch: 5 | loss: 0.0168634\n",
      "\tspeed: 0.0529s/iter; left time: 726.9524s\n",
      "\titers: 800, epoch: 5 | loss: 0.0175499\n",
      "\tspeed: 0.0522s/iter; left time: 711.5540s\n",
      "\titers: 900, epoch: 5 | loss: 0.0164792\n",
      "\tspeed: 0.0525s/iter; left time: 710.3112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:58.06s\n",
      "Steps: 902 | Train Loss: 0.0167912 Vali Loss: 0.0176525 Test Loss: 0.0205528\n",
      "Validation loss decreased (0.018340 --> 0.017653).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0158256\n",
      "\tspeed: 0.1478s/iter; left time: 1984.7557s\n",
      "\titers: 200, epoch: 6 | loss: 0.0186154\n",
      "\tspeed: 0.0515s/iter; left time: 686.9078s\n",
      "\titers: 300, epoch: 6 | loss: 0.0142938\n",
      "\tspeed: 0.0513s/iter; left time: 678.8094s\n",
      "\titers: 400, epoch: 6 | loss: 0.0167240\n",
      "\tspeed: 0.0518s/iter; left time: 679.6925s\n",
      "\titers: 500, epoch: 6 | loss: 0.0155176\n",
      "\tspeed: 0.0516s/iter; left time: 671.8245s\n",
      "\titers: 600, epoch: 6 | loss: 0.0151491\n",
      "\tspeed: 0.0516s/iter; left time: 666.6773s\n",
      "\titers: 700, epoch: 6 | loss: 0.0149393\n",
      "\tspeed: 0.0512s/iter; left time: 657.1318s\n",
      "\titers: 800, epoch: 6 | loss: 0.0143527\n",
      "\tspeed: 0.0511s/iter; left time: 650.1514s\n",
      "\titers: 900, epoch: 6 | loss: 0.0146510\n",
      "\tspeed: 0.0510s/iter; left time: 644.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.81s\n",
      "Steps: 902 | Train Loss: 0.0154842 Vali Loss: 0.0188059 Test Loss: 0.0227140\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0130530\n",
      "\tspeed: 0.1428s/iter; left time: 1788.8689s\n",
      "\titers: 200, epoch: 7 | loss: 0.0151590\n",
      "\tspeed: 0.0514s/iter; left time: 639.1924s\n",
      "\titers: 300, epoch: 7 | loss: 0.0141264\n",
      "\tspeed: 0.0514s/iter; left time: 634.1811s\n",
      "\titers: 400, epoch: 7 | loss: 0.0145031\n",
      "\tspeed: 0.0510s/iter; left time: 624.1067s\n",
      "\titers: 500, epoch: 7 | loss: 0.0130284\n",
      "\tspeed: 0.0511s/iter; left time: 619.2173s\n",
      "\titers: 600, epoch: 7 | loss: 0.0141119\n",
      "\tspeed: 0.0512s/iter; left time: 615.7427s\n",
      "\titers: 700, epoch: 7 | loss: 0.0144239\n",
      "\tspeed: 0.0512s/iter; left time: 610.2346s\n",
      "\titers: 800, epoch: 7 | loss: 0.0143639\n",
      "\tspeed: 0.0513s/iter; left time: 606.3581s\n",
      "\titers: 900, epoch: 7 | loss: 0.0123217\n",
      "\tspeed: 0.0508s/iter; left time: 595.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.53s\n",
      "Steps: 902 | Train Loss: 0.0142994 Vali Loss: 0.0195513 Test Loss: 0.0221172\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0138762\n",
      "\tspeed: 0.1443s/iter; left time: 1677.3878s\n",
      "\titers: 200, epoch: 8 | loss: 0.0138030\n",
      "\tspeed: 0.0512s/iter; left time: 589.6166s\n",
      "\titers: 300, epoch: 8 | loss: 0.0154013\n",
      "\tspeed: 0.0511s/iter; left time: 583.8309s\n",
      "\titers: 400, epoch: 8 | loss: 0.0137396\n",
      "\tspeed: 0.0510s/iter; left time: 577.3447s\n",
      "\titers: 500, epoch: 8 | loss: 0.0140458\n",
      "\tspeed: 0.0510s/iter; left time: 572.0200s\n",
      "\titers: 600, epoch: 8 | loss: 0.0125235\n",
      "\tspeed: 0.0519s/iter; left time: 577.8666s\n",
      "\titers: 700, epoch: 8 | loss: 0.0122497\n",
      "\tspeed: 0.0536s/iter; left time: 590.9076s\n",
      "\titers: 800, epoch: 8 | loss: 0.0124928\n",
      "\tspeed: 0.0950s/iter; left time: 1038.0701s\n",
      "\titers: 900, epoch: 8 | loss: 0.0133401\n",
      "\tspeed: 0.1017s/iter; left time: 1100.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.49s\n",
      "Steps: 902 | Train Loss: 0.0129918 Vali Loss: 0.0208927 Test Loss: 0.0225966\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0125784\n",
      "\tspeed: 0.2970s/iter; left time: 3185.8262s\n",
      "\titers: 200, epoch: 9 | loss: 0.0115299\n",
      "\tspeed: 0.0511s/iter; left time: 542.8985s\n",
      "\titers: 300, epoch: 9 | loss: 0.0138254\n",
      "\tspeed: 0.0511s/iter; left time: 537.8576s\n",
      "\titers: 400, epoch: 9 | loss: 0.0125443\n",
      "\tspeed: 0.0510s/iter; left time: 531.5680s\n",
      "\titers: 500, epoch: 9 | loss: 0.0119621\n",
      "\tspeed: 0.0506s/iter; left time: 522.7962s\n",
      "\titers: 600, epoch: 9 | loss: 0.0108240\n",
      "\tspeed: 0.0507s/iter; left time: 517.9832s\n",
      "\titers: 700, epoch: 9 | loss: 0.0106221\n",
      "\tspeed: 0.0507s/iter; left time: 512.8421s\n",
      "\titers: 800, epoch: 9 | loss: 0.0118533\n",
      "\tspeed: 0.0507s/iter; left time: 508.0741s\n",
      "\titers: 900, epoch: 9 | loss: 0.0114278\n",
      "\tspeed: 0.0508s/iter; left time: 504.2767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.44s\n",
      "Steps: 902 | Train Loss: 0.0117030 Vali Loss: 0.0204482 Test Loss: 0.0228200\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0112076\n",
      "\tspeed: 0.1394s/iter; left time: 1369.1657s\n",
      "\titers: 200, epoch: 10 | loss: 0.0118141\n",
      "\tspeed: 0.0509s/iter; left time: 494.5809s\n",
      "\titers: 300, epoch: 10 | loss: 0.0120569\n",
      "\tspeed: 0.0508s/iter; left time: 489.1606s\n",
      "\titers: 400, epoch: 10 | loss: 0.0113766\n",
      "\tspeed: 0.0508s/iter; left time: 483.8873s\n",
      "\titers: 500, epoch: 10 | loss: 0.0112426\n",
      "\tspeed: 0.0508s/iter; left time: 478.5691s\n",
      "\titers: 600, epoch: 10 | loss: 0.0100483\n",
      "\tspeed: 0.0508s/iter; left time: 473.5713s\n",
      "\titers: 700, epoch: 10 | loss: 0.0111024\n",
      "\tspeed: 0.0508s/iter; left time: 468.7846s\n",
      "\titers: 800, epoch: 10 | loss: 0.0104355\n",
      "\tspeed: 0.0508s/iter; left time: 463.6809s\n",
      "\titers: 900, epoch: 10 | loss: 0.0096493\n",
      "\tspeed: 0.0510s/iter; left time: 459.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 902 | Train Loss: 0.0106408 Vali Loss: 0.0222400 Test Loss: 0.0249648\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02053854614496231, rmse:0.1433127522468567, mae:0.09565677493810654, rse:0.5422554016113281\n",
      "Original data scale mse:4692489.5, rmse:2166.215576171875, mae:1400.195068359375, rse:0.1525885909795761\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2289756\n",
      "\tspeed: 0.0549s/iter; left time: 990.1262s\n",
      "\titers: 200, epoch: 1 | loss: 0.2147405\n",
      "\tspeed: 0.0340s/iter; left time: 610.1203s\n",
      "\titers: 300, epoch: 1 | loss: 0.2024794\n",
      "\tspeed: 0.0342s/iter; left time: 610.2855s\n",
      "\titers: 400, epoch: 1 | loss: 0.1978398\n",
      "\tspeed: 0.0351s/iter; left time: 621.3565s\n",
      "\titers: 500, epoch: 1 | loss: 0.1838570\n",
      "\tspeed: 0.0348s/iter; left time: 613.4514s\n",
      "\titers: 600, epoch: 1 | loss: 0.1871906\n",
      "\tspeed: 0.0347s/iter; left time: 607.1201s\n",
      "\titers: 700, epoch: 1 | loss: 0.1718587\n",
      "\tspeed: 0.0347s/iter; left time: 604.1682s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741228\n",
      "\tspeed: 0.0344s/iter; left time: 595.8422s\n",
      "\titers: 900, epoch: 1 | loss: 0.1741925\n",
      "\tspeed: 0.0341s/iter; left time: 587.2876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.96s\n",
      "Steps: 906 | Train Loss: 0.1946895 Vali Loss: 0.1531637 Test Loss: 0.1688930\n",
      "Validation loss decreased (inf --> 0.153164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200996\n",
      "\tspeed: 0.1076s/iter; left time: 1841.7908s\n",
      "\titers: 200, epoch: 2 | loss: 0.0943886\n",
      "\tspeed: 0.0346s/iter; left time: 588.3090s\n",
      "\titers: 300, epoch: 2 | loss: 0.0873010\n",
      "\tspeed: 0.0346s/iter; left time: 585.6588s\n",
      "\titers: 400, epoch: 2 | loss: 0.0911078\n",
      "\tspeed: 0.0346s/iter; left time: 581.6602s\n",
      "\titers: 500, epoch: 2 | loss: 0.0900601\n",
      "\tspeed: 0.0341s/iter; left time: 570.0030s\n",
      "\titers: 600, epoch: 2 | loss: 0.0939043\n",
      "\tspeed: 0.0341s/iter; left time: 566.5680s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763428\n",
      "\tspeed: 0.0341s/iter; left time: 562.8113s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738119\n",
      "\tspeed: 0.0341s/iter; left time: 559.0866s\n",
      "\titers: 900, epoch: 2 | loss: 0.0727385\n",
      "\tspeed: 0.0341s/iter; left time: 555.6687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0941843 Vali Loss: 0.0731850 Test Loss: 0.0763463\n",
      "Validation loss decreased (0.153164 --> 0.073185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689264\n",
      "\tspeed: 0.0999s/iter; left time: 1618.8934s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680265\n",
      "\tspeed: 0.0341s/iter; left time: 548.6482s\n",
      "\titers: 300, epoch: 3 | loss: 0.0720875\n",
      "\tspeed: 0.0340s/iter; left time: 544.4800s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637039\n",
      "\tspeed: 0.0340s/iter; left time: 540.8900s\n",
      "\titers: 500, epoch: 3 | loss: 0.0603021\n",
      "\tspeed: 0.0340s/iter; left time: 537.8295s\n",
      "\titers: 600, epoch: 3 | loss: 0.0701781\n",
      "\tspeed: 0.0340s/iter; left time: 534.2992s\n",
      "\titers: 700, epoch: 3 | loss: 0.0690891\n",
      "\tspeed: 0.0340s/iter; left time: 531.0566s\n",
      "\titers: 800, epoch: 3 | loss: 0.0771389\n",
      "\tspeed: 0.0340s/iter; left time: 527.3040s\n",
      "\titers: 900, epoch: 3 | loss: 0.0653842\n",
      "\tspeed: 0.0441s/iter; left time: 678.8912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.16s\n",
      "Steps: 906 | Train Loss: 0.0697471 Vali Loss: 0.0669245 Test Loss: 0.0713615\n",
      "Validation loss decreased (0.073185 --> 0.066924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727013\n",
      "\tspeed: 0.1012s/iter; left time: 1547.9813s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631000\n",
      "\tspeed: 0.0341s/iter; left time: 518.5061s\n",
      "\titers: 300, epoch: 4 | loss: 0.0641052\n",
      "\tspeed: 0.0341s/iter; left time: 514.4442s\n",
      "\titers: 400, epoch: 4 | loss: 0.0677283\n",
      "\tspeed: 0.0340s/iter; left time: 510.3607s\n",
      "\titers: 500, epoch: 4 | loss: 0.0661093\n",
      "\tspeed: 0.0344s/iter; left time: 512.5893s\n",
      "\titers: 600, epoch: 4 | loss: 0.0596208\n",
      "\tspeed: 0.0388s/iter; left time: 574.5589s\n",
      "\titers: 700, epoch: 4 | loss: 0.0618208\n",
      "\tspeed: 0.0497s/iter; left time: 731.1782s\n",
      "\titers: 800, epoch: 4 | loss: 0.0644566\n",
      "\tspeed: 0.0481s/iter; left time: 702.8723s\n",
      "\titers: 900, epoch: 4 | loss: 0.0667040\n",
      "\tspeed: 0.0491s/iter; left time: 712.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.41s\n",
      "Steps: 906 | Train Loss: 0.0649319 Vali Loss: 0.0651137 Test Loss: 0.0699982\n",
      "Validation loss decreased (0.066924 --> 0.065114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597008\n",
      "\tspeed: 0.1615s/iter; left time: 2325.5606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717447\n",
      "\tspeed: 0.0481s/iter; left time: 687.7577s\n",
      "\titers: 300, epoch: 5 | loss: 0.0594414\n",
      "\tspeed: 0.0486s/iter; left time: 690.6490s\n",
      "\titers: 400, epoch: 5 | loss: 0.0574381\n",
      "\tspeed: 0.0483s/iter; left time: 680.2591s\n",
      "\titers: 500, epoch: 5 | loss: 0.0629130\n",
      "\tspeed: 0.0485s/iter; left time: 679.3439s\n",
      "\titers: 600, epoch: 5 | loss: 0.0602561\n",
      "\tspeed: 0.0493s/iter; left time: 685.4686s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723139\n",
      "\tspeed: 0.0483s/iter; left time: 665.7755s\n",
      "\titers: 800, epoch: 5 | loss: 0.0493080\n",
      "\tspeed: 0.0489s/iter; left time: 670.1410s\n",
      "\titers: 900, epoch: 5 | loss: 0.0612842\n",
      "\tspeed: 0.0509s/iter; left time: 692.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.95s\n",
      "Steps: 906 | Train Loss: 0.0610163 Vali Loss: 0.0614561 Test Loss: 0.0658055\n",
      "Validation loss decreased (0.065114 --> 0.061456).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591033\n",
      "\tspeed: 0.1620s/iter; left time: 2186.1804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583568\n",
      "\tspeed: 0.0485s/iter; left time: 649.8758s\n",
      "\titers: 300, epoch: 6 | loss: 0.0663953\n",
      "\tspeed: 0.0485s/iter; left time: 644.4826s\n",
      "\titers: 400, epoch: 6 | loss: 0.0580835\n",
      "\tspeed: 0.0523s/iter; left time: 690.2673s\n",
      "\titers: 500, epoch: 6 | loss: 0.0495465\n",
      "\tspeed: 0.0541s/iter; left time: 707.6604s\n",
      "\titers: 600, epoch: 6 | loss: 0.0566977\n",
      "\tspeed: 0.0499s/iter; left time: 648.8261s\n",
      "\titers: 700, epoch: 6 | loss: 0.0582300\n",
      "\tspeed: 0.0484s/iter; left time: 623.3253s\n",
      "\titers: 800, epoch: 6 | loss: 0.0565420\n",
      "\tspeed: 0.0482s/iter; left time: 616.7458s\n",
      "\titers: 900, epoch: 6 | loss: 0.0544238\n",
      "\tspeed: 0.0482s/iter; left time: 612.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 906 | Train Loss: 0.0582357 Vali Loss: 0.0605395 Test Loss: 0.0657733\n",
      "Validation loss decreased (0.061456 --> 0.060540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0518394\n",
      "\tspeed: 0.1610s/iter; left time: 2025.7553s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625482\n",
      "\tspeed: 0.0481s/iter; left time: 599.9669s\n",
      "\titers: 300, epoch: 7 | loss: 0.0538388\n",
      "\tspeed: 0.0487s/iter; left time: 603.7410s\n",
      "\titers: 400, epoch: 7 | loss: 0.0608252\n",
      "\tspeed: 0.0498s/iter; left time: 611.3335s\n",
      "\titers: 500, epoch: 7 | loss: 0.0573636\n",
      "\tspeed: 0.0492s/iter; left time: 599.0954s\n",
      "\titers: 600, epoch: 7 | loss: 0.0511362\n",
      "\tspeed: 0.0492s/iter; left time: 594.1859s\n",
      "\titers: 700, epoch: 7 | loss: 0.0534262\n",
      "\tspeed: 0.0494s/iter; left time: 591.6290s\n",
      "\titers: 800, epoch: 7 | loss: 0.0597523\n",
      "\tspeed: 0.0491s/iter; left time: 584.0605s\n",
      "\titers: 900, epoch: 7 | loss: 0.0498654\n",
      "\tspeed: 0.0491s/iter; left time: 578.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.49s\n",
      "Steps: 906 | Train Loss: 0.0561592 Vali Loss: 0.0586244 Test Loss: 0.0642837\n",
      "Validation loss decreased (0.060540 --> 0.058624).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0509520\n",
      "\tspeed: 0.1443s/iter; left time: 1685.6265s\n",
      "\titers: 200, epoch: 8 | loss: 0.0509359\n",
      "\tspeed: 0.0492s/iter; left time: 569.2770s\n",
      "\titers: 300, epoch: 8 | loss: 0.0527956\n",
      "\tspeed: 0.0482s/iter; left time: 553.8227s\n",
      "\titers: 400, epoch: 8 | loss: 0.0565501\n",
      "\tspeed: 0.0480s/iter; left time: 546.0127s\n",
      "\titers: 500, epoch: 8 | loss: 0.0532382\n",
      "\tspeed: 0.0478s/iter; left time: 538.9741s\n",
      "\titers: 600, epoch: 8 | loss: 0.0565472\n",
      "\tspeed: 0.0479s/iter; left time: 535.6273s\n",
      "\titers: 700, epoch: 8 | loss: 0.0503138\n",
      "\tspeed: 0.0477s/iter; left time: 528.1958s\n",
      "\titers: 800, epoch: 8 | loss: 0.0552599\n",
      "\tspeed: 0.0473s/iter; left time: 519.7131s\n",
      "\titers: 900, epoch: 8 | loss: 0.0519355\n",
      "\tspeed: 0.0470s/iter; left time: 511.3554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 906 | Train Loss: 0.0541787 Vali Loss: 0.0579991 Test Loss: 0.0646259\n",
      "Validation loss decreased (0.058624 --> 0.057999).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463596\n",
      "\tspeed: 0.1263s/iter; left time: 1360.3871s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533909\n",
      "\tspeed: 0.0379s/iter; left time: 404.8751s\n",
      "\titers: 300, epoch: 9 | loss: 0.0609420\n",
      "\tspeed: 0.0380s/iter; left time: 401.3176s\n",
      "\titers: 400, epoch: 9 | loss: 0.0476018\n",
      "\tspeed: 0.0380s/iter; left time: 397.4870s\n",
      "\titers: 500, epoch: 9 | loss: 0.0494947\n",
      "\tspeed: 0.0380s/iter; left time: 394.1571s\n",
      "\titers: 600, epoch: 9 | loss: 0.0558363\n",
      "\tspeed: 0.0382s/iter; left time: 391.9354s\n",
      "\titers: 700, epoch: 9 | loss: 0.0526480\n",
      "\tspeed: 0.0381s/iter; left time: 387.2590s\n",
      "\titers: 800, epoch: 9 | loss: 0.0504616\n",
      "\tspeed: 0.0379s/iter; left time: 381.6059s\n",
      "\titers: 900, epoch: 9 | loss: 0.0483640\n",
      "\tspeed: 0.0378s/iter; left time: 376.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:35.13s\n",
      "Steps: 906 | Train Loss: 0.0524793 Vali Loss: 0.0583450 Test Loss: 0.0629489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541091\n",
      "\tspeed: 0.1094s/iter; left time: 1079.2697s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536419\n",
      "\tspeed: 0.0383s/iter; left time: 374.4389s\n",
      "\titers: 300, epoch: 10 | loss: 0.0514194\n",
      "\tspeed: 0.0373s/iter; left time: 360.9619s\n",
      "\titers: 400, epoch: 10 | loss: 0.0504203\n",
      "\tspeed: 0.0372s/iter; left time: 355.8477s\n",
      "\titers: 500, epoch: 10 | loss: 0.0432660\n",
      "\tspeed: 0.0369s/iter; left time: 349.2516s\n",
      "\titers: 600, epoch: 10 | loss: 0.0556666\n",
      "\tspeed: 0.0369s/iter; left time: 345.6723s\n",
      "\titers: 700, epoch: 10 | loss: 0.0505122\n",
      "\tspeed: 0.0369s/iter; left time: 341.8069s\n",
      "\titers: 800, epoch: 10 | loss: 0.0518186\n",
      "\tspeed: 0.0367s/iter; left time: 336.5103s\n",
      "\titers: 900, epoch: 10 | loss: 0.0462847\n",
      "\tspeed: 0.0367s/iter; left time: 333.1667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:34.15s\n",
      "Steps: 906 | Train Loss: 0.0511121 Vali Loss: 0.0566754 Test Loss: 0.0640028\n",
      "Validation loss decreased (0.057999 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0522779\n",
      "\tspeed: 0.1086s/iter; left time: 972.9886s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463553\n",
      "\tspeed: 0.0365s/iter; left time: 323.3875s\n",
      "\titers: 300, epoch: 11 | loss: 0.0524409\n",
      "\tspeed: 0.0363s/iter; left time: 318.2349s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493511\n",
      "\tspeed: 0.0364s/iter; left time: 314.9420s\n",
      "\titers: 500, epoch: 11 | loss: 0.0535235\n",
      "\tspeed: 0.0365s/iter; left time: 312.1508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.0365s/iter; left time: 308.6240s\n",
      "\titers: 700, epoch: 11 | loss: 0.0487254\n",
      "\tspeed: 0.0364s/iter; left time: 304.7200s\n",
      "\titers: 800, epoch: 11 | loss: 0.0524150\n",
      "\tspeed: 0.0365s/iter; left time: 301.2415s\n",
      "\titers: 900, epoch: 11 | loss: 0.0441130\n",
      "\tspeed: 0.0364s/iter; left time: 297.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.51s\n",
      "Steps: 906 | Train Loss: 0.0498137 Vali Loss: 0.0567335 Test Loss: 0.0640843\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454959\n",
      "\tspeed: 0.1039s/iter; left time: 836.9042s\n",
      "\titers: 200, epoch: 12 | loss: 0.0510769\n",
      "\tspeed: 0.0364s/iter; left time: 289.8777s\n",
      "\titers: 300, epoch: 12 | loss: 0.0456563\n",
      "\tspeed: 0.0360s/iter; left time: 283.0406s\n",
      "\titers: 400, epoch: 12 | loss: 0.0503837\n",
      "\tspeed: 0.0360s/iter; left time: 279.2977s\n",
      "\titers: 500, epoch: 12 | loss: 0.0526142\n",
      "\tspeed: 0.0361s/iter; left time: 276.2053s\n",
      "\titers: 600, epoch: 12 | loss: 0.0477144\n",
      "\tspeed: 0.0361s/iter; left time: 272.9732s\n",
      "\titers: 700, epoch: 12 | loss: 0.0439736\n",
      "\tspeed: 0.0361s/iter; left time: 269.4045s\n",
      "\titers: 800, epoch: 12 | loss: 0.0518971\n",
      "\tspeed: 0.0364s/iter; left time: 267.6893s\n",
      "\titers: 900, epoch: 12 | loss: 0.0473772\n",
      "\tspeed: 0.0361s/iter; left time: 261.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:33.21s\n",
      "Steps: 906 | Train Loss: 0.0486576 Vali Loss: 0.0559295 Test Loss: 0.0642169\n",
      "Validation loss decreased (0.056675 --> 0.055930).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0414750\n",
      "\tspeed: 0.1070s/iter; left time: 764.7068s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494478\n",
      "\tspeed: 0.0362s/iter; left time: 255.0997s\n",
      "\titers: 300, epoch: 13 | loss: 0.0469200\n",
      "\tspeed: 0.0362s/iter; left time: 251.7409s\n",
      "\titers: 400, epoch: 13 | loss: 0.0549754\n",
      "\tspeed: 0.0362s/iter; left time: 248.2033s\n",
      "\titers: 500, epoch: 13 | loss: 0.0429797\n",
      "\tspeed: 0.0362s/iter; left time: 244.3588s\n",
      "\titers: 600, epoch: 13 | loss: 0.0493610\n",
      "\tspeed: 0.0363s/iter; left time: 241.1040s\n",
      "\titers: 700, epoch: 13 | loss: 0.0470018\n",
      "\tspeed: 0.0363s/iter; left time: 237.6180s\n",
      "\titers: 800, epoch: 13 | loss: 0.0505446\n",
      "\tspeed: 0.0364s/iter; left time: 234.5015s\n",
      "\titers: 900, epoch: 13 | loss: 0.0527018\n",
      "\tspeed: 0.0364s/iter; left time: 231.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:33.26s\n",
      "Steps: 906 | Train Loss: 0.0474767 Vali Loss: 0.0565293 Test Loss: 0.0645984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0478024\n",
      "\tspeed: 0.1037s/iter; left time: 647.4428s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465574\n",
      "\tspeed: 0.0363s/iter; left time: 223.0201s\n",
      "\titers: 300, epoch: 14 | loss: 0.0409424\n",
      "\tspeed: 0.0369s/iter; left time: 222.8736s\n",
      "\titers: 400, epoch: 14 | loss: 0.0393596\n",
      "\tspeed: 0.0367s/iter; left time: 218.1721s\n",
      "\titers: 500, epoch: 14 | loss: 0.0479720\n",
      "\tspeed: 0.0360s/iter; left time: 210.2544s\n",
      "\titers: 600, epoch: 14 | loss: 0.0455824\n",
      "\tspeed: 0.0357s/iter; left time: 205.0235s\n",
      "\titers: 700, epoch: 14 | loss: 0.0412655\n",
      "\tspeed: 0.0356s/iter; left time: 200.6092s\n",
      "\titers: 800, epoch: 14 | loss: 0.0518019\n",
      "\tspeed: 0.0356s/iter; left time: 197.3110s\n",
      "\titers: 900, epoch: 14 | loss: 0.0401611\n",
      "\tspeed: 0.0363s/iter; left time: 197.3124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 906 | Train Loss: 0.0464986 Vali Loss: 0.0564530 Test Loss: 0.0648331\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453141\n",
      "\tspeed: 0.1015s/iter; left time: 541.9354s\n",
      "\titers: 200, epoch: 15 | loss: 0.0427157\n",
      "\tspeed: 0.0356s/iter; left time: 186.6870s\n",
      "\titers: 300, epoch: 15 | loss: 0.0424050\n",
      "\tspeed: 0.0355s/iter; left time: 182.5853s\n",
      "\titers: 400, epoch: 15 | loss: 0.0450250\n",
      "\tspeed: 0.0356s/iter; left time: 179.2244s\n",
      "\titers: 500, epoch: 15 | loss: 0.0498884\n",
      "\tspeed: 0.0356s/iter; left time: 175.7776s\n",
      "\titers: 600, epoch: 15 | loss: 0.0426898\n",
      "\tspeed: 0.0356s/iter; left time: 172.2587s\n",
      "\titers: 700, epoch: 15 | loss: 0.0478519\n",
      "\tspeed: 0.0356s/iter; left time: 168.4243s\n",
      "\titers: 800, epoch: 15 | loss: 0.0399454\n",
      "\tspeed: 0.0355s/iter; left time: 164.7651s\n",
      "\titers: 900, epoch: 15 | loss: 0.0482494\n",
      "\tspeed: 0.0356s/iter; left time: 161.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.62s\n",
      "Steps: 906 | Train Loss: 0.0455909 Vali Loss: 0.0574777 Test Loss: 0.0649152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0477243\n",
      "\tspeed: 0.1030s/iter; left time: 456.3738s\n",
      "\titers: 200, epoch: 16 | loss: 0.0499466\n",
      "\tspeed: 0.0367s/iter; left time: 159.0718s\n",
      "\titers: 300, epoch: 16 | loss: 0.0453695\n",
      "\tspeed: 0.0364s/iter; left time: 154.0372s\n",
      "\titers: 400, epoch: 16 | loss: 0.0438813\n",
      "\tspeed: 0.0363s/iter; left time: 150.0823s\n",
      "\titers: 500, epoch: 16 | loss: 0.0471978\n",
      "\tspeed: 0.0363s/iter; left time: 146.2428s\n",
      "\titers: 600, epoch: 16 | loss: 0.0432691\n",
      "\tspeed: 0.0363s/iter; left time: 142.8684s\n",
      "\titers: 700, epoch: 16 | loss: 0.0403846\n",
      "\tspeed: 0.0363s/iter; left time: 138.8803s\n",
      "\titers: 800, epoch: 16 | loss: 0.0475129\n",
      "\tspeed: 0.0363s/iter; left time: 135.5841s\n",
      "\titers: 900, epoch: 16 | loss: 0.0473321\n",
      "\tspeed: 0.0363s/iter; left time: 131.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:33.40s\n",
      "Steps: 906 | Train Loss: 0.0446047 Vali Loss: 0.0561414 Test Loss: 0.0642355\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387600\n",
      "\tspeed: 0.1014s/iter; left time: 357.4797s\n",
      "\titers: 200, epoch: 17 | loss: 0.0365247\n",
      "\tspeed: 0.0360s/iter; left time: 123.2303s\n",
      "\titers: 300, epoch: 17 | loss: 0.0416560\n",
      "\tspeed: 0.0357s/iter; left time: 118.7469s\n",
      "\titers: 400, epoch: 17 | loss: 0.0426961\n",
      "\tspeed: 0.0356s/iter; left time: 114.7506s\n",
      "\titers: 500, epoch: 17 | loss: 0.0431453\n",
      "\tspeed: 0.0356s/iter; left time: 111.2004s\n",
      "\titers: 600, epoch: 17 | loss: 0.0430919\n",
      "\tspeed: 0.0347s/iter; left time: 105.0595s\n",
      "\titers: 700, epoch: 17 | loss: 0.0497445\n",
      "\tspeed: 0.0350s/iter; left time: 102.3518s\n",
      "\titers: 800, epoch: 17 | loss: 0.0412744\n",
      "\tspeed: 0.0356s/iter; left time: 100.6510s\n",
      "\titers: 900, epoch: 17 | loss: 0.0451680\n",
      "\tspeed: 0.0355s/iter; left time: 96.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.58s\n",
      "Steps: 906 | Train Loss: 0.0439459 Vali Loss: 0.0560204 Test Loss: 0.0647921\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01203176286071539, rmse:0.1096893921494484, mae:0.06421584635972977, rse:0.4145238697528839\n",
      "Original data scale mse:1767036.25, rmse:1329.2991943359375, mae:813.9424438476562, rse:0.09341298788785934\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2498116\n",
      "\tspeed: 0.0377s/iter; left time: 679.9452s\n",
      "\titers: 200, epoch: 1 | loss: 0.2011735\n",
      "\tspeed: 0.0347s/iter; left time: 622.4779s\n",
      "\titers: 300, epoch: 1 | loss: 0.2150934\n",
      "\tspeed: 0.0347s/iter; left time: 619.1292s\n",
      "\titers: 400, epoch: 1 | loss: 0.1960537\n",
      "\tspeed: 0.0347s/iter; left time: 615.3222s\n",
      "\titers: 500, epoch: 1 | loss: 0.1826794\n",
      "\tspeed: 0.0347s/iter; left time: 610.9105s\n",
      "\titers: 600, epoch: 1 | loss: 0.1927706\n",
      "\tspeed: 0.0346s/iter; left time: 606.8498s\n",
      "\titers: 700, epoch: 1 | loss: 0.1779167\n",
      "\tspeed: 0.0347s/iter; left time: 604.7175s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746279\n",
      "\tspeed: 0.0348s/iter; left time: 601.9485s\n",
      "\titers: 900, epoch: 1 | loss: 0.1654574\n",
      "\tspeed: 0.0347s/iter; left time: 597.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.80s\n",
      "Steps: 906 | Train Loss: 0.1992125 Vali Loss: 0.1432941 Test Loss: 0.1544233\n",
      "Validation loss decreased (inf --> 0.143294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1207117\n",
      "\tspeed: 0.1040s/iter; left time: 1779.4130s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950160\n",
      "\tspeed: 0.0348s/iter; left time: 592.4506s\n",
      "\titers: 300, epoch: 2 | loss: 0.1002817\n",
      "\tspeed: 0.0348s/iter; left time: 589.3753s\n",
      "\titers: 400, epoch: 2 | loss: 0.0960616\n",
      "\tspeed: 0.0348s/iter; left time: 585.3643s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890009\n",
      "\tspeed: 0.0348s/iter; left time: 582.1026s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752527\n",
      "\tspeed: 0.0348s/iter; left time: 577.9216s\n",
      "\titers: 700, epoch: 2 | loss: 0.0765394\n",
      "\tspeed: 0.0348s/iter; left time: 573.9364s\n",
      "\titers: 800, epoch: 2 | loss: 0.0737386\n",
      "\tspeed: 0.0347s/iter; left time: 570.2224s\n",
      "\titers: 900, epoch: 2 | loss: 0.0719303\n",
      "\tspeed: 0.0348s/iter; left time: 567.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0930362 Vali Loss: 0.0793414 Test Loss: 0.0821712\n",
      "Validation loss decreased (0.143294 --> 0.079341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749184\n",
      "\tspeed: 0.1021s/iter; left time: 1654.6067s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750817\n",
      "\tspeed: 0.0351s/iter; left time: 564.7599s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689839\n",
      "\tspeed: 0.0347s/iter; left time: 556.1284s\n",
      "\titers: 400, epoch: 3 | loss: 0.0704358\n",
      "\tspeed: 0.0347s/iter; left time: 551.3547s\n",
      "\titers: 500, epoch: 3 | loss: 0.0624443\n",
      "\tspeed: 0.0347s/iter; left time: 548.6931s\n",
      "\titers: 600, epoch: 3 | loss: 0.0694029\n",
      "\tspeed: 0.0347s/iter; left time: 544.8820s\n",
      "\titers: 700, epoch: 3 | loss: 0.0815309\n",
      "\tspeed: 0.0347s/iter; left time: 541.6771s\n",
      "\titers: 800, epoch: 3 | loss: 0.0664670\n",
      "\tspeed: 0.0347s/iter; left time: 538.2890s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646821\n",
      "\tspeed: 0.0347s/iter; left time: 535.0300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.86s\n",
      "Steps: 906 | Train Loss: 0.0724885 Vali Loss: 0.0685023 Test Loss: 0.0725131\n",
      "Validation loss decreased (0.079341 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744193\n",
      "\tspeed: 0.1038s/iter; left time: 1588.5692s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712759\n",
      "\tspeed: 0.0349s/iter; left time: 530.1567s\n",
      "\titers: 300, epoch: 4 | loss: 0.0668154\n",
      "\tspeed: 0.0348s/iter; left time: 525.6213s\n",
      "\titers: 400, epoch: 4 | loss: 0.0690735\n",
      "\tspeed: 0.0347s/iter; left time: 521.3429s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684960\n",
      "\tspeed: 0.0348s/iter; left time: 519.1811s\n",
      "\titers: 600, epoch: 4 | loss: 0.0681758\n",
      "\tspeed: 0.0348s/iter; left time: 515.5497s\n",
      "\titers: 700, epoch: 4 | loss: 0.0672854\n",
      "\tspeed: 0.0348s/iter; left time: 511.2669s\n",
      "\titers: 800, epoch: 4 | loss: 0.0688433\n",
      "\tspeed: 0.0347s/iter; left time: 507.1866s\n",
      "\titers: 900, epoch: 4 | loss: 0.0717380\n",
      "\tspeed: 0.0348s/iter; left time: 504.1914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.91s\n",
      "Steps: 906 | Train Loss: 0.0678150 Vali Loss: 0.0665552 Test Loss: 0.0727431\n",
      "Validation loss decreased (0.068502 --> 0.066555).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659932\n",
      "\tspeed: 0.1030s/iter; left time: 1482.6231s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691543\n",
      "\tspeed: 0.0348s/iter; left time: 497.2530s\n",
      "\titers: 300, epoch: 5 | loss: 0.0622396\n",
      "\tspeed: 0.0349s/iter; left time: 495.1291s\n",
      "\titers: 400, epoch: 5 | loss: 0.0609198\n",
      "\tspeed: 0.0348s/iter; left time: 491.1055s\n",
      "\titers: 500, epoch: 5 | loss: 0.0666150\n",
      "\tspeed: 0.0348s/iter; left time: 487.7235s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587350\n",
      "\tspeed: 0.0348s/iter; left time: 483.2866s\n",
      "\titers: 700, epoch: 5 | loss: 0.0578601\n",
      "\tspeed: 0.0347s/iter; left time: 479.1644s\n",
      "\titers: 800, epoch: 5 | loss: 0.0598911\n",
      "\tspeed: 0.0348s/iter; left time: 476.0198s\n",
      "\titers: 900, epoch: 5 | loss: 0.0647039\n",
      "\tspeed: 0.0347s/iter; left time: 472.3193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0635315 Vali Loss: 0.0618177 Test Loss: 0.0684821\n",
      "Validation loss decreased (0.066555 --> 0.061818).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551207\n",
      "\tspeed: 0.1025s/iter; left time: 1382.9035s\n",
      "\titers: 200, epoch: 6 | loss: 0.0664826\n",
      "\tspeed: 0.0347s/iter; left time: 464.9690s\n",
      "\titers: 300, epoch: 6 | loss: 0.0643861\n",
      "\tspeed: 0.0347s/iter; left time: 461.6338s\n",
      "\titers: 400, epoch: 6 | loss: 0.0645496\n",
      "\tspeed: 0.0348s/iter; left time: 458.7964s\n",
      "\titers: 500, epoch: 6 | loss: 0.0522045\n",
      "\tspeed: 0.0347s/iter; left time: 454.6579s\n",
      "\titers: 600, epoch: 6 | loss: 0.0588533\n",
      "\tspeed: 0.0348s/iter; left time: 451.7366s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584210\n",
      "\tspeed: 0.0349s/iter; left time: 449.6483s\n",
      "\titers: 800, epoch: 6 | loss: 0.0518436\n",
      "\tspeed: 0.0348s/iter; left time: 444.5817s\n",
      "\titers: 900, epoch: 6 | loss: 0.0592274\n",
      "\tspeed: 0.0348s/iter; left time: 441.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0598389 Vali Loss: 0.0608522 Test Loss: 0.0686492\n",
      "Validation loss decreased (0.061818 --> 0.060852).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570249\n",
      "\tspeed: 0.1035s/iter; left time: 1301.9967s\n",
      "\titers: 200, epoch: 7 | loss: 0.0546420\n",
      "\tspeed: 0.0347s/iter; left time: 433.7013s\n",
      "\titers: 300, epoch: 7 | loss: 0.0586133\n",
      "\tspeed: 0.0348s/iter; left time: 430.6990s\n",
      "\titers: 400, epoch: 7 | loss: 0.0534843\n",
      "\tspeed: 0.0348s/iter; left time: 426.9856s\n",
      "\titers: 500, epoch: 7 | loss: 0.0500044\n",
      "\tspeed: 0.0348s/iter; left time: 423.8945s\n",
      "\titers: 600, epoch: 7 | loss: 0.0479839\n",
      "\tspeed: 0.0348s/iter; left time: 420.4538s\n",
      "\titers: 700, epoch: 7 | loss: 0.0544220\n",
      "\tspeed: 0.0347s/iter; left time: 416.0986s\n",
      "\titers: 800, epoch: 7 | loss: 0.0504415\n",
      "\tspeed: 0.0347s/iter; left time: 412.9291s\n",
      "\titers: 900, epoch: 7 | loss: 0.0664917\n",
      "\tspeed: 0.0347s/iter; left time: 408.9576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0572039 Vali Loss: 0.0600482 Test Loss: 0.0666491\n",
      "Validation loss decreased (0.060852 --> 0.060048).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569239\n",
      "\tspeed: 0.1054s/iter; left time: 1231.2677s\n",
      "\titers: 200, epoch: 8 | loss: 0.0524420\n",
      "\tspeed: 0.0360s/iter; left time: 417.0321s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549767\n",
      "\tspeed: 0.0354s/iter; left time: 405.8189s\n",
      "\titers: 400, epoch: 8 | loss: 0.0569074\n",
      "\tspeed: 0.0351s/iter; left time: 399.2967s\n",
      "\titers: 500, epoch: 8 | loss: 0.0560224\n",
      "\tspeed: 0.0344s/iter; left time: 388.0709s\n",
      "\titers: 600, epoch: 8 | loss: 0.0586272\n",
      "\tspeed: 0.0351s/iter; left time: 392.2186s\n",
      "\titers: 700, epoch: 8 | loss: 0.0534134\n",
      "\tspeed: 0.0351s/iter; left time: 388.7864s\n",
      "\titers: 800, epoch: 8 | loss: 0.0507184\n",
      "\tspeed: 0.0351s/iter; left time: 385.2647s\n",
      "\titers: 900, epoch: 8 | loss: 0.0588685\n",
      "\tspeed: 0.0352s/iter; left time: 382.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.33s\n",
      "Steps: 906 | Train Loss: 0.0554143 Vali Loss: 0.0588686 Test Loss: 0.0643074\n",
      "Validation loss decreased (0.060048 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554289\n",
      "\tspeed: 0.1005s/iter; left time: 1082.5421s\n",
      "\titers: 200, epoch: 9 | loss: 0.0491354\n",
      "\tspeed: 0.0345s/iter; left time: 367.9343s\n",
      "\titers: 300, epoch: 9 | loss: 0.0533709\n",
      "\tspeed: 0.0344s/iter; left time: 364.1632s\n",
      "\titers: 400, epoch: 9 | loss: 0.0478047\n",
      "\tspeed: 0.0345s/iter; left time: 361.1691s\n",
      "\titers: 500, epoch: 9 | loss: 0.0562404\n",
      "\tspeed: 0.0344s/iter; left time: 357.0031s\n",
      "\titers: 600, epoch: 9 | loss: 0.0546994\n",
      "\tspeed: 0.0345s/iter; left time: 354.4891s\n",
      "\titers: 700, epoch: 9 | loss: 0.0573833\n",
      "\tspeed: 0.0345s/iter; left time: 351.0283s\n",
      "\titers: 800, epoch: 9 | loss: 0.0525519\n",
      "\tspeed: 0.0345s/iter; left time: 347.3084s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501279\n",
      "\tspeed: 0.0345s/iter; left time: 343.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0537802 Vali Loss: 0.0572465 Test Loss: 0.0636292\n",
      "Validation loss decreased (0.058869 --> 0.057246).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570313\n",
      "\tspeed: 0.1024s/iter; left time: 1010.6265s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489191\n",
      "\tspeed: 0.0345s/iter; left time: 336.7999s\n",
      "\titers: 300, epoch: 10 | loss: 0.0466328\n",
      "\tspeed: 0.0345s/iter; left time: 333.5356s\n",
      "\titers: 400, epoch: 10 | loss: 0.0506991\n",
      "\tspeed: 0.0345s/iter; left time: 329.9629s\n",
      "\titers: 500, epoch: 10 | loss: 0.0551326\n",
      "\tspeed: 0.0344s/iter; left time: 326.0982s\n",
      "\titers: 600, epoch: 10 | loss: 0.0489854\n",
      "\tspeed: 0.0344s/iter; left time: 322.5553s\n",
      "\titers: 700, epoch: 10 | loss: 0.0582220\n",
      "\tspeed: 0.0345s/iter; left time: 320.0594s\n",
      "\titers: 800, epoch: 10 | loss: 0.0630818\n",
      "\tspeed: 0.0345s/iter; left time: 316.0620s\n",
      "\titers: 900, epoch: 10 | loss: 0.0590224\n",
      "\tspeed: 0.0345s/iter; left time: 312.8794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.65s\n",
      "Steps: 906 | Train Loss: 0.0524546 Vali Loss: 0.0584495 Test Loss: 0.0668093\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541355\n",
      "\tspeed: 0.0996s/iter; left time: 892.8866s\n",
      "\titers: 200, epoch: 11 | loss: 0.0514751\n",
      "\tspeed: 0.0345s/iter; left time: 305.4828s\n",
      "\titers: 300, epoch: 11 | loss: 0.0508684\n",
      "\tspeed: 0.0342s/iter; left time: 299.3527s\n",
      "\titers: 400, epoch: 11 | loss: 0.0488365\n",
      "\tspeed: 0.0341s/iter; left time: 295.6787s\n",
      "\titers: 500, epoch: 11 | loss: 0.0411242\n",
      "\tspeed: 0.0341s/iter; left time: 292.2782s\n",
      "\titers: 600, epoch: 11 | loss: 0.0533406\n",
      "\tspeed: 0.0342s/iter; left time: 289.1026s\n",
      "\titers: 700, epoch: 11 | loss: 0.0518379\n",
      "\tspeed: 0.0343s/iter; left time: 286.7094s\n",
      "\titers: 800, epoch: 11 | loss: 0.0526628\n",
      "\tspeed: 0.0343s/iter; left time: 283.3028s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498659\n",
      "\tspeed: 0.0343s/iter; left time: 279.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.42s\n",
      "Steps: 906 | Train Loss: 0.0511982 Vali Loss: 0.0571466 Test Loss: 0.0659549\n",
      "Validation loss decreased (0.057246 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0479833\n",
      "\tspeed: 0.1002s/iter; left time: 807.2062s\n",
      "\titers: 200, epoch: 12 | loss: 0.0515542\n",
      "\tspeed: 0.0343s/iter; left time: 272.5373s\n",
      "\titers: 300, epoch: 12 | loss: 0.0507848\n",
      "\tspeed: 0.0342s/iter; left time: 268.8197s\n",
      "\titers: 400, epoch: 12 | loss: 0.0510435\n",
      "\tspeed: 0.0342s/iter; left time: 265.3663s\n",
      "\titers: 500, epoch: 12 | loss: 0.0462130\n",
      "\tspeed: 0.0342s/iter; left time: 262.0749s\n",
      "\titers: 600, epoch: 12 | loss: 0.0533448\n",
      "\tspeed: 0.0342s/iter; left time: 258.4630s\n",
      "\titers: 700, epoch: 12 | loss: 0.0432821\n",
      "\tspeed: 0.0342s/iter; left time: 255.0894s\n",
      "\titers: 800, epoch: 12 | loss: 0.0530810\n",
      "\tspeed: 0.0342s/iter; left time: 251.8856s\n",
      "\titers: 900, epoch: 12 | loss: 0.0456739\n",
      "\tspeed: 0.0342s/iter; left time: 248.2836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.36s\n",
      "Steps: 906 | Train Loss: 0.0497971 Vali Loss: 0.0571572 Test Loss: 0.0657481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0520588\n",
      "\tspeed: 0.0987s/iter; left time: 705.3635s\n",
      "\titers: 200, epoch: 13 | loss: 0.0471978\n",
      "\tspeed: 0.0348s/iter; left time: 245.0608s\n",
      "\titers: 300, epoch: 13 | loss: 0.0492734\n",
      "\tspeed: 0.0343s/iter; left time: 238.3167s\n",
      "\titers: 400, epoch: 13 | loss: 0.0487693\n",
      "\tspeed: 0.0344s/iter; left time: 235.8220s\n",
      "\titers: 500, epoch: 13 | loss: 0.0490274\n",
      "\tspeed: 0.0348s/iter; left time: 234.6202s\n",
      "\titers: 600, epoch: 13 | loss: 0.0444182\n",
      "\tspeed: 0.0348s/iter; left time: 231.5386s\n",
      "\titers: 700, epoch: 13 | loss: 0.0454526\n",
      "\tspeed: 0.0348s/iter; left time: 228.0235s\n",
      "\titers: 800, epoch: 13 | loss: 0.0502009\n",
      "\tspeed: 0.0345s/iter; left time: 222.5046s\n",
      "\titers: 900, epoch: 13 | loss: 0.0519659\n",
      "\tspeed: 0.0345s/iter; left time: 219.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.71s\n",
      "Steps: 906 | Train Loss: 0.0487688 Vali Loss: 0.0568870 Test Loss: 0.0654286\n",
      "Validation loss decreased (0.057147 --> 0.056887).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0472592\n",
      "\tspeed: 0.1002s/iter; left time: 625.7885s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461481\n",
      "\tspeed: 0.0342s/iter; left time: 209.8813s\n",
      "\titers: 300, epoch: 14 | loss: 0.0439564\n",
      "\tspeed: 0.0342s/iter; left time: 206.4675s\n",
      "\titers: 400, epoch: 14 | loss: 0.0481552\n",
      "\tspeed: 0.0342s/iter; left time: 203.0564s\n",
      "\titers: 500, epoch: 14 | loss: 0.0552839\n",
      "\tspeed: 0.0342s/iter; left time: 199.6786s\n",
      "\titers: 600, epoch: 14 | loss: 0.0544599\n",
      "\tspeed: 0.0342s/iter; left time: 196.4713s\n",
      "\titers: 700, epoch: 14 | loss: 0.0492873\n",
      "\tspeed: 0.0342s/iter; left time: 193.2318s\n",
      "\titers: 800, epoch: 14 | loss: 0.0519501\n",
      "\tspeed: 0.0342s/iter; left time: 189.7543s\n",
      "\titers: 900, epoch: 14 | loss: 0.0444011\n",
      "\tspeed: 0.0342s/iter; left time: 186.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.29s\n",
      "Steps: 906 | Train Loss: 0.0478288 Vali Loss: 0.0574118 Test Loss: 0.0649276\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518620\n",
      "\tspeed: 0.0967s/iter; left time: 515.8636s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447321\n",
      "\tspeed: 0.0342s/iter; left time: 178.8927s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470643\n",
      "\tspeed: 0.0341s/iter; left time: 175.3891s\n",
      "\titers: 400, epoch: 15 | loss: 0.0505560\n",
      "\tspeed: 0.0341s/iter; left time: 171.8593s\n",
      "\titers: 500, epoch: 15 | loss: 0.0455437\n",
      "\tspeed: 0.0342s/iter; left time: 168.7319s\n",
      "\titers: 600, epoch: 15 | loss: 0.0463022\n",
      "\tspeed: 0.0342s/iter; left time: 165.6396s\n",
      "\titers: 700, epoch: 15 | loss: 0.0565158\n",
      "\tspeed: 0.0342s/iter; left time: 162.1732s\n",
      "\titers: 800, epoch: 15 | loss: 0.0485040\n",
      "\tspeed: 0.0343s/iter; left time: 158.8992s\n",
      "\titers: 900, epoch: 15 | loss: 0.0463231\n",
      "\tspeed: 0.0343s/iter; left time: 155.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.33s\n",
      "Steps: 906 | Train Loss: 0.0470613 Vali Loss: 0.0568892 Test Loss: 0.0665978\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476478\n",
      "\tspeed: 0.0966s/iter; left time: 428.1729s\n",
      "\titers: 200, epoch: 16 | loss: 0.0442408\n",
      "\tspeed: 0.0342s/iter; left time: 148.2688s\n",
      "\titers: 300, epoch: 16 | loss: 0.0460189\n",
      "\tspeed: 0.0342s/iter; left time: 144.6738s\n",
      "\titers: 400, epoch: 16 | loss: 0.0477852\n",
      "\tspeed: 0.0343s/iter; left time: 141.5326s\n",
      "\titers: 500, epoch: 16 | loss: 0.0508246\n",
      "\tspeed: 0.0342s/iter; left time: 137.9401s\n",
      "\titers: 600, epoch: 16 | loss: 0.0476234\n",
      "\tspeed: 0.0342s/iter; left time: 134.6194s\n",
      "\titers: 700, epoch: 16 | loss: 0.0496349\n",
      "\tspeed: 0.0342s/iter; left time: 131.0207s\n",
      "\titers: 800, epoch: 16 | loss: 0.0451010\n",
      "\tspeed: 0.0342s/iter; left time: 127.7402s\n",
      "\titers: 900, epoch: 16 | loss: 0.0472244\n",
      "\tspeed: 0.0342s/iter; left time: 124.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 906 | Train Loss: 0.0462200 Vali Loss: 0.0565890 Test Loss: 0.0651991\n",
      "Validation loss decreased (0.056887 --> 0.056589).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0511533\n",
      "\tspeed: 0.1034s/iter; left time: 364.6280s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410157\n",
      "\tspeed: 0.0342s/iter; left time: 117.1469s\n",
      "\titers: 300, epoch: 17 | loss: 0.0532006\n",
      "\tspeed: 0.0342s/iter; left time: 113.7880s\n",
      "\titers: 400, epoch: 17 | loss: 0.0506476\n",
      "\tspeed: 0.0342s/iter; left time: 110.4402s\n",
      "\titers: 500, epoch: 17 | loss: 0.0444746\n",
      "\tspeed: 0.0342s/iter; left time: 106.8317s\n",
      "\titers: 600, epoch: 17 | loss: 0.0454823\n",
      "\tspeed: 0.0342s/iter; left time: 103.3351s\n",
      "\titers: 700, epoch: 17 | loss: 0.0417460\n",
      "\tspeed: 0.0342s/iter; left time: 100.0191s\n",
      "\titers: 800, epoch: 17 | loss: 0.0485935\n",
      "\tspeed: 0.0342s/iter; left time: 96.6135s\n",
      "\titers: 900, epoch: 17 | loss: 0.0427209\n",
      "\tspeed: 0.0342s/iter; left time: 93.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0454245 Vali Loss: 0.0563723 Test Loss: 0.0671997\n",
      "Validation loss decreased (0.056589 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0397315\n",
      "\tspeed: 0.1005s/iter; left time: 263.1075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411270\n",
      "\tspeed: 0.0342s/iter; left time: 86.1586s\n",
      "\titers: 300, epoch: 18 | loss: 0.0484297\n",
      "\tspeed: 0.0342s/iter; left time: 82.8027s\n",
      "\titers: 400, epoch: 18 | loss: 0.0467603\n",
      "\tspeed: 0.0341s/iter; left time: 79.1762s\n",
      "\titers: 500, epoch: 18 | loss: 0.0422288\n",
      "\tspeed: 0.0342s/iter; left time: 75.8083s\n",
      "\titers: 600, epoch: 18 | loss: 0.0504954\n",
      "\tspeed: 0.0341s/iter; left time: 72.3610s\n",
      "\titers: 700, epoch: 18 | loss: 0.0396327\n",
      "\tspeed: 0.0342s/iter; left time: 68.9799s\n",
      "\titers: 800, epoch: 18 | loss: 0.0461913\n",
      "\tspeed: 0.0343s/iter; left time: 65.7860s\n",
      "\titers: 900, epoch: 18 | loss: 0.0522097\n",
      "\tspeed: 0.0342s/iter; left time: 62.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.37s\n",
      "Steps: 906 | Train Loss: 0.0448353 Vali Loss: 0.0574077 Test Loss: 0.0666983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0404343\n",
      "\tspeed: 0.0989s/iter; left time: 169.3815s\n",
      "\titers: 200, epoch: 19 | loss: 0.0435289\n",
      "\tspeed: 0.0343s/iter; left time: 55.2672s\n",
      "\titers: 300, epoch: 19 | loss: 0.0437113\n",
      "\tspeed: 0.0342s/iter; left time: 51.8030s\n",
      "\titers: 400, epoch: 19 | loss: 0.0464690\n",
      "\tspeed: 0.0343s/iter; left time: 48.4120s\n",
      "\titers: 500, epoch: 19 | loss: 0.0434488\n",
      "\tspeed: 0.0342s/iter; left time: 44.9089s\n",
      "\titers: 600, epoch: 19 | loss: 0.0420474\n",
      "\tspeed: 0.0342s/iter; left time: 41.5055s\n",
      "\titers: 700, epoch: 19 | loss: 0.0488688\n",
      "\tspeed: 0.0342s/iter; left time: 38.1102s\n",
      "\titers: 800, epoch: 19 | loss: 0.0425040\n",
      "\tspeed: 0.0343s/iter; left time: 34.7056s\n",
      "\titers: 900, epoch: 19 | loss: 0.0387297\n",
      "\tspeed: 0.0342s/iter; left time: 31.2248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.40s\n",
      "Steps: 906 | Train Loss: 0.0441012 Vali Loss: 0.0579686 Test Loss: 0.0662565\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443658\n",
      "\tspeed: 0.0989s/iter; left time: 79.8351s\n",
      "\titers: 200, epoch: 20 | loss: 0.0434084\n",
      "\tspeed: 0.0342s/iter; left time: 24.2121s\n",
      "\titers: 300, epoch: 20 | loss: 0.0444593\n",
      "\tspeed: 0.0343s/iter; left time: 20.7924s\n",
      "\titers: 400, epoch: 20 | loss: 0.0421418\n",
      "\tspeed: 0.0343s/iter; left time: 17.3657s\n",
      "\titers: 500, epoch: 20 | loss: 0.0421504\n",
      "\tspeed: 0.0342s/iter; left time: 13.9296s\n",
      "\titers: 600, epoch: 20 | loss: 0.0476669\n",
      "\tspeed: 0.0343s/iter; left time: 10.5251s\n",
      "\titers: 700, epoch: 20 | loss: 0.0507700\n",
      "\tspeed: 0.0342s/iter; left time: 7.0834s\n",
      "\titers: 800, epoch: 20 | loss: 0.0446998\n",
      "\tspeed: 0.0343s/iter; left time: 3.6648s\n",
      "\titers: 900, epoch: 20 | loss: 0.0413743\n",
      "\tspeed: 0.0343s/iter; left time: 0.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.41s\n",
      "Steps: 906 | Train Loss: 0.0435656 Vali Loss: 0.0569343 Test Loss: 0.0663891\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013082382269203663, rmse:0.11437824368476868, mae:0.06724400073289871, rse:0.43224334716796875\n",
      "Original data scale mse:1968128.25, rmse:1402.89990234375, mae:857.3510131835938, rse:0.0985850915312767\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2329149\n",
      "\tspeed: 0.0625s/iter; left time: 1124.5767s\n",
      "\titers: 200, epoch: 1 | loss: 0.2132984\n",
      "\tspeed: 0.0415s/iter; left time: 741.5448s\n",
      "\titers: 300, epoch: 1 | loss: 0.2021164\n",
      "\tspeed: 0.0416s/iter; left time: 739.1000s\n",
      "\titers: 400, epoch: 1 | loss: 0.1994694\n",
      "\tspeed: 0.0415s/iter; left time: 734.3424s\n",
      "\titers: 500, epoch: 1 | loss: 0.1993076\n",
      "\tspeed: 0.0416s/iter; left time: 730.6598s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911502\n",
      "\tspeed: 0.0416s/iter; left time: 727.3324s\n",
      "\titers: 700, epoch: 1 | loss: 0.1889577\n",
      "\tspeed: 0.0415s/iter; left time: 721.9669s\n",
      "\titers: 800, epoch: 1 | loss: 0.1783947\n",
      "\tspeed: 0.0416s/iter; left time: 718.5942s\n",
      "\titers: 900, epoch: 1 | loss: 0.1868250\n",
      "\tspeed: 0.0417s/iter; left time: 716.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.2045878 Vali Loss: 0.1702724 Test Loss: 0.1878111\n",
      "Validation loss decreased (inf --> 0.170272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1723534\n",
      "\tspeed: 0.1170s/iter; left time: 1998.0238s\n",
      "\titers: 200, epoch: 2 | loss: 0.1603348\n",
      "\tspeed: 0.0415s/iter; left time: 705.1172s\n",
      "\titers: 300, epoch: 2 | loss: 0.1485798\n",
      "\tspeed: 0.0416s/iter; left time: 702.0892s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373307\n",
      "\tspeed: 0.0416s/iter; left time: 697.6313s\n",
      "\titers: 500, epoch: 2 | loss: 0.1285997\n",
      "\tspeed: 0.0416s/iter; left time: 694.2753s\n",
      "\titers: 600, epoch: 2 | loss: 0.1198477\n",
      "\tspeed: 0.0416s/iter; left time: 689.9216s\n",
      "\titers: 700, epoch: 2 | loss: 0.1147303\n",
      "\tspeed: 0.0416s/iter; left time: 685.3850s\n",
      "\titers: 800, epoch: 2 | loss: 0.1007503\n",
      "\tspeed: 0.0416s/iter; left time: 680.7088s\n",
      "\titers: 900, epoch: 2 | loss: 0.0971180\n",
      "\tspeed: 0.0416s/iter; left time: 676.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1339202 Vali Loss: 0.0941798 Test Loss: 0.1007875\n",
      "Validation loss decreased (0.170272 --> 0.094180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933497\n",
      "\tspeed: 0.1180s/iter; left time: 1908.1330s\n",
      "\titers: 200, epoch: 3 | loss: 0.0936517\n",
      "\tspeed: 0.0415s/iter; left time: 667.0889s\n",
      "\titers: 300, epoch: 3 | loss: 0.0927260\n",
      "\tspeed: 0.0416s/iter; left time: 663.7515s\n",
      "\titers: 400, epoch: 3 | loss: 0.0904723\n",
      "\tspeed: 0.0416s/iter; left time: 660.0851s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878174\n",
      "\tspeed: 0.0415s/iter; left time: 655.3119s\n",
      "\titers: 600, epoch: 3 | loss: 0.0923175\n",
      "\tspeed: 0.0416s/iter; left time: 651.3754s\n",
      "\titers: 700, epoch: 3 | loss: 0.0842094\n",
      "\tspeed: 0.0416s/iter; left time: 647.8343s\n",
      "\titers: 800, epoch: 3 | loss: 0.0947829\n",
      "\tspeed: 0.0416s/iter; left time: 642.9995s\n",
      "\titers: 900, epoch: 3 | loss: 0.0795053\n",
      "\tspeed: 0.0416s/iter; left time: 638.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0910683 Vali Loss: 0.0842124 Test Loss: 0.0916354\n",
      "Validation loss decreased (0.094180 --> 0.084212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810681\n",
      "\tspeed: 0.1177s/iter; left time: 1797.1778s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898334\n",
      "\tspeed: 0.0416s/iter; left time: 631.2290s\n",
      "\titers: 300, epoch: 4 | loss: 0.0877813\n",
      "\tspeed: 0.0416s/iter; left time: 626.6074s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827008\n",
      "\tspeed: 0.0416s/iter; left time: 622.2855s\n",
      "\titers: 500, epoch: 4 | loss: 0.0800275\n",
      "\tspeed: 0.0417s/iter; left time: 619.4193s\n",
      "\titers: 600, epoch: 4 | loss: 0.0795660\n",
      "\tspeed: 0.0416s/iter; left time: 614.2605s\n",
      "\titers: 700, epoch: 4 | loss: 0.0887710\n",
      "\tspeed: 0.0416s/iter; left time: 610.7840s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751216\n",
      "\tspeed: 0.0416s/iter; left time: 606.0313s\n",
      "\titers: 900, epoch: 4 | loss: 0.0814652\n",
      "\tspeed: 0.0416s/iter; left time: 601.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0842684 Vali Loss: 0.0824417 Test Loss: 0.0909199\n",
      "Validation loss decreased (0.084212 --> 0.082442).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819404\n",
      "\tspeed: 0.1164s/iter; left time: 1671.9546s\n",
      "\titers: 200, epoch: 5 | loss: 0.0734804\n",
      "\tspeed: 0.0416s/iter; left time: 593.8394s\n",
      "\titers: 300, epoch: 5 | loss: 0.0850687\n",
      "\tspeed: 0.0416s/iter; left time: 589.6366s\n",
      "\titers: 400, epoch: 5 | loss: 0.0805629\n",
      "\tspeed: 0.0416s/iter; left time: 585.1509s\n",
      "\titers: 500, epoch: 5 | loss: 0.0772669\n",
      "\tspeed: 0.0416s/iter; left time: 581.4584s\n",
      "\titers: 600, epoch: 5 | loss: 0.0835028\n",
      "\tspeed: 0.0417s/iter; left time: 578.4996s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755597\n",
      "\tspeed: 0.0416s/iter; left time: 572.9308s\n",
      "\titers: 800, epoch: 5 | loss: 0.0821126\n",
      "\tspeed: 0.0416s/iter; left time: 568.7943s\n",
      "\titers: 900, epoch: 5 | loss: 0.0793681\n",
      "\tspeed: 0.0416s/iter; left time: 564.5852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0794752 Vali Loss: 0.0815711 Test Loss: 0.0942506\n",
      "Validation loss decreased (0.082442 --> 0.081571).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839607\n",
      "\tspeed: 0.1165s/iter; left time: 1567.7003s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795517\n",
      "\tspeed: 0.0415s/iter; left time: 554.9614s\n",
      "\titers: 300, epoch: 6 | loss: 0.0796291\n",
      "\tspeed: 0.0415s/iter; left time: 550.9057s\n",
      "\titers: 400, epoch: 6 | loss: 0.0740407\n",
      "\tspeed: 0.0416s/iter; left time: 547.3535s\n",
      "\titers: 500, epoch: 6 | loss: 0.0732674\n",
      "\tspeed: 0.0415s/iter; left time: 542.0746s\n",
      "\titers: 600, epoch: 6 | loss: 0.0717258\n",
      "\tspeed: 0.0415s/iter; left time: 538.5073s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781353\n",
      "\tspeed: 0.0415s/iter; left time: 534.3261s\n",
      "\titers: 800, epoch: 6 | loss: 0.0775410\n",
      "\tspeed: 0.0417s/iter; left time: 531.5219s\n",
      "\titers: 900, epoch: 6 | loss: 0.0719830\n",
      "\tspeed: 0.0416s/iter; left time: 527.0386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0759981 Vali Loss: 0.0810199 Test Loss: 0.0920831\n",
      "Validation loss decreased (0.081571 --> 0.081020).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723580\n",
      "\tspeed: 0.1168s/iter; left time: 1467.0508s\n",
      "\titers: 200, epoch: 7 | loss: 0.0775005\n",
      "\tspeed: 0.0416s/iter; left time: 518.2076s\n",
      "\titers: 300, epoch: 7 | loss: 0.0755266\n",
      "\tspeed: 0.0416s/iter; left time: 514.1917s\n",
      "\titers: 400, epoch: 7 | loss: 0.0716491\n",
      "\tspeed: 0.0417s/iter; left time: 510.6866s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726988\n",
      "\tspeed: 0.0417s/iter; left time: 506.4100s\n",
      "\titers: 600, epoch: 7 | loss: 0.0645041\n",
      "\tspeed: 0.0416s/iter; left time: 501.7992s\n",
      "\titers: 700, epoch: 7 | loss: 0.0743607\n",
      "\tspeed: 0.0416s/iter; left time: 497.2485s\n",
      "\titers: 800, epoch: 7 | loss: 0.0622560\n",
      "\tspeed: 0.0417s/iter; left time: 494.2482s\n",
      "\titers: 900, epoch: 7 | loss: 0.0748020\n",
      "\tspeed: 0.0416s/iter; left time: 489.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0728088 Vali Loss: 0.0797380 Test Loss: 0.0911746\n",
      "Validation loss decreased (0.081020 --> 0.079738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803198\n",
      "\tspeed: 0.1169s/iter; left time: 1362.3808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0780065\n",
      "\tspeed: 0.0416s/iter; left time: 480.2506s\n",
      "\titers: 300, epoch: 8 | loss: 0.0705057\n",
      "\tspeed: 0.0416s/iter; left time: 476.4226s\n",
      "\titers: 400, epoch: 8 | loss: 0.0695511\n",
      "\tspeed: 0.0416s/iter; left time: 471.9944s\n",
      "\titers: 500, epoch: 8 | loss: 0.0667554\n",
      "\tspeed: 0.0416s/iter; left time: 467.9705s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727597\n",
      "\tspeed: 0.0416s/iter; left time: 463.7615s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681027\n",
      "\tspeed: 0.0416s/iter; left time: 459.6343s\n",
      "\titers: 800, epoch: 8 | loss: 0.0727258\n",
      "\tspeed: 0.0416s/iter; left time: 455.9461s\n",
      "\titers: 900, epoch: 8 | loss: 0.0665395\n",
      "\tspeed: 0.0416s/iter; left time: 451.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0701697 Vali Loss: 0.0797013 Test Loss: 0.0913741\n",
      "Validation loss decreased (0.079738 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698563\n",
      "\tspeed: 0.1173s/iter; left time: 1260.9097s\n",
      "\titers: 200, epoch: 9 | loss: 0.0712313\n",
      "\tspeed: 0.0416s/iter; left time: 443.3270s\n",
      "\titers: 300, epoch: 9 | loss: 0.0642897\n",
      "\tspeed: 0.0416s/iter; left time: 438.3744s\n",
      "\titers: 400, epoch: 9 | loss: 0.0650743\n",
      "\tspeed: 0.0415s/iter; left time: 433.9851s\n",
      "\titers: 500, epoch: 9 | loss: 0.0677874\n",
      "\tspeed: 0.0416s/iter; left time: 430.0534s\n",
      "\titers: 600, epoch: 9 | loss: 0.0642288\n",
      "\tspeed: 0.0417s/iter; left time: 426.9064s\n",
      "\titers: 700, epoch: 9 | loss: 0.0613472\n",
      "\tspeed: 0.0417s/iter; left time: 423.0093s\n",
      "\titers: 800, epoch: 9 | loss: 0.0655759\n",
      "\tspeed: 0.0416s/iter; left time: 418.0862s\n",
      "\titers: 900, epoch: 9 | loss: 0.0630118\n",
      "\tspeed: 0.0416s/iter; left time: 413.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0675159 Vali Loss: 0.0817569 Test Loss: 0.0939381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0707889\n",
      "\tspeed: 0.1139s/iter; left time: 1121.5378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0646257\n",
      "\tspeed: 0.0416s/iter; left time: 404.9200s\n",
      "\titers: 300, epoch: 10 | loss: 0.0597870\n",
      "\tspeed: 0.0416s/iter; left time: 400.9223s\n",
      "\titers: 400, epoch: 10 | loss: 0.0606851\n",
      "\tspeed: 0.0416s/iter; left time: 396.6420s\n",
      "\titers: 500, epoch: 10 | loss: 0.0722949\n",
      "\tspeed: 0.0416s/iter; left time: 392.6873s\n",
      "\titers: 600, epoch: 10 | loss: 0.0613441\n",
      "\tspeed: 0.0416s/iter; left time: 388.6736s\n",
      "\titers: 700, epoch: 10 | loss: 0.0637856\n",
      "\tspeed: 0.0415s/iter; left time: 384.0569s\n",
      "\titers: 800, epoch: 10 | loss: 0.0674466\n",
      "\tspeed: 0.0416s/iter; left time: 379.9879s\n",
      "\titers: 900, epoch: 10 | loss: 0.0660359\n",
      "\tspeed: 0.0416s/iter; left time: 375.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0650114 Vali Loss: 0.0814649 Test Loss: 0.0932802\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628955\n",
      "\tspeed: 0.1127s/iter; left time: 1008.0033s\n",
      "\titers: 200, epoch: 11 | loss: 0.0667712\n",
      "\tspeed: 0.0415s/iter; left time: 367.2613s\n",
      "\titers: 300, epoch: 11 | loss: 0.0622564\n",
      "\tspeed: 0.0416s/iter; left time: 363.2537s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667247\n",
      "\tspeed: 0.0416s/iter; left time: 359.2532s\n",
      "\titers: 500, epoch: 11 | loss: 0.0588989\n",
      "\tspeed: 0.0415s/iter; left time: 354.7833s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601503\n",
      "\tspeed: 0.0416s/iter; left time: 350.7901s\n",
      "\titers: 700, epoch: 11 | loss: 0.0651884\n",
      "\tspeed: 0.0416s/iter; left time: 346.7569s\n",
      "\titers: 800, epoch: 11 | loss: 0.0648965\n",
      "\tspeed: 0.0416s/iter; left time: 342.6994s\n",
      "\titers: 900, epoch: 11 | loss: 0.0662556\n",
      "\tspeed: 0.0416s/iter; left time: 338.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0628507 Vali Loss: 0.0824759 Test Loss: 0.0953183\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586193\n",
      "\tspeed: 0.1130s/iter; left time: 908.5539s\n",
      "\titers: 200, epoch: 12 | loss: 0.0632593\n",
      "\tspeed: 0.0416s/iter; left time: 329.8416s\n",
      "\titers: 300, epoch: 12 | loss: 0.0581805\n",
      "\tspeed: 0.0416s/iter; left time: 325.7241s\n",
      "\titers: 400, epoch: 12 | loss: 0.0527286\n",
      "\tspeed: 0.0416s/iter; left time: 321.5225s\n",
      "\titers: 500, epoch: 12 | loss: 0.0617137\n",
      "\tspeed: 0.0416s/iter; left time: 317.4147s\n",
      "\titers: 600, epoch: 12 | loss: 0.0588900\n",
      "\tspeed: 0.0416s/iter; left time: 313.2914s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644570\n",
      "\tspeed: 0.0417s/iter; left time: 309.8406s\n",
      "\titers: 800, epoch: 12 | loss: 0.0602104\n",
      "\tspeed: 0.0417s/iter; left time: 305.8512s\n",
      "\titers: 900, epoch: 12 | loss: 0.0594495\n",
      "\tspeed: 0.0416s/iter; left time: 301.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0606359 Vali Loss: 0.0830488 Test Loss: 0.0953343\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596162\n",
      "\tspeed: 0.1130s/iter; left time: 806.0487s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571232\n",
      "\tspeed: 0.0416s/iter; left time: 292.3219s\n",
      "\titers: 300, epoch: 13 | loss: 0.0555218\n",
      "\tspeed: 0.0415s/iter; left time: 287.8518s\n",
      "\titers: 400, epoch: 13 | loss: 0.0576127\n",
      "\tspeed: 0.0415s/iter; left time: 283.6851s\n",
      "\titers: 500, epoch: 13 | loss: 0.0613527\n",
      "\tspeed: 0.0415s/iter; left time: 279.6292s\n",
      "\titers: 600, epoch: 13 | loss: 0.0561092\n",
      "\tspeed: 0.0415s/iter; left time: 275.5358s\n",
      "\titers: 700, epoch: 13 | loss: 0.0549113\n",
      "\tspeed: 0.0415s/iter; left time: 271.2652s\n",
      "\titers: 800, epoch: 13 | loss: 0.0601151\n",
      "\tspeed: 0.0415s/iter; left time: 267.0093s\n",
      "\titers: 900, epoch: 13 | loss: 0.0564174\n",
      "\tspeed: 0.0415s/iter; left time: 262.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0588037 Vali Loss: 0.0848033 Test Loss: 0.0960292\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022316191345453262, rmse:0.14938604831695557, mae:0.09133996814489365, rse:0.5648447275161743\n",
      "Original data scale mse:3587957.25, rmse:1894.1904296875, mae:1209.4962158203125, rse:0.13330191373825073\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2292959\n",
      "\tspeed: 0.0436s/iter; left time: 784.4314s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081810\n",
      "\tspeed: 0.0415s/iter; left time: 742.3908s\n",
      "\titers: 300, epoch: 1 | loss: 0.2096158\n",
      "\tspeed: 0.0415s/iter; left time: 738.3307s\n",
      "\titers: 400, epoch: 1 | loss: 0.2077726\n",
      "\tspeed: 0.0416s/iter; left time: 734.9492s\n",
      "\titers: 500, epoch: 1 | loss: 0.1998558\n",
      "\tspeed: 0.0416s/iter; left time: 731.0103s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957197\n",
      "\tspeed: 0.0416s/iter; left time: 727.4164s\n",
      "\titers: 700, epoch: 1 | loss: 0.1891191\n",
      "\tspeed: 0.0416s/iter; left time: 723.2605s\n",
      "\titers: 800, epoch: 1 | loss: 0.1786730\n",
      "\tspeed: 0.0416s/iter; left time: 718.6975s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799013\n",
      "\tspeed: 0.0417s/iter; left time: 715.6068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.2049319 Vali Loss: 0.1680077 Test Loss: 0.1860517\n",
      "Validation loss decreased (inf --> 0.168008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652640\n",
      "\tspeed: 0.1172s/iter; left time: 2000.7531s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542776\n",
      "\tspeed: 0.0416s/iter; left time: 705.5053s\n",
      "\titers: 300, epoch: 2 | loss: 0.1318608\n",
      "\tspeed: 0.0416s/iter; left time: 701.3330s\n",
      "\titers: 400, epoch: 2 | loss: 0.1279899\n",
      "\tspeed: 0.0415s/iter; left time: 696.5773s\n",
      "\titers: 500, epoch: 2 | loss: 0.1211760\n",
      "\tspeed: 0.0416s/iter; left time: 693.3474s\n",
      "\titers: 600, epoch: 2 | loss: 0.1045376\n",
      "\tspeed: 0.0415s/iter; left time: 688.4711s\n",
      "\titers: 700, epoch: 2 | loss: 0.1058448\n",
      "\tspeed: 0.0416s/iter; left time: 684.6972s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937553\n",
      "\tspeed: 0.0416s/iter; left time: 680.5882s\n",
      "\titers: 900, epoch: 2 | loss: 0.0992664\n",
      "\tspeed: 0.0415s/iter; left time: 676.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.1267896 Vali Loss: 0.0913177 Test Loss: 0.0968462\n",
      "Validation loss decreased (0.168008 --> 0.091318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0841759\n",
      "\tspeed: 0.1158s/iter; left time: 1873.2858s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893953\n",
      "\tspeed: 0.0416s/iter; left time: 669.0539s\n",
      "\titers: 300, epoch: 3 | loss: 0.0954204\n",
      "\tspeed: 0.0416s/iter; left time: 664.5233s\n",
      "\titers: 400, epoch: 3 | loss: 0.1050853\n",
      "\tspeed: 0.0416s/iter; left time: 660.1259s\n",
      "\titers: 500, epoch: 3 | loss: 0.0887890\n",
      "\tspeed: 0.0416s/iter; left time: 656.1868s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911384\n",
      "\tspeed: 0.0416s/iter; left time: 652.0109s\n",
      "\titers: 700, epoch: 3 | loss: 0.0956997\n",
      "\tspeed: 0.0416s/iter; left time: 648.1649s\n",
      "\titers: 800, epoch: 3 | loss: 0.0855911\n",
      "\tspeed: 0.0416s/iter; left time: 643.8648s\n",
      "\titers: 900, epoch: 3 | loss: 0.0926109\n",
      "\tspeed: 0.0416s/iter; left time: 639.6259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0894015 Vali Loss: 0.0832333 Test Loss: 0.0903517\n",
      "Validation loss decreased (0.091318 --> 0.083233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.1160s/iter; left time: 1771.7134s\n",
      "\titers: 200, epoch: 4 | loss: 0.0908587\n",
      "\tspeed: 0.0415s/iter; left time: 629.9923s\n",
      "\titers: 300, epoch: 4 | loss: 0.0815956\n",
      "\tspeed: 0.0415s/iter; left time: 626.0588s\n",
      "\titers: 400, epoch: 4 | loss: 0.0794364\n",
      "\tspeed: 0.0416s/iter; left time: 622.1080s\n",
      "\titers: 500, epoch: 4 | loss: 0.0824227\n",
      "\tspeed: 0.0416s/iter; left time: 617.8755s\n",
      "\titers: 600, epoch: 4 | loss: 0.0863480\n",
      "\tspeed: 0.0416s/iter; left time: 614.6422s\n",
      "\titers: 700, epoch: 4 | loss: 0.0751134\n",
      "\tspeed: 0.0415s/iter; left time: 609.2223s\n",
      "\titers: 800, epoch: 4 | loss: 0.0925940\n",
      "\tspeed: 0.0416s/iter; left time: 605.8829s\n",
      "\titers: 900, epoch: 4 | loss: 0.0779531\n",
      "\tspeed: 0.0415s/iter; left time: 600.9640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.0827076 Vali Loss: 0.0849494 Test Loss: 0.0960318\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767040\n",
      "\tspeed: 0.1133s/iter; left time: 1627.2919s\n",
      "\titers: 200, epoch: 5 | loss: 0.0699800\n",
      "\tspeed: 0.0416s/iter; left time: 593.4614s\n",
      "\titers: 300, epoch: 5 | loss: 0.0853455\n",
      "\tspeed: 0.0417s/iter; left time: 589.9893s\n",
      "\titers: 400, epoch: 5 | loss: 0.0704516\n",
      "\tspeed: 0.0416s/iter; left time: 585.7014s\n",
      "\titers: 500, epoch: 5 | loss: 0.0756307\n",
      "\tspeed: 0.0416s/iter; left time: 581.3195s\n",
      "\titers: 600, epoch: 5 | loss: 0.0742427\n",
      "\tspeed: 0.0416s/iter; left time: 577.2092s\n",
      "\titers: 700, epoch: 5 | loss: 0.0752169\n",
      "\tspeed: 0.0417s/iter; left time: 573.5065s\n",
      "\titers: 800, epoch: 5 | loss: 0.0806310\n",
      "\tspeed: 0.0417s/iter; left time: 569.2082s\n",
      "\titers: 900, epoch: 5 | loss: 0.0723156\n",
      "\tspeed: 0.0416s/iter; left time: 564.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0782667 Vali Loss: 0.0774129 Test Loss: 0.0860390\n",
      "Validation loss decreased (0.083233 --> 0.077413).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741043\n",
      "\tspeed: 0.1167s/iter; left time: 1571.4782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707103\n",
      "\tspeed: 0.0415s/iter; left time: 555.0698s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718977\n",
      "\tspeed: 0.0415s/iter; left time: 550.8301s\n",
      "\titers: 400, epoch: 6 | loss: 0.0712616\n",
      "\tspeed: 0.0415s/iter; left time: 546.6244s\n",
      "\titers: 500, epoch: 6 | loss: 0.0730634\n",
      "\tspeed: 0.0415s/iter; left time: 542.5050s\n",
      "\titers: 600, epoch: 6 | loss: 0.0824830\n",
      "\tspeed: 0.0415s/iter; left time: 538.4869s\n",
      "\titers: 700, epoch: 6 | loss: 0.0697925\n",
      "\tspeed: 0.0416s/iter; left time: 534.3990s\n",
      "\titers: 800, epoch: 6 | loss: 0.0703837\n",
      "\tspeed: 0.0415s/iter; left time: 529.9483s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704858\n",
      "\tspeed: 0.0415s/iter; left time: 526.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0749824 Vali Loss: 0.0792238 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748432\n",
      "\tspeed: 0.1137s/iter; left time: 1428.2696s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809488\n",
      "\tspeed: 0.0417s/iter; left time: 519.5531s\n",
      "\titers: 300, epoch: 7 | loss: 0.0747016\n",
      "\tspeed: 0.0416s/iter; left time: 514.5460s\n",
      "\titers: 400, epoch: 7 | loss: 0.0723035\n",
      "\tspeed: 0.0416s/iter; left time: 510.0456s\n",
      "\titers: 500, epoch: 7 | loss: 0.0700389\n",
      "\tspeed: 0.0416s/iter; left time: 505.7433s\n",
      "\titers: 600, epoch: 7 | loss: 0.0682066\n",
      "\tspeed: 0.0417s/iter; left time: 502.3680s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772949\n",
      "\tspeed: 0.0416s/iter; left time: 497.8219s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649828\n",
      "\tspeed: 0.0416s/iter; left time: 493.5770s\n",
      "\titers: 900, epoch: 7 | loss: 0.0713191\n",
      "\tspeed: 0.0416s/iter; left time: 489.6683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0719335 Vali Loss: 0.0794691 Test Loss: 0.0918467\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724586\n",
      "\tspeed: 0.1132s/iter; left time: 1318.6076s\n",
      "\titers: 200, epoch: 8 | loss: 0.0715756\n",
      "\tspeed: 0.0415s/iter; left time: 479.9574s\n",
      "\titers: 300, epoch: 8 | loss: 0.0657794\n",
      "\tspeed: 0.0415s/iter; left time: 475.8581s\n",
      "\titers: 400, epoch: 8 | loss: 0.0654476\n",
      "\tspeed: 0.0415s/iter; left time: 471.5701s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704021\n",
      "\tspeed: 0.0415s/iter; left time: 467.3692s\n",
      "\titers: 600, epoch: 8 | loss: 0.0675833\n",
      "\tspeed: 0.0416s/iter; left time: 463.7433s\n",
      "\titers: 700, epoch: 8 | loss: 0.0698371\n",
      "\tspeed: 0.0417s/iter; left time: 460.4970s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766558\n",
      "\tspeed: 0.0417s/iter; left time: 456.3488s\n",
      "\titers: 900, epoch: 8 | loss: 0.0691651\n",
      "\tspeed: 0.0416s/iter; left time: 451.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0692788 Vali Loss: 0.0809576 Test Loss: 0.0899754\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0643936\n",
      "\tspeed: 0.1139s/iter; left time: 1224.2093s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613265\n",
      "\tspeed: 0.0416s/iter; left time: 443.4043s\n",
      "\titers: 300, epoch: 9 | loss: 0.0656117\n",
      "\tspeed: 0.0416s/iter; left time: 438.8676s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665474\n",
      "\tspeed: 0.0416s/iter; left time: 434.8444s\n",
      "\titers: 500, epoch: 9 | loss: 0.0646721\n",
      "\tspeed: 0.0417s/iter; left time: 431.0723s\n",
      "\titers: 600, epoch: 9 | loss: 0.0673045\n",
      "\tspeed: 0.0416s/iter; left time: 426.7336s\n",
      "\titers: 700, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0416s/iter; left time: 422.3595s\n",
      "\titers: 800, epoch: 9 | loss: 0.0713633\n",
      "\tspeed: 0.0416s/iter; left time: 418.3219s\n",
      "\titers: 900, epoch: 9 | loss: 0.0673369\n",
      "\tspeed: 0.0416s/iter; left time: 413.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0662697 Vali Loss: 0.0811222 Test Loss: 0.0916531\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0716086\n",
      "\tspeed: 0.1139s/iter; left time: 1121.3967s\n",
      "\titers: 200, epoch: 10 | loss: 0.0616231\n",
      "\tspeed: 0.0416s/iter; left time: 405.7231s\n",
      "\titers: 300, epoch: 10 | loss: 0.0624919\n",
      "\tspeed: 0.0416s/iter; left time: 401.6778s\n",
      "\titers: 400, epoch: 10 | loss: 0.0612750\n",
      "\tspeed: 0.0416s/iter; left time: 396.9229s\n",
      "\titers: 500, epoch: 10 | loss: 0.0687094\n",
      "\tspeed: 0.0416s/iter; left time: 392.6401s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689967\n",
      "\tspeed: 0.0416s/iter; left time: 388.3892s\n",
      "\titers: 700, epoch: 10 | loss: 0.0666971\n",
      "\tspeed: 0.0416s/iter; left time: 384.5630s\n",
      "\titers: 800, epoch: 10 | loss: 0.0618813\n",
      "\tspeed: 0.0416s/iter; left time: 380.4564s\n",
      "\titers: 900, epoch: 10 | loss: 0.0615688\n",
      "\tspeed: 0.0416s/iter; left time: 376.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0640776 Vali Loss: 0.0819628 Test Loss: 0.0911019\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019260551780462265, rmse:0.13878239691257477, mae:0.08605317771434784, rse:0.5247511863708496\n",
      "Original data scale mse:3035685.0, rmse:1742.32177734375, mae:1125.773193359375, rse:0.1226142942905426\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2417706\n",
      "\tspeed: 0.0732s/iter; left time: 1313.6734s\n",
      "\titers: 200, epoch: 1 | loss: 0.2105667\n",
      "\tspeed: 0.0502s/iter; left time: 894.7541s\n",
      "\titers: 300, epoch: 1 | loss: 0.2133086\n",
      "\tspeed: 0.0501s/iter; left time: 889.6829s\n",
      "\titers: 400, epoch: 1 | loss: 0.2001980\n",
      "\tspeed: 0.0501s/iter; left time: 884.3414s\n",
      "\titers: 500, epoch: 1 | loss: 0.1996722\n",
      "\tspeed: 0.0502s/iter; left time: 879.6867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957152\n",
      "\tspeed: 0.0502s/iter; left time: 875.2917s\n",
      "\titers: 700, epoch: 1 | loss: 0.1911985\n",
      "\tspeed: 0.0501s/iter; left time: 869.5728s\n",
      "\titers: 800, epoch: 1 | loss: 0.1923567\n",
      "\tspeed: 0.0502s/iter; left time: 865.2195s\n",
      "\titers: 900, epoch: 1 | loss: 0.1911421\n",
      "\tspeed: 0.0502s/iter; left time: 860.4972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.2067105 Vali Loss: 0.1742837 Test Loss: 0.1910858\n",
      "Validation loss decreased (inf --> 0.174284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1741898\n",
      "\tspeed: 0.1404s/iter; left time: 2392.3116s\n",
      "\titers: 200, epoch: 2 | loss: 0.1590756\n",
      "\tspeed: 0.0506s/iter; left time: 857.9386s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492482\n",
      "\tspeed: 0.0505s/iter; left time: 850.1480s\n",
      "\titers: 400, epoch: 2 | loss: 0.1439626\n",
      "\tspeed: 0.0508s/iter; left time: 850.4616s\n",
      "\titers: 500, epoch: 2 | loss: 0.1376841\n",
      "\tspeed: 0.0508s/iter; left time: 845.3795s\n",
      "\titers: 600, epoch: 2 | loss: 0.1318157\n",
      "\tspeed: 0.0508s/iter; left time: 839.8752s\n",
      "\titers: 700, epoch: 2 | loss: 0.1226903\n",
      "\tspeed: 0.0508s/iter; left time: 834.9961s\n",
      "\titers: 800, epoch: 2 | loss: 0.1155013\n",
      "\tspeed: 0.0507s/iter; left time: 827.6535s\n",
      "\titers: 900, epoch: 2 | loss: 0.1036045\n",
      "\tspeed: 0.0507s/iter; left time: 823.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.1425180 Vali Loss: 0.0997220 Test Loss: 0.1080564\n",
      "Validation loss decreased (0.174284 --> 0.099722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1070874\n",
      "\tspeed: 0.1398s/iter; left time: 2256.4475s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982135\n",
      "\tspeed: 0.0504s/iter; left time: 808.1067s\n",
      "\titers: 300, epoch: 3 | loss: 0.0975068\n",
      "\tspeed: 0.0504s/iter; left time: 802.6138s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913634\n",
      "\tspeed: 0.0504s/iter; left time: 797.4300s\n",
      "\titers: 500, epoch: 3 | loss: 0.0938966\n",
      "\tspeed: 0.0503s/iter; left time: 791.4884s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963875\n",
      "\tspeed: 0.0503s/iter; left time: 786.6601s\n",
      "\titers: 700, epoch: 3 | loss: 0.0930466\n",
      "\tspeed: 0.0503s/iter; left time: 781.5806s\n",
      "\titers: 800, epoch: 3 | loss: 0.0894339\n",
      "\tspeed: 0.0503s/iter; left time: 776.8466s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931466\n",
      "\tspeed: 0.0503s/iter; left time: 771.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.67s\n",
      "Steps: 902 | Train Loss: 0.0965498 Vali Loss: 0.0912357 Test Loss: 0.1002337\n",
      "Validation loss decreased (0.099722 --> 0.091236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912320\n",
      "\tspeed: 0.1397s/iter; left time: 2128.0002s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867965\n",
      "\tspeed: 0.0505s/iter; left time: 764.5297s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868980\n",
      "\tspeed: 0.0508s/iter; left time: 763.2987s\n",
      "\titers: 400, epoch: 4 | loss: 0.0909916\n",
      "\tspeed: 0.0508s/iter; left time: 759.0966s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869087\n",
      "\tspeed: 0.0506s/iter; left time: 751.0372s\n",
      "\titers: 600, epoch: 4 | loss: 0.0885214\n",
      "\tspeed: 0.0503s/iter; left time: 741.4114s\n",
      "\titers: 700, epoch: 4 | loss: 0.0855719\n",
      "\tspeed: 0.0503s/iter; left time: 736.5400s\n",
      "\titers: 800, epoch: 4 | loss: 0.0911454\n",
      "\tspeed: 0.0503s/iter; left time: 731.5811s\n",
      "\titers: 900, epoch: 4 | loss: 0.0852361\n",
      "\tspeed: 0.0504s/iter; left time: 728.0232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.0885773 Vali Loss: 0.0855312 Test Loss: 0.0943597\n",
      "Validation loss decreased (0.091236 --> 0.085531).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867432\n",
      "\tspeed: 0.1398s/iter; left time: 2003.7861s\n",
      "\titers: 200, epoch: 5 | loss: 0.0810685\n",
      "\tspeed: 0.0504s/iter; left time: 716.7022s\n",
      "\titers: 300, epoch: 5 | loss: 0.0855442\n",
      "\tspeed: 0.0503s/iter; left time: 710.7386s\n",
      "\titers: 400, epoch: 5 | loss: 0.0874002\n",
      "\tspeed: 0.0503s/iter; left time: 706.4313s\n",
      "\titers: 500, epoch: 5 | loss: 0.0819072\n",
      "\tspeed: 0.0503s/iter; left time: 701.0007s\n",
      "\titers: 600, epoch: 5 | loss: 0.0860219\n",
      "\tspeed: 0.0503s/iter; left time: 695.7446s\n",
      "\titers: 700, epoch: 5 | loss: 0.0811444\n",
      "\tspeed: 0.0503s/iter; left time: 691.2264s\n",
      "\titers: 800, epoch: 5 | loss: 0.0809208\n",
      "\tspeed: 0.0503s/iter; left time: 686.3793s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855082\n",
      "\tspeed: 0.0503s/iter; left time: 680.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.66s\n",
      "Steps: 902 | Train Loss: 0.0836334 Vali Loss: 0.0855765 Test Loss: 0.0958990\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0837307\n",
      "\tspeed: 0.1368s/iter; left time: 1837.7812s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879220\n",
      "\tspeed: 0.0503s/iter; left time: 670.4094s\n",
      "\titers: 300, epoch: 6 | loss: 0.0843503\n",
      "\tspeed: 0.0503s/iter; left time: 665.8380s\n",
      "\titers: 400, epoch: 6 | loss: 0.0791846\n",
      "\tspeed: 0.0503s/iter; left time: 660.8877s\n",
      "\titers: 500, epoch: 6 | loss: 0.0788330\n",
      "\tspeed: 0.0504s/iter; left time: 656.2666s\n",
      "\titers: 600, epoch: 6 | loss: 0.0786551\n",
      "\tspeed: 0.0504s/iter; left time: 651.1553s\n",
      "\titers: 700, epoch: 6 | loss: 0.0774791\n",
      "\tspeed: 0.0503s/iter; left time: 645.0547s\n",
      "\titers: 800, epoch: 6 | loss: 0.0832842\n",
      "\tspeed: 0.0503s/iter; left time: 640.0853s\n",
      "\titers: 900, epoch: 6 | loss: 0.0777149\n",
      "\tspeed: 0.0503s/iter; left time: 634.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.61s\n",
      "Steps: 902 | Train Loss: 0.0799680 Vali Loss: 0.0855314 Test Loss: 0.0941967\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832227\n",
      "\tspeed: 0.1360s/iter; left time: 1704.5641s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769130\n",
      "\tspeed: 0.0504s/iter; left time: 626.0757s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797686\n",
      "\tspeed: 0.0504s/iter; left time: 620.8238s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803033\n",
      "\tspeed: 0.0504s/iter; left time: 615.8619s\n",
      "\titers: 500, epoch: 7 | loss: 0.0713358\n",
      "\tspeed: 0.0504s/iter; left time: 611.4078s\n",
      "\titers: 600, epoch: 7 | loss: 0.0767121\n",
      "\tspeed: 0.0504s/iter; left time: 606.4078s\n",
      "\titers: 700, epoch: 7 | loss: 0.0724495\n",
      "\tspeed: 0.0504s/iter; left time: 601.4697s\n",
      "\titers: 800, epoch: 7 | loss: 0.0772860\n",
      "\tspeed: 0.0503s/iter; left time: 595.1761s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758775\n",
      "\tspeed: 0.0503s/iter; left time: 589.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.68s\n",
      "Steps: 902 | Train Loss: 0.0763688 Vali Loss: 0.0862588 Test Loss: 0.0960034\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746740\n",
      "\tspeed: 0.1361s/iter; left time: 1582.0123s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710704\n",
      "\tspeed: 0.0503s/iter; left time: 579.7476s\n",
      "\titers: 300, epoch: 8 | loss: 0.0767001\n",
      "\tspeed: 0.0503s/iter; left time: 574.4545s\n",
      "\titers: 400, epoch: 8 | loss: 0.0722365\n",
      "\tspeed: 0.0503s/iter; left time: 569.7450s\n",
      "\titers: 500, epoch: 8 | loss: 0.0735169\n",
      "\tspeed: 0.0503s/iter; left time: 564.7603s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702938\n",
      "\tspeed: 0.0503s/iter; left time: 559.6372s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752317\n",
      "\tspeed: 0.0503s/iter; left time: 554.7130s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745411\n",
      "\tspeed: 0.0504s/iter; left time: 550.5014s\n",
      "\titers: 900, epoch: 8 | loss: 0.0704616\n",
      "\tspeed: 0.0504s/iter; left time: 545.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.65s\n",
      "Steps: 902 | Train Loss: 0.0728395 Vali Loss: 0.0874766 Test Loss: 0.0982277\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0669056\n",
      "\tspeed: 0.1367s/iter; left time: 1466.3744s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704915\n",
      "\tspeed: 0.0503s/iter; left time: 534.9016s\n",
      "\titers: 300, epoch: 9 | loss: 0.0730468\n",
      "\tspeed: 0.0504s/iter; left time: 530.0172s\n",
      "\titers: 400, epoch: 9 | loss: 0.0681769\n",
      "\tspeed: 0.0504s/iter; left time: 525.0744s\n",
      "\titers: 500, epoch: 9 | loss: 0.0706938\n",
      "\tspeed: 0.0503s/iter; left time: 519.4402s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717596\n",
      "\tspeed: 0.0503s/iter; left time: 514.7432s\n",
      "\titers: 700, epoch: 9 | loss: 0.0657810\n",
      "\tspeed: 0.0504s/iter; left time: 509.9126s\n",
      "\titers: 800, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0503s/iter; left time: 504.3844s\n",
      "\titers: 900, epoch: 9 | loss: 0.0668692\n",
      "\tspeed: 0.0504s/iter; left time: 500.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 902 | Train Loss: 0.0693792 Vali Loss: 0.0873247 Test Loss: 0.0969773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020803824067115784, rmse:0.14423531293869019, mae:0.09436223655939102, rse:0.5457460880279541\n",
      "Original data scale mse:4198082.0, rmse:2048.922119140625, mae:1319.8297119140625, rse:0.14432641863822937\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2284859\n",
      "\tspeed: 0.0528s/iter; left time: 947.9565s\n",
      "\titers: 200, epoch: 1 | loss: 0.2267227\n",
      "\tspeed: 0.0505s/iter; left time: 901.1121s\n",
      "\titers: 300, epoch: 1 | loss: 0.2108397\n",
      "\tspeed: 0.0507s/iter; left time: 899.8530s\n",
      "\titers: 400, epoch: 1 | loss: 0.2069933\n",
      "\tspeed: 0.0507s/iter; left time: 894.1343s\n",
      "\titers: 500, epoch: 1 | loss: 0.2013356\n",
      "\tspeed: 0.0507s/iter; left time: 890.0209s\n",
      "\titers: 600, epoch: 1 | loss: 0.1998173\n",
      "\tspeed: 0.0507s/iter; left time: 884.9019s\n",
      "\titers: 700, epoch: 1 | loss: 0.1979535\n",
      "\tspeed: 0.0508s/iter; left time: 880.6791s\n",
      "\titers: 800, epoch: 1 | loss: 0.1894962\n",
      "\tspeed: 0.0509s/iter; left time: 878.1609s\n",
      "\titers: 900, epoch: 1 | loss: 0.1864503\n",
      "\tspeed: 0.0510s/iter; left time: 874.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.2082656 Vali Loss: 0.1732536 Test Loss: 0.1907203\n",
      "Validation loss decreased (inf --> 0.173254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1713080\n",
      "\tspeed: 0.1459s/iter; left time: 2486.1602s\n",
      "\titers: 200, epoch: 2 | loss: 0.1709103\n",
      "\tspeed: 0.0508s/iter; left time: 860.4514s\n",
      "\titers: 300, epoch: 2 | loss: 0.1648743\n",
      "\tspeed: 0.0508s/iter; left time: 854.9622s\n",
      "\titers: 400, epoch: 2 | loss: 0.1496821\n",
      "\tspeed: 0.0508s/iter; left time: 850.6620s\n",
      "\titers: 500, epoch: 2 | loss: 0.1361954\n",
      "\tspeed: 0.0508s/iter; left time: 845.3745s\n",
      "\titers: 600, epoch: 2 | loss: 0.1361084\n",
      "\tspeed: 0.0508s/iter; left time: 839.6243s\n",
      "\titers: 700, epoch: 2 | loss: 0.1295184\n",
      "\tspeed: 0.0508s/iter; left time: 834.8571s\n",
      "\titers: 800, epoch: 2 | loss: 0.1168782\n",
      "\tspeed: 0.0508s/iter; left time: 829.9455s\n",
      "\titers: 900, epoch: 2 | loss: 0.1084049\n",
      "\tspeed: 0.0508s/iter; left time: 824.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.1460171 Vali Loss: 0.0987828 Test Loss: 0.1063009\n",
      "Validation loss decreased (0.173254 --> 0.098783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1028040\n",
      "\tspeed: 0.1430s/iter; left time: 2307.4413s\n",
      "\titers: 200, epoch: 3 | loss: 0.1012544\n",
      "\tspeed: 0.0503s/iter; left time: 807.3088s\n",
      "\titers: 300, epoch: 3 | loss: 0.0942322\n",
      "\tspeed: 0.0503s/iter; left time: 802.0428s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913546\n",
      "\tspeed: 0.0503s/iter; left time: 797.3676s\n",
      "\titers: 500, epoch: 3 | loss: 0.0966000\n",
      "\tspeed: 0.0504s/iter; left time: 792.4710s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914325\n",
      "\tspeed: 0.0504s/iter; left time: 787.6114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0900648\n",
      "\tspeed: 0.0503s/iter; left time: 782.1404s\n",
      "\titers: 800, epoch: 3 | loss: 0.0941671\n",
      "\tspeed: 0.0504s/iter; left time: 777.6173s\n",
      "\titers: 900, epoch: 3 | loss: 0.0972075\n",
      "\tspeed: 0.0504s/iter; left time: 772.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0964605 Vali Loss: 0.0890032 Test Loss: 0.0937895\n",
      "Validation loss decreased (0.098783 --> 0.089003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857249\n",
      "\tspeed: 0.1408s/iter; left time: 2145.1603s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923728\n",
      "\tspeed: 0.0504s/iter; left time: 762.7480s\n",
      "\titers: 300, epoch: 4 | loss: 0.0903793\n",
      "\tspeed: 0.0504s/iter; left time: 757.0812s\n",
      "\titers: 400, epoch: 4 | loss: 0.0886440\n",
      "\tspeed: 0.0503s/iter; left time: 750.9803s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932834\n",
      "\tspeed: 0.0503s/iter; left time: 746.6138s\n",
      "\titers: 600, epoch: 4 | loss: 0.0853107\n",
      "\tspeed: 0.0504s/iter; left time: 742.2900s\n",
      "\titers: 700, epoch: 4 | loss: 0.0900107\n",
      "\tspeed: 0.0503s/iter; left time: 735.8664s\n",
      "\titers: 800, epoch: 4 | loss: 0.0842938\n",
      "\tspeed: 0.0503s/iter; left time: 730.7650s\n",
      "\titers: 900, epoch: 4 | loss: 0.0850098\n",
      "\tspeed: 0.0503s/iter; left time: 726.5279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 902 | Train Loss: 0.0881512 Vali Loss: 0.0848641 Test Loss: 0.0966458\n",
      "Validation loss decreased (0.089003 --> 0.084864).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882770\n",
      "\tspeed: 0.1405s/iter; left time: 2014.4634s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824666\n",
      "\tspeed: 0.0504s/iter; left time: 717.1276s\n",
      "\titers: 300, epoch: 5 | loss: 0.0812579\n",
      "\tspeed: 0.0504s/iter; left time: 713.0051s\n",
      "\titers: 400, epoch: 5 | loss: 0.0867619\n",
      "\tspeed: 0.0505s/iter; left time: 708.2942s\n",
      "\titers: 500, epoch: 5 | loss: 0.0906413\n",
      "\tspeed: 0.0504s/iter; left time: 702.6749s\n",
      "\titers: 600, epoch: 5 | loss: 0.0816955\n",
      "\tspeed: 0.0503s/iter; left time: 696.1346s\n",
      "\titers: 700, epoch: 5 | loss: 0.0825760\n",
      "\tspeed: 0.0503s/iter; left time: 690.8054s\n",
      "\titers: 800, epoch: 5 | loss: 0.0871430\n",
      "\tspeed: 0.0503s/iter; left time: 686.2776s\n",
      "\titers: 900, epoch: 5 | loss: 0.0818188\n",
      "\tspeed: 0.0503s/iter; left time: 681.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0832878 Vali Loss: 0.0822736 Test Loss: 0.0991102\n",
      "Validation loss decreased (0.084864 --> 0.082274).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807753\n",
      "\tspeed: 0.1439s/iter; left time: 1932.1154s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926194\n",
      "\tspeed: 0.0508s/iter; left time: 677.6089s\n",
      "\titers: 300, epoch: 6 | loss: 0.0734528\n",
      "\tspeed: 0.0508s/iter; left time: 672.2760s\n",
      "\titers: 400, epoch: 6 | loss: 0.0836199\n",
      "\tspeed: 0.0509s/iter; left time: 667.9432s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807985\n",
      "\tspeed: 0.0508s/iter; left time: 662.2467s\n",
      "\titers: 600, epoch: 6 | loss: 0.0781274\n",
      "\tspeed: 0.0509s/iter; left time: 658.2782s\n",
      "\titers: 700, epoch: 6 | loss: 0.0795121\n",
      "\tspeed: 0.0511s/iter; left time: 655.3439s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790593\n",
      "\tspeed: 0.0508s/iter; left time: 646.2384s\n",
      "\titers: 900, epoch: 6 | loss: 0.0770177\n",
      "\tspeed: 0.0504s/iter; left time: 636.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 902 | Train Loss: 0.0793978 Vali Loss: 0.0833777 Test Loss: 0.0989826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754626\n",
      "\tspeed: 0.1371s/iter; left time: 1717.5762s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837843\n",
      "\tspeed: 0.0505s/iter; left time: 627.0626s\n",
      "\titers: 300, epoch: 7 | loss: 0.0735349\n",
      "\tspeed: 0.0505s/iter; left time: 622.5638s\n",
      "\titers: 400, epoch: 7 | loss: 0.0791819\n",
      "\tspeed: 0.0509s/iter; left time: 621.9647s\n",
      "\titers: 500, epoch: 7 | loss: 0.0693690\n",
      "\tspeed: 0.0508s/iter; left time: 616.5585s\n",
      "\titers: 600, epoch: 7 | loss: 0.0743524\n",
      "\tspeed: 0.0508s/iter; left time: 611.3922s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732933\n",
      "\tspeed: 0.0508s/iter; left time: 606.3508s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761782\n",
      "\tspeed: 0.0508s/iter; left time: 601.3687s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737806\n",
      "\tspeed: 0.0507s/iter; left time: 594.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.0760379 Vali Loss: 0.0858319 Test Loss: 0.0968157\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726987\n",
      "\tspeed: 0.1380s/iter; left time: 1604.0718s\n",
      "\titers: 200, epoch: 8 | loss: 0.0783981\n",
      "\tspeed: 0.0509s/iter; left time: 586.4848s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806944\n",
      "\tspeed: 0.0509s/iter; left time: 581.1668s\n",
      "\titers: 400, epoch: 8 | loss: 0.0715075\n",
      "\tspeed: 0.0509s/iter; left time: 576.2698s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0507s/iter; left time: 569.6230s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702019\n",
      "\tspeed: 0.0505s/iter; left time: 562.2030s\n",
      "\titers: 700, epoch: 8 | loss: 0.0728789\n",
      "\tspeed: 0.0505s/iter; left time: 556.6964s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746686\n",
      "\tspeed: 0.0504s/iter; left time: 551.0053s\n",
      "\titers: 900, epoch: 8 | loss: 0.0702752\n",
      "\tspeed: 0.0509s/iter; left time: 550.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.0726852 Vali Loss: 0.0867959 Test Loss: 0.0998598\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0709978\n",
      "\tspeed: 0.1367s/iter; left time: 1466.3880s\n",
      "\titers: 200, epoch: 9 | loss: 0.0679601\n",
      "\tspeed: 0.0503s/iter; left time: 534.4922s\n",
      "\titers: 300, epoch: 9 | loss: 0.0751877\n",
      "\tspeed: 0.0504s/iter; left time: 530.4816s\n",
      "\titers: 400, epoch: 9 | loss: 0.0699946\n",
      "\tspeed: 0.0509s/iter; left time: 531.0785s\n",
      "\titers: 500, epoch: 9 | loss: 0.0732694\n",
      "\tspeed: 0.0509s/iter; left time: 525.4624s\n",
      "\titers: 600, epoch: 9 | loss: 0.0649203\n",
      "\tspeed: 0.0508s/iter; left time: 519.4839s\n",
      "\titers: 700, epoch: 9 | loss: 0.0642313\n",
      "\tspeed: 0.0504s/iter; left time: 510.6238s\n",
      "\titers: 800, epoch: 9 | loss: 0.0708400\n",
      "\tspeed: 0.0505s/iter; left time: 505.8513s\n",
      "\titers: 900, epoch: 9 | loss: 0.0663069\n",
      "\tspeed: 0.0507s/iter; left time: 502.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 902 | Train Loss: 0.0691620 Vali Loss: 0.0897910 Test Loss: 0.1007773\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0708059\n",
      "\tspeed: 0.1367s/iter; left time: 1342.4807s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699524\n",
      "\tspeed: 0.0505s/iter; left time: 491.4053s\n",
      "\titers: 300, epoch: 10 | loss: 0.0707789\n",
      "\tspeed: 0.0505s/iter; left time: 485.9362s\n",
      "\titers: 400, epoch: 10 | loss: 0.0686859\n",
      "\tspeed: 0.0504s/iter; left time: 480.0881s\n",
      "\titers: 500, epoch: 10 | loss: 0.0652517\n",
      "\tspeed: 0.0504s/iter; left time: 474.6876s\n",
      "\titers: 600, epoch: 10 | loss: 0.0646466\n",
      "\tspeed: 0.0503s/iter; left time: 469.2621s\n",
      "\titers: 700, epoch: 10 | loss: 0.0682247\n",
      "\tspeed: 0.0505s/iter; left time: 465.4389s\n",
      "\titers: 800, epoch: 10 | loss: 0.0651449\n",
      "\tspeed: 0.0504s/iter; left time: 460.1285s\n",
      "\titers: 900, epoch: 10 | loss: 0.0604966\n",
      "\tspeed: 0.0504s/iter; left time: 454.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0659150 Vali Loss: 0.0909240 Test Loss: 0.1030022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023398978635668755, rmse:0.15296724438667297, mae:0.09908542037010193, rse:0.578785240650177\n",
      "Original data scale mse:5321987.5, rmse:2306.943359375, mae:1452.3974609375, rse:0.1625014841556549\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.4145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.4322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.5648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.5457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.5788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0111  0.1055  0.0649  0.3989\n",
       "              2         24        0.0115  0.1073  0.0672  0.4054\n",
       "              1         96        0.0195  0.1395  0.0926  0.5276\n",
       "              2         96        0.0187  0.1366  0.0904  0.5165\n",
       "              1         168       0.0212  0.1455  0.0975  0.5507\n",
       "              2         168       0.0205  0.1433  0.0957  0.5423\n",
       "MAE           1         24        0.0120  0.1097  0.0642  0.4145\n",
       "              2         24        0.0131  0.1144  0.0672  0.4322\n",
       "              1         96        0.0223  0.1494  0.0913  0.5648\n",
       "              2         96        0.0193  0.1388  0.0861  0.5248\n",
       "              1         168       0.0208  0.1442  0.0944  0.5457\n",
       "              2         168       0.0234  0.1530  0.0991  0.5788"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/choice'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_IT_default.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_IT_default.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1800234.625</td>\n",
       "      <td>1341.7283</td>\n",
       "      <td>865.4649</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1954150.750</td>\n",
       "      <td>1397.9094</td>\n",
       "      <td>902.0552</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>4252090.500</td>\n",
       "      <td>2062.0598</td>\n",
       "      <td>1342.6979</td>\n",
       "      <td>0.1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3400539.250</td>\n",
       "      <td>1844.0551</td>\n",
       "      <td>1237.2542</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4480882.500</td>\n",
       "      <td>2116.8096</td>\n",
       "      <td>1392.9763</td>\n",
       "      <td>0.1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4692489.500</td>\n",
       "      <td>2166.2156</td>\n",
       "      <td>1400.1951</td>\n",
       "      <td>0.1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1767036.250</td>\n",
       "      <td>1329.2992</td>\n",
       "      <td>813.9424</td>\n",
       "      <td>0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1968128.250</td>\n",
       "      <td>1402.8999</td>\n",
       "      <td>857.3510</td>\n",
       "      <td>0.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3587957.250</td>\n",
       "      <td>1894.1904</td>\n",
       "      <td>1209.4962</td>\n",
       "      <td>0.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3035685.000</td>\n",
       "      <td>1742.3218</td>\n",
       "      <td>1125.7732</td>\n",
       "      <td>0.1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4198082.000</td>\n",
       "      <td>2048.9221</td>\n",
       "      <td>1319.8297</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>5321987.500</td>\n",
       "      <td>2306.9434</td>\n",
       "      <td>1452.3975</td>\n",
       "      <td>0.1625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1800234.625  1341.7283   865.4649  0.0943\n",
       "              2         24        1954150.750  1397.9094   902.0552  0.0982\n",
       "              1         96        4252090.500  2062.0598  1342.6979  0.1451\n",
       "              2         96        3400539.250  1844.0551  1237.2542  0.1298\n",
       "              1         168       4480882.500  2116.8096  1392.9763  0.1491\n",
       "              2         168       4692489.500  2166.2156  1400.1951  0.1526\n",
       "MAE           1         24        1767036.250  1329.2992   813.9424  0.0934\n",
       "              2         24        1968128.250  1402.8999   857.3510  0.0986\n",
       "              1         96        3587957.250  1894.1904  1209.4962  0.1333\n",
       "              2         96        3035685.000  1742.3218  1125.7732  0.1226\n",
       "              1         168       4198082.000  2048.9221  1319.8297  0.1443\n",
       "              2         168       5321987.500  2306.9434  1452.3975  0.1625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.4234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.5448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>0.5465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0126  0.1120  0.0657  0.4234\n",
       "         MSE            0.0113  0.1064  0.0660  0.4021\n",
       "96       MAE            0.0208  0.1441  0.0887  0.5448\n",
       "         MSE            0.0191  0.1381  0.0915  0.5220\n",
       "168      MAE            0.0221  0.1486  0.0967  0.5623\n",
       "         MSE            0.0209  0.1444  0.0966  0.5465"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.867582e+06</td>\n",
       "      <td>1366.0995</td>\n",
       "      <td>835.6467</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.877193e+06</td>\n",
       "      <td>1369.8188</td>\n",
       "      <td>883.7600</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.311821e+06</td>\n",
       "      <td>1818.2561</td>\n",
       "      <td>1167.6347</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.826315e+06</td>\n",
       "      <td>1953.0574</td>\n",
       "      <td>1289.9760</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.760035e+06</td>\n",
       "      <td>2177.9327</td>\n",
       "      <td>1386.1136</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.586686e+06</td>\n",
       "      <td>2141.5126</td>\n",
       "      <td>1396.5857</td>\n",
       "      <td>0.1508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.867582e+06  1366.0995   835.6467  0.0960\n",
       "         MSE            1.877193e+06  1369.8188   883.7600  0.0963\n",
       "96       MAE            3.311821e+06  1818.2561  1167.6347  0.1280\n",
       "         MSE            3.826315e+06  1953.0574  1289.9760  0.1374\n",
       "168      MAE            4.760035e+06  2177.9327  1386.1136  0.1534\n",
       "         MSE            4.586686e+06  2141.5126  1396.5857  0.1508"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0413237\n",
      "\tspeed: 0.0276s/iter; left time: 493.3919s\n",
      "\titers: 200, epoch: 1 | loss: 0.0414541\n",
      "\tspeed: 0.0085s/iter; left time: 150.4297s\n",
      "\titers: 300, epoch: 1 | loss: 0.0285089\n",
      "\tspeed: 0.0084s/iter; left time: 148.5445s\n",
      "\titers: 400, epoch: 1 | loss: 0.0265078\n",
      "\tspeed: 0.0092s/iter; left time: 161.0160s\n",
      "\titers: 500, epoch: 1 | loss: 0.0218464\n",
      "\tspeed: 0.0090s/iter; left time: 156.5956s\n",
      "\titers: 600, epoch: 1 | loss: 0.0222217\n",
      "\tspeed: 0.0093s/iter; left time: 162.1676s\n",
      "\titers: 700, epoch: 1 | loss: 0.0154518\n",
      "\tspeed: 0.0088s/iter; left time: 152.6253s\n",
      "\titers: 800, epoch: 1 | loss: 0.0177985\n",
      "\tspeed: 0.0087s/iter; left time: 149.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 899 | Train Loss: 0.0290097 Vali Loss: 0.0152752 Test Loss: 0.0163119\n",
      "Validation loss decreased (inf --> 0.015275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0136534\n",
      "\tspeed: 0.0425s/iter; left time: 721.3045s\n",
      "\titers: 200, epoch: 2 | loss: 0.0114735\n",
      "\tspeed: 0.0091s/iter; left time: 153.3956s\n",
      "\titers: 300, epoch: 2 | loss: 0.0111327\n",
      "\tspeed: 0.0089s/iter; left time: 148.9291s\n",
      "\titers: 400, epoch: 2 | loss: 0.0120504\n",
      "\tspeed: 0.0089s/iter; left time: 148.5904s\n",
      "\titers: 500, epoch: 2 | loss: 0.0108678\n",
      "\tspeed: 0.0088s/iter; left time: 146.7289s\n",
      "\titers: 600, epoch: 2 | loss: 0.0103024\n",
      "\tspeed: 0.0089s/iter; left time: 145.9708s\n",
      "\titers: 700, epoch: 2 | loss: 0.0141001\n",
      "\tspeed: 0.0089s/iter; left time: 145.2946s\n",
      "\titers: 800, epoch: 2 | loss: 0.0117266\n",
      "\tspeed: 0.0089s/iter; left time: 144.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 899 | Train Loss: 0.0120037 Vali Loss: 0.0097826 Test Loss: 0.0110079\n",
      "Validation loss decreased (0.015275 --> 0.009783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0098456\n",
      "\tspeed: 0.0416s/iter; left time: 668.6402s\n",
      "\titers: 200, epoch: 3 | loss: 0.0075604\n",
      "\tspeed: 0.0095s/iter; left time: 151.3982s\n",
      "\titers: 300, epoch: 3 | loss: 0.0114860\n",
      "\tspeed: 0.0094s/iter; left time: 149.6419s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099784\n",
      "\tspeed: 0.0094s/iter; left time: 147.6390s\n",
      "\titers: 500, epoch: 3 | loss: 0.0119271\n",
      "\tspeed: 0.0091s/iter; left time: 143.3371s\n",
      "\titers: 600, epoch: 3 | loss: 0.0117871\n",
      "\tspeed: 0.0091s/iter; left time: 142.2485s\n",
      "\titers: 700, epoch: 3 | loss: 0.0101010\n",
      "\tspeed: 0.0091s/iter; left time: 141.3762s\n",
      "\titers: 800, epoch: 3 | loss: 0.0133711\n",
      "\tspeed: 0.0091s/iter; left time: 140.6210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 899 | Train Loss: 0.0101975 Vali Loss: 0.0093790 Test Loss: 0.0105155\n",
      "Validation loss decreased (0.009783 --> 0.009379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0073917\n",
      "\tspeed: 0.0422s/iter; left time: 640.9111s\n",
      "\titers: 200, epoch: 4 | loss: 0.0073908\n",
      "\tspeed: 0.0094s/iter; left time: 142.0920s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 300, epoch: 4 | loss: 0.0091413\n",
      "\tspeed: 0.0092s/iter; left time: 137.9772s\n",
      "\titers: 400, epoch: 4 | loss: 0.0086968\n",
      "\tspeed: 0.0092s/iter; left time: 136.6427s\n",
      "\titers: 500, epoch: 4 | loss: 0.0107999\n",
      "\tspeed: 0.0092s/iter; left time: 135.5690s\n",
      "\titers: 600, epoch: 4 | loss: 0.0097379\n",
      "\tspeed: 0.0092s/iter; left time: 135.0998s\n",
      "\titers: 700, epoch: 4 | loss: 0.0107894\n",
      "\tspeed: 0.0090s/iter; left time: 131.9590s\n",
      "\titers: 800, epoch: 4 | loss: 0.0073125\n",
      "\tspeed: 0.0089s/iter; left time: 129.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 899 | Train Loss: 0.0096880 Vali Loss: 0.0092516 Test Loss: 0.0103331\n",
      "Validation loss decreased (0.009379 --> 0.009252).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0096844\n",
      "\tspeed: 0.0415s/iter; left time: 593.1690s\n",
      "\titers: 200, epoch: 5 | loss: 0.0078026\n",
      "\tspeed: 0.0095s/iter; left time: 134.6578s\n",
      "\titers: 300, epoch: 5 | loss: 0.0086012\n",
      "\tspeed: 0.0093s/iter; left time: 131.5254s\n",
      "\titers: 400, epoch: 5 | loss: 0.0126800\n",
      "\tspeed: 0.0092s/iter; left time: 128.3189s\n",
      "\titers: 500, epoch: 5 | loss: 0.0090665\n",
      "\tspeed: 0.0090s/iter; left time: 125.4942s\n",
      "\titers: 600, epoch: 5 | loss: 0.0123089\n",
      "\tspeed: 0.0090s/iter; left time: 124.1171s\n",
      "\titers: 700, epoch: 5 | loss: 0.0082816\n",
      "\tspeed: 0.0089s/iter; left time: 122.3315s\n",
      "\titers: 800, epoch: 5 | loss: 0.0101382\n",
      "\tspeed: 0.0090s/iter; left time: 121.6168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 899 | Train Loss: 0.0093300 Vali Loss: 0.0091703 Test Loss: 0.0104352\n",
      "Validation loss decreased (0.009252 --> 0.009170).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0072891\n",
      "\tspeed: 0.0429s/iter; left time: 574.8042s\n",
      "\titers: 200, epoch: 6 | loss: 0.0090648\n",
      "\tspeed: 0.0090s/iter; left time: 120.0340s\n",
      "\titers: 300, epoch: 6 | loss: 0.0072006\n",
      "\tspeed: 0.0090s/iter; left time: 119.1711s\n",
      "\titers: 400, epoch: 6 | loss: 0.0072824\n",
      "\tspeed: 0.0089s/iter; left time: 115.8278s\n",
      "\titers: 500, epoch: 6 | loss: 0.0076218\n",
      "\tspeed: 0.0087s/iter; left time: 113.1597s\n",
      "\titers: 600, epoch: 6 | loss: 0.0096684\n",
      "\tspeed: 0.0087s/iter; left time: 112.3384s\n",
      "\titers: 700, epoch: 6 | loss: 0.0085068\n",
      "\tspeed: 0.0087s/iter; left time: 111.2732s\n",
      "\titers: 800, epoch: 6 | loss: 0.0084411\n",
      "\tspeed: 0.0087s/iter; left time: 110.4844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 899 | Train Loss: 0.0090898 Vali Loss: 0.0088536 Test Loss: 0.0100814\n",
      "Validation loss decreased (0.009170 --> 0.008854).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0080898\n",
      "\tspeed: 0.0468s/iter; left time: 584.0147s\n",
      "\titers: 200, epoch: 7 | loss: 0.0062180\n",
      "\tspeed: 0.0093s/iter; left time: 114.6533s\n",
      "\titers: 300, epoch: 7 | loss: 0.0102000\n",
      "\tspeed: 0.0092s/iter; left time: 113.6140s\n",
      "\titers: 400, epoch: 7 | loss: 0.0071945\n",
      "\tspeed: 0.0092s/iter; left time: 112.5650s\n",
      "\titers: 500, epoch: 7 | loss: 0.0104952\n",
      "\tspeed: 0.0093s/iter; left time: 112.0681s\n",
      "\titers: 600, epoch: 7 | loss: 0.0089398\n",
      "\tspeed: 0.0092s/iter; left time: 110.6133s\n",
      "\titers: 700, epoch: 7 | loss: 0.0074714\n",
      "\tspeed: 0.0092s/iter; left time: 109.6183s\n",
      "\titers: 800, epoch: 7 | loss: 0.0082831\n",
      "\tspeed: 0.0092s/iter; left time: 108.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 899 | Train Loss: 0.0088810 Vali Loss: 0.0088497 Test Loss: 0.0100632\n",
      "Validation loss decreased (0.008854 --> 0.008850).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0094553\n",
      "\tspeed: 0.0411s/iter; left time: 476.5607s\n",
      "\titers: 200, epoch: 8 | loss: 0.0093104\n",
      "\tspeed: 0.0095s/iter; left time: 109.4518s\n",
      "\titers: 300, epoch: 8 | loss: 0.0083308\n",
      "\tspeed: 0.0095s/iter; left time: 108.3439s\n",
      "\titers: 400, epoch: 8 | loss: 0.0087013\n",
      "\tspeed: 0.0096s/iter; left time: 108.0634s\n",
      "\titers: 500, epoch: 8 | loss: 0.0098523\n",
      "\tspeed: 0.0101s/iter; left time: 113.1528s\n",
      "\titers: 600, epoch: 8 | loss: 0.0096529\n",
      "\tspeed: 0.0101s/iter; left time: 112.1443s\n",
      "\titers: 700, epoch: 8 | loss: 0.0089142\n",
      "\tspeed: 0.0101s/iter; left time: 110.9870s\n",
      "\titers: 800, epoch: 8 | loss: 0.0084799\n",
      "\tspeed: 0.0101s/iter; left time: 110.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 899 | Train Loss: 0.0087289 Vali Loss: 0.0086975 Test Loss: 0.0099730\n",
      "Validation loss decreased (0.008850 --> 0.008698).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0081330\n",
      "\tspeed: 0.0430s/iter; left time: 459.6534s\n",
      "\titers: 200, epoch: 9 | loss: 0.0101716\n",
      "\tspeed: 0.0092s/iter; left time: 97.1949s\n",
      "\titers: 300, epoch: 9 | loss: 0.0093692\n",
      "\tspeed: 0.0092s/iter; left time: 96.4265s\n",
      "\titers: 400, epoch: 9 | loss: 0.0091461\n",
      "\tspeed: 0.0091s/iter; left time: 94.6873s\n",
      "\titers: 500, epoch: 9 | loss: 0.0086185\n",
      "\tspeed: 0.0099s/iter; left time: 102.1393s\n",
      "\titers: 600, epoch: 9 | loss: 0.0096975\n",
      "\tspeed: 0.0101s/iter; left time: 102.9243s\n",
      "\titers: 700, epoch: 9 | loss: 0.0075101\n",
      "\tspeed: 0.0101s/iter; left time: 102.0009s\n",
      "\titers: 800, epoch: 9 | loss: 0.0120186\n",
      "\tspeed: 0.0101s/iter; left time: 101.1261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 899 | Train Loss: 0.0085823 Vali Loss: 0.0088245 Test Loss: 0.0100443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0062453\n",
      "\tspeed: 0.0428s/iter; left time: 419.0432s\n",
      "\titers: 200, epoch: 10 | loss: 0.0094335\n",
      "\tspeed: 0.0091s/iter; left time: 88.2953s\n",
      "\titers: 300, epoch: 10 | loss: 0.0088109\n",
      "\tspeed: 0.0091s/iter; left time: 87.7309s\n",
      "\titers: 400, epoch: 10 | loss: 0.0098260\n",
      "\tspeed: 0.0091s/iter; left time: 86.7761s\n",
      "\titers: 500, epoch: 10 | loss: 0.0095931\n",
      "\tspeed: 0.0091s/iter; left time: 85.7518s\n",
      "\titers: 600, epoch: 10 | loss: 0.0066524\n",
      "\tspeed: 0.0091s/iter; left time: 84.8640s\n",
      "\titers: 700, epoch: 10 | loss: 0.0085678\n",
      "\tspeed: 0.0091s/iter; left time: 83.9501s\n",
      "\titers: 800, epoch: 10 | loss: 0.0091673\n",
      "\tspeed: 0.0091s/iter; left time: 83.1701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 899 | Train Loss: 0.0084647 Vali Loss: 0.0087832 Test Loss: 0.0100974\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0070756\n",
      "\tspeed: 0.0399s/iter; left time: 354.3147s\n",
      "\titers: 200, epoch: 11 | loss: 0.0079320\n",
      "\tspeed: 0.0091s/iter; left time: 79.9625s\n",
      "\titers: 300, epoch: 11 | loss: 0.0066546\n",
      "\tspeed: 0.0091s/iter; left time: 79.0327s\n",
      "\titers: 400, epoch: 11 | loss: 0.0093616\n",
      "\tspeed: 0.0091s/iter; left time: 78.1313s\n",
      "\titers: 500, epoch: 11 | loss: 0.0078648\n",
      "\tspeed: 0.0087s/iter; left time: 74.0565s\n",
      "\titers: 600, epoch: 11 | loss: 0.0069537\n",
      "\tspeed: 0.0088s/iter; left time: 73.6524s\n",
      "\titers: 700, epoch: 11 | loss: 0.0077616\n",
      "\tspeed: 0.0091s/iter; left time: 75.2913s\n",
      "\titers: 800, epoch: 11 | loss: 0.0083379\n",
      "\tspeed: 0.0091s/iter; left time: 74.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 899 | Train Loss: 0.0083475 Vali Loss: 0.0087222 Test Loss: 0.0100768\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0091521\n",
      "\tspeed: 0.0406s/iter; left time: 324.2523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0088016\n",
      "\tspeed: 0.0092s/iter; left time: 72.9015s\n",
      "\titers: 300, epoch: 12 | loss: 0.0093956\n",
      "\tspeed: 0.0092s/iter; left time: 72.0480s\n",
      "\titers: 400, epoch: 12 | loss: 0.0077337\n",
      "\tspeed: 0.0092s/iter; left time: 71.1224s\n",
      "\titers: 500, epoch: 12 | loss: 0.0097963\n",
      "\tspeed: 0.0092s/iter; left time: 70.1374s\n",
      "\titers: 600, epoch: 12 | loss: 0.0104249\n",
      "\tspeed: 0.0093s/iter; left time: 69.3223s\n",
      "\titers: 700, epoch: 12 | loss: 0.0088897\n",
      "\tspeed: 0.0092s/iter; left time: 68.2935s\n",
      "\titers: 800, epoch: 12 | loss: 0.0087337\n",
      "\tspeed: 0.0092s/iter; left time: 67.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 899 | Train Loss: 0.0082537 Vali Loss: 0.0086827 Test Loss: 0.0100157\n",
      "Validation loss decreased (0.008698 --> 0.008683).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0087175\n",
      "\tspeed: 0.0401s/iter; left time: 284.7488s\n",
      "\titers: 200, epoch: 13 | loss: 0.0090104\n",
      "\tspeed: 0.0093s/iter; left time: 65.0953s\n",
      "\titers: 300, epoch: 13 | loss: 0.0064992\n",
      "\tspeed: 0.0092s/iter; left time: 63.5576s\n",
      "\titers: 400, epoch: 13 | loss: 0.0084727\n",
      "\tspeed: 0.0092s/iter; left time: 62.7125s\n",
      "\titers: 500, epoch: 13 | loss: 0.0116350\n",
      "\tspeed: 0.0092s/iter; left time: 61.7100s\n",
      "\titers: 600, epoch: 13 | loss: 0.0067212\n",
      "\tspeed: 0.0092s/iter; left time: 60.9334s\n",
      "\titers: 700, epoch: 13 | loss: 0.0095413\n",
      "\tspeed: 0.0095s/iter; left time: 61.6002s\n",
      "\titers: 800, epoch: 13 | loss: 0.0113080\n",
      "\tspeed: 0.0095s/iter; left time: 60.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 899 | Train Loss: 0.0081539 Vali Loss: 0.0086791 Test Loss: 0.0101022\n",
      "Validation loss decreased (0.008683 --> 0.008679).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0121584\n",
      "\tspeed: 0.0405s/iter; left time: 250.8368s\n",
      "\titers: 200, epoch: 14 | loss: 0.0076806\n",
      "\tspeed: 0.0091s/iter; left time: 55.6462s\n",
      "\titers: 300, epoch: 14 | loss: 0.0081299\n",
      "\tspeed: 0.0091s/iter; left time: 54.7270s\n",
      "\titers: 400, epoch: 14 | loss: 0.0088007\n",
      "\tspeed: 0.0091s/iter; left time: 53.7907s\n",
      "\titers: 500, epoch: 14 | loss: 0.0091158\n",
      "\tspeed: 0.0091s/iter; left time: 52.9929s\n",
      "\titers: 600, epoch: 14 | loss: 0.0119706\n",
      "\tspeed: 0.0091s/iter; left time: 51.9350s\n",
      "\titers: 700, epoch: 14 | loss: 0.0083168\n",
      "\tspeed: 0.0093s/iter; left time: 51.7935s\n",
      "\titers: 800, epoch: 14 | loss: 0.0091508\n",
      "\tspeed: 0.0094s/iter; left time: 51.6489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 899 | Train Loss: 0.0080760 Vali Loss: 0.0087160 Test Loss: 0.0101824\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0092121\n",
      "\tspeed: 0.0418s/iter; left time: 221.1039s\n",
      "\titers: 200, epoch: 15 | loss: 0.0080515\n",
      "\tspeed: 0.0102s/iter; left time: 52.8171s\n",
      "\titers: 300, epoch: 15 | loss: 0.0059927\n",
      "\tspeed: 0.0101s/iter; left time: 51.5542s\n",
      "\titers: 400, epoch: 15 | loss: 0.0074688\n",
      "\tspeed: 0.0101s/iter; left time: 50.5271s\n",
      "\titers: 500, epoch: 15 | loss: 0.0062001\n",
      "\tspeed: 0.0101s/iter; left time: 49.5644s\n",
      "\titers: 600, epoch: 15 | loss: 0.0080330\n",
      "\tspeed: 0.0101s/iter; left time: 48.5602s\n",
      "\titers: 700, epoch: 15 | loss: 0.0090243\n",
      "\tspeed: 0.0095s/iter; left time: 44.7847s\n",
      "\titers: 800, epoch: 15 | loss: 0.0060183\n",
      "\tspeed: 0.0092s/iter; left time: 42.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 899 | Train Loss: 0.0079891 Vali Loss: 0.0087264 Test Loss: 0.0102271\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0111088\n",
      "\tspeed: 0.0415s/iter; left time: 182.3943s\n",
      "\titers: 200, epoch: 16 | loss: 0.0085510\n",
      "\tspeed: 0.0103s/iter; left time: 44.0369s\n",
      "\titers: 300, epoch: 16 | loss: 0.0071232\n",
      "\tspeed: 0.0102s/iter; left time: 42.9789s\n",
      "\titers: 400, epoch: 16 | loss: 0.0085175\n",
      "\tspeed: 0.0102s/iter; left time: 41.9794s\n",
      "\titers: 500, epoch: 16 | loss: 0.0081388\n",
      "\tspeed: 0.0102s/iter; left time: 40.8142s\n",
      "\titers: 600, epoch: 16 | loss: 0.0060266\n",
      "\tspeed: 0.0103s/iter; left time: 40.1013s\n",
      "\titers: 700, epoch: 16 | loss: 0.0076079\n",
      "\tspeed: 0.0102s/iter; left time: 38.6101s\n",
      "\titers: 800, epoch: 16 | loss: 0.0086670\n",
      "\tspeed: 0.0102s/iter; left time: 37.6509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 899 | Train Loss: 0.0079399 Vali Loss: 0.0087578 Test Loss: 0.0101511\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0088305\n",
      "\tspeed: 0.0423s/iter; left time: 148.0085s\n",
      "\titers: 200, epoch: 17 | loss: 0.0079235\n",
      "\tspeed: 0.0095s/iter; left time: 32.1669s\n",
      "\titers: 300, epoch: 17 | loss: 0.0065094\n",
      "\tspeed: 0.0095s/iter; left time: 31.1996s\n",
      "\titers: 400, epoch: 17 | loss: 0.0106381\n",
      "\tspeed: 0.0095s/iter; left time: 30.2750s\n",
      "\titers: 500, epoch: 17 | loss: 0.0084176\n",
      "\tspeed: 0.0095s/iter; left time: 29.3107s\n",
      "\titers: 600, epoch: 17 | loss: 0.0118364\n",
      "\tspeed: 0.0095s/iter; left time: 28.3723s\n",
      "\titers: 700, epoch: 17 | loss: 0.0051764\n",
      "\tspeed: 0.0092s/iter; left time: 26.6506s\n",
      "\titers: 800, epoch: 17 | loss: 0.0083824\n",
      "\tspeed: 0.0091s/iter; left time: 25.5806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 899 | Train Loss: 0.0078595 Vali Loss: 0.0087325 Test Loss: 0.0101260\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0075427\n",
      "\tspeed: 0.0405s/iter; left time: 105.1964s\n",
      "\titers: 200, epoch: 18 | loss: 0.0101333\n",
      "\tspeed: 0.0093s/iter; left time: 23.1611s\n",
      "\titers: 300, epoch: 18 | loss: 0.0083734\n",
      "\tspeed: 0.0093s/iter; left time: 22.2297s\n",
      "\titers: 400, epoch: 18 | loss: 0.0057559\n",
      "\tspeed: 0.0093s/iter; left time: 21.2999s\n",
      "\titers: 500, epoch: 18 | loss: 0.0062597\n",
      "\tspeed: 0.0095s/iter; left time: 20.8109s\n",
      "\titers: 600, epoch: 18 | loss: 0.0088781\n",
      "\tspeed: 0.0095s/iter; left time: 19.8689s\n",
      "\titers: 700, epoch: 18 | loss: 0.0090721\n",
      "\tspeed: 0.0095s/iter; left time: 18.9094s\n",
      "\titers: 800, epoch: 18 | loss: 0.0083109\n",
      "\tspeed: 0.0095s/iter; left time: 17.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 899 | Train Loss: 0.0078222 Vali Loss: 0.0087182 Test Loss: 0.0101631\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010102159343659878, rmse:0.10050950199365616, mae:0.058577075600624084, rse:0.3798324465751648\n",
      "Original data scale mse:1228456.75, rmse:1108.357666015625, mae:708.9411010742188, rse:0.0778869092464447\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0415009\n",
      "\tspeed: 0.0117s/iter; left time: 209.8297s\n",
      "\titers: 200, epoch: 1 | loss: 0.0344580\n",
      "\tspeed: 0.0092s/iter; left time: 163.3153s\n",
      "\titers: 300, epoch: 1 | loss: 0.0247920\n",
      "\tspeed: 0.0092s/iter; left time: 162.2558s\n",
      "\titers: 400, epoch: 1 | loss: 0.0305651\n",
      "\tspeed: 0.0092s/iter; left time: 161.3182s\n",
      "\titers: 500, epoch: 1 | loss: 0.0234488\n",
      "\tspeed: 0.0092s/iter; left time: 160.1950s\n",
      "\titers: 600, epoch: 1 | loss: 0.0222586\n",
      "\tspeed: 0.0092s/iter; left time: 159.5163s\n",
      "\titers: 700, epoch: 1 | loss: 0.0220230\n",
      "\tspeed: 0.0092s/iter; left time: 158.6204s\n",
      "\titers: 800, epoch: 1 | loss: 0.0168002\n",
      "\tspeed: 0.0092s/iter; left time: 157.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 899 | Train Loss: 0.0272510 Vali Loss: 0.0147291 Test Loss: 0.0158004\n",
      "Validation loss decreased (inf --> 0.014729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0146216\n",
      "\tspeed: 0.0416s/iter; left time: 706.6760s\n",
      "\titers: 200, epoch: 2 | loss: 0.0145285\n",
      "\tspeed: 0.0102s/iter; left time: 172.9955s\n",
      "\titers: 300, epoch: 2 | loss: 0.0133755\n",
      "\tspeed: 0.0102s/iter; left time: 172.0013s\n",
      "\titers: 400, epoch: 2 | loss: 0.0155739\n",
      "\tspeed: 0.0103s/iter; left time: 171.3744s\n",
      "\titers: 500, epoch: 2 | loss: 0.0136027\n",
      "\tspeed: 0.0102s/iter; left time: 169.2956s\n",
      "\titers: 600, epoch: 2 | loss: 0.0109570\n",
      "\tspeed: 0.0103s/iter; left time: 169.0518s\n",
      "\titers: 700, epoch: 2 | loss: 0.0105813\n",
      "\tspeed: 0.0102s/iter; left time: 167.6814s\n",
      "\titers: 800, epoch: 2 | loss: 0.0133829\n",
      "\tspeed: 0.0102s/iter; left time: 166.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 899 | Train Loss: 0.0119088 Vali Loss: 0.0096034 Test Loss: 0.0108491\n",
      "Validation loss decreased (0.014729 --> 0.009603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0151471\n",
      "\tspeed: 0.0419s/iter; left time: 673.7946s\n",
      "\titers: 200, epoch: 3 | loss: 0.0111740\n",
      "\tspeed: 0.0094s/iter; left time: 150.5970s\n",
      "\titers: 300, epoch: 3 | loss: 0.0096942\n",
      "\tspeed: 0.0094s/iter; left time: 149.3601s\n",
      "\titers: 400, epoch: 3 | loss: 0.0102352\n",
      "\tspeed: 0.0095s/iter; left time: 149.1990s\n",
      "\titers: 500, epoch: 3 | loss: 0.0100074\n",
      "\tspeed: 0.0094s/iter; left time: 147.7901s\n",
      "\titers: 600, epoch: 3 | loss: 0.0110882\n",
      "\tspeed: 0.0094s/iter; left time: 146.6421s\n",
      "\titers: 700, epoch: 3 | loss: 0.0099761\n",
      "\tspeed: 0.0094s/iter; left time: 145.9698s\n",
      "\titers: 800, epoch: 3 | loss: 0.0114810\n",
      "\tspeed: 0.0094s/iter; left time: 144.8150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 899 | Train Loss: 0.0101256 Vali Loss: 0.0093043 Test Loss: 0.0105520\n",
      "Validation loss decreased (0.009603 --> 0.009304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0126124\n",
      "\tspeed: 0.0423s/iter; left time: 642.0890s\n",
      "\titers: 200, epoch: 4 | loss: 0.0092959\n",
      "\tspeed: 0.0095s/iter; left time: 143.0038s\n",
      "\titers: 300, epoch: 4 | loss: 0.0110300\n",
      "\tspeed: 0.0095s/iter; left time: 141.9473s\n",
      "\titers: 400, epoch: 4 | loss: 0.0075942\n",
      "\tspeed: 0.0095s/iter; left time: 140.7349s\n",
      "\titers: 500, epoch: 4 | loss: 0.0087605\n",
      "\tspeed: 0.0095s/iter; left time: 139.8263s\n",
      "\titers: 600, epoch: 4 | loss: 0.0119146\n",
      "\tspeed: 0.0095s/iter; left time: 138.9141s\n",
      "\titers: 700, epoch: 4 | loss: 0.0090441\n",
      "\tspeed: 0.0095s/iter; left time: 137.8215s\n",
      "\titers: 800, epoch: 4 | loss: 0.0100713\n",
      "\tspeed: 0.0095s/iter; left time: 137.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 899 | Train Loss: 0.0096276 Vali Loss: 0.0091371 Test Loss: 0.0103543\n",
      "Validation loss decreased (0.009304 --> 0.009137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0092584\n",
      "\tspeed: 0.0416s/iter; left time: 594.3077s\n",
      "\titers: 200, epoch: 5 | loss: 0.0076918\n",
      "\tspeed: 0.0095s/iter; left time: 135.3035s\n",
      "\titers: 300, epoch: 5 | loss: 0.0086921\n",
      "\tspeed: 0.0094s/iter; left time: 132.6245s\n",
      "\titers: 400, epoch: 5 | loss: 0.0075587\n",
      "\tspeed: 0.0093s/iter; left time: 129.5732s\n",
      "\titers: 500, epoch: 5 | loss: 0.0071826\n",
      "\tspeed: 0.0093s/iter; left time: 128.5606s\n",
      "\titers: 600, epoch: 5 | loss: 0.0092770\n",
      "\tspeed: 0.0092s/iter; left time: 127.3279s\n",
      "\titers: 700, epoch: 5 | loss: 0.0105744\n",
      "\tspeed: 0.0094s/iter; left time: 129.2282s\n",
      "\titers: 800, epoch: 5 | loss: 0.0088191\n",
      "\tspeed: 0.0095s/iter; left time: 129.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 899 | Train Loss: 0.0092682 Vali Loss: 0.0091192 Test Loss: 0.0103921\n",
      "Validation loss decreased (0.009137 --> 0.009119).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0091213\n",
      "\tspeed: 0.0422s/iter; left time: 565.1184s\n",
      "\titers: 200, epoch: 6 | loss: 0.0089234\n",
      "\tspeed: 0.0089s/iter; left time: 117.7008s\n",
      "\titers: 300, epoch: 6 | loss: 0.0063323\n",
      "\tspeed: 0.0088s/iter; left time: 116.4698s\n",
      "\titers: 400, epoch: 6 | loss: 0.0086634\n",
      "\tspeed: 0.0088s/iter; left time: 115.3737s\n",
      "\titers: 500, epoch: 6 | loss: 0.0094096\n",
      "\tspeed: 0.0088s/iter; left time: 114.4562s\n",
      "\titers: 600, epoch: 6 | loss: 0.0072102\n",
      "\tspeed: 0.0088s/iter; left time: 113.6146s\n",
      "\titers: 700, epoch: 6 | loss: 0.0092353\n",
      "\tspeed: 0.0088s/iter; left time: 113.0175s\n",
      "\titers: 800, epoch: 6 | loss: 0.0080888\n",
      "\tspeed: 0.0088s/iter; left time: 111.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 899 | Train Loss: 0.0090314 Vali Loss: 0.0090171 Test Loss: 0.0101453\n",
      "Validation loss decreased (0.009119 --> 0.009017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0085121\n",
      "\tspeed: 0.0421s/iter; left time: 525.6054s\n",
      "\titers: 200, epoch: 7 | loss: 0.0089289\n",
      "\tspeed: 0.0096s/iter; left time: 118.3099s\n",
      "\titers: 300, epoch: 7 | loss: 0.0113468\n",
      "\tspeed: 0.0095s/iter; left time: 117.3024s\n",
      "\titers: 400, epoch: 7 | loss: 0.0106317\n",
      "\tspeed: 0.0104s/iter; left time: 126.3214s\n",
      "\titers: 500, epoch: 7 | loss: 0.0092540\n",
      "\tspeed: 0.0105s/iter; left time: 126.4195s\n",
      "\titers: 600, epoch: 7 | loss: 0.0110762\n",
      "\tspeed: 0.0102s/iter; left time: 121.8603s\n",
      "\titers: 700, epoch: 7 | loss: 0.0102775\n",
      "\tspeed: 0.0105s/iter; left time: 125.3057s\n",
      "\titers: 800, epoch: 7 | loss: 0.0087572\n",
      "\tspeed: 0.0105s/iter; left time: 124.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 899 | Train Loss: 0.0088528 Vali Loss: 0.0089632 Test Loss: 0.0101337\n",
      "Validation loss decreased (0.009017 --> 0.008963).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0093254\n",
      "\tspeed: 0.0424s/iter; left time: 490.9805s\n",
      "\titers: 200, epoch: 8 | loss: 0.0068411\n",
      "\tspeed: 0.0095s/iter; left time: 109.4577s\n",
      "\titers: 300, epoch: 8 | loss: 0.0097055\n",
      "\tspeed: 0.0094s/iter; left time: 106.7430s\n",
      "\titers: 400, epoch: 8 | loss: 0.0128793\n",
      "\tspeed: 0.0093s/iter; left time: 104.6036s\n",
      "\titers: 500, epoch: 8 | loss: 0.0060271\n",
      "\tspeed: 0.0099s/iter; left time: 110.8160s\n",
      "\titers: 600, epoch: 8 | loss: 0.0104464\n",
      "\tspeed: 0.0103s/iter; left time: 114.2917s\n",
      "\titers: 700, epoch: 8 | loss: 0.0105392\n",
      "\tspeed: 0.0092s/iter; left time: 101.6011s\n",
      "\titers: 800, epoch: 8 | loss: 0.0105891\n",
      "\tspeed: 0.0094s/iter; left time: 102.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.87s\n",
      "Steps: 899 | Train Loss: 0.0086577 Vali Loss: 0.0088969 Test Loss: 0.0102191\n",
      "Validation loss decreased (0.008963 --> 0.008897).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0088366\n",
      "\tspeed: 0.0423s/iter; left time: 451.7896s\n",
      "\titers: 200, epoch: 9 | loss: 0.0075752\n",
      "\tspeed: 0.0093s/iter; left time: 98.0714s\n",
      "\titers: 300, epoch: 9 | loss: 0.0084537\n",
      "\tspeed: 0.0093s/iter; left time: 97.5993s\n",
      "\titers: 400, epoch: 9 | loss: 0.0092094\n",
      "\tspeed: 0.0096s/iter; left time: 99.3772s\n",
      "\titers: 500, epoch: 9 | loss: 0.0077626\n",
      "\tspeed: 0.0096s/iter; left time: 98.8048s\n",
      "\titers: 600, epoch: 9 | loss: 0.0064675\n",
      "\tspeed: 0.0094s/iter; left time: 95.5858s\n",
      "\titers: 700, epoch: 9 | loss: 0.0082963\n",
      "\tspeed: 0.0092s/iter; left time: 93.2542s\n",
      "\titers: 800, epoch: 9 | loss: 0.0077893\n",
      "\tspeed: 0.0098s/iter; left time: 98.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 899 | Train Loss: 0.0085119 Vali Loss: 0.0087606 Test Loss: 0.0101671\n",
      "Validation loss decreased (0.008897 --> 0.008761).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0135799\n",
      "\tspeed: 0.0416s/iter; left time: 407.0635s\n",
      "\titers: 200, epoch: 10 | loss: 0.0058949\n",
      "\tspeed: 0.0094s/iter; left time: 91.5534s\n",
      "\titers: 300, epoch: 10 | loss: 0.0082264\n",
      "\tspeed: 0.0094s/iter; left time: 90.5568s\n",
      "\titers: 400, epoch: 10 | loss: 0.0071504\n",
      "\tspeed: 0.0095s/iter; left time: 90.2198s\n",
      "\titers: 500, epoch: 10 | loss: 0.0081966\n",
      "\tspeed: 0.0095s/iter; left time: 89.1718s\n",
      "\titers: 600, epoch: 10 | loss: 0.0093315\n",
      "\tspeed: 0.0095s/iter; left time: 88.2847s\n",
      "\titers: 700, epoch: 10 | loss: 0.0092644\n",
      "\tspeed: 0.0095s/iter; left time: 87.5660s\n",
      "\titers: 800, epoch: 10 | loss: 0.0059195\n",
      "\tspeed: 0.0095s/iter; left time: 86.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 899 | Train Loss: 0.0083808 Vali Loss: 0.0089173 Test Loss: 0.0100723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0088349\n",
      "\tspeed: 0.0417s/iter; left time: 370.4746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0063182\n",
      "\tspeed: 0.0095s/iter; left time: 83.6608s\n",
      "\titers: 300, epoch: 11 | loss: 0.0054283\n",
      "\tspeed: 0.0095s/iter; left time: 82.5382s\n",
      "\titers: 400, epoch: 11 | loss: 0.0071630\n",
      "\tspeed: 0.0095s/iter; left time: 81.5287s\n",
      "\titers: 500, epoch: 11 | loss: 0.0082714\n",
      "\tspeed: 0.0095s/iter; left time: 80.5742s\n",
      "\titers: 600, epoch: 11 | loss: 0.0093781\n",
      "\tspeed: 0.0095s/iter; left time: 79.5577s\n",
      "\titers: 700, epoch: 11 | loss: 0.0057505\n",
      "\tspeed: 0.0095s/iter; left time: 79.0762s\n",
      "\titers: 800, epoch: 11 | loss: 0.0074048\n",
      "\tspeed: 0.0095s/iter; left time: 78.0777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 899 | Train Loss: 0.0082523 Vali Loss: 0.0086974 Test Loss: 0.0101020\n",
      "Validation loss decreased (0.008761 --> 0.008697).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0086718\n",
      "\tspeed: 0.0415s/iter; left time: 331.7807s\n",
      "\titers: 200, epoch: 12 | loss: 0.0062837\n",
      "\tspeed: 0.0092s/iter; left time: 72.6445s\n",
      "\titers: 300, epoch: 12 | loss: 0.0078317\n",
      "\tspeed: 0.0092s/iter; left time: 71.7810s\n",
      "\titers: 400, epoch: 12 | loss: 0.0099886\n",
      "\tspeed: 0.0092s/iter; left time: 71.1287s\n",
      "\titers: 500, epoch: 12 | loss: 0.0094134\n",
      "\tspeed: 0.0092s/iter; left time: 69.9108s\n",
      "\titers: 600, epoch: 12 | loss: 0.0063468\n",
      "\tspeed: 0.0092s/iter; left time: 69.0611s\n",
      "\titers: 700, epoch: 12 | loss: 0.0057591\n",
      "\tspeed: 0.0092s/iter; left time: 68.0285s\n",
      "\titers: 800, epoch: 12 | loss: 0.0092164\n",
      "\tspeed: 0.0092s/iter; left time: 67.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 899 | Train Loss: 0.0081688 Vali Loss: 0.0087948 Test Loss: 0.0101655\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0079934\n",
      "\tspeed: 0.0421s/iter; left time: 298.6353s\n",
      "\titers: 200, epoch: 13 | loss: 0.0071650\n",
      "\tspeed: 0.0091s/iter; left time: 63.9298s\n",
      "\titers: 300, epoch: 13 | loss: 0.0113882\n",
      "\tspeed: 0.0091s/iter; left time: 62.9708s\n",
      "\titers: 400, epoch: 13 | loss: 0.0083338\n",
      "\tspeed: 0.0092s/iter; left time: 62.1578s\n",
      "\titers: 500, epoch: 13 | loss: 0.0077826\n",
      "\tspeed: 0.0091s/iter; left time: 61.2011s\n",
      "\titers: 600, epoch: 13 | loss: 0.0079092\n",
      "\tspeed: 0.0090s/iter; left time: 59.0495s\n",
      "\titers: 700, epoch: 13 | loss: 0.0059979\n",
      "\tspeed: 0.0089s/iter; left time: 58.0410s\n",
      "\titers: 800, epoch: 13 | loss: 0.0081334\n",
      "\tspeed: 0.0090s/iter; left time: 57.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 899 | Train Loss: 0.0080797 Vali Loss: 0.0087895 Test Loss: 0.0101927\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0075320\n",
      "\tspeed: 0.0424s/iter; left time: 262.9084s\n",
      "\titers: 200, epoch: 14 | loss: 0.0061758\n",
      "\tspeed: 0.0096s/iter; left time: 58.4884s\n",
      "\titers: 300, epoch: 14 | loss: 0.0058848\n",
      "\tspeed: 0.0098s/iter; left time: 58.5921s\n",
      "\titers: 400, epoch: 14 | loss: 0.0056462\n",
      "\tspeed: 0.0106s/iter; left time: 62.4435s\n",
      "\titers: 500, epoch: 14 | loss: 0.0067110\n",
      "\tspeed: 0.0105s/iter; left time: 60.8955s\n",
      "\titers: 600, epoch: 14 | loss: 0.0097151\n",
      "\tspeed: 0.0106s/iter; left time: 60.1175s\n",
      "\titers: 700, epoch: 14 | loss: 0.0060353\n",
      "\tspeed: 0.0104s/iter; left time: 58.3260s\n",
      "\titers: 800, epoch: 14 | loss: 0.0074301\n",
      "\tspeed: 0.0105s/iter; left time: 57.8346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 899 | Train Loss: 0.0079805 Vali Loss: 0.0087329 Test Loss: 0.0101960\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0104310\n",
      "\tspeed: 0.0435s/iter; left time: 230.1353s\n",
      "\titers: 200, epoch: 15 | loss: 0.0087383\n",
      "\tspeed: 0.0093s/iter; left time: 48.1885s\n",
      "\titers: 300, epoch: 15 | loss: 0.0066411\n",
      "\tspeed: 0.0093s/iter; left time: 47.5159s\n",
      "\titers: 400, epoch: 15 | loss: 0.0062273\n",
      "\tspeed: 0.0093s/iter; left time: 46.5449s\n",
      "\titers: 500, epoch: 15 | loss: 0.0096768\n",
      "\tspeed: 0.0093s/iter; left time: 45.3646s\n",
      "\titers: 600, epoch: 15 | loss: 0.0085998\n",
      "\tspeed: 0.0093s/iter; left time: 44.6399s\n",
      "\titers: 700, epoch: 15 | loss: 0.0105915\n",
      "\tspeed: 0.0093s/iter; left time: 43.4849s\n",
      "\titers: 800, epoch: 15 | loss: 0.0076461\n",
      "\tspeed: 0.0092s/iter; left time: 42.3814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 899 | Train Loss: 0.0079334 Vali Loss: 0.0086786 Test Loss: 0.0101763\n",
      "Validation loss decreased (0.008697 --> 0.008679).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0065256\n",
      "\tspeed: 0.0426s/iter; left time: 187.3496s\n",
      "\titers: 200, epoch: 16 | loss: 0.0079687\n",
      "\tspeed: 0.0093s/iter; left time: 39.8431s\n",
      "\titers: 300, epoch: 16 | loss: 0.0054691\n",
      "\tspeed: 0.0093s/iter; left time: 39.0659s\n",
      "\titers: 400, epoch: 16 | loss: 0.0058038\n",
      "\tspeed: 0.0093s/iter; left time: 38.0946s\n",
      "\titers: 500, epoch: 16 | loss: 0.0071522\n",
      "\tspeed: 0.0093s/iter; left time: 37.1665s\n",
      "\titers: 600, epoch: 16 | loss: 0.0065418\n",
      "\tspeed: 0.0092s/iter; left time: 35.9231s\n",
      "\titers: 700, epoch: 16 | loss: 0.0083437\n",
      "\tspeed: 0.0093s/iter; left time: 35.1711s\n",
      "\titers: 800, epoch: 16 | loss: 0.0060881\n",
      "\tspeed: 0.0092s/iter; left time: 34.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 899 | Train Loss: 0.0078319 Vali Loss: 0.0087790 Test Loss: 0.0102591\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0072123\n",
      "\tspeed: 0.0416s/iter; left time: 145.3579s\n",
      "\titers: 200, epoch: 17 | loss: 0.0093641\n",
      "\tspeed: 0.0105s/iter; left time: 35.7865s\n",
      "\titers: 300, epoch: 17 | loss: 0.0082678\n",
      "\tspeed: 0.0105s/iter; left time: 34.7188s\n",
      "\titers: 400, epoch: 17 | loss: 0.0073109\n",
      "\tspeed: 0.0105s/iter; left time: 33.6737s\n",
      "\titers: 500, epoch: 17 | loss: 0.0078265\n",
      "\tspeed: 0.0105s/iter; left time: 32.6053s\n",
      "\titers: 600, epoch: 17 | loss: 0.0062618\n",
      "\tspeed: 0.0105s/iter; left time: 31.5704s\n",
      "\titers: 700, epoch: 17 | loss: 0.0087713\n",
      "\tspeed: 0.0105s/iter; left time: 30.4986s\n",
      "\titers: 800, epoch: 17 | loss: 0.0082345\n",
      "\tspeed: 0.0105s/iter; left time: 29.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 899 | Train Loss: 0.0078189 Vali Loss: 0.0087418 Test Loss: 0.0102824\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0078857\n",
      "\tspeed: 0.0426s/iter; left time: 110.7062s\n",
      "\titers: 200, epoch: 18 | loss: 0.0081035\n",
      "\tspeed: 0.0093s/iter; left time: 23.1671s\n",
      "\titers: 300, epoch: 18 | loss: 0.0105089\n",
      "\tspeed: 0.0093s/iter; left time: 22.2439s\n",
      "\titers: 400, epoch: 18 | loss: 0.0091981\n",
      "\tspeed: 0.0093s/iter; left time: 21.4298s\n",
      "\titers: 500, epoch: 18 | loss: 0.0057106\n",
      "\tspeed: 0.0093s/iter; left time: 20.3601s\n",
      "\titers: 600, epoch: 18 | loss: 0.0059395\n",
      "\tspeed: 0.0093s/iter; left time: 19.4442s\n",
      "\titers: 700, epoch: 18 | loss: 0.0074403\n",
      "\tspeed: 0.0093s/iter; left time: 18.5157s\n",
      "\titers: 800, epoch: 18 | loss: 0.0073986\n",
      "\tspeed: 0.0093s/iter; left time: 17.5853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 899 | Train Loss: 0.0077683 Vali Loss: 0.0087517 Test Loss: 0.0102656\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0072900\n",
      "\tspeed: 0.0410s/iter; left time: 69.6651s\n",
      "\titers: 200, epoch: 19 | loss: 0.0064446\n",
      "\tspeed: 0.0095s/iter; left time: 15.1297s\n",
      "\titers: 300, epoch: 19 | loss: 0.0083038\n",
      "\tspeed: 0.0095s/iter; left time: 14.2668s\n",
      "\titers: 400, epoch: 19 | loss: 0.0090917\n",
      "\tspeed: 0.0092s/iter; left time: 12.8647s\n",
      "\titers: 500, epoch: 19 | loss: 0.0085713\n",
      "\tspeed: 0.0092s/iter; left time: 11.9350s\n",
      "\titers: 600, epoch: 19 | loss: 0.0081188\n",
      "\tspeed: 0.0092s/iter; left time: 11.0090s\n",
      "\titers: 700, epoch: 19 | loss: 0.0062718\n",
      "\tspeed: 0.0091s/iter; left time: 10.0543s\n",
      "\titers: 800, epoch: 19 | loss: 0.0058901\n",
      "\tspeed: 0.0092s/iter; left time: 9.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 899 | Train Loss: 0.0076955 Vali Loss: 0.0087305 Test Loss: 0.0102221\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0086147\n",
      "\tspeed: 0.0409s/iter; left time: 32.7323s\n",
      "\titers: 200, epoch: 20 | loss: 0.0081086\n",
      "\tspeed: 0.0106s/iter; left time: 7.4145s\n",
      "\titers: 300, epoch: 20 | loss: 0.0093738\n",
      "\tspeed: 0.0106s/iter; left time: 6.3507s\n",
      "\titers: 400, epoch: 20 | loss: 0.0053410\n",
      "\tspeed: 0.0106s/iter; left time: 5.2944s\n",
      "\titers: 500, epoch: 20 | loss: 0.0083254\n",
      "\tspeed: 0.0106s/iter; left time: 4.2328s\n",
      "\titers: 600, epoch: 20 | loss: 0.0076163\n",
      "\tspeed: 0.0107s/iter; left time: 3.1954s\n",
      "\titers: 700, epoch: 20 | loss: 0.0060676\n",
      "\tspeed: 0.0105s/iter; left time: 2.1053s\n",
      "\titers: 800, epoch: 20 | loss: 0.0058397\n",
      "\tspeed: 0.0105s/iter; left time: 1.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 899 | Train Loss: 0.0076554 Vali Loss: 0.0087764 Test Loss: 0.0102847\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010176287963986397, rmse:0.10087759047746658, mae:0.05809824913740158, rse:0.3812234401702881\n",
      "Original data scale mse:1194382.0, rmse:1092.8778076171875, mae:695.2028198242188, rse:0.07679910212755203\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0480819\n",
      "\tspeed: 0.0275s/iter; left time: 491.3573s\n",
      "\titers: 200, epoch: 1 | loss: 0.0362830\n",
      "\tspeed: 0.0103s/iter; left time: 182.9322s\n",
      "\titers: 300, epoch: 1 | loss: 0.0315535\n",
      "\tspeed: 0.0089s/iter; left time: 156.2572s\n",
      "\titers: 400, epoch: 1 | loss: 0.0292785\n",
      "\tspeed: 0.0087s/iter; left time: 152.9962s\n",
      "\titers: 500, epoch: 1 | loss: 0.0285411\n",
      "\tspeed: 0.0087s/iter; left time: 151.5378s\n",
      "\titers: 600, epoch: 1 | loss: 0.0276110\n",
      "\tspeed: 0.0087s/iter; left time: 151.6371s\n",
      "\titers: 700, epoch: 1 | loss: 0.0258704\n",
      "\tspeed: 0.0088s/iter; left time: 152.4710s\n",
      "\titers: 800, epoch: 1 | loss: 0.0305075\n",
      "\tspeed: 0.0088s/iter; left time: 151.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 897 | Train Loss: 0.0331523 Vali Loss: 0.0207013 Test Loss: 0.0222523\n",
      "Validation loss decreased (inf --> 0.020701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0217432\n",
      "\tspeed: 0.0414s/iter; left time: 701.9945s\n",
      "\titers: 200, epoch: 2 | loss: 0.0179301\n",
      "\tspeed: 0.0088s/iter; left time: 148.8399s\n",
      "\titers: 300, epoch: 2 | loss: 0.0170268\n",
      "\tspeed: 0.0088s/iter; left time: 147.6362s\n",
      "\titers: 400, epoch: 2 | loss: 0.0191909\n",
      "\tspeed: 0.0088s/iter; left time: 147.2785s\n",
      "\titers: 500, epoch: 2 | loss: 0.0192400\n",
      "\tspeed: 0.0088s/iter; left time: 145.7273s\n",
      "\titers: 600, epoch: 2 | loss: 0.0160726\n",
      "\tspeed: 0.0088s/iter; left time: 144.3248s\n",
      "\titers: 700, epoch: 2 | loss: 0.0145650\n",
      "\tspeed: 0.0088s/iter; left time: 143.5858s\n",
      "\titers: 800, epoch: 2 | loss: 0.0174475\n",
      "\tspeed: 0.0088s/iter; left time: 142.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 897 | Train Loss: 0.0190503 Vali Loss: 0.0162434 Test Loss: 0.0181442\n",
      "Validation loss decreased (0.020701 --> 0.016243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0161745\n",
      "\tspeed: 0.0427s/iter; left time: 685.1543s\n",
      "\titers: 200, epoch: 3 | loss: 0.0176367\n",
      "\tspeed: 0.0092s/iter; left time: 146.9499s\n",
      "\titers: 300, epoch: 3 | loss: 0.0138046\n",
      "\tspeed: 0.0091s/iter; left time: 144.7703s\n",
      "\titers: 400, epoch: 3 | loss: 0.0173073\n",
      "\tspeed: 0.0091s/iter; left time: 143.8204s\n",
      "\titers: 500, epoch: 3 | loss: 0.0119053\n",
      "\tspeed: 0.0091s/iter; left time: 142.6656s\n",
      "\titers: 600, epoch: 3 | loss: 0.0220667\n",
      "\tspeed: 0.0091s/iter; left time: 141.7377s\n",
      "\titers: 700, epoch: 3 | loss: 0.0158816\n",
      "\tspeed: 0.0090s/iter; left time: 139.1940s\n",
      "\titers: 800, epoch: 3 | loss: 0.0164586\n",
      "\tspeed: 0.0118s/iter; left time: 180.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 897 | Train Loss: 0.0170688 Vali Loss: 0.0159528 Test Loss: 0.0180039\n",
      "Validation loss decreased (0.016243 --> 0.015953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0171233\n",
      "\tspeed: 0.0900s/iter; left time: 1363.0327s\n",
      "\titers: 200, epoch: 4 | loss: 0.0156178\n",
      "\tspeed: 0.0498s/iter; left time: 749.7392s\n",
      "\titers: 300, epoch: 4 | loss: 0.0169409\n",
      "\tspeed: 0.0521s/iter; left time: 779.1950s\n",
      "\titers: 400, epoch: 4 | loss: 0.0171706\n",
      "\tspeed: 0.0542s/iter; left time: 804.9297s\n",
      "\titers: 500, epoch: 4 | loss: 0.0143780\n",
      "\tspeed: 0.0497s/iter; left time: 732.9856s\n",
      "\titers: 600, epoch: 4 | loss: 0.0135960\n",
      "\tspeed: 0.0538s/iter; left time: 788.2197s\n",
      "\titers: 700, epoch: 4 | loss: 0.0199836\n",
      "\tspeed: 0.0525s/iter; left time: 763.8794s\n",
      "\titers: 800, epoch: 4 | loss: 0.0150730\n",
      "\tspeed: 0.0544s/iter; left time: 786.6078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 897 | Train Loss: 0.0163408 Vali Loss: 0.0158492 Test Loss: 0.0179081\n",
      "Validation loss decreased (0.015953 --> 0.015849).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0148393\n",
      "\tspeed: 0.2760s/iter; left time: 3933.2043s\n",
      "\titers: 200, epoch: 5 | loss: 0.0134675\n",
      "\tspeed: 0.0558s/iter; left time: 790.0952s\n",
      "\titers: 300, epoch: 5 | loss: 0.0152228\n",
      "\tspeed: 0.0371s/iter; left time: 521.6268s\n",
      "\titers: 400, epoch: 5 | loss: 0.0186174\n",
      "\tspeed: 0.0516s/iter; left time: 720.3276s\n",
      "\titers: 500, epoch: 5 | loss: 0.0195296\n",
      "\tspeed: 0.0213s/iter; left time: 294.4399s\n",
      "\titers: 600, epoch: 5 | loss: 0.0132725\n",
      "\tspeed: 0.0087s/iter; left time: 119.4261s\n",
      "\titers: 700, epoch: 5 | loss: 0.0149563\n",
      "\tspeed: 0.0087s/iter; left time: 118.3480s\n",
      "\titers: 800, epoch: 5 | loss: 0.0227999\n",
      "\tspeed: 0.0091s/iter; left time: 123.2519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.44s\n",
      "Steps: 897 | Train Loss: 0.0157050 Vali Loss: 0.0158709 Test Loss: 0.0176919\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0130483\n",
      "\tspeed: 0.1645s/iter; left time: 2197.4457s\n",
      "\titers: 200, epoch: 6 | loss: 0.0117471\n",
      "\tspeed: 0.0152s/iter; left time: 200.9914s\n",
      "\titers: 300, epoch: 6 | loss: 0.0142716\n",
      "\tspeed: 0.0109s/iter; left time: 143.9957s\n",
      "\titers: 400, epoch: 6 | loss: 0.0145453\n",
      "\tspeed: 0.0109s/iter; left time: 142.6237s\n",
      "\titers: 500, epoch: 6 | loss: 0.0137561\n",
      "\tspeed: 0.0109s/iter; left time: 141.1981s\n",
      "\titers: 600, epoch: 6 | loss: 0.0124844\n",
      "\tspeed: 0.0108s/iter; left time: 138.6243s\n",
      "\titers: 700, epoch: 6 | loss: 0.0170365\n",
      "\tspeed: 0.0125s/iter; left time: 159.1142s\n",
      "\titers: 800, epoch: 6 | loss: 0.0130612\n",
      "\tspeed: 0.0110s/iter; left time: 139.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.48s\n",
      "Steps: 897 | Train Loss: 0.0151079 Vali Loss: 0.0157032 Test Loss: 0.0179839\n",
      "Validation loss decreased (0.015849 --> 0.015703).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0160668\n",
      "\tspeed: 0.0463s/iter; left time: 576.9540s\n",
      "\titers: 200, epoch: 7 | loss: 0.0119003\n",
      "\tspeed: 0.0098s/iter; left time: 120.7440s\n",
      "\titers: 300, epoch: 7 | loss: 0.0127965\n",
      "\tspeed: 0.0098s/iter; left time: 120.0372s\n",
      "\titers: 400, epoch: 7 | loss: 0.0126611\n",
      "\tspeed: 0.0098s/iter; left time: 118.5860s\n",
      "\titers: 500, epoch: 7 | loss: 0.0116660\n",
      "\tspeed: 0.0097s/iter; left time: 116.6078s\n",
      "\titers: 600, epoch: 7 | loss: 0.0182375\n",
      "\tspeed: 0.0096s/iter; left time: 115.3975s\n",
      "\titers: 700, epoch: 7 | loss: 0.0159407\n",
      "\tspeed: 0.0094s/iter; left time: 111.7545s\n",
      "\titers: 800, epoch: 7 | loss: 0.0157776\n",
      "\tspeed: 0.0105s/iter; left time: 123.5468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 897 | Train Loss: 0.0145564 Vali Loss: 0.0159253 Test Loss: 0.0179471\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0121298\n",
      "\tspeed: 0.0458s/iter; left time: 529.9480s\n",
      "\titers: 200, epoch: 8 | loss: 0.0162395\n",
      "\tspeed: 0.0093s/iter; left time: 106.5606s\n",
      "\titers: 300, epoch: 8 | loss: 0.0159666\n",
      "\tspeed: 0.0093s/iter; left time: 106.1706s\n",
      "\titers: 400, epoch: 8 | loss: 0.0134115\n",
      "\tspeed: 0.0093s/iter; left time: 105.2225s\n",
      "\titers: 500, epoch: 8 | loss: 0.0114040\n",
      "\tspeed: 0.0093s/iter; left time: 104.2379s\n",
      "\titers: 600, epoch: 8 | loss: 0.0137805\n",
      "\tspeed: 0.0093s/iter; left time: 103.2415s\n",
      "\titers: 700, epoch: 8 | loss: 0.0127767\n",
      "\tspeed: 0.0092s/iter; left time: 100.9049s\n",
      "\titers: 800, epoch: 8 | loss: 0.0152400\n",
      "\tspeed: 0.0090s/iter; left time: 97.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 897 | Train Loss: 0.0140345 Vali Loss: 0.0160987 Test Loss: 0.0181461\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0173715\n",
      "\tspeed: 0.0431s/iter; left time: 459.6796s\n",
      "\titers: 200, epoch: 9 | loss: 0.0149977\n",
      "\tspeed: 0.0089s/iter; left time: 93.7019s\n",
      "\titers: 300, epoch: 9 | loss: 0.0160420\n",
      "\tspeed: 0.0090s/iter; left time: 94.2017s\n",
      "\titers: 400, epoch: 9 | loss: 0.0146751\n",
      "\tspeed: 0.0089s/iter; left time: 91.9588s\n",
      "\titers: 500, epoch: 9 | loss: 0.0129151\n",
      "\tspeed: 0.0091s/iter; left time: 93.0507s\n",
      "\titers: 600, epoch: 9 | loss: 0.0131759\n",
      "\tspeed: 0.0089s/iter; left time: 90.1702s\n",
      "\titers: 700, epoch: 9 | loss: 0.0143019\n",
      "\tspeed: 0.0088s/iter; left time: 88.7496s\n",
      "\titers: 800, epoch: 9 | loss: 0.0119004\n",
      "\tspeed: 0.0089s/iter; left time: 88.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 897 | Train Loss: 0.0135878 Vali Loss: 0.0161945 Test Loss: 0.0181078\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0092926\n",
      "\tspeed: 0.0423s/iter; left time: 413.3110s\n",
      "\titers: 200, epoch: 10 | loss: 0.0131013\n",
      "\tspeed: 0.0090s/iter; left time: 86.7615s\n",
      "\titers: 300, epoch: 10 | loss: 0.0118378\n",
      "\tspeed: 0.0089s/iter; left time: 85.4108s\n",
      "\titers: 400, epoch: 10 | loss: 0.0158355\n",
      "\tspeed: 0.0089s/iter; left time: 84.5768s\n",
      "\titers: 500, epoch: 10 | loss: 0.0167850\n",
      "\tspeed: 0.0089s/iter; left time: 83.0322s\n",
      "\titers: 600, epoch: 10 | loss: 0.0136658\n",
      "\tspeed: 0.0088s/iter; left time: 81.5060s\n",
      "\titers: 700, epoch: 10 | loss: 0.0122833\n",
      "\tspeed: 0.0088s/iter; left time: 80.6243s\n",
      "\titers: 800, epoch: 10 | loss: 0.0133440\n",
      "\tspeed: 0.0089s/iter; left time: 81.1103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 897 | Train Loss: 0.0132292 Vali Loss: 0.0161405 Test Loss: 0.0185001\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0129231\n",
      "\tspeed: 0.0418s/iter; left time: 371.1035s\n",
      "\titers: 200, epoch: 11 | loss: 0.0146973\n",
      "\tspeed: 0.0089s/iter; left time: 77.6717s\n",
      "\titers: 300, epoch: 11 | loss: 0.0131006\n",
      "\tspeed: 0.0089s/iter; left time: 76.8547s\n",
      "\titers: 400, epoch: 11 | loss: 0.0115173\n",
      "\tspeed: 0.0088s/iter; left time: 75.7968s\n",
      "\titers: 500, epoch: 11 | loss: 0.0137676\n",
      "\tspeed: 0.0088s/iter; left time: 74.7928s\n",
      "\titers: 600, epoch: 11 | loss: 0.0102560\n",
      "\tspeed: 0.0088s/iter; left time: 73.8745s\n",
      "\titers: 700, epoch: 11 | loss: 0.0157796\n",
      "\tspeed: 0.0088s/iter; left time: 72.9592s\n",
      "\titers: 800, epoch: 11 | loss: 0.0110692\n",
      "\tspeed: 0.0089s/iter; left time: 72.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 897 | Train Loss: 0.0128675 Vali Loss: 0.0162930 Test Loss: 0.0184875\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017983945086598396, rmse:0.13410423696041107, mae:0.08237696439027786, rse:0.507062554359436\n",
      "Original data scale mse:2541549.75, rmse:1594.223876953125, mae:1034.8856201171875, rse:0.11219204217195511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0450891\n",
      "\tspeed: 0.0117s/iter; left time: 209.1547s\n",
      "\titers: 200, epoch: 1 | loss: 0.0345827\n",
      "\tspeed: 0.0087s/iter; left time: 155.0492s\n",
      "\titers: 300, epoch: 1 | loss: 0.0323829\n",
      "\tspeed: 0.0088s/iter; left time: 155.0005s\n",
      "\titers: 400, epoch: 1 | loss: 0.0277660\n",
      "\tspeed: 0.0089s/iter; left time: 156.5261s\n",
      "\titers: 500, epoch: 1 | loss: 0.0283018\n",
      "\tspeed: 0.0089s/iter; left time: 155.6148s\n",
      "\titers: 600, epoch: 1 | loss: 0.0254839\n",
      "\tspeed: 0.0090s/iter; left time: 156.4678s\n",
      "\titers: 700, epoch: 1 | loss: 0.0243137\n",
      "\tspeed: 0.0090s/iter; left time: 154.8210s\n",
      "\titers: 800, epoch: 1 | loss: 0.0281626\n",
      "\tspeed: 0.0090s/iter; left time: 153.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 897 | Train Loss: 0.0329252 Vali Loss: 0.0206755 Test Loss: 0.0222118\n",
      "Validation loss decreased (inf --> 0.020675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0226247\n",
      "\tspeed: 0.0419s/iter; left time: 710.3888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0199644\n",
      "\tspeed: 0.0108s/iter; left time: 181.3387s\n",
      "\titers: 300, epoch: 2 | loss: 0.0184773\n",
      "\tspeed: 0.0092s/iter; left time: 153.2777s\n",
      "\titers: 400, epoch: 2 | loss: 0.0166526\n",
      "\tspeed: 0.0086s/iter; left time: 143.1417s\n",
      "\titers: 500, epoch: 2 | loss: 0.0183695\n",
      "\tspeed: 0.0086s/iter; left time: 142.0752s\n",
      "\titers: 600, epoch: 2 | loss: 0.0179139\n",
      "\tspeed: 0.0086s/iter; left time: 142.0700s\n",
      "\titers: 700, epoch: 2 | loss: 0.0193893\n",
      "\tspeed: 0.0087s/iter; left time: 142.4137s\n",
      "\titers: 800, epoch: 2 | loss: 0.0173843\n",
      "\tspeed: 0.0088s/iter; left time: 143.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 897 | Train Loss: 0.0190774 Vali Loss: 0.0161624 Test Loss: 0.0180929\n",
      "Validation loss decreased (0.020675 --> 0.016162).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0147038\n",
      "\tspeed: 0.0411s/iter; left time: 659.2189s\n",
      "\titers: 200, epoch: 3 | loss: 0.0169889\n",
      "\tspeed: 0.0087s/iter; left time: 139.1169s\n",
      "\titers: 300, epoch: 3 | loss: 0.0175021\n",
      "\tspeed: 0.0088s/iter; left time: 139.0862s\n",
      "\titers: 400, epoch: 3 | loss: 0.0194638\n",
      "\tspeed: 0.0088s/iter; left time: 138.0947s\n",
      "\titers: 500, epoch: 3 | loss: 0.0162734\n",
      "\tspeed: 0.0087s/iter; left time: 136.7661s\n",
      "\titers: 600, epoch: 3 | loss: 0.0163567\n",
      "\tspeed: 0.0087s/iter; left time: 135.7765s\n",
      "\titers: 700, epoch: 3 | loss: 0.0152641\n",
      "\tspeed: 0.0087s/iter; left time: 134.6201s\n",
      "\titers: 800, epoch: 3 | loss: 0.0171647\n",
      "\tspeed: 0.0094s/iter; left time: 144.1947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 897 | Train Loss: 0.0170700 Vali Loss: 0.0159039 Test Loss: 0.0179473\n",
      "Validation loss decreased (0.016162 --> 0.015904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0159425\n",
      "\tspeed: 0.0437s/iter; left time: 662.5970s\n",
      "\titers: 200, epoch: 4 | loss: 0.0142012\n",
      "\tspeed: 0.0096s/iter; left time: 144.9094s\n",
      "\titers: 300, epoch: 4 | loss: 0.0152940\n",
      "\tspeed: 0.0096s/iter; left time: 144.0841s\n",
      "\titers: 400, epoch: 4 | loss: 0.0212515\n",
      "\tspeed: 0.0097s/iter; left time: 143.9973s\n",
      "\titers: 500, epoch: 4 | loss: 0.0170630\n",
      "\tspeed: 0.0096s/iter; left time: 141.6995s\n",
      "\titers: 600, epoch: 4 | loss: 0.0173444\n",
      "\tspeed: 0.0096s/iter; left time: 140.9463s\n",
      "\titers: 700, epoch: 4 | loss: 0.0146621\n",
      "\tspeed: 0.0096s/iter; left time: 139.9088s\n",
      "\titers: 800, epoch: 4 | loss: 0.0157213\n",
      "\tspeed: 0.0096s/iter; left time: 139.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 897 | Train Loss: 0.0163680 Vali Loss: 0.0160033 Test Loss: 0.0179127\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0172270\n",
      "\tspeed: 0.0433s/iter; left time: 616.5495s\n",
      "\titers: 200, epoch: 5 | loss: 0.0168974\n",
      "\tspeed: 0.0093s/iter; left time: 131.0331s\n",
      "\titers: 300, epoch: 5 | loss: 0.0129067\n",
      "\tspeed: 0.0087s/iter; left time: 121.9842s\n",
      "\titers: 400, epoch: 5 | loss: 0.0159158\n",
      "\tspeed: 0.0085s/iter; left time: 119.1770s\n",
      "\titers: 500, epoch: 5 | loss: 0.0138109\n",
      "\tspeed: 0.0086s/iter; left time: 118.6105s\n",
      "\titers: 600, epoch: 5 | loss: 0.0163441\n",
      "\tspeed: 0.0085s/iter; left time: 117.2657s\n",
      "\titers: 700, epoch: 5 | loss: 0.0148638\n",
      "\tspeed: 0.0085s/iter; left time: 116.2694s\n",
      "\titers: 800, epoch: 5 | loss: 0.0188415\n",
      "\tspeed: 0.0085s/iter; left time: 115.7168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 897 | Train Loss: 0.0157356 Vali Loss: 0.0160282 Test Loss: 0.0178841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0200365\n",
      "\tspeed: 0.0420s/iter; left time: 560.2914s\n",
      "\titers: 200, epoch: 6 | loss: 0.0158138\n",
      "\tspeed: 0.0089s/iter; left time: 117.7498s\n",
      "\titers: 300, epoch: 6 | loss: 0.0148582\n",
      "\tspeed: 0.0089s/iter; left time: 117.4083s\n",
      "\titers: 400, epoch: 6 | loss: 0.0158861\n",
      "\tspeed: 0.0090s/iter; left time: 117.2901s\n",
      "\titers: 500, epoch: 6 | loss: 0.0149286\n",
      "\tspeed: 0.0090s/iter; left time: 116.1792s\n",
      "\titers: 600, epoch: 6 | loss: 0.0137950\n",
      "\tspeed: 0.0090s/iter; left time: 115.4496s\n",
      "\titers: 700, epoch: 6 | loss: 0.0143760\n",
      "\tspeed: 0.0090s/iter; left time: 114.4833s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142915\n",
      "\tspeed: 0.0088s/iter; left time: 111.6458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 897 | Train Loss: 0.0151137 Vali Loss: 0.0160323 Test Loss: 0.0180576\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0172263\n",
      "\tspeed: 0.0404s/iter; left time: 503.4448s\n",
      "\titers: 200, epoch: 7 | loss: 0.0168404\n",
      "\tspeed: 0.0089s/iter; left time: 110.5886s\n",
      "\titers: 300, epoch: 7 | loss: 0.0121220\n",
      "\tspeed: 0.0087s/iter; left time: 106.7836s\n",
      "\titers: 400, epoch: 7 | loss: 0.0139303\n",
      "\tspeed: 0.0087s/iter; left time: 105.5661s\n",
      "\titers: 500, epoch: 7 | loss: 0.0164427\n",
      "\tspeed: 0.0087s/iter; left time: 105.1906s\n",
      "\titers: 600, epoch: 7 | loss: 0.0134344\n",
      "\tspeed: 0.0088s/iter; left time: 105.6475s\n",
      "\titers: 700, epoch: 7 | loss: 0.0161934\n",
      "\tspeed: 0.0088s/iter; left time: 104.2741s\n",
      "\titers: 800, epoch: 7 | loss: 0.0131848\n",
      "\tspeed: 0.0085s/iter; left time: 100.1178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 897 | Train Loss: 0.0145334 Vali Loss: 0.0160245 Test Loss: 0.0183425\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0133886\n",
      "\tspeed: 0.0426s/iter; left time: 493.0859s\n",
      "\titers: 200, epoch: 8 | loss: 0.0135026\n",
      "\tspeed: 0.0086s/iter; left time: 98.1945s\n",
      "\titers: 300, epoch: 8 | loss: 0.0135307\n",
      "\tspeed: 0.0086s/iter; left time: 97.8003s\n",
      "\titers: 400, epoch: 8 | loss: 0.0137472\n",
      "\tspeed: 0.0086s/iter; left time: 96.5089s\n",
      "\titers: 500, epoch: 8 | loss: 0.0135483\n",
      "\tspeed: 0.0086s/iter; left time: 95.5556s\n",
      "\titers: 600, epoch: 8 | loss: 0.0133925\n",
      "\tspeed: 0.0086s/iter; left time: 95.0921s\n",
      "\titers: 700, epoch: 8 | loss: 0.0126067\n",
      "\tspeed: 0.0085s/iter; left time: 93.6967s\n",
      "\titers: 800, epoch: 8 | loss: 0.0152205\n",
      "\tspeed: 0.0086s/iter; left time: 93.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 897 | Train Loss: 0.0139899 Vali Loss: 0.0162143 Test Loss: 0.0183185\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017947325482964516, rmse:0.13396762311458588, mae:0.08385661989450455, rse:0.5065460205078125\n",
      "Original data scale mse:2719271.75, rmse:1649.021484375, mae:1078.899658203125, rse:0.11604836583137512\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0464109\n",
      "\tspeed: 0.0277s/iter; left time: 492.7364s\n",
      "\titers: 200, epoch: 1 | loss: 0.0361887\n",
      "\tspeed: 0.0089s/iter; left time: 156.7800s\n",
      "\titers: 300, epoch: 1 | loss: 0.0343387\n",
      "\tspeed: 0.0088s/iter; left time: 155.2361s\n",
      "\titers: 400, epoch: 1 | loss: 0.0295457\n",
      "\tspeed: 0.0087s/iter; left time: 152.7960s\n",
      "\titers: 500, epoch: 1 | loss: 0.0309987\n",
      "\tspeed: 0.0088s/iter; left time: 152.7815s\n",
      "\titers: 600, epoch: 1 | loss: 0.0257509\n",
      "\tspeed: 0.0087s/iter; left time: 149.9417s\n",
      "\titers: 700, epoch: 1 | loss: 0.0252158\n",
      "\tspeed: 0.0086s/iter; left time: 147.5200s\n",
      "\titers: 800, epoch: 1 | loss: 0.0247644\n",
      "\tspeed: 0.0087s/iter; left time: 148.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 894 | Train Loss: 0.0341034 Vali Loss: 0.0218626 Test Loss: 0.0231702\n",
      "Validation loss decreased (inf --> 0.021863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0213781\n",
      "\tspeed: 0.0403s/iter; left time: 681.1238s\n",
      "\titers: 200, epoch: 2 | loss: 0.0229823\n",
      "\tspeed: 0.0089s/iter; left time: 150.1208s\n",
      "\titers: 300, epoch: 2 | loss: 0.0217995\n",
      "\tspeed: 0.0089s/iter; left time: 148.0204s\n",
      "\titers: 400, epoch: 2 | loss: 0.0241468\n",
      "\tspeed: 0.0089s/iter; left time: 147.1776s\n",
      "\titers: 500, epoch: 2 | loss: 0.0215835\n",
      "\tspeed: 0.0089s/iter; left time: 146.0444s\n",
      "\titers: 600, epoch: 2 | loss: 0.0231235\n",
      "\tspeed: 0.0089s/iter; left time: 146.2252s\n",
      "\titers: 700, epoch: 2 | loss: 0.0215747\n",
      "\tspeed: 0.0089s/iter; left time: 144.8765s\n",
      "\titers: 800, epoch: 2 | loss: 0.0203265\n",
      "\tspeed: 0.0089s/iter; left time: 144.5782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 894 | Train Loss: 0.0204705 Vali Loss: 0.0177452 Test Loss: 0.0193972\n",
      "Validation loss decreased (0.021863 --> 0.017745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0217652\n",
      "\tspeed: 0.0424s/iter; left time: 677.4394s\n",
      "\titers: 200, epoch: 3 | loss: 0.0194095\n",
      "\tspeed: 0.0090s/iter; left time: 143.1674s\n",
      "\titers: 300, epoch: 3 | loss: 0.0175746\n",
      "\tspeed: 0.0089s/iter; left time: 140.8764s\n",
      "\titers: 400, epoch: 3 | loss: 0.0207958\n",
      "\tspeed: 0.0090s/iter; left time: 140.8579s\n",
      "\titers: 500, epoch: 3 | loss: 0.0155851\n",
      "\tspeed: 0.0088s/iter; left time: 137.1843s\n",
      "\titers: 600, epoch: 3 | loss: 0.0203213\n",
      "\tspeed: 0.0087s/iter; left time: 135.5339s\n",
      "\titers: 700, epoch: 3 | loss: 0.0200264\n",
      "\tspeed: 0.0087s/iter; left time: 134.6821s\n",
      "\titers: 800, epoch: 3 | loss: 0.0200003\n",
      "\tspeed: 0.0087s/iter; left time: 133.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 894 | Train Loss: 0.0183968 Vali Loss: 0.0177684 Test Loss: 0.0196724\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0200898\n",
      "\tspeed: 0.0403s/iter; left time: 608.6204s\n",
      "\titers: 200, epoch: 4 | loss: 0.0161771\n",
      "\tspeed: 0.0089s/iter; left time: 133.6013s\n",
      "\titers: 300, epoch: 4 | loss: 0.0173720\n",
      "\tspeed: 0.0090s/iter; left time: 133.7451s\n",
      "\titers: 400, epoch: 4 | loss: 0.0169685\n",
      "\tspeed: 0.0090s/iter; left time: 133.0459s\n",
      "\titers: 500, epoch: 4 | loss: 0.0172904\n",
      "\tspeed: 0.0089s/iter; left time: 131.4530s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161756\n",
      "\tspeed: 0.0089s/iter; left time: 129.9651s\n",
      "\titers: 700, epoch: 4 | loss: 0.0185437\n",
      "\tspeed: 0.0089s/iter; left time: 128.8177s\n",
      "\titers: 800, epoch: 4 | loss: 0.0146089\n",
      "\tspeed: 0.0089s/iter; left time: 127.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 894 | Train Loss: 0.0176809 Vali Loss: 0.0178539 Test Loss: 0.0198191\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0156661\n",
      "\tspeed: 0.0415s/iter; left time: 589.1632s\n",
      "\titers: 200, epoch: 5 | loss: 0.0163235\n",
      "\tspeed: 0.0092s/iter; left time: 129.7623s\n",
      "\titers: 300, epoch: 5 | loss: 0.0193586\n",
      "\tspeed: 0.0088s/iter; left time: 122.6863s\n",
      "\titers: 400, epoch: 5 | loss: 0.0187044\n",
      "\tspeed: 0.0087s/iter; left time: 120.8750s\n",
      "\titers: 500, epoch: 5 | loss: 0.0162523\n",
      "\tspeed: 0.0087s/iter; left time: 120.1062s\n",
      "\titers: 600, epoch: 5 | loss: 0.0182531\n",
      "\tspeed: 0.0087s/iter; left time: 118.5810s\n",
      "\titers: 700, epoch: 5 | loss: 0.0155543\n",
      "\tspeed: 0.0087s/iter; left time: 118.6178s\n",
      "\titers: 800, epoch: 5 | loss: 0.0175914\n",
      "\tspeed: 0.0089s/iter; left time: 120.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 894 | Train Loss: 0.0169059 Vali Loss: 0.0176183 Test Loss: 0.0199724\n",
      "Validation loss decreased (0.017745 --> 0.017618).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0175742\n",
      "\tspeed: 0.0411s/iter; left time: 546.8505s\n",
      "\titers: 200, epoch: 6 | loss: 0.0142634\n",
      "\tspeed: 0.0089s/iter; left time: 117.2011s\n",
      "\titers: 300, epoch: 6 | loss: 0.0165513\n",
      "\tspeed: 0.0087s/iter; left time: 113.5848s\n",
      "\titers: 400, epoch: 6 | loss: 0.0173183\n",
      "\tspeed: 0.0086s/iter; left time: 112.5204s\n",
      "\titers: 500, epoch: 6 | loss: 0.0160514\n",
      "\tspeed: 0.0087s/iter; left time: 112.7438s\n",
      "\titers: 600, epoch: 6 | loss: 0.0165171\n",
      "\tspeed: 0.0089s/iter; left time: 114.5812s\n",
      "\titers: 700, epoch: 6 | loss: 0.0193715\n",
      "\tspeed: 0.0090s/iter; left time: 114.1268s\n",
      "\titers: 800, epoch: 6 | loss: 0.0140052\n",
      "\tspeed: 0.0089s/iter; left time: 112.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 894 | Train Loss: 0.0160879 Vali Loss: 0.0178874 Test Loss: 0.0198355\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0160109\n",
      "\tspeed: 0.0409s/iter; left time: 508.2394s\n",
      "\titers: 200, epoch: 7 | loss: 0.0138987\n",
      "\tspeed: 0.0089s/iter; left time: 109.0519s\n",
      "\titers: 300, epoch: 7 | loss: 0.0149317\n",
      "\tspeed: 0.0088s/iter; left time: 107.3534s\n",
      "\titers: 400, epoch: 7 | loss: 0.0161886\n",
      "\tspeed: 0.0089s/iter; left time: 107.3796s\n",
      "\titers: 500, epoch: 7 | loss: 0.0162232\n",
      "\tspeed: 0.0089s/iter; left time: 106.4874s\n",
      "\titers: 600, epoch: 7 | loss: 0.0153939\n",
      "\tspeed: 0.0088s/iter; left time: 105.4355s\n",
      "\titers: 700, epoch: 7 | loss: 0.0146930\n",
      "\tspeed: 0.0088s/iter; left time: 104.2483s\n",
      "\titers: 800, epoch: 7 | loss: 0.0138359\n",
      "\tspeed: 0.0088s/iter; left time: 103.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 894 | Train Loss: 0.0154088 Vali Loss: 0.0183227 Test Loss: 0.0203692\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0133051\n",
      "\tspeed: 0.0413s/iter; left time: 475.7703s\n",
      "\titers: 200, epoch: 8 | loss: 0.0129502\n",
      "\tspeed: 0.0089s/iter; left time: 101.9713s\n",
      "\titers: 300, epoch: 8 | loss: 0.0146181\n",
      "\tspeed: 0.0091s/iter; left time: 103.0711s\n",
      "\titers: 400, epoch: 8 | loss: 0.0130213\n",
      "\tspeed: 0.0091s/iter; left time: 101.9775s\n",
      "\titers: 500, epoch: 8 | loss: 0.0128742\n",
      "\tspeed: 0.0091s/iter; left time: 101.4418s\n",
      "\titers: 600, epoch: 8 | loss: 0.0118887\n",
      "\tspeed: 0.0088s/iter; left time: 97.2824s\n",
      "\titers: 700, epoch: 8 | loss: 0.0175533\n",
      "\tspeed: 0.0088s/iter; left time: 96.1720s\n",
      "\titers: 800, epoch: 8 | loss: 0.0144295\n",
      "\tspeed: 0.0088s/iter; left time: 95.6671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 894 | Train Loss: 0.0147680 Vali Loss: 0.0181558 Test Loss: 0.0203611\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0139277\n",
      "\tspeed: 0.0409s/iter; left time: 434.4147s\n",
      "\titers: 200, epoch: 9 | loss: 0.0155986\n",
      "\tspeed: 0.0088s/iter; left time: 92.8762s\n",
      "\titers: 300, epoch: 9 | loss: 0.0143357\n",
      "\tspeed: 0.0089s/iter; left time: 92.5098s\n",
      "\titers: 400, epoch: 9 | loss: 0.0142286\n",
      "\tspeed: 0.0089s/iter; left time: 91.5763s\n",
      "\titers: 500, epoch: 9 | loss: 0.0147045\n",
      "\tspeed: 0.0089s/iter; left time: 90.6954s\n",
      "\titers: 600, epoch: 9 | loss: 0.0139572\n",
      "\tspeed: 0.0089s/iter; left time: 89.9991s\n",
      "\titers: 700, epoch: 9 | loss: 0.0132338\n",
      "\tspeed: 0.0089s/iter; left time: 88.8330s\n",
      "\titers: 800, epoch: 9 | loss: 0.0156314\n",
      "\tspeed: 0.0088s/iter; left time: 87.3719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 894 | Train Loss: 0.0142309 Vali Loss: 0.0181225 Test Loss: 0.0205804\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0135922\n",
      "\tspeed: 0.0404s/iter; left time: 392.8107s\n",
      "\titers: 200, epoch: 10 | loss: 0.0134005\n",
      "\tspeed: 0.0093s/iter; left time: 89.9166s\n",
      "\titers: 300, epoch: 10 | loss: 0.0134395\n",
      "\tspeed: 0.0089s/iter; left time: 84.8716s\n",
      "\titers: 400, epoch: 10 | loss: 0.0139479\n",
      "\tspeed: 0.0089s/iter; left time: 84.0119s\n",
      "\titers: 500, epoch: 10 | loss: 0.0152775\n",
      "\tspeed: 0.0088s/iter; left time: 81.6837s\n",
      "\titers: 600, epoch: 10 | loss: 0.0158018\n",
      "\tspeed: 0.0087s/iter; left time: 80.5087s\n",
      "\titers: 700, epoch: 10 | loss: 0.0131601\n",
      "\tspeed: 0.0087s/iter; left time: 79.6992s\n",
      "\titers: 800, epoch: 10 | loss: 0.0124908\n",
      "\tspeed: 0.0087s/iter; left time: 79.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 894 | Train Loss: 0.0138248 Vali Loss: 0.0181022 Test Loss: 0.0208994\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019972413778305054, rmse:0.14132378995418549, mae:0.08907762914896011, rse:0.5347296595573425\n",
      "Original data scale mse:3073615.0, rmse:1753.1728515625, mae:1146.7259521484375, rse:0.12349379807710648\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0476475\n",
      "\tspeed: 0.0112s/iter; left time: 199.4457s\n",
      "\titers: 200, epoch: 1 | loss: 0.0353168\n",
      "\tspeed: 0.0088s/iter; left time: 154.9746s\n",
      "\titers: 300, epoch: 1 | loss: 0.0336166\n",
      "\tspeed: 0.0088s/iter; left time: 155.4199s\n",
      "\titers: 400, epoch: 1 | loss: 0.0286101\n",
      "\tspeed: 0.0088s/iter; left time: 154.4248s\n",
      "\titers: 500, epoch: 1 | loss: 0.0287010\n",
      "\tspeed: 0.0088s/iter; left time: 153.1217s\n",
      "\titers: 600, epoch: 1 | loss: 0.0234822\n",
      "\tspeed: 0.0088s/iter; left time: 152.0421s\n",
      "\titers: 700, epoch: 1 | loss: 0.0252475\n",
      "\tspeed: 0.0088s/iter; left time: 151.5435s\n",
      "\titers: 800, epoch: 1 | loss: 0.0278688\n",
      "\tspeed: 0.0088s/iter; left time: 150.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 894 | Train Loss: 0.0341514 Vali Loss: 0.0218443 Test Loss: 0.0231164\n",
      "Validation loss decreased (inf --> 0.021844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0196658\n",
      "\tspeed: 0.0417s/iter; left time: 703.6035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0216820\n",
      "\tspeed: 0.0086s/iter; left time: 143.8045s\n",
      "\titers: 300, epoch: 2 | loss: 0.0186834\n",
      "\tspeed: 0.0086s/iter; left time: 143.0306s\n",
      "\titers: 400, epoch: 2 | loss: 0.0186434\n",
      "\tspeed: 0.0086s/iter; left time: 142.2665s\n",
      "\titers: 500, epoch: 2 | loss: 0.0198819\n",
      "\tspeed: 0.0086s/iter; left time: 141.4285s\n",
      "\titers: 600, epoch: 2 | loss: 0.0180211\n",
      "\tspeed: 0.0085s/iter; left time: 139.7137s\n",
      "\titers: 700, epoch: 2 | loss: 0.0177283\n",
      "\tspeed: 0.0085s/iter; left time: 138.8582s\n",
      "\titers: 800, epoch: 2 | loss: 0.0199662\n",
      "\tspeed: 0.0085s/iter; left time: 137.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 894 | Train Loss: 0.0204194 Vali Loss: 0.0177787 Test Loss: 0.0194635\n",
      "Validation loss decreased (0.021844 --> 0.017779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0180503\n",
      "\tspeed: 0.0407s/iter; left time: 651.1203s\n",
      "\titers: 200, epoch: 3 | loss: 0.0183010\n",
      "\tspeed: 0.0086s/iter; left time: 137.1963s\n",
      "\titers: 300, epoch: 3 | loss: 0.0161728\n",
      "\tspeed: 0.0086s/iter; left time: 135.9308s\n",
      "\titers: 400, epoch: 3 | loss: 0.0186620\n",
      "\tspeed: 0.0086s/iter; left time: 134.9564s\n",
      "\titers: 500, epoch: 3 | loss: 0.0207137\n",
      "\tspeed: 0.0086s/iter; left time: 134.3688s\n",
      "\titers: 600, epoch: 3 | loss: 0.0160185\n",
      "\tspeed: 0.0086s/iter; left time: 133.3823s\n",
      "\titers: 700, epoch: 3 | loss: 0.0187472\n",
      "\tspeed: 0.0086s/iter; left time: 132.4836s\n",
      "\titers: 800, epoch: 3 | loss: 0.0167963\n",
      "\tspeed: 0.0086s/iter; left time: 131.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 894 | Train Loss: 0.0184302 Vali Loss: 0.0175141 Test Loss: 0.0192542\n",
      "Validation loss decreased (0.017779 --> 0.017514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0167841\n",
      "\tspeed: 0.0409s/iter; left time: 617.3275s\n",
      "\titers: 200, epoch: 4 | loss: 0.0157090\n",
      "\tspeed: 0.0087s/iter; left time: 130.8159s\n",
      "\titers: 300, epoch: 4 | loss: 0.0174456\n",
      "\tspeed: 0.0087s/iter; left time: 129.9569s\n",
      "\titers: 400, epoch: 4 | loss: 0.0184882\n",
      "\tspeed: 0.0087s/iter; left time: 129.1310s\n",
      "\titers: 500, epoch: 4 | loss: 0.0190038\n",
      "\tspeed: 0.0087s/iter; left time: 128.1782s\n",
      "\titers: 600, epoch: 4 | loss: 0.0170864\n",
      "\tspeed: 0.0087s/iter; left time: 127.2865s\n",
      "\titers: 700, epoch: 4 | loss: 0.0181732\n",
      "\tspeed: 0.0087s/iter; left time: 126.3618s\n",
      "\titers: 800, epoch: 4 | loss: 0.0186235\n",
      "\tspeed: 0.0087s/iter; left time: 125.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 894 | Train Loss: 0.0176733 Vali Loss: 0.0176610 Test Loss: 0.0194707\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0163475\n",
      "\tspeed: 0.0414s/iter; left time: 587.9654s\n",
      "\titers: 200, epoch: 5 | loss: 0.0189672\n",
      "\tspeed: 0.0107s/iter; left time: 151.5236s\n",
      "\titers: 300, epoch: 5 | loss: 0.0149858\n",
      "\tspeed: 0.0107s/iter; left time: 150.2011s\n",
      "\titers: 400, epoch: 5 | loss: 0.0175440\n",
      "\tspeed: 0.0117s/iter; left time: 162.0772s\n",
      "\titers: 500, epoch: 5 | loss: 0.0170268\n",
      "\tspeed: 0.0110s/iter; left time: 151.9509s\n",
      "\titers: 600, epoch: 5 | loss: 0.0163057\n",
      "\tspeed: 0.0104s/iter; left time: 142.9159s\n",
      "\titers: 700, epoch: 5 | loss: 0.0194585\n",
      "\tspeed: 0.0088s/iter; left time: 119.3028s\n",
      "\titers: 800, epoch: 5 | loss: 0.0160460\n",
      "\tspeed: 0.0086s/iter; left time: 116.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.23s\n",
      "Steps: 894 | Train Loss: 0.0169103 Vali Loss: 0.0177129 Test Loss: 0.0197661\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0141891\n",
      "\tspeed: 0.3007s/iter; left time: 4002.3865s\n",
      "\titers: 200, epoch: 6 | loss: 0.0162251\n",
      "\tspeed: 0.0564s/iter; left time: 745.0309s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157704\n",
      "\tspeed: 0.0607s/iter; left time: 795.2126s\n",
      "\titers: 400, epoch: 6 | loss: 0.0151298\n",
      "\tspeed: 0.0641s/iter; left time: 834.4598s\n",
      "\titers: 500, epoch: 6 | loss: 0.0187187\n",
      "\tspeed: 0.0562s/iter; left time: 725.5061s\n",
      "\titers: 600, epoch: 6 | loss: 0.0162756\n",
      "\tspeed: 0.0564s/iter; left time: 723.0110s\n",
      "\titers: 700, epoch: 6 | loss: 0.0141140\n",
      "\tspeed: 0.0610s/iter; left time: 774.9239s\n",
      "\titers: 800, epoch: 6 | loss: 0.0155050\n",
      "\tspeed: 0.0592s/iter; left time: 746.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.76s\n",
      "Steps: 894 | Train Loss: 0.0161332 Vali Loss: 0.0178571 Test Loss: 0.0200594\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0206745\n",
      "\tspeed: 0.3705s/iter; left time: 4600.3529s\n",
      "\titers: 200, epoch: 7 | loss: 0.0140124\n",
      "\tspeed: 0.0251s/iter; left time: 308.5993s\n",
      "\titers: 300, epoch: 7 | loss: 0.0165640\n",
      "\tspeed: 0.0241s/iter; left time: 294.3329s\n",
      "\titers: 400, epoch: 7 | loss: 0.0169174\n",
      "\tspeed: 0.0174s/iter; left time: 211.2021s\n",
      "\titers: 500, epoch: 7 | loss: 0.0178628\n",
      "\tspeed: 0.0130s/iter; left time: 156.1049s\n",
      "\titers: 600, epoch: 7 | loss: 0.0161473\n",
      "\tspeed: 0.0140s/iter; left time: 166.9741s\n",
      "\titers: 700, epoch: 7 | loss: 0.0153554\n",
      "\tspeed: 0.0124s/iter; left time: 147.0322s\n",
      "\titers: 800, epoch: 7 | loss: 0.0145232\n",
      "\tspeed: 0.0119s/iter; left time: 138.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:20.16s\n",
      "Steps: 894 | Train Loss: 0.0154271 Vali Loss: 0.0179674 Test Loss: 0.0200687\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0151093\n",
      "\tspeed: 0.0491s/iter; left time: 566.1019s\n",
      "\titers: 200, epoch: 8 | loss: 0.0158965\n",
      "\tspeed: 0.0111s/iter; left time: 126.8270s\n",
      "\titers: 300, epoch: 8 | loss: 0.0125743\n",
      "\tspeed: 0.0105s/iter; left time: 119.4308s\n",
      "\titers: 400, epoch: 8 | loss: 0.0132885\n",
      "\tspeed: 0.0106s/iter; left time: 119.2348s\n",
      "\titers: 500, epoch: 8 | loss: 0.0135163\n",
      "\tspeed: 0.0111s/iter; left time: 123.4719s\n",
      "\titers: 600, epoch: 8 | loss: 0.0144448\n",
      "\tspeed: 0.0105s/iter; left time: 115.8526s\n",
      "\titers: 700, epoch: 8 | loss: 0.0142335\n",
      "\tspeed: 0.0103s/iter; left time: 112.6054s\n",
      "\titers: 800, epoch: 8 | loss: 0.0141695\n",
      "\tspeed: 0.0101s/iter; left time: 108.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 894 | Train Loss: 0.0148187 Vali Loss: 0.0176302 Test Loss: 0.0206967\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019254181534051895, rmse:0.13875943422317505, mae:0.08878102153539658, rse:0.5250269174575806\n",
      "Original data scale mse:3200891.75, rmse:1789.1036376953125, mae:1168.5704345703125, rse:0.1260247677564621\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1596882\n",
      "\tspeed: 0.0276s/iter; left time: 492.9573s\n",
      "\titers: 200, epoch: 1 | loss: 0.1480528\n",
      "\tspeed: 0.0095s/iter; left time: 169.2743s\n",
      "\titers: 300, epoch: 1 | loss: 0.1244475\n",
      "\tspeed: 0.0095s/iter; left time: 167.5301s\n",
      "\titers: 400, epoch: 1 | loss: 0.1153396\n",
      "\tspeed: 0.0095s/iter; left time: 166.2342s\n",
      "\titers: 500, epoch: 1 | loss: 0.1062054\n",
      "\tspeed: 0.0095s/iter; left time: 165.7057s\n",
      "\titers: 600, epoch: 1 | loss: 0.1072750\n",
      "\tspeed: 0.0095s/iter; left time: 164.6815s\n",
      "\titers: 700, epoch: 1 | loss: 0.0895273\n",
      "\tspeed: 0.0098s/iter; left time: 169.2425s\n",
      "\titers: 800, epoch: 1 | loss: 0.0949725\n",
      "\tspeed: 0.0096s/iter; left time: 165.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 899 | Train Loss: 0.1228012 Vali Loss: 0.0835051 Test Loss: 0.0854919\n",
      "Validation loss decreased (inf --> 0.083505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0771087\n",
      "\tspeed: 0.0439s/iter; left time: 745.1576s\n",
      "\titers: 200, epoch: 2 | loss: 0.0724524\n",
      "\tspeed: 0.0094s/iter; left time: 159.2037s\n",
      "\titers: 300, epoch: 2 | loss: 0.0695473\n",
      "\tspeed: 0.0094s/iter; left time: 158.2605s\n",
      "\titers: 400, epoch: 2 | loss: 0.0678229\n",
      "\tspeed: 0.0094s/iter; left time: 157.2702s\n",
      "\titers: 500, epoch: 2 | loss: 0.0671075\n",
      "\tspeed: 0.0094s/iter; left time: 155.4060s\n",
      "\titers: 600, epoch: 2 | loss: 0.0624708\n",
      "\tspeed: 0.0094s/iter; left time: 154.7599s\n",
      "\titers: 700, epoch: 2 | loss: 0.0720696\n",
      "\tspeed: 0.0092s/iter; left time: 150.6038s\n",
      "\titers: 800, epoch: 2 | loss: 0.0668519\n",
      "\tspeed: 0.0091s/iter; left time: 148.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 899 | Train Loss: 0.0700868 Vali Loss: 0.0602332 Test Loss: 0.0632078\n",
      "Validation loss decreased (0.083505 --> 0.060233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632783\n",
      "\tspeed: 0.0420s/iter; left time: 676.1068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0543382\n",
      "\tspeed: 0.0091s/iter; left time: 146.2396s\n",
      "\titers: 300, epoch: 3 | loss: 0.0682738\n",
      "\tspeed: 0.0091s/iter; left time: 144.8194s\n",
      "\titers: 400, epoch: 3 | loss: 0.0608454\n",
      "\tspeed: 0.0091s/iter; left time: 144.0051s\n",
      "\titers: 500, epoch: 3 | loss: 0.0632823\n",
      "\tspeed: 0.0091s/iter; left time: 143.2296s\n",
      "\titers: 600, epoch: 3 | loss: 0.0650469\n",
      "\tspeed: 0.0091s/iter; left time: 142.2985s\n",
      "\titers: 700, epoch: 3 | loss: 0.0604427\n",
      "\tspeed: 0.0091s/iter; left time: 140.9777s\n",
      "\titers: 800, epoch: 3 | loss: 0.0713355\n",
      "\tspeed: 0.0091s/iter; left time: 140.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 899 | Train Loss: 0.0623138 Vali Loss: 0.0578068 Test Loss: 0.0607190\n",
      "Validation loss decreased (0.060233 --> 0.057807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0542518\n",
      "\tspeed: 0.0408s/iter; left time: 619.1890s\n",
      "\titers: 200, epoch: 4 | loss: 0.0539534\n",
      "\tspeed: 0.0090s/iter; left time: 135.1951s\n",
      "\titers: 300, epoch: 4 | loss: 0.0597318\n",
      "\tspeed: 0.0093s/iter; left time: 138.7751s\n",
      "\titers: 400, epoch: 4 | loss: 0.0583438\n",
      "\tspeed: 0.0092s/iter; left time: 136.7228s\n",
      "\titers: 500, epoch: 4 | loss: 0.0622107\n",
      "\tspeed: 0.0092s/iter; left time: 135.6295s\n",
      "\titers: 600, epoch: 4 | loss: 0.0584910\n",
      "\tspeed: 0.0092s/iter; left time: 134.6604s\n",
      "\titers: 700, epoch: 4 | loss: 0.0629396\n",
      "\tspeed: 0.0092s/iter; left time: 134.1790s\n",
      "\titers: 800, epoch: 4 | loss: 0.0507901\n",
      "\tspeed: 0.0092s/iter; left time: 133.4931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 899 | Train Loss: 0.0599338 Vali Loss: 0.0571941 Test Loss: 0.0600071\n",
      "Validation loss decreased (0.057807 --> 0.057194).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0577396\n",
      "\tspeed: 0.0408s/iter; left time: 582.4813s\n",
      "\titers: 200, epoch: 5 | loss: 0.0526518\n",
      "\tspeed: 0.0091s/iter; left time: 128.8447s\n",
      "\titers: 300, epoch: 5 | loss: 0.0575566\n",
      "\tspeed: 0.0091s/iter; left time: 127.7334s\n",
      "\titers: 400, epoch: 5 | loss: 0.0648565\n",
      "\tspeed: 0.0091s/iter; left time: 126.9642s\n",
      "\titers: 500, epoch: 5 | loss: 0.0580186\n",
      "\tspeed: 0.0091s/iter; left time: 126.2247s\n",
      "\titers: 600, epoch: 5 | loss: 0.0636809\n",
      "\tspeed: 0.0091s/iter; left time: 125.2010s\n",
      "\titers: 700, epoch: 5 | loss: 0.0545535\n",
      "\tspeed: 0.0091s/iter; left time: 124.1300s\n",
      "\titers: 800, epoch: 5 | loss: 0.0576502\n",
      "\tspeed: 0.0091s/iter; left time: 123.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 899 | Train Loss: 0.0582501 Vali Loss: 0.0563178 Test Loss: 0.0594213\n",
      "Validation loss decreased (0.057194 --> 0.056318).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0516586\n",
      "\tspeed: 0.0405s/iter; left time: 542.4418s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592145\n",
      "\tspeed: 0.0090s/iter; left time: 119.3966s\n",
      "\titers: 300, epoch: 6 | loss: 0.0515455\n",
      "\tspeed: 0.0090s/iter; left time: 118.8146s\n",
      "\titers: 400, epoch: 6 | loss: 0.0557425\n",
      "\tspeed: 0.0090s/iter; left time: 118.1610s\n",
      "\titers: 500, epoch: 6 | loss: 0.0512938\n",
      "\tspeed: 0.0091s/iter; left time: 117.5367s\n",
      "\titers: 600, epoch: 6 | loss: 0.0554240\n",
      "\tspeed: 0.0090s/iter; left time: 116.5467s\n",
      "\titers: 700, epoch: 6 | loss: 0.0582196\n",
      "\tspeed: 0.0091s/iter; left time: 116.8762s\n",
      "\titers: 800, epoch: 6 | loss: 0.0544360\n",
      "\tspeed: 0.0092s/iter; left time: 116.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 899 | Train Loss: 0.0570848 Vali Loss: 0.0556235 Test Loss: 0.0586439\n",
      "Validation loss decreased (0.056318 --> 0.055623).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0557189\n",
      "\tspeed: 0.0411s/iter; left time: 512.8450s\n",
      "\titers: 200, epoch: 7 | loss: 0.0487706\n",
      "\tspeed: 0.0092s/iter; left time: 114.2747s\n",
      "\titers: 300, epoch: 7 | loss: 0.0639746\n",
      "\tspeed: 0.0092s/iter; left time: 112.8013s\n",
      "\titers: 400, epoch: 7 | loss: 0.0511835\n",
      "\tspeed: 0.0092s/iter; left time: 111.6856s\n",
      "\titers: 500, epoch: 7 | loss: 0.0612859\n",
      "\tspeed: 0.0091s/iter; left time: 110.5635s\n",
      "\titers: 600, epoch: 7 | loss: 0.0594616\n",
      "\tspeed: 0.0092s/iter; left time: 110.4732s\n",
      "\titers: 700, epoch: 7 | loss: 0.0516715\n",
      "\tspeed: 0.0092s/iter; left time: 109.7257s\n",
      "\titers: 800, epoch: 7 | loss: 0.0551329\n",
      "\tspeed: 0.0092s/iter; left time: 108.4535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 899 | Train Loss: 0.0562256 Vali Loss: 0.0549759 Test Loss: 0.0576836\n",
      "Validation loss decreased (0.055623 --> 0.054976).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570538\n",
      "\tspeed: 0.0419s/iter; left time: 486.0159s\n",
      "\titers: 200, epoch: 8 | loss: 0.0581737\n",
      "\tspeed: 0.0089s/iter; left time: 102.6024s\n",
      "\titers: 300, epoch: 8 | loss: 0.0517250\n",
      "\tspeed: 0.0089s/iter; left time: 101.8206s\n",
      "\titers: 400, epoch: 8 | loss: 0.0550893\n",
      "\tspeed: 0.0090s/iter; left time: 101.2041s\n",
      "\titers: 500, epoch: 8 | loss: 0.0625874\n",
      "\tspeed: 0.0089s/iter; left time: 100.0856s\n",
      "\titers: 600, epoch: 8 | loss: 0.0555443\n",
      "\tspeed: 0.0089s/iter; left time: 98.4324s\n",
      "\titers: 700, epoch: 8 | loss: 0.0589106\n",
      "\tspeed: 0.0088s/iter; left time: 97.0487s\n",
      "\titers: 800, epoch: 8 | loss: 0.0575689\n",
      "\tspeed: 0.0089s/iter; left time: 96.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 899 | Train Loss: 0.0555218 Vali Loss: 0.0547100 Test Loss: 0.0574701\n",
      "Validation loss decreased (0.054976 --> 0.054710).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0523969\n",
      "\tspeed: 0.0412s/iter; left time: 440.1248s\n",
      "\titers: 200, epoch: 9 | loss: 0.0563124\n",
      "\tspeed: 0.0092s/iter; left time: 97.2979s\n",
      "\titers: 300, epoch: 9 | loss: 0.0594130\n",
      "\tspeed: 0.0089s/iter; left time: 93.3048s\n",
      "\titers: 400, epoch: 9 | loss: 0.0585686\n",
      "\tspeed: 0.0089s/iter; left time: 92.1816s\n",
      "\titers: 500, epoch: 9 | loss: 0.0552204\n",
      "\tspeed: 0.0089s/iter; left time: 91.4541s\n",
      "\titers: 600, epoch: 9 | loss: 0.0577851\n",
      "\tspeed: 0.0089s/iter; left time: 90.8949s\n",
      "\titers: 700, epoch: 9 | loss: 0.0509638\n",
      "\tspeed: 0.0089s/iter; left time: 90.1516s\n",
      "\titers: 800, epoch: 9 | loss: 0.0646937\n",
      "\tspeed: 0.0089s/iter; left time: 88.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 899 | Train Loss: 0.0549944 Vali Loss: 0.0545730 Test Loss: 0.0571759\n",
      "Validation loss decreased (0.054710 --> 0.054573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0479186\n",
      "\tspeed: 0.0406s/iter; left time: 397.4154s\n",
      "\titers: 200, epoch: 10 | loss: 0.0584009\n",
      "\tspeed: 0.0090s/iter; left time: 87.6546s\n",
      "\titers: 300, epoch: 10 | loss: 0.0547627\n",
      "\tspeed: 0.0091s/iter; left time: 87.2875s\n",
      "\titers: 400, epoch: 10 | loss: 0.0581041\n",
      "\tspeed: 0.0091s/iter; left time: 86.3198s\n",
      "\titers: 500, epoch: 10 | loss: 0.0571440\n",
      "\tspeed: 0.0099s/iter; left time: 92.8669s\n",
      "\titers: 600, epoch: 10 | loss: 0.0494682\n",
      "\tspeed: 0.0086s/iter; left time: 79.4435s\n",
      "\titers: 700, epoch: 10 | loss: 0.0559517\n",
      "\tspeed: 0.0085s/iter; left time: 78.5543s\n",
      "\titers: 800, epoch: 10 | loss: 0.0546077\n",
      "\tspeed: 0.0086s/iter; left time: 78.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 899 | Train Loss: 0.0544858 Vali Loss: 0.0544532 Test Loss: 0.0572022\n",
      "Validation loss decreased (0.054573 --> 0.054453).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0519248\n",
      "\tspeed: 0.0388s/iter; left time: 345.3507s\n",
      "\titers: 200, epoch: 11 | loss: 0.0537792\n",
      "\tspeed: 0.0084s/iter; left time: 73.4146s\n",
      "\titers: 300, epoch: 11 | loss: 0.0478312\n",
      "\tspeed: 0.0083s/iter; left time: 72.4946s\n",
      "\titers: 400, epoch: 11 | loss: 0.0571694\n",
      "\tspeed: 0.0083s/iter; left time: 71.6980s\n",
      "\titers: 500, epoch: 11 | loss: 0.0507893\n",
      "\tspeed: 0.0085s/iter; left time: 71.7657s\n",
      "\titers: 600, epoch: 11 | loss: 0.0504851\n",
      "\tspeed: 0.0085s/iter; left time: 71.5089s\n",
      "\titers: 700, epoch: 11 | loss: 0.0511787\n",
      "\tspeed: 0.0085s/iter; left time: 70.8066s\n",
      "\titers: 800, epoch: 11 | loss: 0.0534274\n",
      "\tspeed: 0.0087s/iter; left time: 70.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 899 | Train Loss: 0.0541340 Vali Loss: 0.0541357 Test Loss: 0.0571457\n",
      "Validation loss decreased (0.054453 --> 0.054136).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0574521\n",
      "\tspeed: 0.0388s/iter; left time: 309.9598s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558659\n",
      "\tspeed: 0.0084s/iter; left time: 66.4518s\n",
      "\titers: 300, epoch: 12 | loss: 0.0573510\n",
      "\tspeed: 0.0084s/iter; left time: 65.1104s\n",
      "\titers: 400, epoch: 12 | loss: 0.0516572\n",
      "\tspeed: 0.0084s/iter; left time: 64.8034s\n",
      "\titers: 500, epoch: 12 | loss: 0.0567859\n",
      "\tspeed: 0.0084s/iter; left time: 63.5369s\n",
      "\titers: 600, epoch: 12 | loss: 0.0591141\n",
      "\tspeed: 0.0084s/iter; left time: 63.2798s\n",
      "\titers: 700, epoch: 12 | loss: 0.0558623\n",
      "\tspeed: 0.0084s/iter; left time: 62.3837s\n",
      "\titers: 800, epoch: 12 | loss: 0.0543269\n",
      "\tspeed: 0.0085s/iter; left time: 61.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 899 | Train Loss: 0.0538796 Vali Loss: 0.0541165 Test Loss: 0.0571606\n",
      "Validation loss decreased (0.054136 --> 0.054117).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0542878\n",
      "\tspeed: 0.0382s/iter; left time: 270.8705s\n",
      "\titers: 200, epoch: 13 | loss: 0.0577589\n",
      "\tspeed: 0.0085s/iter; left time: 59.3456s\n",
      "\titers: 300, epoch: 13 | loss: 0.0486305\n",
      "\tspeed: 0.0083s/iter; left time: 57.4891s\n",
      "\titers: 400, epoch: 13 | loss: 0.0558641\n",
      "\tspeed: 0.0083s/iter; left time: 56.6083s\n",
      "\titers: 500, epoch: 13 | loss: 0.0629549\n",
      "\tspeed: 0.0084s/iter; left time: 55.9629s\n",
      "\titers: 600, epoch: 13 | loss: 0.0490997\n",
      "\tspeed: 0.0084s/iter; left time: 55.1776s\n",
      "\titers: 700, epoch: 13 | loss: 0.0580531\n",
      "\tspeed: 0.0084s/iter; left time: 54.3333s\n",
      "\titers: 800, epoch: 13 | loss: 0.0676423\n",
      "\tspeed: 0.0084s/iter; left time: 53.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 899 | Train Loss: 0.0535000 Vali Loss: 0.0537869 Test Loss: 0.0567287\n",
      "Validation loss decreased (0.054117 --> 0.053787).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0645191\n",
      "\tspeed: 0.0378s/iter; left time: 234.1666s\n",
      "\titers: 200, epoch: 14 | loss: 0.0520353\n",
      "\tspeed: 0.0086s/iter; left time: 52.2270s\n",
      "\titers: 300, epoch: 14 | loss: 0.0545467\n",
      "\tspeed: 0.0085s/iter; left time: 51.2452s\n",
      "\titers: 400, epoch: 14 | loss: 0.0575039\n",
      "\tspeed: 0.0084s/iter; left time: 49.4045s\n",
      "\titers: 500, epoch: 14 | loss: 0.0579991\n",
      "\tspeed: 0.0083s/iter; left time: 47.9887s\n",
      "\titers: 600, epoch: 14 | loss: 0.0688793\n",
      "\tspeed: 0.0083s/iter; left time: 47.2213s\n",
      "\titers: 700, epoch: 14 | loss: 0.0530366\n",
      "\tspeed: 0.0083s/iter; left time: 46.3348s\n",
      "\titers: 800, epoch: 14 | loss: 0.0523812\n",
      "\tspeed: 0.0083s/iter; left time: 45.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 899 | Train Loss: 0.0532519 Vali Loss: 0.0537448 Test Loss: 0.0571274\n",
      "Validation loss decreased (0.053787 --> 0.053745).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584337\n",
      "\tspeed: 0.0370s/iter; left time: 195.7275s\n",
      "\titers: 200, epoch: 15 | loss: 0.0513506\n",
      "\tspeed: 0.0084s/iter; left time: 43.6632s\n",
      "\titers: 300, epoch: 15 | loss: 0.0491538\n",
      "\tspeed: 0.0086s/iter; left time: 43.7975s\n",
      "\titers: 400, epoch: 15 | loss: 0.0567566\n",
      "\tspeed: 0.0086s/iter; left time: 42.9963s\n",
      "\titers: 500, epoch: 15 | loss: 0.0473421\n",
      "\tspeed: 0.0086s/iter; left time: 41.8857s\n",
      "\titers: 600, epoch: 15 | loss: 0.0538072\n",
      "\tspeed: 0.0084s/iter; left time: 40.1678s\n",
      "\titers: 700, epoch: 15 | loss: 0.0546977\n",
      "\tspeed: 0.0084s/iter; left time: 39.3129s\n",
      "\titers: 800, epoch: 15 | loss: 0.0462549\n",
      "\tspeed: 0.0083s/iter; left time: 38.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 899 | Train Loss: 0.0530578 Vali Loss: 0.0537195 Test Loss: 0.0568474\n",
      "Validation loss decreased (0.053745 --> 0.053719).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0617786\n",
      "\tspeed: 0.0385s/iter; left time: 169.2370s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557882\n",
      "\tspeed: 0.0087s/iter; left time: 37.1897s\n",
      "\titers: 300, epoch: 16 | loss: 0.0473020\n",
      "\tspeed: 0.0086s/iter; left time: 36.2524s\n",
      "\titers: 400, epoch: 16 | loss: 0.0536726\n",
      "\tspeed: 0.0085s/iter; left time: 34.7356s\n",
      "\titers: 500, epoch: 16 | loss: 0.0541505\n",
      "\tspeed: 0.0085s/iter; left time: 33.7783s\n",
      "\titers: 600, epoch: 16 | loss: 0.0463154\n",
      "\tspeed: 0.0085s/iter; left time: 33.1462s\n",
      "\titers: 700, epoch: 16 | loss: 0.0553716\n",
      "\tspeed: 0.0087s/iter; left time: 32.9031s\n",
      "\titers: 800, epoch: 16 | loss: 0.0584276\n",
      "\tspeed: 0.0086s/iter; left time: 31.9155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 899 | Train Loss: 0.0529189 Vali Loss: 0.0536368 Test Loss: 0.0566040\n",
      "Validation loss decreased (0.053719 --> 0.053637).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0547384\n",
      "\tspeed: 0.0383s/iter; left time: 133.9173s\n",
      "\titers: 200, epoch: 17 | loss: 0.0576708\n",
      "\tspeed: 0.0084s/iter; left time: 28.6310s\n",
      "\titers: 300, epoch: 17 | loss: 0.0505483\n",
      "\tspeed: 0.0084s/iter; left time: 27.7938s\n",
      "\titers: 400, epoch: 17 | loss: 0.0616068\n",
      "\tspeed: 0.0084s/iter; left time: 26.9025s\n",
      "\titers: 500, epoch: 17 | loss: 0.0569936\n",
      "\tspeed: 0.0084s/iter; left time: 26.0552s\n",
      "\titers: 600, epoch: 17 | loss: 0.0641668\n",
      "\tspeed: 0.0084s/iter; left time: 25.2723s\n",
      "\titers: 700, epoch: 17 | loss: 0.0420515\n",
      "\tspeed: 0.0084s/iter; left time: 24.3700s\n",
      "\titers: 800, epoch: 17 | loss: 0.0535091\n",
      "\tspeed: 0.0084s/iter; left time: 23.6212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 899 | Train Loss: 0.0527151 Vali Loss: 0.0536366 Test Loss: 0.0564831\n",
      "Validation loss decreased (0.053637 --> 0.053637).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0530321\n",
      "\tspeed: 0.0377s/iter; left time: 97.9678s\n",
      "\titers: 200, epoch: 18 | loss: 0.0623911\n",
      "\tspeed: 0.0084s/iter; left time: 20.9154s\n",
      "\titers: 300, epoch: 18 | loss: 0.0529954\n",
      "\tspeed: 0.0084s/iter; left time: 20.0763s\n",
      "\titers: 400, epoch: 18 | loss: 0.0495064\n",
      "\tspeed: 0.0083s/iter; left time: 19.1764s\n",
      "\titers: 500, epoch: 18 | loss: 0.0456642\n",
      "\tspeed: 0.0083s/iter; left time: 18.1863s\n",
      "\titers: 600, epoch: 18 | loss: 0.0582533\n",
      "\tspeed: 0.0083s/iter; left time: 17.4002s\n",
      "\titers: 700, epoch: 18 | loss: 0.0561704\n",
      "\tspeed: 0.0084s/iter; left time: 16.7265s\n",
      "\titers: 800, epoch: 18 | loss: 0.0557511\n",
      "\tspeed: 0.0084s/iter; left time: 15.8612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 899 | Train Loss: 0.0526160 Vali Loss: 0.0534474 Test Loss: 0.0565230\n",
      "Validation loss decreased (0.053637 --> 0.053447).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0524720\n",
      "\tspeed: 0.0384s/iter; left time: 65.2654s\n",
      "\titers: 200, epoch: 19 | loss: 0.0431766\n",
      "\tspeed: 0.0084s/iter; left time: 13.3995s\n",
      "\titers: 300, epoch: 19 | loss: 0.0505582\n",
      "\tspeed: 0.0084s/iter; left time: 12.5901s\n",
      "\titers: 400, epoch: 19 | loss: 0.0463088\n",
      "\tspeed: 0.0084s/iter; left time: 11.7201s\n",
      "\titers: 500, epoch: 19 | loss: 0.0525645\n",
      "\tspeed: 0.0084s/iter; left time: 10.8957s\n",
      "\titers: 600, epoch: 19 | loss: 0.0438015\n",
      "\tspeed: 0.0084s/iter; left time: 10.0373s\n",
      "\titers: 700, epoch: 19 | loss: 0.0544649\n",
      "\tspeed: 0.0084s/iter; left time: 9.1983s\n",
      "\titers: 800, epoch: 19 | loss: 0.0455427\n",
      "\tspeed: 0.0084s/iter; left time: 8.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 899 | Train Loss: 0.0523823 Vali Loss: 0.0534442 Test Loss: 0.0564228\n",
      "Validation loss decreased (0.053447 --> 0.053444).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0484122\n",
      "\tspeed: 0.0382s/iter; left time: 30.5348s\n",
      "\titers: 200, epoch: 20 | loss: 0.0524424\n",
      "\tspeed: 0.0084s/iter; left time: 5.8468s\n",
      "\titers: 300, epoch: 20 | loss: 0.0511368\n",
      "\tspeed: 0.0083s/iter; left time: 5.0031s\n",
      "\titers: 400, epoch: 20 | loss: 0.0497488\n",
      "\tspeed: 0.0085s/iter; left time: 4.2684s\n",
      "\titers: 500, epoch: 20 | loss: 0.0522895\n",
      "\tspeed: 0.0100s/iter; left time: 3.9884s\n",
      "\titers: 600, epoch: 20 | loss: 0.0440005\n",
      "\tspeed: 0.0087s/iter; left time: 2.6050s\n",
      "\titers: 700, epoch: 20 | loss: 0.0503353\n",
      "\tspeed: 0.0086s/iter; left time: 1.7149s\n",
      "\titers: 800, epoch: 20 | loss: 0.0477799\n",
      "\tspeed: 0.0087s/iter; left time: 0.8726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 899 | Train Loss: 0.0522676 Vali Loss: 0.0532872 Test Loss: 0.0564348\n",
      "Validation loss decreased (0.053444 --> 0.053287).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010154441930353642, rmse:0.10076925158500671, mae:0.05643478408455849, rse:0.3808140456676483\n",
      "Original data scale mse:1136971.75, rmse:1066.288818359375, mae:656.8383178710938, rse:0.07493062317371368\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1745970\n",
      "\tspeed: 0.0104s/iter; left time: 186.4351s\n",
      "\titers: 200, epoch: 1 | loss: 0.1362362\n",
      "\tspeed: 0.0084s/iter; left time: 148.5118s\n",
      "\titers: 300, epoch: 1 | loss: 0.1243619\n",
      "\tspeed: 0.0084s/iter; left time: 147.8588s\n",
      "\titers: 400, epoch: 1 | loss: 0.1100698\n",
      "\tspeed: 0.0084s/iter; left time: 147.4566s\n",
      "\titers: 500, epoch: 1 | loss: 0.1008721\n",
      "\tspeed: 0.0084s/iter; left time: 146.0869s\n",
      "\titers: 600, epoch: 1 | loss: 0.1135284\n",
      "\tspeed: 0.0084s/iter; left time: 145.3980s\n",
      "\titers: 700, epoch: 1 | loss: 0.1039621\n",
      "\tspeed: 0.0084s/iter; left time: 144.7048s\n",
      "\titers: 800, epoch: 1 | loss: 0.1017329\n",
      "\tspeed: 0.0084s/iter; left time: 143.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 899 | Train Loss: 0.1233603 Vali Loss: 0.0836807 Test Loss: 0.0860414\n",
      "Validation loss decreased (inf --> 0.083681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0868273\n",
      "\tspeed: 0.0408s/iter; left time: 692.8041s\n",
      "\titers: 200, epoch: 2 | loss: 0.0712103\n",
      "\tspeed: 0.0091s/iter; left time: 153.7168s\n",
      "\titers: 300, epoch: 2 | loss: 0.0712725\n",
      "\tspeed: 0.0093s/iter; left time: 156.2240s\n",
      "\titers: 400, epoch: 2 | loss: 0.0675616\n",
      "\tspeed: 0.0092s/iter; left time: 152.7202s\n",
      "\titers: 500, epoch: 2 | loss: 0.0643040\n",
      "\tspeed: 0.0110s/iter; left time: 182.3521s\n",
      "\titers: 600, epoch: 2 | loss: 0.0745573\n",
      "\tspeed: 0.0098s/iter; left time: 161.0711s\n",
      "\titers: 700, epoch: 2 | loss: 0.0648972\n",
      "\tspeed: 0.0091s/iter; left time: 148.4574s\n",
      "\titers: 800, epoch: 2 | loss: 0.0661041\n",
      "\tspeed: 0.0087s/iter; left time: 141.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 899 | Train Loss: 0.0698801 Vali Loss: 0.0597775 Test Loss: 0.0622853\n",
      "Validation loss decreased (0.083681 --> 0.059777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0607562\n",
      "\tspeed: 0.0438s/iter; left time: 703.6558s\n",
      "\titers: 200, epoch: 3 | loss: 0.0573382\n",
      "\tspeed: 0.0086s/iter; left time: 138.1900s\n",
      "\titers: 300, epoch: 3 | loss: 0.0584049\n",
      "\tspeed: 0.0108s/iter; left time: 171.7731s\n",
      "\titers: 400, epoch: 3 | loss: 0.0591877\n",
      "\tspeed: 0.0089s/iter; left time: 139.9777s\n",
      "\titers: 500, epoch: 3 | loss: 0.0543827\n",
      "\tspeed: 0.0088s/iter; left time: 137.5784s\n",
      "\titers: 600, epoch: 3 | loss: 0.0601249\n",
      "\tspeed: 0.0087s/iter; left time: 135.5947s\n",
      "\titers: 700, epoch: 3 | loss: 0.0627699\n",
      "\tspeed: 0.0087s/iter; left time: 134.3587s\n",
      "\titers: 800, epoch: 3 | loss: 0.0568044\n",
      "\tspeed: 0.0086s/iter; left time: 133.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 899 | Train Loss: 0.0620550 Vali Loss: 0.0578717 Test Loss: 0.0602620\n",
      "Validation loss decreased (0.059777 --> 0.057872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0641706\n",
      "\tspeed: 0.0412s/iter; left time: 625.9534s\n",
      "\titers: 200, epoch: 4 | loss: 0.0586254\n",
      "\tspeed: 0.0093s/iter; left time: 139.5757s\n",
      "\titers: 300, epoch: 4 | loss: 0.0489829\n",
      "\tspeed: 0.0094s/iter; left time: 140.1822s\n",
      "\titers: 400, epoch: 4 | loss: 0.0579348\n",
      "\tspeed: 0.0091s/iter; left time: 135.0908s\n",
      "\titers: 500, epoch: 4 | loss: 0.0610140\n",
      "\tspeed: 0.0095s/iter; left time: 140.4025s\n",
      "\titers: 600, epoch: 4 | loss: 0.0539877\n",
      "\tspeed: 0.0090s/iter; left time: 132.4561s\n",
      "\titers: 700, epoch: 4 | loss: 0.0545742\n",
      "\tspeed: 0.0098s/iter; left time: 142.8837s\n",
      "\titers: 800, epoch: 4 | loss: 0.0555878\n",
      "\tspeed: 0.0090s/iter; left time: 130.2680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 899 | Train Loss: 0.0596278 Vali Loss: 0.0571546 Test Loss: 0.0598173\n",
      "Validation loss decreased (0.057872 --> 0.057155).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0564064\n",
      "\tspeed: 0.0411s/iter; left time: 586.7144s\n",
      "\titers: 200, epoch: 5 | loss: 0.0553008\n",
      "\tspeed: 0.0089s/iter; left time: 126.1006s\n",
      "\titers: 300, epoch: 5 | loss: 0.0659276\n",
      "\tspeed: 0.0084s/iter; left time: 118.9034s\n",
      "\titers: 400, epoch: 5 | loss: 0.0601190\n",
      "\tspeed: 0.0085s/iter; left time: 118.4001s\n",
      "\titers: 500, epoch: 5 | loss: 0.0584490\n",
      "\tspeed: 0.0085s/iter; left time: 118.1191s\n",
      "\titers: 600, epoch: 5 | loss: 0.0600764\n",
      "\tspeed: 0.0085s/iter; left time: 117.1912s\n",
      "\titers: 700, epoch: 5 | loss: 0.0576137\n",
      "\tspeed: 0.0088s/iter; left time: 120.0677s\n",
      "\titers: 800, epoch: 5 | loss: 0.0565569\n",
      "\tspeed: 0.0094s/iter; left time: 127.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 899 | Train Loss: 0.0580023 Vali Loss: 0.0559461 Test Loss: 0.0585377\n",
      "Validation loss decreased (0.057155 --> 0.055946).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0562517\n",
      "\tspeed: 0.0405s/iter; left time: 541.6449s\n",
      "\titers: 200, epoch: 6 | loss: 0.0498216\n",
      "\tspeed: 0.0088s/iter; left time: 116.3510s\n",
      "\titers: 300, epoch: 6 | loss: 0.0574807\n",
      "\tspeed: 0.0088s/iter; left time: 116.1985s\n",
      "\titers: 400, epoch: 6 | loss: 0.0638005\n",
      "\tspeed: 0.0087s/iter; left time: 113.5635s\n",
      "\titers: 500, epoch: 6 | loss: 0.0499901\n",
      "\tspeed: 0.0087s/iter; left time: 112.5767s\n",
      "\titers: 600, epoch: 6 | loss: 0.0641989\n",
      "\tspeed: 0.0087s/iter; left time: 111.8037s\n",
      "\titers: 700, epoch: 6 | loss: 0.0626553\n",
      "\tspeed: 0.0088s/iter; left time: 112.8708s\n",
      "\titers: 800, epoch: 6 | loss: 0.0624837\n",
      "\tspeed: 0.0094s/iter; left time: 119.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 899 | Train Loss: 0.0568271 Vali Loss: 0.0555891 Test Loss: 0.0586004\n",
      "Validation loss decreased (0.055946 --> 0.055589).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0601121\n",
      "\tspeed: 0.0403s/iter; left time: 503.4359s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570995\n",
      "\tspeed: 0.0088s/iter; left time: 109.4838s\n",
      "\titers: 300, epoch: 7 | loss: 0.0614301\n",
      "\tspeed: 0.0090s/iter; left time: 110.4370s\n",
      "\titers: 400, epoch: 7 | loss: 0.0584103\n",
      "\tspeed: 0.0089s/iter; left time: 108.5102s\n",
      "\titers: 500, epoch: 7 | loss: 0.0564767\n",
      "\tspeed: 0.0088s/iter; left time: 106.8386s\n",
      "\titers: 600, epoch: 7 | loss: 0.0495751\n",
      "\tspeed: 0.0089s/iter; left time: 106.4244s\n",
      "\titers: 700, epoch: 7 | loss: 0.0525894\n",
      "\tspeed: 0.0087s/iter; left time: 102.8907s\n",
      "\titers: 800, epoch: 7 | loss: 0.0567591\n",
      "\tspeed: 0.0086s/iter; left time: 101.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 899 | Train Loss: 0.0560630 Vali Loss: 0.0547386 Test Loss: 0.0575288\n",
      "Validation loss decreased (0.055589 --> 0.054739).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0680977\n",
      "\tspeed: 0.0400s/iter; left time: 463.1704s\n",
      "\titers: 200, epoch: 8 | loss: 0.0493637\n",
      "\tspeed: 0.0088s/iter; left time: 100.6398s\n",
      "\titers: 300, epoch: 8 | loss: 0.0544681\n",
      "\tspeed: 0.0088s/iter; left time: 99.7568s\n",
      "\titers: 400, epoch: 8 | loss: 0.0527861\n",
      "\tspeed: 0.0084s/iter; left time: 94.9367s\n",
      "\titers: 500, epoch: 8 | loss: 0.0531571\n",
      "\tspeed: 0.0087s/iter; left time: 97.6051s\n",
      "\titers: 600, epoch: 8 | loss: 0.0526033\n",
      "\tspeed: 0.0089s/iter; left time: 98.8484s\n",
      "\titers: 700, epoch: 8 | loss: 0.0581967\n",
      "\tspeed: 0.0089s/iter; left time: 97.4796s\n",
      "\titers: 800, epoch: 8 | loss: 0.0510311\n",
      "\tspeed: 0.0088s/iter; left time: 95.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 899 | Train Loss: 0.0554074 Vali Loss: 0.0549750 Test Loss: 0.0576825\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0563632\n",
      "\tspeed: 0.0394s/iter; left time: 421.5725s\n",
      "\titers: 200, epoch: 9 | loss: 0.0524686\n",
      "\tspeed: 0.0086s/iter; left time: 91.5816s\n",
      "\titers: 300, epoch: 9 | loss: 0.0457147\n",
      "\tspeed: 0.0085s/iter; left time: 89.5753s\n",
      "\titers: 400, epoch: 9 | loss: 0.0526936\n",
      "\tspeed: 0.0085s/iter; left time: 87.8622s\n",
      "\titers: 500, epoch: 9 | loss: 0.0509271\n",
      "\tspeed: 0.0090s/iter; left time: 92.6031s\n",
      "\titers: 600, epoch: 9 | loss: 0.0567733\n",
      "\tspeed: 0.0087s/iter; left time: 88.5409s\n",
      "\titers: 700, epoch: 9 | loss: 0.0473347\n",
      "\tspeed: 0.0085s/iter; left time: 85.4429s\n",
      "\titers: 800, epoch: 9 | loss: 0.0538500\n",
      "\tspeed: 0.0085s/iter; left time: 84.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 899 | Train Loss: 0.0548278 Vali Loss: 0.0545451 Test Loss: 0.0572658\n",
      "Validation loss decreased (0.054739 --> 0.054545).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0553836\n",
      "\tspeed: 0.0455s/iter; left time: 445.5684s\n",
      "\titers: 200, epoch: 10 | loss: 0.0484717\n",
      "\tspeed: 0.0093s/iter; left time: 90.1236s\n",
      "\titers: 300, epoch: 10 | loss: 0.0535518\n",
      "\tspeed: 0.0103s/iter; left time: 98.4076s\n",
      "\titers: 400, epoch: 10 | loss: 0.0618981\n",
      "\tspeed: 0.0086s/iter; left time: 81.7802s\n",
      "\titers: 500, epoch: 10 | loss: 0.0558849\n",
      "\tspeed: 0.0108s/iter; left time: 100.9597s\n",
      "\titers: 600, epoch: 10 | loss: 0.0494470\n",
      "\tspeed: 0.0086s/iter; left time: 80.3477s\n",
      "\titers: 700, epoch: 10 | loss: 0.0487612\n",
      "\tspeed: 0.0087s/iter; left time: 79.5363s\n",
      "\titers: 800, epoch: 10 | loss: 0.0580632\n",
      "\tspeed: 0.0087s/iter; left time: 79.0321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 899 | Train Loss: 0.0543593 Vali Loss: 0.0543796 Test Loss: 0.0576214\n",
      "Validation loss decreased (0.054545 --> 0.054380).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0594514\n",
      "\tspeed: 0.0393s/iter; left time: 349.5727s\n",
      "\titers: 200, epoch: 11 | loss: 0.0537957\n",
      "\tspeed: 0.0083s/iter; left time: 73.0458s\n",
      "\titers: 300, epoch: 11 | loss: 0.0633883\n",
      "\tspeed: 0.0084s/iter; left time: 73.4260s\n",
      "\titers: 400, epoch: 11 | loss: 0.0528174\n",
      "\tspeed: 0.0087s/iter; left time: 74.5780s\n",
      "\titers: 500, epoch: 11 | loss: 0.0551074\n",
      "\tspeed: 0.0087s/iter; left time: 73.6186s\n",
      "\titers: 600, epoch: 11 | loss: 0.0560416\n",
      "\tspeed: 0.0087s/iter; left time: 72.6660s\n",
      "\titers: 700, epoch: 11 | loss: 0.0510706\n",
      "\tspeed: 0.0087s/iter; left time: 71.9005s\n",
      "\titers: 800, epoch: 11 | loss: 0.0528166\n",
      "\tspeed: 0.0086s/iter; left time: 70.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 899 | Train Loss: 0.0540606 Vali Loss: 0.0542038 Test Loss: 0.0569707\n",
      "Validation loss decreased (0.054380 --> 0.054204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0515615\n",
      "\tspeed: 0.0419s/iter; left time: 335.0793s\n",
      "\titers: 200, epoch: 12 | loss: 0.0491547\n",
      "\tspeed: 0.0085s/iter; left time: 67.1967s\n",
      "\titers: 300, epoch: 12 | loss: 0.0483418\n",
      "\tspeed: 0.0085s/iter; left time: 66.5531s\n",
      "\titers: 400, epoch: 12 | loss: 0.0459311\n",
      "\tspeed: 0.0086s/iter; left time: 65.8890s\n",
      "\titers: 500, epoch: 12 | loss: 0.0446333\n",
      "\tspeed: 0.0086s/iter; left time: 65.1344s\n",
      "\titers: 600, epoch: 12 | loss: 0.0596376\n",
      "\tspeed: 0.0086s/iter; left time: 64.4990s\n",
      "\titers: 700, epoch: 12 | loss: 0.0518609\n",
      "\tspeed: 0.0086s/iter; left time: 63.5691s\n",
      "\titers: 800, epoch: 12 | loss: 0.0545710\n",
      "\tspeed: 0.0086s/iter; left time: 62.7750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 899 | Train Loss: 0.0536925 Vali Loss: 0.0539636 Test Loss: 0.0570455\n",
      "Validation loss decreased (0.054204 --> 0.053964).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0629774\n",
      "\tspeed: 0.0389s/iter; left time: 276.0461s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536872\n",
      "\tspeed: 0.0085s/iter; left time: 59.6970s\n",
      "\titers: 300, epoch: 13 | loss: 0.0480245\n",
      "\tspeed: 0.0085s/iter; left time: 58.7094s\n",
      "\titers: 400, epoch: 13 | loss: 0.0471891\n",
      "\tspeed: 0.0085s/iter; left time: 57.8796s\n",
      "\titers: 500, epoch: 13 | loss: 0.0607830\n",
      "\tspeed: 0.0085s/iter; left time: 56.9866s\n",
      "\titers: 600, epoch: 13 | loss: 0.0528974\n",
      "\tspeed: 0.0085s/iter; left time: 56.1648s\n",
      "\titers: 700, epoch: 13 | loss: 0.0625108\n",
      "\tspeed: 0.0085s/iter; left time: 55.3245s\n",
      "\titers: 800, epoch: 13 | loss: 0.0497113\n",
      "\tspeed: 0.0086s/iter; left time: 55.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 899 | Train Loss: 0.0534536 Vali Loss: 0.0537022 Test Loss: 0.0564996\n",
      "Validation loss decreased (0.053964 --> 0.053702).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470890\n",
      "\tspeed: 0.0386s/iter; left time: 238.9356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0498632\n",
      "\tspeed: 0.0084s/iter; left time: 51.3460s\n",
      "\titers: 300, epoch: 14 | loss: 0.0435860\n",
      "\tspeed: 0.0084s/iter; left time: 50.6240s\n",
      "\titers: 400, epoch: 14 | loss: 0.0405126\n",
      "\tspeed: 0.0084s/iter; left time: 49.7304s\n",
      "\titers: 500, epoch: 14 | loss: 0.0552683\n",
      "\tspeed: 0.0084s/iter; left time: 48.7615s\n",
      "\titers: 600, epoch: 14 | loss: 0.0532328\n",
      "\tspeed: 0.0084s/iter; left time: 48.0301s\n",
      "\titers: 700, epoch: 14 | loss: 0.0534556\n",
      "\tspeed: 0.0086s/iter; left time: 48.0319s\n",
      "\titers: 800, epoch: 14 | loss: 0.0495995\n",
      "\tspeed: 0.0085s/iter; left time: 46.5366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 899 | Train Loss: 0.0531598 Vali Loss: 0.0537457 Test Loss: 0.0566733\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521199\n",
      "\tspeed: 0.0391s/iter; left time: 207.0364s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575236\n",
      "\tspeed: 0.0087s/iter; left time: 45.1542s\n",
      "\titers: 300, epoch: 15 | loss: 0.0532496\n",
      "\tspeed: 0.0086s/iter; left time: 44.0459s\n",
      "\titers: 400, epoch: 15 | loss: 0.0483925\n",
      "\tspeed: 0.0087s/iter; left time: 43.2465s\n",
      "\titers: 500, epoch: 15 | loss: 0.0554117\n",
      "\tspeed: 0.0087s/iter; left time: 42.3991s\n",
      "\titers: 600, epoch: 15 | loss: 0.0514534\n",
      "\tspeed: 0.0087s/iter; left time: 41.6077s\n",
      "\titers: 700, epoch: 15 | loss: 0.0533527\n",
      "\tspeed: 0.0086s/iter; left time: 40.3459s\n",
      "\titers: 800, epoch: 15 | loss: 0.0547238\n",
      "\tspeed: 0.0086s/iter; left time: 39.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 899 | Train Loss: 0.0529861 Vali Loss: 0.0535848 Test Loss: 0.0565886\n",
      "Validation loss decreased (0.053702 --> 0.053585).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0491242\n",
      "\tspeed: 0.0397s/iter; left time: 174.6016s\n",
      "\titers: 200, epoch: 16 | loss: 0.0519159\n",
      "\tspeed: 0.0086s/iter; left time: 36.8331s\n",
      "\titers: 300, epoch: 16 | loss: 0.0619587\n",
      "\tspeed: 0.0086s/iter; left time: 36.0585s\n",
      "\titers: 400, epoch: 16 | loss: 0.0556353\n",
      "\tspeed: 0.0085s/iter; left time: 34.9784s\n",
      "\titers: 500, epoch: 16 | loss: 0.0447307\n",
      "\tspeed: 0.0085s/iter; left time: 34.1173s\n",
      "\titers: 600, epoch: 16 | loss: 0.0478722\n",
      "\tspeed: 0.0093s/iter; left time: 36.2389s\n",
      "\titers: 700, epoch: 16 | loss: 0.0510559\n",
      "\tspeed: 0.0085s/iter; left time: 32.3538s\n",
      "\titers: 800, epoch: 16 | loss: 0.0529573\n",
      "\tspeed: 0.0087s/iter; left time: 32.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 899 | Train Loss: 0.0527103 Vali Loss: 0.0535088 Test Loss: 0.0565740\n",
      "Validation loss decreased (0.053585 --> 0.053509).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0478330\n",
      "\tspeed: 0.0434s/iter; left time: 151.7949s\n",
      "\titers: 200, epoch: 17 | loss: 0.0523026\n",
      "\tspeed: 0.0084s/iter; left time: 28.4961s\n",
      "\titers: 300, epoch: 17 | loss: 0.0554195\n",
      "\tspeed: 0.0085s/iter; left time: 28.0899s\n",
      "\titers: 400, epoch: 17 | loss: 0.0575015\n",
      "\tspeed: 0.0087s/iter; left time: 27.8535s\n",
      "\titers: 500, epoch: 17 | loss: 0.0580324\n",
      "\tspeed: 0.0087s/iter; left time: 26.8988s\n",
      "\titers: 600, epoch: 17 | loss: 0.0510341\n",
      "\tspeed: 0.0085s/iter; left time: 25.6013s\n",
      "\titers: 700, epoch: 17 | loss: 0.0482460\n",
      "\tspeed: 0.0085s/iter; left time: 24.6555s\n",
      "\titers: 800, epoch: 17 | loss: 0.0458487\n",
      "\tspeed: 0.0084s/iter; left time: 23.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 899 | Train Loss: 0.0525888 Vali Loss: 0.0534194 Test Loss: 0.0565442\n",
      "Validation loss decreased (0.053509 --> 0.053419).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0605156\n",
      "\tspeed: 0.0412s/iter; left time: 107.1137s\n",
      "\titers: 200, epoch: 18 | loss: 0.0549867\n",
      "\tspeed: 0.0111s/iter; left time: 27.6157s\n",
      "\titers: 300, epoch: 18 | loss: 0.0577672\n",
      "\tspeed: 0.0107s/iter; left time: 25.5585s\n",
      "\titers: 400, epoch: 18 | loss: 0.0466577\n",
      "\tspeed: 0.0110s/iter; left time: 25.2958s\n",
      "\titers: 500, epoch: 18 | loss: 0.0546953\n",
      "\tspeed: 0.0117s/iter; left time: 25.7493s\n",
      "\titers: 600, epoch: 18 | loss: 0.0489425\n",
      "\tspeed: 0.0105s/iter; left time: 21.9387s\n",
      "\titers: 700, epoch: 18 | loss: 0.0431009\n",
      "\tspeed: 0.0107s/iter; left time: 21.4146s\n",
      "\titers: 800, epoch: 18 | loss: 0.0475174\n",
      "\tspeed: 0.0089s/iter; left time: 16.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 899 | Train Loss: 0.0524367 Vali Loss: 0.0534199 Test Loss: 0.0564503\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0488207\n",
      "\tspeed: 0.0390s/iter; left time: 66.2528s\n",
      "\titers: 200, epoch: 19 | loss: 0.0470749\n",
      "\tspeed: 0.0086s/iter; left time: 13.7607s\n",
      "\titers: 300, epoch: 19 | loss: 0.0521912\n",
      "\tspeed: 0.0086s/iter; left time: 12.8990s\n",
      "\titers: 400, epoch: 19 | loss: 0.0456030\n",
      "\tspeed: 0.0086s/iter; left time: 11.9957s\n",
      "\titers: 500, epoch: 19 | loss: 0.0558893\n",
      "\tspeed: 0.0086s/iter; left time: 11.1760s\n",
      "\titers: 600, epoch: 19 | loss: 0.0514244\n",
      "\tspeed: 0.0087s/iter; left time: 10.3772s\n",
      "\titers: 700, epoch: 19 | loss: 0.0561091\n",
      "\tspeed: 0.0087s/iter; left time: 9.5127s\n",
      "\titers: 800, epoch: 19 | loss: 0.0482208\n",
      "\tspeed: 0.0084s/iter; left time: 8.4339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 899 | Train Loss: 0.0522364 Vali Loss: 0.0532984 Test Loss: 0.0565264\n",
      "Validation loss decreased (0.053419 --> 0.053298).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0518415\n",
      "\tspeed: 0.0391s/iter; left time: 31.2600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0518799\n",
      "\tspeed: 0.0087s/iter; left time: 6.0809s\n",
      "\titers: 300, epoch: 20 | loss: 0.0542073\n",
      "\tspeed: 0.0087s/iter; left time: 5.2176s\n",
      "\titers: 400, epoch: 20 | loss: 0.0500053\n",
      "\tspeed: 0.0087s/iter; left time: 4.3497s\n",
      "\titers: 500, epoch: 20 | loss: 0.0501625\n",
      "\tspeed: 0.0087s/iter; left time: 3.4745s\n",
      "\titers: 600, epoch: 20 | loss: 0.0498641\n",
      "\tspeed: 0.0087s/iter; left time: 2.6067s\n",
      "\titers: 700, epoch: 20 | loss: 0.0519767\n",
      "\tspeed: 0.0087s/iter; left time: 1.7375s\n",
      "\titers: 800, epoch: 20 | loss: 0.0552066\n",
      "\tspeed: 0.0087s/iter; left time: 0.8702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 899 | Train Loss: 0.0521951 Vali Loss: 0.0532630 Test Loss: 0.0564517\n",
      "Validation loss decreased (0.053298 --> 0.053263).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010180042125284672, rmse:0.1008961945772171, mae:0.056451667100191116, rse:0.38129374384880066\n",
      "Original data scale mse:1138836.625, rmse:1067.162841796875, mae:654.0407104492188, rse:0.07499205321073532\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1708805\n",
      "\tspeed: 0.0303s/iter; left time: 540.2952s\n",
      "\titers: 200, epoch: 1 | loss: 0.1412551\n",
      "\tspeed: 0.0094s/iter; left time: 165.9142s\n",
      "\titers: 300, epoch: 1 | loss: 0.1277216\n",
      "\tspeed: 0.0087s/iter; left time: 153.6471s\n",
      "\titers: 400, epoch: 1 | loss: 0.1194239\n",
      "\tspeed: 0.0085s/iter; left time: 149.9722s\n",
      "\titers: 500, epoch: 1 | loss: 0.1203251\n",
      "\tspeed: 0.0086s/iter; left time: 150.3329s\n",
      "\titers: 600, epoch: 1 | loss: 0.1157655\n",
      "\tspeed: 0.0085s/iter; left time: 147.4755s\n",
      "\titers: 700, epoch: 1 | loss: 0.1135600\n",
      "\tspeed: 0.0085s/iter; left time: 146.8484s\n",
      "\titers: 800, epoch: 1 | loss: 0.1210854\n",
      "\tspeed: 0.0085s/iter; left time: 146.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 897 | Train Loss: 0.1318972 Vali Loss: 0.0978718 Test Loss: 0.1008648\n",
      "Validation loss decreased (inf --> 0.097872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989415\n",
      "\tspeed: 0.0420s/iter; left time: 711.9801s\n",
      "\titers: 200, epoch: 2 | loss: 0.0891925\n",
      "\tspeed: 0.0085s/iter; left time: 142.7567s\n",
      "\titers: 300, epoch: 2 | loss: 0.0866433\n",
      "\tspeed: 0.0085s/iter; left time: 141.8987s\n",
      "\titers: 400, epoch: 2 | loss: 0.0883691\n",
      "\tspeed: 0.0086s/iter; left time: 142.6979s\n",
      "\titers: 500, epoch: 2 | loss: 0.0885621\n",
      "\tspeed: 0.0085s/iter; left time: 140.0466s\n",
      "\titers: 600, epoch: 2 | loss: 0.0794182\n",
      "\tspeed: 0.0118s/iter; left time: 194.7315s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763809\n",
      "\tspeed: 0.0087s/iter; left time: 142.5059s\n",
      "\titers: 800, epoch: 2 | loss: 0.0849773\n",
      "\tspeed: 0.0085s/iter; left time: 138.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 897 | Train Loss: 0.0888911 Vali Loss: 0.0794706 Test Loss: 0.0841773\n",
      "Validation loss decreased (0.097872 --> 0.079471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0824038\n",
      "\tspeed: 0.0434s/iter; left time: 697.2337s\n",
      "\titers: 200, epoch: 3 | loss: 0.0864248\n",
      "\tspeed: 0.0103s/iter; left time: 163.5872s\n",
      "\titers: 300, epoch: 3 | loss: 0.0736913\n",
      "\tspeed: 0.0087s/iter; left time: 137.2521s\n",
      "\titers: 400, epoch: 3 | loss: 0.0795692\n",
      "\tspeed: 0.0086s/iter; left time: 135.3179s\n",
      "\titers: 500, epoch: 3 | loss: 0.0687195\n",
      "\tspeed: 0.0095s/iter; left time: 148.4006s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893032\n",
      "\tspeed: 0.0086s/iter; left time: 133.3548s\n",
      "\titers: 700, epoch: 3 | loss: 0.0771745\n",
      "\tspeed: 0.0086s/iter; left time: 133.5073s\n",
      "\titers: 800, epoch: 3 | loss: 0.0800088\n",
      "\tspeed: 0.0087s/iter; left time: 132.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 897 | Train Loss: 0.0816509 Vali Loss: 0.0779648 Test Loss: 0.0830527\n",
      "Validation loss decreased (0.079471 --> 0.077965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836727\n",
      "\tspeed: 0.0395s/iter; left time: 598.2395s\n",
      "\titers: 200, epoch: 4 | loss: 0.0755323\n",
      "\tspeed: 0.0088s/iter; left time: 133.0544s\n",
      "\titers: 300, epoch: 4 | loss: 0.0811564\n",
      "\tspeed: 0.0088s/iter; left time: 131.7867s\n",
      "\titers: 400, epoch: 4 | loss: 0.0791053\n",
      "\tspeed: 0.0088s/iter; left time: 131.0683s\n",
      "\titers: 500, epoch: 4 | loss: 0.0747812\n",
      "\tspeed: 0.0086s/iter; left time: 126.8418s\n",
      "\titers: 600, epoch: 4 | loss: 0.0741449\n",
      "\tspeed: 0.0086s/iter; left time: 126.4561s\n",
      "\titers: 700, epoch: 4 | loss: 0.0899509\n",
      "\tspeed: 0.0086s/iter; left time: 125.8096s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751809\n",
      "\tspeed: 0.0088s/iter; left time: 126.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 897 | Train Loss: 0.0792859 Vali Loss: 0.0775702 Test Loss: 0.0828155\n",
      "Validation loss decreased (0.077965 --> 0.077570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770186\n",
      "\tspeed: 0.0413s/iter; left time: 588.6752s\n",
      "\titers: 200, epoch: 5 | loss: 0.0705070\n",
      "\tspeed: 0.0086s/iter; left time: 121.8826s\n",
      "\titers: 300, epoch: 5 | loss: 0.0759331\n",
      "\tspeed: 0.0086s/iter; left time: 121.0894s\n",
      "\titers: 400, epoch: 5 | loss: 0.0821801\n",
      "\tspeed: 0.0086s/iter; left time: 120.1174s\n",
      "\titers: 500, epoch: 5 | loss: 0.0862341\n",
      "\tspeed: 0.0086s/iter; left time: 119.6678s\n",
      "\titers: 600, epoch: 5 | loss: 0.0733199\n",
      "\tspeed: 0.0086s/iter; left time: 118.7817s\n",
      "\titers: 700, epoch: 5 | loss: 0.0787596\n",
      "\tspeed: 0.0087s/iter; left time: 118.2187s\n",
      "\titers: 800, epoch: 5 | loss: 0.0949860\n",
      "\tspeed: 0.0087s/iter; left time: 118.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 897 | Train Loss: 0.0775383 Vali Loss: 0.0768286 Test Loss: 0.0818250\n",
      "Validation loss decreased (0.077570 --> 0.076829).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711937\n",
      "\tspeed: 0.0412s/iter; left time: 550.6872s\n",
      "\titers: 200, epoch: 6 | loss: 0.0683018\n",
      "\tspeed: 0.0086s/iter; left time: 114.2008s\n",
      "\titers: 300, epoch: 6 | loss: 0.0738117\n",
      "\tspeed: 0.0087s/iter; left time: 114.4811s\n",
      "\titers: 400, epoch: 6 | loss: 0.0758951\n",
      "\tspeed: 0.0086s/iter; left time: 112.7524s\n",
      "\titers: 500, epoch: 6 | loss: 0.0753310\n",
      "\tspeed: 0.0086s/iter; left time: 111.4614s\n",
      "\titers: 600, epoch: 6 | loss: 0.0704748\n",
      "\tspeed: 0.0086s/iter; left time: 110.6215s\n",
      "\titers: 700, epoch: 6 | loss: 0.0818257\n",
      "\tspeed: 0.0086s/iter; left time: 110.0031s\n",
      "\titers: 800, epoch: 6 | loss: 0.0677308\n",
      "\tspeed: 0.0087s/iter; left time: 110.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 897 | Train Loss: 0.0761277 Vali Loss: 0.0769486 Test Loss: 0.0817598\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0822666\n",
      "\tspeed: 0.0393s/iter; left time: 489.7354s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733081\n",
      "\tspeed: 0.0087s/iter; left time: 106.9205s\n",
      "\titers: 300, epoch: 7 | loss: 0.0692510\n",
      "\tspeed: 0.0086s/iter; left time: 105.7385s\n",
      "\titers: 400, epoch: 7 | loss: 0.0709503\n",
      "\tspeed: 0.0086s/iter; left time: 104.8506s\n",
      "\titers: 500, epoch: 7 | loss: 0.0659880\n",
      "\tspeed: 0.0086s/iter; left time: 103.9736s\n",
      "\titers: 600, epoch: 7 | loss: 0.0822174\n",
      "\tspeed: 0.0086s/iter; left time: 103.0621s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794314\n",
      "\tspeed: 0.0086s/iter; left time: 102.1710s\n",
      "\titers: 800, epoch: 7 | loss: 0.0757879\n",
      "\tspeed: 0.0086s/iter; left time: 101.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 897 | Train Loss: 0.0749485 Vali Loss: 0.0767103 Test Loss: 0.0814315\n",
      "Validation loss decreased (0.076829 --> 0.076710).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0702958\n",
      "\tspeed: 0.0394s/iter; left time: 455.8742s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790633\n",
      "\tspeed: 0.0085s/iter; left time: 97.4325s\n",
      "\titers: 300, epoch: 8 | loss: 0.0794195\n",
      "\tspeed: 0.0085s/iter; left time: 97.0366s\n",
      "\titers: 400, epoch: 8 | loss: 0.0718726\n",
      "\tspeed: 0.0086s/iter; left time: 96.3192s\n",
      "\titers: 500, epoch: 8 | loss: 0.0628259\n",
      "\tspeed: 0.0085s/iter; left time: 95.3142s\n",
      "\titers: 600, epoch: 8 | loss: 0.0689449\n",
      "\tspeed: 0.0085s/iter; left time: 94.3832s\n",
      "\titers: 700, epoch: 8 | loss: 0.0713064\n",
      "\tspeed: 0.0096s/iter; left time: 104.6896s\n",
      "\titers: 800, epoch: 8 | loss: 0.0747390\n",
      "\tspeed: 0.0085s/iter; left time: 91.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 897 | Train Loss: 0.0737772 Vali Loss: 0.0766239 Test Loss: 0.0809693\n",
      "Validation loss decreased (0.076710 --> 0.076624).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829301\n",
      "\tspeed: 0.0412s/iter; left time: 439.4095s\n",
      "\titers: 200, epoch: 9 | loss: 0.0750943\n",
      "\tspeed: 0.0089s/iter; left time: 94.3969s\n",
      "\titers: 300, epoch: 9 | loss: 0.0820963\n",
      "\tspeed: 0.0104s/iter; left time: 108.9049s\n",
      "\titers: 400, epoch: 9 | loss: 0.0745441\n",
      "\tspeed: 0.0088s/iter; left time: 91.0573s\n",
      "\titers: 500, epoch: 9 | loss: 0.0705703\n",
      "\tspeed: 0.0086s/iter; left time: 88.3863s\n",
      "\titers: 600, epoch: 9 | loss: 0.0681622\n",
      "\tspeed: 0.0086s/iter; left time: 87.2774s\n",
      "\titers: 700, epoch: 9 | loss: 0.0779018\n",
      "\tspeed: 0.0086s/iter; left time: 86.1848s\n",
      "\titers: 800, epoch: 9 | loss: 0.0691212\n",
      "\tspeed: 0.0085s/iter; left time: 85.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 897 | Train Loss: 0.0728261 Vali Loss: 0.0766890 Test Loss: 0.0808661\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0603640\n",
      "\tspeed: 0.0381s/iter; left time: 372.5591s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730878\n",
      "\tspeed: 0.0087s/iter; left time: 83.9394s\n",
      "\titers: 300, epoch: 10 | loss: 0.0681768\n",
      "\tspeed: 0.0087s/iter; left time: 83.1590s\n",
      "\titers: 400, epoch: 10 | loss: 0.0759636\n",
      "\tspeed: 0.0087s/iter; left time: 82.0909s\n",
      "\titers: 500, epoch: 10 | loss: 0.0830688\n",
      "\tspeed: 0.0087s/iter; left time: 81.1502s\n",
      "\titers: 600, epoch: 10 | loss: 0.0742471\n",
      "\tspeed: 0.0089s/iter; left time: 82.4307s\n",
      "\titers: 700, epoch: 10 | loss: 0.0710265\n",
      "\tspeed: 0.0087s/iter; left time: 79.8300s\n",
      "\titers: 800, epoch: 10 | loss: 0.0788138\n",
      "\tspeed: 0.0088s/iter; left time: 79.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 897 | Train Loss: 0.0720068 Vali Loss: 0.0764157 Test Loss: 0.0810015\n",
      "Validation loss decreased (0.076624 --> 0.076416).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736144\n",
      "\tspeed: 0.0421s/iter; left time: 373.5382s\n",
      "\titers: 200, epoch: 11 | loss: 0.0762086\n",
      "\tspeed: 0.0084s/iter; left time: 74.1067s\n",
      "\titers: 300, epoch: 11 | loss: 0.0734797\n",
      "\tspeed: 0.0084s/iter; left time: 72.6924s\n",
      "\titers: 400, epoch: 11 | loss: 0.0693691\n",
      "\tspeed: 0.0084s/iter; left time: 71.7495s\n",
      "\titers: 500, epoch: 11 | loss: 0.0711025\n",
      "\tspeed: 0.0084s/iter; left time: 71.2415s\n",
      "\titers: 600, epoch: 11 | loss: 0.0702377\n",
      "\tspeed: 0.0084s/iter; left time: 70.2898s\n",
      "\titers: 700, epoch: 11 | loss: 0.0788250\n",
      "\tspeed: 0.0084s/iter; left time: 69.4932s\n",
      "\titers: 800, epoch: 11 | loss: 0.0683402\n",
      "\tspeed: 0.0084s/iter; left time: 68.8001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 897 | Train Loss: 0.0712321 Vali Loss: 0.0762997 Test Loss: 0.0807599\n",
      "Validation loss decreased (0.076416 --> 0.076300).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0681119\n",
      "\tspeed: 0.0382s/iter; left time: 304.6272s\n",
      "\titers: 200, epoch: 12 | loss: 0.0711084\n",
      "\tspeed: 0.0085s/iter; left time: 66.6270s\n",
      "\titers: 300, epoch: 12 | loss: 0.0702774\n",
      "\tspeed: 0.0083s/iter; left time: 64.8131s\n",
      "\titers: 400, epoch: 12 | loss: 0.0712768\n",
      "\tspeed: 0.0083s/iter; left time: 64.0674s\n",
      "\titers: 500, epoch: 12 | loss: 0.0716618\n",
      "\tspeed: 0.0084s/iter; left time: 63.8656s\n",
      "\titers: 600, epoch: 12 | loss: 0.0686688\n",
      "\tspeed: 0.0084s/iter; left time: 63.0841s\n",
      "\titers: 700, epoch: 12 | loss: 0.0669762\n",
      "\tspeed: 0.0086s/iter; left time: 63.1718s\n",
      "\titers: 800, epoch: 12 | loss: 0.0668795\n",
      "\tspeed: 0.0086s/iter; left time: 62.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 897 | Train Loss: 0.0705363 Vali Loss: 0.0763480 Test Loss: 0.0805624\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721765\n",
      "\tspeed: 0.0388s/iter; left time: 274.4926s\n",
      "\titers: 200, epoch: 13 | loss: 0.0699496\n",
      "\tspeed: 0.0086s/iter; left time: 59.7388s\n",
      "\titers: 300, epoch: 13 | loss: 0.0722701\n",
      "\tspeed: 0.0086s/iter; left time: 58.9363s\n",
      "\titers: 400, epoch: 13 | loss: 0.0710783\n",
      "\tspeed: 0.0086s/iter; left time: 58.4742s\n",
      "\titers: 500, epoch: 13 | loss: 0.0646761\n",
      "\tspeed: 0.0086s/iter; left time: 57.1575s\n",
      "\titers: 600, epoch: 13 | loss: 0.0718390\n",
      "\tspeed: 0.0085s/iter; left time: 56.1090s\n",
      "\titers: 700, epoch: 13 | loss: 0.0646675\n",
      "\tspeed: 0.0085s/iter; left time: 55.2157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0706903\n",
      "\tspeed: 0.0085s/iter; left time: 54.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 897 | Train Loss: 0.0700386 Vali Loss: 0.0759667 Test Loss: 0.0807816\n",
      "Validation loss decreased (0.076300 --> 0.075967).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0668437\n",
      "\tspeed: 0.0390s/iter; left time: 241.2377s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623921\n",
      "\tspeed: 0.0095s/iter; left time: 57.5499s\n",
      "\titers: 300, epoch: 14 | loss: 0.0624417\n",
      "\tspeed: 0.0086s/iter; left time: 51.2171s\n",
      "\titers: 400, epoch: 14 | loss: 0.0628362\n",
      "\tspeed: 0.0086s/iter; left time: 50.5705s\n",
      "\titers: 500, epoch: 14 | loss: 0.0706031\n",
      "\tspeed: 0.0088s/iter; left time: 50.6635s\n",
      "\titers: 600, epoch: 14 | loss: 0.0777184\n",
      "\tspeed: 0.0102s/iter; left time: 57.6569s\n",
      "\titers: 700, epoch: 14 | loss: 0.0684290\n",
      "\tspeed: 0.0089s/iter; left time: 49.9184s\n",
      "\titers: 800, epoch: 14 | loss: 0.0715321\n",
      "\tspeed: 0.0101s/iter; left time: 55.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 897 | Train Loss: 0.0695033 Vali Loss: 0.0762393 Test Loss: 0.0805957\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0693248\n",
      "\tspeed: 0.0413s/iter; left time: 218.1715s\n",
      "\titers: 200, epoch: 15 | loss: 0.0626536\n",
      "\tspeed: 0.0085s/iter; left time: 43.8627s\n",
      "\titers: 300, epoch: 15 | loss: 0.0680994\n",
      "\tspeed: 0.0084s/iter; left time: 42.6802s\n",
      "\titers: 400, epoch: 15 | loss: 0.0716880\n",
      "\tspeed: 0.0084s/iter; left time: 41.7974s\n",
      "\titers: 500, epoch: 15 | loss: 0.0690726\n",
      "\tspeed: 0.0085s/iter; left time: 41.7221s\n",
      "\titers: 600, epoch: 15 | loss: 0.0691273\n",
      "\tspeed: 0.0087s/iter; left time: 41.7486s\n",
      "\titers: 700, epoch: 15 | loss: 0.0622856\n",
      "\tspeed: 0.0087s/iter; left time: 40.6803s\n",
      "\titers: 800, epoch: 15 | loss: 0.0633826\n",
      "\tspeed: 0.0086s/iter; left time: 39.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 897 | Train Loss: 0.0690579 Vali Loss: 0.0759859 Test Loss: 0.0806678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0686625\n",
      "\tspeed: 0.0388s/iter; left time: 170.2880s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666124\n",
      "\tspeed: 0.0087s/iter; left time: 37.3130s\n",
      "\titers: 300, epoch: 16 | loss: 0.0751578\n",
      "\tspeed: 0.0086s/iter; left time: 35.8662s\n",
      "\titers: 400, epoch: 16 | loss: 0.0715827\n",
      "\tspeed: 0.0108s/iter; left time: 44.0044s\n",
      "\titers: 500, epoch: 16 | loss: 0.0637077\n",
      "\tspeed: 0.0088s/iter; left time: 34.8959s\n",
      "\titers: 600, epoch: 16 | loss: 0.0741029\n",
      "\tspeed: 0.0094s/iter; left time: 36.7117s\n",
      "\titers: 700, epoch: 16 | loss: 0.0697047\n",
      "\tspeed: 0.0097s/iter; left time: 36.8544s\n",
      "\titers: 800, epoch: 16 | loss: 0.0746869\n",
      "\tspeed: 0.0092s/iter; left time: 33.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 897 | Train Loss: 0.0687106 Vali Loss: 0.0763052 Test Loss: 0.0804712\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705440\n",
      "\tspeed: 0.0381s/iter; left time: 132.9031s\n",
      "\titers: 200, epoch: 17 | loss: 0.0635481\n",
      "\tspeed: 0.0085s/iter; left time: 28.9110s\n",
      "\titers: 300, epoch: 17 | loss: 0.0739564\n",
      "\tspeed: 0.0085s/iter; left time: 28.1020s\n",
      "\titers: 400, epoch: 17 | loss: 0.0816909\n",
      "\tspeed: 0.0085s/iter; left time: 27.1234s\n",
      "\titers: 500, epoch: 17 | loss: 0.0659272\n",
      "\tspeed: 0.0085s/iter; left time: 26.2913s\n",
      "\titers: 600, epoch: 17 | loss: 0.0693205\n",
      "\tspeed: 0.0083s/iter; left time: 24.9239s\n",
      "\titers: 700, epoch: 17 | loss: 0.0663598\n",
      "\tspeed: 0.0083s/iter; left time: 23.8779s\n",
      "\titers: 800, epoch: 17 | loss: 0.0659669\n",
      "\tspeed: 0.0083s/iter; left time: 23.0580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 897 | Train Loss: 0.0682975 Vali Loss: 0.0760981 Test Loss: 0.0805807\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0626941\n",
      "\tspeed: 0.0385s/iter; left time: 99.8989s\n",
      "\titers: 200, epoch: 18 | loss: 0.0657801\n",
      "\tspeed: 0.0085s/iter; left time: 21.1912s\n",
      "\titers: 300, epoch: 18 | loss: 0.0693399\n",
      "\tspeed: 0.0085s/iter; left time: 20.3454s\n",
      "\titers: 400, epoch: 18 | loss: 0.0693728\n",
      "\tspeed: 0.0085s/iter; left time: 19.5307s\n",
      "\titers: 500, epoch: 18 | loss: 0.0563471\n",
      "\tspeed: 0.0085s/iter; left time: 18.5819s\n",
      "\titers: 600, epoch: 18 | loss: 0.0734187\n",
      "\tspeed: 0.0085s/iter; left time: 17.6993s\n",
      "\titers: 700, epoch: 18 | loss: 0.0661468\n",
      "\tspeed: 0.0085s/iter; left time: 16.8779s\n",
      "\titers: 800, epoch: 18 | loss: 0.0646449\n",
      "\tspeed: 0.0085s/iter; left time: 16.0726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 897 | Train Loss: 0.0679788 Vali Loss: 0.0758671 Test Loss: 0.0808429\n",
      "Validation loss decreased (0.075967 --> 0.075867).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711051\n",
      "\tspeed: 0.0391s/iter; left time: 66.2946s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709902\n",
      "\tspeed: 0.0085s/iter; left time: 13.6244s\n",
      "\titers: 300, epoch: 19 | loss: 0.0745760\n",
      "\tspeed: 0.0085s/iter; left time: 12.7689s\n",
      "\titers: 400, epoch: 19 | loss: 0.0647195\n",
      "\tspeed: 0.0085s/iter; left time: 11.9094s\n",
      "\titers: 500, epoch: 19 | loss: 0.0622132\n",
      "\tspeed: 0.0085s/iter; left time: 11.0350s\n",
      "\titers: 600, epoch: 19 | loss: 0.0612881\n",
      "\tspeed: 0.0085s/iter; left time: 10.1686s\n",
      "\titers: 700, epoch: 19 | loss: 0.0661993\n",
      "\tspeed: 0.0085s/iter; left time: 9.3173s\n",
      "\titers: 800, epoch: 19 | loss: 0.0669945\n",
      "\tspeed: 0.0085s/iter; left time: 8.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 897 | Train Loss: 0.0677087 Vali Loss: 0.0761142 Test Loss: 0.0805917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0749392\n",
      "\tspeed: 0.0400s/iter; left time: 31.9265s\n",
      "\titers: 200, epoch: 20 | loss: 0.0650681\n",
      "\tspeed: 0.0100s/iter; left time: 6.9991s\n",
      "\titers: 300, epoch: 20 | loss: 0.0674877\n",
      "\tspeed: 0.0086s/iter; left time: 5.1684s\n",
      "\titers: 400, epoch: 20 | loss: 0.0653007\n",
      "\tspeed: 0.0092s/iter; left time: 4.6031s\n",
      "\titers: 500, epoch: 20 | loss: 0.0725830\n",
      "\tspeed: 0.0101s/iter; left time: 4.0378s\n",
      "\titers: 600, epoch: 20 | loss: 0.0652029\n",
      "\tspeed: 0.0089s/iter; left time: 2.6467s\n",
      "\titers: 700, epoch: 20 | loss: 0.0685860\n",
      "\tspeed: 0.0088s/iter; left time: 1.7343s\n",
      "\titers: 800, epoch: 20 | loss: 0.0717030\n",
      "\tspeed: 0.0087s/iter; left time: 0.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 897 | Train Loss: 0.0675701 Vali Loss: 0.0759812 Test Loss: 0.0806642\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01871649920940399, rmse:0.13680826127529144, mae:0.08084283769130707, rse:0.5172867178916931\n",
      "Original data scale mse:2374954.25, rmse:1541.088623046875, mae:972.7523803710938, rse:0.108452707529068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1764216\n",
      "\tspeed: 0.0109s/iter; left time: 193.6869s\n",
      "\titers: 200, epoch: 1 | loss: 0.1487204\n",
      "\tspeed: 0.0083s/iter; left time: 147.9258s\n",
      "\titers: 300, epoch: 1 | loss: 0.1316128\n",
      "\tspeed: 0.0085s/iter; left time: 149.3688s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300153\n",
      "\tspeed: 0.0086s/iter; left time: 150.5979s\n",
      "\titers: 500, epoch: 1 | loss: 0.1162089\n",
      "\tspeed: 0.0088s/iter; left time: 153.7345s\n",
      "\titers: 600, epoch: 1 | loss: 0.1210243\n",
      "\tspeed: 0.0086s/iter; left time: 149.4851s\n",
      "\titers: 700, epoch: 1 | loss: 0.1078550\n",
      "\tspeed: 0.0086s/iter; left time: 149.1344s\n",
      "\titers: 800, epoch: 1 | loss: 0.1064629\n",
      "\tspeed: 0.0088s/iter; left time: 150.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 897 | Train Loss: 0.1310837 Vali Loss: 0.0974577 Test Loss: 0.1004544\n",
      "Validation loss decreased (inf --> 0.097458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962409\n",
      "\tspeed: 0.0437s/iter; left time: 741.1833s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924856\n",
      "\tspeed: 0.0086s/iter; left time: 144.9975s\n",
      "\titers: 300, epoch: 2 | loss: 0.0862916\n",
      "\tspeed: 0.0086s/iter; left time: 143.7997s\n",
      "\titers: 400, epoch: 2 | loss: 0.0957766\n",
      "\tspeed: 0.0086s/iter; left time: 143.2387s\n",
      "\titers: 500, epoch: 2 | loss: 0.0826875\n",
      "\tspeed: 0.0086s/iter; left time: 142.5334s\n",
      "\titers: 600, epoch: 2 | loss: 0.0768120\n",
      "\tspeed: 0.0086s/iter; left time: 141.1984s\n",
      "\titers: 700, epoch: 2 | loss: 0.0802395\n",
      "\tspeed: 0.0086s/iter; left time: 140.1031s\n",
      "\titers: 800, epoch: 2 | loss: 0.0809717\n",
      "\tspeed: 0.0086s/iter; left time: 139.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 897 | Train Loss: 0.0888422 Vali Loss: 0.0791979 Test Loss: 0.0838224\n",
      "Validation loss decreased (0.097458 --> 0.079198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795708\n",
      "\tspeed: 0.0393s/iter; left time: 631.0180s\n",
      "\titers: 200, epoch: 3 | loss: 0.0866132\n",
      "\tspeed: 0.0086s/iter; left time: 136.5722s\n",
      "\titers: 300, epoch: 3 | loss: 0.0798445\n",
      "\tspeed: 0.0086s/iter; left time: 137.0224s\n",
      "\titers: 400, epoch: 3 | loss: 0.0835910\n",
      "\tspeed: 0.0086s/iter; left time: 135.6434s\n",
      "\titers: 500, epoch: 3 | loss: 0.0859751\n",
      "\tspeed: 0.0086s/iter; left time: 135.0135s\n",
      "\titers: 600, epoch: 3 | loss: 0.0732036\n",
      "\tspeed: 0.0086s/iter; left time: 133.8404s\n",
      "\titers: 700, epoch: 3 | loss: 0.0794780\n",
      "\tspeed: 0.0086s/iter; left time: 133.0623s\n",
      "\titers: 800, epoch: 3 | loss: 0.0839007\n",
      "\tspeed: 0.0086s/iter; left time: 131.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 897 | Train Loss: 0.0816037 Vali Loss: 0.0785294 Test Loss: 0.0829009\n",
      "Validation loss decreased (0.079198 --> 0.078529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0768041\n",
      "\tspeed: 0.0407s/iter; left time: 616.2648s\n",
      "\titers: 200, epoch: 4 | loss: 0.0811102\n",
      "\tspeed: 0.0086s/iter; left time: 128.8714s\n",
      "\titers: 300, epoch: 4 | loss: 0.0769751\n",
      "\tspeed: 0.0086s/iter; left time: 127.9866s\n",
      "\titers: 400, epoch: 4 | loss: 0.0795978\n",
      "\tspeed: 0.0086s/iter; left time: 126.9822s\n",
      "\titers: 500, epoch: 4 | loss: 0.0745579\n",
      "\tspeed: 0.0086s/iter; left time: 126.7658s\n",
      "\titers: 600, epoch: 4 | loss: 0.0729626\n",
      "\tspeed: 0.0086s/iter; left time: 125.3713s\n",
      "\titers: 700, epoch: 4 | loss: 0.0806928\n",
      "\tspeed: 0.0085s/iter; left time: 124.1527s\n",
      "\titers: 800, epoch: 4 | loss: 0.0738188\n",
      "\tspeed: 0.0085s/iter; left time: 123.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 897 | Train Loss: 0.0793524 Vali Loss: 0.0780493 Test Loss: 0.0824024\n",
      "Validation loss decreased (0.078529 --> 0.078049).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0828017\n",
      "\tspeed: 0.0396s/iter; left time: 564.7795s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784330\n",
      "\tspeed: 0.0086s/iter; left time: 122.1928s\n",
      "\titers: 300, epoch: 5 | loss: 0.0827423\n",
      "\tspeed: 0.0087s/iter; left time: 121.7371s\n",
      "\titers: 400, epoch: 5 | loss: 0.0788836\n",
      "\tspeed: 0.0086s/iter; left time: 120.6678s\n",
      "\titers: 500, epoch: 5 | loss: 0.0868732\n",
      "\tspeed: 0.0086s/iter; left time: 119.6909s\n",
      "\titers: 600, epoch: 5 | loss: 0.0787728\n",
      "\tspeed: 0.0085s/iter; left time: 117.5050s\n",
      "\titers: 700, epoch: 5 | loss: 0.0776858\n",
      "\tspeed: 0.0084s/iter; left time: 114.5671s\n",
      "\titers: 800, epoch: 5 | loss: 0.0802494\n",
      "\tspeed: 0.0084s/iter; left time: 113.8665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 897 | Train Loss: 0.0775413 Vali Loss: 0.0772784 Test Loss: 0.0815480\n",
      "Validation loss decreased (0.078049 --> 0.077278).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0769298\n",
      "\tspeed: 0.0428s/iter; left time: 572.2755s\n",
      "\titers: 200, epoch: 6 | loss: 0.0782943\n",
      "\tspeed: 0.0087s/iter; left time: 114.9494s\n",
      "\titers: 300, epoch: 6 | loss: 0.0730536\n",
      "\tspeed: 0.0089s/iter; left time: 117.4473s\n",
      "\titers: 400, epoch: 6 | loss: 0.0744902\n",
      "\tspeed: 0.0094s/iter; left time: 122.6591s\n",
      "\titers: 500, epoch: 6 | loss: 0.0734538\n",
      "\tspeed: 0.0089s/iter; left time: 115.1884s\n",
      "\titers: 600, epoch: 6 | loss: 0.0819343\n",
      "\tspeed: 0.0088s/iter; left time: 113.6252s\n",
      "\titers: 700, epoch: 6 | loss: 0.0666599\n",
      "\tspeed: 0.0087s/iter; left time: 110.9734s\n",
      "\titers: 800, epoch: 6 | loss: 0.0720203\n",
      "\tspeed: 0.0086s/iter; left time: 108.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 897 | Train Loss: 0.0761613 Vali Loss: 0.0775140 Test Loss: 0.0809974\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0730525\n",
      "\tspeed: 0.0405s/iter; left time: 504.6091s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679854\n",
      "\tspeed: 0.0086s/iter; left time: 106.2758s\n",
      "\titers: 300, epoch: 7 | loss: 0.0720927\n",
      "\tspeed: 0.0086s/iter; left time: 105.2850s\n",
      "\titers: 400, epoch: 7 | loss: 0.0770753\n",
      "\tspeed: 0.0087s/iter; left time: 105.1861s\n",
      "\titers: 500, epoch: 7 | loss: 0.0744169\n",
      "\tspeed: 0.0086s/iter; left time: 104.2015s\n",
      "\titers: 600, epoch: 7 | loss: 0.0692931\n",
      "\tspeed: 0.0086s/iter; left time: 102.5345s\n",
      "\titers: 700, epoch: 7 | loss: 0.0691958\n",
      "\tspeed: 0.0085s/iter; left time: 101.2925s\n",
      "\titers: 800, epoch: 7 | loss: 0.0754674\n",
      "\tspeed: 0.0103s/iter; left time: 120.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 897 | Train Loss: 0.0748851 Vali Loss: 0.0767040 Test Loss: 0.0812463\n",
      "Validation loss decreased (0.077278 --> 0.076704).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696710\n",
      "\tspeed: 0.0437s/iter; left time: 505.1748s\n",
      "\titers: 200, epoch: 8 | loss: 0.0763672\n",
      "\tspeed: 0.0101s/iter; left time: 115.6795s\n",
      "\titers: 300, epoch: 8 | loss: 0.0615931\n",
      "\tspeed: 0.0098s/iter; left time: 111.2286s\n",
      "\titers: 400, epoch: 8 | loss: 0.0795314\n",
      "\tspeed: 0.0102s/iter; left time: 115.0334s\n",
      "\titers: 500, epoch: 8 | loss: 0.0752174\n",
      "\tspeed: 0.0135s/iter; left time: 151.0009s\n",
      "\titers: 600, epoch: 8 | loss: 0.0693099\n",
      "\tspeed: 0.0104s/iter; left time: 115.2217s\n",
      "\titers: 700, epoch: 8 | loss: 0.0736928\n",
      "\tspeed: 0.0107s/iter; left time: 117.8044s\n",
      "\titers: 800, epoch: 8 | loss: 0.0776321\n",
      "\tspeed: 0.0101s/iter; left time: 109.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 897 | Train Loss: 0.0738498 Vali Loss: 0.0769178 Test Loss: 0.0811158\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0747849\n",
      "\tspeed: 0.0406s/iter; left time: 433.3969s\n",
      "\titers: 200, epoch: 9 | loss: 0.0706521\n",
      "\tspeed: 0.0086s/iter; left time: 90.5200s\n",
      "\titers: 300, epoch: 9 | loss: 0.0681434\n",
      "\tspeed: 0.0086s/iter; left time: 89.6816s\n",
      "\titers: 400, epoch: 9 | loss: 0.0739066\n",
      "\tspeed: 0.0086s/iter; left time: 88.6923s\n",
      "\titers: 500, epoch: 9 | loss: 0.0668490\n",
      "\tspeed: 0.0084s/iter; left time: 86.5556s\n",
      "\titers: 600, epoch: 9 | loss: 0.0771326\n",
      "\tspeed: 0.0086s/iter; left time: 87.4968s\n",
      "\titers: 700, epoch: 9 | loss: 0.0793742\n",
      "\tspeed: 0.0086s/iter; left time: 86.8295s\n",
      "\titers: 800, epoch: 9 | loss: 0.0704737\n",
      "\tspeed: 0.0086s/iter; left time: 85.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 897 | Train Loss: 0.0728780 Vali Loss: 0.0770575 Test Loss: 0.0802230\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0663449\n",
      "\tspeed: 0.0395s/iter; left time: 385.6729s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704834\n",
      "\tspeed: 0.0086s/iter; left time: 83.5862s\n",
      "\titers: 300, epoch: 10 | loss: 0.0739264\n",
      "\tspeed: 0.0086s/iter; left time: 82.6638s\n",
      "\titers: 400, epoch: 10 | loss: 0.0738486\n",
      "\tspeed: 0.0086s/iter; left time: 81.6708s\n",
      "\titers: 500, epoch: 10 | loss: 0.0781138\n",
      "\tspeed: 0.0086s/iter; left time: 80.8343s\n",
      "\titers: 600, epoch: 10 | loss: 0.0861478\n",
      "\tspeed: 0.0086s/iter; left time: 80.0966s\n",
      "\titers: 700, epoch: 10 | loss: 0.0757280\n",
      "\tspeed: 0.0086s/iter; left time: 78.6466s\n",
      "\titers: 800, epoch: 10 | loss: 0.0663526\n",
      "\tspeed: 0.0085s/iter; left time: 77.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 897 | Train Loss: 0.0718697 Vali Loss: 0.0767785 Test Loss: 0.0803980\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0653223\n",
      "\tspeed: 0.0384s/iter; left time: 340.4937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676055\n",
      "\tspeed: 0.0086s/iter; left time: 75.4292s\n",
      "\titers: 300, epoch: 11 | loss: 0.0676592\n",
      "\tspeed: 0.0086s/iter; left time: 74.4311s\n",
      "\titers: 400, epoch: 11 | loss: 0.0797908\n",
      "\tspeed: 0.0086s/iter; left time: 73.5419s\n",
      "\titers: 500, epoch: 11 | loss: 0.0686739\n",
      "\tspeed: 0.0086s/iter; left time: 72.6361s\n",
      "\titers: 600, epoch: 11 | loss: 0.0686589\n",
      "\tspeed: 0.0086s/iter; left time: 71.8569s\n",
      "\titers: 700, epoch: 11 | loss: 0.0720364\n",
      "\tspeed: 0.0120s/iter; left time: 99.2309s\n",
      "\titers: 800, epoch: 11 | loss: 0.0808564\n",
      "\tspeed: 0.0086s/iter; left time: 70.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 897 | Train Loss: 0.0710960 Vali Loss: 0.0768533 Test Loss: 0.0804145\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0704030\n",
      "\tspeed: 0.0416s/iter; left time: 331.6508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0684930\n",
      "\tspeed: 0.0094s/iter; left time: 73.7131s\n",
      "\titers: 300, epoch: 12 | loss: 0.0671661\n",
      "\tspeed: 0.0087s/iter; left time: 67.7221s\n",
      "\titers: 400, epoch: 12 | loss: 0.0812063\n",
      "\tspeed: 0.0092s/iter; left time: 70.7615s\n",
      "\titers: 500, epoch: 12 | loss: 0.0716422\n",
      "\tspeed: 0.0091s/iter; left time: 69.2850s\n",
      "\titers: 600, epoch: 12 | loss: 0.0710999\n",
      "\tspeed: 0.0088s/iter; left time: 66.1401s\n",
      "\titers: 700, epoch: 12 | loss: 0.0734499\n",
      "\tspeed: 0.0087s/iter; left time: 64.3284s\n",
      "\titers: 800, epoch: 12 | loss: 0.0592436\n",
      "\tspeed: 0.0094s/iter; left time: 68.6675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 897 | Train Loss: 0.0704140 Vali Loss: 0.0765855 Test Loss: 0.0803188\n",
      "Validation loss decreased (0.076704 --> 0.076586).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0663913\n",
      "\tspeed: 0.0421s/iter; left time: 297.9054s\n",
      "\titers: 200, epoch: 13 | loss: 0.0746842\n",
      "\tspeed: 0.0094s/iter; left time: 65.7575s\n",
      "\titers: 300, epoch: 13 | loss: 0.0699914\n",
      "\tspeed: 0.0110s/iter; left time: 75.6489s\n",
      "\titers: 400, epoch: 13 | loss: 0.0771514\n",
      "\tspeed: 0.0113s/iter; left time: 76.7489s\n",
      "\titers: 500, epoch: 13 | loss: 0.0785270\n",
      "\tspeed: 0.0088s/iter; left time: 58.8734s\n",
      "\titers: 600, epoch: 13 | loss: 0.0636684\n",
      "\tspeed: 0.0090s/iter; left time: 59.3747s\n",
      "\titers: 700, epoch: 13 | loss: 0.0790440\n",
      "\tspeed: 0.0089s/iter; left time: 57.6293s\n",
      "\titers: 800, epoch: 13 | loss: 0.0638074\n",
      "\tspeed: 0.0092s/iter; left time: 58.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 897 | Train Loss: 0.0697692 Vali Loss: 0.0769554 Test Loss: 0.0810162\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0673871\n",
      "\tspeed: 0.0440s/iter; left time: 271.9582s\n",
      "\titers: 200, epoch: 14 | loss: 0.0670344\n",
      "\tspeed: 0.0085s/iter; left time: 51.9136s\n",
      "\titers: 300, epoch: 14 | loss: 0.0685085\n",
      "\tspeed: 0.0086s/iter; left time: 51.3412s\n",
      "\titers: 400, epoch: 14 | loss: 0.0641380\n",
      "\tspeed: 0.0085s/iter; left time: 50.1899s\n",
      "\titers: 500, epoch: 14 | loss: 0.0685883\n",
      "\tspeed: 0.0085s/iter; left time: 49.2860s\n",
      "\titers: 600, epoch: 14 | loss: 0.0726631\n",
      "\tspeed: 0.0086s/iter; left time: 48.9521s\n",
      "\titers: 700, epoch: 14 | loss: 0.0716188\n",
      "\tspeed: 0.0086s/iter; left time: 48.2327s\n",
      "\titers: 800, epoch: 14 | loss: 0.0754714\n",
      "\tspeed: 0.0086s/iter; left time: 47.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 897 | Train Loss: 0.0691436 Vali Loss: 0.0766860 Test Loss: 0.0807832\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0666481\n",
      "\tspeed: 0.0430s/iter; left time: 227.0413s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691985\n",
      "\tspeed: 0.0095s/iter; left time: 49.4911s\n",
      "\titers: 300, epoch: 15 | loss: 0.0721074\n",
      "\tspeed: 0.0097s/iter; left time: 49.3114s\n",
      "\titers: 400, epoch: 15 | loss: 0.0710379\n",
      "\tspeed: 0.0086s/iter; left time: 42.9606s\n",
      "\titers: 500, epoch: 15 | loss: 0.0731740\n",
      "\tspeed: 0.0087s/iter; left time: 42.3047s\n",
      "\titers: 600, epoch: 15 | loss: 0.0665691\n",
      "\tspeed: 0.0086s/iter; left time: 41.3477s\n",
      "\titers: 700, epoch: 15 | loss: 0.0650770\n",
      "\tspeed: 0.0086s/iter; left time: 40.2315s\n",
      "\titers: 800, epoch: 15 | loss: 0.0698803\n",
      "\tspeed: 0.0086s/iter; left time: 39.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 897 | Train Loss: 0.0687823 Vali Loss: 0.0767938 Test Loss: 0.0809827\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0716217\n",
      "\tspeed: 0.0405s/iter; left time: 177.4396s\n",
      "\titers: 200, epoch: 16 | loss: 0.0714265\n",
      "\tspeed: 0.0086s/iter; left time: 37.0025s\n",
      "\titers: 300, epoch: 16 | loss: 0.0637786\n",
      "\tspeed: 0.0085s/iter; left time: 35.7799s\n",
      "\titers: 400, epoch: 16 | loss: 0.0717098\n",
      "\tspeed: 0.0085s/iter; left time: 34.9117s\n",
      "\titers: 500, epoch: 16 | loss: 0.0691444\n",
      "\tspeed: 0.0085s/iter; left time: 34.0384s\n",
      "\titers: 600, epoch: 16 | loss: 0.0692955\n",
      "\tspeed: 0.0085s/iter; left time: 33.0026s\n",
      "\titers: 700, epoch: 16 | loss: 0.0649698\n",
      "\tspeed: 0.0085s/iter; left time: 32.1448s\n",
      "\titers: 800, epoch: 16 | loss: 0.0679418\n",
      "\tspeed: 0.0085s/iter; left time: 31.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 897 | Train Loss: 0.0683519 Vali Loss: 0.0763213 Test Loss: 0.0808516\n",
      "Validation loss decreased (0.076586 --> 0.076321).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616460\n",
      "\tspeed: 0.0393s/iter; left time: 137.1488s\n",
      "\titers: 200, epoch: 17 | loss: 0.0662839\n",
      "\tspeed: 0.0086s/iter; left time: 29.0614s\n",
      "\titers: 300, epoch: 17 | loss: 0.0638993\n",
      "\tspeed: 0.0099s/iter; left time: 32.6334s\n",
      "\titers: 400, epoch: 17 | loss: 0.0719500\n",
      "\tspeed: 0.0110s/iter; left time: 35.1636s\n",
      "\titers: 500, epoch: 17 | loss: 0.0607939\n",
      "\tspeed: 0.0093s/iter; left time: 28.7798s\n",
      "\titers: 600, epoch: 17 | loss: 0.0735797\n",
      "\tspeed: 0.0087s/iter; left time: 25.9640s\n",
      "\titers: 700, epoch: 17 | loss: 0.0713516\n",
      "\tspeed: 0.0101s/iter; left time: 29.1163s\n",
      "\titers: 800, epoch: 17 | loss: 0.0736077\n",
      "\tspeed: 0.0095s/iter; left time: 26.4230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 897 | Train Loss: 0.0679667 Vali Loss: 0.0764359 Test Loss: 0.0809963\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729668\n",
      "\tspeed: 0.0400s/iter; left time: 103.7100s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691720\n",
      "\tspeed: 0.0085s/iter; left time: 21.1808s\n",
      "\titers: 300, epoch: 18 | loss: 0.0707033\n",
      "\tspeed: 0.0085s/iter; left time: 20.3629s\n",
      "\titers: 400, epoch: 18 | loss: 0.0603812\n",
      "\tspeed: 0.0086s/iter; left time: 19.6394s\n",
      "\titers: 500, epoch: 18 | loss: 0.0691694\n",
      "\tspeed: 0.0086s/iter; left time: 18.8184s\n",
      "\titers: 600, epoch: 18 | loss: 0.0634946\n",
      "\tspeed: 0.0086s/iter; left time: 18.0836s\n",
      "\titers: 700, epoch: 18 | loss: 0.0642861\n",
      "\tspeed: 0.0091s/iter; left time: 18.1793s\n",
      "\titers: 800, epoch: 18 | loss: 0.0624955\n",
      "\tspeed: 0.0105s/iter; left time: 19.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 897 | Train Loss: 0.0676646 Vali Loss: 0.0766452 Test Loss: 0.0805800\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0671453\n",
      "\tspeed: 0.0450s/iter; left time: 76.3330s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759159\n",
      "\tspeed: 0.0085s/iter; left time: 13.5904s\n",
      "\titers: 300, epoch: 19 | loss: 0.0658691\n",
      "\tspeed: 0.0085s/iter; left time: 12.7616s\n",
      "\titers: 400, epoch: 19 | loss: 0.0673757\n",
      "\tspeed: 0.0085s/iter; left time: 11.8619s\n",
      "\titers: 500, epoch: 19 | loss: 0.0623002\n",
      "\tspeed: 0.0085s/iter; left time: 11.0164s\n",
      "\titers: 600, epoch: 19 | loss: 0.0681596\n",
      "\tspeed: 0.0085s/iter; left time: 10.1604s\n",
      "\titers: 700, epoch: 19 | loss: 0.0676891\n",
      "\tspeed: 0.0085s/iter; left time: 9.3061s\n",
      "\titers: 800, epoch: 19 | loss: 0.0644339\n",
      "\tspeed: 0.0086s/iter; left time: 8.5284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 897 | Train Loss: 0.0673641 Vali Loss: 0.0757408 Test Loss: 0.0810490\n",
      "Validation loss decreased (0.076321 --> 0.075741).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0634677\n",
      "\tspeed: 0.0400s/iter; left time: 31.8883s\n",
      "\titers: 200, epoch: 20 | loss: 0.0610706\n",
      "\tspeed: 0.0086s/iter; left time: 6.0335s\n",
      "\titers: 300, epoch: 20 | loss: 0.0690134\n",
      "\tspeed: 0.0087s/iter; left time: 5.1966s\n",
      "\titers: 400, epoch: 20 | loss: 0.0658732\n",
      "\tspeed: 0.0086s/iter; left time: 4.3071s\n",
      "\titers: 500, epoch: 20 | loss: 0.0684351\n",
      "\tspeed: 0.0086s/iter; left time: 3.4128s\n",
      "\titers: 600, epoch: 20 | loss: 0.0673174\n",
      "\tspeed: 0.0086s/iter; left time: 2.5686s\n",
      "\titers: 700, epoch: 20 | loss: 0.0653443\n",
      "\tspeed: 0.0086s/iter; left time: 1.6952s\n",
      "\titers: 800, epoch: 20 | loss: 0.0696531\n",
      "\tspeed: 0.0086s/iter; left time: 0.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 897 | Train Loss: 0.0670726 Vali Loss: 0.0760162 Test Loss: 0.0809968\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018979672342538834, rmse:0.1377667337656021, mae:0.08104903250932693, rse:0.5209108591079712\n",
      "Original data scale mse:2350334.25, rmse:1533.0799560546875, mae:967.2764282226562, rse:0.1078891009092331\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1676631\n",
      "\tspeed: 0.0313s/iter; left time: 555.6772s\n",
      "\titers: 200, epoch: 1 | loss: 0.1426097\n",
      "\tspeed: 0.0095s/iter; left time: 168.4008s\n",
      "\titers: 300, epoch: 1 | loss: 0.1332137\n",
      "\tspeed: 0.0094s/iter; left time: 165.4124s\n",
      "\titers: 400, epoch: 1 | loss: 0.1236079\n",
      "\tspeed: 0.0094s/iter; left time: 163.8150s\n",
      "\titers: 500, epoch: 1 | loss: 0.1263428\n",
      "\tspeed: 0.0095s/iter; left time: 164.4593s\n",
      "\titers: 600, epoch: 1 | loss: 0.1137364\n",
      "\tspeed: 0.0095s/iter; left time: 163.6606s\n",
      "\titers: 700, epoch: 1 | loss: 0.1145076\n",
      "\tspeed: 0.0108s/iter; left time: 184.7690s\n",
      "\titers: 800, epoch: 1 | loss: 0.1114139\n",
      "\tspeed: 0.0097s/iter; left time: 165.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 894 | Train Loss: 0.1339725 Vali Loss: 0.1008623 Test Loss: 0.1035258\n",
      "Validation loss decreased (inf --> 0.100862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982762\n",
      "\tspeed: 0.0451s/iter; left time: 762.1636s\n",
      "\titers: 200, epoch: 2 | loss: 0.0982117\n",
      "\tspeed: 0.0096s/iter; left time: 160.9527s\n",
      "\titers: 300, epoch: 2 | loss: 0.0964627\n",
      "\tspeed: 0.0089s/iter; left time: 148.0447s\n",
      "\titers: 400, epoch: 2 | loss: 0.1007937\n",
      "\tspeed: 0.0088s/iter; left time: 145.6398s\n",
      "\titers: 500, epoch: 2 | loss: 0.0936966\n",
      "\tspeed: 0.0088s/iter; left time: 144.7295s\n",
      "\titers: 600, epoch: 2 | loss: 0.0998424\n",
      "\tspeed: 0.0087s/iter; left time: 143.2005s\n",
      "\titers: 700, epoch: 2 | loss: 0.0937382\n",
      "\tspeed: 0.0087s/iter; left time: 142.1151s\n",
      "\titers: 800, epoch: 2 | loss: 0.0903431\n",
      "\tspeed: 0.0088s/iter; left time: 141.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 894 | Train Loss: 0.0928284 Vali Loss: 0.0836631 Test Loss: 0.0887228\n",
      "Validation loss decreased (0.100862 --> 0.083663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925581\n",
      "\tspeed: 0.0424s/iter; left time: 678.0362s\n",
      "\titers: 200, epoch: 3 | loss: 0.0904151\n",
      "\tspeed: 0.0094s/iter; left time: 149.7629s\n",
      "\titers: 300, epoch: 3 | loss: 0.0869564\n",
      "\tspeed: 0.0091s/iter; left time: 144.2474s\n",
      "\titers: 400, epoch: 3 | loss: 0.0921788\n",
      "\tspeed: 0.0097s/iter; left time: 152.4749s\n",
      "\titers: 500, epoch: 3 | loss: 0.0759394\n",
      "\tspeed: 0.0112s/iter; left time: 174.3693s\n",
      "\titers: 600, epoch: 3 | loss: 0.0892078\n",
      "\tspeed: 0.0087s/iter; left time: 134.6486s\n",
      "\titers: 700, epoch: 3 | loss: 0.0894642\n",
      "\tspeed: 0.0086s/iter; left time: 132.1573s\n",
      "\titers: 800, epoch: 3 | loss: 0.0865110\n",
      "\tspeed: 0.0086s/iter; left time: 132.0672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 894 | Train Loss: 0.0855744 Vali Loss: 0.0825992 Test Loss: 0.0881007\n",
      "Validation loss decreased (0.083663 --> 0.082599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0898065\n",
      "\tspeed: 0.0395s/iter; left time: 596.4653s\n",
      "\titers: 200, epoch: 4 | loss: 0.0821942\n",
      "\tspeed: 0.0085s/iter; left time: 128.1823s\n",
      "\titers: 300, epoch: 4 | loss: 0.0802417\n",
      "\tspeed: 0.0086s/iter; left time: 127.9736s\n",
      "\titers: 400, epoch: 4 | loss: 0.0808136\n",
      "\tspeed: 0.0086s/iter; left time: 127.5612s\n",
      "\titers: 500, epoch: 4 | loss: 0.0811172\n",
      "\tspeed: 0.0086s/iter; left time: 126.5603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0781578\n",
      "\tspeed: 0.0086s/iter; left time: 126.0943s\n",
      "\titers: 700, epoch: 4 | loss: 0.0823004\n",
      "\tspeed: 0.0086s/iter; left time: 125.2546s\n",
      "\titers: 800, epoch: 4 | loss: 0.0757930\n",
      "\tspeed: 0.0086s/iter; left time: 124.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 894 | Train Loss: 0.0832663 Vali Loss: 0.0830262 Test Loss: 0.0879437\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0763075\n",
      "\tspeed: 0.0383s/iter; left time: 543.4063s\n",
      "\titers: 200, epoch: 5 | loss: 0.0829726\n",
      "\tspeed: 0.0087s/iter; left time: 122.7348s\n",
      "\titers: 300, epoch: 5 | loss: 0.0848208\n",
      "\tspeed: 0.0087s/iter; left time: 121.6044s\n",
      "\titers: 400, epoch: 5 | loss: 0.0856856\n",
      "\tspeed: 0.0087s/iter; left time: 120.7089s\n",
      "\titers: 500, epoch: 5 | loss: 0.0807456\n",
      "\tspeed: 0.0087s/iter; left time: 119.7975s\n",
      "\titers: 600, epoch: 5 | loss: 0.0865609\n",
      "\tspeed: 0.0087s/iter; left time: 119.0172s\n",
      "\titers: 700, epoch: 5 | loss: 0.0772804\n",
      "\tspeed: 0.0087s/iter; left time: 118.0897s\n",
      "\titers: 800, epoch: 5 | loss: 0.0858641\n",
      "\tspeed: 0.0087s/iter; left time: 117.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 894 | Train Loss: 0.0815560 Vali Loss: 0.0821677 Test Loss: 0.0880615\n",
      "Validation loss decreased (0.082599 --> 0.082168).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0868327\n",
      "\tspeed: 0.0391s/iter; left time: 521.1232s\n",
      "\titers: 200, epoch: 6 | loss: 0.0766530\n",
      "\tspeed: 0.0086s/iter; left time: 113.6616s\n",
      "\titers: 300, epoch: 6 | loss: 0.0826215\n",
      "\tspeed: 0.0086s/iter; left time: 112.8916s\n",
      "\titers: 400, epoch: 6 | loss: 0.0824801\n",
      "\tspeed: 0.0086s/iter; left time: 112.3559s\n",
      "\titers: 500, epoch: 6 | loss: 0.0768832\n",
      "\tspeed: 0.0086s/iter; left time: 111.6109s\n",
      "\titers: 600, epoch: 6 | loss: 0.0811780\n",
      "\tspeed: 0.0087s/iter; left time: 111.0682s\n",
      "\titers: 700, epoch: 6 | loss: 0.0854350\n",
      "\tspeed: 0.0097s/iter; left time: 123.3770s\n",
      "\titers: 800, epoch: 6 | loss: 0.0775294\n",
      "\tspeed: 0.0086s/iter; left time: 108.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 894 | Train Loss: 0.0799344 Vali Loss: 0.0819523 Test Loss: 0.0872872\n",
      "Validation loss decreased (0.082168 --> 0.081952).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801979\n",
      "\tspeed: 0.0426s/iter; left time: 528.6491s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729250\n",
      "\tspeed: 0.0086s/iter; left time: 106.1962s\n",
      "\titers: 300, epoch: 7 | loss: 0.0777908\n",
      "\tspeed: 0.0086s/iter; left time: 105.4108s\n",
      "\titers: 400, epoch: 7 | loss: 0.0833218\n",
      "\tspeed: 0.0087s/iter; left time: 105.4459s\n",
      "\titers: 500, epoch: 7 | loss: 0.0819925\n",
      "\tspeed: 0.0087s/iter; left time: 104.6211s\n",
      "\titers: 600, epoch: 7 | loss: 0.0787476\n",
      "\tspeed: 0.0087s/iter; left time: 103.7703s\n",
      "\titers: 700, epoch: 7 | loss: 0.0750095\n",
      "\tspeed: 0.0087s/iter; left time: 102.8657s\n",
      "\titers: 800, epoch: 7 | loss: 0.0765415\n",
      "\tspeed: 0.0087s/iter; left time: 102.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 894 | Train Loss: 0.0786356 Vali Loss: 0.0820361 Test Loss: 0.0873266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0721518\n",
      "\tspeed: 0.0384s/iter; left time: 442.5912s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730626\n",
      "\tspeed: 0.0085s/iter; left time: 97.3032s\n",
      "\titers: 300, epoch: 8 | loss: 0.0763769\n",
      "\tspeed: 0.0084s/iter; left time: 95.3592s\n",
      "\titers: 400, epoch: 8 | loss: 0.0730331\n",
      "\tspeed: 0.0084s/iter; left time: 94.4954s\n",
      "\titers: 500, epoch: 8 | loss: 0.0753745\n",
      "\tspeed: 0.0084s/iter; left time: 93.6753s\n",
      "\titers: 600, epoch: 8 | loss: 0.0688097\n",
      "\tspeed: 0.0084s/iter; left time: 92.8642s\n",
      "\titers: 700, epoch: 8 | loss: 0.0881403\n",
      "\tspeed: 0.0084s/iter; left time: 92.0582s\n",
      "\titers: 800, epoch: 8 | loss: 0.0767288\n",
      "\tspeed: 0.0084s/iter; left time: 91.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 894 | Train Loss: 0.0774420 Vali Loss: 0.0823787 Test Loss: 0.0874536\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0776979\n",
      "\tspeed: 0.0406s/iter; left time: 431.9726s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788525\n",
      "\tspeed: 0.0092s/iter; left time: 96.6976s\n",
      "\titers: 300, epoch: 9 | loss: 0.0779241\n",
      "\tspeed: 0.0092s/iter; left time: 95.7452s\n",
      "\titers: 400, epoch: 9 | loss: 0.0774643\n",
      "\tspeed: 0.0089s/iter; left time: 92.3183s\n",
      "\titers: 500, epoch: 9 | loss: 0.0747745\n",
      "\tspeed: 0.0088s/iter; left time: 89.7518s\n",
      "\titers: 600, epoch: 9 | loss: 0.0706947\n",
      "\tspeed: 0.0088s/iter; left time: 88.9815s\n",
      "\titers: 700, epoch: 9 | loss: 0.0729236\n",
      "\tspeed: 0.0088s/iter; left time: 88.5578s\n",
      "\titers: 800, epoch: 9 | loss: 0.0786334\n",
      "\tspeed: 0.0089s/iter; left time: 87.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 894 | Train Loss: 0.0764264 Vali Loss: 0.0816443 Test Loss: 0.0871328\n",
      "Validation loss decreased (0.081952 --> 0.081644).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0718096\n",
      "\tspeed: 0.0395s/iter; left time: 384.8013s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721445\n",
      "\tspeed: 0.0084s/iter; left time: 80.8253s\n",
      "\titers: 300, epoch: 10 | loss: 0.0754400\n",
      "\tspeed: 0.0084s/iter; left time: 79.8511s\n",
      "\titers: 400, epoch: 10 | loss: 0.0761036\n",
      "\tspeed: 0.0087s/iter; left time: 81.8436s\n",
      "\titers: 500, epoch: 10 | loss: 0.0790467\n",
      "\tspeed: 0.0088s/iter; left time: 81.6918s\n",
      "\titers: 600, epoch: 10 | loss: 0.0805561\n",
      "\tspeed: 0.0085s/iter; left time: 78.8034s\n",
      "\titers: 700, epoch: 10 | loss: 0.0742743\n",
      "\tspeed: 0.0086s/iter; left time: 78.2663s\n",
      "\titers: 800, epoch: 10 | loss: 0.0775000\n",
      "\tspeed: 0.0085s/iter; left time: 77.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 894 | Train Loss: 0.0754924 Vali Loss: 0.0817005 Test Loss: 0.0872950\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764734\n",
      "\tspeed: 0.0401s/iter; left time: 354.5838s\n",
      "\titers: 200, epoch: 11 | loss: 0.0814360\n",
      "\tspeed: 0.0096s/iter; left time: 83.5295s\n",
      "\titers: 300, epoch: 11 | loss: 0.0730188\n",
      "\tspeed: 0.0094s/iter; left time: 81.4207s\n",
      "\titers: 400, epoch: 11 | loss: 0.0731893\n",
      "\tspeed: 0.0095s/iter; left time: 81.4889s\n",
      "\titers: 500, epoch: 11 | loss: 0.0727932\n",
      "\tspeed: 0.0105s/iter; left time: 88.9098s\n",
      "\titers: 600, epoch: 11 | loss: 0.0774737\n",
      "\tspeed: 0.0106s/iter; left time: 88.2973s\n",
      "\titers: 700, epoch: 11 | loss: 0.0802900\n",
      "\tspeed: 0.0109s/iter; left time: 89.6873s\n",
      "\titers: 800, epoch: 11 | loss: 0.0745332\n",
      "\tspeed: 0.0096s/iter; left time: 77.8268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.10s\n",
      "Steps: 894 | Train Loss: 0.0746826 Vali Loss: 0.0817863 Test Loss: 0.0873130\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0772094\n",
      "\tspeed: 0.0433s/iter; left time: 343.8789s\n",
      "\titers: 200, epoch: 12 | loss: 0.0750696\n",
      "\tspeed: 0.0107s/iter; left time: 84.1450s\n",
      "\titers: 300, epoch: 12 | loss: 0.0763485\n",
      "\tspeed: 0.0107s/iter; left time: 82.7162s\n",
      "\titers: 400, epoch: 12 | loss: 0.0799676\n",
      "\tspeed: 0.0106s/iter; left time: 81.0617s\n",
      "\titers: 500, epoch: 12 | loss: 0.0768250\n",
      "\tspeed: 0.0085s/iter; left time: 64.4265s\n",
      "\titers: 600, epoch: 12 | loss: 0.0715757\n",
      "\tspeed: 0.0085s/iter; left time: 63.4764s\n",
      "\titers: 700, epoch: 12 | loss: 0.0714161\n",
      "\tspeed: 0.0086s/iter; left time: 63.1434s\n",
      "\titers: 800, epoch: 12 | loss: 0.0807038\n",
      "\tspeed: 0.0086s/iter; left time: 62.5636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 894 | Train Loss: 0.0740122 Vali Loss: 0.0816479 Test Loss: 0.0869386\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0786668\n",
      "\tspeed: 0.0396s/iter; left time: 279.4159s\n",
      "\titers: 200, epoch: 13 | loss: 0.0710765\n",
      "\tspeed: 0.0086s/iter; left time: 59.7310s\n",
      "\titers: 300, epoch: 13 | loss: 0.0727081\n",
      "\tspeed: 0.0085s/iter; left time: 58.4726s\n",
      "\titers: 400, epoch: 13 | loss: 0.0799780\n",
      "\tspeed: 0.0085s/iter; left time: 57.2262s\n",
      "\titers: 500, epoch: 13 | loss: 0.0762860\n",
      "\tspeed: 0.0085s/iter; left time: 56.3686s\n",
      "\titers: 600, epoch: 13 | loss: 0.0777735\n",
      "\tspeed: 0.0085s/iter; left time: 55.4880s\n",
      "\titers: 700, epoch: 13 | loss: 0.0718263\n",
      "\tspeed: 0.0085s/iter; left time: 54.6734s\n",
      "\titers: 800, epoch: 13 | loss: 0.0661025\n",
      "\tspeed: 0.0085s/iter; left time: 54.0388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 894 | Train Loss: 0.0733053 Vali Loss: 0.0815843 Test Loss: 0.0868065\n",
      "Validation loss decreased (0.081644 --> 0.081584).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764800\n",
      "\tspeed: 0.0389s/iter; left time: 239.3180s\n",
      "\titers: 200, epoch: 14 | loss: 0.0753890\n",
      "\tspeed: 0.0085s/iter; left time: 51.5924s\n",
      "\titers: 300, epoch: 14 | loss: 0.0797547\n",
      "\tspeed: 0.0085s/iter; left time: 50.7213s\n",
      "\titers: 400, epoch: 14 | loss: 0.0775461\n",
      "\tspeed: 0.0085s/iter; left time: 49.8680s\n",
      "\titers: 500, epoch: 14 | loss: 0.0755035\n",
      "\tspeed: 0.0085s/iter; left time: 49.0136s\n",
      "\titers: 600, epoch: 14 | loss: 0.0697026\n",
      "\tspeed: 0.0085s/iter; left time: 48.1510s\n",
      "\titers: 700, epoch: 14 | loss: 0.0762542\n",
      "\tspeed: 0.0085s/iter; left time: 47.2796s\n",
      "\titers: 800, epoch: 14 | loss: 0.0669765\n",
      "\tspeed: 0.0085s/iter; left time: 46.5510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 894 | Train Loss: 0.0728547 Vali Loss: 0.0816916 Test Loss: 0.0874153\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0698596\n",
      "\tspeed: 0.0383s/iter; left time: 201.4324s\n",
      "\titers: 200, epoch: 15 | loss: 0.0679832\n",
      "\tspeed: 0.0085s/iter; left time: 44.0594s\n",
      "\titers: 300, epoch: 15 | loss: 0.0669634\n",
      "\tspeed: 0.0084s/iter; left time: 42.7077s\n",
      "\titers: 400, epoch: 15 | loss: 0.0765448\n",
      "\tspeed: 0.0084s/iter; left time: 41.8339s\n",
      "\titers: 500, epoch: 15 | loss: 0.0608581\n",
      "\tspeed: 0.0084s/iter; left time: 41.0555s\n",
      "\titers: 600, epoch: 15 | loss: 0.0735885\n",
      "\tspeed: 0.0084s/iter; left time: 40.2213s\n",
      "\titers: 700, epoch: 15 | loss: 0.0737299\n",
      "\tspeed: 0.0084s/iter; left time: 39.3176s\n",
      "\titers: 800, epoch: 15 | loss: 0.0745507\n",
      "\tspeed: 0.0084s/iter; left time: 38.4675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 894 | Train Loss: 0.0723528 Vali Loss: 0.0813551 Test Loss: 0.0870353\n",
      "Validation loss decreased (0.081584 --> 0.081355).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692273\n",
      "\tspeed: 0.0434s/iter; left time: 189.5008s\n",
      "\titers: 200, epoch: 16 | loss: 0.0773633\n",
      "\tspeed: 0.0107s/iter; left time: 45.6697s\n",
      "\titers: 300, epoch: 16 | loss: 0.0752365\n",
      "\tspeed: 0.0106s/iter; left time: 44.1018s\n",
      "\titers: 400, epoch: 16 | loss: 0.0726915\n",
      "\tspeed: 0.0097s/iter; left time: 39.3895s\n",
      "\titers: 500, epoch: 16 | loss: 0.0753377\n",
      "\tspeed: 0.0086s/iter; left time: 34.0029s\n",
      "\titers: 600, epoch: 16 | loss: 0.0680992\n",
      "\tspeed: 0.0086s/iter; left time: 33.1694s\n",
      "\titers: 700, epoch: 16 | loss: 0.0749957\n",
      "\tspeed: 0.0086s/iter; left time: 32.2951s\n",
      "\titers: 800, epoch: 16 | loss: 0.0682190\n",
      "\tspeed: 0.0086s/iter; left time: 31.4479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 894 | Train Loss: 0.0719654 Vali Loss: 0.0812389 Test Loss: 0.0872389\n",
      "Validation loss decreased (0.081355 --> 0.081239).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0736102\n",
      "\tspeed: 0.0413s/iter; left time: 143.4493s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727421\n",
      "\tspeed: 0.0106s/iter; left time: 35.7644s\n",
      "\titers: 300, epoch: 17 | loss: 0.0798749\n",
      "\tspeed: 0.0105s/iter; left time: 34.5375s\n",
      "\titers: 400, epoch: 17 | loss: 0.0678909\n",
      "\tspeed: 0.0106s/iter; left time: 33.7241s\n",
      "\titers: 500, epoch: 17 | loss: 0.0697635\n",
      "\tspeed: 0.0106s/iter; left time: 32.7186s\n",
      "\titers: 600, epoch: 17 | loss: 0.0730367\n",
      "\tspeed: 0.0106s/iter; left time: 31.6043s\n",
      "\titers: 700, epoch: 17 | loss: 0.0739769\n",
      "\tspeed: 0.0107s/iter; left time: 30.7749s\n",
      "\titers: 800, epoch: 17 | loss: 0.0720364\n",
      "\tspeed: 0.0108s/iter; left time: 29.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 894 | Train Loss: 0.0714891 Vali Loss: 0.0816015 Test Loss: 0.0875076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0738157\n",
      "\tspeed: 0.0432s/iter; left time: 111.6655s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666296\n",
      "\tspeed: 0.0094s/iter; left time: 23.3501s\n",
      "\titers: 300, epoch: 18 | loss: 0.0681162\n",
      "\tspeed: 0.0093s/iter; left time: 22.2641s\n",
      "\titers: 400, epoch: 18 | loss: 0.0746048\n",
      "\tspeed: 0.0093s/iter; left time: 21.2845s\n",
      "\titers: 500, epoch: 18 | loss: 0.0731742\n",
      "\tspeed: 0.0093s/iter; left time: 20.3379s\n",
      "\titers: 600, epoch: 18 | loss: 0.0686330\n",
      "\tspeed: 0.0093s/iter; left time: 19.3778s\n",
      "\titers: 700, epoch: 18 | loss: 0.0772570\n",
      "\tspeed: 0.0093s/iter; left time: 18.4536s\n",
      "\titers: 800, epoch: 18 | loss: 0.0734346\n",
      "\tspeed: 0.0093s/iter; left time: 17.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 894 | Train Loss: 0.0713043 Vali Loss: 0.0812010 Test Loss: 0.0872498\n",
      "Validation loss decreased (0.081239 --> 0.081201).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0780274\n",
      "\tspeed: 0.0399s/iter; left time: 67.3932s\n",
      "\titers: 200, epoch: 19 | loss: 0.0720917\n",
      "\tspeed: 0.0087s/iter; left time: 13.8060s\n",
      "\titers: 300, epoch: 19 | loss: 0.0756924\n",
      "\tspeed: 0.0087s/iter; left time: 12.8893s\n",
      "\titers: 400, epoch: 19 | loss: 0.0794804\n",
      "\tspeed: 0.0086s/iter; left time: 12.0127s\n",
      "\titers: 500, epoch: 19 | loss: 0.0738623\n",
      "\tspeed: 0.0086s/iter; left time: 11.1391s\n",
      "\titers: 600, epoch: 19 | loss: 0.0832400\n",
      "\tspeed: 0.0085s/iter; left time: 10.0487s\n",
      "\titers: 700, epoch: 19 | loss: 0.0738254\n",
      "\tspeed: 0.0085s/iter; left time: 9.2129s\n",
      "\titers: 800, epoch: 19 | loss: 0.0652518\n",
      "\tspeed: 0.0084s/iter; left time: 8.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 894 | Train Loss: 0.0709535 Vali Loss: 0.0810140 Test Loss: 0.0873328\n",
      "Validation loss decreased (0.081201 --> 0.081014).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0775646\n",
      "\tspeed: 0.0387s/iter; left time: 30.7890s\n",
      "\titers: 200, epoch: 20 | loss: 0.0727784\n",
      "\tspeed: 0.0085s/iter; left time: 5.8984s\n",
      "\titers: 300, epoch: 20 | loss: 0.0710121\n",
      "\tspeed: 0.0085s/iter; left time: 5.0459s\n",
      "\titers: 400, epoch: 20 | loss: 0.0746401\n",
      "\tspeed: 0.0085s/iter; left time: 4.1998s\n",
      "\titers: 500, epoch: 20 | loss: 0.0682924\n",
      "\tspeed: 0.0085s/iter; left time: 3.3717s\n",
      "\titers: 600, epoch: 20 | loss: 0.0671866\n",
      "\tspeed: 0.0087s/iter; left time: 2.5678s\n",
      "\titers: 700, epoch: 20 | loss: 0.0769067\n",
      "\tspeed: 0.0086s/iter; left time: 1.6769s\n",
      "\titers: 800, epoch: 20 | loss: 0.0756626\n",
      "\tspeed: 0.0085s/iter; left time: 0.8050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 894 | Train Loss: 0.0706790 Vali Loss: 0.0810555 Test Loss: 0.0877031\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02112378552556038, rmse:0.145340234041214, mae:0.0873328149318695, rse:0.5499268174171448\n",
      "Original data scale mse:2851058.5, rmse:1688.5078125, mae:1070.8997802734375, rse:0.11893877387046814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1761340\n",
      "\tspeed: 0.0110s/iter; left time: 195.1450s\n",
      "\titers: 200, epoch: 1 | loss: 0.1442881\n",
      "\tspeed: 0.0088s/iter; left time: 155.1859s\n",
      "\titers: 300, epoch: 1 | loss: 0.1350050\n",
      "\tspeed: 0.0088s/iter; left time: 154.0862s\n",
      "\titers: 400, epoch: 1 | loss: 0.1279581\n",
      "\tspeed: 0.0088s/iter; left time: 153.2417s\n",
      "\titers: 500, epoch: 1 | loss: 0.1265344\n",
      "\tspeed: 0.0088s/iter; left time: 152.1527s\n",
      "\titers: 600, epoch: 1 | loss: 0.1189172\n",
      "\tspeed: 0.0088s/iter; left time: 151.2547s\n",
      "\titers: 700, epoch: 1 | loss: 0.1214259\n",
      "\tspeed: 0.0087s/iter; left time: 150.3119s\n",
      "\titers: 800, epoch: 1 | loss: 0.1136109\n",
      "\tspeed: 0.0088s/iter; left time: 149.5119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 894 | Train Loss: 0.1343771 Vali Loss: 0.1009048 Test Loss: 0.1035921\n",
      "Validation loss decreased (inf --> 0.100905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1085248\n",
      "\tspeed: 0.0386s/iter; left time: 651.5003s\n",
      "\titers: 200, epoch: 2 | loss: 0.0885387\n",
      "\tspeed: 0.0085s/iter; left time: 142.0698s\n",
      "\titers: 300, epoch: 2 | loss: 0.0964822\n",
      "\tspeed: 0.0084s/iter; left time: 140.8283s\n",
      "\titers: 400, epoch: 2 | loss: 0.0883560\n",
      "\tspeed: 0.0084s/iter; left time: 139.8419s\n",
      "\titers: 500, epoch: 2 | loss: 0.0825061\n",
      "\tspeed: 0.0084s/iter; left time: 139.0946s\n",
      "\titers: 600, epoch: 2 | loss: 0.0917150\n",
      "\tspeed: 0.0084s/iter; left time: 138.0226s\n",
      "\titers: 700, epoch: 2 | loss: 0.0800588\n",
      "\tspeed: 0.0084s/iter; left time: 137.2597s\n",
      "\titers: 800, epoch: 2 | loss: 0.0874557\n",
      "\tspeed: 0.0084s/iter; left time: 136.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 894 | Train Loss: 0.0928199 Vali Loss: 0.0841567 Test Loss: 0.0889222\n",
      "Validation loss decreased (0.100905 --> 0.084157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0892415\n",
      "\tspeed: 0.0387s/iter; left time: 619.4884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877660\n",
      "\tspeed: 0.0087s/iter; left time: 138.4053s\n",
      "\titers: 300, epoch: 3 | loss: 0.0936635\n",
      "\tspeed: 0.0087s/iter; left time: 136.8345s\n",
      "\titers: 400, epoch: 3 | loss: 0.0829858\n",
      "\tspeed: 0.0085s/iter; left time: 132.7153s\n",
      "\titers: 500, epoch: 3 | loss: 0.0800809\n",
      "\tspeed: 0.0085s/iter; left time: 132.3058s\n",
      "\titers: 600, epoch: 3 | loss: 0.0909075\n",
      "\tspeed: 0.0085s/iter; left time: 131.1698s\n",
      "\titers: 700, epoch: 3 | loss: 0.0901069\n",
      "\tspeed: 0.0085s/iter; left time: 130.1334s\n",
      "\titers: 800, epoch: 3 | loss: 0.0852634\n",
      "\tspeed: 0.0085s/iter; left time: 129.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 894 | Train Loss: 0.0857337 Vali Loss: 0.0828018 Test Loss: 0.0882786\n",
      "Validation loss decreased (0.084157 --> 0.082802).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836834\n",
      "\tspeed: 0.0391s/iter; left time: 590.1731s\n",
      "\titers: 200, epoch: 4 | loss: 0.0813850\n",
      "\tspeed: 0.0084s/iter; left time: 126.4213s\n",
      "\titers: 300, epoch: 4 | loss: 0.0831876\n",
      "\tspeed: 0.0084s/iter; left time: 125.5469s\n",
      "\titers: 400, epoch: 4 | loss: 0.0879111\n",
      "\tspeed: 0.0084s/iter; left time: 124.9641s\n",
      "\titers: 500, epoch: 4 | loss: 0.0850285\n",
      "\tspeed: 0.0084s/iter; left time: 123.8057s\n",
      "\titers: 600, epoch: 4 | loss: 0.0882107\n",
      "\tspeed: 0.0085s/iter; left time: 124.7204s\n",
      "\titers: 700, epoch: 4 | loss: 0.0826036\n",
      "\tspeed: 0.0085s/iter; left time: 123.9265s\n",
      "\titers: 800, epoch: 4 | loss: 0.0855715\n",
      "\tspeed: 0.0085s/iter; left time: 122.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 894 | Train Loss: 0.0832201 Vali Loss: 0.0822921 Test Loss: 0.0877924\n",
      "Validation loss decreased (0.082802 --> 0.082292).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0745312\n",
      "\tspeed: 0.0386s/iter; left time: 548.7240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0795702\n",
      "\tspeed: 0.0085s/iter; left time: 119.8894s\n",
      "\titers: 300, epoch: 5 | loss: 0.0846348\n",
      "\tspeed: 0.0085s/iter; left time: 119.0214s\n",
      "\titers: 400, epoch: 5 | loss: 0.0798955\n",
      "\tspeed: 0.0085s/iter; left time: 118.0787s\n",
      "\titers: 500, epoch: 5 | loss: 0.0791318\n",
      "\tspeed: 0.0085s/iter; left time: 117.2715s\n",
      "\titers: 600, epoch: 5 | loss: 0.0956186\n",
      "\tspeed: 0.0085s/iter; left time: 116.4224s\n",
      "\titers: 700, epoch: 5 | loss: 0.0846813\n",
      "\tspeed: 0.0085s/iter; left time: 115.6041s\n",
      "\titers: 800, epoch: 5 | loss: 0.0840697\n",
      "\tspeed: 0.0085s/iter; left time: 114.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 894 | Train Loss: 0.0814269 Vali Loss: 0.0824545 Test Loss: 0.0881976\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0802825\n",
      "\tspeed: 0.0383s/iter; left time: 509.4798s\n",
      "\titers: 200, epoch: 6 | loss: 0.0769161\n",
      "\tspeed: 0.0085s/iter; left time: 112.0695s\n",
      "\titers: 300, epoch: 6 | loss: 0.0843926\n",
      "\tspeed: 0.0085s/iter; left time: 111.0928s\n",
      "\titers: 400, epoch: 6 | loss: 0.0746516\n",
      "\tspeed: 0.0085s/iter; left time: 110.2323s\n",
      "\titers: 500, epoch: 6 | loss: 0.0739571\n",
      "\tspeed: 0.0085s/iter; left time: 109.2796s\n",
      "\titers: 600, epoch: 6 | loss: 0.0802201\n",
      "\tspeed: 0.0085s/iter; left time: 108.3531s\n",
      "\titers: 700, epoch: 6 | loss: 0.0757018\n",
      "\tspeed: 0.0085s/iter; left time: 107.5032s\n",
      "\titers: 800, epoch: 6 | loss: 0.0745845\n",
      "\tspeed: 0.0085s/iter; left time: 106.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 894 | Train Loss: 0.0797208 Vali Loss: 0.0831764 Test Loss: 0.0882166\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0820937\n",
      "\tspeed: 0.0389s/iter; left time: 483.2372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0803651\n",
      "\tspeed: 0.0087s/iter; left time: 107.1268s\n",
      "\titers: 300, epoch: 7 | loss: 0.0732215\n",
      "\tspeed: 0.0087s/iter; left time: 105.9536s\n",
      "\titers: 400, epoch: 7 | loss: 0.0832034\n",
      "\tspeed: 0.0087s/iter; left time: 104.9958s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772675\n",
      "\tspeed: 0.0087s/iter; left time: 104.3846s\n",
      "\titers: 600, epoch: 7 | loss: 0.0788731\n",
      "\tspeed: 0.0087s/iter; left time: 103.4921s\n",
      "\titers: 700, epoch: 7 | loss: 0.0798795\n",
      "\tspeed: 0.0087s/iter; left time: 102.5813s\n",
      "\titers: 800, epoch: 7 | loss: 0.0746496\n",
      "\tspeed: 0.0087s/iter; left time: 101.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 894 | Train Loss: 0.0783500 Vali Loss: 0.0829139 Test Loss: 0.0881045\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0841243\n",
      "\tspeed: 0.0384s/iter; left time: 442.5803s\n",
      "\titers: 200, epoch: 8 | loss: 0.0746083\n",
      "\tspeed: 0.0085s/iter; left time: 97.0057s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762716\n",
      "\tspeed: 0.0085s/iter; left time: 96.1197s\n",
      "\titers: 400, epoch: 8 | loss: 0.0853525\n",
      "\tspeed: 0.0085s/iter; left time: 95.2706s\n",
      "\titers: 500, epoch: 8 | loss: 0.0830853\n",
      "\tspeed: 0.0085s/iter; left time: 94.3464s\n",
      "\titers: 600, epoch: 8 | loss: 0.0775082\n",
      "\tspeed: 0.0085s/iter; left time: 93.4883s\n",
      "\titers: 700, epoch: 8 | loss: 0.0733569\n",
      "\tspeed: 0.0085s/iter; left time: 92.5330s\n",
      "\titers: 800, epoch: 8 | loss: 0.0782840\n",
      "\tspeed: 0.0085s/iter; left time: 91.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 894 | Train Loss: 0.0771774 Vali Loss: 0.0826734 Test Loss: 0.0882902\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766850\n",
      "\tspeed: 0.0385s/iter; left time: 409.3904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0723158\n",
      "\tspeed: 0.0086s/iter; left time: 90.0922s\n",
      "\titers: 300, epoch: 9 | loss: 0.0761673\n",
      "\tspeed: 0.0084s/iter; left time: 87.5056s\n",
      "\titers: 400, epoch: 9 | loss: 0.0676531\n",
      "\tspeed: 0.0084s/iter; left time: 86.5689s\n",
      "\titers: 500, epoch: 9 | loss: 0.0745027\n",
      "\tspeed: 0.0085s/iter; left time: 87.3335s\n",
      "\titers: 600, epoch: 9 | loss: 0.0709937\n",
      "\tspeed: 0.0086s/iter; left time: 87.3190s\n",
      "\titers: 700, epoch: 9 | loss: 0.0757448\n",
      "\tspeed: 0.0086s/iter; left time: 86.5379s\n",
      "\titers: 800, epoch: 9 | loss: 0.0844225\n",
      "\tspeed: 0.0086s/iter; left time: 85.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 894 | Train Loss: 0.0760660 Vali Loss: 0.0828981 Test Loss: 0.0891567\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_loss_choice_for_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020908666774630547, rmse:0.14459829032421112, mae:0.08779238164424896, rse:0.5471194982528687\n",
      "Original data scale mse:3054074.25, rmse:1747.5909423828125, mae:1107.2745361328125, rse:0.12310060858726501\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2 \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.5071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.5065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.5173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.5499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.5471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0101  0.1005  0.0586  0.3798\n",
       "              2         24        0.0102  0.1009  0.0581  0.3812\n",
       "              1         96        0.0180  0.1341  0.0824  0.5071\n",
       "              2         96        0.0179  0.1340  0.0839  0.5065\n",
       "              1         168       0.0200  0.1413  0.0891  0.5347\n",
       "              2         168       0.0193  0.1388  0.0888  0.5250\n",
       "MAE           1         24        0.0102  0.1008  0.0564  0.3808\n",
       "              2         24        0.0102  0.1009  0.0565  0.3813\n",
       "              1         96        0.0187  0.1368  0.0808  0.5173\n",
       "              2         96        0.0190  0.1378  0.0810  0.5209\n",
       "              1         168       0.0211  0.1453  0.0873  0.5499\n",
       "              2         168       0.0209  0.1446  0.0878  0.5471"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_IT_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_IT_default.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1228456.750</td>\n",
       "      <td>1108.3577</td>\n",
       "      <td>708.9411</td>\n",
       "      <td>0.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1194382.000</td>\n",
       "      <td>1092.8778</td>\n",
       "      <td>695.2028</td>\n",
       "      <td>0.0768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2541549.750</td>\n",
       "      <td>1594.2239</td>\n",
       "      <td>1034.8856</td>\n",
       "      <td>0.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2719271.750</td>\n",
       "      <td>1649.0215</td>\n",
       "      <td>1078.8997</td>\n",
       "      <td>0.1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3073615.000</td>\n",
       "      <td>1753.1729</td>\n",
       "      <td>1146.7260</td>\n",
       "      <td>0.1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3200891.750</td>\n",
       "      <td>1789.1036</td>\n",
       "      <td>1168.5704</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1136971.750</td>\n",
       "      <td>1066.2888</td>\n",
       "      <td>656.8383</td>\n",
       "      <td>0.0749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1138836.625</td>\n",
       "      <td>1067.1628</td>\n",
       "      <td>654.0407</td>\n",
       "      <td>0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2374954.250</td>\n",
       "      <td>1541.0886</td>\n",
       "      <td>972.7524</td>\n",
       "      <td>0.1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2350334.250</td>\n",
       "      <td>1533.0800</td>\n",
       "      <td>967.2764</td>\n",
       "      <td>0.1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>2851058.500</td>\n",
       "      <td>1688.5078</td>\n",
       "      <td>1070.8998</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3054074.250</td>\n",
       "      <td>1747.5909</td>\n",
       "      <td>1107.2745</td>\n",
       "      <td>0.1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1228456.750  1108.3577   708.9411  0.0779\n",
       "              2         24        1194382.000  1092.8778   695.2028  0.0768\n",
       "              1         96        2541549.750  1594.2239  1034.8856  0.1122\n",
       "              2         96        2719271.750  1649.0215  1078.8997  0.1160\n",
       "              1         168       3073615.000  1753.1729  1146.7260  0.1235\n",
       "              2         168       3200891.750  1789.1036  1168.5704  0.1260\n",
       "MAE           1         24        1136971.750  1066.2888   656.8383  0.0749\n",
       "              2         24        1138836.625  1067.1628   654.0407  0.0750\n",
       "              1         96        2374954.250  1541.0886   972.7524  0.1085\n",
       "              2         96        2350334.250  1533.0800   967.2764  0.1079\n",
       "              1         168       2851058.500  1688.5078  1070.8998  0.1189\n",
       "              2         168       3054074.250  1747.5909  1107.2745  0.1231"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.3805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.5191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.5068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0102  0.1008  0.0564  0.3811\n",
       "         MSE            0.0101  0.1007  0.0583  0.3805\n",
       "96       MAE            0.0188  0.1373  0.0809  0.5191\n",
       "         MSE            0.0180  0.1340  0.0831  0.5068\n",
       "168      MAE            0.0210  0.1450  0.0876  0.5485\n",
       "         MSE            0.0196  0.1400  0.0889  0.5299"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.137904e+06</td>\n",
       "      <td>1066.7258</td>\n",
       "      <td>655.4395</td>\n",
       "      <td>0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.211419e+06</td>\n",
       "      <td>1100.6177</td>\n",
       "      <td>702.0720</td>\n",
       "      <td>0.0773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.362644e+06</td>\n",
       "      <td>1537.0843</td>\n",
       "      <td>970.0144</td>\n",
       "      <td>0.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.630411e+06</td>\n",
       "      <td>1621.6227</td>\n",
       "      <td>1056.8926</td>\n",
       "      <td>0.1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.952566e+06</td>\n",
       "      <td>1718.0494</td>\n",
       "      <td>1089.0872</td>\n",
       "      <td>0.1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.137253e+06</td>\n",
       "      <td>1771.1382</td>\n",
       "      <td>1157.6482</td>\n",
       "      <td>0.1248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.137904e+06  1066.7258   655.4395  0.0750\n",
       "         MSE            1.211419e+06  1100.6177   702.0720  0.0773\n",
       "96       MAE            2.362644e+06  1537.0843   970.0144  0.1082\n",
       "         MSE            2.630411e+06  1621.6227  1056.8926  0.1141\n",
       "168      MAE            2.952566e+06  1718.0494  1089.0872  0.1210\n",
       "         MSE            3.137253e+06  1771.1382  1157.6482  0.1248"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_IT'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
