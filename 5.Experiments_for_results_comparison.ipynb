{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. P=S=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_lens = [512, 512, 336, 168, 168]\n",
    "\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_patch12_stride12.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1390104\n",
      "\tspeed: 0.0450s/iter; left time: 1002.9685s\n",
      "\titers: 200, epoch: 1 | loss: 0.1306635\n",
      "\tspeed: 0.0190s/iter; left time: 422.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.1456043 Vali Loss: 0.1306175 Test Loss: 0.1384864\n",
      "Validation loss decreased (inf --> 0.130618).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0857702\n",
      "\tspeed: 0.0406s/iter; left time: 897.2934s\n",
      "\titers: 200, epoch: 2 | loss: 0.0842525\n",
      "\tspeed: 0.0191s/iter; left time: 419.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0910520 Vali Loss: 0.0957686 Test Loss: 0.0959963\n",
      "Validation loss decreased (0.130618 --> 0.095769).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799115\n",
      "\tspeed: 0.0403s/iter; left time: 880.8551s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785743\n",
      "\tspeed: 0.0190s/iter; left time: 414.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0816918 Vali Loss: 0.0926551 Test Loss: 0.0935114\n",
      "Validation loss decreased (0.095769 --> 0.092655).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0782383\n",
      "\tspeed: 0.0406s/iter; left time: 877.7256s\n",
      "\titers: 200, epoch: 4 | loss: 0.0742993\n",
      "\tspeed: 0.0199s/iter; left time: 428.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0792537 Vali Loss: 0.0904859 Test Loss: 0.0918777\n",
      "Validation loss decreased (0.092655 --> 0.090486).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767110\n",
      "\tspeed: 0.0404s/iter; left time: 865.2661s\n",
      "\titers: 200, epoch: 5 | loss: 0.0748729\n",
      "\tspeed: 0.0191s/iter; left time: 407.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0775567 Vali Loss: 0.0899617 Test Loss: 0.0912588\n",
      "Validation loss decreased (0.090486 --> 0.089962).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0751294\n",
      "\tspeed: 0.0404s/iter; left time: 855.0297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706649\n",
      "\tspeed: 0.0191s/iter; left time: 401.7632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0764587 Vali Loss: 0.0885547 Test Loss: 0.0902015\n",
      "Validation loss decreased (0.089962 --> 0.088555).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0789272\n",
      "\tspeed: 0.0407s/iter; left time: 851.9691s\n",
      "\titers: 200, epoch: 7 | loss: 0.0744249\n",
      "\tspeed: 0.0190s/iter; left time: 397.3234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0755118 Vali Loss: 0.0882935 Test Loss: 0.0901076\n",
      "Validation loss decreased (0.088555 --> 0.088293).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0747029\n",
      "\tspeed: 0.0413s/iter; left time: 856.4228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0737020\n",
      "\tspeed: 0.0192s/iter; left time: 395.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0748493 Vali Loss: 0.0879338 Test Loss: 0.0892938\n",
      "Validation loss decreased (0.088293 --> 0.087934).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0720454\n",
      "\tspeed: 0.0404s/iter; left time: 829.1401s\n",
      "\titers: 200, epoch: 9 | loss: 0.0786647\n",
      "\tspeed: 0.0191s/iter; left time: 389.1157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0742321 Vali Loss: 0.0873747 Test Loss: 0.0889646\n",
      "Validation loss decreased (0.087934 --> 0.087375).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0771783\n",
      "\tspeed: 0.0400s/iter; left time: 810.6910s\n",
      "\titers: 200, epoch: 10 | loss: 0.0729394\n",
      "\tspeed: 0.0190s/iter; left time: 383.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0737820 Vali Loss: 0.0872244 Test Loss: 0.0886157\n",
      "Validation loss decreased (0.087375 --> 0.087224).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0706486\n",
      "\tspeed: 0.0401s/iter; left time: 803.7315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0781847\n",
      "\tspeed: 0.0190s/iter; left time: 379.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0733603 Vali Loss: 0.0870402 Test Loss: 0.0886056\n",
      "Validation loss decreased (0.087224 --> 0.087040).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0760511\n",
      "\tspeed: 0.0400s/iter; left time: 793.7660s\n",
      "\titers: 200, epoch: 12 | loss: 0.0698628\n",
      "\tspeed: 0.0190s/iter; left time: 374.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0730090 Vali Loss: 0.0867771 Test Loss: 0.0882945\n",
      "Validation loss decreased (0.087040 --> 0.086777).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721637\n",
      "\tspeed: 0.0405s/iter; left time: 794.7292s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752120\n",
      "\tspeed: 0.0191s/iter; left time: 372.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0728298 Vali Loss: 0.0865257 Test Loss: 0.0881905\n",
      "Validation loss decreased (0.086777 --> 0.086526).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0661056\n",
      "\tspeed: 0.0407s/iter; left time: 789.4197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0724057\n",
      "\tspeed: 0.0204s/iter; left time: 392.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0725672 Vali Loss: 0.0862321 Test Loss: 0.0879862\n",
      "Validation loss decreased (0.086526 --> 0.086232).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734106\n",
      "\tspeed: 0.0407s/iter; left time: 780.3679s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713034\n",
      "\tspeed: 0.0191s/iter; left time: 364.8994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0723946 Vali Loss: 0.0864512 Test Loss: 0.0878862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719900\n",
      "\tspeed: 0.0399s/iter; left time: 755.3490s\n",
      "\titers: 200, epoch: 16 | loss: 0.0788645\n",
      "\tspeed: 0.0191s/iter; left time: 358.9714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0722101 Vali Loss: 0.0861762 Test Loss: 0.0878953\n",
      "Validation loss decreased (0.086232 --> 0.086176).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0746477\n",
      "\tspeed: 0.0406s/iter; left time: 759.0563s\n",
      "\titers: 200, epoch: 17 | loss: 0.0641406\n",
      "\tspeed: 0.0190s/iter; left time: 353.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0720242 Vali Loss: 0.0862646 Test Loss: 0.0877500\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0696233\n",
      "\tspeed: 0.0410s/iter; left time: 757.8218s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703789\n",
      "\tspeed: 0.0197s/iter; left time: 361.8807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0719515 Vali Loss: 0.0862659 Test Loss: 0.0877570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0683246\n",
      "\tspeed: 0.0399s/iter; left time: 728.1013s\n",
      "\titers: 200, epoch: 19 | loss: 0.0649746\n",
      "\tspeed: 0.0190s/iter; left time: 345.7611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0718198 Vali Loss: 0.0859920 Test Loss: 0.0877457\n",
      "Validation loss decreased (0.086176 --> 0.085992).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709220\n",
      "\tspeed: 0.0415s/iter; left time: 749.4447s\n",
      "\titers: 200, epoch: 20 | loss: 0.0674668\n",
      "\tspeed: 0.0191s/iter; left time: 342.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0716595 Vali Loss: 0.0861307 Test Loss: 0.0878117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0655229\n",
      "\tspeed: 0.0402s/iter; left time: 716.3148s\n",
      "\titers: 200, epoch: 21 | loss: 0.0713508\n",
      "\tspeed: 0.0194s/iter; left time: 344.4802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0715411 Vali Loss: 0.0858220 Test Loss: 0.0876685\n",
      "Validation loss decreased (0.085992 --> 0.085822).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0709133\n",
      "\tspeed: 0.0418s/iter; left time: 735.4555s\n",
      "\titers: 200, epoch: 22 | loss: 0.0679249\n",
      "\tspeed: 0.0192s/iter; left time: 335.6374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0715454 Vali Loss: 0.0859173 Test Loss: 0.0876761\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0659600\n",
      "\tspeed: 0.0406s/iter; left time: 705.8039s\n",
      "\titers: 200, epoch: 23 | loss: 0.0703013\n",
      "\tspeed: 0.0192s/iter; left time: 331.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0714225 Vali Loss: 0.0856287 Test Loss: 0.0875073\n",
      "Validation loss decreased (0.085822 --> 0.085629).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0700625\n",
      "\tspeed: 0.0398s/iter; left time: 682.0181s\n",
      "\titers: 200, epoch: 24 | loss: 0.0739232\n",
      "\tspeed: 0.0190s/iter; left time: 323.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0713990 Vali Loss: 0.0858275 Test Loss: 0.0875490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0643301\n",
      "\tspeed: 0.0395s/iter; left time: 668.4682s\n",
      "\titers: 200, epoch: 25 | loss: 0.0639384\n",
      "\tspeed: 0.0190s/iter; left time: 319.4295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0713362 Vali Loss: 0.0857420 Test Loss: 0.0875513\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0721036\n",
      "\tspeed: 0.0405s/iter; left time: 675.8762s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739591\n",
      "\tspeed: 0.0201s/iter; left time: 333.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0713224 Vali Loss: 0.0856996 Test Loss: 0.0875339\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722580\n",
      "\tspeed: 0.0401s/iter; left time: 660.7263s\n",
      "\titers: 200, epoch: 27 | loss: 0.0680410\n",
      "\tspeed: 0.0190s/iter; left time: 310.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0712632 Vali Loss: 0.0857577 Test Loss: 0.0875739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0673447\n",
      "\tspeed: 0.0405s/iter; left time: 658.1308s\n",
      "\titers: 200, epoch: 28 | loss: 0.0726671\n",
      "\tspeed: 0.0196s/iter; left time: 317.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0711663 Vali Loss: 0.0857660 Test Loss: 0.0874649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0709745\n",
      "\tspeed: 0.0397s/iter; left time: 636.7790s\n",
      "\titers: 200, epoch: 29 | loss: 0.0682928\n",
      "\tspeed: 0.0190s/iter; left time: 303.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0712104 Vali Loss: 0.0857773 Test Loss: 0.0875411\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0712471\n",
      "\tspeed: 0.0400s/iter; left time: 631.8976s\n",
      "\titers: 200, epoch: 30 | loss: 0.0674734\n",
      "\tspeed: 0.0190s/iter; left time: 298.3120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0711408 Vali Loss: 0.0854827 Test Loss: 0.0874065\n",
      "Validation loss decreased (0.085629 --> 0.085483).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0758306\n",
      "\tspeed: 0.0399s/iter; left time: 622.3041s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712512\n",
      "\tspeed: 0.0190s/iter; left time: 294.6988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0711001 Vali Loss: 0.0856675 Test Loss: 0.0874518\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0728408\n",
      "\tspeed: 0.0399s/iter; left time: 612.0389s\n",
      "\titers: 200, epoch: 32 | loss: 0.0672414\n",
      "\tspeed: 0.0190s/iter; left time: 290.0387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0710636 Vali Loss: 0.0856932 Test Loss: 0.0875001\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0716739\n",
      "\tspeed: 0.0398s/iter; left time: 601.9597s\n",
      "\titers: 200, epoch: 33 | loss: 0.0758073\n",
      "\tspeed: 0.0189s/iter; left time: 284.4792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0710632 Vali Loss: 0.0855391 Test Loss: 0.0874366\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0787640\n",
      "\tspeed: 0.0402s/iter; left time: 598.8377s\n",
      "\titers: 200, epoch: 34 | loss: 0.0743429\n",
      "\tspeed: 0.0190s/iter; left time: 281.3623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0710408 Vali Loss: 0.0856415 Test Loss: 0.0874467\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0767041\n",
      "\tspeed: 0.0399s/iter; left time: 585.2778s\n",
      "\titers: 200, epoch: 35 | loss: 0.0739208\n",
      "\tspeed: 0.0190s/iter; left time: 276.7287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0709352 Vali Loss: 0.0855687 Test Loss: 0.0874200\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0738015\n",
      "\tspeed: 0.0402s/iter; left time: 581.7660s\n",
      "\titers: 200, epoch: 36 | loss: 0.0653064\n",
      "\tspeed: 0.0190s/iter; left time: 272.2130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0709377 Vali Loss: 0.0855245 Test Loss: 0.0874222\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0684521\n",
      "\tspeed: 0.0398s/iter; left time: 566.6333s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782391\n",
      "\tspeed: 0.0190s/iter; left time: 268.1014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0709105 Vali Loss: 0.0856386 Test Loss: 0.0874006\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0718137\n",
      "\tspeed: 0.0411s/iter; left time: 575.6787s\n",
      "\titers: 200, epoch: 38 | loss: 0.0688488\n",
      "\tspeed: 0.0197s/iter; left time: 274.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 224 | Train Loss: 0.0709340 Vali Loss: 0.0854817 Test Loss: 0.0874419\n",
      "Validation loss decreased (0.085483 --> 0.085482).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0691011\n",
      "\tspeed: 0.0408s/iter; left time: 562.8530s\n",
      "\titers: 200, epoch: 39 | loss: 0.0679710\n",
      "\tspeed: 0.0197s/iter; left time: 270.0858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0709498 Vali Loss: 0.0855370 Test Loss: 0.0874000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0764718\n",
      "\tspeed: 0.0400s/iter; left time: 542.4789s\n",
      "\titers: 200, epoch: 40 | loss: 0.0701911\n",
      "\tspeed: 0.0190s/iter; left time: 255.4688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0710338 Vali Loss: 0.0856020 Test Loss: 0.0874086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0691738\n",
      "\tspeed: 0.0395s/iter; left time: 527.3026s\n",
      "\titers: 200, epoch: 41 | loss: 0.0677927\n",
      "\tspeed: 0.0189s/iter; left time: 250.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0709142 Vali Loss: 0.0854789 Test Loss: 0.0873899\n",
      "Validation loss decreased (0.085482 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0694527\n",
      "\tspeed: 0.0403s/iter; left time: 529.2050s\n",
      "\titers: 200, epoch: 42 | loss: 0.0680840\n",
      "\tspeed: 0.0193s/iter; left time: 251.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0708751 Vali Loss: 0.0855154 Test Loss: 0.0873886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0694931\n",
      "\tspeed: 0.0405s/iter; left time: 521.9657s\n",
      "\titers: 200, epoch: 43 | loss: 0.0745130\n",
      "\tspeed: 0.0190s/iter; left time: 242.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0708966 Vali Loss: 0.0854501 Test Loss: 0.0873806\n",
      "Validation loss decreased (0.085479 --> 0.085450).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0737589\n",
      "\tspeed: 0.0407s/iter; left time: 515.5490s\n",
      "\titers: 200, epoch: 44 | loss: 0.0697594\n",
      "\tspeed: 0.0191s/iter; left time: 239.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0709149 Vali Loss: 0.0855381 Test Loss: 0.0873815\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0759644\n",
      "\tspeed: 0.0401s/iter; left time: 499.5909s\n",
      "\titers: 200, epoch: 45 | loss: 0.0694993\n",
      "\tspeed: 0.0191s/iter; left time: 235.2404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0709008 Vali Loss: 0.0854994 Test Loss: 0.0873818\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0698969\n",
      "\tspeed: 0.0403s/iter; left time: 491.9145s\n",
      "\titers: 200, epoch: 46 | loss: 0.0738863\n",
      "\tspeed: 0.0192s/iter; left time: 232.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0708416 Vali Loss: 0.0855306 Test Loss: 0.0873761\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0707226\n",
      "\tspeed: 0.0401s/iter; left time: 480.7067s\n",
      "\titers: 200, epoch: 47 | loss: 0.0699695\n",
      "\tspeed: 0.0193s/iter; left time: 229.0858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0709024 Vali Loss: 0.0855462 Test Loss: 0.0873759\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0729972\n",
      "\tspeed: 0.0408s/iter; left time: 480.8740s\n",
      "\titers: 200, epoch: 48 | loss: 0.0727456\n",
      "\tspeed: 0.0189s/iter; left time: 221.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0708515 Vali Loss: 0.0855015 Test Loss: 0.0873700\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0705544\n",
      "\tspeed: 0.0398s/iter; left time: 459.8529s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708530\n",
      "\tspeed: 0.0190s/iter; left time: 217.8430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0708744 Vali Loss: 0.0854887 Test Loss: 0.0873857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0711896\n",
      "\tspeed: 0.0402s/iter; left time: 455.5602s\n",
      "\titers: 200, epoch: 50 | loss: 0.0731277\n",
      "\tspeed: 0.0191s/iter; left time: 214.3792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0708251 Vali Loss: 0.0854943 Test Loss: 0.0873617\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0666675\n",
      "\tspeed: 0.0403s/iter; left time: 447.4691s\n",
      "\titers: 200, epoch: 51 | loss: 0.0686336\n",
      "\tspeed: 0.0190s/iter; left time: 208.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0708935 Vali Loss: 0.0855538 Test Loss: 0.0873683\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0694573\n",
      "\tspeed: 0.0410s/iter; left time: 446.1603s\n",
      "\titers: 200, epoch: 52 | loss: 0.0678102\n",
      "\tspeed: 0.0190s/iter; left time: 204.4508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0708544 Vali Loss: 0.0855154 Test Loss: 0.0873644\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0745891\n",
      "\tspeed: 0.0401s/iter; left time: 426.9193s\n",
      "\titers: 200, epoch: 53 | loss: 0.0689821\n",
      "\tspeed: 0.0189s/iter; left time: 199.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0708216 Vali Loss: 0.0855750 Test Loss: 0.0873769\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020775962620973587, rmse:0.14413869380950928, mae:0.08738063275814056, rse:0.5086854100227356\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1382839\n",
      "\tspeed: 0.0210s/iter; left time: 468.6859s\n",
      "\titers: 200, epoch: 1 | loss: 0.1317416\n",
      "\tspeed: 0.0189s/iter; left time: 419.3236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.1453816 Vali Loss: 0.1302141 Test Loss: 0.1371635\n",
      "Validation loss decreased (inf --> 0.130214).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0868807\n",
      "\tspeed: 0.0409s/iter; left time: 902.6926s\n",
      "\titers: 200, epoch: 2 | loss: 0.0776484\n",
      "\tspeed: 0.0189s/iter; left time: 415.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0908715 Vali Loss: 0.0953656 Test Loss: 0.0959476\n",
      "Validation loss decreased (0.130214 --> 0.095366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0842380\n",
      "\tspeed: 0.0410s/iter; left time: 895.8712s\n",
      "\titers: 200, epoch: 3 | loss: 0.0791469\n",
      "\tspeed: 0.0189s/iter; left time: 411.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0813681 Vali Loss: 0.0921044 Test Loss: 0.0927423\n",
      "Validation loss decreased (0.095366 --> 0.092104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0785433\n",
      "\tspeed: 0.0411s/iter; left time: 889.8907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0723553\n",
      "\tspeed: 0.0191s/iter; left time: 412.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0786754 Vali Loss: 0.0898856 Test Loss: 0.0913173\n",
      "Validation loss decreased (0.092104 --> 0.089886).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773682\n",
      "\tspeed: 0.0421s/iter; left time: 901.0448s\n",
      "\titers: 200, epoch: 5 | loss: 0.0753453\n",
      "\tspeed: 0.0190s/iter; left time: 404.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0770475 Vali Loss: 0.0903975 Test Loss: 0.0911537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0752769\n",
      "\tspeed: 0.0404s/iter; left time: 856.1845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0714960\n",
      "\tspeed: 0.0190s/iter; left time: 399.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0759102 Vali Loss: 0.0891706 Test Loss: 0.0904217\n",
      "Validation loss decreased (0.089886 --> 0.089171).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0719072\n",
      "\tspeed: 0.0429s/iter; left time: 899.3813s\n",
      "\titers: 200, epoch: 7 | loss: 0.0765047\n",
      "\tspeed: 0.0189s/iter; left time: 394.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0749907 Vali Loss: 0.0884877 Test Loss: 0.0898169\n",
      "Validation loss decreased (0.089171 --> 0.088488).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0752080\n",
      "\tspeed: 0.0415s/iter; left time: 860.9355s\n",
      "\titers: 200, epoch: 8 | loss: 0.0815097\n",
      "\tspeed: 0.0189s/iter; left time: 389.2386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0743919 Vali Loss: 0.0873128 Test Loss: 0.0892443\n",
      "Validation loss decreased (0.088488 --> 0.087313).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690823\n",
      "\tspeed: 0.0409s/iter; left time: 838.9570s\n",
      "\titers: 200, epoch: 9 | loss: 0.0755916\n",
      "\tspeed: 0.0190s/iter; left time: 386.7609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0739525 Vali Loss: 0.0874310 Test Loss: 0.0888167\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725496\n",
      "\tspeed: 0.0403s/iter; left time: 818.3633s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732202\n",
      "\tspeed: 0.0190s/iter; left time: 383.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0735196 Vali Loss: 0.0869763 Test Loss: 0.0885015\n",
      "Validation loss decreased (0.087313 --> 0.086976).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774748\n",
      "\tspeed: 0.0408s/iter; left time: 818.1650s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794151\n",
      "\tspeed: 0.0190s/iter; left time: 378.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0731364 Vali Loss: 0.0868483 Test Loss: 0.0888146\n",
      "Validation loss decreased (0.086976 --> 0.086848).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0666322\n",
      "\tspeed: 0.0409s/iter; left time: 812.2630s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707943\n",
      "\tspeed: 0.0189s/iter; left time: 372.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0728625 Vali Loss: 0.0864565 Test Loss: 0.0883091\n",
      "Validation loss decreased (0.086848 --> 0.086456).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0735964\n",
      "\tspeed: 0.0412s/iter; left time: 807.3787s\n",
      "\titers: 200, epoch: 13 | loss: 0.0689830\n",
      "\tspeed: 0.0190s/iter; left time: 370.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0725228 Vali Loss: 0.0862483 Test Loss: 0.0881860\n",
      "Validation loss decreased (0.086456 --> 0.086248).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706963\n",
      "\tspeed: 0.0414s/iter; left time: 803.4067s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735797\n",
      "\tspeed: 0.0190s/iter; left time: 366.5320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0723174 Vali Loss: 0.0865515 Test Loss: 0.0881944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717876\n",
      "\tspeed: 0.0419s/iter; left time: 803.8076s\n",
      "\titers: 200, epoch: 15 | loss: 0.0692433\n",
      "\tspeed: 0.0194s/iter; left time: 369.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0721889 Vali Loss: 0.0863182 Test Loss: 0.0881067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709660\n",
      "\tspeed: 0.0413s/iter; left time: 782.7283s\n",
      "\titers: 200, epoch: 16 | loss: 0.0746997\n",
      "\tspeed: 0.0191s/iter; left time: 359.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0720041 Vali Loss: 0.0863501 Test Loss: 0.0881810\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0743170\n",
      "\tspeed: 0.0411s/iter; left time: 768.5433s\n",
      "\titers: 200, epoch: 17 | loss: 0.0684961\n",
      "\tspeed: 0.0191s/iter; left time: 355.0749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0718370 Vali Loss: 0.0859819 Test Loss: 0.0879762\n",
      "Validation loss decreased (0.086248 --> 0.085982).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0669800\n",
      "\tspeed: 0.0410s/iter; left time: 758.7671s\n",
      "\titers: 200, epoch: 18 | loss: 0.0719126\n",
      "\tspeed: 0.0191s/iter; left time: 352.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0716695 Vali Loss: 0.0859454 Test Loss: 0.0877421\n",
      "Validation loss decreased (0.085982 --> 0.085945).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0732925\n",
      "\tspeed: 0.0415s/iter; left time: 758.7569s\n",
      "\titers: 200, epoch: 19 | loss: 0.0722163\n",
      "\tspeed: 0.0190s/iter; left time: 346.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0715902 Vali Loss: 0.0858156 Test Loss: 0.0877504\n",
      "Validation loss decreased (0.085945 --> 0.085816).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0656557\n",
      "\tspeed: 0.0411s/iter; left time: 742.3466s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710390\n",
      "\tspeed: 0.0190s/iter; left time: 340.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0714782 Vali Loss: 0.0857837 Test Loss: 0.0877334\n",
      "Validation loss decreased (0.085816 --> 0.085784).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0691885\n",
      "\tspeed: 0.0412s/iter; left time: 734.8906s\n",
      "\titers: 200, epoch: 21 | loss: 0.0712942\n",
      "\tspeed: 0.0190s/iter; left time: 336.7377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0714117 Vali Loss: 0.0857461 Test Loss: 0.0877527\n",
      "Validation loss decreased (0.085784 --> 0.085746).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0704286\n",
      "\tspeed: 0.0411s/iter; left time: 723.2541s\n",
      "\titers: 200, epoch: 22 | loss: 0.0733802\n",
      "\tspeed: 0.0189s/iter; left time: 330.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0713625 Vali Loss: 0.0856716 Test Loss: 0.0876202\n",
      "Validation loss decreased (0.085746 --> 0.085672).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0798259\n",
      "\tspeed: 0.0419s/iter; left time: 727.3348s\n",
      "\titers: 200, epoch: 23 | loss: 0.0771071\n",
      "\tspeed: 0.0190s/iter; left time: 328.7441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0712115 Vali Loss: 0.0858053 Test Loss: 0.0876781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741955\n",
      "\tspeed: 0.0404s/iter; left time: 693.4592s\n",
      "\titers: 200, epoch: 24 | loss: 0.0727603\n",
      "\tspeed: 0.0194s/iter; left time: 330.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0711932 Vali Loss: 0.0857117 Test Loss: 0.0877528\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0675537\n",
      "\tspeed: 0.0416s/iter; left time: 704.6607s\n",
      "\titers: 200, epoch: 25 | loss: 0.0683353\n",
      "\tspeed: 0.0191s/iter; left time: 322.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0711560 Vali Loss: 0.0857716 Test Loss: 0.0876595\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0665315\n",
      "\tspeed: 0.0416s/iter; left time: 694.6525s\n",
      "\titers: 200, epoch: 26 | loss: 0.0753333\n",
      "\tspeed: 0.0202s/iter; left time: 334.8853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0710794 Vali Loss: 0.0857467 Test Loss: 0.0876468\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0705765\n",
      "\tspeed: 0.0405s/iter; left time: 667.3849s\n",
      "\titers: 200, epoch: 27 | loss: 0.0720120\n",
      "\tspeed: 0.0191s/iter; left time: 312.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0710388 Vali Loss: 0.0857734 Test Loss: 0.0875198\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0710347\n",
      "\tspeed: 0.0408s/iter; left time: 663.7873s\n",
      "\titers: 200, epoch: 28 | loss: 0.0665011\n",
      "\tspeed: 0.0193s/iter; left time: 310.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0709849 Vali Loss: 0.0855429 Test Loss: 0.0874894\n",
      "Validation loss decreased (0.085672 --> 0.085543).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0756830\n",
      "\tspeed: 0.0443s/iter; left time: 710.1739s\n",
      "\titers: 200, epoch: 29 | loss: 0.0684050\n",
      "\tspeed: 0.0202s/iter; left time: 321.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0709842 Vali Loss: 0.0856957 Test Loss: 0.0875430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0766710\n",
      "\tspeed: 0.0438s/iter; left time: 692.8905s\n",
      "\titers: 200, epoch: 30 | loss: 0.0723647\n",
      "\tspeed: 0.0203s/iter; left time: 318.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0709809 Vali Loss: 0.0855488 Test Loss: 0.0876509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0720632\n",
      "\tspeed: 0.0409s/iter; left time: 637.0998s\n",
      "\titers: 200, epoch: 31 | loss: 0.0717908\n",
      "\tspeed: 0.0191s/iter; left time: 295.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0709363 Vali Loss: 0.0856305 Test Loss: 0.0875346\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0680252\n",
      "\tspeed: 0.0406s/iter; left time: 623.1303s\n",
      "\titers: 200, epoch: 32 | loss: 0.0718523\n",
      "\tspeed: 0.0194s/iter; left time: 296.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0709088 Vali Loss: 0.0856672 Test Loss: 0.0876184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0740256\n",
      "\tspeed: 0.0411s/iter; left time: 622.0215s\n",
      "\titers: 200, epoch: 33 | loss: 0.0677403\n",
      "\tspeed: 0.0190s/iter; left time: 286.2304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0708790 Vali Loss: 0.0854948 Test Loss: 0.0875113\n",
      "Validation loss decreased (0.085543 --> 0.085495).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0702207\n",
      "\tspeed: 0.0415s/iter; left time: 619.3863s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725866\n",
      "\tspeed: 0.0194s/iter; left time: 287.8362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0708545 Vali Loss: 0.0856211 Test Loss: 0.0874862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0733193\n",
      "\tspeed: 0.0413s/iter; left time: 606.4908s\n",
      "\titers: 200, epoch: 35 | loss: 0.0699445\n",
      "\tspeed: 0.0194s/iter; left time: 282.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0708885 Vali Loss: 0.0854699 Test Loss: 0.0874829\n",
      "Validation loss decreased (0.085495 --> 0.085470).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0708525\n",
      "\tspeed: 0.0453s/iter; left time: 655.1657s\n",
      "\titers: 200, epoch: 36 | loss: 0.0662201\n",
      "\tspeed: 0.0190s/iter; left time: 273.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0708731 Vali Loss: 0.0855557 Test Loss: 0.0874449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0692631\n",
      "\tspeed: 0.0415s/iter; left time: 591.3859s\n",
      "\titers: 200, epoch: 37 | loss: 0.0741625\n",
      "\tspeed: 0.0191s/iter; left time: 269.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0708183 Vali Loss: 0.0854321 Test Loss: 0.0874916\n",
      "Validation loss decreased (0.085470 --> 0.085432).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0692166\n",
      "\tspeed: 0.0414s/iter; left time: 580.3999s\n",
      "\titers: 200, epoch: 38 | loss: 0.0753213\n",
      "\tspeed: 0.0191s/iter; left time: 265.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0708202 Vali Loss: 0.0856224 Test Loss: 0.0874877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0707719\n",
      "\tspeed: 0.0412s/iter; left time: 567.6590s\n",
      "\titers: 200, epoch: 39 | loss: 0.0680646\n",
      "\tspeed: 0.0190s/iter; left time: 260.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0707755 Vali Loss: 0.0854468 Test Loss: 0.0874768\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0676217\n",
      "\tspeed: 0.0406s/iter; left time: 551.3771s\n",
      "\titers: 200, epoch: 40 | loss: 0.0722163\n",
      "\tspeed: 0.0192s/iter; left time: 259.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0707856 Vali Loss: 0.0854901 Test Loss: 0.0874684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0738809\n",
      "\tspeed: 0.0411s/iter; left time: 548.9679s\n",
      "\titers: 200, epoch: 41 | loss: 0.0671665\n",
      "\tspeed: 0.0190s/iter; left time: 252.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0707683 Vali Loss: 0.0854791 Test Loss: 0.0874681\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0701810\n",
      "\tspeed: 0.0405s/iter; left time: 531.7312s\n",
      "\titers: 200, epoch: 42 | loss: 0.0695928\n",
      "\tspeed: 0.0192s/iter; left time: 249.2966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0707770 Vali Loss: 0.0853792 Test Loss: 0.0874501\n",
      "Validation loss decreased (0.085432 --> 0.085379).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0720962\n",
      "\tspeed: 0.0417s/iter; left time: 537.9614s\n",
      "\titers: 200, epoch: 43 | loss: 0.0699790\n",
      "\tspeed: 0.0194s/iter; left time: 248.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0707305 Vali Loss: 0.0854921 Test Loss: 0.0874615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0657566\n",
      "\tspeed: 0.0411s/iter; left time: 520.4790s\n",
      "\titers: 200, epoch: 44 | loss: 0.0658051\n",
      "\tspeed: 0.0199s/iter; left time: 250.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0707446 Vali Loss: 0.0855165 Test Loss: 0.0874452\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0737500\n",
      "\tspeed: 0.0423s/iter; left time: 526.2770s\n",
      "\titers: 200, epoch: 45 | loss: 0.0692668\n",
      "\tspeed: 0.0208s/iter; left time: 256.3573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0707268 Vali Loss: 0.0854369 Test Loss: 0.0874491\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0708209\n",
      "\tspeed: 0.0411s/iter; left time: 502.2579s\n",
      "\titers: 200, epoch: 46 | loss: 0.0713661\n",
      "\tspeed: 0.0190s/iter; left time: 230.3633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0706946 Vali Loss: 0.0855110 Test Loss: 0.0874441\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0717110\n",
      "\tspeed: 0.0403s/iter; left time: 484.0319s\n",
      "\titers: 200, epoch: 47 | loss: 0.0643711\n",
      "\tspeed: 0.0192s/iter; left time: 227.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0707674 Vali Loss: 0.0853831 Test Loss: 0.0874311\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0708713\n",
      "\tspeed: 0.0421s/iter; left time: 496.0538s\n",
      "\titers: 200, epoch: 48 | loss: 0.0747935\n",
      "\tspeed: 0.0190s/iter; left time: 221.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0707510 Vali Loss: 0.0855048 Test Loss: 0.0874334\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0694890\n",
      "\tspeed: 0.0410s/iter; left time: 473.8215s\n",
      "\titers: 200, epoch: 49 | loss: 0.0777500\n",
      "\tspeed: 0.0190s/iter; left time: 217.1458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0707410 Vali Loss: 0.0854721 Test Loss: 0.0874323\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0706330\n",
      "\tspeed: 0.0408s/iter; left time: 462.3947s\n",
      "\titers: 200, epoch: 50 | loss: 0.0692083\n",
      "\tspeed: 0.0189s/iter; left time: 212.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0706782 Vali Loss: 0.0855109 Test Loss: 0.0874380\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0676168\n",
      "\tspeed: 0.0406s/iter; left time: 450.8209s\n",
      "\titers: 200, epoch: 51 | loss: 0.0729639\n",
      "\tspeed: 0.0190s/iter; left time: 208.7238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0707401 Vali Loss: 0.0854975 Test Loss: 0.0874366\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0667401\n",
      "\tspeed: 0.0412s/iter; left time: 447.7626s\n",
      "\titers: 200, epoch: 52 | loss: 0.0639158\n",
      "\tspeed: 0.0191s/iter; left time: 205.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0706729 Vali Loss: 0.0855150 Test Loss: 0.0874496\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02080211229622364, rmse:0.14422936737537384, mae:0.0874500721693039, rse:0.5090054273605347\n",
      "Intermediate time for DE and pred_len 24: 00h:10m:40.58s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1448422\n",
      "\tspeed: 0.0509s/iter; left time: 1123.9067s\n",
      "\titers: 200, epoch: 1 | loss: 0.1363422\n",
      "\tspeed: 0.0278s/iter; left time: 610.7888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.1504359 Vali Loss: 0.1402378 Test Loss: 0.1489351\n",
      "Validation loss decreased (inf --> 0.140238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1164342\n",
      "\tspeed: 0.0557s/iter; left time: 1219.7500s\n",
      "\titers: 200, epoch: 2 | loss: 0.1094030\n",
      "\tspeed: 0.0277s/iter; left time: 603.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1145769 Vali Loss: 0.1221124 Test Loss: 0.1288646\n",
      "Validation loss decreased (0.140238 --> 0.122112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0999483\n",
      "\tspeed: 0.0545s/iter; left time: 1180.5683s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059662\n",
      "\tspeed: 0.0277s/iter; left time: 597.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.1063131 Vali Loss: 0.1193725 Test Loss: 0.1274190\n",
      "Validation loss decreased (0.122112 --> 0.119373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1011208\n",
      "\tspeed: 0.0551s/iter; left time: 1180.0332s\n",
      "\titers: 200, epoch: 4 | loss: 0.0995065\n",
      "\tspeed: 0.0277s/iter; left time: 590.5191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.1041440 Vali Loss: 0.1187930 Test Loss: 0.1267404\n",
      "Validation loss decreased (0.119373 --> 0.118793).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0963430\n",
      "\tspeed: 0.0551s/iter; left time: 1168.3409s\n",
      "\titers: 200, epoch: 5 | loss: 0.1030525\n",
      "\tspeed: 0.0277s/iter; left time: 584.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.1029781 Vali Loss: 0.1175517 Test Loss: 0.1257069\n",
      "Validation loss decreased (0.118793 --> 0.117552).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1022038\n",
      "\tspeed: 0.0551s/iter; left time: 1155.7992s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987644\n",
      "\tspeed: 0.0276s/iter; left time: 577.1114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.1020023 Vali Loss: 0.1172371 Test Loss: 0.1250693\n",
      "Validation loss decreased (0.117552 --> 0.117237).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0972073\n",
      "\tspeed: 0.0554s/iter; left time: 1150.1759s\n",
      "\titers: 200, epoch: 7 | loss: 0.0977257\n",
      "\tspeed: 0.0281s/iter; left time: 581.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1012405 Vali Loss: 0.1170064 Test Loss: 0.1246477\n",
      "Validation loss decreased (0.117237 --> 0.117006).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0984652\n",
      "\tspeed: 0.0555s/iter; left time: 1141.0132s\n",
      "\titers: 200, epoch: 8 | loss: 0.0951705\n",
      "\tspeed: 0.0277s/iter; left time: 566.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1005851 Vali Loss: 0.1166312 Test Loss: 0.1244090\n",
      "Validation loss decreased (0.117006 --> 0.116631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0975863\n",
      "\tspeed: 0.0552s/iter; left time: 1122.7391s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037872\n",
      "\tspeed: 0.0277s/iter; left time: 559.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.1000303 Vali Loss: 0.1167199 Test Loss: 0.1247047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018944\n",
      "\tspeed: 0.0542s/iter; left time: 1090.1988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0990148\n",
      "\tspeed: 0.0277s/iter; left time: 553.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0995444 Vali Loss: 0.1164791 Test Loss: 0.1248254\n",
      "Validation loss decreased (0.116631 --> 0.116479).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969951\n",
      "\tspeed: 0.0550s/iter; left time: 1092.9788s\n",
      "\titers: 200, epoch: 11 | loss: 0.1092681\n",
      "\tspeed: 0.0277s/iter; left time: 547.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0990378 Vali Loss: 0.1160587 Test Loss: 0.1246186\n",
      "Validation loss decreased (0.116479 --> 0.116059).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0948307\n",
      "\tspeed: 0.0552s/iter; left time: 1085.2024s\n",
      "\titers: 200, epoch: 12 | loss: 0.1000536\n",
      "\tspeed: 0.0277s/iter; left time: 541.3291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0986880 Vali Loss: 0.1161684 Test Loss: 0.1245788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1001819\n",
      "\tspeed: 0.0552s/iter; left time: 1072.9093s\n",
      "\titers: 200, epoch: 13 | loss: 0.0985170\n",
      "\tspeed: 0.0277s/iter; left time: 536.1574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0983419 Vali Loss: 0.1158574 Test Loss: 0.1242616\n",
      "Validation loss decreased (0.116059 --> 0.115857).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0974434\n",
      "\tspeed: 0.0555s/iter; left time: 1067.0141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0992433\n",
      "\tspeed: 0.0278s/iter; left time: 530.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0981031 Vali Loss: 0.1157838 Test Loss: 0.1243149\n",
      "Validation loss decreased (0.115857 --> 0.115784).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1013076\n",
      "\tspeed: 0.0561s/iter; left time: 1066.2765s\n",
      "\titers: 200, epoch: 15 | loss: 0.0929533\n",
      "\tspeed: 0.0279s/iter; left time: 526.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0977878 Vali Loss: 0.1160283 Test Loss: 0.1244334\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0966398\n",
      "\tspeed: 0.0551s/iter; left time: 1033.5975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0979470\n",
      "\tspeed: 0.0277s/iter; left time: 516.8376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0975783 Vali Loss: 0.1154296 Test Loss: 0.1240534\n",
      "Validation loss decreased (0.115784 --> 0.115430).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0986287\n",
      "\tspeed: 0.0555s/iter; left time: 1029.7255s\n",
      "\titers: 200, epoch: 17 | loss: 0.0948331\n",
      "\tspeed: 0.0276s/iter; left time: 509.5046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0973462 Vali Loss: 0.1155483 Test Loss: 0.1241251\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0966052\n",
      "\tspeed: 0.0550s/iter; left time: 1008.4259s\n",
      "\titers: 200, epoch: 18 | loss: 0.0964522\n",
      "\tspeed: 0.0276s/iter; left time: 503.8915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0971675 Vali Loss: 0.1154481 Test Loss: 0.1242441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0957802\n",
      "\tspeed: 0.0546s/iter; left time: 989.1118s\n",
      "\titers: 200, epoch: 19 | loss: 0.0953669\n",
      "\tspeed: 0.0277s/iter; left time: 498.2836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0970161 Vali Loss: 0.1156135 Test Loss: 0.1243618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0946655\n",
      "\tspeed: 0.0546s/iter; left time: 976.6290s\n",
      "\titers: 200, epoch: 20 | loss: 0.0976110\n",
      "\tspeed: 0.0278s/iter; left time: 494.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0968333 Vali Loss: 0.1154710 Test Loss: 0.1244684\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0967295\n",
      "\tspeed: 0.0548s/iter; left time: 967.5845s\n",
      "\titers: 200, epoch: 21 | loss: 0.0968487\n",
      "\tspeed: 0.0276s/iter; left time: 485.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0967215 Vali Loss: 0.1156443 Test Loss: 0.1247063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0966832\n",
      "\tspeed: 0.0556s/iter; left time: 970.0146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0960135\n",
      "\tspeed: 0.0281s/iter; left time: 486.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0965749 Vali Loss: 0.1156081 Test Loss: 0.1243835\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0949099\n",
      "\tspeed: 0.0548s/iter; left time: 943.8328s\n",
      "\titers: 200, epoch: 23 | loss: 0.0930903\n",
      "\tspeed: 0.0277s/iter; left time: 474.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0964881 Vali Loss: 0.1157188 Test Loss: 0.1245421\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0977766\n",
      "\tspeed: 0.0548s/iter; left time: 930.6862s\n",
      "\titers: 200, epoch: 24 | loss: 0.0943436\n",
      "\tspeed: 0.0277s/iter; left time: 468.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0963578 Vali Loss: 0.1156795 Test Loss: 0.1247397\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0963662\n",
      "\tspeed: 0.0546s/iter; left time: 915.0701s\n",
      "\titers: 200, epoch: 25 | loss: 0.0967899\n",
      "\tspeed: 0.0277s/iter; left time: 461.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0963129 Vali Loss: 0.1156121 Test Loss: 0.1246196\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0949216\n",
      "\tspeed: 0.0546s/iter; left time: 904.1278s\n",
      "\titers: 200, epoch: 26 | loss: 0.0995658\n",
      "\tspeed: 0.0277s/iter; left time: 454.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0961712 Vali Loss: 0.1155513 Test Loss: 0.1246417\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.034996990114450455, rmse:0.18707482516765594, mae:0.12405332177877426, rse:0.6624698042869568\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1508011\n",
      "\tspeed: 0.0299s/iter; left time: 659.8752s\n",
      "\titers: 200, epoch: 1 | loss: 0.1387800\n",
      "\tspeed: 0.0277s/iter; left time: 609.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1502961 Vali Loss: 0.1396873 Test Loss: 0.1482950\n",
      "Validation loss decreased (inf --> 0.139687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1180024\n",
      "\tspeed: 0.0561s/iter; left time: 1226.3615s\n",
      "\titers: 200, epoch: 2 | loss: 0.1101981\n",
      "\tspeed: 0.0277s/iter; left time: 604.1309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1143135 Vali Loss: 0.1216162 Test Loss: 0.1286995\n",
      "Validation loss decreased (0.139687 --> 0.121616).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1101205\n",
      "\tspeed: 0.0566s/iter; left time: 1225.6979s\n",
      "\titers: 200, epoch: 3 | loss: 0.1115119\n",
      "\tspeed: 0.0285s/iter; left time: 613.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1062683 Vali Loss: 0.1195027 Test Loss: 0.1276552\n",
      "Validation loss decreased (0.121616 --> 0.119503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1043563\n",
      "\tspeed: 0.0562s/iter; left time: 1204.2738s\n",
      "\titers: 200, epoch: 4 | loss: 0.1019932\n",
      "\tspeed: 0.0277s/iter; left time: 590.8455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.1041656 Vali Loss: 0.1183342 Test Loss: 0.1267769\n",
      "Validation loss decreased (0.119503 --> 0.118334).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1066071\n",
      "\tspeed: 0.0559s/iter; left time: 1185.9392s\n",
      "\titers: 200, epoch: 5 | loss: 0.1080640\n",
      "\tspeed: 0.0279s/iter; left time: 588.9435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1029221 Vali Loss: 0.1178664 Test Loss: 0.1258595\n",
      "Validation loss decreased (0.118334 --> 0.117866).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0986439\n",
      "\tspeed: 0.0558s/iter; left time: 1171.0407s\n",
      "\titers: 200, epoch: 6 | loss: 0.1004146\n",
      "\tspeed: 0.0277s/iter; left time: 579.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1019961 Vali Loss: 0.1173763 Test Loss: 0.1257013\n",
      "Validation loss decreased (0.117866 --> 0.117376).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1012715\n",
      "\tspeed: 0.0572s/iter; left time: 1187.9045s\n",
      "\titers: 200, epoch: 7 | loss: 0.1039649\n",
      "\tspeed: 0.0277s/iter; left time: 572.0507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1011883 Vali Loss: 0.1170758 Test Loss: 0.1256567\n",
      "Validation loss decreased (0.117376 --> 0.117076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0971749\n",
      "\tspeed: 0.0560s/iter; left time: 1149.7847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0961012\n",
      "\tspeed: 0.0277s/iter; left time: 565.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1005770 Vali Loss: 0.1170290 Test Loss: 0.1260326\n",
      "Validation loss decreased (0.117076 --> 0.117029).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1047409\n",
      "\tspeed: 0.0558s/iter; left time: 1133.8228s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001890\n",
      "\tspeed: 0.0277s/iter; left time: 559.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0998663 Vali Loss: 0.1163488 Test Loss: 0.1251576\n",
      "Validation loss decreased (0.117029 --> 0.116349).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0969014\n",
      "\tspeed: 0.0563s/iter; left time: 1130.9430s\n",
      "\titers: 200, epoch: 10 | loss: 0.0994502\n",
      "\tspeed: 0.0281s/iter; left time: 563.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0993711 Vali Loss: 0.1161906 Test Loss: 0.1250414\n",
      "Validation loss decreased (0.116349 --> 0.116191).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0998349\n",
      "\tspeed: 0.0560s/iter; left time: 1112.7444s\n",
      "\titers: 200, epoch: 11 | loss: 0.1012784\n",
      "\tspeed: 0.0277s/iter; left time: 547.8852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0988616 Vali Loss: 0.1163812 Test Loss: 0.1246876\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0938694\n",
      "\tspeed: 0.0556s/iter; left time: 1093.0149s\n",
      "\titers: 200, epoch: 12 | loss: 0.1003336\n",
      "\tspeed: 0.0277s/iter; left time: 542.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0984998 Vali Loss: 0.1159598 Test Loss: 0.1247678\n",
      "Validation loss decreased (0.116191 --> 0.115960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1008254\n",
      "\tspeed: 0.0560s/iter; left time: 1088.9887s\n",
      "\titers: 200, epoch: 13 | loss: 0.0954685\n",
      "\tspeed: 0.0282s/iter; left time: 544.4745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0980707 Vali Loss: 0.1159985 Test Loss: 0.1243998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0997873\n",
      "\tspeed: 0.0558s/iter; left time: 1071.5033s\n",
      "\titers: 200, epoch: 14 | loss: 0.0970589\n",
      "\tspeed: 0.0277s/iter; left time: 529.5526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0978463 Vali Loss: 0.1161223 Test Loss: 0.1245773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0935097\n",
      "\tspeed: 0.0550s/iter; left time: 1045.5519s\n",
      "\titers: 200, epoch: 15 | loss: 0.1009847\n",
      "\tspeed: 0.0277s/iter; left time: 524.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0974911 Vali Loss: 0.1158599 Test Loss: 0.1246603\n",
      "Validation loss decreased (0.115960 --> 0.115860).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0946110\n",
      "\tspeed: 0.0554s/iter; left time: 1040.2136s\n",
      "\titers: 200, epoch: 16 | loss: 0.0943336\n",
      "\tspeed: 0.0277s/iter; left time: 517.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0972688 Vali Loss: 0.1159991 Test Loss: 0.1243012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0988798\n",
      "\tspeed: 0.0555s/iter; left time: 1030.3171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0996477\n",
      "\tspeed: 0.0277s/iter; left time: 510.7133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0970698 Vali Loss: 0.1159112 Test Loss: 0.1242256\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0945986\n",
      "\tspeed: 0.0562s/iter; left time: 1029.3013s\n",
      "\titers: 200, epoch: 18 | loss: 0.0968164\n",
      "\tspeed: 0.0277s/iter; left time: 505.0981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0968700 Vali Loss: 0.1162891 Test Loss: 0.1249378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0976604\n",
      "\tspeed: 0.0554s/iter; left time: 1003.4992s\n",
      "\titers: 200, epoch: 19 | loss: 0.0990758\n",
      "\tspeed: 0.0277s/iter; left time: 498.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0966695 Vali Loss: 0.1159711 Test Loss: 0.1243086\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0954628\n",
      "\tspeed: 0.0555s/iter; left time: 992.1393s\n",
      "\titers: 200, epoch: 20 | loss: 0.0955926\n",
      "\tspeed: 0.0279s/iter; left time: 495.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0964811 Vali Loss: 0.1162587 Test Loss: 0.1244755\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0931929\n",
      "\tspeed: 0.0557s/iter; left time: 983.2556s\n",
      "\titers: 200, epoch: 21 | loss: 0.0989608\n",
      "\tspeed: 0.0277s/iter; left time: 485.6935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0964273 Vali Loss: 0.1160783 Test Loss: 0.1244108\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0973845\n",
      "\tspeed: 0.0558s/iter; left time: 972.3483s\n",
      "\titers: 200, epoch: 22 | loss: 0.0939951\n",
      "\tspeed: 0.0277s/iter; left time: 480.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0962287 Vali Loss: 0.1161583 Test Loss: 0.1246323\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0943893\n",
      "\tspeed: 0.0558s/iter; left time: 961.2871s\n",
      "\titers: 200, epoch: 23 | loss: 0.0916504\n",
      "\tspeed: 0.0278s/iter; left time: 475.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0961257 Vali Loss: 0.1159300 Test Loss: 0.1242638\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1012308\n",
      "\tspeed: 0.0555s/iter; left time: 943.8590s\n",
      "\titers: 200, epoch: 24 | loss: 0.0963220\n",
      "\tspeed: 0.0278s/iter; left time: 469.9523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0959404 Vali Loss: 0.1160208 Test Loss: 0.1241548\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0981243\n",
      "\tspeed: 0.0557s/iter; left time: 933.7367s\n",
      "\titers: 200, epoch: 25 | loss: 0.0943939\n",
      "\tspeed: 0.0278s/iter; left time: 463.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0958715 Vali Loss: 0.1161850 Test Loss: 0.1245718\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.035689570009708405, rmse:0.18891683220863342, mae:0.12466028332710266, rse:0.6689926981925964\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:17.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1480220\n",
      "\tspeed: 0.0546s/iter; left time: 1205.9412s\n",
      "\titers: 200, epoch: 1 | loss: 0.1393373\n",
      "\tspeed: 0.0280s/iter; left time: 615.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.1516553 Vali Loss: 0.1415078 Test Loss: 0.1507657\n",
      "Validation loss decreased (inf --> 0.141508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1195863\n",
      "\tspeed: 0.0566s/iter; left time: 1238.7066s\n",
      "\titers: 200, epoch: 2 | loss: 0.1153403\n",
      "\tspeed: 0.0280s/iter; left time: 608.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1196029 Vali Loss: 0.1256738 Test Loss: 0.1345409\n",
      "Validation loss decreased (0.141508 --> 0.125674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1137367\n",
      "\tspeed: 0.0565s/iter; left time: 1223.7197s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142617\n",
      "\tspeed: 0.0280s/iter; left time: 604.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1119885 Vali Loss: 0.1233889 Test Loss: 0.1328375\n",
      "Validation loss decreased (0.125674 --> 0.123389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1080929\n",
      "\tspeed: 0.0579s/iter; left time: 1241.6169s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128098\n",
      "\tspeed: 0.0281s/iter; left time: 598.4859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1099012 Vali Loss: 0.1226364 Test Loss: 0.1320891\n",
      "Validation loss decreased (0.123389 --> 0.122636).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1112633\n",
      "\tspeed: 0.0570s/iter; left time: 1208.7133s\n",
      "\titers: 200, epoch: 5 | loss: 0.1099532\n",
      "\tspeed: 0.0281s/iter; left time: 593.2476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1084957 Vali Loss: 0.1216478 Test Loss: 0.1317766\n",
      "Validation loss decreased (0.122636 --> 0.121648).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1094956\n",
      "\tspeed: 0.0572s/iter; left time: 1200.4391s\n",
      "\titers: 200, epoch: 6 | loss: 0.1095484\n",
      "\tspeed: 0.0279s/iter; left time: 583.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1073033 Vali Loss: 0.1209301 Test Loss: 0.1318667\n",
      "Validation loss decreased (0.121648 --> 0.120930).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1068038\n",
      "\tspeed: 0.0564s/iter; left time: 1170.5136s\n",
      "\titers: 200, epoch: 7 | loss: 0.1049403\n",
      "\tspeed: 0.0282s/iter; left time: 582.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1063503 Vali Loss: 0.1206215 Test Loss: 0.1318367\n",
      "Validation loss decreased (0.120930 --> 0.120622).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023208\n",
      "\tspeed: 0.0563s/iter; left time: 1157.2049s\n",
      "\titers: 200, epoch: 8 | loss: 0.1052910\n",
      "\tspeed: 0.0280s/iter; left time: 571.5149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1056386 Vali Loss: 0.1204815 Test Loss: 0.1321248\n",
      "Validation loss decreased (0.120622 --> 0.120482).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1054432\n",
      "\tspeed: 0.0562s/iter; left time: 1142.1836s\n",
      "\titers: 200, epoch: 9 | loss: 0.1036015\n",
      "\tspeed: 0.0280s/iter; left time: 566.1554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1050095 Vali Loss: 0.1200156 Test Loss: 0.1312271\n",
      "Validation loss decreased (0.120482 --> 0.120016).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1063284\n",
      "\tspeed: 0.0564s/iter; left time: 1133.4714s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046131\n",
      "\tspeed: 0.0280s/iter; left time: 560.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1044801 Vali Loss: 0.1200360 Test Loss: 0.1321850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1066574\n",
      "\tspeed: 0.0558s/iter; left time: 1110.0976s\n",
      "\titers: 200, epoch: 11 | loss: 0.1039348\n",
      "\tspeed: 0.0280s/iter; left time: 553.9395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1040509 Vali Loss: 0.1199340 Test Loss: 0.1317887\n",
      "Validation loss decreased (0.120016 --> 0.119934).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008396\n",
      "\tspeed: 0.0563s/iter; left time: 1106.7997s\n",
      "\titers: 200, epoch: 12 | loss: 0.1049676\n",
      "\tspeed: 0.0281s/iter; left time: 549.1056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1036242 Vali Loss: 0.1199903 Test Loss: 0.1321659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016561\n",
      "\tspeed: 0.0562s/iter; left time: 1091.8265s\n",
      "\titers: 200, epoch: 13 | loss: 0.1035263\n",
      "\tspeed: 0.0281s/iter; left time: 542.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1032311 Vali Loss: 0.1200884 Test Loss: 0.1315788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1032759\n",
      "\tspeed: 0.0556s/iter; left time: 1068.1139s\n",
      "\titers: 200, epoch: 14 | loss: 0.1046192\n",
      "\tspeed: 0.0280s/iter; left time: 534.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1029024 Vali Loss: 0.1199578 Test Loss: 0.1322332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1022594\n",
      "\tspeed: 0.0556s/iter; left time: 1056.8097s\n",
      "\titers: 200, epoch: 15 | loss: 0.1020416\n",
      "\tspeed: 0.0281s/iter; left time: 530.9822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1025592 Vali Loss: 0.1199660 Test Loss: 0.1321799\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1035744\n",
      "\tspeed: 0.0558s/iter; left time: 1048.0362s\n",
      "\titers: 200, epoch: 16 | loss: 0.1043096\n",
      "\tspeed: 0.0279s/iter; left time: 521.2901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1023491 Vali Loss: 0.1197689 Test Loss: 0.1321448\n",
      "Validation loss decreased (0.119934 --> 0.119769).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1076264\n",
      "\tspeed: 0.0564s/iter; left time: 1045.8063s\n",
      "\titers: 200, epoch: 17 | loss: 0.1032241\n",
      "\tspeed: 0.0279s/iter; left time: 515.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1020695 Vali Loss: 0.1199339 Test Loss: 0.1323298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0992077\n",
      "\tspeed: 0.0562s/iter; left time: 1029.9163s\n",
      "\titers: 200, epoch: 18 | loss: 0.1066426\n",
      "\tspeed: 0.0280s/iter; left time: 510.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1018769 Vali Loss: 0.1201867 Test Loss: 0.1321113\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1030198\n",
      "\tspeed: 0.0556s/iter; left time: 1006.4722s\n",
      "\titers: 200, epoch: 19 | loss: 0.1033373\n",
      "\tspeed: 0.0281s/iter; left time: 505.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1017276 Vali Loss: 0.1200730 Test Loss: 0.1319721\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1004092\n",
      "\tspeed: 0.0571s/iter; left time: 1020.2699s\n",
      "\titers: 200, epoch: 20 | loss: 0.0962599\n",
      "\tspeed: 0.0280s/iter; left time: 497.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.1014926 Vali Loss: 0.1202604 Test Loss: 0.1323757\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0966609\n",
      "\tspeed: 0.0564s/iter; left time: 996.3928s\n",
      "\titers: 200, epoch: 21 | loss: 0.1010498\n",
      "\tspeed: 0.0281s/iter; left time: 492.7736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.1013291 Vali Loss: 0.1201521 Test Loss: 0.1323243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0969337\n",
      "\tspeed: 0.0556s/iter; left time: 969.8971s\n",
      "\titers: 200, epoch: 22 | loss: 0.1029822\n",
      "\tspeed: 0.0280s/iter; left time: 485.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1011988 Vali Loss: 0.1200047 Test Loss: 0.1321865\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0988439\n",
      "\tspeed: 0.0555s/iter; left time: 956.1339s\n",
      "\titers: 200, epoch: 23 | loss: 0.1009730\n",
      "\tspeed: 0.0279s/iter; left time: 477.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1010313 Vali Loss: 0.1202459 Test Loss: 0.1324827\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0974094\n",
      "\tspeed: 0.0551s/iter; left time: 935.9834s\n",
      "\titers: 200, epoch: 24 | loss: 0.1024806\n",
      "\tspeed: 0.0279s/iter; left time: 471.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1009681 Vali Loss: 0.1200090 Test Loss: 0.1326567\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1016544\n",
      "\tspeed: 0.0560s/iter; left time: 939.8211s\n",
      "\titers: 200, epoch: 25 | loss: 0.1056893\n",
      "\tspeed: 0.0278s/iter; left time: 464.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1008437 Vali Loss: 0.1200563 Test Loss: 0.1323705\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1011046\n",
      "\tspeed: 0.0569s/iter; left time: 941.2787s\n",
      "\titers: 200, epoch: 26 | loss: 0.0996052\n",
      "\tspeed: 0.0280s/iter; left time: 460.0078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1007666 Vali Loss: 0.1201455 Test Loss: 0.1325531\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03847430273890495, rmse:0.19614867866039276, mae:0.13214491307735443, rse:0.6947743892669678\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1523425\n",
      "\tspeed: 0.0302s/iter; left time: 667.4071s\n",
      "\titers: 200, epoch: 1 | loss: 0.1342569\n",
      "\tspeed: 0.0279s/iter; left time: 614.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1508746 Vali Loss: 0.1406786 Test Loss: 0.1499086\n",
      "Validation loss decreased (inf --> 0.140679).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1172043\n",
      "\tspeed: 0.0576s/iter; left time: 1260.1131s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148622\n",
      "\tspeed: 0.0280s/iter; left time: 609.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1191878 Vali Loss: 0.1256592 Test Loss: 0.1349177\n",
      "Validation loss decreased (0.140679 --> 0.125659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1124872\n",
      "\tspeed: 0.0582s/iter; left time: 1260.3018s\n",
      "\titers: 200, epoch: 3 | loss: 0.1080386\n",
      "\tspeed: 0.0279s/iter; left time: 602.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1118740 Vali Loss: 0.1235449 Test Loss: 0.1330403\n",
      "Validation loss decreased (0.125659 --> 0.123545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068941\n",
      "\tspeed: 0.0583s/iter; left time: 1248.9345s\n",
      "\titers: 200, epoch: 4 | loss: 0.1034974\n",
      "\tspeed: 0.0280s/iter; left time: 597.9408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1099263 Vali Loss: 0.1222351 Test Loss: 0.1321633\n",
      "Validation loss decreased (0.123545 --> 0.122235).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1101589\n",
      "\tspeed: 0.0577s/iter; left time: 1224.2603s\n",
      "\titers: 200, epoch: 5 | loss: 0.1062033\n",
      "\tspeed: 0.0280s/iter; left time: 591.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1086780 Vali Loss: 0.1218831 Test Loss: 0.1314891\n",
      "Validation loss decreased (0.122235 --> 0.121883).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1102117\n",
      "\tspeed: 0.0571s/iter; left time: 1198.3154s\n",
      "\titers: 200, epoch: 6 | loss: 0.1083656\n",
      "\tspeed: 0.0281s/iter; left time: 587.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.1077483 Vali Loss: 0.1218067 Test Loss: 0.1324826\n",
      "Validation loss decreased (0.121883 --> 0.121807).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1104413\n",
      "\tspeed: 0.0573s/iter; left time: 1190.3860s\n",
      "\titers: 200, epoch: 7 | loss: 0.1029781\n",
      "\tspeed: 0.0280s/iter; left time: 578.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1070370 Vali Loss: 0.1211006 Test Loss: 0.1321228\n",
      "Validation loss decreased (0.121807 --> 0.121101).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1028888\n",
      "\tspeed: 0.0572s/iter; left time: 1174.8010s\n",
      "\titers: 200, epoch: 8 | loss: 0.1064227\n",
      "\tspeed: 0.0280s/iter; left time: 572.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1063281 Vali Loss: 0.1205455 Test Loss: 0.1317590\n",
      "Validation loss decreased (0.121101 --> 0.120546).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1090608\n",
      "\tspeed: 0.0563s/iter; left time: 1144.4605s\n",
      "\titers: 200, epoch: 9 | loss: 0.1029782\n",
      "\tspeed: 0.0280s/iter; left time: 566.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1057450 Vali Loss: 0.1201432 Test Loss: 0.1313811\n",
      "Validation loss decreased (0.120546 --> 0.120143).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1025040\n",
      "\tspeed: 0.0573s/iter; left time: 1152.1630s\n",
      "\titers: 200, epoch: 10 | loss: 0.1021822\n",
      "\tspeed: 0.0280s/iter; left time: 559.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1051708 Vali Loss: 0.1205720 Test Loss: 0.1323366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1059138\n",
      "\tspeed: 0.0566s/iter; left time: 1126.2388s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048243\n",
      "\tspeed: 0.0280s/iter; left time: 553.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.1047510 Vali Loss: 0.1203798 Test Loss: 0.1318815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1029848\n",
      "\tspeed: 0.0561s/iter; left time: 1102.7881s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028544\n",
      "\tspeed: 0.0280s/iter; left time: 546.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1042878 Vali Loss: 0.1205960 Test Loss: 0.1326547\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1007241\n",
      "\tspeed: 0.0564s/iter; left time: 1097.1091s\n",
      "\titers: 200, epoch: 13 | loss: 0.1065909\n",
      "\tspeed: 0.0280s/iter; left time: 540.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1039224 Vali Loss: 0.1201670 Test Loss: 0.1326820\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1003817\n",
      "\tspeed: 0.0571s/iter; left time: 1096.8954s\n",
      "\titers: 200, epoch: 14 | loss: 0.1022922\n",
      "\tspeed: 0.0280s/iter; left time: 535.1793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.1035619 Vali Loss: 0.1200690 Test Loss: 0.1324921\n",
      "Validation loss decreased (0.120143 --> 0.120069).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1033663\n",
      "\tspeed: 0.0581s/iter; left time: 1103.7004s\n",
      "\titers: 200, epoch: 15 | loss: 0.1054965\n",
      "\tspeed: 0.0280s/iter; left time: 528.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.1032120 Vali Loss: 0.1195879 Test Loss: 0.1323589\n",
      "Validation loss decreased (0.120069 --> 0.119588).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1007466\n",
      "\tspeed: 0.0574s/iter; left time: 1078.1770s\n",
      "\titers: 200, epoch: 16 | loss: 0.1019763\n",
      "\tspeed: 0.0280s/iter; left time: 522.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1029593 Vali Loss: 0.1200155 Test Loss: 0.1323413\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0975646\n",
      "\tspeed: 0.0561s/iter; left time: 1039.8467s\n",
      "\titers: 200, epoch: 17 | loss: 0.0999924\n",
      "\tspeed: 0.0280s/iter; left time: 516.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1026376 Vali Loss: 0.1200417 Test Loss: 0.1322282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0962463\n",
      "\tspeed: 0.0566s/iter; left time: 1038.0106s\n",
      "\titers: 200, epoch: 18 | loss: 0.1073761\n",
      "\tspeed: 0.0279s/iter; left time: 509.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1024065 Vali Loss: 0.1198415 Test Loss: 0.1322177\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0982725\n",
      "\tspeed: 0.0561s/iter; left time: 1015.8753s\n",
      "\titers: 200, epoch: 19 | loss: 0.0992184\n",
      "\tspeed: 0.0279s/iter; left time: 502.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1022311 Vali Loss: 0.1200744 Test Loss: 0.1323467\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1032869\n",
      "\tspeed: 0.0561s/iter; left time: 1003.4075s\n",
      "\titers: 200, epoch: 20 | loss: 0.0985212\n",
      "\tspeed: 0.0281s/iter; left time: 499.4128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.1019780 Vali Loss: 0.1201072 Test Loss: 0.1323747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1019522\n",
      "\tspeed: 0.0567s/iter; left time: 1001.2593s\n",
      "\titers: 200, epoch: 21 | loss: 0.1042993\n",
      "\tspeed: 0.0280s/iter; left time: 490.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1018176 Vali Loss: 0.1198804 Test Loss: 0.1326069\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0990084\n",
      "\tspeed: 0.0571s/iter; left time: 995.6840s\n",
      "\titers: 200, epoch: 22 | loss: 0.1005618\n",
      "\tspeed: 0.0280s/iter; left time: 485.1760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.1016806 Vali Loss: 0.1202719 Test Loss: 0.1325779\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1010377\n",
      "\tspeed: 0.0564s/iter; left time: 971.1495s\n",
      "\titers: 200, epoch: 23 | loss: 0.0972386\n",
      "\tspeed: 0.0280s/iter; left time: 478.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1014453 Vali Loss: 0.1200341 Test Loss: 0.1322815\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1031217\n",
      "\tspeed: 0.0559s/iter; left time: 949.6029s\n",
      "\titers: 200, epoch: 24 | loss: 0.1039861\n",
      "\tspeed: 0.0280s/iter; left time: 472.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1013959 Vali Loss: 0.1201200 Test Loss: 0.1327659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1001187\n",
      "\tspeed: 0.0561s/iter; left time: 941.2888s\n",
      "\titers: 200, epoch: 25 | loss: 0.0993303\n",
      "\tspeed: 0.0279s/iter; left time: 465.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1012128 Vali Loss: 0.1202189 Test Loss: 0.1325312\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038423992693424225, rmse:0.19602039456367493, mae:0.13235895335674286, rse:0.6943199634552002\n",
      "Intermediate time for DE and pred_len 168: 00h:07m:25.04s\n",
      "Intermediate time for DE: 00h:25m:22.83s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1309941\n",
      "\tspeed: 0.0529s/iter; left time: 1174.3279s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171876\n",
      "\tspeed: 0.0275s/iter; left time: 606.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 223 | Train Loss: 0.1311860 Vali Loss: 0.1247457 Test Loss: 0.1464349\n",
      "Validation loss decreased (inf --> 0.124746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0816034\n",
      "\tspeed: 0.0538s/iter; left time: 1182.4630s\n",
      "\titers: 200, epoch: 2 | loss: 0.0815799\n",
      "\tspeed: 0.0283s/iter; left time: 618.7976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0871402 Vali Loss: 0.0910752 Test Loss: 0.1034212\n",
      "Validation loss decreased (0.124746 --> 0.091075).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825083\n",
      "\tspeed: 0.0543s/iter; left time: 1181.2580s\n",
      "\titers: 200, epoch: 3 | loss: 0.0752306\n",
      "\tspeed: 0.0274s/iter; left time: 593.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0794966 Vali Loss: 0.0905501 Test Loss: 0.1018069\n",
      "Validation loss decreased (0.091075 --> 0.090550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0738629\n",
      "\tspeed: 0.0538s/iter; left time: 1158.8839s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809827\n",
      "\tspeed: 0.0274s/iter; left time: 587.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0780704 Vali Loss: 0.0896828 Test Loss: 0.1027374\n",
      "Validation loss decreased (0.090550 --> 0.089683).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773610\n",
      "\tspeed: 0.0538s/iter; left time: 1145.6954s\n",
      "\titers: 200, epoch: 5 | loss: 0.0711381\n",
      "\tspeed: 0.0274s/iter; left time: 581.7817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0769836 Vali Loss: 0.0898154 Test Loss: 0.1022240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814983\n",
      "\tspeed: 0.0531s/iter; left time: 1119.7317s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739402\n",
      "\tspeed: 0.0274s/iter; left time: 575.7556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0762243 Vali Loss: 0.0888775 Test Loss: 0.1012101\n",
      "Validation loss decreased (0.089683 --> 0.088878).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769496\n",
      "\tspeed: 0.0536s/iter; left time: 1118.6733s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761454\n",
      "\tspeed: 0.0274s/iter; left time: 569.3690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0755959 Vali Loss: 0.0887783 Test Loss: 0.1006353\n",
      "Validation loss decreased (0.088878 --> 0.088778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0769426\n",
      "\tspeed: 0.0539s/iter; left time: 1112.4229s\n",
      "\titers: 200, epoch: 8 | loss: 0.0777145\n",
      "\tspeed: 0.0274s/iter; left time: 563.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0751390 Vali Loss: 0.0885936 Test Loss: 0.1004058\n",
      "Validation loss decreased (0.088778 --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0757621\n",
      "\tspeed: 0.0536s/iter; left time: 1093.9226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0736766\n",
      "\tspeed: 0.0273s/iter; left time: 555.1881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0747695 Vali Loss: 0.0880487 Test Loss: 0.1004148\n",
      "Validation loss decreased (0.088594 --> 0.088049).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799202\n",
      "\tspeed: 0.0541s/iter; left time: 1092.7404s\n",
      "\titers: 200, epoch: 10 | loss: 0.0780373\n",
      "\tspeed: 0.0277s/iter; left time: 556.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0743807 Vali Loss: 0.0877937 Test Loss: 0.1000286\n",
      "Validation loss decreased (0.088049 --> 0.087794).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736421\n",
      "\tspeed: 0.0535s/iter; left time: 1068.1153s\n",
      "\titers: 200, epoch: 11 | loss: 0.0757832\n",
      "\tspeed: 0.0275s/iter; left time: 546.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0741117 Vali Loss: 0.0875779 Test Loss: 0.1002189\n",
      "Validation loss decreased (0.087794 --> 0.087578).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778826\n",
      "\tspeed: 0.0543s/iter; left time: 1072.4841s\n",
      "\titers: 200, epoch: 12 | loss: 0.0755589\n",
      "\tspeed: 0.0274s/iter; left time: 537.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0738969 Vali Loss: 0.0876164 Test Loss: 0.0999753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0750620\n",
      "\tspeed: 0.0536s/iter; left time: 1046.8113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0773834\n",
      "\tspeed: 0.0273s/iter; left time: 530.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0736983 Vali Loss: 0.0874996 Test Loss: 0.0993635\n",
      "Validation loss decreased (0.087578 --> 0.087500).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0708852\n",
      "\tspeed: 0.0538s/iter; left time: 1038.7737s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716029\n",
      "\tspeed: 0.0274s/iter; left time: 526.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0735105 Vali Loss: 0.0873187 Test Loss: 0.0996633\n",
      "Validation loss decreased (0.087500 --> 0.087319).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713399\n",
      "\tspeed: 0.0538s/iter; left time: 1027.1669s\n",
      "\titers: 200, epoch: 15 | loss: 0.0778721\n",
      "\tspeed: 0.0273s/iter; left time: 519.0732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0733524 Vali Loss: 0.0871135 Test Loss: 0.0996814\n",
      "Validation loss decreased (0.087319 --> 0.087114).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0687655\n",
      "\tspeed: 0.0536s/iter; left time: 1011.0060s\n",
      "\titers: 200, epoch: 16 | loss: 0.0719672\n",
      "\tspeed: 0.0274s/iter; left time: 513.4583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0732006 Vali Loss: 0.0871004 Test Loss: 0.0994064\n",
      "Validation loss decreased (0.087114 --> 0.087100).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0720945\n",
      "\tspeed: 0.0537s/iter; left time: 1001.3329s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759879\n",
      "\tspeed: 0.0273s/iter; left time: 506.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0730925 Vali Loss: 0.0871474 Test Loss: 0.0991593\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0691575\n",
      "\tspeed: 0.0544s/iter; left time: 1001.5756s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700986\n",
      "\tspeed: 0.0275s/iter; left time: 503.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0729248 Vali Loss: 0.0871558 Test Loss: 0.0991535\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775585\n",
      "\tspeed: 0.0534s/iter; left time: 970.2777s\n",
      "\titers: 200, epoch: 19 | loss: 0.0703488\n",
      "\tspeed: 0.0274s/iter; left time: 496.4270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0728934 Vali Loss: 0.0870261 Test Loss: 0.0994280\n",
      "Validation loss decreased (0.087100 --> 0.087026).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0745199\n",
      "\tspeed: 0.0535s/iter; left time: 961.2728s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774186\n",
      "\tspeed: 0.0274s/iter; left time: 488.9315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0727917 Vali Loss: 0.0870352 Test Loss: 0.0992547\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0714403\n",
      "\tspeed: 0.0537s/iter; left time: 951.9941s\n",
      "\titers: 200, epoch: 21 | loss: 0.0727665\n",
      "\tspeed: 0.0274s/iter; left time: 484.1093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0726971 Vali Loss: 0.0870782 Test Loss: 0.0993801\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0696317\n",
      "\tspeed: 0.0533s/iter; left time: 934.0357s\n",
      "\titers: 200, epoch: 22 | loss: 0.0731587\n",
      "\tspeed: 0.0274s/iter; left time: 476.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0725566 Vali Loss: 0.0868771 Test Loss: 0.0993815\n",
      "Validation loss decreased (0.087026 --> 0.086877).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0686894\n",
      "\tspeed: 0.0537s/iter; left time: 929.4167s\n",
      "\titers: 200, epoch: 23 | loss: 0.0734855\n",
      "\tspeed: 0.0274s/iter; left time: 471.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0725656 Vali Loss: 0.0870143 Test Loss: 0.0991844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0720081\n",
      "\tspeed: 0.0534s/iter; left time: 911.0545s\n",
      "\titers: 200, epoch: 24 | loss: 0.0727767\n",
      "\tspeed: 0.0274s/iter; left time: 464.9034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0724960 Vali Loss: 0.0869442 Test Loss: 0.0993392\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0764914\n",
      "\tspeed: 0.0538s/iter; left time: 906.3459s\n",
      "\titers: 200, epoch: 25 | loss: 0.0761137\n",
      "\tspeed: 0.0274s/iter; left time: 459.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0724510 Vali Loss: 0.0869138 Test Loss: 0.0991062\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0760863\n",
      "\tspeed: 0.0534s/iter; left time: 888.5465s\n",
      "\titers: 200, epoch: 26 | loss: 0.0745971\n",
      "\tspeed: 0.0273s/iter; left time: 451.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0724212 Vali Loss: 0.0869428 Test Loss: 0.0991838\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0698398\n",
      "\tspeed: 0.0537s/iter; left time: 880.7959s\n",
      "\titers: 200, epoch: 27 | loss: 0.0729912\n",
      "\tspeed: 0.0274s/iter; left time: 446.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0723420 Vali Loss: 0.0869109 Test Loss: 0.0991179\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0741425\n",
      "\tspeed: 0.0529s/iter; left time: 856.1144s\n",
      "\titers: 200, epoch: 28 | loss: 0.0705790\n",
      "\tspeed: 0.0275s/iter; left time: 441.5051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0723184 Vali Loss: 0.0869706 Test Loss: 0.0990583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0703126\n",
      "\tspeed: 0.0537s/iter; left time: 856.8972s\n",
      "\titers: 200, epoch: 29 | loss: 0.0719176\n",
      "\tspeed: 0.0275s/iter; left time: 435.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0722554 Vali Loss: 0.0867944 Test Loss: 0.0990957\n",
      "Validation loss decreased (0.086877 --> 0.086794).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0727249\n",
      "\tspeed: 0.0536s/iter; left time: 843.1402s\n",
      "\titers: 200, epoch: 30 | loss: 0.0707365\n",
      "\tspeed: 0.0274s/iter; left time: 428.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0722727 Vali Loss: 0.0869849 Test Loss: 0.0990697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0711395\n",
      "\tspeed: 0.0535s/iter; left time: 829.0888s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757641\n",
      "\tspeed: 0.0273s/iter; left time: 420.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0722053 Vali Loss: 0.0868477 Test Loss: 0.0991189\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0735539\n",
      "\tspeed: 0.0533s/iter; left time: 814.8540s\n",
      "\titers: 200, epoch: 32 | loss: 0.0710700\n",
      "\tspeed: 0.0279s/iter; left time: 423.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0721681 Vali Loss: 0.0867283 Test Loss: 0.0990592\n",
      "Validation loss decreased (0.086794 --> 0.086728).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0739090\n",
      "\tspeed: 0.0542s/iter; left time: 817.2665s\n",
      "\titers: 200, epoch: 33 | loss: 0.0682071\n",
      "\tspeed: 0.0274s/iter; left time: 409.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0721622 Vali Loss: 0.0869020 Test Loss: 0.0991398\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0722358\n",
      "\tspeed: 0.0535s/iter; left time: 793.7076s\n",
      "\titers: 200, epoch: 34 | loss: 0.0758414\n",
      "\tspeed: 0.0272s/iter; left time: 401.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0721147 Vali Loss: 0.0867610 Test Loss: 0.0991589\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0744621\n",
      "\tspeed: 0.0530s/iter; left time: 775.1081s\n",
      "\titers: 200, epoch: 35 | loss: 0.0691639\n",
      "\tspeed: 0.0273s/iter; left time: 396.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0721121 Vali Loss: 0.0868527 Test Loss: 0.0990702\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686463\n",
      "\tspeed: 0.0537s/iter; left time: 772.4960s\n",
      "\titers: 200, epoch: 36 | loss: 0.0712055\n",
      "\tspeed: 0.0274s/iter; left time: 391.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0721071 Vali Loss: 0.0869381 Test Loss: 0.0990447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0710986\n",
      "\tspeed: 0.0532s/iter; left time: 753.5752s\n",
      "\titers: 200, epoch: 37 | loss: 0.0746401\n",
      "\tspeed: 0.0275s/iter; left time: 386.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0720684 Vali Loss: 0.0868554 Test Loss: 0.0990848\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0720197\n",
      "\tspeed: 0.0534s/iter; left time: 745.1184s\n",
      "\titers: 200, epoch: 38 | loss: 0.0723542\n",
      "\tspeed: 0.0275s/iter; left time: 380.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0720791 Vali Loss: 0.0867166 Test Loss: 0.0990559\n",
      "Validation loss decreased (0.086728 --> 0.086717).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0721339\n",
      "\tspeed: 0.0548s/iter; left time: 751.6512s\n",
      "\titers: 200, epoch: 39 | loss: 0.0735621\n",
      "\tspeed: 0.0275s/iter; left time: 374.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0720901 Vali Loss: 0.0868566 Test Loss: 0.0990409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0736422\n",
      "\tspeed: 0.0545s/iter; left time: 736.5994s\n",
      "\titers: 200, epoch: 40 | loss: 0.0735413\n",
      "\tspeed: 0.0274s/iter; left time: 367.2557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0720341 Vali Loss: 0.0867758 Test Loss: 0.0991125\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0730390\n",
      "\tspeed: 0.0534s/iter; left time: 708.7950s\n",
      "\titers: 200, epoch: 41 | loss: 0.0712292\n",
      "\tspeed: 0.0274s/iter; left time: 360.7859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0720382 Vali Loss: 0.0868360 Test Loss: 0.0990113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0765831\n",
      "\tspeed: 0.0535s/iter; left time: 698.6037s\n",
      "\titers: 200, epoch: 42 | loss: 0.0702229\n",
      "\tspeed: 0.0274s/iter; left time: 354.8046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0720299 Vali Loss: 0.0868494 Test Loss: 0.0990290\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0714861\n",
      "\tspeed: 0.0534s/iter; left time: 684.9771s\n",
      "\titers: 200, epoch: 43 | loss: 0.0757662\n",
      "\tspeed: 0.0274s/iter; left time: 348.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0719966 Vali Loss: 0.0867837 Test Loss: 0.0990338\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0725786\n",
      "\tspeed: 0.0537s/iter; left time: 676.8602s\n",
      "\titers: 200, epoch: 44 | loss: 0.0782682\n",
      "\tspeed: 0.0274s/iter; left time: 343.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0720422 Vali Loss: 0.0869320 Test Loss: 0.0990215\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0807863\n",
      "\tspeed: 0.0541s/iter; left time: 670.4121s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766727\n",
      "\tspeed: 0.0273s/iter; left time: 336.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0719756 Vali Loss: 0.0867029 Test Loss: 0.0990529\n",
      "Validation loss decreased (0.086717 --> 0.086703).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0725876\n",
      "\tspeed: 0.0534s/iter; left time: 649.8379s\n",
      "\titers: 200, epoch: 46 | loss: 0.0768504\n",
      "\tspeed: 0.0274s/iter; left time: 330.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0720612 Vali Loss: 0.0867418 Test Loss: 0.0990579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0728662\n",
      "\tspeed: 0.0539s/iter; left time: 643.3562s\n",
      "\titers: 200, epoch: 47 | loss: 0.0782241\n",
      "\tspeed: 0.0277s/iter; left time: 327.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0720235 Vali Loss: 0.0868377 Test Loss: 0.0990386\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0693394\n",
      "\tspeed: 0.0536s/iter; left time: 628.4600s\n",
      "\titers: 200, epoch: 48 | loss: 0.0667867\n",
      "\tspeed: 0.0275s/iter; left time: 319.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0719658 Vali Loss: 0.0868148 Test Loss: 0.0990175\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0766490\n",
      "\tspeed: 0.0536s/iter; left time: 615.9011s\n",
      "\titers: 200, epoch: 49 | loss: 0.0684964\n",
      "\tspeed: 0.0274s/iter; left time: 312.6144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0720541 Vali Loss: 0.0867527 Test Loss: 0.0990708\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0720386\n",
      "\tspeed: 0.0533s/iter; left time: 601.4114s\n",
      "\titers: 200, epoch: 50 | loss: 0.0691606\n",
      "\tspeed: 0.0274s/iter; left time: 306.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0719735 Vali Loss: 0.0868239 Test Loss: 0.0990330\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0719138\n",
      "\tspeed: 0.0534s/iter; left time: 590.2806s\n",
      "\titers: 200, epoch: 51 | loss: 0.0760764\n",
      "\tspeed: 0.0274s/iter; left time: 300.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0719444 Vali Loss: 0.0867566 Test Loss: 0.0990110\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0642662\n",
      "\tspeed: 0.0536s/iter; left time: 580.0526s\n",
      "\titers: 200, epoch: 52 | loss: 0.0678484\n",
      "\tspeed: 0.0274s/iter; left time: 294.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0719686 Vali Loss: 0.0867558 Test Loss: 0.0990356\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0777483\n",
      "\tspeed: 0.0535s/iter; left time: 567.2365s\n",
      "\titers: 200, epoch: 53 | loss: 0.0655660\n",
      "\tspeed: 0.0273s/iter; left time: 287.0821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0719899 Vali Loss: 0.0867343 Test Loss: 0.0990459\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0719759\n",
      "\tspeed: 0.0537s/iter; left time: 557.2880s\n",
      "\titers: 200, epoch: 54 | loss: 0.0741493\n",
      "\tspeed: 0.0274s/iter; left time: 281.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0719883 Vali Loss: 0.0868094 Test Loss: 0.0990347\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0739030\n",
      "\tspeed: 0.0546s/iter; left time: 554.3523s\n",
      "\titers: 200, epoch: 55 | loss: 0.0701330\n",
      "\tspeed: 0.0274s/iter; left time: 275.6556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0720027 Vali Loss: 0.0868540 Test Loss: 0.0990256\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02455294132232666, rmse:0.15669378638267517, mae:0.09905292838811874, rse:0.5405491590499878\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1326493\n",
      "\tspeed: 0.0295s/iter; left time: 654.6152s\n",
      "\titers: 200, epoch: 1 | loss: 0.1200074\n",
      "\tspeed: 0.0274s/iter; left time: 605.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1323698 Vali Loss: 0.1252716 Test Loss: 0.1466190\n",
      "Validation loss decreased (inf --> 0.125272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0850775\n",
      "\tspeed: 0.0552s/iter; left time: 1212.6890s\n",
      "\titers: 200, epoch: 2 | loss: 0.0819438\n",
      "\tspeed: 0.0275s/iter; left time: 601.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0872868 Vali Loss: 0.0914871 Test Loss: 0.1033925\n",
      "Validation loss decreased (0.125272 --> 0.091487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754679\n",
      "\tspeed: 0.0552s/iter; left time: 1201.3322s\n",
      "\titers: 200, epoch: 3 | loss: 0.0768187\n",
      "\tspeed: 0.0275s/iter; left time: 594.8668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0795305 Vali Loss: 0.0904868 Test Loss: 0.1026524\n",
      "Validation loss decreased (0.091487 --> 0.090487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0768645\n",
      "\tspeed: 0.0547s/iter; left time: 1178.7668s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772880\n",
      "\tspeed: 0.0274s/iter; left time: 587.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0781246 Vali Loss: 0.0900738 Test Loss: 0.1023896\n",
      "Validation loss decreased (0.090487 --> 0.090074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0823580\n",
      "\tspeed: 0.0548s/iter; left time: 1168.4941s\n",
      "\titers: 200, epoch: 5 | loss: 0.0764529\n",
      "\tspeed: 0.0274s/iter; left time: 581.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0770865 Vali Loss: 0.0897425 Test Loss: 0.1013145\n",
      "Validation loss decreased (0.090074 --> 0.089743).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0707342\n",
      "\tspeed: 0.0549s/iter; left time: 1158.1020s\n",
      "\titers: 200, epoch: 6 | loss: 0.0784836\n",
      "\tspeed: 0.0275s/iter; left time: 577.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0764093 Vali Loss: 0.0891294 Test Loss: 0.1011342\n",
      "Validation loss decreased (0.089743 --> 0.089129).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772591\n",
      "\tspeed: 0.0562s/iter; left time: 1172.8302s\n",
      "\titers: 200, epoch: 7 | loss: 0.0807541\n",
      "\tspeed: 0.0274s/iter; left time: 569.2739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0756835 Vali Loss: 0.0887344 Test Loss: 0.1011224\n",
      "Validation loss decreased (0.089129 --> 0.088734).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0802612\n",
      "\tspeed: 0.0554s/iter; left time: 1143.3474s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776656\n",
      "\tspeed: 0.0274s/iter; left time: 562.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0752450 Vali Loss: 0.0884729 Test Loss: 0.1005936\n",
      "Validation loss decreased (0.088734 --> 0.088473).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774994\n",
      "\tspeed: 0.0573s/iter; left time: 1170.8837s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757322\n",
      "\tspeed: 0.0274s/iter; left time: 557.5639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0748448 Vali Loss: 0.0881102 Test Loss: 0.1003882\n",
      "Validation loss decreased (0.088473 --> 0.088110).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748589\n",
      "\tspeed: 0.0562s/iter; left time: 1134.2690s\n",
      "\titers: 200, epoch: 10 | loss: 0.0743278\n",
      "\tspeed: 0.0274s/iter; left time: 550.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0745427 Vali Loss: 0.0880075 Test Loss: 0.1003272\n",
      "Validation loss decreased (0.088110 --> 0.088007).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762924\n",
      "\tspeed: 0.0549s/iter; left time: 1096.9758s\n",
      "\titers: 200, epoch: 11 | loss: 0.0757078\n",
      "\tspeed: 0.0274s/iter; left time: 544.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0742399 Vali Loss: 0.0876354 Test Loss: 0.0998496\n",
      "Validation loss decreased (0.088007 --> 0.087635).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710022\n",
      "\tspeed: 0.0555s/iter; left time: 1095.9283s\n",
      "\titers: 200, epoch: 12 | loss: 0.0703789\n",
      "\tspeed: 0.0274s/iter; left time: 538.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0739917 Vali Loss: 0.0877495 Test Loss: 0.1002433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727424\n",
      "\tspeed: 0.0542s/iter; left time: 1058.6302s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790164\n",
      "\tspeed: 0.0276s/iter; left time: 536.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0738023 Vali Loss: 0.0874333 Test Loss: 0.0997272\n",
      "Validation loss decreased (0.087635 --> 0.087433).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738410\n",
      "\tspeed: 0.0559s/iter; left time: 1079.0838s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762605\n",
      "\tspeed: 0.0275s/iter; left time: 527.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0735593 Vali Loss: 0.0875690 Test Loss: 0.0997234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0799038\n",
      "\tspeed: 0.0545s/iter; left time: 1040.1306s\n",
      "\titers: 200, epoch: 15 | loss: 0.0738861\n",
      "\tspeed: 0.0274s/iter; left time: 520.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0734929 Vali Loss: 0.0872836 Test Loss: 0.0995043\n",
      "Validation loss decreased (0.087433 --> 0.087284).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715463\n",
      "\tspeed: 0.0553s/iter; left time: 1043.1697s\n",
      "\titers: 200, epoch: 16 | loss: 0.0777637\n",
      "\tspeed: 0.0274s/iter; left time: 514.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0733002 Vali Loss: 0.0872864 Test Loss: 0.0994915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754602\n",
      "\tspeed: 0.0547s/iter; left time: 1019.3666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0698130\n",
      "\tspeed: 0.0276s/iter; left time: 510.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0731618 Vali Loss: 0.0873302 Test Loss: 0.0994336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0701669\n",
      "\tspeed: 0.0546s/iter; left time: 1005.7485s\n",
      "\titers: 200, epoch: 18 | loss: 0.0774849\n",
      "\tspeed: 0.0276s/iter; left time: 505.3867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0730581 Vali Loss: 0.0873172 Test Loss: 0.0993486\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0700108\n",
      "\tspeed: 0.0549s/iter; left time: 998.4255s\n",
      "\titers: 200, epoch: 19 | loss: 0.0738471\n",
      "\tspeed: 0.0274s/iter; left time: 495.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0729616 Vali Loss: 0.0872928 Test Loss: 0.0992460\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0712361\n",
      "\tspeed: 0.0547s/iter; left time: 982.9204s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720378\n",
      "\tspeed: 0.0275s/iter; left time: 491.6142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0728522 Vali Loss: 0.0874014 Test Loss: 0.0995350\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0726300\n",
      "\tspeed: 0.0552s/iter; left time: 979.4907s\n",
      "\titers: 200, epoch: 21 | loss: 0.0719331\n",
      "\tspeed: 0.0277s/iter; left time: 489.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0728064 Vali Loss: 0.0871748 Test Loss: 0.0991150\n",
      "Validation loss decreased (0.087284 --> 0.087175).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0730615\n",
      "\tspeed: 0.0558s/iter; left time: 976.9743s\n",
      "\titers: 200, epoch: 22 | loss: 0.0731785\n",
      "\tspeed: 0.0274s/iter; left time: 476.7663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0727137 Vali Loss: 0.0872213 Test Loss: 0.0993991\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0794019\n",
      "\tspeed: 0.0549s/iter; left time: 948.9403s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753881\n",
      "\tspeed: 0.0278s/iter; left time: 478.5163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0726509 Vali Loss: 0.0871247 Test Loss: 0.0992309\n",
      "Validation loss decreased (0.087175 --> 0.087125).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0738947\n",
      "\tspeed: 0.0551s/iter; left time: 939.8516s\n",
      "\titers: 200, epoch: 24 | loss: 0.0688659\n",
      "\tspeed: 0.0274s/iter; left time: 465.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0726102 Vali Loss: 0.0869932 Test Loss: 0.0993247\n",
      "Validation loss decreased (0.087125 --> 0.086993).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0718051\n",
      "\tspeed: 0.0549s/iter; left time: 925.1054s\n",
      "\titers: 200, epoch: 25 | loss: 0.0680502\n",
      "\tspeed: 0.0274s/iter; left time: 459.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0725834 Vali Loss: 0.0871950 Test Loss: 0.0991744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0721880\n",
      "\tspeed: 0.0546s/iter; left time: 907.0940s\n",
      "\titers: 200, epoch: 26 | loss: 0.0721655\n",
      "\tspeed: 0.0274s/iter; left time: 452.8224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0724713 Vali Loss: 0.0870506 Test Loss: 0.0992005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0778404\n",
      "\tspeed: 0.0547s/iter; left time: 897.1234s\n",
      "\titers: 200, epoch: 27 | loss: 0.0697074\n",
      "\tspeed: 0.0276s/iter; left time: 449.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0724853 Vali Loss: 0.0871137 Test Loss: 0.0991393\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0730291\n",
      "\tspeed: 0.0544s/iter; left time: 880.9555s\n",
      "\titers: 200, epoch: 28 | loss: 0.0782640\n",
      "\tspeed: 0.0278s/iter; left time: 447.8068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0724615 Vali Loss: 0.0870807 Test Loss: 0.0991468\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0743251\n",
      "\tspeed: 0.0552s/iter; left time: 880.7017s\n",
      "\titers: 200, epoch: 29 | loss: 0.0652277\n",
      "\tspeed: 0.0275s/iter; left time: 436.0265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0724328 Vali Loss: 0.0870906 Test Loss: 0.0992440\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0751968\n",
      "\tspeed: 0.0550s/iter; left time: 866.0863s\n",
      "\titers: 200, epoch: 30 | loss: 0.0757616\n",
      "\tspeed: 0.0275s/iter; left time: 430.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0724047 Vali Loss: 0.0871188 Test Loss: 0.0992362\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0743669\n",
      "\tspeed: 0.0545s/iter; left time: 845.9753s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729432\n",
      "\tspeed: 0.0275s/iter; left time: 424.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0723841 Vali Loss: 0.0871432 Test Loss: 0.0990055\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0718038\n",
      "\tspeed: 0.0548s/iter; left time: 838.1177s\n",
      "\titers: 200, epoch: 32 | loss: 0.0692881\n",
      "\tspeed: 0.0275s/iter; left time: 417.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0723094 Vali Loss: 0.0870409 Test Loss: 0.0990783\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671424\n",
      "\tspeed: 0.0543s/iter; left time: 818.6815s\n",
      "\titers: 200, epoch: 33 | loss: 0.0697533\n",
      "\tspeed: 0.0274s/iter; left time: 410.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0722992 Vali Loss: 0.0870797 Test Loss: 0.0991078\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0744830\n",
      "\tspeed: 0.0546s/iter; left time: 810.1624s\n",
      "\titers: 200, epoch: 34 | loss: 0.0723428\n",
      "\tspeed: 0.0275s/iter; left time: 405.0089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0723344 Vali Loss: 0.0869751 Test Loss: 0.0990399\n",
      "Validation loss decreased (0.086993 --> 0.086975).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0713649\n",
      "\tspeed: 0.0558s/iter; left time: 816.3972s\n",
      "\titers: 200, epoch: 35 | loss: 0.0704165\n",
      "\tspeed: 0.0275s/iter; left time: 398.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0722748 Vali Loss: 0.0870526 Test Loss: 0.0990508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0723842\n",
      "\tspeed: 0.0557s/iter; left time: 801.3742s\n",
      "\titers: 200, epoch: 36 | loss: 0.0720524\n",
      "\tspeed: 0.0275s/iter; left time: 393.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0722845 Vali Loss: 0.0870406 Test Loss: 0.0990780\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0697426\n",
      "\tspeed: 0.0551s/iter; left time: 780.7510s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717373\n",
      "\tspeed: 0.0275s/iter; left time: 386.4166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0723062 Vali Loss: 0.0870231 Test Loss: 0.0991348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0671379\n",
      "\tspeed: 0.0546s/iter; left time: 761.6499s\n",
      "\titers: 200, epoch: 38 | loss: 0.0729962\n",
      "\tspeed: 0.0277s/iter; left time: 384.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0722581 Vali Loss: 0.0869522 Test Loss: 0.0990842\n",
      "Validation loss decreased (0.086975 --> 0.086952).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0681354\n",
      "\tspeed: 0.0558s/iter; left time: 766.3797s\n",
      "\titers: 200, epoch: 39 | loss: 0.0697607\n",
      "\tspeed: 0.0275s/iter; left time: 374.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0722092 Vali Loss: 0.0869388 Test Loss: 0.0990804\n",
      "Validation loss decreased (0.086952 --> 0.086939).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0724417\n",
      "\tspeed: 0.0553s/iter; left time: 746.9514s\n",
      "\titers: 200, epoch: 40 | loss: 0.0695194\n",
      "\tspeed: 0.0274s/iter; left time: 367.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0722335 Vali Loss: 0.0870770 Test Loss: 0.0990758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0710477\n",
      "\tspeed: 0.0555s/iter; left time: 737.3705s\n",
      "\titers: 200, epoch: 41 | loss: 0.0714780\n",
      "\tspeed: 0.0275s/iter; left time: 362.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0722101 Vali Loss: 0.0870551 Test Loss: 0.0990871\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0729959\n",
      "\tspeed: 0.0549s/iter; left time: 716.7508s\n",
      "\titers: 200, epoch: 42 | loss: 0.0731762\n",
      "\tspeed: 0.0275s/iter; left time: 356.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0722176 Vali Loss: 0.0870186 Test Loss: 0.0990798\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0696957\n",
      "\tspeed: 0.0552s/iter; left time: 708.4867s\n",
      "\titers: 200, epoch: 43 | loss: 0.0742865\n",
      "\tspeed: 0.0273s/iter; left time: 347.8541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0721808 Vali Loss: 0.0870299 Test Loss: 0.0990869\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0707738\n",
      "\tspeed: 0.0548s/iter; left time: 690.8057s\n",
      "\titers: 200, epoch: 44 | loss: 0.0735459\n",
      "\tspeed: 0.0274s/iter; left time: 342.3132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0721658 Vali Loss: 0.0870273 Test Loss: 0.0991185\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0685524\n",
      "\tspeed: 0.0554s/iter; left time: 686.6672s\n",
      "\titers: 200, epoch: 45 | loss: 0.0731006\n",
      "\tspeed: 0.0275s/iter; left time: 338.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0721599 Vali Loss: 0.0870868 Test Loss: 0.0990567\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0733079\n",
      "\tspeed: 0.0548s/iter; left time: 667.2659s\n",
      "\titers: 200, epoch: 46 | loss: 0.0734962\n",
      "\tspeed: 0.0275s/iter; left time: 331.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0721439 Vali Loss: 0.0870370 Test Loss: 0.0990536\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0720074\n",
      "\tspeed: 0.0549s/iter; left time: 655.8333s\n",
      "\titers: 200, epoch: 47 | loss: 0.0677996\n",
      "\tspeed: 0.0275s/iter; left time: 325.2830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0721155 Vali Loss: 0.0870405 Test Loss: 0.0990694\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0653876\n",
      "\tspeed: 0.0551s/iter; left time: 646.0509s\n",
      "\titers: 200, epoch: 48 | loss: 0.0724103\n",
      "\tspeed: 0.0276s/iter; left time: 321.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0721247 Vali Loss: 0.0869497 Test Loss: 0.0990640\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0706327\n",
      "\tspeed: 0.0541s/iter; left time: 621.4333s\n",
      "\titers: 200, epoch: 49 | loss: 0.0714311\n",
      "\tspeed: 0.0274s/iter; left time: 312.5596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0722060 Vali Loss: 0.0869205 Test Loss: 0.0991038\n",
      "Validation loss decreased (0.086939 --> 0.086921).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0691157\n",
      "\tspeed: 0.0556s/iter; left time: 627.1738s\n",
      "\titers: 200, epoch: 50 | loss: 0.0745057\n",
      "\tspeed: 0.0277s/iter; left time: 309.4944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0721507 Vali Loss: 0.0869514 Test Loss: 0.0990506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0696817\n",
      "\tspeed: 0.0546s/iter; left time: 603.1448s\n",
      "\titers: 200, epoch: 51 | loss: 0.0673249\n",
      "\tspeed: 0.0275s/iter; left time: 300.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0721517 Vali Loss: 0.0870177 Test Loss: 0.0990696\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0733455\n",
      "\tspeed: 0.0549s/iter; left time: 594.8613s\n",
      "\titers: 200, epoch: 52 | loss: 0.0684303\n",
      "\tspeed: 0.0275s/iter; left time: 295.4240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0721067 Vali Loss: 0.0869252 Test Loss: 0.0990756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0704044\n",
      "\tspeed: 0.0551s/iter; left time: 584.0208s\n",
      "\titers: 200, epoch: 53 | loss: 0.0669803\n",
      "\tspeed: 0.0274s/iter; left time: 288.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0721210 Vali Loss: 0.0870864 Test Loss: 0.0990590\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0740190\n",
      "\tspeed: 0.0550s/iter; left time: 571.2606s\n",
      "\titers: 200, epoch: 54 | loss: 0.0709148\n",
      "\tspeed: 0.0275s/iter; left time: 282.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0721214 Vali Loss: 0.0871028 Test Loss: 0.0990684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0761958\n",
      "\tspeed: 0.0547s/iter; left time: 555.2269s\n",
      "\titers: 200, epoch: 55 | loss: 0.0691041\n",
      "\tspeed: 0.0275s/iter; left time: 276.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0721010 Vali Loss: 0.0869533 Test Loss: 0.0990627\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0708593\n",
      "\tspeed: 0.0544s/iter; left time: 540.5139s\n",
      "\titers: 200, epoch: 56 | loss: 0.0676377\n",
      "\tspeed: 0.0274s/iter; left time: 269.5365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0721274 Vali Loss: 0.0869847 Test Loss: 0.0990525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0749755\n",
      "\tspeed: 0.0546s/iter; left time: 530.7956s\n",
      "\titers: 200, epoch: 57 | loss: 0.0738492\n",
      "\tspeed: 0.0279s/iter; left time: 268.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0721008 Vali Loss: 0.0870038 Test Loss: 0.0990895\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0728374\n",
      "\tspeed: 0.0550s/iter; left time: 522.2881s\n",
      "\titers: 200, epoch: 58 | loss: 0.0725888\n",
      "\tspeed: 0.0276s/iter; left time: 258.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0720944 Vali Loss: 0.0870936 Test Loss: 0.0990578\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0685350\n",
      "\tspeed: 0.0549s/iter; left time: 508.9567s\n",
      "\titers: 200, epoch: 59 | loss: 0.0679364\n",
      "\tspeed: 0.0276s/iter; left time: 253.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0721380 Vali Loss: 0.0870145 Test Loss: 0.0990548\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02452985942363739, rmse:0.1566201150417328, mae:0.09910380840301514, rse:0.5402949452400208\n",
      "Intermediate time for GB and pred_len 24: 00h:15m:45.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1327405\n",
      "\tspeed: 0.0544s/iter; left time: 1202.3029s\n",
      "\titers: 200, epoch: 1 | loss: 0.1243629\n",
      "\tspeed: 0.0277s/iter; left time: 608.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.1360018 Vali Loss: 0.1319303 Test Loss: 0.1561294\n",
      "Validation loss decreased (inf --> 0.131930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1104123\n",
      "\tspeed: 0.0554s/iter; left time: 1212.6447s\n",
      "\titers: 200, epoch: 2 | loss: 0.1038653\n",
      "\tspeed: 0.0277s/iter; left time: 602.9261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1086582 Vali Loss: 0.1173126 Test Loss: 0.1381347\n",
      "Validation loss decreased (0.131930 --> 0.117313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1030800\n",
      "\tspeed: 0.0552s/iter; left time: 1194.6172s\n",
      "\titers: 200, epoch: 3 | loss: 0.1040743\n",
      "\tspeed: 0.0277s/iter; left time: 596.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.1038056 Vali Loss: 0.1160963 Test Loss: 0.1381614\n",
      "Validation loss decreased (0.117313 --> 0.116096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1001123\n",
      "\tspeed: 0.0556s/iter; left time: 1190.8040s\n",
      "\titers: 200, epoch: 4 | loss: 0.1045213\n",
      "\tspeed: 0.0277s/iter; left time: 591.6547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1022709 Vali Loss: 0.1154291 Test Loss: 0.1391387\n",
      "Validation loss decreased (0.116096 --> 0.115429).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0987614\n",
      "\tspeed: 0.0553s/iter; left time: 1173.2211s\n",
      "\titers: 200, epoch: 5 | loss: 0.1011921\n",
      "\tspeed: 0.0277s/iter; left time: 584.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.1013648 Vali Loss: 0.1150698 Test Loss: 0.1373641\n",
      "Validation loss decreased (0.115429 --> 0.115070).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1037633\n",
      "\tspeed: 0.0552s/iter; left time: 1158.0524s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977643\n",
      "\tspeed: 0.0277s/iter; left time: 577.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.1006952 Vali Loss: 0.1147179 Test Loss: 0.1374119\n",
      "Validation loss decreased (0.115070 --> 0.114718).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0995319\n",
      "\tspeed: 0.0551s/iter; left time: 1144.3863s\n",
      "\titers: 200, epoch: 7 | loss: 0.1002181\n",
      "\tspeed: 0.0276s/iter; left time: 570.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.1000816 Vali Loss: 0.1145912 Test Loss: 0.1383313\n",
      "Validation loss decreased (0.114718 --> 0.114591).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997116\n",
      "\tspeed: 0.0546s/iter; left time: 1122.4292s\n",
      "\titers: 200, epoch: 8 | loss: 0.0983746\n",
      "\tspeed: 0.0276s/iter; left time: 565.1626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0995788 Vali Loss: 0.1145448 Test Loss: 0.1381885\n",
      "Validation loss decreased (0.114591 --> 0.114545).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991581\n",
      "\tspeed: 0.0552s/iter; left time: 1122.3412s\n",
      "\titers: 200, epoch: 9 | loss: 0.0968385\n",
      "\tspeed: 0.0277s/iter; left time: 559.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0991564 Vali Loss: 0.1144790 Test Loss: 0.1383531\n",
      "Validation loss decreased (0.114545 --> 0.114479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1012635\n",
      "\tspeed: 0.0557s/iter; left time: 1120.3142s\n",
      "\titers: 200, epoch: 10 | loss: 0.1009406\n",
      "\tspeed: 0.0277s/iter; left time: 553.8397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0986427 Vali Loss: 0.1150127 Test Loss: 0.1381276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0957322\n",
      "\tspeed: 0.0544s/iter; left time: 1082.2060s\n",
      "\titers: 200, epoch: 11 | loss: 0.1009643\n",
      "\tspeed: 0.0277s/iter; left time: 548.1908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0982024 Vali Loss: 0.1147650 Test Loss: 0.1389920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0975333\n",
      "\tspeed: 0.0551s/iter; left time: 1083.8082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0997255\n",
      "\tspeed: 0.0277s/iter; left time: 541.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0977982 Vali Loss: 0.1151670 Test Loss: 0.1391113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996402\n",
      "\tspeed: 0.0538s/iter; left time: 1045.6179s\n",
      "\titers: 200, epoch: 13 | loss: 0.0977008\n",
      "\tspeed: 0.0275s/iter; left time: 532.2989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0973461 Vali Loss: 0.1151676 Test Loss: 0.1398406\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0996735\n",
      "\tspeed: 0.0538s/iter; left time: 1034.4663s\n",
      "\titers: 200, epoch: 14 | loss: 0.1013699\n",
      "\tspeed: 0.0276s/iter; left time: 527.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0970579 Vali Loss: 0.1149830 Test Loss: 0.1391248\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0975581\n",
      "\tspeed: 0.0541s/iter; left time: 1028.3262s\n",
      "\titers: 200, epoch: 15 | loss: 0.0939162\n",
      "\tspeed: 0.0276s/iter; left time: 521.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0967082 Vali Loss: 0.1153191 Test Loss: 0.1399669\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0947649\n",
      "\tspeed: 0.0542s/iter; left time: 1017.2054s\n",
      "\titers: 200, epoch: 16 | loss: 0.0971435\n",
      "\tspeed: 0.0278s/iter; left time: 518.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0963652 Vali Loss: 0.1153320 Test Loss: 0.1403481\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0913939\n",
      "\tspeed: 0.0542s/iter; left time: 1005.3337s\n",
      "\titers: 200, epoch: 17 | loss: 0.0924671\n",
      "\tspeed: 0.0276s/iter; left time: 509.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0961299 Vali Loss: 0.1153559 Test Loss: 0.1403337\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0962678\n",
      "\tspeed: 0.0545s/iter; left time: 998.9957s\n",
      "\titers: 200, epoch: 18 | loss: 0.0957264\n",
      "\tspeed: 0.0276s/iter; left time: 503.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0958089 Vali Loss: 0.1154434 Test Loss: 0.1402712\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0927861\n",
      "\tspeed: 0.0556s/iter; left time: 1006.5840s\n",
      "\titers: 200, epoch: 19 | loss: 0.0988788\n",
      "\tspeed: 0.0279s/iter; left time: 502.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0956514 Vali Loss: 0.1153018 Test Loss: 0.1403805\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04103749245405197, rmse:0.2025771290063858, mae:0.13835307955741882, rse:0.7005399465560913\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1322768\n",
      "\tspeed: 0.0298s/iter; left time: 658.8596s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232727\n",
      "\tspeed: 0.0277s/iter; left time: 608.5743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.1361218 Vali Loss: 0.1318289 Test Loss: 0.1557044\n",
      "Validation loss decreased (inf --> 0.131829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1084266\n",
      "\tspeed: 0.0560s/iter; left time: 1224.8188s\n",
      "\titers: 200, epoch: 2 | loss: 0.1075629\n",
      "\tspeed: 0.0276s/iter; left time: 601.6934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1086644 Vali Loss: 0.1174318 Test Loss: 0.1383385\n",
      "Validation loss decreased (0.131829 --> 0.117432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034233\n",
      "\tspeed: 0.0565s/iter; left time: 1222.7893s\n",
      "\titers: 200, epoch: 3 | loss: 0.0990774\n",
      "\tspeed: 0.0277s/iter; left time: 597.3496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1038747 Vali Loss: 0.1169057 Test Loss: 0.1391974\n",
      "Validation loss decreased (0.117432 --> 0.116906).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1028465\n",
      "\tspeed: 0.0571s/iter; left time: 1224.8391s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982938\n",
      "\tspeed: 0.0277s/iter; left time: 590.6842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1023380 Vali Loss: 0.1156920 Test Loss: 0.1377567\n",
      "Validation loss decreased (0.116906 --> 0.115692).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994471\n",
      "\tspeed: 0.0565s/iter; left time: 1199.3111s\n",
      "\titers: 200, epoch: 5 | loss: 0.1006992\n",
      "\tspeed: 0.0277s/iter; left time: 585.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.1013651 Vali Loss: 0.1155495 Test Loss: 0.1386454\n",
      "Validation loss decreased (0.115692 --> 0.115550).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023831\n",
      "\tspeed: 0.0566s/iter; left time: 1187.6262s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024807\n",
      "\tspeed: 0.0275s/iter; left time: 574.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.1006738 Vali Loss: 0.1151175 Test Loss: 0.1375258\n",
      "Validation loss decreased (0.115550 --> 0.115117).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0977555\n",
      "\tspeed: 0.0572s/iter; left time: 1188.0972s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071143\n",
      "\tspeed: 0.0278s/iter; left time: 574.4479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1001502 Vali Loss: 0.1150844 Test Loss: 0.1382716\n",
      "Validation loss decreased (0.115117 --> 0.115084).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1009836\n",
      "\tspeed: 0.0556s/iter; left time: 1143.3203s\n",
      "\titers: 200, epoch: 8 | loss: 0.0984353\n",
      "\tspeed: 0.0276s/iter; left time: 564.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0997035 Vali Loss: 0.1151254 Test Loss: 0.1387418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1067791\n",
      "\tspeed: 0.0551s/iter; left time: 1119.0090s\n",
      "\titers: 200, epoch: 9 | loss: 0.1010808\n",
      "\tspeed: 0.0276s/iter; left time: 558.4412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0991905 Vali Loss: 0.1151151 Test Loss: 0.1383947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0988759\n",
      "\tspeed: 0.0554s/iter; left time: 1113.7714s\n",
      "\titers: 200, epoch: 10 | loss: 0.1045415\n",
      "\tspeed: 0.0277s/iter; left time: 553.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0987487 Vali Loss: 0.1157125 Test Loss: 0.1390911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0971992\n",
      "\tspeed: 0.0556s/iter; left time: 1105.1864s\n",
      "\titers: 200, epoch: 11 | loss: 0.0955135\n",
      "\tspeed: 0.0276s/iter; left time: 546.7218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0983224 Vali Loss: 0.1157972 Test Loss: 0.1393044\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1032200\n",
      "\tspeed: 0.0554s/iter; left time: 1089.3380s\n",
      "\titers: 200, epoch: 12 | loss: 0.0979569\n",
      "\tspeed: 0.0278s/iter; left time: 544.4170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0978991 Vali Loss: 0.1161788 Test Loss: 0.1398200\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1001930\n",
      "\tspeed: 0.0558s/iter; left time: 1083.9636s\n",
      "\titers: 200, epoch: 13 | loss: 0.0932302\n",
      "\tspeed: 0.0277s/iter; left time: 534.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0975759 Vali Loss: 0.1155320 Test Loss: 0.1393119\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0979193\n",
      "\tspeed: 0.0564s/iter; left time: 1084.5771s\n",
      "\titers: 200, epoch: 14 | loss: 0.0984236\n",
      "\tspeed: 0.0280s/iter; left time: 534.6976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0972351 Vali Loss: 0.1161485 Test Loss: 0.1396833\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0944086\n",
      "\tspeed: 0.0555s/iter; left time: 1053.7872s\n",
      "\titers: 200, epoch: 15 | loss: 0.0940565\n",
      "\tspeed: 0.0276s/iter; left time: 521.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0969673 Vali Loss: 0.1161226 Test Loss: 0.1405476\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1005118\n",
      "\tspeed: 0.0557s/iter; left time: 1045.3053s\n",
      "\titers: 200, epoch: 16 | loss: 0.0982231\n",
      "\tspeed: 0.0276s/iter; left time: 516.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0966692 Vali Loss: 0.1163388 Test Loss: 0.1401479\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0967874\n",
      "\tspeed: 0.0558s/iter; left time: 1035.9544s\n",
      "\titers: 200, epoch: 17 | loss: 0.0957243\n",
      "\tspeed: 0.0276s/iter; left time: 510.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0964403 Vali Loss: 0.1162060 Test Loss: 0.1400563\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04094025865197182, rmse:0.20233699679374695, mae:0.13827164471149445, rse:0.6997095346450806\n",
      "Intermediate time for GB and pred_len 96: 00h:05m:11.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1347650\n",
      "\tspeed: 0.0529s/iter; left time: 1169.6658s\n",
      "\titers: 200, epoch: 1 | loss: 0.1276309\n",
      "\tspeed: 0.0279s/iter; left time: 614.2102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.1370002 Vali Loss: 0.1334339 Test Loss: 0.1581242\n",
      "Validation loss decreased (inf --> 0.133434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1146453\n",
      "\tspeed: 0.0569s/iter; left time: 1245.3921s\n",
      "\titers: 200, epoch: 2 | loss: 0.1078754\n",
      "\tspeed: 0.0280s/iter; left time: 609.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1128790 Vali Loss: 0.1215125 Test Loss: 0.1444910\n",
      "Validation loss decreased (0.133434 --> 0.121513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1090863\n",
      "\tspeed: 0.0572s/iter; left time: 1239.2874s\n",
      "\titers: 200, epoch: 3 | loss: 0.1092802\n",
      "\tspeed: 0.0284s/iter; left time: 611.5169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.1084377 Vali Loss: 0.1207003 Test Loss: 0.1441532\n",
      "Validation loss decreased (0.121513 --> 0.120700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040198\n",
      "\tspeed: 0.0570s/iter; left time: 1222.2519s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051570\n",
      "\tspeed: 0.0280s/iter; left time: 596.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1068213 Vali Loss: 0.1201760 Test Loss: 0.1442699\n",
      "Validation loss decreased (0.120700 --> 0.120176).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059773\n",
      "\tspeed: 0.0572s/iter; left time: 1213.5096s\n",
      "\titers: 200, epoch: 5 | loss: 0.1093468\n",
      "\tspeed: 0.0279s/iter; left time: 588.8062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1057905 Vali Loss: 0.1197248 Test Loss: 0.1445071\n",
      "Validation loss decreased (0.120176 --> 0.119725).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1075472\n",
      "\tspeed: 0.0566s/iter; left time: 1188.5503s\n",
      "\titers: 200, epoch: 6 | loss: 0.1025704\n",
      "\tspeed: 0.0280s/iter; left time: 584.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.1050095 Vali Loss: 0.1198707 Test Loss: 0.1446527\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1069770\n",
      "\tspeed: 0.0556s/iter; left time: 1155.2920s\n",
      "\titers: 200, epoch: 7 | loss: 0.1025716\n",
      "\tspeed: 0.0279s/iter; left time: 576.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1041711 Vali Loss: 0.1199401 Test Loss: 0.1445111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988023\n",
      "\tspeed: 0.0553s/iter; left time: 1136.3049s\n",
      "\titers: 200, epoch: 8 | loss: 0.1057062\n",
      "\tspeed: 0.0279s/iter; left time: 570.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1034249 Vali Loss: 0.1201355 Test Loss: 0.1444249\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1017852\n",
      "\tspeed: 0.0557s/iter; left time: 1131.9389s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009359\n",
      "\tspeed: 0.0282s/iter; left time: 569.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1028025 Vali Loss: 0.1209832 Test Loss: 0.1457750\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1030849\n",
      "\tspeed: 0.0560s/iter; left time: 1125.6821s\n",
      "\titers: 200, epoch: 10 | loss: 0.1036072\n",
      "\tspeed: 0.0285s/iter; left time: 569.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1021603 Vali Loss: 0.1210356 Test Loss: 0.1455536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1034537\n",
      "\tspeed: 0.0565s/iter; left time: 1122.5566s\n",
      "\titers: 200, epoch: 11 | loss: 0.1003527\n",
      "\tspeed: 0.0279s/iter; left time: 551.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1015546 Vali Loss: 0.1213752 Test Loss: 0.1458076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0984684\n",
      "\tspeed: 0.0569s/iter; left time: 1117.8841s\n",
      "\titers: 200, epoch: 12 | loss: 0.1031672\n",
      "\tspeed: 0.0280s/iter; left time: 546.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.1011189 Vali Loss: 0.1219492 Test Loss: 0.1477038\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0992456\n",
      "\tspeed: 0.0565s/iter; left time: 1097.5848s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973925\n",
      "\tspeed: 0.0279s/iter; left time: 540.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1006000 Vali Loss: 0.1218889 Test Loss: 0.1464390\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0993553\n",
      "\tspeed: 0.0562s/iter; left time: 1079.1071s\n",
      "\titers: 200, epoch: 14 | loss: 0.0990723\n",
      "\tspeed: 0.0281s/iter; left time: 537.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1001175 Vali Loss: 0.1220132 Test Loss: 0.1457612\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0986414\n",
      "\tspeed: 0.0562s/iter; left time: 1068.0081s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030153\n",
      "\tspeed: 0.0279s/iter; left time: 527.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0996694 Vali Loss: 0.1221891 Test Loss: 0.1468757\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04340211674571037, rmse:0.20833174884319305, mae:0.1445070505142212, rse:0.7223160862922668\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1339769\n",
      "\tspeed: 0.0301s/iter; left time: 665.8574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1294794\n",
      "\tspeed: 0.0278s/iter; left time: 611.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.1367866 Vali Loss: 0.1331977 Test Loss: 0.1577220\n",
      "Validation loss decreased (inf --> 0.133198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1110311\n",
      "\tspeed: 0.0594s/iter; left time: 1299.9396s\n",
      "\titers: 200, epoch: 2 | loss: 0.1098771\n",
      "\tspeed: 0.0278s/iter; left time: 604.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.1128032 Vali Loss: 0.1215736 Test Loss: 0.1443224\n",
      "Validation loss decreased (0.133198 --> 0.121574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072261\n",
      "\tspeed: 0.0587s/iter; left time: 1270.2866s\n",
      "\titers: 200, epoch: 3 | loss: 0.1054629\n",
      "\tspeed: 0.0284s/iter; left time: 611.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.1084783 Vali Loss: 0.1210374 Test Loss: 0.1444447\n",
      "Validation loss decreased (0.121574 --> 0.121037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117364\n",
      "\tspeed: 0.0578s/iter; left time: 1238.6688s\n",
      "\titers: 200, epoch: 4 | loss: 0.1035394\n",
      "\tspeed: 0.0279s/iter; left time: 595.3007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.1069008 Vali Loss: 0.1208476 Test Loss: 0.1448698\n",
      "Validation loss decreased (0.121037 --> 0.120848).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043344\n",
      "\tspeed: 0.0576s/iter; left time: 1222.1477s\n",
      "\titers: 200, epoch: 5 | loss: 0.1038461\n",
      "\tspeed: 0.0278s/iter; left time: 587.9244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1059211 Vali Loss: 0.1205633 Test Loss: 0.1449205\n",
      "Validation loss decreased (0.120848 --> 0.120563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1031239\n",
      "\tspeed: 0.0585s/iter; left time: 1227.5951s\n",
      "\titers: 200, epoch: 6 | loss: 0.1016193\n",
      "\tspeed: 0.0279s/iter; left time: 582.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.1051543 Vali Loss: 0.1206746 Test Loss: 0.1448787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1080348\n",
      "\tspeed: 0.0581s/iter; left time: 1205.7857s\n",
      "\titers: 200, epoch: 7 | loss: 0.1014774\n",
      "\tspeed: 0.0281s/iter; left time: 581.2295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.1044601 Vali Loss: 0.1214000 Test Loss: 0.1456714\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1067783\n",
      "\tspeed: 0.0580s/iter; left time: 1191.7521s\n",
      "\titers: 200, epoch: 8 | loss: 0.0980323\n",
      "\tspeed: 0.0284s/iter; left time: 580.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.1037810 Vali Loss: 0.1211917 Test Loss: 0.1458393\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1016269\n",
      "\tspeed: 0.0594s/iter; left time: 1207.1640s\n",
      "\titers: 200, epoch: 9 | loss: 0.1047949\n",
      "\tspeed: 0.0278s/iter; left time: 562.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.1030960 Vali Loss: 0.1214143 Test Loss: 0.1449590\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1013009\n",
      "\tspeed: 0.0571s/iter; left time: 1148.7901s\n",
      "\titers: 200, epoch: 10 | loss: 0.1037955\n",
      "\tspeed: 0.0278s/iter; left time: 556.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1024449 Vali Loss: 0.1220832 Test Loss: 0.1452367\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025939\n",
      "\tspeed: 0.0585s/iter; left time: 1163.5125s\n",
      "\titers: 200, epoch: 11 | loss: 0.1057903\n",
      "\tspeed: 0.0281s/iter; left time: 556.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.1018432 Vali Loss: 0.1223256 Test Loss: 0.1461930\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1044922\n",
      "\tspeed: 0.0581s/iter; left time: 1142.4045s\n",
      "\titers: 200, epoch: 12 | loss: 0.1001102\n",
      "\tspeed: 0.0279s/iter; left time: 545.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1012480 Vali Loss: 0.1228115 Test Loss: 0.1466614\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1021211\n",
      "\tspeed: 0.0580s/iter; left time: 1127.6961s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995632\n",
      "\tspeed: 0.0281s/iter; left time: 543.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.1006941 Vali Loss: 0.1232791 Test Loss: 0.1464134\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1018477\n",
      "\tspeed: 0.0574s/iter; left time: 1103.5637s\n",
      "\titers: 200, epoch: 14 | loss: 0.1007373\n",
      "\tspeed: 0.0280s/iter; left time: 534.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.1001451 Vali Loss: 0.1233907 Test Loss: 0.1463752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0958651\n",
      "\tspeed: 0.0578s/iter; left time: 1097.4992s\n",
      "\titers: 200, epoch: 15 | loss: 0.0988765\n",
      "\tspeed: 0.0284s/iter; left time: 535.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0997284 Vali Loss: 0.1235788 Test Loss: 0.1468997\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04363047704100609, rmse:0.20887909829616547, mae:0.14492040872573853, rse:0.7242138385772705\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:30.00s\n",
      "Intermediate time for GB: 00h:25m:26.82s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1425482\n",
      "\tspeed: 0.0394s/iter; left time: 879.7703s\n",
      "\titers: 200, epoch: 1 | loss: 0.1104893\n",
      "\tspeed: 0.0126s/iter; left time: 279.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 224 | Train Loss: 0.1421386 Vali Loss: 0.1024634 Test Loss: 0.1156230\n",
      "Validation loss decreased (inf --> 0.102463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754029\n",
      "\tspeed: 0.0293s/iter; left time: 647.6095s\n",
      "\titers: 200, epoch: 2 | loss: 0.0698134\n",
      "\tspeed: 0.0127s/iter; left time: 278.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0789382 Vali Loss: 0.0659860 Test Loss: 0.0725923\n",
      "Validation loss decreased (0.102463 --> 0.065986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697408\n",
      "\tspeed: 0.0334s/iter; left time: 729.5954s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669259\n",
      "\tspeed: 0.0132s/iter; left time: 288.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0677439 Vali Loss: 0.0623854 Test Loss: 0.0690371\n",
      "Validation loss decreased (0.065986 --> 0.062385).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0663753\n",
      "\tspeed: 0.0352s/iter; left time: 760.6249s\n",
      "\titers: 200, epoch: 4 | loss: 0.0620801\n",
      "\tspeed: 0.0155s/iter; left time: 334.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0647137 Vali Loss: 0.0599460 Test Loss: 0.0667055\n",
      "Validation loss decreased (0.062385 --> 0.059946).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0587628\n",
      "\tspeed: 0.0359s/iter; left time: 768.9500s\n",
      "\titers: 200, epoch: 5 | loss: 0.0644008\n",
      "\tspeed: 0.0153s/iter; left time: 326.1157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0626116 Vali Loss: 0.0584746 Test Loss: 0.0653509\n",
      "Validation loss decreased (0.059946 --> 0.058475).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0615298\n",
      "\tspeed: 0.0324s/iter; left time: 686.9278s\n",
      "\titers: 200, epoch: 6 | loss: 0.0624429\n",
      "\tspeed: 0.0163s/iter; left time: 342.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0610244 Vali Loss: 0.0574327 Test Loss: 0.0641283\n",
      "Validation loss decreased (0.058475 --> 0.057433).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0596650\n",
      "\tspeed: 0.0338s/iter; left time: 707.4615s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583340\n",
      "\tspeed: 0.0135s/iter; left time: 280.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0598346 Vali Loss: 0.0564253 Test Loss: 0.0632567\n",
      "Validation loss decreased (0.057433 --> 0.056425).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0566126\n",
      "\tspeed: 0.0298s/iter; left time: 618.4315s\n",
      "\titers: 200, epoch: 8 | loss: 0.0581193\n",
      "\tspeed: 0.0139s/iter; left time: 287.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0588653 Vali Loss: 0.0560569 Test Loss: 0.0627393\n",
      "Validation loss decreased (0.056425 --> 0.056057).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0575493\n",
      "\tspeed: 0.0311s/iter; left time: 638.7608s\n",
      "\titers: 200, epoch: 9 | loss: 0.0590428\n",
      "\tspeed: 0.0129s/iter; left time: 263.1687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0581826 Vali Loss: 0.0558127 Test Loss: 0.0624923\n",
      "Validation loss decreased (0.056057 --> 0.055813).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0584252\n",
      "\tspeed: 0.0296s/iter; left time: 600.9989s\n",
      "\titers: 200, epoch: 10 | loss: 0.0561229\n",
      "\tspeed: 0.0124s/iter; left time: 251.0681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0576705 Vali Loss: 0.0553937 Test Loss: 0.0623941\n",
      "Validation loss decreased (0.055813 --> 0.055394).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0540729\n",
      "\tspeed: 0.0309s/iter; left time: 619.3650s\n",
      "\titers: 200, epoch: 11 | loss: 0.0559405\n",
      "\tspeed: 0.0124s/iter; left time: 247.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 224 | Train Loss: 0.0571071 Vali Loss: 0.0554232 Test Loss: 0.0619265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0581580\n",
      "\tspeed: 0.0326s/iter; left time: 646.0836s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559574\n",
      "\tspeed: 0.0153s/iter; left time: 302.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0568031 Vali Loss: 0.0549059 Test Loss: 0.0613526\n",
      "Validation loss decreased (0.055394 --> 0.054906).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0574033\n",
      "\tspeed: 0.0311s/iter; left time: 609.4376s\n",
      "\titers: 200, epoch: 13 | loss: 0.0588684\n",
      "\tspeed: 0.0146s/iter; left time: 284.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 224 | Train Loss: 0.0564792 Vali Loss: 0.0546547 Test Loss: 0.0616889\n",
      "Validation loss decreased (0.054906 --> 0.054655).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577393\n",
      "\tspeed: 0.0305s/iter; left time: 591.0703s\n",
      "\titers: 200, epoch: 14 | loss: 0.0558686\n",
      "\tspeed: 0.0128s/iter; left time: 247.7890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.0561604 Vali Loss: 0.0543734 Test Loss: 0.0609931\n",
      "Validation loss decreased (0.054655 --> 0.054373).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0579033\n",
      "\tspeed: 0.0303s/iter; left time: 580.6453s\n",
      "\titers: 200, epoch: 15 | loss: 0.0535756\n",
      "\tspeed: 0.0125s/iter; left time: 238.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.0558500 Vali Loss: 0.0542650 Test Loss: 0.0609051\n",
      "Validation loss decreased (0.054373 --> 0.054265).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0562449\n",
      "\tspeed: 0.0324s/iter; left time: 614.1498s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561106\n",
      "\tspeed: 0.0124s/iter; left time: 234.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 224 | Train Loss: 0.0556149 Vali Loss: 0.0542614 Test Loss: 0.0608960\n",
      "Validation loss decreased (0.054265 --> 0.054261).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0563525\n",
      "\tspeed: 0.0349s/iter; left time: 653.9779s\n",
      "\titers: 200, epoch: 17 | loss: 0.0538133\n",
      "\tspeed: 0.0172s/iter; left time: 320.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 224 | Train Loss: 0.0554824 Vali Loss: 0.0542809 Test Loss: 0.0609239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0552306\n",
      "\tspeed: 0.0300s/iter; left time: 555.3744s\n",
      "\titers: 200, epoch: 18 | loss: 0.0528534\n",
      "\tspeed: 0.0125s/iter; left time: 229.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 224 | Train Loss: 0.0553357 Vali Loss: 0.0540823 Test Loss: 0.0606030\n",
      "Validation loss decreased (0.054261 --> 0.054082).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0540370\n",
      "\tspeed: 0.0296s/iter; left time: 541.0689s\n",
      "\titers: 200, epoch: 19 | loss: 0.0543503\n",
      "\tspeed: 0.0124s/iter; left time: 225.2102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0551812 Vali Loss: 0.0541816 Test Loss: 0.0607240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0575754\n",
      "\tspeed: 0.0289s/iter; left time: 520.8277s\n",
      "\titers: 200, epoch: 20 | loss: 0.0548795\n",
      "\tspeed: 0.0125s/iter; left time: 225.1082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0550216 Vali Loss: 0.0539896 Test Loss: 0.0605306\n",
      "Validation loss decreased (0.054082 --> 0.053990).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0575276\n",
      "\tspeed: 0.0316s/iter; left time: 562.3753s\n",
      "\titers: 200, epoch: 21 | loss: 0.0543469\n",
      "\tspeed: 0.0127s/iter; left time: 224.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0548482 Vali Loss: 0.0537500 Test Loss: 0.0603008\n",
      "Validation loss decreased (0.053990 --> 0.053750).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0548617\n",
      "\tspeed: 0.0329s/iter; left time: 578.5450s\n",
      "\titers: 200, epoch: 22 | loss: 0.0566439\n",
      "\tspeed: 0.0150s/iter; left time: 262.9958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 224 | Train Loss: 0.0547552 Vali Loss: 0.0538126 Test Loss: 0.0604658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0564763\n",
      "\tspeed: 0.0306s/iter; left time: 532.3853s\n",
      "\titers: 200, epoch: 23 | loss: 0.0510527\n",
      "\tspeed: 0.0127s/iter; left time: 219.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0546330 Vali Loss: 0.0536577 Test Loss: 0.0602690\n",
      "Validation loss decreased (0.053750 --> 0.053658).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0537765\n",
      "\tspeed: 0.0318s/iter; left time: 545.6313s\n",
      "\titers: 200, epoch: 24 | loss: 0.0571833\n",
      "\tspeed: 0.0126s/iter; left time: 214.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0546128 Vali Loss: 0.0537215 Test Loss: 0.0602477\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0538050\n",
      "\tspeed: 0.0336s/iter; left time: 568.2767s\n",
      "\titers: 200, epoch: 25 | loss: 0.0557826\n",
      "\tspeed: 0.0135s/iter; left time: 227.5996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0545751 Vali Loss: 0.0536525 Test Loss: 0.0601464\n",
      "Validation loss decreased (0.053658 --> 0.053652).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0569728\n",
      "\tspeed: 0.0318s/iter; left time: 530.9742s\n",
      "\titers: 200, epoch: 26 | loss: 0.0556218\n",
      "\tspeed: 0.0136s/iter; left time: 225.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0544085 Vali Loss: 0.0536649 Test Loss: 0.0601456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0546645\n",
      "\tspeed: 0.0328s/iter; left time: 539.8024s\n",
      "\titers: 200, epoch: 27 | loss: 0.0564713\n",
      "\tspeed: 0.0177s/iter; left time: 290.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 224 | Train Loss: 0.0543927 Vali Loss: 0.0534832 Test Loss: 0.0600631\n",
      "Validation loss decreased (0.053652 --> 0.053483).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0562936\n",
      "\tspeed: 0.0339s/iter; left time: 551.3606s\n",
      "\titers: 200, epoch: 28 | loss: 0.0576871\n",
      "\tspeed: 0.0153s/iter; left time: 246.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 224 | Train Loss: 0.0543202 Vali Loss: 0.0535050 Test Loss: 0.0601452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0538100\n",
      "\tspeed: 0.0380s/iter; left time: 609.3856s\n",
      "\titers: 200, epoch: 29 | loss: 0.0547883\n",
      "\tspeed: 0.0153s/iter; left time: 243.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0542349 Vali Loss: 0.0535748 Test Loss: 0.0600708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0528111\n",
      "\tspeed: 0.0295s/iter; left time: 466.6749s\n",
      "\titers: 200, epoch: 30 | loss: 0.0566908\n",
      "\tspeed: 0.0138s/iter; left time: 216.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 224 | Train Loss: 0.0541868 Vali Loss: 0.0534982 Test Loss: 0.0600329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0570735\n",
      "\tspeed: 0.0337s/iter; left time: 525.7737s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548441\n",
      "\tspeed: 0.0133s/iter; left time: 206.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 224 | Train Loss: 0.0541496 Vali Loss: 0.0534787 Test Loss: 0.0600048\n",
      "Validation loss decreased (0.053483 --> 0.053479).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0561353\n",
      "\tspeed: 0.0292s/iter; left time: 448.0110s\n",
      "\titers: 200, epoch: 32 | loss: 0.0549570\n",
      "\tspeed: 0.0124s/iter; left time: 188.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0541973 Vali Loss: 0.0535334 Test Loss: 0.0600278\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0546849\n",
      "\tspeed: 0.0326s/iter; left time: 493.5664s\n",
      "\titers: 200, epoch: 33 | loss: 0.0553715\n",
      "\tspeed: 0.0133s/iter; left time: 200.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 224 | Train Loss: 0.0541045 Vali Loss: 0.0533982 Test Loss: 0.0599360\n",
      "Validation loss decreased (0.053479 --> 0.053398).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0563013\n",
      "\tspeed: 0.0334s/iter; left time: 498.0300s\n",
      "\titers: 200, epoch: 34 | loss: 0.0567345\n",
      "\tspeed: 0.0165s/iter; left time: 244.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0540234 Vali Loss: 0.0534736 Test Loss: 0.0599731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0505541\n",
      "\tspeed: 0.0354s/iter; left time: 519.4922s\n",
      "\titers: 200, epoch: 35 | loss: 0.0593530\n",
      "\tspeed: 0.0132s/iter; left time: 191.8792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0541377 Vali Loss: 0.0534211 Test Loss: 0.0598892\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0590323\n",
      "\tspeed: 0.0322s/iter; left time: 465.6202s\n",
      "\titers: 200, epoch: 36 | loss: 0.0512331\n",
      "\tspeed: 0.0144s/iter; left time: 207.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 224 | Train Loss: 0.0539921 Vali Loss: 0.0533596 Test Loss: 0.0599006\n",
      "Validation loss decreased (0.053398 --> 0.053360).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0516185\n",
      "\tspeed: 0.0303s/iter; left time: 431.6920s\n",
      "\titers: 200, epoch: 37 | loss: 0.0517964\n",
      "\tspeed: 0.0133s/iter; left time: 187.6435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0539818 Vali Loss: 0.0534184 Test Loss: 0.0599677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0523120\n",
      "\tspeed: 0.0303s/iter; left time: 425.0178s\n",
      "\titers: 200, epoch: 38 | loss: 0.0527229\n",
      "\tspeed: 0.0125s/iter; left time: 174.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.0539424 Vali Loss: 0.0533503 Test Loss: 0.0598853\n",
      "Validation loss decreased (0.053360 --> 0.053350).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0542665\n",
      "\tspeed: 0.0303s/iter; left time: 418.3896s\n",
      "\titers: 200, epoch: 39 | loss: 0.0548936\n",
      "\tspeed: 0.0124s/iter; left time: 170.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 224 | Train Loss: 0.0539725 Vali Loss: 0.0533520 Test Loss: 0.0598737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0541467\n",
      "\tspeed: 0.0301s/iter; left time: 408.3966s\n",
      "\titers: 200, epoch: 40 | loss: 0.0521219\n",
      "\tspeed: 0.0124s/iter; left time: 167.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0539471 Vali Loss: 0.0534283 Test Loss: 0.0599088\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0518075\n",
      "\tspeed: 0.0294s/iter; left time: 391.6725s\n",
      "\titers: 200, epoch: 41 | loss: 0.0540718\n",
      "\tspeed: 0.0124s/iter; left time: 164.3545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0539534 Vali Loss: 0.0533785 Test Loss: 0.0598657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0531682\n",
      "\tspeed: 0.0332s/iter; left time: 435.4256s\n",
      "\titers: 200, epoch: 42 | loss: 0.0527127\n",
      "\tspeed: 0.0146s/iter; left time: 189.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 224 | Train Loss: 0.0539347 Vali Loss: 0.0533247 Test Loss: 0.0598726\n",
      "Validation loss decreased (0.053350 --> 0.053325).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0488264\n",
      "\tspeed: 0.0316s/iter; left time: 407.8943s\n",
      "\titers: 200, epoch: 43 | loss: 0.0539191\n",
      "\tspeed: 0.0134s/iter; left time: 171.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0539457 Vali Loss: 0.0533475 Test Loss: 0.0598917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0539953\n",
      "\tspeed: 0.0291s/iter; left time: 368.3772s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535581\n",
      "\tspeed: 0.0124s/iter; left time: 155.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0539183 Vali Loss: 0.0533803 Test Loss: 0.0598657\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556054\n",
      "\tspeed: 0.0299s/iter; left time: 372.3599s\n",
      "\titers: 200, epoch: 45 | loss: 0.0526824\n",
      "\tspeed: 0.0144s/iter; left time: 177.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 224 | Train Loss: 0.0538678 Vali Loss: 0.0533748 Test Loss: 0.0598727\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0552082\n",
      "\tspeed: 0.0295s/iter; left time: 360.8627s\n",
      "\titers: 200, epoch: 46 | loss: 0.0538167\n",
      "\tspeed: 0.0142s/iter; left time: 172.6341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0539247 Vali Loss: 0.0533262 Test Loss: 0.0598545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0526304\n",
      "\tspeed: 0.0304s/iter; left time: 364.8761s\n",
      "\titers: 200, epoch: 47 | loss: 0.0547760\n",
      "\tspeed: 0.0125s/iter; left time: 148.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 224 | Train Loss: 0.0539397 Vali Loss: 0.0533718 Test Loss: 0.0598320\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0559515\n",
      "\tspeed: 0.0299s/iter; left time: 352.4207s\n",
      "\titers: 200, epoch: 48 | loss: 0.0529149\n",
      "\tspeed: 0.0130s/iter; left time: 151.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.0538842 Vali Loss: 0.0533702 Test Loss: 0.0598220\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0551404\n",
      "\tspeed: 0.0308s/iter; left time: 356.0871s\n",
      "\titers: 200, epoch: 49 | loss: 0.0550315\n",
      "\tspeed: 0.0125s/iter; left time: 143.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0538812 Vali Loss: 0.0533507 Test Loss: 0.0598567\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0531370\n",
      "\tspeed: 0.0307s/iter; left time: 348.1863s\n",
      "\titers: 200, epoch: 50 | loss: 0.0523815\n",
      "\tspeed: 0.0131s/iter; left time: 146.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0538734 Vali Loss: 0.0533317 Test Loss: 0.0598490\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0539780\n",
      "\tspeed: 0.0318s/iter; left time: 352.6326s\n",
      "\titers: 200, epoch: 51 | loss: 0.0488174\n",
      "\tspeed: 0.0131s/iter; left time: 144.2155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0538727 Vali Loss: 0.0533422 Test Loss: 0.0598622\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0556580\n",
      "\tspeed: 0.0328s/iter; left time: 356.9867s\n",
      "\titers: 200, epoch: 52 | loss: 0.0543341\n",
      "\tspeed: 0.0158s/iter; left time: 169.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0538189 Vali Loss: 0.0533340 Test Loss: 0.0598302\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00980358012020588, rmse:0.09901303052902222, mae:0.05987260490655899, rse:0.2913833558559418\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1435407\n",
      "\tspeed: 0.0149s/iter; left time: 331.9872s\n",
      "\titers: 200, epoch: 1 | loss: 0.1207220\n",
      "\tspeed: 0.0151s/iter; left time: 334.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 224 | Train Loss: 0.1436454 Vali Loss: 0.1023005 Test Loss: 0.1161305\n",
      "Validation loss decreased (inf --> 0.102300).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0767974\n",
      "\tspeed: 0.0315s/iter; left time: 694.3741s\n",
      "\titers: 200, epoch: 2 | loss: 0.0741069\n",
      "\tspeed: 0.0158s/iter; left time: 347.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0783967 Vali Loss: 0.0657723 Test Loss: 0.0724153\n",
      "Validation loss decreased (0.102300 --> 0.065772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0681014\n",
      "\tspeed: 0.0340s/iter; left time: 742.9647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0695439\n",
      "\tspeed: 0.0162s/iter; left time: 351.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0673819 Vali Loss: 0.0622238 Test Loss: 0.0688050\n",
      "Validation loss decreased (0.065772 --> 0.062224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0613913\n",
      "\tspeed: 0.0331s/iter; left time: 716.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0613495\n",
      "\tspeed: 0.0129s/iter; left time: 278.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0646703 Vali Loss: 0.0600227 Test Loss: 0.0668252\n",
      "Validation loss decreased (0.062224 --> 0.060023).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649476\n",
      "\tspeed: 0.0335s/iter; left time: 718.0036s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652792\n",
      "\tspeed: 0.0185s/iter; left time: 394.7601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0627083 Vali Loss: 0.0585905 Test Loss: 0.0654137\n",
      "Validation loss decreased (0.060023 --> 0.058591).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612719\n",
      "\tspeed: 0.0357s/iter; left time: 756.6358s\n",
      "\titers: 200, epoch: 6 | loss: 0.0660474\n",
      "\tspeed: 0.0135s/iter; left time: 285.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 224 | Train Loss: 0.0612476 Vali Loss: 0.0576280 Test Loss: 0.0645763\n",
      "Validation loss decreased (0.058591 --> 0.057628).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595772\n",
      "\tspeed: 0.0328s/iter; left time: 686.7032s\n",
      "\titers: 200, epoch: 7 | loss: 0.0565623\n",
      "\tspeed: 0.0124s/iter; left time: 258.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0600903 Vali Loss: 0.0567575 Test Loss: 0.0634947\n",
      "Validation loss decreased (0.057628 --> 0.056757).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0551272\n",
      "\tspeed: 0.0306s/iter; left time: 634.1832s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570751\n",
      "\tspeed: 0.0124s/iter; left time: 255.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0591723 Vali Loss: 0.0560151 Test Loss: 0.0627181\n",
      "Validation loss decreased (0.056757 --> 0.056015).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0576126\n",
      "\tspeed: 0.0353s/iter; left time: 724.6808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0559395\n",
      "\tspeed: 0.0206s/iter; left time: 420.2703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0583651 Vali Loss: 0.0555462 Test Loss: 0.0623228\n",
      "Validation loss decreased (0.056015 --> 0.055546).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0560586\n",
      "\tspeed: 0.0333s/iter; left time: 675.6534s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605261\n",
      "\tspeed: 0.0157s/iter; left time: 316.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0577177 Vali Loss: 0.0550147 Test Loss: 0.0617528\n",
      "Validation loss decreased (0.055546 --> 0.055015).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0554302\n",
      "\tspeed: 0.0359s/iter; left time: 720.1463s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597751\n",
      "\tspeed: 0.0175s/iter; left time: 348.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0572129 Vali Loss: 0.0550474 Test Loss: 0.0615983\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613269\n",
      "\tspeed: 0.0347s/iter; left time: 688.7224s\n",
      "\titers: 200, epoch: 12 | loss: 0.0526708\n",
      "\tspeed: 0.0145s/iter; left time: 285.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 224 | Train Loss: 0.0568236 Vali Loss: 0.0546227 Test Loss: 0.0613652\n",
      "Validation loss decreased (0.055015 --> 0.054623).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0593225\n",
      "\tspeed: 0.0309s/iter; left time: 606.0120s\n",
      "\titers: 200, epoch: 13 | loss: 0.0582850\n",
      "\tspeed: 0.0124s/iter; left time: 241.6783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0564241 Vali Loss: 0.0543386 Test Loss: 0.0610633\n",
      "Validation loss decreased (0.054623 --> 0.054339).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0565399\n",
      "\tspeed: 0.0330s/iter; left time: 640.3086s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560407\n",
      "\tspeed: 0.0166s/iter; left time: 320.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0561661 Vali Loss: 0.0544246 Test Loss: 0.0610822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0534695\n",
      "\tspeed: 0.0315s/iter; left time: 604.6107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0559624\n",
      "\tspeed: 0.0135s/iter; left time: 256.7685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0558687 Vali Loss: 0.0542338 Test Loss: 0.0609795\n",
      "Validation loss decreased (0.054339 --> 0.054234).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0537864\n",
      "\tspeed: 0.0309s/iter; left time: 585.8696s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557857\n",
      "\tspeed: 0.0127s/iter; left time: 239.6799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0556367 Vali Loss: 0.0540954 Test Loss: 0.0607191\n",
      "Validation loss decreased (0.054234 --> 0.054095).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0530062\n",
      "\tspeed: 0.0316s/iter; left time: 590.5342s\n",
      "\titers: 200, epoch: 17 | loss: 0.0538013\n",
      "\tspeed: 0.0125s/iter; left time: 233.1585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 224 | Train Loss: 0.0553981 Vali Loss: 0.0539052 Test Loss: 0.0604521\n",
      "Validation loss decreased (0.054095 --> 0.053905).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0513250\n",
      "\tspeed: 0.0315s/iter; left time: 582.3968s\n",
      "\titers: 200, epoch: 18 | loss: 0.0572616\n",
      "\tspeed: 0.0151s/iter; left time: 278.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 224 | Train Loss: 0.0552307 Vali Loss: 0.0537893 Test Loss: 0.0603094\n",
      "Validation loss decreased (0.053905 --> 0.053789).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0544362\n",
      "\tspeed: 0.0323s/iter; left time: 589.4108s\n",
      "\titers: 200, epoch: 19 | loss: 0.0516768\n",
      "\tspeed: 0.0124s/iter; left time: 224.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0550960 Vali Loss: 0.0539165 Test Loss: 0.0604041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0577114\n",
      "\tspeed: 0.0309s/iter; left time: 558.1153s\n",
      "\titers: 200, epoch: 20 | loss: 0.0531561\n",
      "\tspeed: 0.0136s/iter; left time: 244.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 224 | Train Loss: 0.0549615 Vali Loss: 0.0537066 Test Loss: 0.0602580\n",
      "Validation loss decreased (0.053789 --> 0.053707).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555227\n",
      "\tspeed: 0.0319s/iter; left time: 567.6916s\n",
      "\titers: 200, epoch: 21 | loss: 0.0561253\n",
      "\tspeed: 0.0123s/iter; left time: 218.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 224 | Train Loss: 0.0548436 Vali Loss: 0.0536510 Test Loss: 0.0600112\n",
      "Validation loss decreased (0.053707 --> 0.053651).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0559401\n",
      "\tspeed: 0.0296s/iter; left time: 521.2822s\n",
      "\titers: 200, epoch: 22 | loss: 0.0547799\n",
      "\tspeed: 0.0160s/iter; left time: 279.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 224 | Train Loss: 0.0546664 Vali Loss: 0.0535812 Test Loss: 0.0599993\n",
      "Validation loss decreased (0.053651 --> 0.053581).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0541676\n",
      "\tspeed: 0.0307s/iter; left time: 534.0782s\n",
      "\titers: 200, epoch: 23 | loss: 0.0545476\n",
      "\tspeed: 0.0124s/iter; left time: 215.0109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.0545792 Vali Loss: 0.0535054 Test Loss: 0.0599828\n",
      "Validation loss decreased (0.053581 --> 0.053505).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0532352\n",
      "\tspeed: 0.0307s/iter; left time: 527.0177s\n",
      "\titers: 200, epoch: 24 | loss: 0.0553313\n",
      "\tspeed: 0.0125s/iter; left time: 213.1312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0545810 Vali Loss: 0.0535347 Test Loss: 0.0600860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0569770\n",
      "\tspeed: 0.0313s/iter; left time: 529.8028s\n",
      "\titers: 200, epoch: 25 | loss: 0.0555228\n",
      "\tspeed: 0.0125s/iter; left time: 209.6438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0543828 Vali Loss: 0.0534632 Test Loss: 0.0599130\n",
      "Validation loss decreased (0.053505 --> 0.053463).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0553953\n",
      "\tspeed: 0.0305s/iter; left time: 509.1259s\n",
      "\titers: 200, epoch: 26 | loss: 0.0527639\n",
      "\tspeed: 0.0126s/iter; left time: 209.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0543240 Vali Loss: 0.0533425 Test Loss: 0.0598117\n",
      "Validation loss decreased (0.053463 --> 0.053342).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524301\n",
      "\tspeed: 0.0304s/iter; left time: 500.5540s\n",
      "\titers: 200, epoch: 27 | loss: 0.0553720\n",
      "\tspeed: 0.0124s/iter; left time: 202.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.0543599 Vali Loss: 0.0533696 Test Loss: 0.0598188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0529407\n",
      "\tspeed: 0.0298s/iter; left time: 484.3305s\n",
      "\titers: 200, epoch: 28 | loss: 0.0540488\n",
      "\tspeed: 0.0125s/iter; left time: 201.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.0542927 Vali Loss: 0.0533442 Test Loss: 0.0597497\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0544333\n",
      "\tspeed: 0.0309s/iter; left time: 494.8543s\n",
      "\titers: 200, epoch: 29 | loss: 0.0507390\n",
      "\tspeed: 0.0124s/iter; left time: 197.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 224 | Train Loss: 0.0541682 Vali Loss: 0.0532721 Test Loss: 0.0596530\n",
      "Validation loss decreased (0.053342 --> 0.053272).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0536925\n",
      "\tspeed: 0.0316s/iter; left time: 499.0237s\n",
      "\titers: 200, epoch: 30 | loss: 0.0548809\n",
      "\tspeed: 0.0130s/iter; left time: 203.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0541227 Vali Loss: 0.0533526 Test Loss: 0.0597426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0575247\n",
      "\tspeed: 0.0297s/iter; left time: 462.6109s\n",
      "\titers: 200, epoch: 31 | loss: 0.0525311\n",
      "\tspeed: 0.0124s/iter; left time: 192.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0541270 Vali Loss: 0.0532811 Test Loss: 0.0597268\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0557992\n",
      "\tspeed: 0.0306s/iter; left time: 470.3016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0556330\n",
      "\tspeed: 0.0124s/iter; left time: 189.3422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 224 | Train Loss: 0.0540937 Vali Loss: 0.0532633 Test Loss: 0.0596860\n",
      "Validation loss decreased (0.053272 --> 0.053263).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0500584\n",
      "\tspeed: 0.0301s/iter; left time: 455.6288s\n",
      "\titers: 200, epoch: 33 | loss: 0.0566356\n",
      "\tspeed: 0.0124s/iter; left time: 186.4028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0540433 Vali Loss: 0.0532675 Test Loss: 0.0597175\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0542595\n",
      "\tspeed: 0.0311s/iter; left time: 463.2475s\n",
      "\titers: 200, epoch: 34 | loss: 0.0545629\n",
      "\tspeed: 0.0152s/iter; left time: 224.6301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 224 | Train Loss: 0.0540169 Vali Loss: 0.0532733 Test Loss: 0.0596260\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0520636\n",
      "\tspeed: 0.0317s/iter; left time: 465.9252s\n",
      "\titers: 200, epoch: 35 | loss: 0.0525975\n",
      "\tspeed: 0.0143s/iter; left time: 208.9301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 224 | Train Loss: 0.0540359 Vali Loss: 0.0532681 Test Loss: 0.0596436\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0534087\n",
      "\tspeed: 0.0310s/iter; left time: 448.0494s\n",
      "\titers: 200, epoch: 36 | loss: 0.0518873\n",
      "\tspeed: 0.0124s/iter; left time: 177.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0539461 Vali Loss: 0.0532098 Test Loss: 0.0596426\n",
      "Validation loss decreased (0.053263 --> 0.053210).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0523269\n",
      "\tspeed: 0.0333s/iter; left time: 473.4785s\n",
      "\titers: 200, epoch: 37 | loss: 0.0545035\n",
      "\tspeed: 0.0154s/iter; left time: 218.2404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 224 | Train Loss: 0.0539576 Vali Loss: 0.0531615 Test Loss: 0.0595651\n",
      "Validation loss decreased (0.053210 --> 0.053161).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0571362\n",
      "\tspeed: 0.0307s/iter; left time: 430.5327s\n",
      "\titers: 200, epoch: 38 | loss: 0.0537782\n",
      "\tspeed: 0.0133s/iter; left time: 185.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0539978 Vali Loss: 0.0532383 Test Loss: 0.0595554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0521768\n",
      "\tspeed: 0.0304s/iter; left time: 419.6813s\n",
      "\titers: 200, epoch: 39 | loss: 0.0535663\n",
      "\tspeed: 0.0125s/iter; left time: 170.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0539193 Vali Loss: 0.0532262 Test Loss: 0.0596267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0550007\n",
      "\tspeed: 0.0304s/iter; left time: 412.8919s\n",
      "\titers: 200, epoch: 40 | loss: 0.0533863\n",
      "\tspeed: 0.0124s/iter; left time: 166.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0539388 Vali Loss: 0.0531837 Test Loss: 0.0596086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0553725\n",
      "\tspeed: 0.0303s/iter; left time: 404.4153s\n",
      "\titers: 200, epoch: 41 | loss: 0.0517051\n",
      "\tspeed: 0.0145s/iter; left time: 192.4218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 224 | Train Loss: 0.0539254 Vali Loss: 0.0531058 Test Loss: 0.0594750\n",
      "Validation loss decreased (0.053161 --> 0.053106).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0553073\n",
      "\tspeed: 0.0304s/iter; left time: 399.1938s\n",
      "\titers: 200, epoch: 42 | loss: 0.0546914\n",
      "\tspeed: 0.0128s/iter; left time: 167.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 224 | Train Loss: 0.0538614 Vali Loss: 0.0531903 Test Loss: 0.0595190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0503242\n",
      "\tspeed: 0.0317s/iter; left time: 408.9930s\n",
      "\titers: 200, epoch: 43 | loss: 0.0566136\n",
      "\tspeed: 0.0144s/iter; left time: 183.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 224 | Train Loss: 0.0538681 Vali Loss: 0.0531114 Test Loss: 0.0595558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0541324\n",
      "\tspeed: 0.0298s/iter; left time: 376.9436s\n",
      "\titers: 200, epoch: 44 | loss: 0.0546893\n",
      "\tspeed: 0.0124s/iter; left time: 155.8312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0538828 Vali Loss: 0.0531653 Test Loss: 0.0595748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0513158\n",
      "\tspeed: 0.0298s/iter; left time: 371.2725s\n",
      "\titers: 200, epoch: 45 | loss: 0.0550816\n",
      "\tspeed: 0.0132s/iter; left time: 162.3670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0538117 Vali Loss: 0.0531446 Test Loss: 0.0595459\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0550515\n",
      "\tspeed: 0.0305s/iter; left time: 372.5452s\n",
      "\titers: 200, epoch: 46 | loss: 0.0544181\n",
      "\tspeed: 0.0124s/iter; left time: 150.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.0538693 Vali Loss: 0.0531233 Test Loss: 0.0595157\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0585298\n",
      "\tspeed: 0.0321s/iter; left time: 385.1504s\n",
      "\titers: 200, epoch: 47 | loss: 0.0502051\n",
      "\tspeed: 0.0125s/iter; left time: 148.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0538014 Vali Loss: 0.0531459 Test Loss: 0.0595203\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0514469\n",
      "\tspeed: 0.0313s/iter; left time: 368.9293s\n",
      "\titers: 200, epoch: 48 | loss: 0.0496586\n",
      "\tspeed: 0.0128s/iter; left time: 149.4952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0538121 Vali Loss: 0.0531243 Test Loss: 0.0595881\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0557650\n",
      "\tspeed: 0.0314s/iter; left time: 363.0852s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518219\n",
      "\tspeed: 0.0124s/iter; left time: 141.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0538110 Vali Loss: 0.0531748 Test Loss: 0.0595133\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0544767\n",
      "\tspeed: 0.0317s/iter; left time: 359.2918s\n",
      "\titers: 200, epoch: 50 | loss: 0.0523316\n",
      "\tspeed: 0.0128s/iter; left time: 143.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0537868 Vali Loss: 0.0531098 Test Loss: 0.0595361\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525416\n",
      "\tspeed: 0.0293s/iter; left time: 325.7800s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547637\n",
      "\tspeed: 0.0149s/iter; left time: 163.8447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0537911 Vali Loss: 0.0530999 Test Loss: 0.0595540\n",
      "Validation loss decreased (0.053106 --> 0.053100).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0531155\n",
      "\tspeed: 0.0309s/iter; left time: 336.5723s\n",
      "\titers: 200, epoch: 52 | loss: 0.0512804\n",
      "\tspeed: 0.0133s/iter; left time: 142.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.0538350 Vali Loss: 0.0531810 Test Loss: 0.0595589\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0557468\n",
      "\tspeed: 0.0300s/iter; left time: 319.0644s\n",
      "\titers: 200, epoch: 53 | loss: 0.0546438\n",
      "\tspeed: 0.0124s/iter; left time: 130.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 224 | Train Loss: 0.0537961 Vali Loss: 0.0531621 Test Loss: 0.0595360\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0553301\n",
      "\tspeed: 0.0308s/iter; left time: 321.6485s\n",
      "\titers: 200, epoch: 54 | loss: 0.0554172\n",
      "\tspeed: 0.0138s/iter; left time: 142.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 224 | Train Loss: 0.0538016 Vali Loss: 0.0530790 Test Loss: 0.0595175\n",
      "Validation loss decreased (0.053100 --> 0.053079).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0540677\n",
      "\tspeed: 0.0300s/iter; left time: 306.5616s\n",
      "\titers: 200, epoch: 55 | loss: 0.0539172\n",
      "\tspeed: 0.0124s/iter; left time: 125.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.0537712 Vali Loss: 0.0531199 Test Loss: 0.0594826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0495086\n",
      "\tspeed: 0.0305s/iter; left time: 304.0360s\n",
      "\titers: 200, epoch: 56 | loss: 0.0522331\n",
      "\tspeed: 0.0128s/iter; left time: 126.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 224 | Train Loss: 0.0538154 Vali Loss: 0.0530582 Test Loss: 0.0595190\n",
      "Validation loss decreased (0.053079 --> 0.053058).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0520802\n",
      "\tspeed: 0.0312s/iter; left time: 304.1639s\n",
      "\titers: 200, epoch: 57 | loss: 0.0543556\n",
      "\tspeed: 0.0132s/iter; left time: 127.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0538059 Vali Loss: 0.0531389 Test Loss: 0.0595044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538117\n",
      "\tspeed: 0.0301s/iter; left time: 286.8984s\n",
      "\titers: 200, epoch: 58 | loss: 0.0511537\n",
      "\tspeed: 0.0124s/iter; left time: 116.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.0537977 Vali Loss: 0.0531101 Test Loss: 0.0594705\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0547721\n",
      "\tspeed: 0.0323s/iter; left time: 300.9885s\n",
      "\titers: 200, epoch: 59 | loss: 0.0520021\n",
      "\tspeed: 0.0130s/iter; left time: 119.8264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 224 | Train Loss: 0.0538014 Vali Loss: 0.0531438 Test Loss: 0.0595263\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0544137\n",
      "\tspeed: 0.0298s/iter; left time: 270.5863s\n",
      "\titers: 200, epoch: 60 | loss: 0.0545669\n",
      "\tspeed: 0.0124s/iter; left time: 111.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0537876 Vali Loss: 0.0530364 Test Loss: 0.0594853\n",
      "Validation loss decreased (0.053058 --> 0.053036).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0533388\n",
      "\tspeed: 0.0300s/iter; left time: 265.7462s\n",
      "\titers: 200, epoch: 61 | loss: 0.0554440\n",
      "\tspeed: 0.0129s/iter; left time: 112.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0538040 Vali Loss: 0.0531370 Test Loss: 0.0595620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0510084\n",
      "\tspeed: 0.0308s/iter; left time: 265.6739s\n",
      "\titers: 200, epoch: 62 | loss: 0.0551622\n",
      "\tspeed: 0.0168s/iter; left time: 143.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 224 | Train Loss: 0.0538182 Vali Loss: 0.0531115 Test Loss: 0.0595177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0538713\n",
      "\tspeed: 0.0344s/iter; left time: 289.6835s\n",
      "\titers: 200, epoch: 63 | loss: 0.0513479\n",
      "\tspeed: 0.0142s/iter; left time: 118.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0537150 Vali Loss: 0.0530949 Test Loss: 0.0595163\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0527010\n",
      "\tspeed: 0.0302s/iter; left time: 247.4757s\n",
      "\titers: 200, epoch: 64 | loss: 0.0505448\n",
      "\tspeed: 0.0125s/iter; left time: 100.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0537999 Vali Loss: 0.0531405 Test Loss: 0.0595039\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0540351\n",
      "\tspeed: 0.0346s/iter; left time: 275.7515s\n",
      "\titers: 200, epoch: 65 | loss: 0.0526464\n",
      "\tspeed: 0.0168s/iter; left time: 131.7833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 224 | Train Loss: 0.0537007 Vali Loss: 0.0530991 Test Loss: 0.0594807\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0545687\n",
      "\tspeed: 0.0315s/iter; left time: 243.6600s\n",
      "\titers: 200, epoch: 66 | loss: 0.0562715\n",
      "\tspeed: 0.0125s/iter; left time: 95.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0538190 Vali Loss: 0.0531063 Test Loss: 0.0595124\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0529547\n",
      "\tspeed: 0.0300s/iter; left time: 225.2901s\n",
      "\titers: 200, epoch: 67 | loss: 0.0540814\n",
      "\tspeed: 0.0126s/iter; left time: 93.4676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0538217 Vali Loss: 0.0530404 Test Loss: 0.0594309\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0516211\n",
      "\tspeed: 0.0309s/iter; left time: 225.1525s\n",
      "\titers: 200, epoch: 68 | loss: 0.0561957\n",
      "\tspeed: 0.0157s/iter; left time: 112.6803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0537775 Vali Loss: 0.0530743 Test Loss: 0.0594759\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0511297\n",
      "\tspeed: 0.0306s/iter; left time: 216.5150s\n",
      "\titers: 200, epoch: 69 | loss: 0.0535428\n",
      "\tspeed: 0.0124s/iter; left time: 86.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0537763 Vali Loss: 0.0531100 Test Loss: 0.0594881\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0533147\n",
      "\tspeed: 0.0326s/iter; left time: 223.1991s\n",
      "\titers: 200, epoch: 70 | loss: 0.0536659\n",
      "\tspeed: 0.0148s/iter; left time: 99.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 224 | Train Loss: 0.0537747 Vali Loss: 0.0531239 Test Loss: 0.0594974\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00973607785999775, rmse:0.0986715629696846, mae:0.05948532000184059, rse:0.29037848114967346\n",
      "Intermediate time for ES and pred_len 24: 00h:09m:22.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1468400\n",
      "\tspeed: 0.0401s/iter; left time: 895.2957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232552\n",
      "\tspeed: 0.0127s/iter; left time: 281.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 224 | Train Loss: 0.1487494 Vali Loss: 0.1126049 Test Loss: 0.1268169\n",
      "Validation loss decreased (inf --> 0.112605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0997134\n",
      "\tspeed: 0.0349s/iter; left time: 771.5756s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949578\n",
      "\tspeed: 0.0138s/iter; left time: 302.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0972749 Vali Loss: 0.0875713 Test Loss: 0.0982403\n",
      "Validation loss decreased (0.112605 --> 0.087571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0868003\n",
      "\tspeed: 0.0334s/iter; left time: 729.4902s\n",
      "\titers: 200, epoch: 3 | loss: 0.0833299\n",
      "\tspeed: 0.0128s/iter; left time: 278.7531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0879120 Vali Loss: 0.0820683 Test Loss: 0.0931008\n",
      "Validation loss decreased (0.087571 --> 0.082068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0813625\n",
      "\tspeed: 0.0324s/iter; left time: 700.8373s\n",
      "\titers: 200, epoch: 4 | loss: 0.0823146\n",
      "\tspeed: 0.0139s/iter; left time: 298.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 224 | Train Loss: 0.0842708 Vali Loss: 0.0798243 Test Loss: 0.0908691\n",
      "Validation loss decreased (0.082068 --> 0.079824).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803766\n",
      "\tspeed: 0.0346s/iter; left time: 741.4960s\n",
      "\titers: 200, epoch: 5 | loss: 0.0821054\n",
      "\tspeed: 0.0132s/iter; left time: 281.4181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 224 | Train Loss: 0.0821298 Vali Loss: 0.0787687 Test Loss: 0.0899156\n",
      "Validation loss decreased (0.079824 --> 0.078769).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834553\n",
      "\tspeed: 0.0315s/iter; left time: 666.5784s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793621\n",
      "\tspeed: 0.0126s/iter; left time: 266.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0808472 Vali Loss: 0.0778861 Test Loss: 0.0887596\n",
      "Validation loss decreased (0.078769 --> 0.077886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0809939\n",
      "\tspeed: 0.0374s/iter; left time: 784.5781s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804217\n",
      "\tspeed: 0.0202s/iter; left time: 421.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0798516 Vali Loss: 0.0775900 Test Loss: 0.0881740\n",
      "Validation loss decreased (0.077886 --> 0.077590).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0788476\n",
      "\tspeed: 0.0330s/iter; left time: 683.6985s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790137\n",
      "\tspeed: 0.0129s/iter; left time: 266.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0791280 Vali Loss: 0.0774345 Test Loss: 0.0885318\n",
      "Validation loss decreased (0.077590 --> 0.077434).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0784681\n",
      "\tspeed: 0.0349s/iter; left time: 716.0670s\n",
      "\titers: 200, epoch: 9 | loss: 0.0744130\n",
      "\tspeed: 0.0129s/iter; left time: 263.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 224 | Train Loss: 0.0784969 Vali Loss: 0.0766449 Test Loss: 0.0876954\n",
      "Validation loss decreased (0.077434 --> 0.076645).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0765372\n",
      "\tspeed: 0.0331s/iter; left time: 671.3928s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767164\n",
      "\tspeed: 0.0127s/iter; left time: 255.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 224 | Train Loss: 0.0779591 Vali Loss: 0.0763461 Test Loss: 0.0873259\n",
      "Validation loss decreased (0.076645 --> 0.076346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0806388\n",
      "\tspeed: 0.0335s/iter; left time: 672.8990s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797773\n",
      "\tspeed: 0.0153s/iter; left time: 304.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 224 | Train Loss: 0.0775189 Vali Loss: 0.0763474 Test Loss: 0.0872889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767406\n",
      "\tspeed: 0.0330s/iter; left time: 654.0424s\n",
      "\titers: 200, epoch: 12 | loss: 0.0777284\n",
      "\tspeed: 0.0126s/iter; left time: 248.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 224 | Train Loss: 0.0771779 Vali Loss: 0.0765048 Test Loss: 0.0869703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817986\n",
      "\tspeed: 0.0356s/iter; left time: 698.7516s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782859\n",
      "\tspeed: 0.0175s/iter; left time: 340.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0768909 Vali Loss: 0.0761573 Test Loss: 0.0871293\n",
      "Validation loss decreased (0.076346 --> 0.076157).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764247\n",
      "\tspeed: 0.0344s/iter; left time: 667.6503s\n",
      "\titers: 200, epoch: 14 | loss: 0.0769282\n",
      "\tspeed: 0.0153s/iter; left time: 295.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0765794 Vali Loss: 0.0761985 Test Loss: 0.0866737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782356\n",
      "\tspeed: 0.0331s/iter; left time: 634.0864s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799452\n",
      "\tspeed: 0.0127s/iter; left time: 241.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 224 | Train Loss: 0.0763542 Vali Loss: 0.0759994 Test Loss: 0.0868692\n",
      "Validation loss decreased (0.076157 --> 0.075999).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0781991\n",
      "\tspeed: 0.0329s/iter; left time: 622.4526s\n",
      "\titers: 200, epoch: 16 | loss: 0.0771706\n",
      "\tspeed: 0.0146s/iter; left time: 274.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0761841 Vali Loss: 0.0760745 Test Loss: 0.0868069\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0759007\n",
      "\tspeed: 0.0344s/iter; left time: 643.7980s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778819\n",
      "\tspeed: 0.0136s/iter; left time: 253.4793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 224 | Train Loss: 0.0760407 Vali Loss: 0.0759646 Test Loss: 0.0865455\n",
      "Validation loss decreased (0.075999 --> 0.075965).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0751718\n",
      "\tspeed: 0.0319s/iter; left time: 590.3085s\n",
      "\titers: 200, epoch: 18 | loss: 0.0768914\n",
      "\tspeed: 0.0129s/iter; left time: 238.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0758133 Vali Loss: 0.0760771 Test Loss: 0.0865404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766536\n",
      "\tspeed: 0.0360s/iter; left time: 657.9910s\n",
      "\titers: 200, epoch: 19 | loss: 0.0743595\n",
      "\tspeed: 0.0158s/iter; left time: 287.5002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0757443 Vali Loss: 0.0758645 Test Loss: 0.0865021\n",
      "Validation loss decreased (0.075965 --> 0.075864).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743717\n",
      "\tspeed: 0.0338s/iter; left time: 609.6761s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733243\n",
      "\tspeed: 0.0127s/iter; left time: 228.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0756088 Vali Loss: 0.0758198 Test Loss: 0.0863493\n",
      "Validation loss decreased (0.075864 --> 0.075820).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0745691\n",
      "\tspeed: 0.0327s/iter; left time: 583.0731s\n",
      "\titers: 200, epoch: 21 | loss: 0.0813978\n",
      "\tspeed: 0.0129s/iter; left time: 228.0496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0754841 Vali Loss: 0.0759028 Test Loss: 0.0865787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0743274\n",
      "\tspeed: 0.0332s/iter; left time: 583.6373s\n",
      "\titers: 200, epoch: 22 | loss: 0.0752125\n",
      "\tspeed: 0.0126s/iter; left time: 220.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0753413 Vali Loss: 0.0758487 Test Loss: 0.0864664\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0773356\n",
      "\tspeed: 0.0361s/iter; left time: 627.3113s\n",
      "\titers: 200, epoch: 23 | loss: 0.0770110\n",
      "\tspeed: 0.0136s/iter; left time: 235.3718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 224 | Train Loss: 0.0753310 Vali Loss: 0.0758414 Test Loss: 0.0864566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0771433\n",
      "\tspeed: 0.0305s/iter; left time: 523.0485s\n",
      "\titers: 200, epoch: 24 | loss: 0.0730931\n",
      "\tspeed: 0.0127s/iter; left time: 216.2986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 224 | Train Loss: 0.0752107 Vali Loss: 0.0757442 Test Loss: 0.0863572\n",
      "Validation loss decreased (0.075820 --> 0.075744).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0732026\n",
      "\tspeed: 0.0355s/iter; left time: 601.6322s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721769\n",
      "\tspeed: 0.0188s/iter; left time: 316.7056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0751781 Vali Loss: 0.0757918 Test Loss: 0.0863979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0740754\n",
      "\tspeed: 0.0334s/iter; left time: 558.3697s\n",
      "\titers: 200, epoch: 26 | loss: 0.0751898\n",
      "\tspeed: 0.0129s/iter; left time: 213.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 224 | Train Loss: 0.0750762 Vali Loss: 0.0757368 Test Loss: 0.0863081\n",
      "Validation loss decreased (0.075744 --> 0.075737).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747075\n",
      "\tspeed: 0.0312s/iter; left time: 514.5688s\n",
      "\titers: 200, epoch: 27 | loss: 0.0736839\n",
      "\tspeed: 0.0136s/iter; left time: 222.9468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0750206 Vali Loss: 0.0758148 Test Loss: 0.0864835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0725433\n",
      "\tspeed: 0.0318s/iter; left time: 516.2192s\n",
      "\titers: 200, epoch: 28 | loss: 0.0771146\n",
      "\tspeed: 0.0155s/iter; left time: 250.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0749778 Vali Loss: 0.0759712 Test Loss: 0.0862643\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0776515\n",
      "\tspeed: 0.0342s/iter; left time: 548.2385s\n",
      "\titers: 200, epoch: 29 | loss: 0.0705761\n",
      "\tspeed: 0.0140s/iter; left time: 222.8578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0749419 Vali Loss: 0.0757983 Test Loss: 0.0862841\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0695795\n",
      "\tspeed: 0.0332s/iter; left time: 524.4095s\n",
      "\titers: 200, epoch: 30 | loss: 0.0757099\n",
      "\tspeed: 0.0127s/iter; left time: 199.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 224 | Train Loss: 0.0749575 Vali Loss: 0.0758891 Test Loss: 0.0863262\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0775752\n",
      "\tspeed: 0.0331s/iter; left time: 515.2079s\n",
      "\titers: 200, epoch: 31 | loss: 0.0755311\n",
      "\tspeed: 0.0127s/iter; left time: 196.6941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0748478 Vali Loss: 0.0759212 Test Loss: 0.0863854\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0730617\n",
      "\tspeed: 0.0333s/iter; left time: 511.0702s\n",
      "\titers: 200, epoch: 32 | loss: 0.0759544\n",
      "\tspeed: 0.0127s/iter; left time: 193.7710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 224 | Train Loss: 0.0748142 Vali Loss: 0.0758465 Test Loss: 0.0861799\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0762628\n",
      "\tspeed: 0.0309s/iter; left time: 467.9561s\n",
      "\titers: 200, epoch: 33 | loss: 0.0748202\n",
      "\tspeed: 0.0127s/iter; left time: 191.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0747746 Vali Loss: 0.0757104 Test Loss: 0.0862173\n",
      "Validation loss decreased (0.075737 --> 0.075710).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0760764\n",
      "\tspeed: 0.0335s/iter; left time: 499.1511s\n",
      "\titers: 200, epoch: 34 | loss: 0.0791079\n",
      "\tspeed: 0.0130s/iter; left time: 192.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.0748080 Vali Loss: 0.0757319 Test Loss: 0.0862865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0744127\n",
      "\tspeed: 0.0340s/iter; left time: 499.2882s\n",
      "\titers: 200, epoch: 35 | loss: 0.0722204\n",
      "\tspeed: 0.0162s/iter; left time: 236.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 224 | Train Loss: 0.0747407 Vali Loss: 0.0757823 Test Loss: 0.0861773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0758465\n",
      "\tspeed: 0.0318s/iter; left time: 460.1681s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743944\n",
      "\tspeed: 0.0134s/iter; left time: 193.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0747572 Vali Loss: 0.0757863 Test Loss: 0.0863018\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0738689\n",
      "\tspeed: 0.0328s/iter; left time: 466.6155s\n",
      "\titers: 200, epoch: 37 | loss: 0.0744384\n",
      "\tspeed: 0.0128s/iter; left time: 180.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0746982 Vali Loss: 0.0757288 Test Loss: 0.0861792\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0717608\n",
      "\tspeed: 0.0313s/iter; left time: 439.0581s\n",
      "\titers: 200, epoch: 38 | loss: 0.0741143\n",
      "\tspeed: 0.0127s/iter; left time: 177.2810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0746739 Vali Loss: 0.0757153 Test Loss: 0.0861892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0728255\n",
      "\tspeed: 0.0306s/iter; left time: 421.9841s\n",
      "\titers: 200, epoch: 39 | loss: 0.0716758\n",
      "\tspeed: 0.0127s/iter; left time: 174.3103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0747081 Vali Loss: 0.0757539 Test Loss: 0.0862267\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0745876\n",
      "\tspeed: 0.0327s/iter; left time: 443.4786s\n",
      "\titers: 200, epoch: 40 | loss: 0.0724062\n",
      "\tspeed: 0.0129s/iter; left time: 173.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 224 | Train Loss: 0.0746947 Vali Loss: 0.0757588 Test Loss: 0.0862861\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0750171\n",
      "\tspeed: 0.0305s/iter; left time: 406.5053s\n",
      "\titers: 200, epoch: 41 | loss: 0.0724968\n",
      "\tspeed: 0.0127s/iter; left time: 167.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.0745967 Vali Loss: 0.0757351 Test Loss: 0.0861879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0808127\n",
      "\tspeed: 0.0327s/iter; left time: 429.1209s\n",
      "\titers: 200, epoch: 42 | loss: 0.0716565\n",
      "\tspeed: 0.0136s/iter; left time: 176.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 224 | Train Loss: 0.0746502 Vali Loss: 0.0757814 Test Loss: 0.0862281\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0714690\n",
      "\tspeed: 0.0313s/iter; left time: 403.0563s\n",
      "\titers: 200, epoch: 43 | loss: 0.0752003\n",
      "\tspeed: 0.0159s/iter; left time: 203.6208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 224 | Train Loss: 0.0746084 Vali Loss: 0.0757507 Test Loss: 0.0862182\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01843559555709362, rmse:0.13577774167060852, mae:0.08621731400489807, rse:0.3988741636276245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1459682\n",
      "\tspeed: 0.0157s/iter; left time: 350.4678s\n",
      "\titers: 200, epoch: 1 | loss: 0.1241308\n",
      "\tspeed: 0.0135s/iter; left time: 299.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 224 | Train Loss: 0.1474566 Vali Loss: 0.1119465 Test Loss: 0.1257237\n",
      "Validation loss decreased (inf --> 0.111947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918303\n",
      "\tspeed: 0.0377s/iter; left time: 832.0342s\n",
      "\titers: 200, epoch: 2 | loss: 0.0921925\n",
      "\tspeed: 0.0172s/iter; left time: 377.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0967843 Vali Loss: 0.0879007 Test Loss: 0.0984314\n",
      "Validation loss decreased (0.111947 --> 0.087901).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860915\n",
      "\tspeed: 0.0346s/iter; left time: 755.7446s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871424\n",
      "\tspeed: 0.0127s/iter; left time: 275.2881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 224 | Train Loss: 0.0879923 Vali Loss: 0.0826635 Test Loss: 0.0936844\n",
      "Validation loss decreased (0.087901 --> 0.082664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0834486\n",
      "\tspeed: 0.0314s/iter; left time: 679.3984s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806814\n",
      "\tspeed: 0.0126s/iter; left time: 272.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.0841942 Vali Loss: 0.0797406 Test Loss: 0.0907403\n",
      "Validation loss decreased (0.082664 --> 0.079741).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0848270\n",
      "\tspeed: 0.0345s/iter; left time: 738.7552s\n",
      "\titers: 200, epoch: 5 | loss: 0.0840470\n",
      "\tspeed: 0.0161s/iter; left time: 343.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 224 | Train Loss: 0.0821317 Vali Loss: 0.0783175 Test Loss: 0.0893664\n",
      "Validation loss decreased (0.079741 --> 0.078318).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807788\n",
      "\tspeed: 0.0340s/iter; left time: 720.8332s\n",
      "\titers: 200, epoch: 6 | loss: 0.0834602\n",
      "\tspeed: 0.0134s/iter; left time: 281.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 224 | Train Loss: 0.0807993 Vali Loss: 0.0779212 Test Loss: 0.0887780\n",
      "Validation loss decreased (0.078318 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764753\n",
      "\tspeed: 0.0361s/iter; left time: 756.1118s\n",
      "\titers: 200, epoch: 7 | loss: 0.0841446\n",
      "\tspeed: 0.0155s/iter; left time: 323.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 224 | Train Loss: 0.0797098 Vali Loss: 0.0774594 Test Loss: 0.0881515\n",
      "Validation loss decreased (0.077921 --> 0.077459).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736670\n",
      "\tspeed: 0.0336s/iter; left time: 697.5158s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776215\n",
      "\tspeed: 0.0164s/iter; left time: 339.2765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 224 | Train Loss: 0.0789763 Vali Loss: 0.0768919 Test Loss: 0.0878309\n",
      "Validation loss decreased (0.077459 --> 0.076892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746747\n",
      "\tspeed: 0.0328s/iter; left time: 673.5657s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747335\n",
      "\tspeed: 0.0127s/iter; left time: 259.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0783495 Vali Loss: 0.0764817 Test Loss: 0.0872476\n",
      "Validation loss decreased (0.076892 --> 0.076482).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772358\n",
      "\tspeed: 0.0350s/iter; left time: 709.2646s\n",
      "\titers: 200, epoch: 10 | loss: 0.0759152\n",
      "\tspeed: 0.0171s/iter; left time: 345.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0778967 Vali Loss: 0.0767464 Test Loss: 0.0872352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0790324\n",
      "\tspeed: 0.0343s/iter; left time: 687.2091s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776360\n",
      "\tspeed: 0.0136s/iter; left time: 271.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0774438 Vali Loss: 0.0762204 Test Loss: 0.0868346\n",
      "Validation loss decreased (0.076482 --> 0.076220).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0764487\n",
      "\tspeed: 0.0348s/iter; left time: 690.0125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0758275\n",
      "\tspeed: 0.0175s/iter; left time: 346.0316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 224 | Train Loss: 0.0771044 Vali Loss: 0.0763191 Test Loss: 0.0868724\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718672\n",
      "\tspeed: 0.0371s/iter; left time: 727.5353s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761693\n",
      "\tspeed: 0.0164s/iter; left time: 320.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 224 | Train Loss: 0.0767931 Vali Loss: 0.0760071 Test Loss: 0.0867123\n",
      "Validation loss decreased (0.076220 --> 0.076007).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0780695\n",
      "\tspeed: 0.0321s/iter; left time: 622.5047s\n",
      "\titers: 200, epoch: 14 | loss: 0.0787371\n",
      "\tspeed: 0.0127s/iter; left time: 244.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 224 | Train Loss: 0.0765520 Vali Loss: 0.0761902 Test Loss: 0.0865391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0741081\n",
      "\tspeed: 0.0332s/iter; left time: 636.2801s\n",
      "\titers: 200, epoch: 15 | loss: 0.0765818\n",
      "\tspeed: 0.0134s/iter; left time: 254.8847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 224 | Train Loss: 0.0762961 Vali Loss: 0.0760151 Test Loss: 0.0865599\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0751503\n",
      "\tspeed: 0.0337s/iter; left time: 639.2217s\n",
      "\titers: 200, epoch: 16 | loss: 0.0756685\n",
      "\tspeed: 0.0135s/iter; left time: 253.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 224 | Train Loss: 0.0760962 Vali Loss: 0.0760833 Test Loss: 0.0863364\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0762167\n",
      "\tspeed: 0.0320s/iter; left time: 598.5891s\n",
      "\titers: 200, epoch: 17 | loss: 0.0720553\n",
      "\tspeed: 0.0127s/iter; left time: 235.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 224 | Train Loss: 0.0758834 Vali Loss: 0.0758874 Test Loss: 0.0864260\n",
      "Validation loss decreased (0.076007 --> 0.075887).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766128\n",
      "\tspeed: 0.0345s/iter; left time: 638.8288s\n",
      "\titers: 200, epoch: 18 | loss: 0.0746352\n",
      "\tspeed: 0.0134s/iter; left time: 245.9771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 224 | Train Loss: 0.0757757 Vali Loss: 0.0758876 Test Loss: 0.0861741\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0763244\n",
      "\tspeed: 0.0346s/iter; left time: 632.0699s\n",
      "\titers: 200, epoch: 19 | loss: 0.0757160\n",
      "\tspeed: 0.0148s/iter; left time: 269.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0755963 Vali Loss: 0.0759528 Test Loss: 0.0861244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0785197\n",
      "\tspeed: 0.0351s/iter; left time: 632.6513s\n",
      "\titers: 200, epoch: 20 | loss: 0.0742307\n",
      "\tspeed: 0.0152s/iter; left time: 272.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 224 | Train Loss: 0.0754855 Vali Loss: 0.0756837 Test Loss: 0.0861177\n",
      "Validation loss decreased (0.075887 --> 0.075684).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0736889\n",
      "\tspeed: 0.0325s/iter; left time: 578.4438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0767437\n",
      "\tspeed: 0.0127s/iter; left time: 224.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 224 | Train Loss: 0.0754053 Vali Loss: 0.0755407 Test Loss: 0.0859788\n",
      "Validation loss decreased (0.075684 --> 0.075541).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0773565\n",
      "\tspeed: 0.0330s/iter; left time: 580.9762s\n",
      "\titers: 200, epoch: 22 | loss: 0.0774874\n",
      "\tspeed: 0.0149s/iter; left time: 260.5587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 224 | Train Loss: 0.0753072 Vali Loss: 0.0756376 Test Loss: 0.0860564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0756626\n",
      "\tspeed: 0.0351s/iter; left time: 610.0749s\n",
      "\titers: 200, epoch: 23 | loss: 0.0707311\n",
      "\tspeed: 0.0129s/iter; left time: 222.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 224 | Train Loss: 0.0751855 Vali Loss: 0.0755963 Test Loss: 0.0859183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0757168\n",
      "\tspeed: 0.0323s/iter; left time: 554.0130s\n",
      "\titers: 200, epoch: 24 | loss: 0.0741730\n",
      "\tspeed: 0.0131s/iter; left time: 224.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0751056 Vali Loss: 0.0756576 Test Loss: 0.0859916\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770389\n",
      "\tspeed: 0.0338s/iter; left time: 572.8654s\n",
      "\titers: 200, epoch: 25 | loss: 0.0749975\n",
      "\tspeed: 0.0138s/iter; left time: 232.0638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 224 | Train Loss: 0.0751059 Vali Loss: 0.0755141 Test Loss: 0.0859115\n",
      "Validation loss decreased (0.075541 --> 0.075514).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0729992\n",
      "\tspeed: 0.0332s/iter; left time: 554.7868s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739465\n",
      "\tspeed: 0.0172s/iter; left time: 286.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 224 | Train Loss: 0.0749975 Vali Loss: 0.0755443 Test Loss: 0.0858786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0738025\n",
      "\tspeed: 0.0322s/iter; left time: 530.7502s\n",
      "\titers: 200, epoch: 27 | loss: 0.0733412\n",
      "\tspeed: 0.0135s/iter; left time: 221.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0749626 Vali Loss: 0.0756904 Test Loss: 0.0859533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0778724\n",
      "\tspeed: 0.0337s/iter; left time: 547.8232s\n",
      "\titers: 200, epoch: 28 | loss: 0.0720507\n",
      "\tspeed: 0.0127s/iter; left time: 204.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 224 | Train Loss: 0.0749215 Vali Loss: 0.0754557 Test Loss: 0.0858275\n",
      "Validation loss decreased (0.075514 --> 0.075456).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0739187\n",
      "\tspeed: 0.0359s/iter; left time: 575.9377s\n",
      "\titers: 200, epoch: 29 | loss: 0.0716530\n",
      "\tspeed: 0.0161s/iter; left time: 257.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 224 | Train Loss: 0.0747935 Vali Loss: 0.0755389 Test Loss: 0.0858605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0753577\n",
      "\tspeed: 0.0326s/iter; left time: 516.0078s\n",
      "\titers: 200, epoch: 30 | loss: 0.0797524\n",
      "\tspeed: 0.0127s/iter; left time: 198.9025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0748646 Vali Loss: 0.0756154 Test Loss: 0.0858355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0763943\n",
      "\tspeed: 0.0316s/iter; left time: 491.6367s\n",
      "\titers: 200, epoch: 31 | loss: 0.0714904\n",
      "\tspeed: 0.0126s/iter; left time: 195.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.0747468 Vali Loss: 0.0757150 Test Loss: 0.0858850\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0718360\n",
      "\tspeed: 0.0372s/iter; left time: 571.8416s\n",
      "\titers: 200, epoch: 32 | loss: 0.0714721\n",
      "\tspeed: 0.0166s/iter; left time: 253.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0747459 Vali Loss: 0.0755740 Test Loss: 0.0857875\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0758766\n",
      "\tspeed: 0.0316s/iter; left time: 478.2267s\n",
      "\titers: 200, epoch: 33 | loss: 0.0724604\n",
      "\tspeed: 0.0160s/iter; left time: 240.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 224 | Train Loss: 0.0746983 Vali Loss: 0.0756245 Test Loss: 0.0858066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0751932\n",
      "\tspeed: 0.0321s/iter; left time: 478.5499s\n",
      "\titers: 200, epoch: 34 | loss: 0.0745194\n",
      "\tspeed: 0.0126s/iter; left time: 187.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 224 | Train Loss: 0.0746754 Vali Loss: 0.0756697 Test Loss: 0.0857856\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0712382\n",
      "\tspeed: 0.0336s/iter; left time: 494.0214s\n",
      "\titers: 200, epoch: 35 | loss: 0.0767579\n",
      "\tspeed: 0.0142s/iter; left time: 207.1210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 224 | Train Loss: 0.0746145 Vali Loss: 0.0756619 Test Loss: 0.0857833\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0723625\n",
      "\tspeed: 0.0354s/iter; left time: 511.6080s\n",
      "\titers: 200, epoch: 36 | loss: 0.0753322\n",
      "\tspeed: 0.0143s/iter; left time: 204.9017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 224 | Train Loss: 0.0746386 Vali Loss: 0.0755051 Test Loss: 0.0857492\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0714901\n",
      "\tspeed: 0.0323s/iter; left time: 459.7517s\n",
      "\titers: 200, epoch: 37 | loss: 0.0763826\n",
      "\tspeed: 0.0127s/iter; left time: 179.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 224 | Train Loss: 0.0746525 Vali Loss: 0.0755915 Test Loss: 0.0857468\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0773016\n",
      "\tspeed: 0.0317s/iter; left time: 444.5562s\n",
      "\titers: 200, epoch: 38 | loss: 0.0713082\n",
      "\tspeed: 0.0127s/iter; left time: 176.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0745897 Vali Loss: 0.0756364 Test Loss: 0.0858203\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01835753582417965, rmse:0.13548998534679413, mae:0.08582748472690582, rse:0.39802882075309753\n",
      "Intermediate time for ES and pred_len 96: 00h:06m:36.44s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1426952\n",
      "\tspeed: 0.0386s/iter; left time: 856.2813s\n",
      "\titers: 200, epoch: 1 | loss: 0.1257764\n",
      "\tspeed: 0.0138s/iter; left time: 304.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.1490935 Vali Loss: 0.1151372 Test Loss: 0.1284923\n",
      "Validation loss decreased (inf --> 0.115137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0975357\n",
      "\tspeed: 0.0348s/iter; left time: 765.0334s\n",
      "\titers: 200, epoch: 2 | loss: 0.0961228\n",
      "\tspeed: 0.0151s/iter; left time: 330.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 223 | Train Loss: 0.1010134 Vali Loss: 0.0924055 Test Loss: 0.1033997\n",
      "Validation loss decreased (0.115137 --> 0.092406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933916\n",
      "\tspeed: 0.0320s/iter; left time: 695.1585s\n",
      "\titers: 200, epoch: 3 | loss: 0.0887781\n",
      "\tspeed: 0.0128s/iter; left time: 278.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0925811 Vali Loss: 0.0880209 Test Loss: 0.0985914\n",
      "Validation loss decreased (0.092406 --> 0.088021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0899815\n",
      "\tspeed: 0.0326s/iter; left time: 702.7647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0885130\n",
      "\tspeed: 0.0176s/iter; left time: 377.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0891123 Vali Loss: 0.0859459 Test Loss: 0.0965789\n",
      "Validation loss decreased (0.088021 --> 0.085946).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0820367\n",
      "\tspeed: 0.0347s/iter; left time: 739.6060s\n",
      "\titers: 200, epoch: 5 | loss: 0.0877002\n",
      "\tspeed: 0.0155s/iter; left time: 328.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 223 | Train Loss: 0.0871848 Vali Loss: 0.0846888 Test Loss: 0.0954342\n",
      "Validation loss decreased (0.085946 --> 0.084689).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844401\n",
      "\tspeed: 0.0365s/iter; left time: 769.8341s\n",
      "\titers: 200, epoch: 6 | loss: 0.0852726\n",
      "\tspeed: 0.0153s/iter; left time: 321.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 223 | Train Loss: 0.0858367 Vali Loss: 0.0835759 Test Loss: 0.0946998\n",
      "Validation loss decreased (0.084689 --> 0.083576).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0814573\n",
      "\tspeed: 0.0351s/iter; left time: 732.6668s\n",
      "\titers: 200, epoch: 7 | loss: 0.0871445\n",
      "\tspeed: 0.0148s/iter; left time: 306.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0848770 Vali Loss: 0.0830702 Test Loss: 0.0938276\n",
      "Validation loss decreased (0.083576 --> 0.083070).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0837773\n",
      "\tspeed: 0.0336s/iter; left time: 694.0927s\n",
      "\titers: 200, epoch: 8 | loss: 0.0771854\n",
      "\tspeed: 0.0138s/iter; left time: 282.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 223 | Train Loss: 0.0840813 Vali Loss: 0.0823467 Test Loss: 0.0935658\n",
      "Validation loss decreased (0.083070 --> 0.082347).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0827388\n",
      "\tspeed: 0.0345s/iter; left time: 704.6170s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846697\n",
      "\tspeed: 0.0156s/iter; left time: 317.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0834983 Vali Loss: 0.0824262 Test Loss: 0.0933918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0823700\n",
      "\tspeed: 0.0313s/iter; left time: 632.8538s\n",
      "\titers: 200, epoch: 10 | loss: 0.0814517\n",
      "\tspeed: 0.0129s/iter; left time: 258.9674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.0830283 Vali Loss: 0.0825351 Test Loss: 0.0930737\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0857472\n",
      "\tspeed: 0.0345s/iter; left time: 688.8309s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827915\n",
      "\tspeed: 0.0136s/iter; left time: 270.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 223 | Train Loss: 0.0826081 Vali Loss: 0.0818929 Test Loss: 0.0925488\n",
      "Validation loss decreased (0.082347 --> 0.081893).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0842591\n",
      "\tspeed: 0.0332s/iter; left time: 654.9097s\n",
      "\titers: 200, epoch: 12 | loss: 0.0809393\n",
      "\tspeed: 0.0128s/iter; left time: 252.3587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0822712 Vali Loss: 0.0820797 Test Loss: 0.0930032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0801710\n",
      "\tspeed: 0.0353s/iter; left time: 689.2667s\n",
      "\titers: 200, epoch: 13 | loss: 0.0816530\n",
      "\tspeed: 0.0169s/iter; left time: 327.7918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 223 | Train Loss: 0.0819320 Vali Loss: 0.0817904 Test Loss: 0.0924388\n",
      "Validation loss decreased (0.081893 --> 0.081790).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0837388\n",
      "\tspeed: 0.0323s/iter; left time: 624.3439s\n",
      "\titers: 200, epoch: 14 | loss: 0.0802476\n",
      "\tspeed: 0.0128s/iter; left time: 245.8319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0817028 Vali Loss: 0.0817052 Test Loss: 0.0924333\n",
      "Validation loss decreased (0.081790 --> 0.081705).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0826058\n",
      "\tspeed: 0.0370s/iter; left time: 704.9873s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799740\n",
      "\tspeed: 0.0141s/iter; left time: 267.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0815291 Vali Loss: 0.0817491 Test Loss: 0.0925842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0834640\n",
      "\tspeed: 0.0317s/iter; left time: 597.7276s\n",
      "\titers: 200, epoch: 16 | loss: 0.0806538\n",
      "\tspeed: 0.0128s/iter; left time: 239.9206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 223 | Train Loss: 0.0812805 Vali Loss: 0.0816654 Test Loss: 0.0924281\n",
      "Validation loss decreased (0.081705 --> 0.081665).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0825423\n",
      "\tspeed: 0.0322s/iter; left time: 600.6193s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813875\n",
      "\tspeed: 0.0170s/iter; left time: 314.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.0811457 Vali Loss: 0.0813805 Test Loss: 0.0921845\n",
      "Validation loss decreased (0.081665 --> 0.081380).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0794470\n",
      "\tspeed: 0.0336s/iter; left time: 618.6369s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812129\n",
      "\tspeed: 0.0127s/iter; left time: 233.2944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0809723 Vali Loss: 0.0814762 Test Loss: 0.0923305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0798765\n",
      "\tspeed: 0.0344s/iter; left time: 625.9079s\n",
      "\titers: 200, epoch: 19 | loss: 0.0819497\n",
      "\tspeed: 0.0132s/iter; left time: 238.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0808590 Vali Loss: 0.0814628 Test Loss: 0.0921146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808056\n",
      "\tspeed: 0.0345s/iter; left time: 619.6821s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791076\n",
      "\tspeed: 0.0178s/iter; left time: 317.6688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.0806692 Vali Loss: 0.0815720 Test Loss: 0.0922729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0801933\n",
      "\tspeed: 0.0342s/iter; left time: 605.8626s\n",
      "\titers: 200, epoch: 21 | loss: 0.0812996\n",
      "\tspeed: 0.0141s/iter; left time: 249.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 223 | Train Loss: 0.0806306 Vali Loss: 0.0812687 Test Loss: 0.0921065\n",
      "Validation loss decreased (0.081380 --> 0.081269).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802179\n",
      "\tspeed: 0.0336s/iter; left time: 589.3666s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796860\n",
      "\tspeed: 0.0128s/iter; left time: 222.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 223 | Train Loss: 0.0804929 Vali Loss: 0.0815499 Test Loss: 0.0922932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0750428\n",
      "\tspeed: 0.0333s/iter; left time: 575.2167s\n",
      "\titers: 200, epoch: 23 | loss: 0.0808148\n",
      "\tspeed: 0.0153s/iter; left time: 262.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.0803914 Vali Loss: 0.0814775 Test Loss: 0.0921265\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0807701\n",
      "\tspeed: 0.0362s/iter; left time: 617.2642s\n",
      "\titers: 200, epoch: 24 | loss: 0.0826282\n",
      "\tspeed: 0.0151s/iter; left time: 256.3111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.0803028 Vali Loss: 0.0813313 Test Loss: 0.0920593\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0816124\n",
      "\tspeed: 0.0317s/iter; left time: 533.3613s\n",
      "\titers: 200, epoch: 25 | loss: 0.0802048\n",
      "\tspeed: 0.0128s/iter; left time: 214.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.0802464 Vali Loss: 0.0814555 Test Loss: 0.0920626\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0793562\n",
      "\tspeed: 0.0322s/iter; left time: 534.5384s\n",
      "\titers: 200, epoch: 26 | loss: 0.0802535\n",
      "\tspeed: 0.0160s/iter; left time: 264.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 223 | Train Loss: 0.0802107 Vali Loss: 0.0813662 Test Loss: 0.0920735\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0809886\n",
      "\tspeed: 0.0330s/iter; left time: 540.6538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780857\n",
      "\tspeed: 0.0128s/iter; left time: 209.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 223 | Train Loss: 0.0801222 Vali Loss: 0.0813769 Test Loss: 0.0919411\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0828010\n",
      "\tspeed: 0.0360s/iter; left time: 582.3433s\n",
      "\titers: 200, epoch: 28 | loss: 0.0781703\n",
      "\tspeed: 0.0169s/iter; left time: 271.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 223 | Train Loss: 0.0800819 Vali Loss: 0.0814171 Test Loss: 0.0919944\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0807718\n",
      "\tspeed: 0.0323s/iter; left time: 515.2426s\n",
      "\titers: 200, epoch: 29 | loss: 0.0799723\n",
      "\tspeed: 0.0128s/iter; left time: 203.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 223 | Train Loss: 0.0800133 Vali Loss: 0.0813341 Test Loss: 0.0920163\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0817873\n",
      "\tspeed: 0.0320s/iter; left time: 502.7388s\n",
      "\titers: 200, epoch: 30 | loss: 0.0790077\n",
      "\tspeed: 0.0172s/iter; left time: 269.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0800754 Vali Loss: 0.0814072 Test Loss: 0.0918496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0829585\n",
      "\tspeed: 0.0314s/iter; left time: 487.4777s\n",
      "\titers: 200, epoch: 31 | loss: 0.0813839\n",
      "\tspeed: 0.0127s/iter; left time: 195.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0799560 Vali Loss: 0.0813269 Test Loss: 0.0920620\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020562058314681053, rmse:0.14339476823806763, mae:0.09210649132728577, rse:0.4212809205055237\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1502437\n",
      "\tspeed: 0.0163s/iter; left time: 362.3741s\n",
      "\titers: 200, epoch: 1 | loss: 0.1254971\n",
      "\tspeed: 0.0165s/iter; left time: 364.5691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.1516325 Vali Loss: 0.1158346 Test Loss: 0.1291790\n",
      "Validation loss decreased (inf --> 0.115835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1010122\n",
      "\tspeed: 0.0341s/iter; left time: 749.1825s\n",
      "\titers: 200, epoch: 2 | loss: 0.0987693\n",
      "\tspeed: 0.0128s/iter; left time: 279.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 223 | Train Loss: 0.1007471 Vali Loss: 0.0924537 Test Loss: 0.1035259\n",
      "Validation loss decreased (0.115835 --> 0.092454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903587\n",
      "\tspeed: 0.0318s/iter; left time: 692.5933s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914113\n",
      "\tspeed: 0.0127s/iter; left time: 275.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 223 | Train Loss: 0.0924059 Vali Loss: 0.0876923 Test Loss: 0.0982845\n",
      "Validation loss decreased (0.092454 --> 0.087692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901701\n",
      "\tspeed: 0.0327s/iter; left time: 704.1254s\n",
      "\titers: 200, epoch: 4 | loss: 0.0881008\n",
      "\tspeed: 0.0176s/iter; left time: 377.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0888560 Vali Loss: 0.0854778 Test Loss: 0.0960285\n",
      "Validation loss decreased (0.087692 --> 0.085478).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0878372\n",
      "\tspeed: 0.0345s/iter; left time: 735.3581s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862915\n",
      "\tspeed: 0.0128s/iter; left time: 271.4009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 223 | Train Loss: 0.0868994 Vali Loss: 0.0842510 Test Loss: 0.0948967\n",
      "Validation loss decreased (0.085478 --> 0.084251).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0881855\n",
      "\tspeed: 0.0368s/iter; left time: 775.2580s\n",
      "\titers: 200, epoch: 6 | loss: 0.0828562\n",
      "\tspeed: 0.0187s/iter; left time: 391.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.0855696 Vali Loss: 0.0836035 Test Loss: 0.0938707\n",
      "Validation loss decreased (0.084251 --> 0.083604).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0885454\n",
      "\tspeed: 0.0341s/iter; left time: 711.7086s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834161\n",
      "\tspeed: 0.0129s/iter; left time: 267.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 223 | Train Loss: 0.0845940 Vali Loss: 0.0829399 Test Loss: 0.0934671\n",
      "Validation loss decreased (0.083604 --> 0.082940).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0843805\n",
      "\tspeed: 0.0346s/iter; left time: 713.9617s\n",
      "\titers: 200, epoch: 8 | loss: 0.0880142\n",
      "\tspeed: 0.0163s/iter; left time: 334.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0838240 Vali Loss: 0.0825768 Test Loss: 0.0927495\n",
      "Validation loss decreased (0.082940 --> 0.082577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0854332\n",
      "\tspeed: 0.0325s/iter; left time: 662.7251s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820717\n",
      "\tspeed: 0.0128s/iter; left time: 259.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 223 | Train Loss: 0.0832260 Vali Loss: 0.0820799 Test Loss: 0.0924623\n",
      "Validation loss decreased (0.082577 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0866779\n",
      "\tspeed: 0.0327s/iter; left time: 660.1736s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821955\n",
      "\tspeed: 0.0127s/iter; left time: 255.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0826538 Vali Loss: 0.0822511 Test Loss: 0.0925826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0799154\n",
      "\tspeed: 0.0316s/iter; left time: 630.9651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0860390\n",
      "\tspeed: 0.0128s/iter; left time: 254.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0823205 Vali Loss: 0.0823661 Test Loss: 0.0928630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0836935\n",
      "\tspeed: 0.0324s/iter; left time: 638.8745s\n",
      "\titers: 200, epoch: 12 | loss: 0.0805698\n",
      "\tspeed: 0.0144s/iter; left time: 283.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 223 | Train Loss: 0.0820193 Vali Loss: 0.0820110 Test Loss: 0.0920838\n",
      "Validation loss decreased (0.082080 --> 0.082011).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0832511\n",
      "\tspeed: 0.0320s/iter; left time: 625.7004s\n",
      "\titers: 200, epoch: 13 | loss: 0.0834782\n",
      "\tspeed: 0.0128s/iter; left time: 249.1985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0816734 Vali Loss: 0.0820294 Test Loss: 0.0922698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0840433\n",
      "\tspeed: 0.0319s/iter; left time: 616.3508s\n",
      "\titers: 200, epoch: 14 | loss: 0.0814902\n",
      "\tspeed: 0.0127s/iter; left time: 244.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 223 | Train Loss: 0.0814447 Vali Loss: 0.0822301 Test Loss: 0.0922972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782689\n",
      "\tspeed: 0.0328s/iter; left time: 626.0845s\n",
      "\titers: 200, epoch: 15 | loss: 0.0775106\n",
      "\tspeed: 0.0161s/iter; left time: 304.7192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.0812477 Vali Loss: 0.0817957 Test Loss: 0.0921128\n",
      "Validation loss decreased (0.082011 --> 0.081796).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0826267\n",
      "\tspeed: 0.0358s/iter; left time: 674.8610s\n",
      "\titers: 200, epoch: 16 | loss: 0.0831628\n",
      "\tspeed: 0.0147s/iter; left time: 275.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 223 | Train Loss: 0.0809873 Vali Loss: 0.0823844 Test Loss: 0.0922320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0804489\n",
      "\tspeed: 0.0354s/iter; left time: 659.7302s\n",
      "\titers: 200, epoch: 17 | loss: 0.0798360\n",
      "\tspeed: 0.0129s/iter; left time: 239.1125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 223 | Train Loss: 0.0808435 Vali Loss: 0.0818870 Test Loss: 0.0921629\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0808345\n",
      "\tspeed: 0.0327s/iter; left time: 602.7682s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812632\n",
      "\tspeed: 0.0163s/iter; left time: 298.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 223 | Train Loss: 0.0807508 Vali Loss: 0.0816080 Test Loss: 0.0920099\n",
      "Validation loss decreased (0.081796 --> 0.081608).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0805951\n",
      "\tspeed: 0.0326s/iter; left time: 592.3347s\n",
      "\titers: 200, epoch: 19 | loss: 0.0818176\n",
      "\tspeed: 0.0128s/iter; left time: 230.9933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 223 | Train Loss: 0.0805768 Vali Loss: 0.0818136 Test Loss: 0.0920359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0808800\n",
      "\tspeed: 0.0328s/iter; left time: 589.6767s\n",
      "\titers: 200, epoch: 20 | loss: 0.0867311\n",
      "\tspeed: 0.0128s/iter; left time: 229.1275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 223 | Train Loss: 0.0804598 Vali Loss: 0.0816207 Test Loss: 0.0917321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0804236\n",
      "\tspeed: 0.0318s/iter; left time: 564.4829s\n",
      "\titers: 200, epoch: 21 | loss: 0.0813942\n",
      "\tspeed: 0.0128s/iter; left time: 224.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0803784 Vali Loss: 0.0817261 Test Loss: 0.0916585\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0799659\n",
      "\tspeed: 0.0328s/iter; left time: 573.9268s\n",
      "\titers: 200, epoch: 22 | loss: 0.0813135\n",
      "\tspeed: 0.0128s/iter; left time: 222.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 223 | Train Loss: 0.0802698 Vali Loss: 0.0817093 Test Loss: 0.0918824\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0848580\n",
      "\tspeed: 0.0316s/iter; left time: 546.5452s\n",
      "\titers: 200, epoch: 23 | loss: 0.0818472\n",
      "\tspeed: 0.0173s/iter; left time: 297.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 223 | Train Loss: 0.0802030 Vali Loss: 0.0816619 Test Loss: 0.0917049\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0835023\n",
      "\tspeed: 0.0326s/iter; left time: 557.3535s\n",
      "\titers: 200, epoch: 24 | loss: 0.0789229\n",
      "\tspeed: 0.0129s/iter; left time: 219.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 223 | Train Loss: 0.0800944 Vali Loss: 0.0817329 Test Loss: 0.0918278\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0799017\n",
      "\tspeed: 0.0350s/iter; left time: 589.4745s\n",
      "\titers: 200, epoch: 25 | loss: 0.0783587\n",
      "\tspeed: 0.0135s/iter; left time: 225.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 223 | Train Loss: 0.0800052 Vali Loss: 0.0814836 Test Loss: 0.0915721\n",
      "Validation loss decreased (0.081608 --> 0.081484).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0786363\n",
      "\tspeed: 0.0340s/iter; left time: 565.4700s\n",
      "\titers: 200, epoch: 26 | loss: 0.0795248\n",
      "\tspeed: 0.0145s/iter; left time: 239.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 223 | Train Loss: 0.0799781 Vali Loss: 0.0817045 Test Loss: 0.0916322\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0833622\n",
      "\tspeed: 0.0346s/iter; left time: 567.3900s\n",
      "\titers: 200, epoch: 27 | loss: 0.0799694\n",
      "\tspeed: 0.0137s/iter; left time: 223.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 223 | Train Loss: 0.0799107 Vali Loss: 0.0817470 Test Loss: 0.0915949\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0808381\n",
      "\tspeed: 0.0313s/iter; left time: 506.1355s\n",
      "\titers: 200, epoch: 28 | loss: 0.0766860\n",
      "\tspeed: 0.0128s/iter; left time: 205.0251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 223 | Train Loss: 0.0798401 Vali Loss: 0.0818494 Test Loss: 0.0916982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0769423\n",
      "\tspeed: 0.0316s/iter; left time: 504.3297s\n",
      "\titers: 200, epoch: 29 | loss: 0.0770965\n",
      "\tspeed: 0.0128s/iter; left time: 202.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 223 | Train Loss: 0.0797812 Vali Loss: 0.0817337 Test Loss: 0.0916325\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0808872\n",
      "\tspeed: 0.0349s/iter; left time: 548.3364s\n",
      "\titers: 200, epoch: 30 | loss: 0.0806343\n",
      "\tspeed: 0.0136s/iter; left time: 212.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 223 | Train Loss: 0.0797441 Vali Loss: 0.0817683 Test Loss: 0.0916489\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0814143\n",
      "\tspeed: 0.0349s/iter; left time: 541.7731s\n",
      "\titers: 200, epoch: 31 | loss: 0.0794253\n",
      "\tspeed: 0.0139s/iter; left time: 214.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 223 | Train Loss: 0.0797284 Vali Loss: 0.0816585 Test Loss: 0.0916255\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0779980\n",
      "\tspeed: 0.0322s/iter; left time: 493.0184s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811560\n",
      "\tspeed: 0.0130s/iter; left time: 197.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0797131 Vali Loss: 0.0816876 Test Loss: 0.0915593\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0779019\n",
      "\tspeed: 0.0340s/iter; left time: 512.0718s\n",
      "\titers: 200, epoch: 33 | loss: 0.0813268\n",
      "\tspeed: 0.0172s/iter; left time: 257.8532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0796656 Vali Loss: 0.0818026 Test Loss: 0.0916599\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0796773\n",
      "\tspeed: 0.0354s/iter; left time: 525.5439s\n",
      "\titers: 200, epoch: 34 | loss: 0.0782494\n",
      "\tspeed: 0.0145s/iter; left time: 213.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 223 | Train Loss: 0.0796543 Vali Loss: 0.0816361 Test Loss: 0.0915912\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0809171\n",
      "\tspeed: 0.0322s/iter; left time: 470.4878s\n",
      "\titers: 200, epoch: 35 | loss: 0.0806476\n",
      "\tspeed: 0.0127s/iter; left time: 184.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 223 | Train Loss: 0.0796245 Vali Loss: 0.0817167 Test Loss: 0.0915837\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02045246958732605, rmse:0.143012136220932, mae:0.09157206118106842, rse:0.4201567769050598\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:27.64s\n",
      "Intermediate time for ES: 00h:21m:26.40s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1060625\n",
      "\tspeed: 0.0398s/iter; left time: 896.6500s\n",
      "\titers: 200, epoch: 1 | loss: 0.0912452\n",
      "\tspeed: 0.0133s/iter; left time: 297.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.1106058 Vali Loss: 0.0972138 Test Loss: 0.1078673\n",
      "Validation loss decreased (inf --> 0.097214).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0574707\n",
      "\tspeed: 0.0289s/iter; left time: 644.7375s\n",
      "\titers: 200, epoch: 2 | loss: 0.0536962\n",
      "\tspeed: 0.0133s/iter; left time: 295.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 226 | Train Loss: 0.0592674 Vali Loss: 0.0603557 Test Loss: 0.0631131\n",
      "Validation loss decreased (0.097214 --> 0.060356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0514698\n",
      "\tspeed: 0.0303s/iter; left time: 668.4780s\n",
      "\titers: 200, epoch: 3 | loss: 0.0514899\n",
      "\tspeed: 0.0137s/iter; left time: 300.9011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0516627 Vali Loss: 0.0581408 Test Loss: 0.0608993\n",
      "Validation loss decreased (0.060356 --> 0.058141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0513853\n",
      "\tspeed: 0.0315s/iter; left time: 687.8574s\n",
      "\titers: 200, epoch: 4 | loss: 0.0521481\n",
      "\tspeed: 0.0190s/iter; left time: 411.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0499776 Vali Loss: 0.0569380 Test Loss: 0.0599556\n",
      "Validation loss decreased (0.058141 --> 0.056938).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0487639\n",
      "\tspeed: 0.0319s/iter; left time: 688.4098s\n",
      "\titers: 200, epoch: 5 | loss: 0.0500868\n",
      "\tspeed: 0.0136s/iter; left time: 291.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0489388 Vali Loss: 0.0561527 Test Loss: 0.0592675\n",
      "Validation loss decreased (0.056938 --> 0.056153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0475378\n",
      "\tspeed: 0.0332s/iter; left time: 708.5744s\n",
      "\titers: 200, epoch: 6 | loss: 0.0434667\n",
      "\tspeed: 0.0138s/iter; left time: 292.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0479542 Vali Loss: 0.0550446 Test Loss: 0.0587084\n",
      "Validation loss decreased (0.056153 --> 0.055045).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0478253\n",
      "\tspeed: 0.0300s/iter; left time: 634.2103s\n",
      "\titers: 200, epoch: 7 | loss: 0.0469816\n",
      "\tspeed: 0.0135s/iter; left time: 283.3346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0473231 Vali Loss: 0.0544623 Test Loss: 0.0579584\n",
      "Validation loss decreased (0.055045 --> 0.054462).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0463750\n",
      "\tspeed: 0.0316s/iter; left time: 660.9674s\n",
      "\titers: 200, epoch: 8 | loss: 0.0502244\n",
      "\tspeed: 0.0137s/iter; left time: 284.8794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0467366 Vali Loss: 0.0535307 Test Loss: 0.0574489\n",
      "Validation loss decreased (0.054462 --> 0.053531).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0434354\n",
      "\tspeed: 0.0310s/iter; left time: 641.7379s\n",
      "\titers: 200, epoch: 9 | loss: 0.0457561\n",
      "\tspeed: 0.0144s/iter; left time: 296.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0462207 Vali Loss: 0.0532126 Test Loss: 0.0570184\n",
      "Validation loss decreased (0.053531 --> 0.053213).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0439801\n",
      "\tspeed: 0.0324s/iter; left time: 662.2215s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442396\n",
      "\tspeed: 0.0150s/iter; left time: 305.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0458010 Vali Loss: 0.0528103 Test Loss: 0.0566243\n",
      "Validation loss decreased (0.053213 --> 0.052810).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0468842\n",
      "\tspeed: 0.0347s/iter; left time: 702.2991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0467618\n",
      "\tspeed: 0.0169s/iter; left time: 340.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0454804 Vali Loss: 0.0524995 Test Loss: 0.0564222\n",
      "Validation loss decreased (0.052810 --> 0.052499).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0439075\n",
      "\tspeed: 0.0302s/iter; left time: 604.9477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0411428\n",
      "\tspeed: 0.0142s/iter; left time: 283.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0451976 Vali Loss: 0.0522233 Test Loss: 0.0563692\n",
      "Validation loss decreased (0.052499 --> 0.052223).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0475037\n",
      "\tspeed: 0.0298s/iter; left time: 589.1173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0429972\n",
      "\tspeed: 0.0150s/iter; left time: 294.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0449785 Vali Loss: 0.0519085 Test Loss: 0.0562953\n",
      "Validation loss decreased (0.052223 --> 0.051908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0494510\n",
      "\tspeed: 0.0300s/iter; left time: 586.4847s\n",
      "\titers: 200, epoch: 14 | loss: 0.0437519\n",
      "\tspeed: 0.0140s/iter; left time: 272.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0447034 Vali Loss: 0.0518797 Test Loss: 0.0558909\n",
      "Validation loss decreased (0.051908 --> 0.051880).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0447066\n",
      "\tspeed: 0.0292s/iter; left time: 565.5337s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447475\n",
      "\tspeed: 0.0127s/iter; left time: 244.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0445134 Vali Loss: 0.0515889 Test Loss: 0.0558992\n",
      "Validation loss decreased (0.051880 --> 0.051589).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0452005\n",
      "\tspeed: 0.0295s/iter; left time: 563.3044s\n",
      "\titers: 200, epoch: 16 | loss: 0.0428965\n",
      "\tspeed: 0.0131s/iter; left time: 249.5603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0443750 Vali Loss: 0.0513296 Test Loss: 0.0557149\n",
      "Validation loss decreased (0.051589 --> 0.051330).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0441204\n",
      "\tspeed: 0.0294s/iter; left time: 555.7635s\n",
      "\titers: 200, epoch: 17 | loss: 0.0414689\n",
      "\tspeed: 0.0150s/iter; left time: 281.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0442032 Vali Loss: 0.0513475 Test Loss: 0.0556469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0486124\n",
      "\tspeed: 0.0312s/iter; left time: 581.6609s\n",
      "\titers: 200, epoch: 18 | loss: 0.0434283\n",
      "\tspeed: 0.0135s/iter; left time: 251.2268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0440683 Vali Loss: 0.0512119 Test Loss: 0.0555730\n",
      "Validation loss decreased (0.051330 --> 0.051212).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0421891\n",
      "\tspeed: 0.0297s/iter; left time: 547.4302s\n",
      "\titers: 200, epoch: 19 | loss: 0.0431417\n",
      "\tspeed: 0.0143s/iter; left time: 262.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0439838 Vali Loss: 0.0511732 Test Loss: 0.0555482\n",
      "Validation loss decreased (0.051212 --> 0.051173).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0422821\n",
      "\tspeed: 0.0308s/iter; left time: 560.5602s\n",
      "\titers: 200, epoch: 20 | loss: 0.0420321\n",
      "\tspeed: 0.0143s/iter; left time: 258.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0438585 Vali Loss: 0.0511559 Test Loss: 0.0554535\n",
      "Validation loss decreased (0.051173 --> 0.051156).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0444407\n",
      "\tspeed: 0.0323s/iter; left time: 580.8389s\n",
      "\titers: 200, epoch: 21 | loss: 0.0441018\n",
      "\tspeed: 0.0161s/iter; left time: 287.8927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0438082 Vali Loss: 0.0510903 Test Loss: 0.0553842\n",
      "Validation loss decreased (0.051156 --> 0.051090).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0448238\n",
      "\tspeed: 0.0270s/iter; left time: 479.4483s\n",
      "\titers: 200, epoch: 22 | loss: 0.0453544\n",
      "\tspeed: 0.0092s/iter; left time: 162.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 226 | Train Loss: 0.0437145 Vali Loss: 0.0508597 Test Loss: 0.0553870\n",
      "Validation loss decreased (0.051090 --> 0.050860).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0461388\n",
      "\tspeed: 0.0307s/iter; left time: 538.4833s\n",
      "\titers: 200, epoch: 23 | loss: 0.0432247\n",
      "\tspeed: 0.0141s/iter; left time: 245.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 226 | Train Loss: 0.0436651 Vali Loss: 0.0509211 Test Loss: 0.0552605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0430605\n",
      "\tspeed: 0.0322s/iter; left time: 557.8723s\n",
      "\titers: 200, epoch: 24 | loss: 0.0411512\n",
      "\tspeed: 0.0141s/iter; left time: 242.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0435658 Vali Loss: 0.0509761 Test Loss: 0.0552537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0428862\n",
      "\tspeed: 0.0318s/iter; left time: 542.8262s\n",
      "\titers: 200, epoch: 25 | loss: 0.0431869\n",
      "\tspeed: 0.0128s/iter; left time: 216.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0435366 Vali Loss: 0.0508415 Test Loss: 0.0552171\n",
      "Validation loss decreased (0.050860 --> 0.050841).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0408315\n",
      "\tspeed: 0.0398s/iter; left time: 670.2627s\n",
      "\titers: 200, epoch: 26 | loss: 0.0423444\n",
      "\tspeed: 0.0182s/iter; left time: 304.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 226 | Train Loss: 0.0434585 Vali Loss: 0.0507655 Test Loss: 0.0551781\n",
      "Validation loss decreased (0.050841 --> 0.050765).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0428261\n",
      "\tspeed: 0.0335s/iter; left time: 557.0898s\n",
      "\titers: 200, epoch: 27 | loss: 0.0465105\n",
      "\tspeed: 0.0154s/iter; left time: 254.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0434307 Vali Loss: 0.0508561 Test Loss: 0.0550848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0436736\n",
      "\tspeed: 0.0317s/iter; left time: 519.6177s\n",
      "\titers: 200, epoch: 28 | loss: 0.0424185\n",
      "\tspeed: 0.0176s/iter; left time: 287.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0434084 Vali Loss: 0.0507310 Test Loss: 0.0550996\n",
      "Validation loss decreased (0.050765 --> 0.050731).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0424499\n",
      "\tspeed: 0.0311s/iter; left time: 503.7618s\n",
      "\titers: 200, epoch: 29 | loss: 0.0451251\n",
      "\tspeed: 0.0143s/iter; left time: 229.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0433443 Vali Loss: 0.0507456 Test Loss: 0.0551493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0411471\n",
      "\tspeed: 0.0319s/iter; left time: 507.9903s\n",
      "\titers: 200, epoch: 30 | loss: 0.0464486\n",
      "\tspeed: 0.0165s/iter; left time: 262.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0432838 Vali Loss: 0.0506384 Test Loss: 0.0550707\n",
      "Validation loss decreased (0.050731 --> 0.050638).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0438320\n",
      "\tspeed: 0.0295s/iter; left time: 463.6331s\n",
      "\titers: 200, epoch: 31 | loss: 0.0435973\n",
      "\tspeed: 0.0127s/iter; left time: 198.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0433117 Vali Loss: 0.0506111 Test Loss: 0.0550311\n",
      "Validation loss decreased (0.050638 --> 0.050611).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0415103\n",
      "\tspeed: 0.0301s/iter; left time: 466.0407s\n",
      "\titers: 200, epoch: 32 | loss: 0.0429377\n",
      "\tspeed: 0.0132s/iter; left time: 203.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 226 | Train Loss: 0.0432910 Vali Loss: 0.0505773 Test Loss: 0.0550379\n",
      "Validation loss decreased (0.050611 --> 0.050577).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0432881\n",
      "\tspeed: 0.0302s/iter; left time: 460.8706s\n",
      "\titers: 200, epoch: 33 | loss: 0.0431300\n",
      "\tspeed: 0.0126s/iter; left time: 191.6444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0432502 Vali Loss: 0.0506056 Test Loss: 0.0550383\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0443775\n",
      "\tspeed: 0.0291s/iter; left time: 438.0430s\n",
      "\titers: 200, epoch: 34 | loss: 0.0422093\n",
      "\tspeed: 0.0149s/iter; left time: 223.2864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0432416 Vali Loss: 0.0505842 Test Loss: 0.0550132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0459518\n",
      "\tspeed: 0.0283s/iter; left time: 418.9333s\n",
      "\titers: 200, epoch: 35 | loss: 0.0454904\n",
      "\tspeed: 0.0138s/iter; left time: 202.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0431727 Vali Loss: 0.0506345 Test Loss: 0.0550111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0417737\n",
      "\tspeed: 0.0307s/iter; left time: 448.5892s\n",
      "\titers: 200, epoch: 36 | loss: 0.0399015\n",
      "\tspeed: 0.0134s/iter; left time: 194.4290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0432215 Vali Loss: 0.0506072 Test Loss: 0.0549815\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0438274\n",
      "\tspeed: 0.0303s/iter; left time: 435.8271s\n",
      "\titers: 200, epoch: 37 | loss: 0.0424024\n",
      "\tspeed: 0.0155s/iter; left time: 221.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0432072 Vali Loss: 0.0506064 Test Loss: 0.0550074\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0426931\n",
      "\tspeed: 0.0297s/iter; left time: 420.1998s\n",
      "\titers: 200, epoch: 38 | loss: 0.0396262\n",
      "\tspeed: 0.0136s/iter; left time: 190.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0431663 Vali Loss: 0.0506054 Test Loss: 0.0550021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0444762\n",
      "\tspeed: 0.0292s/iter; left time: 406.3124s\n",
      "\titers: 200, epoch: 39 | loss: 0.0406112\n",
      "\tspeed: 0.0138s/iter; left time: 190.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0432206 Vali Loss: 0.0505484 Test Loss: 0.0549560\n",
      "Validation loss decreased (0.050577 --> 0.050548).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0456339\n",
      "\tspeed: 0.0301s/iter; left time: 411.3583s\n",
      "\titers: 200, epoch: 40 | loss: 0.0405607\n",
      "\tspeed: 0.0132s/iter; left time: 179.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 226 | Train Loss: 0.0431266 Vali Loss: 0.0505964 Test Loss: 0.0549480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0441409\n",
      "\tspeed: 0.0302s/iter; left time: 407.0503s\n",
      "\titers: 200, epoch: 41 | loss: 0.0421112\n",
      "\tspeed: 0.0143s/iter; left time: 191.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0431628 Vali Loss: 0.0506412 Test Loss: 0.0549614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0413996\n",
      "\tspeed: 0.0313s/iter; left time: 414.5590s\n",
      "\titers: 200, epoch: 42 | loss: 0.0437304\n",
      "\tspeed: 0.0183s/iter; left time: 239.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0431709 Vali Loss: 0.0505848 Test Loss: 0.0549639\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0461118\n",
      "\tspeed: 0.0304s/iter; left time: 395.2049s\n",
      "\titers: 200, epoch: 43 | loss: 0.0433474\n",
      "\tspeed: 0.0148s/iter; left time: 190.8177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0431170 Vali Loss: 0.0505085 Test Loss: 0.0549879\n",
      "Validation loss decreased (0.050548 --> 0.050509).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0436720\n",
      "\tspeed: 0.0335s/iter; left time: 427.9557s\n",
      "\titers: 200, epoch: 44 | loss: 0.0422855\n",
      "\tspeed: 0.0147s/iter; left time: 186.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.0431253 Vali Loss: 0.0505445 Test Loss: 0.0549463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0425966\n",
      "\tspeed: 0.0295s/iter; left time: 371.0292s\n",
      "\titers: 200, epoch: 45 | loss: 0.0406591\n",
      "\tspeed: 0.0140s/iter; left time: 174.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0431322 Vali Loss: 0.0505018 Test Loss: 0.0549695\n",
      "Validation loss decreased (0.050509 --> 0.050502).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0417108\n",
      "\tspeed: 0.0297s/iter; left time: 366.4153s\n",
      "\titers: 200, epoch: 46 | loss: 0.0412333\n",
      "\tspeed: 0.0155s/iter; left time: 190.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0431725 Vali Loss: 0.0505631 Test Loss: 0.0549393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0427210\n",
      "\tspeed: 0.0309s/iter; left time: 373.8737s\n",
      "\titers: 200, epoch: 47 | loss: 0.0442664\n",
      "\tspeed: 0.0148s/iter; left time: 177.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0431186 Vali Loss: 0.0505455 Test Loss: 0.0549315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0398364\n",
      "\tspeed: 0.0283s/iter; left time: 336.7584s\n",
      "\titers: 200, epoch: 48 | loss: 0.0434183\n",
      "\tspeed: 0.0132s/iter; left time: 155.9869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 226 | Train Loss: 0.0431293 Vali Loss: 0.0504869 Test Loss: 0.0549437\n",
      "Validation loss decreased (0.050502 --> 0.050487).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0458617\n",
      "\tspeed: 0.0302s/iter; left time: 351.8419s\n",
      "\titers: 200, epoch: 49 | loss: 0.0403122\n",
      "\tspeed: 0.0150s/iter; left time: 173.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0430812 Vali Loss: 0.0505334 Test Loss: 0.0549541\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0426102\n",
      "\tspeed: 0.0314s/iter; left time: 358.6790s\n",
      "\titers: 200, epoch: 50 | loss: 0.0422080\n",
      "\tspeed: 0.0178s/iter; left time: 202.0157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0430783 Vali Loss: 0.0505348 Test Loss: 0.0549305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0431671\n",
      "\tspeed: 0.0313s/iter; left time: 350.9703s\n",
      "\titers: 200, epoch: 51 | loss: 0.0449550\n",
      "\tspeed: 0.0131s/iter; left time: 145.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0430281 Vali Loss: 0.0505737 Test Loss: 0.0549435\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0443885\n",
      "\tspeed: 0.0297s/iter; left time: 326.1426s\n",
      "\titers: 200, epoch: 52 | loss: 0.0422768\n",
      "\tspeed: 0.0160s/iter; left time: 174.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0430744 Vali Loss: 0.0505666 Test Loss: 0.0549170\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0452064\n",
      "\tspeed: 0.0312s/iter; left time: 335.6220s\n",
      "\titers: 200, epoch: 53 | loss: 0.0421723\n",
      "\tspeed: 0.0132s/iter; left time: 140.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0430699 Vali Loss: 0.0505772 Test Loss: 0.0549556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0430398\n",
      "\tspeed: 0.0283s/iter; left time: 298.0687s\n",
      "\titers: 200, epoch: 54 | loss: 0.0457688\n",
      "\tspeed: 0.0165s/iter; left time: 171.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0430767 Vali Loss: 0.0505139 Test Loss: 0.0549542\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0436852\n",
      "\tspeed: 0.0314s/iter; left time: 323.0082s\n",
      "\titers: 200, epoch: 55 | loss: 0.0436785\n",
      "\tspeed: 0.0146s/iter; left time: 148.8770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0431085 Vali Loss: 0.0505567 Test Loss: 0.0549312\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0426609\n",
      "\tspeed: 0.0343s/iter; left time: 345.7832s\n",
      "\titers: 200, epoch: 56 | loss: 0.0382742\n",
      "\tspeed: 0.0170s/iter; left time: 169.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0430599 Vali Loss: 0.0505646 Test Loss: 0.0549429\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0401129\n",
      "\tspeed: 0.0303s/iter; left time: 298.1054s\n",
      "\titers: 200, epoch: 57 | loss: 0.0448331\n",
      "\tspeed: 0.0136s/iter; left time: 132.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0430703 Vali Loss: 0.0505644 Test Loss: 0.0549144\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0455024\n",
      "\tspeed: 0.0308s/iter; left time: 296.3428s\n",
      "\titers: 200, epoch: 58 | loss: 0.0461371\n",
      "\tspeed: 0.0148s/iter; left time: 141.2488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0431149 Vali Loss: 0.0504859 Test Loss: 0.0549167\n",
      "Validation loss decreased (0.050487 --> 0.050486).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0432871\n",
      "\tspeed: 0.0319s/iter; left time: 299.6726s\n",
      "\titers: 200, epoch: 59 | loss: 0.0461057\n",
      "\tspeed: 0.0150s/iter; left time: 139.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 226 | Train Loss: 0.0430678 Vali Loss: 0.0505368 Test Loss: 0.0549258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0424391\n",
      "\tspeed: 0.0310s/iter; left time: 284.0606s\n",
      "\titers: 200, epoch: 60 | loss: 0.0416878\n",
      "\tspeed: 0.0135s/iter; left time: 122.3397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0430786 Vali Loss: 0.0505145 Test Loss: 0.0549320\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0402681\n",
      "\tspeed: 0.0295s/iter; left time: 264.0755s\n",
      "\titers: 200, epoch: 61 | loss: 0.0434605\n",
      "\tspeed: 0.0135s/iter; left time: 119.0470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0430475 Vali Loss: 0.0505281 Test Loss: 0.0549709\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0421262\n",
      "\tspeed: 0.0286s/iter; left time: 249.5270s\n",
      "\titers: 200, epoch: 62 | loss: 0.0442856\n",
      "\tspeed: 0.0116s/iter; left time: 99.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0430506 Vali Loss: 0.0505215 Test Loss: 0.0549315\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0426427\n",
      "\tspeed: 0.0290s/iter; left time: 246.4611s\n",
      "\titers: 200, epoch: 63 | loss: 0.0418918\n",
      "\tspeed: 0.0145s/iter; left time: 121.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0431118 Vali Loss: 0.0505646 Test Loss: 0.0549117\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0456960\n",
      "\tspeed: 0.0291s/iter; left time: 240.3379s\n",
      "\titers: 200, epoch: 64 | loss: 0.0410204\n",
      "\tspeed: 0.0126s/iter; left time: 102.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0431284 Vali Loss: 0.0505165 Test Loss: 0.0549387\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0419518\n",
      "\tspeed: 0.0327s/iter; left time: 262.8018s\n",
      "\titers: 200, epoch: 65 | loss: 0.0415572\n",
      "\tspeed: 0.0144s/iter; left time: 114.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0430930 Vali Loss: 0.0505489 Test Loss: 0.0549763\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0412027\n",
      "\tspeed: 0.0306s/iter; left time: 238.6923s\n",
      "\titers: 200, epoch: 66 | loss: 0.0401068\n",
      "\tspeed: 0.0152s/iter; left time: 117.3666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0430675 Vali Loss: 0.0505454 Test Loss: 0.0549279\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0404989\n",
      "\tspeed: 0.0296s/iter; left time: 224.2933s\n",
      "\titers: 200, epoch: 67 | loss: 0.0453020\n",
      "\tspeed: 0.0149s/iter; left time: 111.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0430111 Vali Loss: 0.0504871 Test Loss: 0.0549125\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0425493\n",
      "\tspeed: 0.0292s/iter; left time: 214.8413s\n",
      "\titers: 200, epoch: 68 | loss: 0.0416755\n",
      "\tspeed: 0.0156s/iter; left time: 113.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0430410 Vali Loss: 0.0505040 Test Loss: 0.0549149\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009941867552697659, rmse:0.0997089147567749, mae:0.05491669103503227, rse:0.38467422127723694\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1146234\n",
      "\tspeed: 0.0167s/iter; left time: 375.5849s\n",
      "\titers: 200, epoch: 1 | loss: 0.0938724\n",
      "\tspeed: 0.0130s/iter; left time: 291.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.1105014 Vali Loss: 0.0969285 Test Loss: 0.1074306\n",
      "Validation loss decreased (inf --> 0.096928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0564827\n",
      "\tspeed: 0.0302s/iter; left time: 673.6856s\n",
      "\titers: 200, epoch: 2 | loss: 0.0503704\n",
      "\tspeed: 0.0159s/iter; left time: 351.7712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0588829 Vali Loss: 0.0601485 Test Loss: 0.0630276\n",
      "Validation loss decreased (0.096928 --> 0.060149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0526972\n",
      "\tspeed: 0.0320s/iter; left time: 705.2865s\n",
      "\titers: 200, epoch: 3 | loss: 0.0506199\n",
      "\tspeed: 0.0144s/iter; left time: 315.2287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0516219 Vali Loss: 0.0581717 Test Loss: 0.0610005\n",
      "Validation loss decreased (0.060149 --> 0.058172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0506809\n",
      "\tspeed: 0.0295s/iter; left time: 643.4928s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496093\n",
      "\tspeed: 0.0148s/iter; left time: 320.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0499295 Vali Loss: 0.0568983 Test Loss: 0.0599148\n",
      "Validation loss decreased (0.058172 --> 0.056898).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0505949\n",
      "\tspeed: 0.0309s/iter; left time: 666.5594s\n",
      "\titers: 200, epoch: 5 | loss: 0.0452290\n",
      "\tspeed: 0.0132s/iter; left time: 284.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0487994 Vali Loss: 0.0558213 Test Loss: 0.0589275\n",
      "Validation loss decreased (0.056898 --> 0.055821).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0466777\n",
      "\tspeed: 0.0300s/iter; left time: 640.5892s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490869\n",
      "\tspeed: 0.0146s/iter; left time: 310.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0480778 Vali Loss: 0.0550395 Test Loss: 0.0582837\n",
      "Validation loss decreased (0.055821 --> 0.055039).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0530791\n",
      "\tspeed: 0.0309s/iter; left time: 653.4153s\n",
      "\titers: 200, epoch: 7 | loss: 0.0466418\n",
      "\tspeed: 0.0134s/iter; left time: 282.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0473387 Vali Loss: 0.0543851 Test Loss: 0.0577922\n",
      "Validation loss decreased (0.055039 --> 0.054385).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0442172\n",
      "\tspeed: 0.0333s/iter; left time: 695.7621s\n",
      "\titers: 200, epoch: 8 | loss: 0.0438185\n",
      "\tspeed: 0.0155s/iter; left time: 323.4942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0467762 Vali Loss: 0.0536854 Test Loss: 0.0572478\n",
      "Validation loss decreased (0.054385 --> 0.053685).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0483233\n",
      "\tspeed: 0.0312s/iter; left time: 645.6008s\n",
      "\titers: 200, epoch: 9 | loss: 0.0453414\n",
      "\tspeed: 0.0154s/iter; left time: 317.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0462767 Vali Loss: 0.0532997 Test Loss: 0.0569474\n",
      "Validation loss decreased (0.053685 --> 0.053300).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0428389\n",
      "\tspeed: 0.0307s/iter; left time: 629.1680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0443230\n",
      "\tspeed: 0.0154s/iter; left time: 314.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0458712 Vali Loss: 0.0531465 Test Loss: 0.0568259\n",
      "Validation loss decreased (0.053300 --> 0.053147).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0450105\n",
      "\tspeed: 0.0306s/iter; left time: 619.5621s\n",
      "\titers: 200, epoch: 11 | loss: 0.0433449\n",
      "\tspeed: 0.0141s/iter; left time: 284.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 226 | Train Loss: 0.0455657 Vali Loss: 0.0526221 Test Loss: 0.0564658\n",
      "Validation loss decreased (0.053147 --> 0.052622).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0465978\n",
      "\tspeed: 0.0320s/iter; left time: 639.7263s\n",
      "\titers: 200, epoch: 12 | loss: 0.0449172\n",
      "\tspeed: 0.0150s/iter; left time: 298.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0451824 Vali Loss: 0.0524933 Test Loss: 0.0563997\n",
      "Validation loss decreased (0.052622 --> 0.052493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463449\n",
      "\tspeed: 0.0323s/iter; left time: 638.4994s\n",
      "\titers: 200, epoch: 13 | loss: 0.0462351\n",
      "\tspeed: 0.0144s/iter; left time: 284.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0449842 Vali Loss: 0.0520573 Test Loss: 0.0561038\n",
      "Validation loss decreased (0.052493 --> 0.052057).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0430221\n",
      "\tspeed: 0.0317s/iter; left time: 620.6772s\n",
      "\titers: 200, epoch: 14 | loss: 0.0492483\n",
      "\tspeed: 0.0146s/iter; left time: 283.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0447385 Vali Loss: 0.0520652 Test Loss: 0.0560733\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0451980\n",
      "\tspeed: 0.0298s/iter; left time: 575.7973s\n",
      "\titers: 200, epoch: 15 | loss: 0.0439300\n",
      "\tspeed: 0.0133s/iter; left time: 255.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0445438 Vali Loss: 0.0516998 Test Loss: 0.0558173\n",
      "Validation loss decreased (0.052057 --> 0.051700).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0448337\n",
      "\tspeed: 0.0321s/iter; left time: 614.0824s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441869\n",
      "\tspeed: 0.0135s/iter; left time: 256.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0443531 Vali Loss: 0.0517519 Test Loss: 0.0557044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0445471\n",
      "\tspeed: 0.0299s/iter; left time: 565.0784s\n",
      "\titers: 200, epoch: 17 | loss: 0.0433283\n",
      "\tspeed: 0.0162s/iter; left time: 303.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0442475 Vali Loss: 0.0516402 Test Loss: 0.0556401\n",
      "Validation loss decreased (0.051700 --> 0.051640).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0470164\n",
      "\tspeed: 0.0309s/iter; left time: 577.1379s\n",
      "\titers: 200, epoch: 18 | loss: 0.0443331\n",
      "\tspeed: 0.0132s/iter; left time: 245.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0440625 Vali Loss: 0.0515960 Test Loss: 0.0555905\n",
      "Validation loss decreased (0.051640 --> 0.051596).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0395070\n",
      "\tspeed: 0.0327s/iter; left time: 602.5834s\n",
      "\titers: 200, epoch: 19 | loss: 0.0443311\n",
      "\tspeed: 0.0138s/iter; left time: 253.2484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0439571 Vali Loss: 0.0513844 Test Loss: 0.0555486\n",
      "Validation loss decreased (0.051596 --> 0.051384).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0449634\n",
      "\tspeed: 0.0341s/iter; left time: 621.1653s\n",
      "\titers: 200, epoch: 20 | loss: 0.0446243\n",
      "\tspeed: 0.0167s/iter; left time: 301.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 226 | Train Loss: 0.0438875 Vali Loss: 0.0512845 Test Loss: 0.0553931\n",
      "Validation loss decreased (0.051384 --> 0.051285).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0452567\n",
      "\tspeed: 0.0329s/iter; left time: 592.2606s\n",
      "\titers: 200, epoch: 21 | loss: 0.0428735\n",
      "\tspeed: 0.0104s/iter; left time: 186.1686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0438441 Vali Loss: 0.0512786 Test Loss: 0.0554227\n",
      "Validation loss decreased (0.051285 --> 0.051279).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0436745\n",
      "\tspeed: 0.0290s/iter; left time: 515.4055s\n",
      "\titers: 200, epoch: 22 | loss: 0.0443317\n",
      "\tspeed: 0.0144s/iter; left time: 253.9422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0437117 Vali Loss: 0.0511852 Test Loss: 0.0553247\n",
      "Validation loss decreased (0.051279 --> 0.051185).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0437436\n",
      "\tspeed: 0.0305s/iter; left time: 534.9801s\n",
      "\titers: 200, epoch: 23 | loss: 0.0415540\n",
      "\tspeed: 0.0133s/iter; left time: 231.1051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0436257 Vali Loss: 0.0510723 Test Loss: 0.0553307\n",
      "Validation loss decreased (0.051185 --> 0.051072).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0419801\n",
      "\tspeed: 0.0313s/iter; left time: 540.9976s\n",
      "\titers: 200, epoch: 24 | loss: 0.0443381\n",
      "\tspeed: 0.0144s/iter; left time: 248.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0435742 Vali Loss: 0.0511410 Test Loss: 0.0552610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0429912\n",
      "\tspeed: 0.0293s/iter; left time: 500.3106s\n",
      "\titers: 200, epoch: 25 | loss: 0.0401810\n",
      "\tspeed: 0.0124s/iter; left time: 210.3534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0435479 Vali Loss: 0.0510619 Test Loss: 0.0552265\n",
      "Validation loss decreased (0.051072 --> 0.051062).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0383867\n",
      "\tspeed: 0.0315s/iter; left time: 531.4255s\n",
      "\titers: 200, epoch: 26 | loss: 0.0439783\n",
      "\tspeed: 0.0142s/iter; left time: 237.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0434704 Vali Loss: 0.0509174 Test Loss: 0.0552054\n",
      "Validation loss decreased (0.051062 --> 0.050917).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0431164\n",
      "\tspeed: 0.0316s/iter; left time: 525.8031s\n",
      "\titers: 200, epoch: 27 | loss: 0.0450050\n",
      "\tspeed: 0.0126s/iter; left time: 208.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 226 | Train Loss: 0.0434181 Vali Loss: 0.0509986 Test Loss: 0.0551521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0434347\n",
      "\tspeed: 0.0285s/iter; left time: 467.0285s\n",
      "\titers: 200, epoch: 28 | loss: 0.0431598\n",
      "\tspeed: 0.0132s/iter; left time: 214.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0434002 Vali Loss: 0.0509291 Test Loss: 0.0551391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0437596\n",
      "\tspeed: 0.0306s/iter; left time: 494.1996s\n",
      "\titers: 200, epoch: 29 | loss: 0.0416731\n",
      "\tspeed: 0.0156s/iter; left time: 250.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0433732 Vali Loss: 0.0509113 Test Loss: 0.0551295\n",
      "Validation loss decreased (0.050917 --> 0.050911).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0418742\n",
      "\tspeed: 0.0323s/iter; left time: 515.4368s\n",
      "\titers: 200, epoch: 30 | loss: 0.0420183\n",
      "\tspeed: 0.0136s/iter; left time: 215.5155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0433450 Vali Loss: 0.0509345 Test Loss: 0.0551585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0453114\n",
      "\tspeed: 0.0296s/iter; left time: 464.9897s\n",
      "\titers: 200, epoch: 31 | loss: 0.0438949\n",
      "\tspeed: 0.0152s/iter; left time: 237.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0432821 Vali Loss: 0.0509121 Test Loss: 0.0550637\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0421501\n",
      "\tspeed: 0.0306s/iter; left time: 474.5770s\n",
      "\titers: 200, epoch: 32 | loss: 0.0447672\n",
      "\tspeed: 0.0126s/iter; left time: 194.3298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0432737 Vali Loss: 0.0508788 Test Loss: 0.0550904\n",
      "Validation loss decreased (0.050911 --> 0.050879).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0441503\n",
      "\tspeed: 0.0316s/iter; left time: 482.2248s\n",
      "\titers: 200, epoch: 33 | loss: 0.0435807\n",
      "\tspeed: 0.0165s/iter; left time: 250.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0432101 Vali Loss: 0.0507877 Test Loss: 0.0550530\n",
      "Validation loss decreased (0.050879 --> 0.050788).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0397283\n",
      "\tspeed: 0.0318s/iter; left time: 479.0370s\n",
      "\titers: 200, epoch: 34 | loss: 0.0440855\n",
      "\tspeed: 0.0141s/iter; left time: 210.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0432564 Vali Loss: 0.0508414 Test Loss: 0.0550539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0388196\n",
      "\tspeed: 0.0334s/iter; left time: 494.4054s\n",
      "\titers: 200, epoch: 35 | loss: 0.0435165\n",
      "\tspeed: 0.0180s/iter; left time: 265.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0431960 Vali Loss: 0.0508146 Test Loss: 0.0550739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0428908\n",
      "\tspeed: 0.0300s/iter; left time: 437.9002s\n",
      "\titers: 200, epoch: 36 | loss: 0.0435042\n",
      "\tspeed: 0.0136s/iter; left time: 197.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0432426 Vali Loss: 0.0508056 Test Loss: 0.0550212\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0414643\n",
      "\tspeed: 0.0313s/iter; left time: 449.8828s\n",
      "\titers: 200, epoch: 37 | loss: 0.0462129\n",
      "\tspeed: 0.0160s/iter; left time: 227.8543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0432394 Vali Loss: 0.0507837 Test Loss: 0.0550466\n",
      "Validation loss decreased (0.050788 --> 0.050784).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0438836\n",
      "\tspeed: 0.0311s/iter; left time: 439.6360s\n",
      "\titers: 200, epoch: 38 | loss: 0.0434997\n",
      "\tspeed: 0.0151s/iter; left time: 211.7402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0431377 Vali Loss: 0.0507243 Test Loss: 0.0550147\n",
      "Validation loss decreased (0.050784 --> 0.050724).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0439870\n",
      "\tspeed: 0.0333s/iter; left time: 463.1491s\n",
      "\titers: 200, epoch: 39 | loss: 0.0413421\n",
      "\tspeed: 0.0148s/iter; left time: 204.6905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0431094 Vali Loss: 0.0507756 Test Loss: 0.0550088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0430110\n",
      "\tspeed: 0.0328s/iter; left time: 449.0657s\n",
      "\titers: 200, epoch: 40 | loss: 0.0399776\n",
      "\tspeed: 0.0178s/iter; left time: 242.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0431481 Vali Loss: 0.0507613 Test Loss: 0.0550177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0430746\n",
      "\tspeed: 0.0327s/iter; left time: 440.5936s\n",
      "\titers: 200, epoch: 41 | loss: 0.0433787\n",
      "\tspeed: 0.0148s/iter; left time: 197.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0431525 Vali Loss: 0.0507548 Test Loss: 0.0549703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0449266\n",
      "\tspeed: 0.0327s/iter; left time: 432.5601s\n",
      "\titers: 200, epoch: 42 | loss: 0.0450761\n",
      "\tspeed: 0.0141s/iter; left time: 185.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0431045 Vali Loss: 0.0507354 Test Loss: 0.0549881\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0425885\n",
      "\tspeed: 0.0286s/iter; left time: 371.7344s\n",
      "\titers: 200, epoch: 43 | loss: 0.0434434\n",
      "\tspeed: 0.0145s/iter; left time: 187.0688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0430776 Vali Loss: 0.0507072 Test Loss: 0.0549775\n",
      "Validation loss decreased (0.050724 --> 0.050707).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0408435\n",
      "\tspeed: 0.0336s/iter; left time: 429.3466s\n",
      "\titers: 200, epoch: 44 | loss: 0.0427987\n",
      "\tspeed: 0.0163s/iter; left time: 206.1990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0431057 Vali Loss: 0.0507314 Test Loss: 0.0549798\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0409385\n",
      "\tspeed: 0.0294s/iter; left time: 368.6161s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418524\n",
      "\tspeed: 0.0152s/iter; left time: 188.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0430653 Vali Loss: 0.0506809 Test Loss: 0.0549721\n",
      "Validation loss decreased (0.050707 --> 0.050681).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0453043\n",
      "\tspeed: 0.0307s/iter; left time: 378.9254s\n",
      "\titers: 200, epoch: 46 | loss: 0.0438552\n",
      "\tspeed: 0.0140s/iter; left time: 171.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0431330 Vali Loss: 0.0507187 Test Loss: 0.0549790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0424765\n",
      "\tspeed: 0.0294s/iter; left time: 355.7503s\n",
      "\titers: 200, epoch: 47 | loss: 0.0439590\n",
      "\tspeed: 0.0161s/iter; left time: 193.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0431166 Vali Loss: 0.0506662 Test Loss: 0.0549689\n",
      "Validation loss decreased (0.050681 --> 0.050666).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0411980\n",
      "\tspeed: 0.0319s/iter; left time: 378.5916s\n",
      "\titers: 200, epoch: 48 | loss: 0.0395439\n",
      "\tspeed: 0.0148s/iter; left time: 174.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0430564 Vali Loss: 0.0506900 Test Loss: 0.0549860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0436099\n",
      "\tspeed: 0.0326s/iter; left time: 379.6568s\n",
      "\titers: 200, epoch: 49 | loss: 0.0429440\n",
      "\tspeed: 0.0175s/iter; left time: 201.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0431119 Vali Loss: 0.0506990 Test Loss: 0.0549716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0450417\n",
      "\tspeed: 0.0327s/iter; left time: 373.8165s\n",
      "\titers: 200, epoch: 50 | loss: 0.0444434\n",
      "\tspeed: 0.0153s/iter; left time: 173.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0431149 Vali Loss: 0.0507101 Test Loss: 0.0549725\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0421611\n",
      "\tspeed: 0.0296s/iter; left time: 331.6193s\n",
      "\titers: 200, epoch: 51 | loss: 0.0435321\n",
      "\tspeed: 0.0145s/iter; left time: 161.2008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 226 | Train Loss: 0.0431035 Vali Loss: 0.0507139 Test Loss: 0.0549482\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0424182\n",
      "\tspeed: 0.0315s/iter; left time: 345.6264s\n",
      "\titers: 200, epoch: 52 | loss: 0.0442301\n",
      "\tspeed: 0.0134s/iter; left time: 146.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0430737 Vali Loss: 0.0506744 Test Loss: 0.0549734\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0436164\n",
      "\tspeed: 0.0297s/iter; left time: 319.5459s\n",
      "\titers: 200, epoch: 53 | loss: 0.0433913\n",
      "\tspeed: 0.0134s/iter; left time: 142.6351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 226 | Train Loss: 0.0430618 Vali Loss: 0.0506472 Test Loss: 0.0549666\n",
      "Validation loss decreased (0.050666 --> 0.050647).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0452793\n",
      "\tspeed: 0.0299s/iter; left time: 315.0854s\n",
      "\titers: 200, epoch: 54 | loss: 0.0407006\n",
      "\tspeed: 0.0126s/iter; left time: 131.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0430745 Vali Loss: 0.0507148 Test Loss: 0.0549333\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0468082\n",
      "\tspeed: 0.0338s/iter; left time: 348.2679s\n",
      "\titers: 200, epoch: 55 | loss: 0.0439261\n",
      "\tspeed: 0.0145s/iter; left time: 148.0336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0430622 Vali Loss: 0.0506985 Test Loss: 0.0549541\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0430603\n",
      "\tspeed: 0.0343s/iter; left time: 345.7739s\n",
      "\titers: 200, epoch: 56 | loss: 0.0444989\n",
      "\tspeed: 0.0181s/iter; left time: 180.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0430448 Vali Loss: 0.0506888 Test Loss: 0.0549399\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0414006\n",
      "\tspeed: 0.0308s/iter; left time: 303.2937s\n",
      "\titers: 200, epoch: 57 | loss: 0.0450305\n",
      "\tspeed: 0.0144s/iter; left time: 140.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0430492 Vali Loss: 0.0506665 Test Loss: 0.0549662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0417495\n",
      "\tspeed: 0.0353s/iter; left time: 339.9971s\n",
      "\titers: 200, epoch: 58 | loss: 0.0408005\n",
      "\tspeed: 0.0174s/iter; left time: 165.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0430744 Vali Loss: 0.0506372 Test Loss: 0.0549693\n",
      "Validation loss decreased (0.050647 --> 0.050637).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0430800\n",
      "\tspeed: 0.0309s/iter; left time: 290.4302s\n",
      "\titers: 200, epoch: 59 | loss: 0.0434624\n",
      "\tspeed: 0.0139s/iter; left time: 129.5302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 226 | Train Loss: 0.0430344 Vali Loss: 0.0506865 Test Loss: 0.0549351\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0435798\n",
      "\tspeed: 0.0295s/iter; left time: 270.7425s\n",
      "\titers: 200, epoch: 60 | loss: 0.0420732\n",
      "\tspeed: 0.0134s/iter; left time: 121.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0431092 Vali Loss: 0.0506773 Test Loss: 0.0549537\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0438269\n",
      "\tspeed: 0.0292s/iter; left time: 261.1811s\n",
      "\titers: 200, epoch: 61 | loss: 0.0431520\n",
      "\tspeed: 0.0133s/iter; left time: 117.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 226 | Train Loss: 0.0430179 Vali Loss: 0.0506042 Test Loss: 0.0549587\n",
      "Validation loss decreased (0.050637 --> 0.050604).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0431973\n",
      "\tspeed: 0.0305s/iter; left time: 266.0090s\n",
      "\titers: 200, epoch: 62 | loss: 0.0424179\n",
      "\tspeed: 0.0148s/iter; left time: 127.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0430668 Vali Loss: 0.0506604 Test Loss: 0.0549420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0418285\n",
      "\tspeed: 0.0312s/iter; left time: 264.8970s\n",
      "\titers: 200, epoch: 63 | loss: 0.0389086\n",
      "\tspeed: 0.0139s/iter; left time: 116.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0430058 Vali Loss: 0.0507011 Test Loss: 0.0549805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0418547\n",
      "\tspeed: 0.0324s/iter; left time: 267.9503s\n",
      "\titers: 200, epoch: 64 | loss: 0.0398098\n",
      "\tspeed: 0.0152s/iter; left time: 124.1057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0430954 Vali Loss: 0.0507379 Test Loss: 0.0549483\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0396600\n",
      "\tspeed: 0.0307s/iter; left time: 246.8064s\n",
      "\titers: 200, epoch: 65 | loss: 0.0430534\n",
      "\tspeed: 0.0155s/iter; left time: 122.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0430633 Vali Loss: 0.0507133 Test Loss: 0.0549578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0433830\n",
      "\tspeed: 0.0306s/iter; left time: 238.8820s\n",
      "\titers: 200, epoch: 66 | loss: 0.0438008\n",
      "\tspeed: 0.0154s/iter; left time: 119.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0430326 Vali Loss: 0.0507192 Test Loss: 0.0549680\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0418150\n",
      "\tspeed: 0.0310s/iter; left time: 235.2219s\n",
      "\titers: 200, epoch: 67 | loss: 0.0436168\n",
      "\tspeed: 0.0150s/iter; left time: 112.1683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0430596 Vali Loss: 0.0507325 Test Loss: 0.0549417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0459583\n",
      "\tspeed: 0.0322s/iter; left time: 236.9397s\n",
      "\titers: 200, epoch: 68 | loss: 0.0476491\n",
      "\tspeed: 0.0155s/iter; left time: 112.2081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0430406 Vali Loss: 0.0506591 Test Loss: 0.0549373\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0429209\n",
      "\tspeed: 0.0331s/iter; left time: 235.7601s\n",
      "\titers: 200, epoch: 69 | loss: 0.0438509\n",
      "\tspeed: 0.0150s/iter; left time: 105.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0430596 Vali Loss: 0.0507226 Test Loss: 0.0549591\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0446244\n",
      "\tspeed: 0.0338s/iter; left time: 233.1309s\n",
      "\titers: 200, epoch: 70 | loss: 0.0410070\n",
      "\tspeed: 0.0137s/iter; left time: 93.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0430196 Vali Loss: 0.0506766 Test Loss: 0.0549500\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0435453\n",
      "\tspeed: 0.0305s/iter; left time: 203.6836s\n",
      "\titers: 200, epoch: 71 | loss: 0.0457425\n",
      "\tspeed: 0.0149s/iter; left time: 97.9617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0430731 Vali Loss: 0.0506899 Test Loss: 0.0549589\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009983686730265617, rmse:0.09991840273141861, mae:0.054958682507276535, rse:0.38548240065574646\n",
      "Intermediate time for FR and pred_len 24: 00h:10m:44.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213823\n",
      "\tspeed: 0.0386s/iter; left time: 864.6235s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003784\n",
      "\tspeed: 0.0132s/iter; left time: 295.3506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.1169873 Vali Loss: 0.1067801 Test Loss: 0.1204125\n",
      "Validation loss decreased (inf --> 0.106780).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0725478\n",
      "\tspeed: 0.0296s/iter; left time: 655.8663s\n",
      "\titers: 200, epoch: 2 | loss: 0.0658032\n",
      "\tspeed: 0.0145s/iter; left time: 319.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0752878 Vali Loss: 0.0782067 Test Loss: 0.0872289\n",
      "Validation loss decreased (0.106780 --> 0.078207).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0654304\n",
      "\tspeed: 0.0311s/iter; left time: 681.7269s\n",
      "\titers: 200, epoch: 3 | loss: 0.0737600\n",
      "\tspeed: 0.0143s/iter; left time: 312.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0685372 Vali Loss: 0.0755081 Test Loss: 0.0849136\n",
      "Validation loss decreased (0.078207 --> 0.075508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659383\n",
      "\tspeed: 0.0321s/iter; left time: 696.6037s\n",
      "\titers: 200, epoch: 4 | loss: 0.0678298\n",
      "\tspeed: 0.0142s/iter; left time: 308.1083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0663274 Vali Loss: 0.0737124 Test Loss: 0.0833804\n",
      "Validation loss decreased (0.075508 --> 0.073712).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0608121\n",
      "\tspeed: 0.0307s/iter; left time: 659.2176s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621299\n",
      "\tspeed: 0.0134s/iter; left time: 287.0028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0650092 Vali Loss: 0.0724081 Test Loss: 0.0821487\n",
      "Validation loss decreased (0.073712 --> 0.072408).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633885\n",
      "\tspeed: 0.0311s/iter; left time: 660.6543s\n",
      "\titers: 200, epoch: 6 | loss: 0.0654834\n",
      "\tspeed: 0.0135s/iter; left time: 285.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0641521 Vali Loss: 0.0717606 Test Loss: 0.0817135\n",
      "Validation loss decreased (0.072408 --> 0.071761).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611005\n",
      "\tspeed: 0.0307s/iter; left time: 647.2040s\n",
      "\titers: 200, epoch: 7 | loss: 0.0627252\n",
      "\tspeed: 0.0165s/iter; left time: 345.5434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0635534 Vali Loss: 0.0710914 Test Loss: 0.0815617\n",
      "Validation loss decreased (0.071761 --> 0.071091).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629593\n",
      "\tspeed: 0.0327s/iter; left time: 680.7846s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609245\n",
      "\tspeed: 0.0152s/iter; left time: 315.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0630446 Vali Loss: 0.0707710 Test Loss: 0.0813526\n",
      "Validation loss decreased (0.071091 --> 0.070771).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0608296\n",
      "\tspeed: 0.0343s/iter; left time: 707.2203s\n",
      "\titers: 200, epoch: 9 | loss: 0.0591662\n",
      "\tspeed: 0.0161s/iter; left time: 330.2802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0626222 Vali Loss: 0.0706569 Test Loss: 0.0810445\n",
      "Validation loss decreased (0.070771 --> 0.070657).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0592829\n",
      "\tspeed: 0.0316s/iter; left time: 643.6322s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633586\n",
      "\tspeed: 0.0161s/iter; left time: 326.3366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0622729 Vali Loss: 0.0703390 Test Loss: 0.0808929\n",
      "Validation loss decreased (0.070657 --> 0.070339).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601474\n",
      "\tspeed: 0.0334s/iter; left time: 672.5835s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592674\n",
      "\tspeed: 0.0162s/iter; left time: 325.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0619831 Vali Loss: 0.0701880 Test Loss: 0.0808096\n",
      "Validation loss decreased (0.070339 --> 0.070188).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0648796\n",
      "\tspeed: 0.0348s/iter; left time: 692.8558s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589895\n",
      "\tspeed: 0.0159s/iter; left time: 315.7080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0616730 Vali Loss: 0.0699925 Test Loss: 0.0806474\n",
      "Validation loss decreased (0.070188 --> 0.069993).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0581306\n",
      "\tspeed: 0.0345s/iter; left time: 679.1610s\n",
      "\titers: 200, epoch: 13 | loss: 0.0584462\n",
      "\tspeed: 0.0150s/iter; left time: 293.5773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0614251 Vali Loss: 0.0698369 Test Loss: 0.0806463\n",
      "Validation loss decreased (0.069993 --> 0.069837).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0593792\n",
      "\tspeed: 0.0331s/iter; left time: 644.2267s\n",
      "\titers: 200, epoch: 14 | loss: 0.0654081\n",
      "\tspeed: 0.0151s/iter; left time: 293.3697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0612237 Vali Loss: 0.0697837 Test Loss: 0.0805190\n",
      "Validation loss decreased (0.069837 --> 0.069784).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0608094\n",
      "\tspeed: 0.0302s/iter; left time: 580.4748s\n",
      "\titers: 200, epoch: 15 | loss: 0.0646425\n",
      "\tspeed: 0.0137s/iter; left time: 262.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.0610841 Vali Loss: 0.0696523 Test Loss: 0.0803047\n",
      "Validation loss decreased (0.069784 --> 0.069652).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0624865\n",
      "\tspeed: 0.0300s/iter; left time: 571.2093s\n",
      "\titers: 200, epoch: 16 | loss: 0.0587738\n",
      "\tspeed: 0.0144s/iter; left time: 272.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0608896 Vali Loss: 0.0695235 Test Loss: 0.0801887\n",
      "Validation loss decreased (0.069652 --> 0.069524).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0598202\n",
      "\tspeed: 0.0330s/iter; left time: 619.7755s\n",
      "\titers: 200, epoch: 17 | loss: 0.0649846\n",
      "\tspeed: 0.0152s/iter; left time: 284.3304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0607565 Vali Loss: 0.0694232 Test Loss: 0.0800491\n",
      "Validation loss decreased (0.069524 --> 0.069423).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0581791\n",
      "\tspeed: 0.0322s/iter; left time: 598.9130s\n",
      "\titers: 200, epoch: 18 | loss: 0.0595902\n",
      "\tspeed: 0.0144s/iter; left time: 265.4565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0606594 Vali Loss: 0.0693742 Test Loss: 0.0799929\n",
      "Validation loss decreased (0.069423 --> 0.069374).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0597893\n",
      "\tspeed: 0.0326s/iter; left time: 598.1709s\n",
      "\titers: 200, epoch: 19 | loss: 0.0573944\n",
      "\tspeed: 0.0150s/iter; left time: 273.7950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0605296 Vali Loss: 0.0693606 Test Loss: 0.0799891\n",
      "Validation loss decreased (0.069374 --> 0.069361).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0603150\n",
      "\tspeed: 0.0330s/iter; left time: 598.2345s\n",
      "\titers: 200, epoch: 20 | loss: 0.0595961\n",
      "\tspeed: 0.0151s/iter; left time: 272.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0604196 Vali Loss: 0.0692521 Test Loss: 0.0798292\n",
      "Validation loss decreased (0.069361 --> 0.069252).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555903\n",
      "\tspeed: 0.0317s/iter; left time: 567.4090s\n",
      "\titers: 200, epoch: 21 | loss: 0.0579108\n",
      "\tspeed: 0.0146s/iter; left time: 260.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0603143 Vali Loss: 0.0692621 Test Loss: 0.0798486\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0568889\n",
      "\tspeed: 0.0318s/iter; left time: 562.2144s\n",
      "\titers: 200, epoch: 22 | loss: 0.0607575\n",
      "\tspeed: 0.0154s/iter; left time: 271.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0602727 Vali Loss: 0.0692234 Test Loss: 0.0798159\n",
      "Validation loss decreased (0.069252 --> 0.069223).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0598051\n",
      "\tspeed: 0.0312s/iter; left time: 544.0210s\n",
      "\titers: 200, epoch: 23 | loss: 0.0636796\n",
      "\tspeed: 0.0138s/iter; left time: 238.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.0602030 Vali Loss: 0.0692164 Test Loss: 0.0797281\n",
      "Validation loss decreased (0.069223 --> 0.069216).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0591035\n",
      "\tspeed: 0.0305s/iter; left time: 526.2224s\n",
      "\titers: 200, epoch: 24 | loss: 0.0578901\n",
      "\tspeed: 0.0156s/iter; left time: 267.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0601221 Vali Loss: 0.0691631 Test Loss: 0.0797442\n",
      "Validation loss decreased (0.069216 --> 0.069163).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0599099\n",
      "\tspeed: 0.0308s/iter; left time: 523.7545s\n",
      "\titers: 200, epoch: 25 | loss: 0.0572757\n",
      "\tspeed: 0.0137s/iter; left time: 230.7790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0600987 Vali Loss: 0.0691796 Test Loss: 0.0797475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625361\n",
      "\tspeed: 0.0301s/iter; left time: 504.5975s\n",
      "\titers: 200, epoch: 26 | loss: 0.0585819\n",
      "\tspeed: 0.0146s/iter; left time: 243.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0600163 Vali Loss: 0.0691020 Test Loss: 0.0797136\n",
      "Validation loss decreased (0.069163 --> 0.069102).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0561144\n",
      "\tspeed: 0.0337s/iter; left time: 557.6544s\n",
      "\titers: 200, epoch: 27 | loss: 0.0621182\n",
      "\tspeed: 0.0156s/iter; left time: 256.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0600040 Vali Loss: 0.0690929 Test Loss: 0.0797266\n",
      "Validation loss decreased (0.069102 --> 0.069093).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0545678\n",
      "\tspeed: 0.0311s/iter; left time: 506.9833s\n",
      "\titers: 200, epoch: 28 | loss: 0.0584432\n",
      "\tspeed: 0.0133s/iter; left time: 215.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.0599764 Vali Loss: 0.0691044 Test Loss: 0.0796324\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0564996\n",
      "\tspeed: 0.0288s/iter; left time: 464.4602s\n",
      "\titers: 200, epoch: 29 | loss: 0.0591064\n",
      "\tspeed: 0.0150s/iter; left time: 240.2355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0599625 Vali Loss: 0.0690716 Test Loss: 0.0796948\n",
      "Validation loss decreased (0.069093 --> 0.069072).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0553428\n",
      "\tspeed: 0.0354s/iter; left time: 561.4160s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573128\n",
      "\tspeed: 0.0181s/iter; left time: 285.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0599181 Vali Loss: 0.0690629 Test Loss: 0.0796169\n",
      "Validation loss decreased (0.069072 --> 0.069063).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0581566\n",
      "\tspeed: 0.0332s/iter; left time: 520.3369s\n",
      "\titers: 200, epoch: 31 | loss: 0.0565621\n",
      "\tspeed: 0.0143s/iter; left time: 222.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0598924 Vali Loss: 0.0690307 Test Loss: 0.0796146\n",
      "Validation loss decreased (0.069063 --> 0.069031).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0566731\n",
      "\tspeed: 0.0319s/iter; left time: 491.6295s\n",
      "\titers: 200, epoch: 32 | loss: 0.0565127\n",
      "\tspeed: 0.0132s/iter; left time: 202.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0598583 Vali Loss: 0.0690180 Test Loss: 0.0796190\n",
      "Validation loss decreased (0.069031 --> 0.069018).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0585185\n",
      "\tspeed: 0.0335s/iter; left time: 509.5955s\n",
      "\titers: 200, epoch: 33 | loss: 0.0637883\n",
      "\tspeed: 0.0155s/iter; left time: 233.3913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0598220 Vali Loss: 0.0690233 Test Loss: 0.0795789\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0569318\n",
      "\tspeed: 0.0328s/iter; left time: 491.1817s\n",
      "\titers: 200, epoch: 34 | loss: 0.0610022\n",
      "\tspeed: 0.0153s/iter; left time: 227.5849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0598034 Vali Loss: 0.0689963 Test Loss: 0.0795843\n",
      "Validation loss decreased (0.069018 --> 0.068996).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0573208\n",
      "\tspeed: 0.0335s/iter; left time: 494.6475s\n",
      "\titers: 200, epoch: 35 | loss: 0.0581069\n",
      "\tspeed: 0.0152s/iter; left time: 222.8005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0598130 Vali Loss: 0.0689925 Test Loss: 0.0795500\n",
      "Validation loss decreased (0.068996 --> 0.068992).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0575978\n",
      "\tspeed: 0.0358s/iter; left time: 519.4919s\n",
      "\titers: 200, epoch: 36 | loss: 0.0620271\n",
      "\tspeed: 0.0184s/iter; left time: 265.6976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0597835 Vali Loss: 0.0689963 Test Loss: 0.0795624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0629052\n",
      "\tspeed: 0.0360s/iter; left time: 515.1916s\n",
      "\titers: 200, epoch: 37 | loss: 0.0599837\n",
      "\tspeed: 0.0169s/iter; left time: 240.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0597588 Vali Loss: 0.0689877 Test Loss: 0.0795335\n",
      "Validation loss decreased (0.068992 --> 0.068988).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0563973\n",
      "\tspeed: 0.0315s/iter; left time: 442.9452s\n",
      "\titers: 200, epoch: 38 | loss: 0.0610352\n",
      "\tspeed: 0.0126s/iter; left time: 175.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0597486 Vali Loss: 0.0689899 Test Loss: 0.0795366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0595938\n",
      "\tspeed: 0.0348s/iter; left time: 481.7968s\n",
      "\titers: 200, epoch: 39 | loss: 0.0583497\n",
      "\tspeed: 0.0179s/iter; left time: 245.9751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0597433 Vali Loss: 0.0689745 Test Loss: 0.0795172\n",
      "Validation loss decreased (0.068988 --> 0.068974).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0587257\n",
      "\tspeed: 0.0322s/iter; left time: 438.3195s\n",
      "\titers: 200, epoch: 40 | loss: 0.0595718\n",
      "\tspeed: 0.0150s/iter; left time: 202.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0597524 Vali Loss: 0.0689715 Test Loss: 0.0795386\n",
      "Validation loss decreased (0.068974 --> 0.068971).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0597586\n",
      "\tspeed: 0.0373s/iter; left time: 500.0949s\n",
      "\titers: 200, epoch: 41 | loss: 0.0618395\n",
      "\tspeed: 0.0137s/iter; left time: 182.2436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0597164 Vali Loss: 0.0689693 Test Loss: 0.0795098\n",
      "Validation loss decreased (0.068971 --> 0.068969).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0597888\n",
      "\tspeed: 0.0349s/iter; left time: 459.3531s\n",
      "\titers: 200, epoch: 42 | loss: 0.0598853\n",
      "\tspeed: 0.0178s/iter; left time: 232.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0597340 Vali Loss: 0.0689551 Test Loss: 0.0795153\n",
      "Validation loss decreased (0.068969 --> 0.068955).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0592168\n",
      "\tspeed: 0.0327s/iter; left time: 422.9504s\n",
      "\titers: 200, epoch: 43 | loss: 0.0603936\n",
      "\tspeed: 0.0164s/iter; left time: 211.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0597652 Vali Loss: 0.0689620 Test Loss: 0.0795028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0601188\n",
      "\tspeed: 0.0262s/iter; left time: 334.0289s\n",
      "\titers: 200, epoch: 44 | loss: 0.0605698\n",
      "\tspeed: 0.0094s/iter; left time: 118.6032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.38s\n",
      "Steps: 225 | Train Loss: 0.0596918 Vali Loss: 0.0689553 Test Loss: 0.0794943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0586773\n",
      "\tspeed: 0.0304s/iter; left time: 379.4184s\n",
      "\titers: 200, epoch: 45 | loss: 0.0617036\n",
      "\tspeed: 0.0147s/iter; left time: 182.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0596868 Vali Loss: 0.0689556 Test Loss: 0.0794982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618185\n",
      "\tspeed: 0.0285s/iter; left time: 349.5862s\n",
      "\titers: 200, epoch: 46 | loss: 0.0646542\n",
      "\tspeed: 0.0119s/iter; left time: 144.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0596928 Vali Loss: 0.0689437 Test Loss: 0.0795057\n",
      "Validation loss decreased (0.068955 --> 0.068944).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0583597\n",
      "\tspeed: 0.0348s/iter; left time: 419.6704s\n",
      "\titers: 200, epoch: 47 | loss: 0.0583405\n",
      "\tspeed: 0.0159s/iter; left time: 189.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0596612 Vali Loss: 0.0689433 Test Loss: 0.0794936\n",
      "Validation loss decreased (0.068944 --> 0.068943).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0606550\n",
      "\tspeed: 0.0333s/iter; left time: 393.9472s\n",
      "\titers: 200, epoch: 48 | loss: 0.0594275\n",
      "\tspeed: 0.0143s/iter; left time: 167.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0597076 Vali Loss: 0.0689452 Test Loss: 0.0794919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0609405\n",
      "\tspeed: 0.0316s/iter; left time: 366.2562s\n",
      "\titers: 200, epoch: 49 | loss: 0.0600403\n",
      "\tspeed: 0.0152s/iter; left time: 174.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0596972 Vali Loss: 0.0689446 Test Loss: 0.0794853\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0569790\n",
      "\tspeed: 0.0312s/iter; left time: 354.4823s\n",
      "\titers: 200, epoch: 50 | loss: 0.0577743\n",
      "\tspeed: 0.0135s/iter; left time: 152.3622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0596819 Vali Loss: 0.0689523 Test Loss: 0.0794748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0609089\n",
      "\tspeed: 0.0300s/iter; left time: 334.1670s\n",
      "\titers: 200, epoch: 51 | loss: 0.0623931\n",
      "\tspeed: 0.0134s/iter; left time: 147.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0596696 Vali Loss: 0.0689478 Test Loss: 0.0794740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0598864\n",
      "\tspeed: 0.0333s/iter; left time: 363.4291s\n",
      "\titers: 200, epoch: 52 | loss: 0.0598405\n",
      "\tspeed: 0.0151s/iter; left time: 163.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0596796 Vali Loss: 0.0689432 Test Loss: 0.0794791\n",
      "Validation loss decreased (0.068943 --> 0.068943).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0646322\n",
      "\tspeed: 0.0318s/iter; left time: 340.1053s\n",
      "\titers: 200, epoch: 53 | loss: 0.0589214\n",
      "\tspeed: 0.0161s/iter; left time: 171.1102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0597133 Vali Loss: 0.0689543 Test Loss: 0.0794673\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0608479\n",
      "\tspeed: 0.0309s/iter; left time: 323.5582s\n",
      "\titers: 200, epoch: 54 | loss: 0.0568962\n",
      "\tspeed: 0.0153s/iter; left time: 158.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0596907 Vali Loss: 0.0689463 Test Loss: 0.0794681\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0638975\n",
      "\tspeed: 0.0305s/iter; left time: 312.6680s\n",
      "\titers: 200, epoch: 55 | loss: 0.0603004\n",
      "\tspeed: 0.0165s/iter; left time: 167.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0596891 Vali Loss: 0.0689456 Test Loss: 0.0794770\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0581549\n",
      "\tspeed: 0.0362s/iter; left time: 363.2748s\n",
      "\titers: 200, epoch: 56 | loss: 0.0552598\n",
      "\tspeed: 0.0145s/iter; left time: 143.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0596648 Vali Loss: 0.0689480 Test Loss: 0.0794591\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0646493\n",
      "\tspeed: 0.0326s/iter; left time: 319.2798s\n",
      "\titers: 200, epoch: 57 | loss: 0.0574132\n",
      "\tspeed: 0.0140s/iter; left time: 135.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0596975 Vali Loss: 0.0689565 Test Loss: 0.0794625\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0646270\n",
      "\tspeed: 0.0308s/iter; left time: 294.7417s\n",
      "\titers: 200, epoch: 58 | loss: 0.0633809\n",
      "\tspeed: 0.0133s/iter; left time: 126.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0596310 Vali Loss: 0.0689464 Test Loss: 0.0794614\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0563880\n",
      "\tspeed: 0.0308s/iter; left time: 287.7884s\n",
      "\titers: 200, epoch: 59 | loss: 0.0610217\n",
      "\tspeed: 0.0133s/iter; left time: 123.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0596401 Vali Loss: 0.0689423 Test Loss: 0.0794692\n",
      "Validation loss decreased (0.068943 --> 0.068942).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0591329\n",
      "\tspeed: 0.0316s/iter; left time: 288.7422s\n",
      "\titers: 200, epoch: 60 | loss: 0.0548014\n",
      "\tspeed: 0.0140s/iter; left time: 126.7398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0596741 Vali Loss: 0.0689436 Test Loss: 0.0794608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0626823\n",
      "\tspeed: 0.0322s/iter; left time: 286.8987s\n",
      "\titers: 200, epoch: 61 | loss: 0.0533003\n",
      "\tspeed: 0.0139s/iter; left time: 122.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0596637 Vali Loss: 0.0689409 Test Loss: 0.0794656\n",
      "Validation loss decreased (0.068942 --> 0.068941).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0603471\n",
      "\tspeed: 0.0326s/iter; left time: 282.9879s\n",
      "\titers: 200, epoch: 62 | loss: 0.0608834\n",
      "\tspeed: 0.0134s/iter; left time: 114.9736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0596634 Vali Loss: 0.0689372 Test Loss: 0.0794732\n",
      "Validation loss decreased (0.068941 --> 0.068937).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0602903\n",
      "\tspeed: 0.0304s/iter; left time: 256.5824s\n",
      "\titers: 200, epoch: 63 | loss: 0.0583523\n",
      "\tspeed: 0.0135s/iter; left time: 112.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0596312 Vali Loss: 0.0689435 Test Loss: 0.0794739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0600427\n",
      "\tspeed: 0.0307s/iter; left time: 252.4986s\n",
      "\titers: 200, epoch: 64 | loss: 0.0595100\n",
      "\tspeed: 0.0136s/iter; left time: 110.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0596662 Vali Loss: 0.0689390 Test Loss: 0.0794699\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0608995\n",
      "\tspeed: 0.0303s/iter; left time: 242.5058s\n",
      "\titers: 200, epoch: 65 | loss: 0.0591059\n",
      "\tspeed: 0.0157s/iter; left time: 124.0013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0596810 Vali Loss: 0.0689364 Test Loss: 0.0794655\n",
      "Validation loss decreased (0.068937 --> 0.068936).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0618175\n",
      "\tspeed: 0.0329s/iter; left time: 255.8673s\n",
      "\titers: 200, epoch: 66 | loss: 0.0565334\n",
      "\tspeed: 0.0150s/iter; left time: 115.2347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0596209 Vali Loss: 0.0689392 Test Loss: 0.0794849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0611173\n",
      "\tspeed: 0.0300s/iter; left time: 226.7791s\n",
      "\titers: 200, epoch: 67 | loss: 0.0579232\n",
      "\tspeed: 0.0148s/iter; left time: 110.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0596636 Vali Loss: 0.0689308 Test Loss: 0.0794691\n",
      "Validation loss decreased (0.068936 --> 0.068931).  Saving model ...\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0592647\n",
      "\tspeed: 0.0329s/iter; left time: 240.7801s\n",
      "\titers: 200, epoch: 68 | loss: 0.0570825\n",
      "\tspeed: 0.0158s/iter; left time: 113.9699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0596565 Vali Loss: 0.0689319 Test Loss: 0.0794679\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0610883\n",
      "\tspeed: 0.0311s/iter; left time: 221.1868s\n",
      "\titers: 200, epoch: 69 | loss: 0.0598903\n",
      "\tspeed: 0.0162s/iter; left time: 113.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0596624 Vali Loss: 0.0689294 Test Loss: 0.0794648\n",
      "Validation loss decreased (0.068931 --> 0.068929).  Saving model ...\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0623557\n",
      "\tspeed: 0.0322s/iter; left time: 221.5839s\n",
      "\titers: 200, epoch: 70 | loss: 0.0599009\n",
      "\tspeed: 0.0156s/iter; left time: 105.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0596753 Vali Loss: 0.0689400 Test Loss: 0.0794624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0554177\n",
      "\tspeed: 0.0263s/iter; left time: 174.8707s\n",
      "\titers: 200, epoch: 71 | loss: 0.0581777\n",
      "\tspeed: 0.0095s/iter; left time: 61.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:02.36s\n",
      "Steps: 225 | Train Loss: 0.0596770 Vali Loss: 0.0689454 Test Loss: 0.0794764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0581497\n",
      "\tspeed: 0.0317s/iter; left time: 203.7757s\n",
      "\titers: 200, epoch: 72 | loss: 0.0620401\n",
      "\tspeed: 0.0160s/iter; left time: 101.0975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0596970 Vali Loss: 0.0689327 Test Loss: 0.0794687\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0585825\n",
      "\tspeed: 0.0349s/iter; left time: 216.1496s\n",
      "\titers: 200, epoch: 73 | loss: 0.0552094\n",
      "\tspeed: 0.0170s/iter; left time: 103.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0596661 Vali Loss: 0.0689421 Test Loss: 0.0794559\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0556363\n",
      "\tspeed: 0.0330s/iter; left time: 197.0234s\n",
      "\titers: 200, epoch: 74 | loss: 0.0612962\n",
      "\tspeed: 0.0154s/iter; left time: 90.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0596135 Vali Loss: 0.0689399 Test Loss: 0.0794641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0606493\n",
      "\tspeed: 0.0332s/iter; left time: 191.0746s\n",
      "\titers: 200, epoch: 75 | loss: 0.0575012\n",
      "\tspeed: 0.0152s/iter; left time: 85.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0596469 Vali Loss: 0.0689273 Test Loss: 0.0794714\n",
      "Validation loss decreased (0.068929 --> 0.068927).  Saving model ...\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0603161\n",
      "\tspeed: 0.0286s/iter; left time: 157.7854s\n",
      "\titers: 200, epoch: 76 | loss: 0.0618575\n",
      "\tspeed: 0.0140s/iter; left time: 75.7577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 225 | Train Loss: 0.0596233 Vali Loss: 0.0689414 Test Loss: 0.0794651\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0611633\n",
      "\tspeed: 0.0311s/iter; left time: 164.8784s\n",
      "\titers: 200, epoch: 77 | loss: 0.0605614\n",
      "\tspeed: 0.0135s/iter; left time: 70.0336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0596649 Vali Loss: 0.0689450 Test Loss: 0.0794628\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0606714\n",
      "\tspeed: 0.0339s/iter; left time: 172.1790s\n",
      "\titers: 200, epoch: 78 | loss: 0.0585585\n",
      "\tspeed: 0.0144s/iter; left time: 71.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0596352 Vali Loss: 0.0689323 Test Loss: 0.0794644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0566387\n",
      "\tspeed: 0.0322s/iter; left time: 156.0923s\n",
      "\titers: 200, epoch: 79 | loss: 0.0611798\n",
      "\tspeed: 0.0146s/iter; left time: 69.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0596002 Vali Loss: 0.0689307 Test Loss: 0.0794622\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0593744\n",
      "\tspeed: 0.0309s/iter; left time: 142.9759s\n",
      "\titers: 200, epoch: 80 | loss: 0.0612360\n",
      "\tspeed: 0.0137s/iter; left time: 62.0132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0596352 Vali Loss: 0.0689433 Test Loss: 0.0794665\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0563210\n",
      "\tspeed: 0.0325s/iter; left time: 142.9972s\n",
      "\titers: 200, epoch: 81 | loss: 0.0587870\n",
      "\tspeed: 0.0152s/iter; left time: 65.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0596278 Vali Loss: 0.0689380 Test Loss: 0.0794680\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.697216055906081e-08\n",
      "\titers: 100, epoch: 82 | loss: 0.0602552\n",
      "\tspeed: 0.0359s/iter; left time: 150.0812s\n",
      "\titers: 200, epoch: 82 | loss: 0.0597390\n",
      "\tspeed: 0.0164s/iter; left time: 66.8811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 82\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0596472 Vali Loss: 0.0689440 Test Loss: 0.0794711\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.427494450315473e-08\n",
      "\titers: 100, epoch: 83 | loss: 0.0583528\n",
      "\tspeed: 0.0309s/iter; left time: 121.9757s\n",
      "\titers: 200, epoch: 83 | loss: 0.0595362\n",
      "\tspeed: 0.0159s/iter; left time: 61.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 83\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0597157 Vali Loss: 0.0689386 Test Loss: 0.0794708\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.1847450052839257e-08\n",
      "\titers: 100, epoch: 84 | loss: 0.0630552\n",
      "\tspeed: 0.0330s/iter; left time: 122.8237s\n",
      "\titers: 200, epoch: 84 | loss: 0.0579049\n",
      "\tspeed: 0.0159s/iter; left time: 57.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 84\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0596781 Vali Loss: 0.0689298 Test Loss: 0.0794627\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9662705047555332e-08\n",
      "\titers: 100, epoch: 85 | loss: 0.0610369\n",
      "\tspeed: 0.0317s/iter; left time: 111.0528s\n",
      "\titers: 200, epoch: 85 | loss: 0.0590663\n",
      "\tspeed: 0.0129s/iter; left time: 43.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 85\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0596737 Vali Loss: 0.0689309 Test Loss: 0.0794660\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019344985485076904, rmse:0.13908624649047852, mae:0.07947136461734772, rse:0.5380225777626038\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265969\n",
      "\tspeed: 0.0176s/iter; left time: 395.1087s\n",
      "\titers: 200, epoch: 1 | loss: 0.1063815\n",
      "\tspeed: 0.0168s/iter; left time: 374.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.1212065 Vali Loss: 0.1106388 Test Loss: 0.1247891\n",
      "Validation loss decreased (inf --> 0.110639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0726923\n",
      "\tspeed: 0.0338s/iter; left time: 749.0917s\n",
      "\titers: 200, epoch: 2 | loss: 0.0651124\n",
      "\tspeed: 0.0155s/iter; left time: 342.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0753340 Vali Loss: 0.0782209 Test Loss: 0.0871643\n",
      "Validation loss decreased (0.110639 --> 0.078221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675197\n",
      "\tspeed: 0.0314s/iter; left time: 688.2629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0698097\n",
      "\tspeed: 0.0150s/iter; left time: 328.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0684049 Vali Loss: 0.0753145 Test Loss: 0.0844544\n",
      "Validation loss decreased (0.078221 --> 0.075314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629576\n",
      "\tspeed: 0.0339s/iter; left time: 736.9249s\n",
      "\titers: 200, epoch: 4 | loss: 0.0667521\n",
      "\tspeed: 0.0178s/iter; left time: 384.0693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0661466 Vali Loss: 0.0735750 Test Loss: 0.0828782\n",
      "Validation loss decreased (0.075314 --> 0.073575).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622595\n",
      "\tspeed: 0.0340s/iter; left time: 731.2849s\n",
      "\titers: 200, epoch: 5 | loss: 0.0668401\n",
      "\tspeed: 0.0142s/iter; left time: 304.3658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0649563 Vali Loss: 0.0724820 Test Loss: 0.0820707\n",
      "Validation loss decreased (0.073575 --> 0.072482).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612340\n",
      "\tspeed: 0.0332s/iter; left time: 706.7412s\n",
      "\titers: 200, epoch: 6 | loss: 0.0649718\n",
      "\tspeed: 0.0143s/iter; left time: 302.2883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0640875 Vali Loss: 0.0717320 Test Loss: 0.0818489\n",
      "Validation loss decreased (0.072482 --> 0.071732).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621025\n",
      "\tspeed: 0.0353s/iter; left time: 743.4587s\n",
      "\titers: 200, epoch: 7 | loss: 0.0634640\n",
      "\tspeed: 0.0156s/iter; left time: 326.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0634674 Vali Loss: 0.0713185 Test Loss: 0.0813943\n",
      "Validation loss decreased (0.071732 --> 0.071318).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0614211\n",
      "\tspeed: 0.0299s/iter; left time: 623.0046s\n",
      "\titers: 200, epoch: 8 | loss: 0.0663050\n",
      "\tspeed: 0.0092s/iter; left time: 191.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.50s\n",
      "Steps: 225 | Train Loss: 0.0629554 Vali Loss: 0.0707654 Test Loss: 0.0811295\n",
      "Validation loss decreased (0.071318 --> 0.070765).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606563\n",
      "\tspeed: 0.0317s/iter; left time: 653.4780s\n",
      "\titers: 200, epoch: 9 | loss: 0.0639160\n",
      "\tspeed: 0.0151s/iter; left time: 310.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0625731 Vali Loss: 0.0705492 Test Loss: 0.0808387\n",
      "Validation loss decreased (0.070765 --> 0.070549).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0655406\n",
      "\tspeed: 0.0331s/iter; left time: 673.8247s\n",
      "\titers: 200, epoch: 10 | loss: 0.0627121\n",
      "\tspeed: 0.0123s/iter; left time: 249.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0622088 Vali Loss: 0.0703554 Test Loss: 0.0807831\n",
      "Validation loss decreased (0.070549 --> 0.070355).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628734\n",
      "\tspeed: 0.0333s/iter; left time: 671.0766s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625313\n",
      "\tspeed: 0.0151s/iter; left time: 303.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0619541 Vali Loss: 0.0701499 Test Loss: 0.0804545\n",
      "Validation loss decreased (0.070355 --> 0.070150).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0606386\n",
      "\tspeed: 0.0311s/iter; left time: 619.8135s\n",
      "\titers: 200, epoch: 12 | loss: 0.0597979\n",
      "\tspeed: 0.0133s/iter; left time: 264.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0617049 Vali Loss: 0.0698781 Test Loss: 0.0804695\n",
      "Validation loss decreased (0.070150 --> 0.069878).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0624372\n",
      "\tspeed: 0.0317s/iter; left time: 623.5877s\n",
      "\titers: 200, epoch: 13 | loss: 0.0590518\n",
      "\tspeed: 0.0125s/iter; left time: 244.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0614653 Vali Loss: 0.0698367 Test Loss: 0.0804019\n",
      "Validation loss decreased (0.069878 --> 0.069837).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0586205\n",
      "\tspeed: 0.0320s/iter; left time: 623.1266s\n",
      "\titers: 200, epoch: 14 | loss: 0.0643078\n",
      "\tspeed: 0.0179s/iter; left time: 346.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0613124 Vali Loss: 0.0697598 Test Loss: 0.0802449\n",
      "Validation loss decreased (0.069837 --> 0.069760).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0600653\n",
      "\tspeed: 0.0355s/iter; left time: 682.6461s\n",
      "\titers: 200, epoch: 15 | loss: 0.0642971\n",
      "\tspeed: 0.0107s/iter; left time: 205.3648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0611273 Vali Loss: 0.0696013 Test Loss: 0.0802070\n",
      "Validation loss decreased (0.069760 --> 0.069601).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0636882\n",
      "\tspeed: 0.0329s/iter; left time: 626.6922s\n",
      "\titers: 200, epoch: 16 | loss: 0.0605635\n",
      "\tspeed: 0.0155s/iter; left time: 293.7124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0609925 Vali Loss: 0.0694294 Test Loss: 0.0801130\n",
      "Validation loss decreased (0.069601 --> 0.069429).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0609337\n",
      "\tspeed: 0.0360s/iter; left time: 676.8622s\n",
      "\titers: 200, epoch: 17 | loss: 0.0608502\n",
      "\tspeed: 0.0141s/iter; left time: 263.6130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0608627 Vali Loss: 0.0695443 Test Loss: 0.0800245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0617632\n",
      "\tspeed: 0.0321s/iter; left time: 595.9681s\n",
      "\titers: 200, epoch: 18 | loss: 0.0600895\n",
      "\tspeed: 0.0148s/iter; left time: 273.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0607331 Vali Loss: 0.0694033 Test Loss: 0.0798553\n",
      "Validation loss decreased (0.069429 --> 0.069403).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0581380\n",
      "\tspeed: 0.0312s/iter; left time: 571.9734s\n",
      "\titers: 200, epoch: 19 | loss: 0.0562820\n",
      "\tspeed: 0.0140s/iter; left time: 255.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0606434 Vali Loss: 0.0693711 Test Loss: 0.0798112\n",
      "Validation loss decreased (0.069403 --> 0.069371).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0614532\n",
      "\tspeed: 0.0333s/iter; left time: 603.3267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0626533\n",
      "\tspeed: 0.0151s/iter; left time: 272.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0605646 Vali Loss: 0.0693304 Test Loss: 0.0800112\n",
      "Validation loss decreased (0.069371 --> 0.069330).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0633391\n",
      "\tspeed: 0.0316s/iter; left time: 566.0849s\n",
      "\titers: 200, epoch: 21 | loss: 0.0628270\n",
      "\tspeed: 0.0134s/iter; left time: 238.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0604426 Vali Loss: 0.0692625 Test Loss: 0.0797937\n",
      "Validation loss decreased (0.069330 --> 0.069263).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0617249\n",
      "\tspeed: 0.0319s/iter; left time: 563.8498s\n",
      "\titers: 200, epoch: 22 | loss: 0.0586878\n",
      "\tspeed: 0.0136s/iter; left time: 239.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0604069 Vali Loss: 0.0691886 Test Loss: 0.0798652\n",
      "Validation loss decreased (0.069263 --> 0.069189).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0610317\n",
      "\tspeed: 0.0315s/iter; left time: 550.0854s\n",
      "\titers: 200, epoch: 23 | loss: 0.0607579\n",
      "\tspeed: 0.0134s/iter; left time: 232.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0603276 Vali Loss: 0.0691264 Test Loss: 0.0798281\n",
      "Validation loss decreased (0.069189 --> 0.069126).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0597171\n",
      "\tspeed: 0.0322s/iter; left time: 554.8047s\n",
      "\titers: 200, epoch: 24 | loss: 0.0614180\n",
      "\tspeed: 0.0153s/iter; left time: 262.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0602773 Vali Loss: 0.0691642 Test Loss: 0.0797187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0570604\n",
      "\tspeed: 0.0323s/iter; left time: 549.1400s\n",
      "\titers: 200, epoch: 25 | loss: 0.0606635\n",
      "\tspeed: 0.0165s/iter; left time: 279.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0601868 Vali Loss: 0.0691393 Test Loss: 0.0797516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0590796\n",
      "\tspeed: 0.0331s/iter; left time: 555.3612s\n",
      "\titers: 200, epoch: 26 | loss: 0.0616838\n",
      "\tspeed: 0.0163s/iter; left time: 271.9230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0601670 Vali Loss: 0.0690985 Test Loss: 0.0797814\n",
      "Validation loss decreased (0.069126 --> 0.069098).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0587852\n",
      "\tspeed: 0.0331s/iter; left time: 547.1244s\n",
      "\titers: 200, epoch: 27 | loss: 0.0634757\n",
      "\tspeed: 0.0164s/iter; left time: 269.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0601059 Vali Loss: 0.0690912 Test Loss: 0.0796228\n",
      "Validation loss decreased (0.069098 --> 0.069091).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578824\n",
      "\tspeed: 0.0325s/iter; left time: 529.9648s\n",
      "\titers: 200, epoch: 28 | loss: 0.0606145\n",
      "\tspeed: 0.0142s/iter; left time: 230.1130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0600833 Vali Loss: 0.0690673 Test Loss: 0.0796140\n",
      "Validation loss decreased (0.069091 --> 0.069067).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0603172\n",
      "\tspeed: 0.0322s/iter; left time: 518.9809s\n",
      "\titers: 200, epoch: 29 | loss: 0.0593381\n",
      "\tspeed: 0.0127s/iter; left time: 203.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0600886 Vali Loss: 0.0690485 Test Loss: 0.0796309\n",
      "Validation loss decreased (0.069067 --> 0.069048).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0584619\n",
      "\tspeed: 0.0303s/iter; left time: 481.0835s\n",
      "\titers: 200, epoch: 30 | loss: 0.0606650\n",
      "\tspeed: 0.0142s/iter; left time: 224.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0600345 Vali Loss: 0.0690103 Test Loss: 0.0796257\n",
      "Validation loss decreased (0.069048 --> 0.069010).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0594551\n",
      "\tspeed: 0.0368s/iter; left time: 575.9167s\n",
      "\titers: 200, epoch: 31 | loss: 0.0588037\n",
      "\tspeed: 0.0162s/iter; left time: 252.6939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0600269 Vali Loss: 0.0690253 Test Loss: 0.0796102\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0613049\n",
      "\tspeed: 0.0314s/iter; left time: 484.7297s\n",
      "\titers: 200, epoch: 32 | loss: 0.0610945\n",
      "\tspeed: 0.0147s/iter; left time: 225.6129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0599783 Vali Loss: 0.0690008 Test Loss: 0.0796730\n",
      "Validation loss decreased (0.069010 --> 0.069001).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0600670\n",
      "\tspeed: 0.0323s/iter; left time: 491.0467s\n",
      "\titers: 200, epoch: 33 | loss: 0.0591111\n",
      "\tspeed: 0.0139s/iter; left time: 210.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0599753 Vali Loss: 0.0690031 Test Loss: 0.0796411\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0565951\n",
      "\tspeed: 0.0310s/iter; left time: 464.3154s\n",
      "\titers: 200, epoch: 34 | loss: 0.0576973\n",
      "\tspeed: 0.0130s/iter; left time: 193.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0599354 Vali Loss: 0.0689930 Test Loss: 0.0796034\n",
      "Validation loss decreased (0.069001 --> 0.068993).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0612601\n",
      "\tspeed: 0.0343s/iter; left time: 506.6558s\n",
      "\titers: 200, epoch: 35 | loss: 0.0607707\n",
      "\tspeed: 0.0186s/iter; left time: 272.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0599439 Vali Loss: 0.0689817 Test Loss: 0.0795837\n",
      "Validation loss decreased (0.068993 --> 0.068982).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0615103\n",
      "\tspeed: 0.0360s/iter; left time: 523.0152s\n",
      "\titers: 200, epoch: 36 | loss: 0.0604886\n",
      "\tspeed: 0.0160s/iter; left time: 231.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0599220 Vali Loss: 0.0689686 Test Loss: 0.0795313\n",
      "Validation loss decreased (0.068982 --> 0.068969).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592824\n",
      "\tspeed: 0.0334s/iter; left time: 477.6299s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558640\n",
      "\tspeed: 0.0148s/iter; left time: 209.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0599191 Vali Loss: 0.0689681 Test Loss: 0.0795878\n",
      "Validation loss decreased (0.068969 --> 0.068968).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0578047\n",
      "\tspeed: 0.0351s/iter; left time: 493.8653s\n",
      "\titers: 200, epoch: 38 | loss: 0.0588840\n",
      "\tspeed: 0.0153s/iter; left time: 213.4089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0598884 Vali Loss: 0.0689614 Test Loss: 0.0795333\n",
      "Validation loss decreased (0.068968 --> 0.068961).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0591957\n",
      "\tspeed: 0.0328s/iter; left time: 454.9039s\n",
      "\titers: 200, epoch: 39 | loss: 0.0613815\n",
      "\tspeed: 0.0160s/iter; left time: 219.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0598854 Vali Loss: 0.0689605 Test Loss: 0.0795795\n",
      "Validation loss decreased (0.068961 --> 0.068960).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0609257\n",
      "\tspeed: 0.0320s/iter; left time: 435.7258s\n",
      "\titers: 200, epoch: 40 | loss: 0.0579021\n",
      "\tspeed: 0.0135s/iter; left time: 182.6537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0598850 Vali Loss: 0.0689521 Test Loss: 0.0795158\n",
      "Validation loss decreased (0.068960 --> 0.068952).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0611246\n",
      "\tspeed: 0.0301s/iter; left time: 403.0593s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582921\n",
      "\tspeed: 0.0134s/iter; left time: 177.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0599035 Vali Loss: 0.0689318 Test Loss: 0.0795444\n",
      "Validation loss decreased (0.068952 --> 0.068932).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0593279\n",
      "\tspeed: 0.0344s/iter; left time: 452.6939s\n",
      "\titers: 200, epoch: 42 | loss: 0.0592907\n",
      "\tspeed: 0.0119s/iter; left time: 155.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0598704 Vali Loss: 0.0689341 Test Loss: 0.0795376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0604258\n",
      "\tspeed: 0.0303s/iter; left time: 391.9890s\n",
      "\titers: 200, epoch: 43 | loss: 0.0550796\n",
      "\tspeed: 0.0153s/iter; left time: 196.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0598594 Vali Loss: 0.0689363 Test Loss: 0.0795179\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0619930\n",
      "\tspeed: 0.0319s/iter; left time: 406.5730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0608519\n",
      "\tspeed: 0.0147s/iter; left time: 185.0414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0598158 Vali Loss: 0.0689414 Test Loss: 0.0795240\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0575242\n",
      "\tspeed: 0.0295s/iter; left time: 368.9729s\n",
      "\titers: 200, epoch: 45 | loss: 0.0581223\n",
      "\tspeed: 0.0150s/iter; left time: 186.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0598086 Vali Loss: 0.0689420 Test Loss: 0.0795268\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0549411\n",
      "\tspeed: 0.0319s/iter; left time: 391.6391s\n",
      "\titers: 200, epoch: 46 | loss: 0.0637212\n",
      "\tspeed: 0.0131s/iter; left time: 159.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0598263 Vali Loss: 0.0689282 Test Loss: 0.0795401\n",
      "Validation loss decreased (0.068932 --> 0.068928).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0614411\n",
      "\tspeed: 0.0330s/iter; left time: 397.3125s\n",
      "\titers: 200, epoch: 47 | loss: 0.0606728\n",
      "\tspeed: 0.0149s/iter; left time: 177.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0598145 Vali Loss: 0.0689381 Test Loss: 0.0795372\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578328\n",
      "\tspeed: 0.0330s/iter; left time: 390.4766s\n",
      "\titers: 200, epoch: 48 | loss: 0.0616376\n",
      "\tspeed: 0.0186s/iter; left time: 217.5930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0597837 Vali Loss: 0.0689290 Test Loss: 0.0795380\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0614254\n",
      "\tspeed: 0.0321s/iter; left time: 372.5372s\n",
      "\titers: 200, epoch: 49 | loss: 0.0609428\n",
      "\tspeed: 0.0154s/iter; left time: 177.2997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0597650 Vali Loss: 0.0689151 Test Loss: 0.0795572\n",
      "Validation loss decreased (0.068928 --> 0.068915).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0610619\n",
      "\tspeed: 0.0340s/iter; left time: 386.9450s\n",
      "\titers: 200, epoch: 50 | loss: 0.0576747\n",
      "\tspeed: 0.0135s/iter; left time: 152.6685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0597950 Vali Loss: 0.0689185 Test Loss: 0.0795231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0564069\n",
      "\tspeed: 0.0308s/iter; left time: 342.9122s\n",
      "\titers: 200, epoch: 51 | loss: 0.0583789\n",
      "\tspeed: 0.0134s/iter; left time: 148.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0598026 Vali Loss: 0.0689218 Test Loss: 0.0795270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0580011\n",
      "\tspeed: 0.0286s/iter; left time: 312.8048s\n",
      "\titers: 200, epoch: 52 | loss: 0.0572442\n",
      "\tspeed: 0.0133s/iter; left time: 144.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0597953 Vali Loss: 0.0689217 Test Loss: 0.0794972\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0600070\n",
      "\tspeed: 0.0319s/iter; left time: 341.7272s\n",
      "\titers: 200, epoch: 53 | loss: 0.0576279\n",
      "\tspeed: 0.0138s/iter; left time: 145.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0597862 Vali Loss: 0.0689239 Test Loss: 0.0795266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0600467\n",
      "\tspeed: 0.0327s/iter; left time: 342.3778s\n",
      "\titers: 200, epoch: 54 | loss: 0.0601599\n",
      "\tspeed: 0.0161s/iter; left time: 167.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0597977 Vali Loss: 0.0689253 Test Loss: 0.0795236\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0595993\n",
      "\tspeed: 0.0311s/iter; left time: 319.2911s\n",
      "\titers: 200, epoch: 55 | loss: 0.0618363\n",
      "\tspeed: 0.0099s/iter; left time: 100.5089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 225 | Train Loss: 0.0597907 Vali Loss: 0.0689346 Test Loss: 0.0795054\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0588265\n",
      "\tspeed: 0.0330s/iter; left time: 330.4688s\n",
      "\titers: 200, epoch: 56 | loss: 0.0551803\n",
      "\tspeed: 0.0164s/iter; left time: 162.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0598149 Vali Loss: 0.0689248 Test Loss: 0.0795008\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0583238\n",
      "\tspeed: 0.0303s/iter; left time: 297.0481s\n",
      "\titers: 200, epoch: 57 | loss: 0.0605104\n",
      "\tspeed: 0.0145s/iter; left time: 141.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0597758 Vali Loss: 0.0689249 Test Loss: 0.0795152\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598935\n",
      "\tspeed: 0.0314s/iter; left time: 300.4059s\n",
      "\titers: 200, epoch: 58 | loss: 0.0634753\n",
      "\tspeed: 0.0137s/iter; left time: 130.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0598003 Vali Loss: 0.0689223 Test Loss: 0.0795031\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0621105\n",
      "\tspeed: 0.0346s/iter; left time: 323.2120s\n",
      "\titers: 200, epoch: 59 | loss: 0.0562835\n",
      "\tspeed: 0.0161s/iter; left time: 148.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0598048 Vali Loss: 0.0689187 Test Loss: 0.0795015\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01942446082830429, rmse:0.13937166333198547, mae:0.07955726981163025, rse:0.5391266345977783\n",
      "Intermediate time for FR and pred_len 96: 00h:11m:27.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1258872\n",
      "\tspeed: 0.0383s/iter; left time: 857.7080s\n",
      "\titers: 200, epoch: 1 | loss: 0.1043407\n",
      "\tspeed: 0.0130s/iter; left time: 290.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.1215116 Vali Loss: 0.1116988 Test Loss: 0.1250417\n",
      "Validation loss decreased (inf --> 0.111699).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0793092\n",
      "\tspeed: 0.0327s/iter; left time: 724.1675s\n",
      "\titers: 200, epoch: 2 | loss: 0.0760325\n",
      "\tspeed: 0.0153s/iter; left time: 336.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0796248 Vali Loss: 0.0824996 Test Loss: 0.0922268\n",
      "Validation loss decreased (0.111699 --> 0.082500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0715488\n",
      "\tspeed: 0.0360s/iter; left time: 789.2029s\n",
      "\titers: 200, epoch: 3 | loss: 0.0704534\n",
      "\tspeed: 0.0169s/iter; left time: 368.9655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0729833 Vali Loss: 0.0798713 Test Loss: 0.0903077\n",
      "Validation loss decreased (0.082500 --> 0.079871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0705439\n",
      "\tspeed: 0.0324s/iter; left time: 703.1048s\n",
      "\titers: 200, epoch: 4 | loss: 0.0683970\n",
      "\tspeed: 0.0136s/iter; left time: 293.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0708504 Vali Loss: 0.0778271 Test Loss: 0.0883018\n",
      "Validation loss decreased (0.079871 --> 0.077827).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0706255\n",
      "\tspeed: 0.0363s/iter; left time: 780.1042s\n",
      "\titers: 200, epoch: 5 | loss: 0.0729319\n",
      "\tspeed: 0.0179s/iter; left time: 383.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0695266 Vali Loss: 0.0768630 Test Loss: 0.0875201\n",
      "Validation loss decreased (0.077827 --> 0.076863).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0681359\n",
      "\tspeed: 0.0344s/iter; left time: 732.8063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708224\n",
      "\tspeed: 0.0131s/iter; left time: 278.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0686947 Vali Loss: 0.0761098 Test Loss: 0.0869796\n",
      "Validation loss decreased (0.076863 --> 0.076110).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0665808\n",
      "\tspeed: 0.0329s/iter; left time: 693.2564s\n",
      "\titers: 200, epoch: 7 | loss: 0.0660063\n",
      "\tspeed: 0.0163s/iter; left time: 340.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0680987 Vali Loss: 0.0758144 Test Loss: 0.0869007\n",
      "Validation loss decreased (0.076110 --> 0.075814).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0693738\n",
      "\tspeed: 0.0331s/iter; left time: 689.4244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0686061\n",
      "\tspeed: 0.0158s/iter; left time: 328.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0676694 Vali Loss: 0.0754771 Test Loss: 0.0863237\n",
      "Validation loss decreased (0.075814 --> 0.075477).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673824\n",
      "\tspeed: 0.0298s/iter; left time: 613.9353s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725628\n",
      "\tspeed: 0.0096s/iter; left time: 196.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.46s\n",
      "Steps: 225 | Train Loss: 0.0673279 Vali Loss: 0.0754616 Test Loss: 0.0862789\n",
      "Validation loss decreased (0.075477 --> 0.075462).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0627660\n",
      "\tspeed: 0.0318s/iter; left time: 648.8035s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632403\n",
      "\tspeed: 0.0150s/iter; left time: 304.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0669887 Vali Loss: 0.0752260 Test Loss: 0.0860723\n",
      "Validation loss decreased (0.075462 --> 0.075226).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0689703\n",
      "\tspeed: 0.0343s/iter; left time: 691.6342s\n",
      "\titers: 200, epoch: 11 | loss: 0.0657837\n",
      "\tspeed: 0.0170s/iter; left time: 340.1312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0667313 Vali Loss: 0.0751627 Test Loss: 0.0860943\n",
      "Validation loss decreased (0.075226 --> 0.075163).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0672862\n",
      "\tspeed: 0.0342s/iter; left time: 681.9547s\n",
      "\titers: 200, epoch: 12 | loss: 0.0647125\n",
      "\tspeed: 0.0147s/iter; left time: 291.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0664865 Vali Loss: 0.0749644 Test Loss: 0.0859547\n",
      "Validation loss decreased (0.075163 --> 0.074964).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0693945\n",
      "\tspeed: 0.0325s/iter; left time: 639.8692s\n",
      "\titers: 200, epoch: 13 | loss: 0.0675491\n",
      "\tspeed: 0.0153s/iter; left time: 300.7145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0662356 Vali Loss: 0.0749521 Test Loss: 0.0859110\n",
      "Validation loss decreased (0.074964 --> 0.074952).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0681882\n",
      "\tspeed: 0.0323s/iter; left time: 629.2516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0648769\n",
      "\tspeed: 0.0142s/iter; left time: 274.7867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0660586 Vali Loss: 0.0748286 Test Loss: 0.0859286\n",
      "Validation loss decreased (0.074952 --> 0.074829).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0639147\n",
      "\tspeed: 0.0285s/iter; left time: 548.4299s\n",
      "\titers: 200, epoch: 15 | loss: 0.0680220\n",
      "\tspeed: 0.0145s/iter; left time: 277.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0659389 Vali Loss: 0.0747449 Test Loss: 0.0858723\n",
      "Validation loss decreased (0.074829 --> 0.074745).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692532\n",
      "\tspeed: 0.0338s/iter; left time: 642.7993s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666745\n",
      "\tspeed: 0.0147s/iter; left time: 277.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0657561 Vali Loss: 0.0747773 Test Loss: 0.0858107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616272\n",
      "\tspeed: 0.0324s/iter; left time: 609.3966s\n",
      "\titers: 200, epoch: 17 | loss: 0.0635841\n",
      "\tspeed: 0.0163s/iter; left time: 304.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0656085 Vali Loss: 0.0746083 Test Loss: 0.0857381\n",
      "Validation loss decreased (0.074745 --> 0.074608).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0632637\n",
      "\tspeed: 0.0343s/iter; left time: 637.7079s\n",
      "\titers: 200, epoch: 18 | loss: 0.0674745\n",
      "\tspeed: 0.0141s/iter; left time: 260.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0655185 Vali Loss: 0.0745890 Test Loss: 0.0857365\n",
      "Validation loss decreased (0.074608 --> 0.074589).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661540\n",
      "\tspeed: 0.0348s/iter; left time: 639.0477s\n",
      "\titers: 200, epoch: 19 | loss: 0.0653579\n",
      "\tspeed: 0.0160s/iter; left time: 292.4895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0654265 Vali Loss: 0.0745945 Test Loss: 0.0856025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0659504\n",
      "\tspeed: 0.0323s/iter; left time: 586.0283s\n",
      "\titers: 200, epoch: 20 | loss: 0.0632919\n",
      "\tspeed: 0.0133s/iter; left time: 240.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0653103 Vali Loss: 0.0744990 Test Loss: 0.0855633\n",
      "Validation loss decreased (0.074589 --> 0.074499).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0619959\n",
      "\tspeed: 0.0314s/iter; left time: 562.2361s\n",
      "\titers: 200, epoch: 21 | loss: 0.0623328\n",
      "\tspeed: 0.0146s/iter; left time: 259.4170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0652304 Vali Loss: 0.0744210 Test Loss: 0.0856444\n",
      "Validation loss decreased (0.074499 --> 0.074421).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0683161\n",
      "\tspeed: 0.0357s/iter; left time: 631.8962s\n",
      "\titers: 200, epoch: 22 | loss: 0.0641205\n",
      "\tspeed: 0.0173s/iter; left time: 304.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0651324 Vali Loss: 0.0744943 Test Loss: 0.0855481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0656182\n",
      "\tspeed: 0.0333s/iter; left time: 580.9381s\n",
      "\titers: 200, epoch: 23 | loss: 0.0661729\n",
      "\tspeed: 0.0161s/iter; left time: 279.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0650879 Vali Loss: 0.0744797 Test Loss: 0.0855629\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0649107\n",
      "\tspeed: 0.0316s/iter; left time: 545.0247s\n",
      "\titers: 200, epoch: 24 | loss: 0.0645990\n",
      "\tspeed: 0.0140s/iter; left time: 239.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0650685 Vali Loss: 0.0745192 Test Loss: 0.0856127\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0665415\n",
      "\tspeed: 0.0351s/iter; left time: 597.5310s\n",
      "\titers: 200, epoch: 25 | loss: 0.0624051\n",
      "\tspeed: 0.0141s/iter; left time: 237.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0649990 Vali Loss: 0.0745008 Test Loss: 0.0855686\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0635931\n",
      "\tspeed: 0.0309s/iter; left time: 518.3559s\n",
      "\titers: 200, epoch: 26 | loss: 0.0630282\n",
      "\tspeed: 0.0134s/iter; left time: 223.1915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0649584 Vali Loss: 0.0744799 Test Loss: 0.0854395\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0637910\n",
      "\tspeed: 0.0330s/iter; left time: 546.8431s\n",
      "\titers: 200, epoch: 27 | loss: 0.0653991\n",
      "\tspeed: 0.0120s/iter; left time: 198.1957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0648713 Vali Loss: 0.0743514 Test Loss: 0.0855882\n",
      "Validation loss decreased (0.074421 --> 0.074351).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631014\n",
      "\tspeed: 0.0340s/iter; left time: 555.8796s\n",
      "\titers: 200, epoch: 28 | loss: 0.0619684\n",
      "\tspeed: 0.0148s/iter; left time: 240.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0648625 Vali Loss: 0.0743438 Test Loss: 0.0855041\n",
      "Validation loss decreased (0.074351 --> 0.074344).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0620156\n",
      "\tspeed: 0.0331s/iter; left time: 533.5552s\n",
      "\titers: 200, epoch: 29 | loss: 0.0648259\n",
      "\tspeed: 0.0171s/iter; left time: 273.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0648312 Vali Loss: 0.0743237 Test Loss: 0.0855411\n",
      "Validation loss decreased (0.074344 --> 0.074324).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0633062\n",
      "\tspeed: 0.0339s/iter; left time: 537.7383s\n",
      "\titers: 200, epoch: 30 | loss: 0.0661748\n",
      "\tspeed: 0.0136s/iter; left time: 214.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0647923 Vali Loss: 0.0744031 Test Loss: 0.0854902\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0626394\n",
      "\tspeed: 0.0316s/iter; left time: 495.0174s\n",
      "\titers: 200, epoch: 31 | loss: 0.0654277\n",
      "\tspeed: 0.0153s/iter; left time: 238.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0647657 Vali Loss: 0.0743387 Test Loss: 0.0855049\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0672857\n",
      "\tspeed: 0.0309s/iter; left time: 476.4953s\n",
      "\titers: 200, epoch: 32 | loss: 0.0625080\n",
      "\tspeed: 0.0134s/iter; left time: 205.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0647459 Vali Loss: 0.0743647 Test Loss: 0.0854845\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0665496\n",
      "\tspeed: 0.0317s/iter; left time: 482.3225s\n",
      "\titers: 200, epoch: 33 | loss: 0.0639671\n",
      "\tspeed: 0.0167s/iter; left time: 251.6126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0647123 Vali Loss: 0.0743460 Test Loss: 0.0855061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0655772\n",
      "\tspeed: 0.0327s/iter; left time: 490.3371s\n",
      "\titers: 200, epoch: 34 | loss: 0.0657287\n",
      "\tspeed: 0.0153s/iter; left time: 227.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0647241 Vali Loss: 0.0743112 Test Loss: 0.0854634\n",
      "Validation loss decreased (0.074324 --> 0.074311).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0644394\n",
      "\tspeed: 0.0330s/iter; left time: 486.2145s\n",
      "\titers: 200, epoch: 35 | loss: 0.0615734\n",
      "\tspeed: 0.0147s/iter; left time: 215.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0646942 Vali Loss: 0.0742806 Test Loss: 0.0854705\n",
      "Validation loss decreased (0.074311 --> 0.074281).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0629356\n",
      "\tspeed: 0.0342s/iter; left time: 496.2187s\n",
      "\titers: 200, epoch: 36 | loss: 0.0665615\n",
      "\tspeed: 0.0149s/iter; left time: 214.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0646555 Vali Loss: 0.0743074 Test Loss: 0.0854525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0620728\n",
      "\tspeed: 0.0301s/iter; left time: 429.9241s\n",
      "\titers: 200, epoch: 37 | loss: 0.0662997\n",
      "\tspeed: 0.0144s/iter; left time: 204.5977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0646534 Vali Loss: 0.0743058 Test Loss: 0.0854616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0632380\n",
      "\tspeed: 0.0308s/iter; left time: 433.9124s\n",
      "\titers: 200, epoch: 38 | loss: 0.0678646\n",
      "\tspeed: 0.0126s/iter; left time: 175.6558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0646487 Vali Loss: 0.0743680 Test Loss: 0.0854770\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0657685\n",
      "\tspeed: 0.0349s/iter; left time: 482.9375s\n",
      "\titers: 200, epoch: 39 | loss: 0.0627712\n",
      "\tspeed: 0.0152s/iter; left time: 208.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0646400 Vali Loss: 0.0743357 Test Loss: 0.0854681\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0646729\n",
      "\tspeed: 0.0308s/iter; left time: 420.3431s\n",
      "\titers: 200, epoch: 40 | loss: 0.0647950\n",
      "\tspeed: 0.0157s/iter; left time: 212.0759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0646310 Vali Loss: 0.0743258 Test Loss: 0.0854439\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0665623\n",
      "\tspeed: 0.0325s/iter; left time: 435.5865s\n",
      "\titers: 200, epoch: 41 | loss: 0.0650554\n",
      "\tspeed: 0.0151s/iter; left time: 200.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0646126 Vali Loss: 0.0742821 Test Loss: 0.0854648\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0619531\n",
      "\tspeed: 0.0304s/iter; left time: 401.0039s\n",
      "\titers: 200, epoch: 42 | loss: 0.0660308\n",
      "\tspeed: 0.0151s/iter; left time: 197.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0645987 Vali Loss: 0.0743288 Test Loss: 0.0854469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0639532\n",
      "\tspeed: 0.0300s/iter; left time: 389.1217s\n",
      "\titers: 200, epoch: 43 | loss: 0.0687484\n",
      "\tspeed: 0.0146s/iter; left time: 188.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0646109 Vali Loss: 0.0743431 Test Loss: 0.0854486\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0624166\n",
      "\tspeed: 0.0323s/iter; left time: 410.9298s\n",
      "\titers: 200, epoch: 44 | loss: 0.0641528\n",
      "\tspeed: 0.0141s/iter; left time: 178.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0645842 Vali Loss: 0.0743553 Test Loss: 0.0854481\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0647501\n",
      "\tspeed: 0.0333s/iter; left time: 415.9829s\n",
      "\titers: 200, epoch: 45 | loss: 0.0676617\n",
      "\tspeed: 0.0152s/iter; left time: 188.1452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0645947 Vali Loss: 0.0742990 Test Loss: 0.0854901\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021148676052689552, rmse:0.14542584121227264, mae:0.08547043800354004, rse:0.5632480382919312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262447\n",
      "\tspeed: 0.0151s/iter; left time: 338.2529s\n",
      "\titers: 200, epoch: 1 | loss: 0.1065421\n",
      "\tspeed: 0.0133s/iter; left time: 297.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.1239376 Vali Loss: 0.1142014 Test Loss: 0.1280966\n",
      "Validation loss decreased (inf --> 0.114201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0773990\n",
      "\tspeed: 0.0443s/iter; left time: 982.5881s\n",
      "\titers: 200, epoch: 2 | loss: 0.0732553\n",
      "\tspeed: 0.0198s/iter; left time: 436.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0794889 Vali Loss: 0.0821932 Test Loss: 0.0921642\n",
      "Validation loss decreased (0.114201 --> 0.082193).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0730615\n",
      "\tspeed: 0.0344s/iter; left time: 754.9838s\n",
      "\titers: 200, epoch: 3 | loss: 0.0736323\n",
      "\tspeed: 0.0131s/iter; left time: 286.4363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0728381 Vali Loss: 0.0796778 Test Loss: 0.0900267\n",
      "Validation loss decreased (0.082193 --> 0.079678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0705398\n",
      "\tspeed: 0.0324s/iter; left time: 703.7985s\n",
      "\titers: 200, epoch: 4 | loss: 0.0722703\n",
      "\tspeed: 0.0136s/iter; left time: 293.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0707959 Vali Loss: 0.0778869 Test Loss: 0.0884778\n",
      "Validation loss decreased (0.079678 --> 0.077887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0739031\n",
      "\tspeed: 0.0366s/iter; left time: 786.9812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0695137\n",
      "\tspeed: 0.0140s/iter; left time: 299.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0695066 Vali Loss: 0.0768303 Test Loss: 0.0874475\n",
      "Validation loss decreased (0.077887 --> 0.076830).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0695348\n",
      "\tspeed: 0.0326s/iter; left time: 693.2963s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662840\n",
      "\tspeed: 0.0152s/iter; left time: 322.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0687171 Vali Loss: 0.0761545 Test Loss: 0.0871214\n",
      "Validation loss decreased (0.076830 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0667721\n",
      "\tspeed: 0.0337s/iter; left time: 709.3137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0660048\n",
      "\tspeed: 0.0176s/iter; left time: 368.2187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0681725 Vali Loss: 0.0759595 Test Loss: 0.0866325\n",
      "Validation loss decreased (0.076155 --> 0.075960).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658313\n",
      "\tspeed: 0.0328s/iter; left time: 683.9776s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695821\n",
      "\tspeed: 0.0148s/iter; left time: 307.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0676989 Vali Loss: 0.0755736 Test Loss: 0.0865448\n",
      "Validation loss decreased (0.075960 --> 0.075574).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0662668\n",
      "\tspeed: 0.0329s/iter; left time: 677.3518s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665054\n",
      "\tspeed: 0.0134s/iter; left time: 274.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0673098 Vali Loss: 0.0752899 Test Loss: 0.0863336\n",
      "Validation loss decreased (0.075574 --> 0.075290).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0656422\n",
      "\tspeed: 0.0329s/iter; left time: 671.2597s\n",
      "\titers: 200, epoch: 10 | loss: 0.0694495\n",
      "\tspeed: 0.0140s/iter; left time: 283.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0670054 Vali Loss: 0.0753431 Test Loss: 0.0862107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702948\n",
      "\tspeed: 0.0311s/iter; left time: 626.1337s\n",
      "\titers: 200, epoch: 11 | loss: 0.0668308\n",
      "\tspeed: 0.0143s/iter; left time: 286.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0667298 Vali Loss: 0.0751219 Test Loss: 0.0861265\n",
      "Validation loss decreased (0.075290 --> 0.075122).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0675987\n",
      "\tspeed: 0.0333s/iter; left time: 664.1234s\n",
      "\titers: 200, epoch: 12 | loss: 0.0675760\n",
      "\tspeed: 0.0144s/iter; left time: 284.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0665284 Vali Loss: 0.0750525 Test Loss: 0.0860539\n",
      "Validation loss decreased (0.075122 --> 0.075052).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0705872\n",
      "\tspeed: 0.0327s/iter; left time: 644.7923s\n",
      "\titers: 200, epoch: 13 | loss: 0.0630206\n",
      "\tspeed: 0.0137s/iter; left time: 268.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0663536 Vali Loss: 0.0749314 Test Loss: 0.0859336\n",
      "Validation loss decreased (0.075052 --> 0.074931).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0658375\n",
      "\tspeed: 0.0335s/iter; left time: 651.5530s\n",
      "\titers: 200, epoch: 14 | loss: 0.0643019\n",
      "\tspeed: 0.0141s/iter; left time: 272.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0661280 Vali Loss: 0.0750214 Test Loss: 0.0859440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0640414\n",
      "\tspeed: 0.0341s/iter; left time: 656.0542s\n",
      "\titers: 200, epoch: 15 | loss: 0.0648404\n",
      "\tspeed: 0.0159s/iter; left time: 304.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0659793 Vali Loss: 0.0748129 Test Loss: 0.0859059\n",
      "Validation loss decreased (0.074931 --> 0.074813).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0667890\n",
      "\tspeed: 0.0320s/iter; left time: 608.4825s\n",
      "\titers: 200, epoch: 16 | loss: 0.0658260\n",
      "\tspeed: 0.0138s/iter; left time: 260.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0658176 Vali Loss: 0.0747673 Test Loss: 0.0857556\n",
      "Validation loss decreased (0.074813 --> 0.074767).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0628344\n",
      "\tspeed: 0.0292s/iter; left time: 548.6480s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619174\n",
      "\tspeed: 0.0160s/iter; left time: 300.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0657616 Vali Loss: 0.0747573 Test Loss: 0.0857303\n",
      "Validation loss decreased (0.074767 --> 0.074757).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0653152\n",
      "\tspeed: 0.0341s/iter; left time: 632.8735s\n",
      "\titers: 200, epoch: 18 | loss: 0.0630368\n",
      "\tspeed: 0.0128s/iter; left time: 235.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0656122 Vali Loss: 0.0747454 Test Loss: 0.0857685\n",
      "Validation loss decreased (0.074757 --> 0.074745).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0641864\n",
      "\tspeed: 0.0331s/iter; left time: 607.9831s\n",
      "\titers: 200, epoch: 19 | loss: 0.0681706\n",
      "\tspeed: 0.0147s/iter; left time: 268.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0654879 Vali Loss: 0.0747397 Test Loss: 0.0856718\n",
      "Validation loss decreased (0.074745 --> 0.074740).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0645947\n",
      "\tspeed: 0.0353s/iter; left time: 639.2174s\n",
      "\titers: 200, epoch: 20 | loss: 0.0663105\n",
      "\tspeed: 0.0141s/iter; left time: 255.0550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0654209 Vali Loss: 0.0747094 Test Loss: 0.0856527\n",
      "Validation loss decreased (0.074740 --> 0.074709).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0606214\n",
      "\tspeed: 0.0374s/iter; left time: 669.2217s\n",
      "\titers: 200, epoch: 21 | loss: 0.0665938\n",
      "\tspeed: 0.0143s/iter; left time: 254.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0653247 Vali Loss: 0.0747670 Test Loss: 0.0855692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0655442\n",
      "\tspeed: 0.0380s/iter; left time: 670.8458s\n",
      "\titers: 200, epoch: 22 | loss: 0.0629322\n",
      "\tspeed: 0.0153s/iter; left time: 269.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0652875 Vali Loss: 0.0746993 Test Loss: 0.0856478\n",
      "Validation loss decreased (0.074709 --> 0.074699).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0673781\n",
      "\tspeed: 0.0336s/iter; left time: 586.2199s\n",
      "\titers: 200, epoch: 23 | loss: 0.0619604\n",
      "\tspeed: 0.0132s/iter; left time: 228.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0652223 Vali Loss: 0.0746275 Test Loss: 0.0856059\n",
      "Validation loss decreased (0.074699 --> 0.074628).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0637613\n",
      "\tspeed: 0.0307s/iter; left time: 528.8250s\n",
      "\titers: 200, epoch: 24 | loss: 0.0677873\n",
      "\tspeed: 0.0132s/iter; left time: 225.5512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 225 | Train Loss: 0.0651950 Vali Loss: 0.0746217 Test Loss: 0.0855469\n",
      "Validation loss decreased (0.074628 --> 0.074622).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0652589\n",
      "\tspeed: 0.0332s/iter; left time: 565.1180s\n",
      "\titers: 200, epoch: 25 | loss: 0.0656955\n",
      "\tspeed: 0.0144s/iter; left time: 243.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0651455 Vali Loss: 0.0746904 Test Loss: 0.0856011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0665715\n",
      "\tspeed: 0.0315s/iter; left time: 528.2867s\n",
      "\titers: 200, epoch: 26 | loss: 0.0707949\n",
      "\tspeed: 0.0140s/iter; left time: 234.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0650659 Vali Loss: 0.0745361 Test Loss: 0.0855275\n",
      "Validation loss decreased (0.074622 --> 0.074536).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0623481\n",
      "\tspeed: 0.0319s/iter; left time: 528.2781s\n",
      "\titers: 200, epoch: 27 | loss: 0.0681382\n",
      "\tspeed: 0.0145s/iter; left time: 238.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0650654 Vali Loss: 0.0745329 Test Loss: 0.0854929\n",
      "Validation loss decreased (0.074536 --> 0.074533).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662295\n",
      "\tspeed: 0.0320s/iter; left time: 522.0915s\n",
      "\titers: 200, epoch: 28 | loss: 0.0626323\n",
      "\tspeed: 0.0131s/iter; left time: 213.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0650183 Vali Loss: 0.0746872 Test Loss: 0.0855503\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0631799\n",
      "\tspeed: 0.0347s/iter; left time: 558.8616s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669906\n",
      "\tspeed: 0.0183s/iter; left time: 292.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0650022 Vali Loss: 0.0745405 Test Loss: 0.0854287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0656260\n",
      "\tspeed: 0.0328s/iter; left time: 520.0314s\n",
      "\titers: 200, epoch: 30 | loss: 0.0617092\n",
      "\tspeed: 0.0141s/iter; left time: 222.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0649297 Vali Loss: 0.0745312 Test Loss: 0.0855281\n",
      "Validation loss decreased (0.074533 --> 0.074531).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0635316\n",
      "\tspeed: 0.0329s/iter; left time: 515.2554s\n",
      "\titers: 200, epoch: 31 | loss: 0.0680177\n",
      "\tspeed: 0.0130s/iter; left time: 202.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0649075 Vali Loss: 0.0745935 Test Loss: 0.0854864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0621585\n",
      "\tspeed: 0.0312s/iter; left time: 480.5993s\n",
      "\titers: 200, epoch: 32 | loss: 0.0649349\n",
      "\tspeed: 0.0136s/iter; left time: 207.9664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0648985 Vali Loss: 0.0745371 Test Loss: 0.0855529\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0653301\n",
      "\tspeed: 0.0345s/iter; left time: 523.6872s\n",
      "\titers: 200, epoch: 33 | loss: 0.0623896\n",
      "\tspeed: 0.0162s/iter; left time: 245.0470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0648728 Vali Loss: 0.0745598 Test Loss: 0.0854831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0663584\n",
      "\tspeed: 0.0354s/iter; left time: 529.8091s\n",
      "\titers: 200, epoch: 34 | loss: 0.0619745\n",
      "\tspeed: 0.0148s/iter; left time: 220.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0648609 Vali Loss: 0.0745829 Test Loss: 0.0854206\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0636345\n",
      "\tspeed: 0.0320s/iter; left time: 472.2420s\n",
      "\titers: 200, epoch: 35 | loss: 0.0581857\n",
      "\tspeed: 0.0181s/iter; left time: 265.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0648583 Vali Loss: 0.0745387 Test Loss: 0.0854823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0683366\n",
      "\tspeed: 0.0326s/iter; left time: 473.4287s\n",
      "\titers: 200, epoch: 36 | loss: 0.0596476\n",
      "\tspeed: 0.0148s/iter; left time: 213.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0648165 Vali Loss: 0.0745171 Test Loss: 0.0854651\n",
      "Validation loss decreased (0.074531 --> 0.074517).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669245\n",
      "\tspeed: 0.0344s/iter; left time: 491.4960s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638746\n",
      "\tspeed: 0.0145s/iter; left time: 206.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0648293 Vali Loss: 0.0745460 Test Loss: 0.0854343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0645055\n",
      "\tspeed: 0.0344s/iter; left time: 484.3071s\n",
      "\titers: 200, epoch: 38 | loss: 0.0620562\n",
      "\tspeed: 0.0157s/iter; left time: 219.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0648233 Vali Loss: 0.0744362 Test Loss: 0.0854662\n",
      "Validation loss decreased (0.074517 --> 0.074436).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0661575\n",
      "\tspeed: 0.0345s/iter; left time: 477.7947s\n",
      "\titers: 200, epoch: 39 | loss: 0.0591688\n",
      "\tspeed: 0.0155s/iter; left time: 213.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0648101 Vali Loss: 0.0744878 Test Loss: 0.0854043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0649203\n",
      "\tspeed: 0.0339s/iter; left time: 462.0345s\n",
      "\titers: 200, epoch: 40 | loss: 0.0630749\n",
      "\tspeed: 0.0178s/iter; left time: 240.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0647663 Vali Loss: 0.0745172 Test Loss: 0.0854489\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0631460\n",
      "\tspeed: 0.0335s/iter; left time: 448.9249s\n",
      "\titers: 200, epoch: 41 | loss: 0.0626825\n",
      "\tspeed: 0.0154s/iter; left time: 205.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0648077 Vali Loss: 0.0745423 Test Loss: 0.0854231\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0660521\n",
      "\tspeed: 0.0337s/iter; left time: 444.4363s\n",
      "\titers: 200, epoch: 42 | loss: 0.0650471\n",
      "\tspeed: 0.0158s/iter; left time: 205.9576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0647831 Vali Loss: 0.0745083 Test Loss: 0.0854155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0666450\n",
      "\tspeed: 0.0329s/iter; left time: 426.0222s\n",
      "\titers: 200, epoch: 43 | loss: 0.0623195\n",
      "\tspeed: 0.0139s/iter; left time: 178.3870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0647737 Vali Loss: 0.0744732 Test Loss: 0.0854384\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644399\n",
      "\tspeed: 0.0291s/iter; left time: 369.7483s\n",
      "\titers: 200, epoch: 44 | loss: 0.0686464\n",
      "\tspeed: 0.0139s/iter; left time: 175.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0647383 Vali Loss: 0.0744373 Test Loss: 0.0854154\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0643462\n",
      "\tspeed: 0.0320s/iter; left time: 399.6565s\n",
      "\titers: 200, epoch: 45 | loss: 0.0628127\n",
      "\tspeed: 0.0161s/iter; left time: 200.0496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0647988 Vali Loss: 0.0744602 Test Loss: 0.0854128\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0696332\n",
      "\tspeed: 0.0344s/iter; left time: 421.8754s\n",
      "\titers: 200, epoch: 46 | loss: 0.0635082\n",
      "\tspeed: 0.0149s/iter; left time: 180.8184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0647335 Vali Loss: 0.0744490 Test Loss: 0.0854417\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0620072\n",
      "\tspeed: 0.0330s/iter; left time: 397.1874s\n",
      "\titers: 200, epoch: 47 | loss: 0.0641156\n",
      "\tspeed: 0.0139s/iter; left time: 166.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0647569 Vali Loss: 0.0745012 Test Loss: 0.0854302\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0658502\n",
      "\tspeed: 0.0343s/iter; left time: 406.2207s\n",
      "\titers: 200, epoch: 48 | loss: 0.0637665\n",
      "\tspeed: 0.0123s/iter; left time: 144.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0647194 Vali Loss: 0.0744390 Test Loss: 0.0854558\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02106769010424614, rmse:0.14514712989330292, mae:0.0854661762714386, rse:0.5621685981750488\n",
      "Intermediate time for FR and pred_len 168: 00h:07m:38.90s\n",
      "Intermediate time for FR: 00h:29m:50.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1688540\n",
      "\tspeed: 0.0385s/iter; left time: 865.7649s\n",
      "\titers: 200, epoch: 1 | loss: 0.1365369\n",
      "\tspeed: 0.0136s/iter; left time: 304.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.1629129 Vali Loss: 0.1186366 Test Loss: 0.1237854\n",
      "Validation loss decreased (inf --> 0.118637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0811344\n",
      "\tspeed: 0.0293s/iter; left time: 652.8263s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731165\n",
      "\tspeed: 0.0132s/iter; left time: 292.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 226 | Train Loss: 0.0833996 Vali Loss: 0.0670457 Test Loss: 0.0689502\n",
      "Validation loss decreased (0.118637 --> 0.067046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0713604\n",
      "\tspeed: 0.0293s/iter; left time: 646.2542s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733064\n",
      "\tspeed: 0.0132s/iter; left time: 288.7790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0704432 Vali Loss: 0.0631563 Test Loss: 0.0656336\n",
      "Validation loss decreased (0.067046 --> 0.063156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0706080\n",
      "\tspeed: 0.0305s/iter; left time: 665.7983s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655016\n",
      "\tspeed: 0.0142s/iter; left time: 307.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 226 | Train Loss: 0.0669583 Vali Loss: 0.0609619 Test Loss: 0.0636363\n",
      "Validation loss decreased (0.063156 --> 0.060962).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0664111\n",
      "\tspeed: 0.0323s/iter; left time: 696.5731s\n",
      "\titers: 200, epoch: 5 | loss: 0.0634347\n",
      "\tspeed: 0.0150s/iter; left time: 322.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0646781 Vali Loss: 0.0594751 Test Loss: 0.0622245\n",
      "Validation loss decreased (0.060962 --> 0.059475).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0621110\n",
      "\tspeed: 0.0285s/iter; left time: 608.5952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0589025\n",
      "\tspeed: 0.0134s/iter; left time: 285.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0630219 Vali Loss: 0.0585987 Test Loss: 0.0610940\n",
      "Validation loss decreased (0.059475 --> 0.058599).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0628111\n",
      "\tspeed: 0.0303s/iter; left time: 641.2159s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645528\n",
      "\tspeed: 0.0124s/iter; left time: 260.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0618432 Vali Loss: 0.0578001 Test Loss: 0.0602766\n",
      "Validation loss decreased (0.058599 --> 0.057800).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591710\n",
      "\tspeed: 0.0294s/iter; left time: 614.4157s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629961\n",
      "\tspeed: 0.0132s/iter; left time: 274.7881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 226 | Train Loss: 0.0611048 Vali Loss: 0.0571213 Test Loss: 0.0594751\n",
      "Validation loss decreased (0.057800 --> 0.057121).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654986\n",
      "\tspeed: 0.0324s/iter; left time: 669.7682s\n",
      "\titers: 200, epoch: 9 | loss: 0.0560476\n",
      "\tspeed: 0.0133s/iter; left time: 274.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0604540 Vali Loss: 0.0567259 Test Loss: 0.0591672\n",
      "Validation loss decreased (0.057121 --> 0.056726).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0626866\n",
      "\tspeed: 0.0292s/iter; left time: 598.5554s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589330\n",
      "\tspeed: 0.0127s/iter; left time: 257.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 226 | Train Loss: 0.0599680 Vali Loss: 0.0564665 Test Loss: 0.0590740\n",
      "Validation loss decreased (0.056726 --> 0.056467).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0625371\n",
      "\tspeed: 0.0312s/iter; left time: 631.4089s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602229\n",
      "\tspeed: 0.0143s/iter; left time: 288.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0594691 Vali Loss: 0.0561698 Test Loss: 0.0585758\n",
      "Validation loss decreased (0.056467 --> 0.056170).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0598456\n",
      "\tspeed: 0.0315s/iter; left time: 629.9221s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585936\n",
      "\tspeed: 0.0129s/iter; left time: 257.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0591292 Vali Loss: 0.0562366 Test Loss: 0.0587365\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0611024\n",
      "\tspeed: 0.0296s/iter; left time: 586.2814s\n",
      "\titers: 200, epoch: 13 | loss: 0.0609800\n",
      "\tspeed: 0.0143s/iter; left time: 281.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0588454 Vali Loss: 0.0558012 Test Loss: 0.0583963\n",
      "Validation loss decreased (0.056170 --> 0.055801).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0611674\n",
      "\tspeed: 0.0316s/iter; left time: 618.8937s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597047\n",
      "\tspeed: 0.0173s/iter; left time: 336.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0585403 Vali Loss: 0.0557166 Test Loss: 0.0581479\n",
      "Validation loss decreased (0.055801 --> 0.055717).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0552325\n",
      "\tspeed: 0.0302s/iter; left time: 584.1746s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595853\n",
      "\tspeed: 0.0126s/iter; left time: 243.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0582560 Vali Loss: 0.0556377 Test Loss: 0.0579832\n",
      "Validation loss decreased (0.055717 --> 0.055638).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0586491\n",
      "\tspeed: 0.0300s/iter; left time: 573.0901s\n",
      "\titers: 200, epoch: 16 | loss: 0.0606189\n",
      "\tspeed: 0.0132s/iter; left time: 250.2591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0581239 Vali Loss: 0.0553932 Test Loss: 0.0579077\n",
      "Validation loss decreased (0.055638 --> 0.055393).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0560868\n",
      "\tspeed: 0.0301s/iter; left time: 568.9096s\n",
      "\titers: 200, epoch: 17 | loss: 0.0604636\n",
      "\tspeed: 0.0132s/iter; left time: 248.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0579179 Vali Loss: 0.0553309 Test Loss: 0.0577999\n",
      "Validation loss decreased (0.055393 --> 0.055331).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0585738\n",
      "\tspeed: 0.0326s/iter; left time: 607.3725s\n",
      "\titers: 200, epoch: 18 | loss: 0.0558441\n",
      "\tspeed: 0.0146s/iter; left time: 270.8746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0577718 Vali Loss: 0.0554522 Test Loss: 0.0578241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0565170\n",
      "\tspeed: 0.0306s/iter; left time: 563.9887s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588446\n",
      "\tspeed: 0.0130s/iter; left time: 237.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0575844 Vali Loss: 0.0552963 Test Loss: 0.0576934\n",
      "Validation loss decreased (0.055331 --> 0.055296).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0576712\n",
      "\tspeed: 0.0300s/iter; left time: 546.2702s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550534\n",
      "\tspeed: 0.0129s/iter; left time: 232.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 226 | Train Loss: 0.0574810 Vali Loss: 0.0552230 Test Loss: 0.0576569\n",
      "Validation loss decreased (0.055296 --> 0.055223).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0559713\n",
      "\tspeed: 0.0304s/iter; left time: 545.8627s\n",
      "\titers: 200, epoch: 21 | loss: 0.0549482\n",
      "\tspeed: 0.0129s/iter; left time: 230.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0574165 Vali Loss: 0.0551739 Test Loss: 0.0575921\n",
      "Validation loss decreased (0.055223 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0582178\n",
      "\tspeed: 0.0307s/iter; left time: 545.2449s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564173\n",
      "\tspeed: 0.0130s/iter; left time: 230.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0573509 Vali Loss: 0.0550957 Test Loss: 0.0575808\n",
      "Validation loss decreased (0.055174 --> 0.055096).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0556125\n",
      "\tspeed: 0.0322s/iter; left time: 564.9469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0561993\n",
      "\tspeed: 0.0154s/iter; left time: 269.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0572009 Vali Loss: 0.0550726 Test Loss: 0.0574800\n",
      "Validation loss decreased (0.055096 --> 0.055073).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0595856\n",
      "\tspeed: 0.0321s/iter; left time: 555.6268s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544058\n",
      "\tspeed: 0.0142s/iter; left time: 244.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0571023 Vali Loss: 0.0549712 Test Loss: 0.0574371\n",
      "Validation loss decreased (0.055073 --> 0.054971).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0561197\n",
      "\tspeed: 0.0295s/iter; left time: 503.5299s\n",
      "\titers: 200, epoch: 25 | loss: 0.0568814\n",
      "\tspeed: 0.0135s/iter; left time: 229.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0570662 Vali Loss: 0.0549365 Test Loss: 0.0573508\n",
      "Validation loss decreased (0.054971 --> 0.054936).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0561464\n",
      "\tspeed: 0.0292s/iter; left time: 492.2598s\n",
      "\titers: 200, epoch: 26 | loss: 0.0580630\n",
      "\tspeed: 0.0148s/iter; left time: 247.5547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0570494 Vali Loss: 0.0549141 Test Loss: 0.0573700\n",
      "Validation loss decreased (0.054936 --> 0.054914).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0586529\n",
      "\tspeed: 0.0314s/iter; left time: 522.4120s\n",
      "\titers: 200, epoch: 27 | loss: 0.0587134\n",
      "\tspeed: 0.0159s/iter; left time: 263.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0569506 Vali Loss: 0.0550122 Test Loss: 0.0573157\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0591513\n",
      "\tspeed: 0.0310s/iter; left time: 507.6913s\n",
      "\titers: 200, epoch: 28 | loss: 0.0577059\n",
      "\tspeed: 0.0148s/iter; left time: 241.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0568112 Vali Loss: 0.0549200 Test Loss: 0.0572914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0627802\n",
      "\tspeed: 0.0302s/iter; left time: 488.8402s\n",
      "\titers: 200, epoch: 29 | loss: 0.0555932\n",
      "\tspeed: 0.0137s/iter; left time: 219.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0568793 Vali Loss: 0.0548825 Test Loss: 0.0573175\n",
      "Validation loss decreased (0.054914 --> 0.054882).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0573625\n",
      "\tspeed: 0.0299s/iter; left time: 477.3543s\n",
      "\titers: 200, epoch: 30 | loss: 0.0574120\n",
      "\tspeed: 0.0162s/iter; left time: 257.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0567440 Vali Loss: 0.0547849 Test Loss: 0.0572417\n",
      "Validation loss decreased (0.054882 --> 0.054785).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0583852\n",
      "\tspeed: 0.0304s/iter; left time: 477.2179s\n",
      "\titers: 200, epoch: 31 | loss: 0.0552656\n",
      "\tspeed: 0.0140s/iter; left time: 218.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0567676 Vali Loss: 0.0547352 Test Loss: 0.0572144\n",
      "Validation loss decreased (0.054785 --> 0.054735).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0546270\n",
      "\tspeed: 0.0311s/iter; left time: 481.8427s\n",
      "\titers: 200, epoch: 32 | loss: 0.0541387\n",
      "\tspeed: 0.0143s/iter; left time: 220.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0567746 Vali Loss: 0.0548153 Test Loss: 0.0572132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0591299\n",
      "\tspeed: 0.0318s/iter; left time: 485.2582s\n",
      "\titers: 200, epoch: 33 | loss: 0.0563423\n",
      "\tspeed: 0.0176s/iter; left time: 267.3870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0567235 Vali Loss: 0.0548218 Test Loss: 0.0572524\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0589454\n",
      "\tspeed: 0.0311s/iter; left time: 467.8565s\n",
      "\titers: 200, epoch: 34 | loss: 0.0525103\n",
      "\tspeed: 0.0134s/iter; left time: 200.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0566389 Vali Loss: 0.0548047 Test Loss: 0.0571965\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0554143\n",
      "\tspeed: 0.0328s/iter; left time: 486.5132s\n",
      "\titers: 200, epoch: 35 | loss: 0.0560800\n",
      "\tspeed: 0.0153s/iter; left time: 224.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0566610 Vali Loss: 0.0546996 Test Loss: 0.0572044\n",
      "Validation loss decreased (0.054735 --> 0.054700).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0606790\n",
      "\tspeed: 0.0299s/iter; left time: 436.7365s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608672\n",
      "\tspeed: 0.0136s/iter; left time: 196.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0566115 Vali Loss: 0.0547285 Test Loss: 0.0571450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0546557\n",
      "\tspeed: 0.0304s/iter; left time: 436.6079s\n",
      "\titers: 200, epoch: 37 | loss: 0.0557337\n",
      "\tspeed: 0.0150s/iter; left time: 214.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0566456 Vali Loss: 0.0546470 Test Loss: 0.0571252\n",
      "Validation loss decreased (0.054700 --> 0.054647).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0529379\n",
      "\tspeed: 0.0332s/iter; left time: 470.1184s\n",
      "\titers: 200, epoch: 38 | loss: 0.0541414\n",
      "\tspeed: 0.0140s/iter; left time: 197.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0566103 Vali Loss: 0.0546640 Test Loss: 0.0571504\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0569721\n",
      "\tspeed: 0.0298s/iter; left time: 413.9799s\n",
      "\titers: 200, epoch: 39 | loss: 0.0579773\n",
      "\tspeed: 0.0140s/iter; left time: 194.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0565915 Vali Loss: 0.0547100 Test Loss: 0.0571145\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0571911\n",
      "\tspeed: 0.0304s/iter; left time: 416.2202s\n",
      "\titers: 200, epoch: 40 | loss: 0.0596315\n",
      "\tspeed: 0.0149s/iter; left time: 202.1009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0565915 Vali Loss: 0.0547481 Test Loss: 0.0571541\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0558093\n",
      "\tspeed: 0.0307s/iter; left time: 413.7578s\n",
      "\titers: 200, epoch: 41 | loss: 0.0540653\n",
      "\tspeed: 0.0145s/iter; left time: 193.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0565130 Vali Loss: 0.0547218 Test Loss: 0.0571257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0555196\n",
      "\tspeed: 0.0328s/iter; left time: 434.2269s\n",
      "\titers: 200, epoch: 42 | loss: 0.0578257\n",
      "\tspeed: 0.0158s/iter; left time: 207.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 226 | Train Loss: 0.0565404 Vali Loss: 0.0546927 Test Loss: 0.0571075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0550024\n",
      "\tspeed: 0.0324s/iter; left time: 421.7998s\n",
      "\titers: 200, epoch: 43 | loss: 0.0568401\n",
      "\tspeed: 0.0176s/iter; left time: 227.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0565761 Vali Loss: 0.0546771 Test Loss: 0.0571543\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0578645\n",
      "\tspeed: 0.0299s/iter; left time: 382.4128s\n",
      "\titers: 200, epoch: 44 | loss: 0.0564495\n",
      "\tspeed: 0.0150s/iter; left time: 190.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0565118 Vali Loss: 0.0547059 Test Loss: 0.0571353\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0602005\n",
      "\tspeed: 0.0309s/iter; left time: 388.1863s\n",
      "\titers: 200, epoch: 45 | loss: 0.0554472\n",
      "\tspeed: 0.0142s/iter; left time: 176.9628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0565609 Vali Loss: 0.0547618 Test Loss: 0.0571277\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547134\n",
      "\tspeed: 0.0288s/iter; left time: 355.7393s\n",
      "\titers: 200, epoch: 46 | loss: 0.0555413\n",
      "\tspeed: 0.0160s/iter; left time: 196.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0565785 Vali Loss: 0.0547929 Test Loss: 0.0571363\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0551656\n",
      "\tspeed: 0.0322s/iter; left time: 389.3625s\n",
      "\titers: 200, epoch: 47 | loss: 0.0578248\n",
      "\tspeed: 0.0124s/iter; left time: 149.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0565235 Vali Loss: 0.0547100 Test Loss: 0.0570904\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010137520730495453, rmse:0.100685253739357, mae:0.057125192135572433, rse:0.38044002652168274\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1539799\n",
      "\tspeed: 0.0148s/iter; left time: 333.6692s\n",
      "\titers: 200, epoch: 1 | loss: 0.1361853\n",
      "\tspeed: 0.0133s/iter; left time: 298.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.1584683 Vali Loss: 0.1138740 Test Loss: 0.1185682\n",
      "Validation loss decreased (inf --> 0.113874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0811349\n",
      "\tspeed: 0.0314s/iter; left time: 700.4233s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726119\n",
      "\tspeed: 0.0136s/iter; left time: 302.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0821625 Vali Loss: 0.0665933 Test Loss: 0.0685938\n",
      "Validation loss decreased (0.113874 --> 0.066593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0730276\n",
      "\tspeed: 0.0315s/iter; left time: 694.7052s\n",
      "\titers: 200, epoch: 3 | loss: 0.0661421\n",
      "\tspeed: 0.0144s/iter; left time: 316.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 226 | Train Loss: 0.0701488 Vali Loss: 0.0632820 Test Loss: 0.0658429\n",
      "Validation loss decreased (0.066593 --> 0.063282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0652974\n",
      "\tspeed: 0.0330s/iter; left time: 719.6794s\n",
      "\titers: 200, epoch: 4 | loss: 0.0682004\n",
      "\tspeed: 0.0140s/iter; left time: 304.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0673030 Vali Loss: 0.0616133 Test Loss: 0.0643654\n",
      "Validation loss decreased (0.063282 --> 0.061613).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0698536\n",
      "\tspeed: 0.0385s/iter; left time: 830.5228s\n",
      "\titers: 200, epoch: 5 | loss: 0.0650207\n",
      "\tspeed: 0.0139s/iter; left time: 297.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0654401 Vali Loss: 0.0602613 Test Loss: 0.0631047\n",
      "Validation loss decreased (0.061613 --> 0.060261).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594638\n",
      "\tspeed: 0.0306s/iter; left time: 654.5055s\n",
      "\titers: 200, epoch: 6 | loss: 0.0589113\n",
      "\tspeed: 0.0148s/iter; left time: 315.3564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0640678 Vali Loss: 0.0593925 Test Loss: 0.0621366\n",
      "Validation loss decreased (0.060261 --> 0.059392).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0667491\n",
      "\tspeed: 0.0333s/iter; left time: 703.7575s\n",
      "\titers: 200, epoch: 7 | loss: 0.0627189\n",
      "\tspeed: 0.0159s/iter; left time: 334.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0628045 Vali Loss: 0.0582049 Test Loss: 0.0610471\n",
      "Validation loss decreased (0.059392 --> 0.058205).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0613432\n",
      "\tspeed: 0.0302s/iter; left time: 631.9281s\n",
      "\titers: 200, epoch: 8 | loss: 0.0624776\n",
      "\tspeed: 0.0134s/iter; left time: 279.7096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0619117 Vali Loss: 0.0576585 Test Loss: 0.0605617\n",
      "Validation loss decreased (0.058205 --> 0.057658).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0638366\n",
      "\tspeed: 0.0302s/iter; left time: 624.0776s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602923\n",
      "\tspeed: 0.0151s/iter; left time: 311.5910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0611404 Vali Loss: 0.0571618 Test Loss: 0.0599073\n",
      "Validation loss decreased (0.057658 --> 0.057162).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0556248\n",
      "\tspeed: 0.0291s/iter; left time: 595.7820s\n",
      "\titers: 200, epoch: 10 | loss: 0.0547275\n",
      "\tspeed: 0.0132s/iter; left time: 268.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0605223 Vali Loss: 0.0570372 Test Loss: 0.0596768\n",
      "Validation loss decreased (0.057162 --> 0.057037).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0578447\n",
      "\tspeed: 0.0306s/iter; left time: 618.4830s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581363\n",
      "\tspeed: 0.0138s/iter; left time: 278.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0600978 Vali Loss: 0.0566079 Test Loss: 0.0591400\n",
      "Validation loss decreased (0.057037 --> 0.056608).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561352\n",
      "\tspeed: 0.0325s/iter; left time: 650.7465s\n",
      "\titers: 200, epoch: 12 | loss: 0.0614420\n",
      "\tspeed: 0.0151s/iter; left time: 300.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0596639 Vali Loss: 0.0563306 Test Loss: 0.0589118\n",
      "Validation loss decreased (0.056608 --> 0.056331).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0628135\n",
      "\tspeed: 0.0296s/iter; left time: 586.1662s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575188\n",
      "\tspeed: 0.0126s/iter; left time: 247.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0592776 Vali Loss: 0.0562184 Test Loss: 0.0587350\n",
      "Validation loss decreased (0.056331 --> 0.056218).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589776\n",
      "\tspeed: 0.0309s/iter; left time: 603.5242s\n",
      "\titers: 200, epoch: 14 | loss: 0.0646306\n",
      "\tspeed: 0.0152s/iter; left time: 295.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0590901 Vali Loss: 0.0560802 Test Loss: 0.0586688\n",
      "Validation loss decreased (0.056218 --> 0.056080).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0603016\n",
      "\tspeed: 0.0291s/iter; left time: 563.1877s\n",
      "\titers: 200, epoch: 15 | loss: 0.0602521\n",
      "\tspeed: 0.0138s/iter; left time: 264.6239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0588087 Vali Loss: 0.0559156 Test Loss: 0.0583283\n",
      "Validation loss decreased (0.056080 --> 0.055916).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0631725\n",
      "\tspeed: 0.0301s/iter; left time: 575.0125s\n",
      "\titers: 200, epoch: 16 | loss: 0.0612999\n",
      "\tspeed: 0.0132s/iter; left time: 250.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0586078 Vali Loss: 0.0557952 Test Loss: 0.0583473\n",
      "Validation loss decreased (0.055916 --> 0.055795).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0543554\n",
      "\tspeed: 0.0318s/iter; left time: 600.5617s\n",
      "\titers: 200, epoch: 17 | loss: 0.0614621\n",
      "\tspeed: 0.0139s/iter; left time: 261.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0583893 Vali Loss: 0.0557436 Test Loss: 0.0582062\n",
      "Validation loss decreased (0.055795 --> 0.055744).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0556625\n",
      "\tspeed: 0.0311s/iter; left time: 580.1232s\n",
      "\titers: 200, epoch: 18 | loss: 0.0564423\n",
      "\tspeed: 0.0126s/iter; left time: 233.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0581835 Vali Loss: 0.0556368 Test Loss: 0.0581076\n",
      "Validation loss decreased (0.055744 --> 0.055637).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0565416\n",
      "\tspeed: 0.0295s/iter; left time: 543.0962s\n",
      "\titers: 200, epoch: 19 | loss: 0.0567843\n",
      "\tspeed: 0.0133s/iter; left time: 243.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0581203 Vali Loss: 0.0555432 Test Loss: 0.0579788\n",
      "Validation loss decreased (0.055637 --> 0.055543).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0623222\n",
      "\tspeed: 0.0318s/iter; left time: 579.0025s\n",
      "\titers: 200, epoch: 20 | loss: 0.0573737\n",
      "\tspeed: 0.0144s/iter; left time: 261.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 226 | Train Loss: 0.0579831 Vali Loss: 0.0554497 Test Loss: 0.0579629\n",
      "Validation loss decreased (0.055543 --> 0.055450).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0577273\n",
      "\tspeed: 0.0336s/iter; left time: 605.0498s\n",
      "\titers: 200, epoch: 21 | loss: 0.0551225\n",
      "\tspeed: 0.0122s/iter; left time: 217.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0578284 Vali Loss: 0.0554022 Test Loss: 0.0578362\n",
      "Validation loss decreased (0.055450 --> 0.055402).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0519038\n",
      "\tspeed: 0.0326s/iter; left time: 578.2199s\n",
      "\titers: 200, epoch: 22 | loss: 0.0558437\n",
      "\tspeed: 0.0161s/iter; left time: 283.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0577748 Vali Loss: 0.0553515 Test Loss: 0.0576862\n",
      "Validation loss decreased (0.055402 --> 0.055352).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0557427\n",
      "\tspeed: 0.0298s/iter; left time: 522.7183s\n",
      "\titers: 200, epoch: 23 | loss: 0.0552805\n",
      "\tspeed: 0.0135s/iter; left time: 236.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 226 | Train Loss: 0.0576156 Vali Loss: 0.0554422 Test Loss: 0.0578294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0564269\n",
      "\tspeed: 0.0305s/iter; left time: 527.0437s\n",
      "\titers: 200, epoch: 24 | loss: 0.0602554\n",
      "\tspeed: 0.0143s/iter; left time: 246.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0575752 Vali Loss: 0.0553521 Test Loss: 0.0576915\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0611194\n",
      "\tspeed: 0.0297s/iter; left time: 507.5303s\n",
      "\titers: 200, epoch: 25 | loss: 0.0580635\n",
      "\tspeed: 0.0138s/iter; left time: 234.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0575317 Vali Loss: 0.0552213 Test Loss: 0.0576793\n",
      "Validation loss decreased (0.055352 --> 0.055221).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0543003\n",
      "\tspeed: 0.0296s/iter; left time: 498.0856s\n",
      "\titers: 200, epoch: 26 | loss: 0.0576580\n",
      "\tspeed: 0.0132s/iter; left time: 220.4581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0573982 Vali Loss: 0.0551965 Test Loss: 0.0575593\n",
      "Validation loss decreased (0.055221 --> 0.055196).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572071\n",
      "\tspeed: 0.0309s/iter; left time: 514.3770s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571104\n",
      "\tspeed: 0.0159s/iter; left time: 263.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0573230 Vali Loss: 0.0552104 Test Loss: 0.0576307\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0626907\n",
      "\tspeed: 0.0301s/iter; left time: 493.5103s\n",
      "\titers: 200, epoch: 28 | loss: 0.0615357\n",
      "\tspeed: 0.0177s/iter; left time: 287.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0572901 Vali Loss: 0.0551527 Test Loss: 0.0575306\n",
      "Validation loss decreased (0.055196 --> 0.055153).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0549023\n",
      "\tspeed: 0.0314s/iter; left time: 507.3278s\n",
      "\titers: 200, epoch: 29 | loss: 0.0586225\n",
      "\tspeed: 0.0138s/iter; left time: 221.4096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0572556 Vali Loss: 0.0550143 Test Loss: 0.0574702\n",
      "Validation loss decreased (0.055153 --> 0.055014).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0590886\n",
      "\tspeed: 0.0296s/iter; left time: 471.2398s\n",
      "\titers: 200, epoch: 30 | loss: 0.0565196\n",
      "\tspeed: 0.0150s/iter; left time: 237.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0572465 Vali Loss: 0.0551218 Test Loss: 0.0575079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565368\n",
      "\tspeed: 0.0334s/iter; left time: 525.0337s\n",
      "\titers: 200, epoch: 31 | loss: 0.0565345\n",
      "\tspeed: 0.0157s/iter; left time: 245.5122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0572838 Vali Loss: 0.0551058 Test Loss: 0.0574753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0586410\n",
      "\tspeed: 0.0315s/iter; left time: 488.4106s\n",
      "\titers: 200, epoch: 32 | loss: 0.0565419\n",
      "\tspeed: 0.0141s/iter; left time: 217.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0572131 Vali Loss: 0.0550809 Test Loss: 0.0575073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0591283\n",
      "\tspeed: 0.0308s/iter; left time: 469.9606s\n",
      "\titers: 200, epoch: 33 | loss: 0.0593829\n",
      "\tspeed: 0.0136s/iter; left time: 206.6709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 226 | Train Loss: 0.0571012 Vali Loss: 0.0550334 Test Loss: 0.0574686\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0586985\n",
      "\tspeed: 0.0297s/iter; left time: 447.0501s\n",
      "\titers: 200, epoch: 34 | loss: 0.0578788\n",
      "\tspeed: 0.0139s/iter; left time: 208.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0571024 Vali Loss: 0.0550324 Test Loss: 0.0574133\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0587165\n",
      "\tspeed: 0.0300s/iter; left time: 445.2012s\n",
      "\titers: 200, epoch: 35 | loss: 0.0596205\n",
      "\tspeed: 0.0141s/iter; left time: 207.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0571095 Vali Loss: 0.0550038 Test Loss: 0.0573776\n",
      "Validation loss decreased (0.055014 --> 0.055004).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0582091\n",
      "\tspeed: 0.0335s/iter; left time: 489.4837s\n",
      "\titers: 200, epoch: 36 | loss: 0.0560012\n",
      "\tspeed: 0.0141s/iter; left time: 204.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0570899 Vali Loss: 0.0549994 Test Loss: 0.0574207\n",
      "Validation loss decreased (0.055004 --> 0.054999).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0534665\n",
      "\tspeed: 0.0303s/iter; left time: 435.7464s\n",
      "\titers: 200, epoch: 37 | loss: 0.0553771\n",
      "\tspeed: 0.0181s/iter; left time: 258.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0570699 Vali Loss: 0.0550342 Test Loss: 0.0573798\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0567976\n",
      "\tspeed: 0.0304s/iter; left time: 430.4139s\n",
      "\titers: 200, epoch: 38 | loss: 0.0541309\n",
      "\tspeed: 0.0138s/iter; left time: 193.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0570057 Vali Loss: 0.0549314 Test Loss: 0.0573647\n",
      "Validation loss decreased (0.054999 --> 0.054931).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0580444\n",
      "\tspeed: 0.0302s/iter; left time: 420.5487s\n",
      "\titers: 200, epoch: 39 | loss: 0.0619875\n",
      "\tspeed: 0.0128s/iter; left time: 177.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0570141 Vali Loss: 0.0549402 Test Loss: 0.0573837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0545708\n",
      "\tspeed: 0.0318s/iter; left time: 434.5757s\n",
      "\titers: 200, epoch: 40 | loss: 0.0605366\n",
      "\tspeed: 0.0140s/iter; left time: 189.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0570325 Vali Loss: 0.0549857 Test Loss: 0.0573908\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0577828\n",
      "\tspeed: 0.0289s/iter; left time: 388.9328s\n",
      "\titers: 200, epoch: 41 | loss: 0.0555863\n",
      "\tspeed: 0.0128s/iter; left time: 171.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0570407 Vali Loss: 0.0549662 Test Loss: 0.0573818\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0578980\n",
      "\tspeed: 0.0304s/iter; left time: 402.8709s\n",
      "\titers: 200, epoch: 42 | loss: 0.0577660\n",
      "\tspeed: 0.0144s/iter; left time: 188.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0569706 Vali Loss: 0.0548869 Test Loss: 0.0573568\n",
      "Validation loss decreased (0.054931 --> 0.054887).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0567902\n",
      "\tspeed: 0.0301s/iter; left time: 391.5488s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514606\n",
      "\tspeed: 0.0148s/iter; left time: 190.6876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0569657 Vali Loss: 0.0550157 Test Loss: 0.0573616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0586686\n",
      "\tspeed: 0.0308s/iter; left time: 393.8527s\n",
      "\titers: 200, epoch: 44 | loss: 0.0554094\n",
      "\tspeed: 0.0152s/iter; left time: 193.1020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0569268 Vali Loss: 0.0549712 Test Loss: 0.0573666\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0552669\n",
      "\tspeed: 0.0312s/iter; left time: 392.2917s\n",
      "\titers: 200, epoch: 45 | loss: 0.0554723\n",
      "\tspeed: 0.0161s/iter; left time: 200.6032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0569725 Vali Loss: 0.0549824 Test Loss: 0.0573552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0538784\n",
      "\tspeed: 0.0301s/iter; left time: 370.6993s\n",
      "\titers: 200, epoch: 46 | loss: 0.0571138\n",
      "\tspeed: 0.0130s/iter; left time: 158.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0569799 Vali Loss: 0.0549509 Test Loss: 0.0573609\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0496207\n",
      "\tspeed: 0.0312s/iter; left time: 378.1012s\n",
      "\titers: 200, epoch: 47 | loss: 0.0593435\n",
      "\tspeed: 0.0138s/iter; left time: 165.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0569202 Vali Loss: 0.0549102 Test Loss: 0.0573357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0580918\n",
      "\tspeed: 0.0305s/iter; left time: 362.0462s\n",
      "\titers: 200, epoch: 48 | loss: 0.0518328\n",
      "\tspeed: 0.0140s/iter; left time: 165.2038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 226 | Train Loss: 0.0569901 Vali Loss: 0.0549707 Test Loss: 0.0573438\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0584176\n",
      "\tspeed: 0.0288s/iter; left time: 335.9656s\n",
      "\titers: 200, epoch: 49 | loss: 0.0589793\n",
      "\tspeed: 0.0128s/iter; left time: 147.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0569327 Vali Loss: 0.0549463 Test Loss: 0.0573346\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0593008\n",
      "\tspeed: 0.0293s/iter; left time: 334.7635s\n",
      "\titers: 200, epoch: 50 | loss: 0.0563344\n",
      "\tspeed: 0.0138s/iter; left time: 156.0377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0569446 Vali Loss: 0.0549876 Test Loss: 0.0573458\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0571280\n",
      "\tspeed: 0.0285s/iter; left time: 319.7812s\n",
      "\titers: 200, epoch: 51 | loss: 0.0558902\n",
      "\tspeed: 0.0127s/iter; left time: 141.2889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 226 | Train Loss: 0.0570049 Vali Loss: 0.0550360 Test Loss: 0.0573646\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0602567\n",
      "\tspeed: 0.0294s/iter; left time: 322.5606s\n",
      "\titers: 200, epoch: 52 | loss: 0.0591826\n",
      "\tspeed: 0.0127s/iter; left time: 137.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0569473 Vali Loss: 0.0549787 Test Loss: 0.0573351\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010162911377847195, rmse:0.10081126540899277, mae:0.057356785982847214, rse:0.38091614842414856\n",
      "Intermediate time for IT and pred_len 24: 00h:07m:35.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1753311\n",
      "\tspeed: 0.0429s/iter; left time: 960.5804s\n",
      "\titers: 200, epoch: 1 | loss: 0.1436570\n",
      "\tspeed: 0.0131s/iter; left time: 292.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1702219 Vali Loss: 0.1290655 Test Loss: 0.1349992\n",
      "Validation loss decreased (inf --> 0.129066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1026154\n",
      "\tspeed: 0.0327s/iter; left time: 725.7367s\n",
      "\titers: 200, epoch: 2 | loss: 0.0957569\n",
      "\tspeed: 0.0141s/iter; left time: 310.4757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.1052531 Vali Loss: 0.0874697 Test Loss: 0.0918007\n",
      "Validation loss decreased (0.129066 --> 0.087470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0938003\n",
      "\tspeed: 0.0264s/iter; left time: 579.8248s\n",
      "\titers: 200, epoch: 3 | loss: 0.0929629\n",
      "\tspeed: 0.0111s/iter; left time: 241.5270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.60s\n",
      "Steps: 225 | Train Loss: 0.0916488 Vali Loss: 0.0820255 Test Loss: 0.0865718\n",
      "Validation loss decreased (0.087470 --> 0.082025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0893885\n",
      "\tspeed: 0.0312s/iter; left time: 677.6429s\n",
      "\titers: 200, epoch: 4 | loss: 0.0860986\n",
      "\tspeed: 0.0110s/iter; left time: 236.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0873048 Vali Loss: 0.0800837 Test Loss: 0.0844712\n",
      "Validation loss decreased (0.082025 --> 0.080084).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0841507\n",
      "\tspeed: 0.0325s/iter; left time: 699.6756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0855052\n",
      "\tspeed: 0.0150s/iter; left time: 321.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0852577 Vali Loss: 0.0790920 Test Loss: 0.0832717\n",
      "Validation loss decreased (0.080084 --> 0.079092).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839201\n",
      "\tspeed: 0.0306s/iter; left time: 651.9325s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811668\n",
      "\tspeed: 0.0153s/iter; left time: 323.7886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0838343 Vali Loss: 0.0783462 Test Loss: 0.0827517\n",
      "Validation loss decreased (0.079092 --> 0.078346).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811209\n",
      "\tspeed: 0.0304s/iter; left time: 639.3158s\n",
      "\titers: 200, epoch: 7 | loss: 0.0807324\n",
      "\tspeed: 0.0150s/iter; left time: 314.9460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0828525 Vali Loss: 0.0778023 Test Loss: 0.0820419\n",
      "Validation loss decreased (0.078346 --> 0.077802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0840556\n",
      "\tspeed: 0.0305s/iter; left time: 635.8289s\n",
      "\titers: 200, epoch: 8 | loss: 0.0841476\n",
      "\tspeed: 0.0144s/iter; left time: 299.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0821178 Vali Loss: 0.0773986 Test Loss: 0.0818890\n",
      "Validation loss decreased (0.077802 --> 0.077399).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0823614\n",
      "\tspeed: 0.0354s/iter; left time: 729.4334s\n",
      "\titers: 200, epoch: 9 | loss: 0.0803317\n",
      "\tspeed: 0.0151s/iter; left time: 309.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0814449 Vali Loss: 0.0771080 Test Loss: 0.0813903\n",
      "Validation loss decreased (0.077399 --> 0.077108).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0818028\n",
      "\tspeed: 0.0334s/iter; left time: 680.3686s\n",
      "\titers: 200, epoch: 10 | loss: 0.0837469\n",
      "\tspeed: 0.0173s/iter; left time: 351.2174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0809766 Vali Loss: 0.0768782 Test Loss: 0.0810334\n",
      "Validation loss decreased (0.077108 --> 0.076878).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0822819\n",
      "\tspeed: 0.0341s/iter; left time: 687.9935s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759115\n",
      "\tspeed: 0.0157s/iter; left time: 314.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0804781 Vali Loss: 0.0764895 Test Loss: 0.0807764\n",
      "Validation loss decreased (0.076878 --> 0.076489).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0793670\n",
      "\tspeed: 0.0311s/iter; left time: 620.1253s\n",
      "\titers: 200, epoch: 12 | loss: 0.0827993\n",
      "\tspeed: 0.0134s/iter; left time: 264.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0801399 Vali Loss: 0.0762626 Test Loss: 0.0805810\n",
      "Validation loss decreased (0.076489 --> 0.076263).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738112\n",
      "\tspeed: 0.0314s/iter; left time: 617.7619s\n",
      "\titers: 200, epoch: 13 | loss: 0.0803811\n",
      "\tspeed: 0.0146s/iter; left time: 285.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0798073 Vali Loss: 0.0760761 Test Loss: 0.0804072\n",
      "Validation loss decreased (0.076263 --> 0.076076).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0791950\n",
      "\tspeed: 0.0310s/iter; left time: 604.6228s\n",
      "\titers: 200, epoch: 14 | loss: 0.0825432\n",
      "\tspeed: 0.0137s/iter; left time: 266.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0794891 Vali Loss: 0.0760745 Test Loss: 0.0804997\n",
      "Validation loss decreased (0.076076 --> 0.076075).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776878\n",
      "\tspeed: 0.0325s/iter; left time: 625.1190s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791670\n",
      "\tspeed: 0.0168s/iter; left time: 322.3645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0793035 Vali Loss: 0.0757409 Test Loss: 0.0801055\n",
      "Validation loss decreased (0.076075 --> 0.075741).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0744964\n",
      "\tspeed: 0.0306s/iter; left time: 582.7793s\n",
      "\titers: 200, epoch: 16 | loss: 0.0783239\n",
      "\tspeed: 0.0129s/iter; left time: 243.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0790749 Vali Loss: 0.0755226 Test Loss: 0.0798602\n",
      "Validation loss decreased (0.075741 --> 0.075523).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0774590\n",
      "\tspeed: 0.0281s/iter; left time: 529.0041s\n",
      "\titers: 200, epoch: 17 | loss: 0.0847981\n",
      "\tspeed: 0.0123s/iter; left time: 229.6708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0788030 Vali Loss: 0.0755649 Test Loss: 0.0800134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0783567\n",
      "\tspeed: 0.0295s/iter; left time: 548.9148s\n",
      "\titers: 200, epoch: 18 | loss: 0.0761599\n",
      "\tspeed: 0.0138s/iter; left time: 255.3450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0787061 Vali Loss: 0.0754229 Test Loss: 0.0799732\n",
      "Validation loss decreased (0.075523 --> 0.075423).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0775192\n",
      "\tspeed: 0.0328s/iter; left time: 601.1162s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769421\n",
      "\tspeed: 0.0187s/iter; left time: 341.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0785809 Vali Loss: 0.0752701 Test Loss: 0.0797506\n",
      "Validation loss decreased (0.075423 --> 0.075270).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790527\n",
      "\tspeed: 0.0328s/iter; left time: 593.7409s\n",
      "\titers: 200, epoch: 20 | loss: 0.0794995\n",
      "\tspeed: 0.0156s/iter; left time: 280.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0784401 Vali Loss: 0.0752977 Test Loss: 0.0797484\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0735694\n",
      "\tspeed: 0.0291s/iter; left time: 521.3093s\n",
      "\titers: 200, epoch: 21 | loss: 0.0761741\n",
      "\tspeed: 0.0142s/iter; left time: 252.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0782853 Vali Loss: 0.0753317 Test Loss: 0.0798160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0799037\n",
      "\tspeed: 0.0282s/iter; left time: 497.7635s\n",
      "\titers: 200, epoch: 22 | loss: 0.0760585\n",
      "\tspeed: 0.0122s/iter; left time: 213.9361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0782821 Vali Loss: 0.0751441 Test Loss: 0.0796287\n",
      "Validation loss decreased (0.075270 --> 0.075144).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0799712\n",
      "\tspeed: 0.0293s/iter; left time: 510.9038s\n",
      "\titers: 200, epoch: 23 | loss: 0.0824410\n",
      "\tspeed: 0.0130s/iter; left time: 225.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0781483 Vali Loss: 0.0751111 Test Loss: 0.0795692\n",
      "Validation loss decreased (0.075144 --> 0.075111).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0765089\n",
      "\tspeed: 0.0305s/iter; left time: 525.4740s\n",
      "\titers: 200, epoch: 24 | loss: 0.0794485\n",
      "\tspeed: 0.0140s/iter; left time: 239.1651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0781010 Vali Loss: 0.0750819 Test Loss: 0.0795733\n",
      "Validation loss decreased (0.075111 --> 0.075082).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0795115\n",
      "\tspeed: 0.0303s/iter; left time: 515.8438s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784891\n",
      "\tspeed: 0.0141s/iter; left time: 238.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0780577 Vali Loss: 0.0750737 Test Loss: 0.0796257\n",
      "Validation loss decreased (0.075082 --> 0.075074).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0760862\n",
      "\tspeed: 0.0290s/iter; left time: 485.8633s\n",
      "\titers: 200, epoch: 26 | loss: 0.0754807\n",
      "\tspeed: 0.0129s/iter; left time: 214.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0779914 Vali Loss: 0.0749976 Test Loss: 0.0795383\n",
      "Validation loss decreased (0.075074 --> 0.074998).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0748885\n",
      "\tspeed: 0.0313s/iter; left time: 517.6403s\n",
      "\titers: 200, epoch: 27 | loss: 0.0758040\n",
      "\tspeed: 0.0139s/iter; left time: 229.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0779101 Vali Loss: 0.0749967 Test Loss: 0.0795172\n",
      "Validation loss decreased (0.074998 --> 0.074997).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0774521\n",
      "\tspeed: 0.0315s/iter; left time: 514.3547s\n",
      "\titers: 200, epoch: 28 | loss: 0.0781550\n",
      "\tspeed: 0.0159s/iter; left time: 258.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0778878 Vali Loss: 0.0750303 Test Loss: 0.0795694\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0745610\n",
      "\tspeed: 0.0343s/iter; left time: 552.4124s\n",
      "\titers: 200, epoch: 29 | loss: 0.0755035\n",
      "\tspeed: 0.0173s/iter; left time: 276.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0777929 Vali Loss: 0.0749397 Test Loss: 0.0794642\n",
      "Validation loss decreased (0.074997 --> 0.074940).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0771899\n",
      "\tspeed: 0.0358s/iter; left time: 568.1962s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765079\n",
      "\tspeed: 0.0166s/iter; left time: 262.0888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0777232 Vali Loss: 0.0749183 Test Loss: 0.0794563\n",
      "Validation loss decreased (0.074940 --> 0.074918).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0769537\n",
      "\tspeed: 0.0313s/iter; left time: 490.1826s\n",
      "\titers: 200, epoch: 31 | loss: 0.0775254\n",
      "\tspeed: 0.0148s/iter; left time: 230.7920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0777443 Vali Loss: 0.0749626 Test Loss: 0.0795339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0741379\n",
      "\tspeed: 0.0274s/iter; left time: 422.0136s\n",
      "\titers: 200, epoch: 32 | loss: 0.0799718\n",
      "\tspeed: 0.0123s/iter; left time: 189.1198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 225 | Train Loss: 0.0776630 Vali Loss: 0.0748911 Test Loss: 0.0794593\n",
      "Validation loss decreased (0.074918 --> 0.074891).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0771977\n",
      "\tspeed: 0.0315s/iter; left time: 478.8161s\n",
      "\titers: 200, epoch: 33 | loss: 0.0821928\n",
      "\tspeed: 0.0137s/iter; left time: 207.3768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0776186 Vali Loss: 0.0748408 Test Loss: 0.0793588\n",
      "Validation loss decreased (0.074891 --> 0.074841).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0768530\n",
      "\tspeed: 0.0329s/iter; left time: 492.7206s\n",
      "\titers: 200, epoch: 34 | loss: 0.0787376\n",
      "\tspeed: 0.0146s/iter; left time: 217.4262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0776415 Vali Loss: 0.0748613 Test Loss: 0.0793993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0790400\n",
      "\tspeed: 0.0302s/iter; left time: 444.8686s\n",
      "\titers: 200, epoch: 35 | loss: 0.0740347\n",
      "\tspeed: 0.0142s/iter; left time: 207.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0776289 Vali Loss: 0.0747877 Test Loss: 0.0793631\n",
      "Validation loss decreased (0.074841 --> 0.074788).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0782250\n",
      "\tspeed: 0.0318s/iter; left time: 461.5118s\n",
      "\titers: 200, epoch: 36 | loss: 0.0748798\n",
      "\tspeed: 0.0151s/iter; left time: 217.2993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0776196 Vali Loss: 0.0748268 Test Loss: 0.0793252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0800715\n",
      "\tspeed: 0.0347s/iter; left time: 496.7355s\n",
      "\titers: 200, epoch: 37 | loss: 0.0758734\n",
      "\tspeed: 0.0153s/iter; left time: 217.5220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.0775753 Vali Loss: 0.0748081 Test Loss: 0.0793407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0747246\n",
      "\tspeed: 0.0302s/iter; left time: 424.5580s\n",
      "\titers: 200, epoch: 38 | loss: 0.0803036\n",
      "\tspeed: 0.0138s/iter; left time: 192.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0774808 Vali Loss: 0.0748460 Test Loss: 0.0793845\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0809956\n",
      "\tspeed: 0.0292s/iter; left time: 405.0555s\n",
      "\titers: 200, epoch: 39 | loss: 0.0767839\n",
      "\tspeed: 0.0141s/iter; left time: 193.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0775626 Vali Loss: 0.0747953 Test Loss: 0.0793372\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0797421\n",
      "\tspeed: 0.0300s/iter; left time: 408.4062s\n",
      "\titers: 200, epoch: 40 | loss: 0.0750588\n",
      "\tspeed: 0.0124s/iter; left time: 167.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0775625 Vali Loss: 0.0747911 Test Loss: 0.0793558\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0773940\n",
      "\tspeed: 0.0287s/iter; left time: 385.2574s\n",
      "\titers: 200, epoch: 41 | loss: 0.0747099\n",
      "\tspeed: 0.0135s/iter; left time: 179.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0774556 Vali Loss: 0.0748073 Test Loss: 0.0793242\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0808406\n",
      "\tspeed: 0.0310s/iter; left time: 408.1767s\n",
      "\titers: 200, epoch: 42 | loss: 0.0762237\n",
      "\tspeed: 0.0154s/iter; left time: 200.8775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0775023 Vali Loss: 0.0747769 Test Loss: 0.0793393\n",
      "Validation loss decreased (0.074788 --> 0.074777).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0732376\n",
      "\tspeed: 0.0303s/iter; left time: 391.9227s\n",
      "\titers: 200, epoch: 43 | loss: 0.0785128\n",
      "\tspeed: 0.0155s/iter; left time: 198.6509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0774617 Vali Loss: 0.0748207 Test Loss: 0.0793770\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0767571\n",
      "\tspeed: 0.0297s/iter; left time: 378.4056s\n",
      "\titers: 200, epoch: 44 | loss: 0.0772179\n",
      "\tspeed: 0.0141s/iter; left time: 177.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0774623 Vali Loss: 0.0748057 Test Loss: 0.0793576\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0731953\n",
      "\tspeed: 0.0297s/iter; left time: 371.2717s\n",
      "\titers: 200, epoch: 45 | loss: 0.0744313\n",
      "\tspeed: 0.0152s/iter; left time: 188.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0774715 Vali Loss: 0.0747933 Test Loss: 0.0793405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757875\n",
      "\tspeed: 0.0257s/iter; left time: 315.7931s\n",
      "\titers: 200, epoch: 46 | loss: 0.0774035\n",
      "\tspeed: 0.0137s/iter; left time: 166.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0774581 Vali Loss: 0.0747870 Test Loss: 0.0793270\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0764094\n",
      "\tspeed: 0.0313s/iter; left time: 377.3251s\n",
      "\titers: 200, epoch: 47 | loss: 0.0744040\n",
      "\tspeed: 0.0151s/iter; left time: 180.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0774913 Vali Loss: 0.0747535 Test Loss: 0.0793254\n",
      "Validation loss decreased (0.074777 --> 0.074753).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0778681\n",
      "\tspeed: 0.0338s/iter; left time: 399.7902s\n",
      "\titers: 200, epoch: 48 | loss: 0.0763813\n",
      "\tspeed: 0.0194s/iter; left time: 226.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0774767 Vali Loss: 0.0747689 Test Loss: 0.0793125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0775122\n",
      "\tspeed: 0.0323s/iter; left time: 374.1337s\n",
      "\titers: 200, epoch: 49 | loss: 0.0794601\n",
      "\tspeed: 0.0156s/iter; left time: 179.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0774807 Vali Loss: 0.0747666 Test Loss: 0.0793180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0761088\n",
      "\tspeed: 0.0302s/iter; left time: 343.6324s\n",
      "\titers: 200, epoch: 50 | loss: 0.0779669\n",
      "\tspeed: 0.0101s/iter; left time: 113.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0774584 Vali Loss: 0.0747605 Test Loss: 0.0793315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0745999\n",
      "\tspeed: 0.0326s/iter; left time: 363.7360s\n",
      "\titers: 200, epoch: 51 | loss: 0.0788790\n",
      "\tspeed: 0.0154s/iter; left time: 170.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0774307 Vali Loss: 0.0747423 Test Loss: 0.0793105\n",
      "Validation loss decreased (0.074753 --> 0.074742).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0753374\n",
      "\tspeed: 0.0301s/iter; left time: 329.2973s\n",
      "\titers: 200, epoch: 52 | loss: 0.0742523\n",
      "\tspeed: 0.0136s/iter; left time: 147.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0774718 Vali Loss: 0.0747737 Test Loss: 0.0793268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0783091\n",
      "\tspeed: 0.0314s/iter; left time: 336.3973s\n",
      "\titers: 200, epoch: 53 | loss: 0.0773548\n",
      "\tspeed: 0.0143s/iter; left time: 151.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0774527 Vali Loss: 0.0747587 Test Loss: 0.0793310\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0784637\n",
      "\tspeed: 0.0333s/iter; left time: 348.8736s\n",
      "\titers: 200, epoch: 54 | loss: 0.0796923\n",
      "\tspeed: 0.0171s/iter; left time: 177.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0774756 Vali Loss: 0.0747565 Test Loss: 0.0793397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0778829\n",
      "\tspeed: 0.0300s/iter; left time: 307.4324s\n",
      "\titers: 200, epoch: 55 | loss: 0.0769686\n",
      "\tspeed: 0.0095s/iter; left time: 96.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 225 | Train Loss: 0.0774334 Vali Loss: 0.0747482 Test Loss: 0.0793268\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0799946\n",
      "\tspeed: 0.0286s/iter; left time: 286.7587s\n",
      "\titers: 200, epoch: 56 | loss: 0.0776002\n",
      "\tspeed: 0.0136s/iter; left time: 135.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0774270 Vali Loss: 0.0747584 Test Loss: 0.0793307\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0779561\n",
      "\tspeed: 0.0323s/iter; left time: 316.8382s\n",
      "\titers: 200, epoch: 57 | loss: 0.0777749\n",
      "\tspeed: 0.0153s/iter; left time: 148.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0774326 Vali Loss: 0.0747703 Test Loss: 0.0793328\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0806668\n",
      "\tspeed: 0.0332s/iter; left time: 317.8814s\n",
      "\titers: 200, epoch: 58 | loss: 0.0847034\n",
      "\tspeed: 0.0153s/iter; left time: 145.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0773916 Vali Loss: 0.0747545 Test Loss: 0.0793121\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0769409\n",
      "\tspeed: 0.0341s/iter; left time: 319.0964s\n",
      "\titers: 200, epoch: 59 | loss: 0.0774845\n",
      "\tspeed: 0.0152s/iter; left time: 140.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0773863 Vali Loss: 0.0747519 Test Loss: 0.0793118\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0753553\n",
      "\tspeed: 0.0319s/iter; left time: 291.3422s\n",
      "\titers: 200, epoch: 60 | loss: 0.0757663\n",
      "\tspeed: 0.0158s/iter; left time: 142.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0774388 Vali Loss: 0.0747387 Test Loss: 0.0793193\n",
      "Validation loss decreased (0.074742 --> 0.074739).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0821476\n",
      "\tspeed: 0.0321s/iter; left time: 285.3043s\n",
      "\titers: 200, epoch: 61 | loss: 0.0764556\n",
      "\tspeed: 0.0143s/iter; left time: 125.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0774342 Vali Loss: 0.0747492 Test Loss: 0.0793182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0767880\n",
      "\tspeed: 0.0310s/iter; left time: 268.5818s\n",
      "\titers: 200, epoch: 62 | loss: 0.0760076\n",
      "\tspeed: 0.0138s/iter; left time: 118.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0774547 Vali Loss: 0.0747579 Test Loss: 0.0793104\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0803858\n",
      "\tspeed: 0.0305s/iter; left time: 257.8222s\n",
      "\titers: 200, epoch: 63 | loss: 0.0794679\n",
      "\tspeed: 0.0137s/iter; left time: 114.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0774434 Vali Loss: 0.0747405 Test Loss: 0.0793082\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0749724\n",
      "\tspeed: 0.0311s/iter; left time: 255.6708s\n",
      "\titers: 200, epoch: 64 | loss: 0.0771190\n",
      "\tspeed: 0.0146s/iter; left time: 118.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0774226 Vali Loss: 0.0747386 Test Loss: 0.0792983\n",
      "Validation loss decreased (0.074739 --> 0.074739).  Saving model ...\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0790097\n",
      "\tspeed: 0.0302s/iter; left time: 241.8490s\n",
      "\titers: 200, epoch: 65 | loss: 0.0741301\n",
      "\tspeed: 0.0135s/iter; left time: 106.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0773952 Vali Loss: 0.0747408 Test Loss: 0.0793006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0776911\n",
      "\tspeed: 0.0297s/iter; left time: 230.8152s\n",
      "\titers: 200, epoch: 66 | loss: 0.0786832\n",
      "\tspeed: 0.0153s/iter; left time: 117.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0774126 Vali Loss: 0.0747489 Test Loss: 0.0793331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0797125\n",
      "\tspeed: 0.0307s/iter; left time: 232.0743s\n",
      "\titers: 200, epoch: 67 | loss: 0.0728599\n",
      "\tspeed: 0.0148s/iter; left time: 110.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0774355 Vali Loss: 0.0747613 Test Loss: 0.0793128\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0791888\n",
      "\tspeed: 0.0314s/iter; left time: 230.0877s\n",
      "\titers: 200, epoch: 68 | loss: 0.0757377\n",
      "\tspeed: 0.0153s/iter; left time: 110.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0774436 Vali Loss: 0.0747595 Test Loss: 0.0793028\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0764372\n",
      "\tspeed: 0.0354s/iter; left time: 251.0213s\n",
      "\titers: 200, epoch: 69 | loss: 0.0744094\n",
      "\tspeed: 0.0146s/iter; left time: 102.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0774245 Vali Loss: 0.0747367 Test Loss: 0.0793052\n",
      "Validation loss decreased (0.074739 --> 0.074737).  Saving model ...\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0826194\n",
      "\tspeed: 0.0304s/iter; left time: 209.3529s\n",
      "\titers: 200, epoch: 70 | loss: 0.0769218\n",
      "\tspeed: 0.0132s/iter; left time: 89.6813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0773831 Vali Loss: 0.0747561 Test Loss: 0.0793273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0752633\n",
      "\tspeed: 0.0305s/iter; left time: 202.6086s\n",
      "\titers: 200, epoch: 71 | loss: 0.0775461\n",
      "\tspeed: 0.0160s/iter; left time: 104.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0774465 Vali Loss: 0.0747688 Test Loss: 0.0793367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0779451\n",
      "\tspeed: 0.0308s/iter; left time: 197.7616s\n",
      "\titers: 200, epoch: 72 | loss: 0.0793812\n",
      "\tspeed: 0.0130s/iter; left time: 82.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0773530 Vali Loss: 0.0747803 Test Loss: 0.0793217\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0749686\n",
      "\tspeed: 0.0306s/iter; left time: 190.0380s\n",
      "\titers: 200, epoch: 73 | loss: 0.0781531\n",
      "\tspeed: 0.0149s/iter; left time: 91.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0774387 Vali Loss: 0.0747325 Test Loss: 0.0792935\n",
      "Validation loss decreased (0.074737 --> 0.074733).  Saving model ...\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0777414\n",
      "\tspeed: 0.0313s/iter; left time: 186.7621s\n",
      "\titers: 200, epoch: 74 | loss: 0.0795761\n",
      "\tspeed: 0.0155s/iter; left time: 90.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0774312 Vali Loss: 0.0747575 Test Loss: 0.0793210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0804360\n",
      "\tspeed: 0.0298s/iter; left time: 171.4408s\n",
      "\titers: 200, epoch: 75 | loss: 0.0727557\n",
      "\tspeed: 0.0135s/iter; left time: 76.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0774344 Vali Loss: 0.0747587 Test Loss: 0.0793194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0781007\n",
      "\tspeed: 0.0305s/iter; left time: 168.5543s\n",
      "\titers: 200, epoch: 76 | loss: 0.0830547\n",
      "\tspeed: 0.0149s/iter; left time: 80.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0773910 Vali Loss: 0.0747377 Test Loss: 0.0792992\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.567759074507749e-08\n",
      "\titers: 100, epoch: 77 | loss: 0.0821363\n",
      "\tspeed: 0.0294s/iter; left time: 155.6525s\n",
      "\titers: 200, epoch: 77 | loss: 0.0769827\n",
      "\tspeed: 0.0147s/iter; left time: 76.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 77\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0774398 Vali Loss: 0.0747572 Test Loss: 0.0793237\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.1109831670569744e-08\n",
      "\titers: 100, epoch: 78 | loss: 0.0796495\n",
      "\tspeed: 0.0317s/iter; left time: 161.1399s\n",
      "\titers: 200, epoch: 78 | loss: 0.0746681\n",
      "\tspeed: 0.0128s/iter; left time: 63.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 78\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0774157 Vali Loss: 0.0747625 Test Loss: 0.0793077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.6998848503512764e-08\n",
      "\titers: 100, epoch: 79 | loss: 0.0765261\n",
      "\tspeed: 0.0273s/iter; left time: 132.6599s\n",
      "\titers: 200, epoch: 79 | loss: 0.0734660\n",
      "\tspeed: 0.0093s/iter; left time: 43.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 79\n",
      "Cost time: 00h:00m:02.50s\n",
      "Steps: 225 | Train Loss: 0.0774231 Vali Loss: 0.0747255 Test Loss: 0.0793063\n",
      "Validation loss decreased (0.074733 --> 0.074725).  Saving model ...\n",
      "Updating learning rate to 3.3298963653161496e-08\n",
      "\titers: 100, epoch: 80 | loss: 0.0718898\n",
      "\tspeed: 0.0294s/iter; left time: 136.1763s\n",
      "\titers: 200, epoch: 80 | loss: 0.0741302\n",
      "\tspeed: 0.0120s/iter; left time: 54.3504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 80\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0774328 Vali Loss: 0.0747393 Test Loss: 0.0793178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.996906728784534e-08\n",
      "\titers: 100, epoch: 81 | loss: 0.0728583\n",
      "\tspeed: 0.0288s/iter; left time: 126.7009s\n",
      "\titers: 200, epoch: 81 | loss: 0.0825374\n",
      "\tspeed: 0.0148s/iter; left time: 63.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 81\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0774357 Vali Loss: 0.0747541 Test Loss: 0.0793253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.697216055906081e-08\n",
      "\titers: 100, epoch: 82 | loss: 0.0745414\n",
      "\tspeed: 0.0291s/iter; left time: 121.3354s\n",
      "\titers: 200, epoch: 82 | loss: 0.0784527\n",
      "\tspeed: 0.0151s/iter; left time: 61.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 82\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0773980 Vali Loss: 0.0747330 Test Loss: 0.0793118\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.427494450315473e-08\n",
      "\titers: 100, epoch: 83 | loss: 0.0763556\n",
      "\tspeed: 0.0297s/iter; left time: 117.4791s\n",
      "\titers: 200, epoch: 83 | loss: 0.0772864\n",
      "\tspeed: 0.0147s/iter; left time: 56.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 83\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0774040 Vali Loss: 0.0747497 Test Loss: 0.0793176\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.1847450052839257e-08\n",
      "\titers: 100, epoch: 84 | loss: 0.0790844\n",
      "\tspeed: 0.0302s/iter; left time: 112.3470s\n",
      "\titers: 200, epoch: 84 | loss: 0.0773246\n",
      "\tspeed: 0.0140s/iter; left time: 50.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 84\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0773570 Vali Loss: 0.0747647 Test Loss: 0.0793175\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9662705047555332e-08\n",
      "\titers: 100, epoch: 85 | loss: 0.0782616\n",
      "\tspeed: 0.0352s/iter; left time: 123.2584s\n",
      "\titers: 200, epoch: 85 | loss: 0.0758819\n",
      "\tspeed: 0.0170s/iter; left time: 57.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 85\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0774307 Vali Loss: 0.0747381 Test Loss: 0.0793077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.7696434542799797e-08\n",
      "\titers: 100, epoch: 86 | loss: 0.0756707\n",
      "\tspeed: 0.0287s/iter; left time: 93.8947s\n",
      "\titers: 200, epoch: 86 | loss: 0.0792461\n",
      "\tspeed: 0.0114s/iter; left time: 36.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 86\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0773729 Vali Loss: 0.0747394 Test Loss: 0.0792856\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5926791088519817e-08\n",
      "\titers: 100, epoch: 87 | loss: 0.0780069\n",
      "\tspeed: 0.0302s/iter; left time: 92.2820s\n",
      "\titers: 200, epoch: 87 | loss: 0.0758708\n",
      "\tspeed: 0.0115s/iter; left time: 34.0571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 87\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0774030 Vali Loss: 0.0747305 Test Loss: 0.0793080\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4334111979667836e-08\n",
      "\titers: 100, epoch: 88 | loss: 0.0762707\n",
      "\tspeed: 0.0300s/iter; left time: 84.8067s\n",
      "\titers: 200, epoch: 88 | loss: 0.0773667\n",
      "\tspeed: 0.0176s/iter; left time: 47.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 88\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0774186 Vali Loss: 0.0747501 Test Loss: 0.0793152\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2900700781701054e-08\n",
      "\titers: 100, epoch: 89 | loss: 0.0771601\n",
      "\tspeed: 0.0303s/iter; left time: 78.8682s\n",
      "\titers: 200, epoch: 89 | loss: 0.0790908\n",
      "\tspeed: 0.0158s/iter; left time: 39.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 89\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0773822 Vali Loss: 0.0747431 Test Loss: 0.0792977\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018169526010751724, rmse:0.13479438424110413, mae:0.07930632680654526, rse:0.5096721053123474\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1757905\n",
      "\tspeed: 0.0151s/iter; left time: 337.5116s\n",
      "\titers: 200, epoch: 1 | loss: 0.1533180\n",
      "\tspeed: 0.0122s/iter; left time: 272.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.1731134 Vali Loss: 0.1311231 Test Loss: 0.1377414\n",
      "Validation loss decreased (inf --> 0.131123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1033643\n",
      "\tspeed: 0.0328s/iter; left time: 726.6802s\n",
      "\titers: 200, epoch: 2 | loss: 0.0987961\n",
      "\tspeed: 0.0147s/iter; left time: 325.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.1046933 Vali Loss: 0.0868314 Test Loss: 0.0913650\n",
      "Validation loss decreased (0.131123 --> 0.086831).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0871408\n",
      "\tspeed: 0.0311s/iter; left time: 681.6447s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896924\n",
      "\tspeed: 0.0135s/iter; left time: 294.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0911094 Vali Loss: 0.0815486 Test Loss: 0.0859379\n",
      "Validation loss decreased (0.086831 --> 0.081549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0894916\n",
      "\tspeed: 0.0321s/iter; left time: 698.0524s\n",
      "\titers: 200, epoch: 4 | loss: 0.0906945\n",
      "\tspeed: 0.0137s/iter; left time: 295.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0868993 Vali Loss: 0.0800269 Test Loss: 0.0841111\n",
      "Validation loss decreased (0.081549 --> 0.080027).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852746\n",
      "\tspeed: 0.0337s/iter; left time: 725.2159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0794768\n",
      "\tspeed: 0.0151s/iter; left time: 322.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0850271 Vali Loss: 0.0790196 Test Loss: 0.0830500\n",
      "Validation loss decreased (0.080027 --> 0.079020).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863806\n",
      "\tspeed: 0.0314s/iter; left time: 667.1631s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848266\n",
      "\tspeed: 0.0130s/iter; left time: 276.0041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 225 | Train Loss: 0.0838033 Vali Loss: 0.0784399 Test Loss: 0.0824386\n",
      "Validation loss decreased (0.079020 --> 0.078440).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0834531\n",
      "\tspeed: 0.0303s/iter; left time: 638.0734s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849618\n",
      "\tspeed: 0.0159s/iter; left time: 333.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0828685 Vali Loss: 0.0776467 Test Loss: 0.0817295\n",
      "Validation loss decreased (0.078440 --> 0.077647).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0806454\n",
      "\tspeed: 0.0320s/iter; left time: 666.7907s\n",
      "\titers: 200, epoch: 8 | loss: 0.0812222\n",
      "\tspeed: 0.0141s/iter; left time: 293.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0821232 Vali Loss: 0.0772602 Test Loss: 0.0814455\n",
      "Validation loss decreased (0.077647 --> 0.077260).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0842466\n",
      "\tspeed: 0.0289s/iter; left time: 594.8952s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805770\n",
      "\tspeed: 0.0092s/iter; left time: 188.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.57s\n",
      "Steps: 225 | Train Loss: 0.0814816 Vali Loss: 0.0769066 Test Loss: 0.0810342\n",
      "Validation loss decreased (0.077260 --> 0.076907).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0770628\n",
      "\tspeed: 0.0261s/iter; left time: 531.4933s\n",
      "\titers: 200, epoch: 10 | loss: 0.0873721\n",
      "\tspeed: 0.0146s/iter; left time: 296.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 225 | Train Loss: 0.0810410 Vali Loss: 0.0766858 Test Loss: 0.0809546\n",
      "Validation loss decreased (0.076907 --> 0.076686).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0826626\n",
      "\tspeed: 0.0318s/iter; left time: 640.3444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828113\n",
      "\tspeed: 0.0146s/iter; left time: 291.8435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0806253 Vali Loss: 0.0764047 Test Loss: 0.0805632\n",
      "Validation loss decreased (0.076686 --> 0.076405).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0785356\n",
      "\tspeed: 0.0347s/iter; left time: 691.6625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0805149\n",
      "\tspeed: 0.0179s/iter; left time: 353.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0802538 Vali Loss: 0.0761147 Test Loss: 0.0804021\n",
      "Validation loss decreased (0.076405 --> 0.076115).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0827091\n",
      "\tspeed: 0.0431s/iter; left time: 849.3943s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826255\n",
      "\tspeed: 0.0208s/iter; left time: 408.6675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 225 | Train Loss: 0.0800045 Vali Loss: 0.0759716 Test Loss: 0.0802001\n",
      "Validation loss decreased (0.076115 --> 0.075972).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792982\n",
      "\tspeed: 0.0333s/iter; left time: 648.9871s\n",
      "\titers: 200, epoch: 14 | loss: 0.0838051\n",
      "\tspeed: 0.0138s/iter; left time: 266.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0797107 Vali Loss: 0.0759867 Test Loss: 0.0801655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0795935\n",
      "\tspeed: 0.0312s/iter; left time: 601.5612s\n",
      "\titers: 200, epoch: 15 | loss: 0.0787614\n",
      "\tspeed: 0.0123s/iter; left time: 235.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0794918 Vali Loss: 0.0756547 Test Loss: 0.0798049\n",
      "Validation loss decreased (0.075972 --> 0.075655).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0774229\n",
      "\tspeed: 0.0322s/iter; left time: 613.3959s\n",
      "\titers: 200, epoch: 16 | loss: 0.0794620\n",
      "\tspeed: 0.0158s/iter; left time: 298.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0792348 Vali Loss: 0.0755967 Test Loss: 0.0798241\n",
      "Validation loss decreased (0.075655 --> 0.075597).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0817391\n",
      "\tspeed: 0.0392s/iter; left time: 737.5625s\n",
      "\titers: 200, epoch: 17 | loss: 0.0785300\n",
      "\tspeed: 0.0158s/iter; left time: 294.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0790980 Vali Loss: 0.0755302 Test Loss: 0.0797514\n",
      "Validation loss decreased (0.075597 --> 0.075530).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786269\n",
      "\tspeed: 0.0298s/iter; left time: 553.0299s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752963\n",
      "\tspeed: 0.0148s/iter; left time: 273.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0789682 Vali Loss: 0.0754268 Test Loss: 0.0796185\n",
      "Validation loss decreased (0.075530 --> 0.075427).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0844178\n",
      "\tspeed: 0.0309s/iter; left time: 566.4154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0728510\n",
      "\tspeed: 0.0170s/iter; left time: 311.1336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0787671 Vali Loss: 0.0753956 Test Loss: 0.0795513\n",
      "Validation loss decreased (0.075427 --> 0.075396).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0793854\n",
      "\tspeed: 0.0344s/iter; left time: 622.7754s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796325\n",
      "\tspeed: 0.0160s/iter; left time: 287.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0786965 Vali Loss: 0.0753739 Test Loss: 0.0795372\n",
      "Validation loss decreased (0.075396 --> 0.075374).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749959\n",
      "\tspeed: 0.0307s/iter; left time: 548.6995s\n",
      "\titers: 200, epoch: 21 | loss: 0.0786702\n",
      "\tspeed: 0.0151s/iter; left time: 268.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0785362 Vali Loss: 0.0753688 Test Loss: 0.0796365\n",
      "Validation loss decreased (0.075374 --> 0.075369).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0751506\n",
      "\tspeed: 0.0317s/iter; left time: 560.8064s\n",
      "\titers: 200, epoch: 22 | loss: 0.0795390\n",
      "\tspeed: 0.0150s/iter; left time: 264.1787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0784891 Vali Loss: 0.0751833 Test Loss: 0.0793499\n",
      "Validation loss decreased (0.075369 --> 0.075183).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0793063\n",
      "\tspeed: 0.0318s/iter; left time: 555.1251s\n",
      "\titers: 200, epoch: 23 | loss: 0.0770318\n",
      "\tspeed: 0.0162s/iter; left time: 281.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0783942 Vali Loss: 0.0751287 Test Loss: 0.0793039\n",
      "Validation loss decreased (0.075183 --> 0.075129).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0748397\n",
      "\tspeed: 0.0346s/iter; left time: 596.0315s\n",
      "\titers: 200, epoch: 24 | loss: 0.0767953\n",
      "\tspeed: 0.0130s/iter; left time: 223.2295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0783026 Vali Loss: 0.0752068 Test Loss: 0.0794113\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0755837\n",
      "\tspeed: 0.0309s/iter; left time: 526.0472s\n",
      "\titers: 200, epoch: 25 | loss: 0.0777018\n",
      "\tspeed: 0.0154s/iter; left time: 260.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0782710 Vali Loss: 0.0751213 Test Loss: 0.0793577\n",
      "Validation loss decreased (0.075129 --> 0.075121).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0798871\n",
      "\tspeed: 0.0320s/iter; left time: 536.4355s\n",
      "\titers: 200, epoch: 26 | loss: 0.0808795\n",
      "\tspeed: 0.0140s/iter; left time: 233.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0782204 Vali Loss: 0.0750830 Test Loss: 0.0792356\n",
      "Validation loss decreased (0.075121 --> 0.075083).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0773975\n",
      "\tspeed: 0.0326s/iter; left time: 538.7728s\n",
      "\titers: 200, epoch: 27 | loss: 0.0779151\n",
      "\tspeed: 0.0157s/iter; left time: 258.0211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0781271 Vali Loss: 0.0750569 Test Loss: 0.0792396\n",
      "Validation loss decreased (0.075083 --> 0.075057).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0770311\n",
      "\tspeed: 0.0354s/iter; left time: 578.0172s\n",
      "\titers: 200, epoch: 28 | loss: 0.0814189\n",
      "\tspeed: 0.0175s/iter; left time: 284.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0780923 Vali Loss: 0.0751162 Test Loss: 0.0793054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0782135\n",
      "\tspeed: 0.0331s/iter; left time: 532.9766s\n",
      "\titers: 200, epoch: 29 | loss: 0.0810577\n",
      "\tspeed: 0.0159s/iter; left time: 254.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0780385 Vali Loss: 0.0750539 Test Loss: 0.0792714\n",
      "Validation loss decreased (0.075057 --> 0.075054).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0784606\n",
      "\tspeed: 0.0316s/iter; left time: 500.9117s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751671\n",
      "\tspeed: 0.0142s/iter; left time: 223.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0780154 Vali Loss: 0.0750176 Test Loss: 0.0791584\n",
      "Validation loss decreased (0.075054 --> 0.075018).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0787354\n",
      "\tspeed: 0.0357s/iter; left time: 558.1307s\n",
      "\titers: 200, epoch: 31 | loss: 0.0810523\n",
      "\tspeed: 0.0162s/iter; left time: 251.4050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0779846 Vali Loss: 0.0750133 Test Loss: 0.0792084\n",
      "Validation loss decreased (0.075018 --> 0.075013).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0787912\n",
      "\tspeed: 0.0320s/iter; left time: 494.1471s\n",
      "\titers: 200, epoch: 32 | loss: 0.0777048\n",
      "\tspeed: 0.0134s/iter; left time: 205.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0779680 Vali Loss: 0.0749892 Test Loss: 0.0791622\n",
      "Validation loss decreased (0.075013 --> 0.074989).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0772747\n",
      "\tspeed: 0.0315s/iter; left time: 478.9418s\n",
      "\titers: 200, epoch: 33 | loss: 0.0766307\n",
      "\tspeed: 0.0136s/iter; left time: 205.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0779721 Vali Loss: 0.0749656 Test Loss: 0.0791683\n",
      "Validation loss decreased (0.074989 --> 0.074966).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0741812\n",
      "\tspeed: 0.0345s/iter; left time: 517.3089s\n",
      "\titers: 200, epoch: 34 | loss: 0.0782380\n",
      "\tspeed: 0.0171s/iter; left time: 254.3361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0778920 Vali Loss: 0.0749916 Test Loss: 0.0791760\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0772897\n",
      "\tspeed: 0.0304s/iter; left time: 447.9198s\n",
      "\titers: 200, epoch: 35 | loss: 0.0807684\n",
      "\tspeed: 0.0131s/iter; left time: 191.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0778359 Vali Loss: 0.0749327 Test Loss: 0.0791211\n",
      "Validation loss decreased (0.074966 --> 0.074933).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0755012\n",
      "\tspeed: 0.0307s/iter; left time: 445.4897s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774848\n",
      "\tspeed: 0.0132s/iter; left time: 190.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0777872 Vali Loss: 0.0748957 Test Loss: 0.0790801\n",
      "Validation loss decreased (0.074933 --> 0.074896).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0790919\n",
      "\tspeed: 0.0326s/iter; left time: 466.1352s\n",
      "\titers: 200, epoch: 37 | loss: 0.0758902\n",
      "\tspeed: 0.0138s/iter; left time: 195.6795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0778456 Vali Loss: 0.0749434 Test Loss: 0.0791581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0758921\n",
      "\tspeed: 0.0304s/iter; left time: 427.9443s\n",
      "\titers: 200, epoch: 38 | loss: 0.0818606\n",
      "\tspeed: 0.0151s/iter; left time: 211.7242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0777678 Vali Loss: 0.0749043 Test Loss: 0.0791165\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812748\n",
      "\tspeed: 0.0361s/iter; left time: 499.4709s\n",
      "\titers: 200, epoch: 39 | loss: 0.0731252\n",
      "\tspeed: 0.0167s/iter; left time: 229.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0778141 Vali Loss: 0.0749143 Test Loss: 0.0791035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0760038\n",
      "\tspeed: 0.0320s/iter; left time: 435.7181s\n",
      "\titers: 200, epoch: 40 | loss: 0.0783180\n",
      "\tspeed: 0.0163s/iter; left time: 219.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0777595 Vali Loss: 0.0749389 Test Loss: 0.0791230\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0790715\n",
      "\tspeed: 0.0308s/iter; left time: 413.2597s\n",
      "\titers: 200, epoch: 41 | loss: 0.0751928\n",
      "\tspeed: 0.0160s/iter; left time: 212.6400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0777728 Vali Loss: 0.0749010 Test Loss: 0.0790943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0706556\n",
      "\tspeed: 0.0262s/iter; left time: 344.9066s\n",
      "\titers: 200, epoch: 42 | loss: 0.0816257\n",
      "\tspeed: 0.0105s/iter; left time: 137.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.60s\n",
      "Steps: 225 | Train Loss: 0.0778015 Vali Loss: 0.0749044 Test Loss: 0.0790957\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0761632\n",
      "\tspeed: 0.0320s/iter; left time: 414.2507s\n",
      "\titers: 200, epoch: 43 | loss: 0.0757311\n",
      "\tspeed: 0.0147s/iter; left time: 189.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0777553 Vali Loss: 0.0748958 Test Loss: 0.0790705\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0782938\n",
      "\tspeed: 0.0307s/iter; left time: 390.8261s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762009\n",
      "\tspeed: 0.0139s/iter; left time: 175.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0777363 Vali Loss: 0.0748808 Test Loss: 0.0790762\n",
      "Validation loss decreased (0.074896 --> 0.074881).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0806774\n",
      "\tspeed: 0.0337s/iter; left time: 420.9233s\n",
      "\titers: 200, epoch: 45 | loss: 0.0805928\n",
      "\tspeed: 0.0140s/iter; left time: 173.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0777506 Vali Loss: 0.0748680 Test Loss: 0.0790856\n",
      "Validation loss decreased (0.074881 --> 0.074868).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0751238\n",
      "\tspeed: 0.0312s/iter; left time: 383.1332s\n",
      "\titers: 200, epoch: 46 | loss: 0.0771807\n",
      "\tspeed: 0.0140s/iter; left time: 170.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0776942 Vali Loss: 0.0748736 Test Loss: 0.0790972\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0761534\n",
      "\tspeed: 0.0332s/iter; left time: 400.5037s\n",
      "\titers: 200, epoch: 47 | loss: 0.0785965\n",
      "\tspeed: 0.0143s/iter; left time: 171.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0776791 Vali Loss: 0.0748683 Test Loss: 0.0790615\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0773962\n",
      "\tspeed: 0.0314s/iter; left time: 371.7444s\n",
      "\titers: 200, epoch: 48 | loss: 0.0767924\n",
      "\tspeed: 0.0146s/iter; left time: 171.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0777466 Vali Loss: 0.0748990 Test Loss: 0.0790804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0765519\n",
      "\tspeed: 0.0349s/iter; left time: 405.2888s\n",
      "\titers: 200, epoch: 49 | loss: 0.0753565\n",
      "\tspeed: 0.0164s/iter; left time: 188.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0777727 Vali Loss: 0.0748921 Test Loss: 0.0790869\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0763434\n",
      "\tspeed: 0.0318s/iter; left time: 361.8958s\n",
      "\titers: 200, epoch: 50 | loss: 0.0835120\n",
      "\tspeed: 0.0129s/iter; left time: 145.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0776858 Vali Loss: 0.0748538 Test Loss: 0.0790545\n",
      "Validation loss decreased (0.074868 --> 0.074854).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0762343\n",
      "\tspeed: 0.0313s/iter; left time: 349.0811s\n",
      "\titers: 200, epoch: 51 | loss: 0.0741411\n",
      "\tspeed: 0.0140s/iter; left time: 154.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0777145 Vali Loss: 0.0748871 Test Loss: 0.0790835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0764073\n",
      "\tspeed: 0.0303s/iter; left time: 330.6037s\n",
      "\titers: 200, epoch: 52 | loss: 0.0767159\n",
      "\tspeed: 0.0123s/iter; left time: 133.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 225 | Train Loss: 0.0776936 Vali Loss: 0.0748931 Test Loss: 0.0790909\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0730638\n",
      "\tspeed: 0.0324s/iter; left time: 346.5631s\n",
      "\titers: 200, epoch: 53 | loss: 0.0750567\n",
      "\tspeed: 0.0135s/iter; left time: 142.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0777233 Vali Loss: 0.0748881 Test Loss: 0.0790936\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0760155\n",
      "\tspeed: 0.0318s/iter; left time: 333.4067s\n",
      "\titers: 200, epoch: 54 | loss: 0.0830644\n",
      "\tspeed: 0.0157s/iter; left time: 163.4196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0777015 Vali Loss: 0.0748809 Test Loss: 0.0790739\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0806499\n",
      "\tspeed: 0.0307s/iter; left time: 314.6300s\n",
      "\titers: 200, epoch: 55 | loss: 0.0777161\n",
      "\tspeed: 0.0138s/iter; left time: 140.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0776971 Vali Loss: 0.0748633 Test Loss: 0.0790658\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0763094\n",
      "\tspeed: 0.0297s/iter; left time: 297.3149s\n",
      "\titers: 200, epoch: 56 | loss: 0.0770429\n",
      "\tspeed: 0.0118s/iter; left time: 116.9961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0776627 Vali Loss: 0.0748663 Test Loss: 0.0790574\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0762478\n",
      "\tspeed: 0.0323s/iter; left time: 316.2513s\n",
      "\titers: 200, epoch: 57 | loss: 0.0771594\n",
      "\tspeed: 0.0140s/iter; left time: 135.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0776335 Vali Loss: 0.0748674 Test Loss: 0.0790580\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0801637\n",
      "\tspeed: 0.0327s/iter; left time: 313.1999s\n",
      "\titers: 200, epoch: 58 | loss: 0.0762619\n",
      "\tspeed: 0.0140s/iter; left time: 132.9731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0776533 Vali Loss: 0.0748720 Test Loss: 0.0790630\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0758238\n",
      "\tspeed: 0.0301s/iter; left time: 281.3019s\n",
      "\titers: 200, epoch: 59 | loss: 0.0782589\n",
      "\tspeed: 0.0172s/iter; left time: 158.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0777239 Vali Loss: 0.0748764 Test Loss: 0.0790695\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0755245\n",
      "\tspeed: 0.0342s/iter; left time: 312.2893s\n",
      "\titers: 200, epoch: 60 | loss: 0.0733155\n",
      "\tspeed: 0.0176s/iter; left time: 159.0920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0777231 Vali Loss: 0.0748605 Test Loss: 0.0790687\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017972556874155998, rmse:0.1340617686510086, mae:0.07905451208353043, rse:0.5069019794464111\n",
      "Intermediate time for IT and pred_len 96: 00h:11m:35.39s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=12, stride=12, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1794243\n",
      "\tspeed: 0.0357s/iter; left time: 800.0247s\n",
      "\titers: 200, epoch: 1 | loss: 0.1545141\n",
      "\tspeed: 0.0134s/iter; left time: 298.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.1753299 Vali Loss: 0.1334617 Test Loss: 0.1397683\n",
      "Validation loss decreased (inf --> 0.133462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1078497\n",
      "\tspeed: 0.0316s/iter; left time: 700.5288s\n",
      "\titers: 200, epoch: 2 | loss: 0.1017275\n",
      "\tspeed: 0.0140s/iter; left time: 308.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.1095461 Vali Loss: 0.0914779 Test Loss: 0.0952932\n",
      "Validation loss decreased (0.133462 --> 0.091478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0938466\n",
      "\tspeed: 0.0323s/iter; left time: 709.6134s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945736\n",
      "\tspeed: 0.0148s/iter; left time: 322.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0959207 Vali Loss: 0.0861497 Test Loss: 0.0896623\n",
      "Validation loss decreased (0.091478 --> 0.086150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0906038\n",
      "\tspeed: 0.0339s/iter; left time: 737.2284s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939294\n",
      "\tspeed: 0.0143s/iter; left time: 309.7618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0913119 Vali Loss: 0.0845192 Test Loss: 0.0877525\n",
      "Validation loss decreased (0.086150 --> 0.084519).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0922788\n",
      "\tspeed: 0.0369s/iter; left time: 793.7574s\n",
      "\titers: 200, epoch: 5 | loss: 0.0910795\n",
      "\tspeed: 0.0160s/iter; left time: 342.3086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0895421 Vali Loss: 0.0837832 Test Loss: 0.0868734\n",
      "Validation loss decreased (0.084519 --> 0.083783).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0887866\n",
      "\tspeed: 0.0339s/iter; left time: 721.2896s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926208\n",
      "\tspeed: 0.0135s/iter; left time: 285.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0883698 Vali Loss: 0.0829841 Test Loss: 0.0862519\n",
      "Validation loss decreased (0.083783 --> 0.082984).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0868587\n",
      "\tspeed: 0.0338s/iter; left time: 710.7764s\n",
      "\titers: 200, epoch: 7 | loss: 0.0897257\n",
      "\tspeed: 0.0150s/iter; left time: 313.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0874387 Vali Loss: 0.0826783 Test Loss: 0.0860318\n",
      "Validation loss decreased (0.082984 --> 0.082678).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0883796\n",
      "\tspeed: 0.0340s/iter; left time: 707.6968s\n",
      "\titers: 200, epoch: 8 | loss: 0.0865351\n",
      "\tspeed: 0.0141s/iter; left time: 292.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0867357 Vali Loss: 0.0823606 Test Loss: 0.0856219\n",
      "Validation loss decreased (0.082678 --> 0.082361).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0910444\n",
      "\tspeed: 0.0325s/iter; left time: 669.5249s\n",
      "\titers: 200, epoch: 9 | loss: 0.0886428\n",
      "\tspeed: 0.0159s/iter; left time: 326.1807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0861998 Vali Loss: 0.0820032 Test Loss: 0.0854317\n",
      "Validation loss decreased (0.082361 --> 0.082003).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0843542\n",
      "\tspeed: 0.0317s/iter; left time: 646.2804s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846316\n",
      "\tspeed: 0.0154s/iter; left time: 312.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0856368 Vali Loss: 0.0817179 Test Loss: 0.0851303\n",
      "Validation loss decreased (0.082003 --> 0.081718).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0866130\n",
      "\tspeed: 0.0315s/iter; left time: 635.1228s\n",
      "\titers: 200, epoch: 11 | loss: 0.0819480\n",
      "\tspeed: 0.0146s/iter; left time: 293.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0852452 Vali Loss: 0.0815896 Test Loss: 0.0850694\n",
      "Validation loss decreased (0.081718 --> 0.081590).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0875783\n",
      "\tspeed: 0.0325s/iter; left time: 648.3408s\n",
      "\titers: 200, epoch: 12 | loss: 0.0870005\n",
      "\tspeed: 0.0155s/iter; left time: 307.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0849274 Vali Loss: 0.0814576 Test Loss: 0.0847808\n",
      "Validation loss decreased (0.081590 --> 0.081458).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0841844\n",
      "\tspeed: 0.0305s/iter; left time: 601.1535s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818336\n",
      "\tspeed: 0.0160s/iter; left time: 313.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0845843 Vali Loss: 0.0812256 Test Loss: 0.0846273\n",
      "Validation loss decreased (0.081458 --> 0.081226).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0862697\n",
      "\tspeed: 0.0331s/iter; left time: 644.7850s\n",
      "\titers: 200, epoch: 14 | loss: 0.0871195\n",
      "\tspeed: 0.0150s/iter; left time: 289.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0843462 Vali Loss: 0.0811865 Test Loss: 0.0845923\n",
      "Validation loss decreased (0.081226 --> 0.081187).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0843640\n",
      "\tspeed: 0.0329s/iter; left time: 634.1724s\n",
      "\titers: 200, epoch: 15 | loss: 0.0848120\n",
      "\tspeed: 0.0136s/iter; left time: 260.9022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0841116 Vali Loss: 0.0810506 Test Loss: 0.0844216\n",
      "Validation loss decreased (0.081187 --> 0.081051).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0851771\n",
      "\tspeed: 0.0317s/iter; left time: 602.2777s\n",
      "\titers: 200, epoch: 16 | loss: 0.0849150\n",
      "\tspeed: 0.0142s/iter; left time: 267.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0839256 Vali Loss: 0.0810296 Test Loss: 0.0846201\n",
      "Validation loss decreased (0.081051 --> 0.081030).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807493\n",
      "\tspeed: 0.0319s/iter; left time: 599.9456s\n",
      "\titers: 200, epoch: 17 | loss: 0.0829107\n",
      "\tspeed: 0.0143s/iter; left time: 266.5947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0837836 Vali Loss: 0.0809390 Test Loss: 0.0843796\n",
      "Validation loss decreased (0.081030 --> 0.080939).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0832614\n",
      "\tspeed: 0.0300s/iter; left time: 556.6666s\n",
      "\titers: 200, epoch: 18 | loss: 0.0848252\n",
      "\tspeed: 0.0139s/iter; left time: 257.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0835827 Vali Loss: 0.0808751 Test Loss: 0.0843197\n",
      "Validation loss decreased (0.080939 --> 0.080875).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0829302\n",
      "\tspeed: 0.0317s/iter; left time: 582.2707s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836381\n",
      "\tspeed: 0.0145s/iter; left time: 264.9295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0834986 Vali Loss: 0.0808107 Test Loss: 0.0843368\n",
      "Validation loss decreased (0.080875 --> 0.080811).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0826948\n",
      "\tspeed: 0.0318s/iter; left time: 576.3577s\n",
      "\titers: 200, epoch: 20 | loss: 0.0848874\n",
      "\tspeed: 0.0145s/iter; left time: 261.3302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0833774 Vali Loss: 0.0807700 Test Loss: 0.0842024\n",
      "Validation loss decreased (0.080811 --> 0.080770).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0800888\n",
      "\tspeed: 0.0323s/iter; left time: 578.1431s\n",
      "\titers: 200, epoch: 21 | loss: 0.0838991\n",
      "\tspeed: 0.0132s/iter; left time: 234.9877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0833193 Vali Loss: 0.0807535 Test Loss: 0.0842818\n",
      "Validation loss decreased (0.080770 --> 0.080753).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856803\n",
      "\tspeed: 0.0301s/iter; left time: 532.6464s\n",
      "\titers: 200, epoch: 22 | loss: 0.0871196\n",
      "\tspeed: 0.0134s/iter; left time: 234.9250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0832028 Vali Loss: 0.0807617 Test Loss: 0.0841309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0834106\n",
      "\tspeed: 0.0328s/iter; left time: 572.7346s\n",
      "\titers: 200, epoch: 23 | loss: 0.0825058\n",
      "\tspeed: 0.0153s/iter; left time: 265.3624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0830934 Vali Loss: 0.0806805 Test Loss: 0.0841292\n",
      "Validation loss decreased (0.080753 --> 0.080681).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0822173\n",
      "\tspeed: 0.0334s/iter; left time: 575.6907s\n",
      "\titers: 200, epoch: 24 | loss: 0.0799167\n",
      "\tspeed: 0.0144s/iter; left time: 247.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0830560 Vali Loss: 0.0806526 Test Loss: 0.0841626\n",
      "Validation loss decreased (0.080681 --> 0.080653).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0833554\n",
      "\tspeed: 0.0321s/iter; left time: 546.4506s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822198\n",
      "\tspeed: 0.0143s/iter; left time: 241.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0829832 Vali Loss: 0.0807056 Test Loss: 0.0841306\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0793545\n",
      "\tspeed: 0.0308s/iter; left time: 516.0583s\n",
      "\titers: 200, epoch: 26 | loss: 0.0851567\n",
      "\tspeed: 0.0165s/iter; left time: 275.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0829455 Vali Loss: 0.0805867 Test Loss: 0.0840598\n",
      "Validation loss decreased (0.080653 --> 0.080587).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0826467\n",
      "\tspeed: 0.0321s/iter; left time: 531.2385s\n",
      "\titers: 200, epoch: 27 | loss: 0.0844331\n",
      "\tspeed: 0.0135s/iter; left time: 222.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0828525 Vali Loss: 0.0805419 Test Loss: 0.0840317\n",
      "Validation loss decreased (0.080587 --> 0.080542).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0800223\n",
      "\tspeed: 0.0333s/iter; left time: 544.0504s\n",
      "\titers: 200, epoch: 28 | loss: 0.0800340\n",
      "\tspeed: 0.0162s/iter; left time: 262.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0828492 Vali Loss: 0.0805744 Test Loss: 0.0840408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777397\n",
      "\tspeed: 0.0302s/iter; left time: 486.3187s\n",
      "\titers: 200, epoch: 29 | loss: 0.0811778\n",
      "\tspeed: 0.0144s/iter; left time: 229.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0827454 Vali Loss: 0.0805498 Test Loss: 0.0839639\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0835300\n",
      "\tspeed: 0.0309s/iter; left time: 489.9205s\n",
      "\titers: 200, epoch: 30 | loss: 0.0868257\n",
      "\tspeed: 0.0135s/iter; left time: 212.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0827651 Vali Loss: 0.0805681 Test Loss: 0.0839407\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0806377\n",
      "\tspeed: 0.0335s/iter; left time: 524.5088s\n",
      "\titers: 200, epoch: 31 | loss: 0.0845461\n",
      "\tspeed: 0.0137s/iter; left time: 213.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0827232 Vali Loss: 0.0805522 Test Loss: 0.0839689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0835842\n",
      "\tspeed: 0.0342s/iter; left time: 527.3555s\n",
      "\titers: 200, epoch: 32 | loss: 0.0815962\n",
      "\tspeed: 0.0157s/iter; left time: 240.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0826887 Vali Loss: 0.0805310 Test Loss: 0.0839658\n",
      "Validation loss decreased (0.080542 --> 0.080531).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0809866\n",
      "\tspeed: 0.0335s/iter; left time: 509.2234s\n",
      "\titers: 200, epoch: 33 | loss: 0.0824218\n",
      "\tspeed: 0.0138s/iter; left time: 208.0215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0826472 Vali Loss: 0.0805753 Test Loss: 0.0839609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0847640\n",
      "\tspeed: 0.0324s/iter; left time: 485.4754s\n",
      "\titers: 200, epoch: 34 | loss: 0.0827174\n",
      "\tspeed: 0.0135s/iter; left time: 200.7018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0825902 Vali Loss: 0.0804826 Test Loss: 0.0839031\n",
      "Validation loss decreased (0.080531 --> 0.080483).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0850436\n",
      "\tspeed: 0.0322s/iter; left time: 475.1488s\n",
      "\titers: 200, epoch: 35 | loss: 0.0816110\n",
      "\tspeed: 0.0172s/iter; left time: 252.6787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0826398 Vali Loss: 0.0805596 Test Loss: 0.0839525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0815209\n",
      "\tspeed: 0.0327s/iter; left time: 474.3686s\n",
      "\titers: 200, epoch: 36 | loss: 0.0839648\n",
      "\tspeed: 0.0152s/iter; left time: 218.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0826163 Vali Loss: 0.0805038 Test Loss: 0.0839111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0860296\n",
      "\tspeed: 0.0349s/iter; left time: 498.8212s\n",
      "\titers: 200, epoch: 37 | loss: 0.0869261\n",
      "\tspeed: 0.0134s/iter; left time: 190.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0825956 Vali Loss: 0.0805430 Test Loss: 0.0839338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0802676\n",
      "\tspeed: 0.0297s/iter; left time: 417.4501s\n",
      "\titers: 200, epoch: 38 | loss: 0.0837821\n",
      "\tspeed: 0.0162s/iter; left time: 226.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0825881 Vali Loss: 0.0804906 Test Loss: 0.0838943\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806852\n",
      "\tspeed: 0.0342s/iter; left time: 474.0467s\n",
      "\titers: 200, epoch: 39 | loss: 0.0814533\n",
      "\tspeed: 0.0138s/iter; left time: 190.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0825416 Vali Loss: 0.0805234 Test Loss: 0.0838914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0820888\n",
      "\tspeed: 0.0327s/iter; left time: 445.6093s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821560\n",
      "\tspeed: 0.0121s/iter; left time: 164.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0825614 Vali Loss: 0.0804942 Test Loss: 0.0838800\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0850261\n",
      "\tspeed: 0.0319s/iter; left time: 427.2972s\n",
      "\titers: 200, epoch: 41 | loss: 0.0803443\n",
      "\tspeed: 0.0135s/iter; left time: 179.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0825454 Vali Loss: 0.0805076 Test Loss: 0.0839223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0823137\n",
      "\tspeed: 0.0317s/iter; left time: 417.1898s\n",
      "\titers: 200, epoch: 42 | loss: 0.0821693\n",
      "\tspeed: 0.0140s/iter; left time: 182.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0825342 Vali Loss: 0.0804796 Test Loss: 0.0838957\n",
      "Validation loss decreased (0.080483 --> 0.080480).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0818895\n",
      "\tspeed: 0.0323s/iter; left time: 418.7576s\n",
      "\titers: 200, epoch: 43 | loss: 0.0808004\n",
      "\tspeed: 0.0165s/iter; left time: 211.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0825386 Vali Loss: 0.0804740 Test Loss: 0.0839132\n",
      "Validation loss decreased (0.080480 --> 0.080474).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0800021\n",
      "\tspeed: 0.0318s/iter; left time: 404.5871s\n",
      "\titers: 200, epoch: 44 | loss: 0.0816120\n",
      "\tspeed: 0.0148s/iter; left time: 186.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0824817 Vali Loss: 0.0804895 Test Loss: 0.0838856\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0832690\n",
      "\tspeed: 0.0303s/iter; left time: 378.3625s\n",
      "\titers: 200, epoch: 45 | loss: 0.0851741\n",
      "\tspeed: 0.0144s/iter; left time: 178.2285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0825183 Vali Loss: 0.0804640 Test Loss: 0.0838956\n",
      "Validation loss decreased (0.080474 --> 0.080464).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0826780\n",
      "\tspeed: 0.0336s/iter; left time: 412.4833s\n",
      "\titers: 200, epoch: 46 | loss: 0.0814674\n",
      "\tspeed: 0.0154s/iter; left time: 187.9869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0824728 Vali Loss: 0.0805161 Test Loss: 0.0838991\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0824381\n",
      "\tspeed: 0.0326s/iter; left time: 393.1660s\n",
      "\titers: 200, epoch: 47 | loss: 0.0820720\n",
      "\tspeed: 0.0138s/iter; left time: 164.3648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0824719 Vali Loss: 0.0805329 Test Loss: 0.0838937\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0816704\n",
      "\tspeed: 0.0319s/iter; left time: 377.5341s\n",
      "\titers: 200, epoch: 48 | loss: 0.0824049\n",
      "\tspeed: 0.0156s/iter; left time: 183.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.0824819 Vali Loss: 0.0805211 Test Loss: 0.0838738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0831242\n",
      "\tspeed: 0.0334s/iter; left time: 387.6008s\n",
      "\titers: 200, epoch: 49 | loss: 0.0879656\n",
      "\tspeed: 0.0144s/iter; left time: 165.7400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0824898 Vali Loss: 0.0804586 Test Loss: 0.0838833\n",
      "Validation loss decreased (0.080464 --> 0.080459).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0832050\n",
      "\tspeed: 0.0312s/iter; left time: 355.4163s\n",
      "\titers: 200, epoch: 50 | loss: 0.0803512\n",
      "\tspeed: 0.0142s/iter; left time: 160.3731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0824435 Vali Loss: 0.0805330 Test Loss: 0.0838903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0852500\n",
      "\tspeed: 0.0309s/iter; left time: 344.6940s\n",
      "\titers: 200, epoch: 51 | loss: 0.0870893\n",
      "\tspeed: 0.0146s/iter; left time: 161.8017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0824777 Vali Loss: 0.0804915 Test Loss: 0.0839028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0807032\n",
      "\tspeed: 0.0318s/iter; left time: 347.5795s\n",
      "\titers: 200, epoch: 52 | loss: 0.0786206\n",
      "\tspeed: 0.0138s/iter; left time: 149.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0824486 Vali Loss: 0.0805221 Test Loss: 0.0838674\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0842347\n",
      "\tspeed: 0.0337s/iter; left time: 360.4496s\n",
      "\titers: 200, epoch: 53 | loss: 0.0816653\n",
      "\tspeed: 0.0151s/iter; left time: 159.9184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0824646 Vali Loss: 0.0804913 Test Loss: 0.0838816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0840804\n",
      "\tspeed: 0.0317s/iter; left time: 331.6062s\n",
      "\titers: 200, epoch: 54 | loss: 0.0853561\n",
      "\tspeed: 0.0133s/iter; left time: 138.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0824673 Vali Loss: 0.0804322 Test Loss: 0.0838672\n",
      "Validation loss decreased (0.080459 --> 0.080432).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0808371\n",
      "\tspeed: 0.0303s/iter; left time: 310.6777s\n",
      "\titers: 200, epoch: 55 | loss: 0.0865470\n",
      "\tspeed: 0.0164s/iter; left time: 166.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0824481 Vali Loss: 0.0804339 Test Loss: 0.0838670\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0815622\n",
      "\tspeed: 0.0316s/iter; left time: 316.7971s\n",
      "\titers: 200, epoch: 56 | loss: 0.0795510\n",
      "\tspeed: 0.0147s/iter; left time: 146.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0824146 Vali Loss: 0.0804940 Test Loss: 0.0838698\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0829281\n",
      "\tspeed: 0.0315s/iter; left time: 308.8791s\n",
      "\titers: 200, epoch: 57 | loss: 0.0846835\n",
      "\tspeed: 0.0155s/iter; left time: 150.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0824535 Vali Loss: 0.0804635 Test Loss: 0.0838689\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0851593\n",
      "\tspeed: 0.0262s/iter; left time: 251.2046s\n",
      "\titers: 200, epoch: 58 | loss: 0.0845411\n",
      "\tspeed: 0.0127s/iter; left time: 120.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:02.68s\n",
      "Steps: 225 | Train Loss: 0.0824196 Vali Loss: 0.0804588 Test Loss: 0.0838646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0828821\n",
      "\tspeed: 0.0301s/iter; left time: 281.3254s\n",
      "\titers: 200, epoch: 59 | loss: 0.0813395\n",
      "\tspeed: 0.0139s/iter; left time: 128.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0824488 Vali Loss: 0.0804834 Test Loss: 0.0838694\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0852619\n",
      "\tspeed: 0.0349s/iter; left time: 318.5720s\n",
      "\titers: 200, epoch: 60 | loss: 0.0812910\n",
      "\tspeed: 0.0142s/iter; left time: 128.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0824398 Vali Loss: 0.0804793 Test Loss: 0.0838750\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0842244\n",
      "\tspeed: 0.0333s/iter; left time: 296.8399s\n",
      "\titers: 200, epoch: 61 | loss: 0.0784000\n",
      "\tspeed: 0.0157s/iter; left time: 137.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0824617 Vali Loss: 0.0804156 Test Loss: 0.0838659\n",
      "Validation loss decreased (0.080432 --> 0.080416).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0833371\n",
      "\tspeed: 0.0331s/iter; left time: 287.0181s\n",
      "\titers: 200, epoch: 62 | loss: 0.0833605\n",
      "\tspeed: 0.0136s/iter; left time: 117.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0824234 Vali Loss: 0.0804492 Test Loss: 0.0838645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0863370\n",
      "\tspeed: 0.0344s/iter; left time: 290.3235s\n",
      "\titers: 200, epoch: 63 | loss: 0.0839509\n",
      "\tspeed: 0.0162s/iter; left time: 135.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0824044 Vali Loss: 0.0804877 Test Loss: 0.0838886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0846398\n",
      "\tspeed: 0.0329s/iter; left time: 270.3732s\n",
      "\titers: 200, epoch: 64 | loss: 0.0764934\n",
      "\tspeed: 0.0143s/iter; left time: 116.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0824521 Vali Loss: 0.0804694 Test Loss: 0.0838725\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0814513\n",
      "\tspeed: 0.0309s/iter; left time: 247.5049s\n",
      "\titers: 200, epoch: 65 | loss: 0.0797426\n",
      "\tspeed: 0.0149s/iter; left time: 118.0801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0824519 Vali Loss: 0.0804954 Test Loss: 0.0838692\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0839763\n",
      "\tspeed: 0.0319s/iter; left time: 247.8746s\n",
      "\titers: 200, epoch: 66 | loss: 0.0816002\n",
      "\tspeed: 0.0152s/iter; left time: 116.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0824202 Vali Loss: 0.0805162 Test Loss: 0.0838694\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0851041\n",
      "\tspeed: 0.0320s/iter; left time: 241.3074s\n",
      "\titers: 200, epoch: 67 | loss: 0.0837165\n",
      "\tspeed: 0.0148s/iter; left time: 110.2715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0823954 Vali Loss: 0.0804389 Test Loss: 0.0838651\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0821131\n",
      "\tspeed: 0.0301s/iter; left time: 220.6340s\n",
      "\titers: 200, epoch: 68 | loss: 0.0796441\n",
      "\tspeed: 0.0155s/iter; left time: 111.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0824576 Vali Loss: 0.0804658 Test Loss: 0.0838831\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0829792\n",
      "\tspeed: 0.0331s/iter; left time: 234.8539s\n",
      "\titers: 200, epoch: 69 | loss: 0.0791521\n",
      "\tspeed: 0.0144s/iter; left time: 100.5982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0824028 Vali Loss: 0.0804799 Test Loss: 0.0838974\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0805139\n",
      "\tspeed: 0.0308s/iter; left time: 212.1246s\n",
      "\titers: 200, epoch: 70 | loss: 0.0803692\n",
      "\tspeed: 0.0136s/iter; left time: 91.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0824049 Vali Loss: 0.0804179 Test Loss: 0.0838689\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0809416\n",
      "\tspeed: 0.0294s/iter; left time: 195.8512s\n",
      "\titers: 200, epoch: 71 | loss: 0.0801527\n",
      "\tspeed: 0.0136s/iter; left time: 89.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0824179 Vali Loss: 0.0804512 Test Loss: 0.0838736\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0193416029214859, rmse:0.13907408714294434, mae:0.0838659256696701, rse:0.5263428092002869\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1784988\n",
      "\tspeed: 0.0155s/iter; left time: 346.5457s\n",
      "\titers: 200, epoch: 1 | loss: 0.1549337\n",
      "\tspeed: 0.0135s/iter; left time: 301.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.1748003 Vali Loss: 0.1329075 Test Loss: 0.1391202\n",
      "Validation loss decreased (inf --> 0.132907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1049042\n",
      "\tspeed: 0.0327s/iter; left time: 725.2683s\n",
      "\titers: 200, epoch: 2 | loss: 0.1010684\n",
      "\tspeed: 0.0164s/iter; left time: 361.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.1089396 Vali Loss: 0.0914637 Test Loss: 0.0949391\n",
      "Validation loss decreased (0.132907 --> 0.091464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0942871\n",
      "\tspeed: 0.0329s/iter; left time: 721.5386s\n",
      "\titers: 200, epoch: 3 | loss: 0.0930805\n",
      "\tspeed: 0.0146s/iter; left time: 319.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0956224 Vali Loss: 0.0859430 Test Loss: 0.0893671\n",
      "Validation loss decreased (0.091464 --> 0.085943).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0898725\n",
      "\tspeed: 0.0329s/iter; left time: 715.3305s\n",
      "\titers: 200, epoch: 4 | loss: 0.0885198\n",
      "\tspeed: 0.0156s/iter; left time: 337.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0910334 Vali Loss: 0.0843306 Test Loss: 0.0875303\n",
      "Validation loss decreased (0.085943 --> 0.084331).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0931762\n",
      "\tspeed: 0.0337s/iter; left time: 724.3696s\n",
      "\titers: 200, epoch: 5 | loss: 0.0880800\n",
      "\tspeed: 0.0173s/iter; left time: 370.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0892447 Vali Loss: 0.0836374 Test Loss: 0.0867536\n",
      "Validation loss decreased (0.084331 --> 0.083637).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0866768\n",
      "\tspeed: 0.0335s/iter; left time: 713.1059s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857697\n",
      "\tspeed: 0.0154s/iter; left time: 325.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0881193 Vali Loss: 0.0829323 Test Loss: 0.0861180\n",
      "Validation loss decreased (0.083637 --> 0.082932).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0853349\n",
      "\tspeed: 0.0368s/iter; left time: 775.0329s\n",
      "\titers: 200, epoch: 7 | loss: 0.0869276\n",
      "\tspeed: 0.0169s/iter; left time: 354.0945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0872537 Vali Loss: 0.0825240 Test Loss: 0.0857578\n",
      "Validation loss decreased (0.082932 --> 0.082524).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0842554\n",
      "\tspeed: 0.0369s/iter; left time: 769.2271s\n",
      "\titers: 200, epoch: 8 | loss: 0.0871452\n",
      "\tspeed: 0.0179s/iter; left time: 371.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0865878 Vali Loss: 0.0822259 Test Loss: 0.0852763\n",
      "Validation loss decreased (0.082524 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0836091\n",
      "\tspeed: 0.0330s/iter; left time: 679.1685s\n",
      "\titers: 200, epoch: 9 | loss: 0.0802410\n",
      "\tspeed: 0.0137s/iter; left time: 281.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0860360 Vali Loss: 0.0819291 Test Loss: 0.0849906\n",
      "Validation loss decreased (0.082226 --> 0.081929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0853468\n",
      "\tspeed: 0.0341s/iter; left time: 694.0844s\n",
      "\titers: 200, epoch: 10 | loss: 0.0832742\n",
      "\tspeed: 0.0147s/iter; left time: 298.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0855387 Vali Loss: 0.0817657 Test Loss: 0.0847857\n",
      "Validation loss decreased (0.081929 --> 0.081766).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0891358\n",
      "\tspeed: 0.0362s/iter; left time: 729.9010s\n",
      "\titers: 200, epoch: 11 | loss: 0.0872889\n",
      "\tspeed: 0.0186s/iter; left time: 372.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0851633 Vali Loss: 0.0814892 Test Loss: 0.0845693\n",
      "Validation loss decreased (0.081766 --> 0.081489).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0813624\n",
      "\tspeed: 0.0386s/iter; left time: 768.9990s\n",
      "\titers: 200, epoch: 12 | loss: 0.0836944\n",
      "\tspeed: 0.0159s/iter; left time: 315.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0848586 Vali Loss: 0.0813308 Test Loss: 0.0844407\n",
      "Validation loss decreased (0.081489 --> 0.081331).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0848219\n",
      "\tspeed: 0.0306s/iter; left time: 603.3629s\n",
      "\titers: 200, epoch: 13 | loss: 0.0855045\n",
      "\tspeed: 0.0158s/iter; left time: 309.8236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0845868 Vali Loss: 0.0812327 Test Loss: 0.0841800\n",
      "Validation loss decreased (0.081331 --> 0.081233).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0850773\n",
      "\tspeed: 0.0356s/iter; left time: 693.0714s\n",
      "\titers: 200, epoch: 14 | loss: 0.0848274\n",
      "\tspeed: 0.0149s/iter; left time: 287.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0842811 Vali Loss: 0.0810937 Test Loss: 0.0840996\n",
      "Validation loss decreased (0.081233 --> 0.081094).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0840248\n",
      "\tspeed: 0.0332s/iter; left time: 638.5560s\n",
      "\titers: 200, epoch: 15 | loss: 0.0851064\n",
      "\tspeed: 0.0160s/iter; left time: 306.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 225 | Train Loss: 0.0840714 Vali Loss: 0.0809693 Test Loss: 0.0840812\n",
      "Validation loss decreased (0.081094 --> 0.080969).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0814152\n",
      "\tspeed: 0.0327s/iter; left time: 621.3903s\n",
      "\titers: 200, epoch: 16 | loss: 0.0859399\n",
      "\tspeed: 0.0138s/iter; left time: 261.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0838823 Vali Loss: 0.0807974 Test Loss: 0.0840038\n",
      "Validation loss decreased (0.080969 --> 0.080797).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0891059\n",
      "\tspeed: 0.0383s/iter; left time: 720.8372s\n",
      "\titers: 200, epoch: 17 | loss: 0.0839673\n",
      "\tspeed: 0.0160s/iter; left time: 298.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.0837397 Vali Loss: 0.0808102 Test Loss: 0.0838756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0834020\n",
      "\tspeed: 0.0340s/iter; left time: 631.4375s\n",
      "\titers: 200, epoch: 18 | loss: 0.0852193\n",
      "\tspeed: 0.0148s/iter; left time: 273.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0835563 Vali Loss: 0.0807235 Test Loss: 0.0839719\n",
      "Validation loss decreased (0.080797 --> 0.080723).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0840779\n",
      "\tspeed: 0.0336s/iter; left time: 616.3674s\n",
      "\titers: 200, epoch: 19 | loss: 0.0853806\n",
      "\tspeed: 0.0138s/iter; left time: 252.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0834333 Vali Loss: 0.0807208 Test Loss: 0.0837957\n",
      "Validation loss decreased (0.080723 --> 0.080721).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0856571\n",
      "\tspeed: 0.0385s/iter; left time: 697.0169s\n",
      "\titers: 200, epoch: 20 | loss: 0.0811809\n",
      "\tspeed: 0.0161s/iter; left time: 290.1358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0833354 Vali Loss: 0.0806525 Test Loss: 0.0837614\n",
      "Validation loss decreased (0.080721 --> 0.080653).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0816818\n",
      "\tspeed: 0.0346s/iter; left time: 620.0940s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783284\n",
      "\tspeed: 0.0159s/iter; left time: 282.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0832280 Vali Loss: 0.0806199 Test Loss: 0.0837189\n",
      "Validation loss decreased (0.080653 --> 0.080620).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0859399\n",
      "\tspeed: 0.0340s/iter; left time: 601.2955s\n",
      "\titers: 200, epoch: 22 | loss: 0.0845785\n",
      "\tspeed: 0.0169s/iter; left time: 296.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0831869 Vali Loss: 0.0804965 Test Loss: 0.0836891\n",
      "Validation loss decreased (0.080620 --> 0.080496).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0833930\n",
      "\tspeed: 0.0342s/iter; left time: 596.0683s\n",
      "\titers: 200, epoch: 23 | loss: 0.0846428\n",
      "\tspeed: 0.0157s/iter; left time: 272.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0830643 Vali Loss: 0.0805329 Test Loss: 0.0835506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0793139\n",
      "\tspeed: 0.0331s/iter; left time: 569.7538s\n",
      "\titers: 200, epoch: 24 | loss: 0.0828555\n",
      "\tspeed: 0.0150s/iter; left time: 256.5613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0830092 Vali Loss: 0.0805353 Test Loss: 0.0835840\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0858048\n",
      "\tspeed: 0.0330s/iter; left time: 560.5382s\n",
      "\titers: 200, epoch: 25 | loss: 0.0830038\n",
      "\tspeed: 0.0124s/iter; left time: 210.0328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 225 | Train Loss: 0.0829615 Vali Loss: 0.0804541 Test Loss: 0.0836086\n",
      "Validation loss decreased (0.080496 --> 0.080454).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0778056\n",
      "\tspeed: 0.0311s/iter; left time: 521.6997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0810597\n",
      "\tspeed: 0.0113s/iter; left time: 188.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0828246 Vali Loss: 0.0805540 Test Loss: 0.0836263\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0842848\n",
      "\tspeed: 0.0326s/iter; left time: 539.8889s\n",
      "\titers: 200, epoch: 27 | loss: 0.0821154\n",
      "\tspeed: 0.0148s/iter; left time: 243.7366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.0828159 Vali Loss: 0.0804413 Test Loss: 0.0835247\n",
      "Validation loss decreased (0.080454 --> 0.080441).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0853203\n",
      "\tspeed: 0.0345s/iter; left time: 562.5078s\n",
      "\titers: 200, epoch: 28 | loss: 0.0874631\n",
      "\tspeed: 0.0153s/iter; left time: 248.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0827551 Vali Loss: 0.0805700 Test Loss: 0.0835873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0799956\n",
      "\tspeed: 0.0316s/iter; left time: 509.3941s\n",
      "\titers: 200, epoch: 29 | loss: 0.0815700\n",
      "\tspeed: 0.0163s/iter; left time: 260.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0826542 Vali Loss: 0.0804916 Test Loss: 0.0836076\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0839046\n",
      "\tspeed: 0.0317s/iter; left time: 502.8993s\n",
      "\titers: 200, epoch: 30 | loss: 0.0859862\n",
      "\tspeed: 0.0149s/iter; left time: 234.3110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0827082 Vali Loss: 0.0804205 Test Loss: 0.0834989\n",
      "Validation loss decreased (0.080441 --> 0.080421).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785363\n",
      "\tspeed: 0.0344s/iter; left time: 538.9357s\n",
      "\titers: 200, epoch: 31 | loss: 0.0807141\n",
      "\tspeed: 0.0142s/iter; left time: 220.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0826330 Vali Loss: 0.0803600 Test Loss: 0.0835197\n",
      "Validation loss decreased (0.080421 --> 0.080360).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0846244\n",
      "\tspeed: 0.0329s/iter; left time: 508.2559s\n",
      "\titers: 200, epoch: 32 | loss: 0.0800492\n",
      "\tspeed: 0.0147s/iter; left time: 225.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0826634 Vali Loss: 0.0804198 Test Loss: 0.0835178\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0860632\n",
      "\tspeed: 0.0316s/iter; left time: 480.6323s\n",
      "\titers: 200, epoch: 33 | loss: 0.0821227\n",
      "\tspeed: 0.0159s/iter; left time: 240.8134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0825794 Vali Loss: 0.0804476 Test Loss: 0.0835956\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0821408\n",
      "\tspeed: 0.0330s/iter; left time: 494.2803s\n",
      "\titers: 200, epoch: 34 | loss: 0.0846917\n",
      "\tspeed: 0.0135s/iter; left time: 200.4905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.0825484 Vali Loss: 0.0804066 Test Loss: 0.0834931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0847293\n",
      "\tspeed: 0.0375s/iter; left time: 552.6937s\n",
      "\titers: 200, epoch: 35 | loss: 0.0837943\n",
      "\tspeed: 0.0151s/iter; left time: 221.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0825543 Vali Loss: 0.0804073 Test Loss: 0.0835391\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0858705\n",
      "\tspeed: 0.0335s/iter; left time: 487.0941s\n",
      "\titers: 200, epoch: 36 | loss: 0.0832348\n",
      "\tspeed: 0.0153s/iter; left time: 221.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0825066 Vali Loss: 0.0803504 Test Loss: 0.0834923\n",
      "Validation loss decreased (0.080360 --> 0.080350).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0843036\n",
      "\tspeed: 0.0326s/iter; left time: 466.1062s\n",
      "\titers: 200, epoch: 37 | loss: 0.0852268\n",
      "\tspeed: 0.0145s/iter; left time: 205.6040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0825554 Vali Loss: 0.0803276 Test Loss: 0.0834192\n",
      "Validation loss decreased (0.080350 --> 0.080328).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829972\n",
      "\tspeed: 0.0337s/iter; left time: 474.4427s\n",
      "\titers: 200, epoch: 38 | loss: 0.0801826\n",
      "\tspeed: 0.0131s/iter; left time: 182.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0824824 Vali Loss: 0.0803668 Test Loss: 0.0834639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0849120\n",
      "\tspeed: 0.0345s/iter; left time: 477.4757s\n",
      "\titers: 200, epoch: 39 | loss: 0.0813960\n",
      "\tspeed: 0.0150s/iter; left time: 205.6081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0824876 Vali Loss: 0.0803633 Test Loss: 0.0834384\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0810695\n",
      "\tspeed: 0.0335s/iter; left time: 456.8660s\n",
      "\titers: 200, epoch: 40 | loss: 0.0809172\n",
      "\tspeed: 0.0115s/iter; left time: 154.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0825420 Vali Loss: 0.0803031 Test Loss: 0.0834674\n",
      "Validation loss decreased (0.080328 --> 0.080303).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0851122\n",
      "\tspeed: 0.0317s/iter; left time: 425.0348s\n",
      "\titers: 200, epoch: 41 | loss: 0.0811130\n",
      "\tspeed: 0.0139s/iter; left time: 185.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0824601 Vali Loss: 0.0804046 Test Loss: 0.0834626\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0806999\n",
      "\tspeed: 0.0338s/iter; left time: 444.7616s\n",
      "\titers: 200, epoch: 42 | loss: 0.0843640\n",
      "\tspeed: 0.0151s/iter; left time: 197.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.0824278 Vali Loss: 0.0803756 Test Loss: 0.0834578\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0815923\n",
      "\tspeed: 0.0303s/iter; left time: 392.6815s\n",
      "\titers: 200, epoch: 43 | loss: 0.0811890\n",
      "\tspeed: 0.0137s/iter; left time: 176.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0824681 Vali Loss: 0.0803768 Test Loss: 0.0834570\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0826172\n",
      "\tspeed: 0.0313s/iter; left time: 398.3824s\n",
      "\titers: 200, epoch: 44 | loss: 0.0818189\n",
      "\tspeed: 0.0131s/iter; left time: 165.0688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0824418 Vali Loss: 0.0803616 Test Loss: 0.0834882\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0817119\n",
      "\tspeed: 0.0339s/iter; left time: 423.2425s\n",
      "\titers: 200, epoch: 45 | loss: 0.0845270\n",
      "\tspeed: 0.0150s/iter; left time: 185.6950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0824282 Vali Loss: 0.0803492 Test Loss: 0.0834687\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0804311\n",
      "\tspeed: 0.0318s/iter; left time: 390.4195s\n",
      "\titers: 200, epoch: 46 | loss: 0.0827753\n",
      "\tspeed: 0.0141s/iter; left time: 172.1936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0824462 Vali Loss: 0.0803093 Test Loss: 0.0834684\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0836362\n",
      "\tspeed: 0.0307s/iter; left time: 370.1008s\n",
      "\titers: 200, epoch: 47 | loss: 0.0831367\n",
      "\tspeed: 0.0138s/iter; left time: 165.4546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0824477 Vali Loss: 0.0802994 Test Loss: 0.0834500\n",
      "Validation loss decreased (0.080303 --> 0.080299).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0875860\n",
      "\tspeed: 0.0368s/iter; left time: 435.2491s\n",
      "\titers: 200, epoch: 48 | loss: 0.0818463\n",
      "\tspeed: 0.0159s/iter; left time: 186.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0824216 Vali Loss: 0.0803793 Test Loss: 0.0834427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0791136\n",
      "\tspeed: 0.0313s/iter; left time: 363.0695s\n",
      "\titers: 200, epoch: 49 | loss: 0.0819060\n",
      "\tspeed: 0.0138s/iter; left time: 158.4806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0824030 Vali Loss: 0.0802259 Test Loss: 0.0834320\n",
      "Validation loss decreased (0.080299 --> 0.080226).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0818883\n",
      "\tspeed: 0.0351s/iter; left time: 399.2640s\n",
      "\titers: 200, epoch: 50 | loss: 0.0830338\n",
      "\tspeed: 0.0135s/iter; left time: 151.7218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0823729 Vali Loss: 0.0803033 Test Loss: 0.0834494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0815962\n",
      "\tspeed: 0.0310s/iter; left time: 346.0904s\n",
      "\titers: 200, epoch: 51 | loss: 0.0868048\n",
      "\tspeed: 0.0128s/iter; left time: 141.1499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0823990 Vali Loss: 0.0803362 Test Loss: 0.0834526\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0827550\n",
      "\tspeed: 0.0322s/iter; left time: 351.6882s\n",
      "\titers: 200, epoch: 52 | loss: 0.0800598\n",
      "\tspeed: 0.0131s/iter; left time: 141.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0823701 Vali Loss: 0.0803447 Test Loss: 0.0834157\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0834138\n",
      "\tspeed: 0.0315s/iter; left time: 337.6128s\n",
      "\titers: 200, epoch: 53 | loss: 0.0845081\n",
      "\tspeed: 0.0139s/iter; left time: 147.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0824211 Vali Loss: 0.0802739 Test Loss: 0.0834224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0819310\n",
      "\tspeed: 0.0308s/iter; left time: 322.5646s\n",
      "\titers: 200, epoch: 54 | loss: 0.0815623\n",
      "\tspeed: 0.0127s/iter; left time: 131.6544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0823798 Vali Loss: 0.0803688 Test Loss: 0.0834595\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0833901\n",
      "\tspeed: 0.0307s/iter; left time: 314.4701s\n",
      "\titers: 200, epoch: 55 | loss: 0.0825498\n",
      "\tspeed: 0.0139s/iter; left time: 141.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0823757 Vali Loss: 0.0803462 Test Loss: 0.0834499\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0810068\n",
      "\tspeed: 0.0325s/iter; left time: 325.5205s\n",
      "\titers: 200, epoch: 56 | loss: 0.0798856\n",
      "\tspeed: 0.0141s/iter; left time: 139.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0823553 Vali Loss: 0.0803168 Test Loss: 0.0834589\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0838879\n",
      "\tspeed: 0.0314s/iter; left time: 308.0115s\n",
      "\titers: 200, epoch: 57 | loss: 0.0840291\n",
      "\tspeed: 0.0143s/iter; left time: 138.6960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0824082 Vali Loss: 0.0802780 Test Loss: 0.0834247\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0831917\n",
      "\tspeed: 0.0313s/iter; left time: 299.8424s\n",
      "\titers: 200, epoch: 58 | loss: 0.0840894\n",
      "\tspeed: 0.0120s/iter; left time: 113.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0823862 Vali Loss: 0.0802933 Test Loss: 0.0834472\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0811067\n",
      "\tspeed: 0.0310s/iter; left time: 289.5092s\n",
      "\titers: 200, epoch: 59 | loss: 0.0839771\n",
      "\tspeed: 0.0102s/iter; left time: 94.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0823735 Vali Loss: 0.0802963 Test Loss: 0.0834475\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019266340881586075, rmse:0.13880324363708496, mae:0.08343201130628586, rse:0.5253177285194397\n",
      "Intermediate time for IT and pred_len 168: 00h:10m:25.87s\n",
      "Intermediate time for IT: 00h:29m:37.16s\n",
      "Total time: 02h:11m:43.89s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --patch_len 12 \\\n",
    "              --stride 12 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST_p12_s12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.0991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST_p12_s12                \n",
       "Metrics                       MSE    RMSE     MAE\n",
       "Country Pred_len                                 \n",
       "DE      24                 0.0208  0.1442  0.0874\n",
       "        96                 0.0353  0.1880  0.1244\n",
       "        168                0.0384  0.1961  0.1323\n",
       "ES      24                 0.0098  0.0988  0.0597\n",
       "        96                 0.0184  0.1356  0.0860\n",
       "        168                0.0205  0.1432  0.0918\n",
       "FR      24                 0.0100  0.0998  0.0549\n",
       "        96                 0.0194  0.1392  0.0795\n",
       "        168                0.0211  0.1453  0.0855\n",
       "GB      24                 0.0245  0.1567  0.0991\n",
       "        96                 0.0410  0.2025  0.1383\n",
       "        168                0.0435  0.2086  0.1447\n",
       "IT      24                 0.0102  0.1007  0.0572\n",
       "        96                 0.0181  0.1344  0.0792\n",
       "        168                0.0193  0.1389  0.0836"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST_p12_s12'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_patch12_stride12.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
