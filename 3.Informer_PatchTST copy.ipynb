{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 168](#3-patchtst-168)\n",
    "- [4. PatchTST 336](#4-patchtst-336)\n",
    "- [5. PatchTST 512](#5-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with input look-back windows =168, 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A6000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MSE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0844291\n",
      "\tspeed: 0.1427s/iter; left time: 2572.1345s\n",
      "\titers: 200, epoch: 1 | loss: 0.0693888\n",
      "\tspeed: 0.0494s/iter; left time: 885.8380s\n",
      "\titers: 300, epoch: 1 | loss: 0.0655493\n",
      "\tspeed: 0.0499s/iter; left time: 890.1312s\n",
      "\titers: 400, epoch: 1 | loss: 0.0564399\n",
      "\tspeed: 0.0496s/iter; left time: 879.7680s\n",
      "\titers: 500, epoch: 1 | loss: 0.0501456\n",
      "\tspeed: 0.0501s/iter; left time: 882.9455s\n",
      "\titers: 600, epoch: 1 | loss: 0.0479440\n",
      "\tspeed: 0.0499s/iter; left time: 873.8236s\n",
      "\titers: 700, epoch: 1 | loss: 0.0540418\n",
      "\tspeed: 0.0497s/iter; left time: 866.1543s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 168\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values.\n",
    "\n",
    "Again, we separated all look-back windows into different cells, to settle up training on remote servers. Here is first with look-back 168 time steps, the next will be 336 and finally 512. In the following 3 parts all arguments are the same except seq_lem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0383199\n",
      "\tspeed: 0.0538s/iter; left time: 1210.6422s\n",
      "\titers: 200, epoch: 1 | loss: 0.0312549\n",
      "\tspeed: 0.0263s/iter; left time: 590.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 226 | Train Loss: 0.0377966 Vali Loss: 0.0340360 Test Loss: 0.0390400\n",
      "Validation loss decreased (inf --> 0.034036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0153823\n",
      "\tspeed: 0.0444s/iter; left time: 988.6494s\n",
      "\titers: 200, epoch: 2 | loss: 0.0156625\n",
      "\tspeed: 0.0235s/iter; left time: 521.2420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 226 | Train Loss: 0.0177919 Vali Loss: 0.0212845 Test Loss: 0.0229115\n",
      "Validation loss decreased (0.034036 --> 0.021285).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0143448\n",
      "\tspeed: 0.0464s/iter; left time: 1022.2165s\n",
      "\titers: 200, epoch: 3 | loss: 0.0157216\n",
      "\tspeed: 0.0227s/iter; left time: 499.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 226 | Train Loss: 0.0150513 Vali Loss: 0.0200835 Test Loss: 0.0220109\n",
      "Validation loss decreased (0.021285 --> 0.020084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0155801\n",
      "\tspeed: 0.0444s/iter; left time: 968.1773s\n",
      "\titers: 200, epoch: 4 | loss: 0.0138919\n",
      "\tspeed: 0.0219s/iter; left time: 475.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 226 | Train Loss: 0.0143696 Vali Loss: 0.0197017 Test Loss: 0.0216145\n",
      "Validation loss decreased (0.020084 --> 0.019702).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0155787\n",
      "\tspeed: 0.0520s/iter; left time: 1123.7833s\n",
      "\titers: 200, epoch: 5 | loss: 0.0120253\n",
      "\tspeed: 0.0255s/iter; left time: 547.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0140176 Vali Loss: 0.0197954 Test Loss: 0.0217132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0116973\n",
      "\tspeed: 0.0473s/iter; left time: 1010.2116s\n",
      "\titers: 200, epoch: 6 | loss: 0.0129933\n",
      "\tspeed: 0.0275s/iter; left time: 584.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0137816 Vali Loss: 0.0194198 Test Loss: 0.0212227\n",
      "Validation loss decreased (0.019702 --> 0.019420).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0148134\n",
      "\tspeed: 0.0510s/iter; left time: 1077.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0137267\n",
      "\tspeed: 0.0265s/iter; left time: 558.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0136141 Vali Loss: 0.0193366 Test Loss: 0.0213316\n",
      "Validation loss decreased (0.019420 --> 0.019337).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0116126\n",
      "\tspeed: 0.0460s/iter; left time: 961.8929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0123869\n",
      "\tspeed: 0.0185s/iter; left time: 385.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0135009 Vali Loss: 0.0191222 Test Loss: 0.0213271\n",
      "Validation loss decreased (0.019337 --> 0.019122).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0126129\n",
      "\tspeed: 0.0480s/iter; left time: 994.0540s\n",
      "\titers: 200, epoch: 9 | loss: 0.0113241\n",
      "\tspeed: 0.0280s/iter; left time: 575.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0133891 Vali Loss: 0.0191334 Test Loss: 0.0211914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0143735\n",
      "\tspeed: 0.0497s/iter; left time: 1017.7869s\n",
      "\titers: 200, epoch: 10 | loss: 0.0132874\n",
      "\tspeed: 0.0210s/iter; left time: 427.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0132893 Vali Loss: 0.0191786 Test Loss: 0.0212638\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0139704\n",
      "\tspeed: 0.0473s/iter; left time: 957.6863s\n",
      "\titers: 200, epoch: 11 | loss: 0.0125956\n",
      "\tspeed: 0.0253s/iter; left time: 509.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0132077 Vali Loss: 0.0191151 Test Loss: 0.0212688\n",
      "Validation loss decreased (0.019122 --> 0.019115).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0130513\n",
      "\tspeed: 0.0502s/iter; left time: 1004.8599s\n",
      "\titers: 200, epoch: 12 | loss: 0.0148896\n",
      "\tspeed: 0.0255s/iter; left time: 508.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 226 | Train Loss: 0.0131658 Vali Loss: 0.0190011 Test Loss: 0.0211472\n",
      "Validation loss decreased (0.019115 --> 0.019001).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0128899\n",
      "\tspeed: 0.0478s/iter; left time: 946.5364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0118731\n",
      "\tspeed: 0.0253s/iter; left time: 498.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 226 | Train Loss: 0.0131046 Vali Loss: 0.0189218 Test Loss: 0.0210358\n",
      "Validation loss decreased (0.019001 --> 0.018922).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0133532\n",
      "\tspeed: 0.0469s/iter; left time: 917.2947s\n",
      "\titers: 200, epoch: 14 | loss: 0.0144624\n",
      "\tspeed: 0.0254s/iter; left time: 494.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 226 | Train Loss: 0.0130366 Vali Loss: 0.0189040 Test Loss: 0.0210546\n",
      "Validation loss decreased (0.018922 --> 0.018904).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0130911\n",
      "\tspeed: 0.0488s/iter; left time: 943.7265s\n",
      "\titers: 200, epoch: 15 | loss: 0.0122813\n",
      "\tspeed: 0.0263s/iter; left time: 506.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 226 | Train Loss: 0.0129929 Vali Loss: 0.0188822 Test Loss: 0.0209941\n",
      "Validation loss decreased (0.018904 --> 0.018882).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0127345\n",
      "\tspeed: 0.0504s/iter; left time: 963.2289s\n",
      "\titers: 200, epoch: 16 | loss: 0.0142818\n",
      "\tspeed: 0.0271s/iter; left time: 514.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0129400 Vali Loss: 0.0188522 Test Loss: 0.0209537\n",
      "Validation loss decreased (0.018882 --> 0.018852).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0127672\n",
      "\tspeed: 0.0469s/iter; left time: 886.4343s\n",
      "\titers: 200, epoch: 17 | loss: 0.0128871\n",
      "\tspeed: 0.0204s/iter; left time: 382.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0129139 Vali Loss: 0.0188519 Test Loss: 0.0210161\n",
      "Validation loss decreased (0.018852 --> 0.018852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0121936\n",
      "\tspeed: 0.0476s/iter; left time: 887.5064s\n",
      "\titers: 200, epoch: 18 | loss: 0.0122830\n",
      "\tspeed: 0.0253s/iter; left time: 469.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0128742 Vali Loss: 0.0188405 Test Loss: 0.0209885\n",
      "Validation loss decreased (0.018852 --> 0.018841).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0152183\n",
      "\tspeed: 0.0461s/iter; left time: 848.9115s\n",
      "\titers: 200, epoch: 19 | loss: 0.0130465\n",
      "\tspeed: 0.0257s/iter; left time: 470.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 226 | Train Loss: 0.0128390 Vali Loss: 0.0188048 Test Loss: 0.0209550\n",
      "Validation loss decreased (0.018841 --> 0.018805).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0138098\n",
      "\tspeed: 0.0483s/iter; left time: 879.3514s\n",
      "\titers: 200, epoch: 20 | loss: 0.0152119\n",
      "\tspeed: 0.0266s/iter; left time: 480.9686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0128229 Vali Loss: 0.0186983 Test Loss: 0.0209512\n",
      "Validation loss decreased (0.018805 --> 0.018698).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0121355\n",
      "\tspeed: 0.0476s/iter; left time: 855.5641s\n",
      "\titers: 200, epoch: 21 | loss: 0.0112943\n",
      "\tspeed: 0.0263s/iter; left time: 470.2271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0127835 Vali Loss: 0.0188119 Test Loss: 0.0209863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0121620\n",
      "\tspeed: 0.0465s/iter; left time: 826.2803s\n",
      "\titers: 200, epoch: 22 | loss: 0.0122019\n",
      "\tspeed: 0.0278s/iter; left time: 490.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0127699 Vali Loss: 0.0188123 Test Loss: 0.0210200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0129834\n",
      "\tspeed: 0.0496s/iter; left time: 869.7931s\n",
      "\titers: 200, epoch: 23 | loss: 0.0121842\n",
      "\tspeed: 0.0200s/iter; left time: 348.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0127693 Vali Loss: 0.0187909 Test Loss: 0.0210002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0110590\n",
      "\tspeed: 0.0414s/iter; left time: 717.1757s\n",
      "\titers: 200, epoch: 24 | loss: 0.0139926\n",
      "\tspeed: 0.0188s/iter; left time: 324.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0127507 Vali Loss: 0.0187344 Test Loss: 0.0209447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0128071\n",
      "\tspeed: 0.0464s/iter; left time: 791.6337s\n",
      "\titers: 200, epoch: 25 | loss: 0.0132529\n",
      "\tspeed: 0.0251s/iter; left time: 426.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0127247 Vali Loss: 0.0188031 Test Loss: 0.0209953\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0114409\n",
      "\tspeed: 0.0433s/iter; left time: 729.4194s\n",
      "\titers: 200, epoch: 26 | loss: 0.0129284\n",
      "\tspeed: 0.0234s/iter; left time: 392.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 226 | Train Loss: 0.0127187 Vali Loss: 0.0188277 Test Loss: 0.0209686\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0145785\n",
      "\tspeed: 0.0469s/iter; left time: 780.0009s\n",
      "\titers: 200, epoch: 27 | loss: 0.0137299\n",
      "\tspeed: 0.0258s/iter; left time: 426.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 226 | Train Loss: 0.0127071 Vali Loss: 0.0187976 Test Loss: 0.0209546\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0120018\n",
      "\tspeed: 0.0482s/iter; left time: 791.0466s\n",
      "\titers: 200, epoch: 28 | loss: 0.0117700\n",
      "\tspeed: 0.0273s/iter; left time: 445.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0126744 Vali Loss: 0.0187394 Test Loss: 0.0209601\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0133241\n",
      "\tspeed: 0.0510s/iter; left time: 824.5815s\n",
      "\titers: 200, epoch: 29 | loss: 0.0133722\n",
      "\tspeed: 0.0264s/iter; left time: 424.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0126740 Vali Loss: 0.0187694 Test Loss: 0.0209734\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0131072\n",
      "\tspeed: 0.0468s/iter; left time: 746.9519s\n",
      "\titers: 200, epoch: 30 | loss: 0.0118285\n",
      "\tspeed: 0.0256s/iter; left time: 405.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 226 | Train Loss: 0.0126849 Vali Loss: 0.0186991 Test Loss: 0.0209547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020951194688677788, rmse:0.14474527537822723, mae:0.09142162650823593, rse:0.5108261108398438\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:48.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0411841\n",
      "\tspeed: 0.0479s/iter; left time: 1072.1390s\n",
      "\titers: 200, epoch: 1 | loss: 0.0347563\n",
      "\tspeed: 0.0200s/iter; left time: 445.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0428926 Vali Loss: 0.0408700 Test Loss: 0.0488379\n",
      "Validation loss decreased (inf --> 0.040870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0280918\n",
      "\tspeed: 0.0529s/iter; left time: 1172.3212s\n",
      "\titers: 200, epoch: 2 | loss: 0.0259415\n",
      "\tspeed: 0.0274s/iter; left time: 604.1406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 225 | Train Loss: 0.0278961 Vali Loss: 0.0323799 Test Loss: 0.0383353\n",
      "Validation loss decreased (0.040870 --> 0.032380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0256202\n",
      "\tspeed: 0.0543s/iter; left time: 1191.7391s\n",
      "\titers: 200, epoch: 3 | loss: 0.0249472\n",
      "\tspeed: 0.0268s/iter; left time: 586.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0248436 Vali Loss: 0.0313352 Test Loss: 0.0374697\n",
      "Validation loss decreased (0.032380 --> 0.031335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0231897\n",
      "\tspeed: 0.0543s/iter; left time: 1179.5102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0219180\n",
      "\tspeed: 0.0273s/iter; left time: 590.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 225 | Train Loss: 0.0240810 Vali Loss: 0.0309673 Test Loss: 0.0371241\n",
      "Validation loss decreased (0.031335 --> 0.030967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0224635\n",
      "\tspeed: 0.0535s/iter; left time: 1150.8540s\n",
      "\titers: 200, epoch: 5 | loss: 0.0248532\n",
      "\tspeed: 0.0252s/iter; left time: 539.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0236383 Vali Loss: 0.0312279 Test Loss: 0.0370489\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0259781\n",
      "\tspeed: 0.0527s/iter; left time: 1120.8972s\n",
      "\titers: 200, epoch: 6 | loss: 0.0241365\n",
      "\tspeed: 0.0239s/iter; left time: 505.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0232959 Vali Loss: 0.0309534 Test Loss: 0.0370188\n",
      "Validation loss decreased (0.030967 --> 0.030953).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0221646\n",
      "\tspeed: 0.0525s/iter; left time: 1105.9718s\n",
      "\titers: 200, epoch: 7 | loss: 0.0239294\n",
      "\tspeed: 0.0302s/iter; left time: 632.4346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 225 | Train Loss: 0.0231015 Vali Loss: 0.0309000 Test Loss: 0.0367180\n",
      "Validation loss decreased (0.030953 --> 0.030900).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0237838\n",
      "\tspeed: 0.0575s/iter; left time: 1197.4413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0253054\n",
      "\tspeed: 0.0306s/iter; left time: 633.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 225 | Train Loss: 0.0229007 Vali Loss: 0.0309551 Test Loss: 0.0369570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0234542\n",
      "\tspeed: 0.0540s/iter; left time: 1112.7232s\n",
      "\titers: 200, epoch: 9 | loss: 0.0214983\n",
      "\tspeed: 0.0306s/iter; left time: 626.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 225 | Train Loss: 0.0227605 Vali Loss: 0.0308411 Test Loss: 0.0365352\n",
      "Validation loss decreased (0.030900 --> 0.030841).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0219778\n",
      "\tspeed: 0.0546s/iter; left time: 1113.0700s\n",
      "\titers: 200, epoch: 10 | loss: 0.0220064\n",
      "\tspeed: 0.0286s/iter; left time: 578.9570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0225765 Vali Loss: 0.0307082 Test Loss: 0.0365368\n",
      "Validation loss decreased (0.030841 --> 0.030708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0229735\n",
      "\tspeed: 0.0555s/iter; left time: 1118.1702s\n",
      "\titers: 200, epoch: 11 | loss: 0.0225767\n",
      "\tspeed: 0.0293s/iter; left time: 586.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0224487 Vali Loss: 0.0306180 Test Loss: 0.0365732\n",
      "Validation loss decreased (0.030708 --> 0.030618).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0217478\n",
      "\tspeed: 0.0521s/iter; left time: 1038.9132s\n",
      "\titers: 200, epoch: 12 | loss: 0.0245087\n",
      "\tspeed: 0.0237s/iter; left time: 470.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0223362 Vali Loss: 0.0307271 Test Loss: 0.0367705\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0234131\n",
      "\tspeed: 0.0498s/iter; left time: 980.9358s\n",
      "\titers: 200, epoch: 13 | loss: 0.0227327\n",
      "\tspeed: 0.0203s/iter; left time: 396.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 225 | Train Loss: 0.0222529 Vali Loss: 0.0309070 Test Loss: 0.0368769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0223071\n",
      "\tspeed: 0.0502s/iter; left time: 978.3189s\n",
      "\titers: 200, epoch: 14 | loss: 0.0235474\n",
      "\tspeed: 0.0263s/iter; left time: 509.9303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0221733 Vali Loss: 0.0307393 Test Loss: 0.0366288\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0220968\n",
      "\tspeed: 0.0534s/iter; left time: 1027.1092s\n",
      "\titers: 200, epoch: 15 | loss: 0.0209606\n",
      "\tspeed: 0.0284s/iter; left time: 544.7682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 225 | Train Loss: 0.0221032 Vali Loss: 0.0307878 Test Loss: 0.0366282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0221824\n",
      "\tspeed: 0.0531s/iter; left time: 1011.0572s\n",
      "\titers: 200, epoch: 16 | loss: 0.0217833\n",
      "\tspeed: 0.0269s/iter; left time: 509.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 225 | Train Loss: 0.0220159 Vali Loss: 0.0307263 Test Loss: 0.0364834\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0211384\n",
      "\tspeed: 0.0488s/iter; left time: 918.3960s\n",
      "\titers: 200, epoch: 17 | loss: 0.0233507\n",
      "\tspeed: 0.0268s/iter; left time: 501.8258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 225 | Train Loss: 0.0219597 Vali Loss: 0.0307062 Test Loss: 0.0367133\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0248679\n",
      "\tspeed: 0.0519s/iter; left time: 963.8943s\n",
      "\titers: 200, epoch: 18 | loss: 0.0207510\n",
      "\tspeed: 0.0271s/iter; left time: 500.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0218721 Vali Loss: 0.0306500 Test Loss: 0.0365560\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0224404\n",
      "\tspeed: 0.0491s/iter; left time: 900.1339s\n",
      "\titers: 200, epoch: 19 | loss: 0.0215610\n",
      "\tspeed: 0.0243s/iter; left time: 444.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 225 | Train Loss: 0.0218504 Vali Loss: 0.0308245 Test Loss: 0.0366136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0218998\n",
      "\tspeed: 0.0529s/iter; left time: 958.2390s\n",
      "\titers: 200, epoch: 20 | loss: 0.0231873\n",
      "\tspeed: 0.0268s/iter; left time: 483.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0218139 Vali Loss: 0.0308543 Test Loss: 0.0368732\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0215853\n",
      "\tspeed: 0.0448s/iter; left time: 801.9054s\n",
      "\titers: 200, epoch: 21 | loss: 0.0210817\n",
      "\tspeed: 0.0195s/iter; left time: 346.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.0217619 Vali Loss: 0.0308317 Test Loss: 0.0368701\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036573249846696854, rmse:0.1912413388490677, mae:0.12977558374404907, rse:0.6772242784500122\n",
      "Intermediate time for DE and pred_len 96: 00h:02m:56.07s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0447109\n",
      "\tspeed: 0.0359s/iter; left time: 803.6922s\n",
      "\titers: 200, epoch: 1 | loss: 0.0350626\n",
      "\tspeed: 0.0223s/iter; left time: 497.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 225 | Train Loss: 0.0450947 Vali Loss: 0.0424763 Test Loss: 0.0511885\n",
      "Validation loss decreased (inf --> 0.042476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0322759\n",
      "\tspeed: 0.0457s/iter; left time: 1013.7407s\n",
      "\titers: 200, epoch: 2 | loss: 0.0286798\n",
      "\tspeed: 0.0212s/iter; left time: 468.1730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0307300 Vali Loss: 0.0340023 Test Loss: 0.0414040\n",
      "Validation loss decreased (0.042476 --> 0.034002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0276802\n",
      "\tspeed: 0.0483s/iter; left time: 1060.7960s\n",
      "\titers: 200, epoch: 3 | loss: 0.0266256\n",
      "\tspeed: 0.0213s/iter; left time: 465.3776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 225 | Train Loss: 0.0274781 Vali Loss: 0.0334509 Test Loss: 0.0405938\n",
      "Validation loss decreased (0.034002 --> 0.033451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0282453\n",
      "\tspeed: 0.0470s/iter; left time: 1020.1148s\n",
      "\titers: 200, epoch: 4 | loss: 0.0259354\n",
      "\tspeed: 0.0198s/iter; left time: 427.5512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 225 | Train Loss: 0.0266396 Vali Loss: 0.0331835 Test Loss: 0.0402118\n",
      "Validation loss decreased (0.033451 --> 0.033183).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0275930\n",
      "\tspeed: 0.0499s/iter; left time: 1073.3855s\n",
      "\titers: 200, epoch: 5 | loss: 0.0242258\n",
      "\tspeed: 0.0199s/iter; left time: 425.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0261759 Vali Loss: 0.0331400 Test Loss: 0.0401583\n",
      "Validation loss decreased (0.033183 --> 0.033140).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0249907\n",
      "\tspeed: 0.0462s/iter; left time: 982.1340s\n",
      "\titers: 200, epoch: 6 | loss: 0.0265714\n",
      "\tspeed: 0.0209s/iter; left time: 442.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0258694 Vali Loss: 0.0327760 Test Loss: 0.0400483\n",
      "Validation loss decreased (0.033140 --> 0.032776).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0262237\n",
      "\tspeed: 0.0496s/iter; left time: 1044.8968s\n",
      "\titers: 200, epoch: 7 | loss: 0.0241183\n",
      "\tspeed: 0.0195s/iter; left time: 409.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0256120 Vali Loss: 0.0329920 Test Loss: 0.0398653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0235487\n",
      "\tspeed: 0.0476s/iter; left time: 990.3748s\n",
      "\titers: 200, epoch: 8 | loss: 0.0245051\n",
      "\tspeed: 0.0235s/iter; left time: 486.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 225 | Train Loss: 0.0254211 Vali Loss: 0.0331922 Test Loss: 0.0402371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0269264\n",
      "\tspeed: 0.0531s/iter; left time: 1094.1857s\n",
      "\titers: 200, epoch: 9 | loss: 0.0250130\n",
      "\tspeed: 0.0251s/iter; left time: 514.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 225 | Train Loss: 0.0252059 Vali Loss: 0.0330678 Test Loss: 0.0398848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0238565\n",
      "\tspeed: 0.0691s/iter; left time: 1408.9169s\n",
      "\titers: 200, epoch: 10 | loss: 0.0237731\n",
      "\tspeed: 0.0285s/iter; left time: 577.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 225 | Train Loss: 0.0250347 Vali Loss: 0.0327603 Test Loss: 0.0400813\n",
      "Validation loss decreased (0.032776 --> 0.032760).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0244635\n",
      "\tspeed: 0.0768s/iter; left time: 1547.0035s\n",
      "\titers: 200, epoch: 11 | loss: 0.0232718\n",
      "\tspeed: 0.0270s/iter; left time: 541.0004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0248838 Vali Loss: 0.0326611 Test Loss: 0.0401495\n",
      "Validation loss decreased (0.032760 --> 0.032661).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0247994\n",
      "\tspeed: 0.0771s/iter; left time: 1536.4119s\n",
      "\titers: 200, epoch: 12 | loss: 0.0246821\n",
      "\tspeed: 0.0276s/iter; left time: 546.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 225 | Train Loss: 0.0247419 Vali Loss: 0.0327078 Test Loss: 0.0401618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0239694\n",
      "\tspeed: 0.0842s/iter; left time: 1659.3024s\n",
      "\titers: 200, epoch: 13 | loss: 0.0218429\n",
      "\tspeed: 0.0284s/iter; left time: 557.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 225 | Train Loss: 0.0246602 Vali Loss: 0.0327330 Test Loss: 0.0401319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0255009\n",
      "\tspeed: 0.0678s/iter; left time: 1319.6675s\n",
      "\titers: 200, epoch: 14 | loss: 0.0252126\n",
      "\tspeed: 0.0275s/iter; left time: 533.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 225 | Train Loss: 0.0245515 Vali Loss: 0.0327835 Test Loss: 0.0401811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0236850\n",
      "\tspeed: 0.0792s/iter; left time: 1525.1057s\n",
      "\titers: 200, epoch: 15 | loss: 0.0246431\n",
      "\tspeed: 0.0250s/iter; left time: 478.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0244478 Vali Loss: 0.0326965 Test Loss: 0.0404440\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0271170\n",
      "\tspeed: 0.0718s/iter; left time: 1366.7172s\n",
      "\titers: 200, epoch: 16 | loss: 0.0265224\n",
      "\tspeed: 0.0339s/iter; left time: 640.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 225 | Train Loss: 0.0243604 Vali Loss: 0.0327115 Test Loss: 0.0401209\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0254853\n",
      "\tspeed: 0.0750s/iter; left time: 1410.3246s\n",
      "\titers: 200, epoch: 17 | loss: 0.0264738\n",
      "\tspeed: 0.0269s/iter; left time: 503.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0242914 Vali Loss: 0.0326806 Test Loss: 0.0404772\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0232780\n",
      "\tspeed: 0.0693s/iter; left time: 1287.6609s\n",
      "\titers: 200, epoch: 18 | loss: 0.0237292\n",
      "\tspeed: 0.0306s/iter; left time: 564.5865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 225 | Train Loss: 0.0242091 Vali Loss: 0.0327785 Test Loss: 0.0405320\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0236547\n",
      "\tspeed: 0.0724s/iter; left time: 1328.5391s\n",
      "\titers: 200, epoch: 19 | loss: 0.0253258\n",
      "\tspeed: 0.0304s/iter; left time: 554.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 225 | Train Loss: 0.0241632 Vali Loss: 0.0326887 Test Loss: 0.0406219\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0250084\n",
      "\tspeed: 0.0884s/iter; left time: 1602.4261s\n",
      "\titers: 200, epoch: 20 | loss: 0.0265045\n",
      "\tspeed: 0.0322s/iter; left time: 581.2436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 225 | Train Loss: 0.0241166 Vali Loss: 0.0326053 Test Loss: 0.0405097\n",
      "Validation loss decreased (0.032661 --> 0.032605).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0238479\n",
      "\tspeed: 0.0786s/iter; left time: 1406.8111s\n",
      "\titers: 200, epoch: 21 | loss: 0.0227442\n",
      "\tspeed: 0.0281s/iter; left time: 499.5196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0240373 Vali Loss: 0.0325985 Test Loss: 0.0406184\n",
      "Validation loss decreased (0.032605 --> 0.032598).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0242475\n",
      "\tspeed: 0.0833s/iter; left time: 1473.0018s\n",
      "\titers: 200, epoch: 22 | loss: 0.0240004\n",
      "\tspeed: 0.0474s/iter; left time: 833.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.32s\n",
      "Steps: 225 | Train Loss: 0.0240255 Vali Loss: 0.0326136 Test Loss: 0.0406383\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0233491\n",
      "\tspeed: 0.1110s/iter; left time: 1937.1116s\n",
      "\titers: 200, epoch: 23 | loss: 0.0215407\n",
      "\tspeed: 0.0453s/iter; left time: 786.4895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:10.40s\n",
      "Steps: 225 | Train Loss: 0.0239283 Vali Loss: 0.0326419 Test Loss: 0.0406990\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0229299\n",
      "\tspeed: 0.1253s/iter; left time: 2158.4732s\n",
      "\titers: 200, epoch: 24 | loss: 0.0237968\n",
      "\tspeed: 0.0419s/iter; left time: 718.1554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 225 | Train Loss: 0.0239189 Vali Loss: 0.0327209 Test Loss: 0.0407308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0228200\n",
      "\tspeed: 0.1314s/iter; left time: 2233.7386s\n",
      "\titers: 200, epoch: 25 | loss: 0.0248429\n",
      "\tspeed: 0.0401s/iter; left time: 678.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.0238833 Vali Loss: 0.0326425 Test Loss: 0.0406959\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0235288\n",
      "\tspeed: 0.1557s/iter; left time: 2612.2294s\n",
      "\titers: 200, epoch: 26 | loss: 0.0227188\n",
      "\tspeed: 0.0514s/iter; left time: 857.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:13.29s\n",
      "Steps: 225 | Train Loss: 0.0238446 Vali Loss: 0.0327189 Test Loss: 0.0407183\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0231323\n",
      "\tspeed: 0.1150s/iter; left time: 1903.1002s\n",
      "\titers: 200, epoch: 27 | loss: 0.0251811\n",
      "\tspeed: 0.0458s/iter; left time: 753.6024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:10.71s\n",
      "Steps: 225 | Train Loss: 0.0238494 Vali Loss: 0.0326425 Test Loss: 0.0406725\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0233792\n",
      "\tspeed: 0.1166s/iter; left time: 1903.0459s\n",
      "\titers: 200, epoch: 28 | loss: 0.0243124\n",
      "\tspeed: 0.0429s/iter; left time: 696.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 225 | Train Loss: 0.0238004 Vali Loss: 0.0327135 Test Loss: 0.0407996\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0253402\n",
      "\tspeed: 0.1110s/iter; left time: 1786.6988s\n",
      "\titers: 200, epoch: 29 | loss: 0.0235787\n",
      "\tspeed: 0.0437s/iter; left time: 698.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 225 | Train Loss: 0.0237641 Vali Loss: 0.0326271 Test Loss: 0.0408671\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0221469\n",
      "\tspeed: 0.1325s/iter; left time: 2103.2824s\n",
      "\titers: 200, epoch: 30 | loss: 0.0262810\n",
      "\tspeed: 0.0643s/iter; left time: 1013.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:14.16s\n",
      "Steps: 225 | Train Loss: 0.0237545 Vali Loss: 0.0326350 Test Loss: 0.0408822\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0240579\n",
      "\tspeed: 0.1174s/iter; left time: 1838.1702s\n",
      "\titers: 200, epoch: 31 | loss: 0.0251211\n",
      "\tspeed: 0.0414s/iter; left time: 643.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:10.38s\n",
      "Steps: 225 | Train Loss: 0.0237316 Vali Loss: 0.0327280 Test Loss: 0.0408680\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0406184159219265, rmse:0.20154011249542236, mae:0.13821378350257874, rse:0.7138713002204895\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:06.96s\n",
      "Intermediate time for DE: 00h:12m:51.73s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0306815\n",
      "\tspeed: 0.0681s/iter; left time: 1532.5494s\n",
      "\titers: 200, epoch: 1 | loss: 0.0266523\n",
      "\tspeed: 0.0423s/iter; left time: 946.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 226 | Train Loss: 0.0323873 Vali Loss: 0.0310920 Test Loss: 0.0430876\n",
      "Validation loss decreased (inf --> 0.031092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0153087\n",
      "\tspeed: 0.1056s/iter; left time: 2352.3071s\n",
      "\titers: 200, epoch: 2 | loss: 0.0142865\n",
      "\tspeed: 0.0512s/iter; left time: 1135.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 226 | Train Loss: 0.0165819 Vali Loss: 0.0204234 Test Loss: 0.0264011\n",
      "Validation loss decreased (0.031092 --> 0.020423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0170686\n",
      "\tspeed: 0.1340s/iter; left time: 2954.9373s\n",
      "\titers: 200, epoch: 3 | loss: 0.0158198\n",
      "\tspeed: 0.0500s/iter; left time: 1098.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.71s\n",
      "Steps: 226 | Train Loss: 0.0145620 Vali Loss: 0.0201542 Test Loss: 0.0261200\n",
      "Validation loss decreased (0.020423 --> 0.020154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0144440\n",
      "\tspeed: 0.1015s/iter; left time: 2214.5517s\n",
      "\titers: 200, epoch: 4 | loss: 0.0145676\n",
      "\tspeed: 0.0391s/iter; left time: 849.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 226 | Train Loss: 0.0141880 Vali Loss: 0.0201375 Test Loss: 0.0256896\n",
      "Validation loss decreased (0.020154 --> 0.020138).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0139161\n",
      "\tspeed: 0.1047s/iter; left time: 2260.4077s\n",
      "\titers: 200, epoch: 5 | loss: 0.0156245\n",
      "\tspeed: 0.0447s/iter; left time: 960.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.77s\n",
      "Steps: 226 | Train Loss: 0.0139841 Vali Loss: 0.0199274 Test Loss: 0.0255548\n",
      "Validation loss decreased (0.020138 --> 0.019927).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0134839\n",
      "\tspeed: 0.0952s/iter; left time: 2034.9297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130852\n",
      "\tspeed: 0.0457s/iter; left time: 971.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 226 | Train Loss: 0.0138393 Vali Loss: 0.0195793 Test Loss: 0.0252798\n",
      "Validation loss decreased (0.019927 --> 0.019579).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0130190\n",
      "\tspeed: 0.1178s/iter; left time: 2491.4614s\n",
      "\titers: 200, epoch: 7 | loss: 0.0126406\n",
      "\tspeed: 0.0563s/iter; left time: 1184.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.02s\n",
      "Steps: 226 | Train Loss: 0.0137379 Vali Loss: 0.0195426 Test Loss: 0.0252673\n",
      "Validation loss decreased (0.019579 --> 0.019543).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0126214\n",
      "\tspeed: 0.1138s/iter; left time: 2380.7048s\n",
      "\titers: 200, epoch: 8 | loss: 0.0131759\n",
      "\tspeed: 0.0461s/iter; left time: 960.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 226 | Train Loss: 0.0136468 Vali Loss: 0.0195262 Test Loss: 0.0252110\n",
      "Validation loss decreased (0.019543 --> 0.019526).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0142638\n",
      "\tspeed: 0.0991s/iter; left time: 2050.6731s\n",
      "\titers: 200, epoch: 9 | loss: 0.0131716\n",
      "\tspeed: 0.0427s/iter; left time: 879.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 226 | Train Loss: 0.0135563 Vali Loss: 0.0193729 Test Loss: 0.0252877\n",
      "Validation loss decreased (0.019526 --> 0.019373).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0127078\n",
      "\tspeed: 0.0971s/iter; left time: 1986.3346s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139840\n",
      "\tspeed: 0.0447s/iter; left time: 910.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 226 | Train Loss: 0.0134777 Vali Loss: 0.0194025 Test Loss: 0.0252130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0161274\n",
      "\tspeed: 0.0958s/iter; left time: 1938.3375s\n",
      "\titers: 200, epoch: 11 | loss: 0.0138039\n",
      "\tspeed: 0.0550s/iter; left time: 1107.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 226 | Train Loss: 0.0134166 Vali Loss: 0.0192794 Test Loss: 0.0250856\n",
      "Validation loss decreased (0.019373 --> 0.019279).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0121306\n",
      "\tspeed: 0.1345s/iter; left time: 2691.7819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0160302\n",
      "\tspeed: 0.0399s/iter; left time: 794.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 226 | Train Loss: 0.0133569 Vali Loss: 0.0192511 Test Loss: 0.0251192\n",
      "Validation loss decreased (0.019279 --> 0.019251).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0113891\n",
      "\tspeed: 0.1013s/iter; left time: 2005.0537s\n",
      "\titers: 200, epoch: 13 | loss: 0.0132807\n",
      "\tspeed: 0.0383s/iter; left time: 753.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.07s\n",
      "Steps: 226 | Train Loss: 0.0133088 Vali Loss: 0.0192478 Test Loss: 0.0251219\n",
      "Validation loss decreased (0.019251 --> 0.019248).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0134227\n",
      "\tspeed: 0.0917s/iter; left time: 1793.1355s\n",
      "\titers: 200, epoch: 14 | loss: 0.0130552\n",
      "\tspeed: 0.0476s/iter; left time: 927.2188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 226 | Train Loss: 0.0132481 Vali Loss: 0.0193488 Test Loss: 0.0250907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0139046\n",
      "\tspeed: 0.1020s/iter; left time: 1971.9664s\n",
      "\titers: 200, epoch: 15 | loss: 0.0139125\n",
      "\tspeed: 0.0410s/iter; left time: 789.0880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 226 | Train Loss: 0.0132269 Vali Loss: 0.0191523 Test Loss: 0.0251043\n",
      "Validation loss decreased (0.019248 --> 0.019152).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0133044\n",
      "\tspeed: 0.1234s/iter; left time: 2357.4765s\n",
      "\titers: 200, epoch: 16 | loss: 0.0134255\n",
      "\tspeed: 0.0614s/iter; left time: 1167.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.21s\n",
      "Steps: 226 | Train Loss: 0.0131907 Vali Loss: 0.0191569 Test Loss: 0.0251692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0126479\n",
      "\tspeed: 0.0948s/iter; left time: 1789.6101s\n",
      "\titers: 200, epoch: 17 | loss: 0.0132790\n",
      "\tspeed: 0.0392s/iter; left time: 737.2248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 226 | Train Loss: 0.0131559 Vali Loss: 0.0192524 Test Loss: 0.0252377\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0124893\n",
      "\tspeed: 0.0968s/iter; left time: 1805.6232s\n",
      "\titers: 200, epoch: 18 | loss: 0.0135506\n",
      "\tspeed: 0.0469s/iter; left time: 870.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.91s\n",
      "Steps: 226 | Train Loss: 0.0131313 Vali Loss: 0.0191961 Test Loss: 0.0251142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0135661\n",
      "\tspeed: 0.0941s/iter; left time: 1734.4131s\n",
      "\titers: 200, epoch: 19 | loss: 0.0137399\n",
      "\tspeed: 0.0438s/iter; left time: 803.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.09s\n",
      "Steps: 226 | Train Loss: 0.0130996 Vali Loss: 0.0191331 Test Loss: 0.0251709\n",
      "Validation loss decreased (0.019152 --> 0.019133).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0151006\n",
      "\tspeed: 0.1026s/iter; left time: 1867.9672s\n",
      "\titers: 200, epoch: 20 | loss: 0.0137961\n",
      "\tspeed: 0.0575s/iter; left time: 1041.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 226 | Train Loss: 0.0130854 Vali Loss: 0.0191960 Test Loss: 0.0250267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0132778\n",
      "\tspeed: 0.1176s/iter; left time: 2114.1918s\n",
      "\titers: 200, epoch: 21 | loss: 0.0140660\n",
      "\tspeed: 0.0434s/iter; left time: 776.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 226 | Train Loss: 0.0130569 Vali Loss: 0.0192014 Test Loss: 0.0251986\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0109714\n",
      "\tspeed: 0.0987s/iter; left time: 1753.1350s\n",
      "\titers: 200, epoch: 22 | loss: 0.0144550\n",
      "\tspeed: 0.0396s/iter; left time: 698.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 226 | Train Loss: 0.0130485 Vali Loss: 0.0191108 Test Loss: 0.0251565\n",
      "Validation loss decreased (0.019133 --> 0.019111).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0115084\n",
      "\tspeed: 0.1004s/iter; left time: 1760.5756s\n",
      "\titers: 200, epoch: 23 | loss: 0.0116755\n",
      "\tspeed: 0.0515s/iter; left time: 898.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.12s\n",
      "Steps: 226 | Train Loss: 0.0129933 Vali Loss: 0.0190995 Test Loss: 0.0251609\n",
      "Validation loss decreased (0.019111 --> 0.019099).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0130449\n",
      "\tspeed: 0.0924s/iter; left time: 1599.3736s\n",
      "\titers: 200, epoch: 24 | loss: 0.0129596\n",
      "\tspeed: 0.0521s/iter; left time: 896.8435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.54s\n",
      "Steps: 226 | Train Loss: 0.0129977 Vali Loss: 0.0191031 Test Loss: 0.0252141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0124596\n",
      "\tspeed: 0.1359s/iter; left time: 2321.4060s\n",
      "\titers: 200, epoch: 25 | loss: 0.0103465\n",
      "\tspeed: 0.0510s/iter; left time: 865.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:12.36s\n",
      "Steps: 226 | Train Loss: 0.0129898 Vali Loss: 0.0190852 Test Loss: 0.0251680\n",
      "Validation loss decreased (0.019099 --> 0.019085).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0146096\n",
      "\tspeed: 0.0786s/iter; left time: 1325.1361s\n",
      "\titers: 200, epoch: 26 | loss: 0.0114260\n",
      "\tspeed: 0.0303s/iter; left time: 507.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 226 | Train Loss: 0.0129762 Vali Loss: 0.0191453 Test Loss: 0.0251956\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0148471\n",
      "\tspeed: 0.0625s/iter; left time: 1039.4186s\n",
      "\titers: 200, epoch: 27 | loss: 0.0142760\n",
      "\tspeed: 0.0299s/iter; left time: 494.3536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 226 | Train Loss: 0.0129704 Vali Loss: 0.0190854 Test Loss: 0.0251721\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0120537\n",
      "\tspeed: 0.0607s/iter; left time: 995.3985s\n",
      "\titers: 200, epoch: 28 | loss: 0.0137661\n",
      "\tspeed: 0.0343s/iter; left time: 559.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 226 | Train Loss: 0.0129575 Vali Loss: 0.0190943 Test Loss: 0.0251400\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0132743\n",
      "\tspeed: 0.0585s/iter; left time: 946.4002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0129417\n",
      "\tspeed: 0.0220s/iter; left time: 353.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 226 | Train Loss: 0.0129509 Vali Loss: 0.0191139 Test Loss: 0.0251515\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0116974\n",
      "\tspeed: 0.0734s/iter; left time: 1170.7012s\n",
      "\titers: 200, epoch: 30 | loss: 0.0134378\n",
      "\tspeed: 0.0296s/iter; left time: 469.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 226 | Train Loss: 0.0129296 Vali Loss: 0.0191253 Test Loss: 0.0252005\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0125019\n",
      "\tspeed: 0.0731s/iter; left time: 1149.3511s\n",
      "\titers: 200, epoch: 31 | loss: 0.0145108\n",
      "\tspeed: 0.0440s/iter; left time: 687.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 226 | Train Loss: 0.0129281 Vali Loss: 0.0191124 Test Loss: 0.0251992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0113440\n",
      "\tspeed: 0.0676s/iter; left time: 1048.1478s\n",
      "\titers: 200, epoch: 32 | loss: 0.0121925\n",
      "\tspeed: 0.0273s/iter; left time: 420.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0129249 Vali Loss: 0.0191041 Test Loss: 0.0251873\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0128363\n",
      "\tspeed: 0.0857s/iter; left time: 1309.2490s\n",
      "\titers: 200, epoch: 33 | loss: 0.0128919\n",
      "\tspeed: 0.0379s/iter; left time: 574.7631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 226 | Train Loss: 0.0129289 Vali Loss: 0.0190764 Test Loss: 0.0251854\n",
      "Validation loss decreased (0.019085 --> 0.019076).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0115401\n",
      "\tspeed: 0.0747s/iter; left time: 1123.5613s\n",
      "\titers: 200, epoch: 34 | loss: 0.0133728\n",
      "\tspeed: 0.0289s/iter; left time: 432.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0129210 Vali Loss: 0.0190594 Test Loss: 0.0251820\n",
      "Validation loss decreased (0.019076 --> 0.019059).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0132487\n",
      "\tspeed: 0.0829s/iter; left time: 1227.9971s\n",
      "\titers: 200, epoch: 35 | loss: 0.0136201\n",
      "\tspeed: 0.0287s/iter; left time: 421.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 226 | Train Loss: 0.0129160 Vali Loss: 0.0190945 Test Loss: 0.0251921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0129037\n",
      "\tspeed: 0.0651s/iter; left time: 949.3845s\n",
      "\titers: 200, epoch: 36 | loss: 0.0127028\n",
      "\tspeed: 0.0250s/iter; left time: 362.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 226 | Train Loss: 0.0129073 Vali Loss: 0.0190527 Test Loss: 0.0252187\n",
      "Validation loss decreased (0.019059 --> 0.019053).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0122460\n",
      "\tspeed: 0.0930s/iter; left time: 1335.6076s\n",
      "\titers: 200, epoch: 37 | loss: 0.0127358\n",
      "\tspeed: 0.0276s/iter; left time: 393.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 226 | Train Loss: 0.0128986 Vali Loss: 0.0190852 Test Loss: 0.0251907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0129839\n",
      "\tspeed: 0.0619s/iter; left time: 875.1020s\n",
      "\titers: 200, epoch: 38 | loss: 0.0129735\n",
      "\tspeed: 0.0255s/iter; left time: 358.6629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0128992 Vali Loss: 0.0190683 Test Loss: 0.0251875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0111598\n",
      "\tspeed: 0.0940s/iter; left time: 1307.5915s\n",
      "\titers: 200, epoch: 39 | loss: 0.0126943\n",
      "\tspeed: 0.0273s/iter; left time: 377.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 226 | Train Loss: 0.0128922 Vali Loss: 0.0191263 Test Loss: 0.0252117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0118141\n",
      "\tspeed: 0.0635s/iter; left time: 869.0862s\n",
      "\titers: 200, epoch: 40 | loss: 0.0135553\n",
      "\tspeed: 0.0310s/iter; left time: 421.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0128836 Vali Loss: 0.0190870 Test Loss: 0.0252051\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0121245\n",
      "\tspeed: 0.0895s/iter; left time: 1204.1751s\n",
      "\titers: 200, epoch: 41 | loss: 0.0123877\n",
      "\tspeed: 0.0282s/iter; left time: 377.3275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.0128702 Vali Loss: 0.0190757 Test Loss: 0.0252135\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0133441\n",
      "\tspeed: 0.0663s/iter; left time: 877.9292s\n",
      "\titers: 200, epoch: 42 | loss: 0.0115185\n",
      "\tspeed: 0.0244s/iter; left time: 320.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0128975 Vali Loss: 0.0190773 Test Loss: 0.0251964\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0139865\n",
      "\tspeed: 0.0925s/iter; left time: 1203.5689s\n",
      "\titers: 200, epoch: 43 | loss: 0.0128980\n",
      "\tspeed: 0.0291s/iter; left time: 375.6127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 226 | Train Loss: 0.0128922 Vali Loss: 0.0190738 Test Loss: 0.0251991\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0123033\n",
      "\tspeed: 0.0670s/iter; left time: 856.5725s\n",
      "\titers: 200, epoch: 44 | loss: 0.0136023\n",
      "\tspeed: 0.0352s/iter; left time: 446.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 226 | Train Loss: 0.0128689 Vali Loss: 0.0191055 Test Loss: 0.0252051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0129680\n",
      "\tspeed: 0.0867s/iter; left time: 1089.1394s\n",
      "\titers: 200, epoch: 45 | loss: 0.0121593\n",
      "\tspeed: 0.0256s/iter; left time: 318.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0128768 Vali Loss: 0.0191128 Test Loss: 0.0252108\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0136561\n",
      "\tspeed: 0.0652s/iter; left time: 804.3159s\n",
      "\titers: 200, epoch: 46 | loss: 0.0120851\n",
      "\tspeed: 0.0356s/iter; left time: 436.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 226 | Train Loss: 0.0128930 Vali Loss: 0.0190865 Test Loss: 0.0252188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02521873079240322, rmse:0.1588040590286255, mae:0.10287422686815262, rse:0.5478290319442749\n",
      "Intermediate time for GB and pred_len 24: 00h:10m:12.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0354775\n",
      "\tspeed: 0.0686s/iter; left time: 1537.7750s\n",
      "\titers: 200, epoch: 1 | loss: 0.0330818\n",
      "\tspeed: 0.0267s/iter; left time: 595.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 225 | Train Loss: 0.0363572 Vali Loss: 0.0369944 Test Loss: 0.0533514\n",
      "Validation loss decreased (inf --> 0.036994).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0240189\n",
      "\tspeed: 0.0687s/iter; left time: 1522.9947s\n",
      "\titers: 200, epoch: 2 | loss: 0.0249086\n",
      "\tspeed: 0.0230s/iter; left time: 507.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0249381 Vali Loss: 0.0303441 Test Loss: 0.0435347\n",
      "Validation loss decreased (0.036994 --> 0.030344).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0232706\n",
      "\tspeed: 0.0965s/iter; left time: 2118.9901s\n",
      "\titers: 200, epoch: 3 | loss: 0.0220721\n",
      "\tspeed: 0.0259s/iter; left time: 566.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 225 | Train Loss: 0.0230414 Vali Loss: 0.0300716 Test Loss: 0.0431415\n",
      "Validation loss decreased (0.030344 --> 0.030072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0217916\n",
      "\tspeed: 0.0679s/iter; left time: 1475.3727s\n",
      "\titers: 200, epoch: 4 | loss: 0.0222335\n",
      "\tspeed: 0.0246s/iter; left time: 531.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 225 | Train Loss: 0.0226242 Vali Loss: 0.0299814 Test Loss: 0.0439132\n",
      "Validation loss decreased (0.030072 --> 0.029981).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0231342\n",
      "\tspeed: 0.0942s/iter; left time: 2026.1295s\n",
      "\titers: 200, epoch: 5 | loss: 0.0215362\n",
      "\tspeed: 0.0238s/iter; left time: 508.9080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 225 | Train Loss: 0.0223468 Vali Loss: 0.0297319 Test Loss: 0.0439771\n",
      "Validation loss decreased (0.029981 --> 0.029732).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0237017\n",
      "\tspeed: 0.0668s/iter; left time: 1421.6003s\n",
      "\titers: 200, epoch: 6 | loss: 0.0222148\n",
      "\tspeed: 0.0246s/iter; left time: 521.7184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 225 | Train Loss: 0.0221197 Vali Loss: 0.0296820 Test Loss: 0.0441826\n",
      "Validation loss decreased (0.029732 --> 0.029682).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0203015\n",
      "\tspeed: 0.0928s/iter; left time: 1954.4820s\n",
      "\titers: 200, epoch: 7 | loss: 0.0225045\n",
      "\tspeed: 0.0318s/iter; left time: 665.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 225 | Train Loss: 0.0219527 Vali Loss: 0.0296131 Test Loss: 0.0441187\n",
      "Validation loss decreased (0.029682 --> 0.029613).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0205286\n",
      "\tspeed: 0.0717s/iter; left time: 1492.2687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0234542\n",
      "\tspeed: 0.0284s/iter; left time: 588.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0218284 Vali Loss: 0.0296417 Test Loss: 0.0449920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0223067\n",
      "\tspeed: 0.0972s/iter; left time: 2002.5576s\n",
      "\titers: 200, epoch: 9 | loss: 0.0220027\n",
      "\tspeed: 0.0262s/iter; left time: 536.1908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 225 | Train Loss: 0.0217147 Vali Loss: 0.0295708 Test Loss: 0.0446208\n",
      "Validation loss decreased (0.029613 --> 0.029571).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0218705\n",
      "\tspeed: 0.0752s/iter; left time: 1532.2417s\n",
      "\titers: 200, epoch: 10 | loss: 0.0221990\n",
      "\tspeed: 0.0290s/iter; left time: 587.0119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0215910 Vali Loss: 0.0298560 Test Loss: 0.0454434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0200138\n",
      "\tspeed: 0.0936s/iter; left time: 1886.5657s\n",
      "\titers: 200, epoch: 11 | loss: 0.0235559\n",
      "\tspeed: 0.0270s/iter; left time: 542.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 225 | Train Loss: 0.0214932 Vali Loss: 0.0295766 Test Loss: 0.0446929\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0203710\n",
      "\tspeed: 0.0709s/iter; left time: 1412.6928s\n",
      "\titers: 200, epoch: 12 | loss: 0.0218972\n",
      "\tspeed: 0.0219s/iter; left time: 433.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 225 | Train Loss: 0.0214143 Vali Loss: 0.0297747 Test Loss: 0.0450747\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0206936\n",
      "\tspeed: 0.0502s/iter; left time: 989.9310s\n",
      "\titers: 200, epoch: 13 | loss: 0.0215404\n",
      "\tspeed: 0.0265s/iter; left time: 520.3283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 225 | Train Loss: 0.0213293 Vali Loss: 0.0299438 Test Loss: 0.0450182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0214430\n",
      "\tspeed: 0.0658s/iter; left time: 1281.0194s\n",
      "\titers: 200, epoch: 14 | loss: 0.0220037\n",
      "\tspeed: 0.0329s/iter; left time: 637.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 225 | Train Loss: 0.0212775 Vali Loss: 0.0300351 Test Loss: 0.0455550\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0208235\n",
      "\tspeed: 0.1150s/iter; left time: 2214.7338s\n",
      "\titers: 200, epoch: 15 | loss: 0.0200474\n",
      "\tspeed: 0.0219s/iter; left time: 419.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 225 | Train Loss: 0.0211910 Vali Loss: 0.0299286 Test Loss: 0.0452272\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0191070\n",
      "\tspeed: 0.0546s/iter; left time: 1039.2616s\n",
      "\titers: 200, epoch: 16 | loss: 0.0219055\n",
      "\tspeed: 0.0220s/iter; left time: 416.4554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0211475 Vali Loss: 0.0298784 Test Loss: 0.0450351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0200941\n",
      "\tspeed: 0.0658s/iter; left time: 1237.6131s\n",
      "\titers: 200, epoch: 17 | loss: 0.0211507\n",
      "\tspeed: 0.0361s/iter; left time: 675.0819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 225 | Train Loss: 0.0210881 Vali Loss: 0.0300969 Test Loss: 0.0456566\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0223482\n",
      "\tspeed: 0.0953s/iter; left time: 1770.0382s\n",
      "\titers: 200, epoch: 18 | loss: 0.0198237\n",
      "\tspeed: 0.0341s/iter; left time: 629.4172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.99s\n",
      "Steps: 225 | Train Loss: 0.0210304 Vali Loss: 0.0299435 Test Loss: 0.0452439\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0211381\n",
      "\tspeed: 0.0916s/iter; left time: 1681.6391s\n",
      "\titers: 200, epoch: 19 | loss: 0.0200907\n",
      "\tspeed: 0.0294s/iter; left time: 535.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 225 | Train Loss: 0.0209759 Vali Loss: 0.0300613 Test Loss: 0.0456903\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0446208193898201, rmse:0.2112364023923874, mae:0.14619070291519165, rse:0.7304849028587341\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:38.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0390243\n",
      "\tspeed: 0.0472s/iter; left time: 1057.3378s\n",
      "\titers: 200, epoch: 1 | loss: 0.0298407\n",
      "\tspeed: 0.0390s/iter; left time: 870.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 225 | Train Loss: 0.0378106 Vali Loss: 0.0389916 Test Loss: 0.0558763\n",
      "Validation loss decreased (inf --> 0.038992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0256391\n",
      "\tspeed: 0.1145s/iter; left time: 2540.2143s\n",
      "\titers: 200, epoch: 2 | loss: 0.0244381\n",
      "\tspeed: 0.0264s/iter; left time: 583.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 225 | Train Loss: 0.0269063 Vali Loss: 0.0326266 Test Loss: 0.0464468\n",
      "Validation loss decreased (0.038992 --> 0.032627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0238225\n",
      "\tspeed: 0.0938s/iter; left time: 2058.0264s\n",
      "\titers: 200, epoch: 3 | loss: 0.0257555\n",
      "\tspeed: 0.0484s/iter; left time: 1056.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.17s\n",
      "Steps: 225 | Train Loss: 0.0248508 Vali Loss: 0.0326770 Test Loss: 0.0472591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0263294\n",
      "\tspeed: 0.0825s/iter; left time: 1792.8509s\n",
      "\titers: 200, epoch: 4 | loss: 0.0246007\n",
      "\tspeed: 0.0388s/iter; left time: 838.5596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.92s\n",
      "Steps: 225 | Train Loss: 0.0244757 Vali Loss: 0.0326091 Test Loss: 0.0475681\n",
      "Validation loss decreased (0.032627 --> 0.032609).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0237154\n",
      "\tspeed: 0.0802s/iter; left time: 1723.6471s\n",
      "\titers: 200, epoch: 5 | loss: 0.0240872\n",
      "\tspeed: 0.0502s/iter; left time: 1073.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.67s\n",
      "Steps: 225 | Train Loss: 0.0241992 Vali Loss: 0.0324431 Test Loss: 0.0476243\n",
      "Validation loss decreased (0.032609 --> 0.032443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0234693\n",
      "\tspeed: 0.0744s/iter; left time: 1582.3650s\n",
      "\titers: 200, epoch: 6 | loss: 0.0254878\n",
      "\tspeed: 0.0304s/iter; left time: 643.9315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0239851 Vali Loss: 0.0322094 Test Loss: 0.0475896\n",
      "Validation loss decreased (0.032443 --> 0.032209).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0246653\n",
      "\tspeed: 0.1300s/iter; left time: 2736.5306s\n",
      "\titers: 200, epoch: 7 | loss: 0.0230549\n",
      "\tspeed: 0.0268s/iter; left time: 560.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 225 | Train Loss: 0.0238235 Vali Loss: 0.0325111 Test Loss: 0.0482226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0213825\n",
      "\tspeed: 0.0816s/iter; left time: 1699.7433s\n",
      "\titers: 200, epoch: 8 | loss: 0.0244884\n",
      "\tspeed: 0.0459s/iter; left time: 952.1830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 225 | Train Loss: 0.0236538 Vali Loss: 0.0322481 Test Loss: 0.0477532\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0229579\n",
      "\tspeed: 0.0895s/iter; left time: 1844.4827s\n",
      "\titers: 200, epoch: 9 | loss: 0.0238026\n",
      "\tspeed: 0.0478s/iter; left time: 980.1436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 225 | Train Loss: 0.0235430 Vali Loss: 0.0323157 Test Loss: 0.0479474\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0232745\n",
      "\tspeed: 0.0847s/iter; left time: 1725.6330s\n",
      "\titers: 200, epoch: 10 | loss: 0.0231921\n",
      "\tspeed: 0.0435s/iter; left time: 881.2897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.0234294 Vali Loss: 0.0321824 Test Loss: 0.0477643\n",
      "Validation loss decreased (0.032209 --> 0.032182).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0238903\n",
      "\tspeed: 0.0957s/iter; left time: 1927.6426s\n",
      "\titers: 200, epoch: 11 | loss: 0.0227449\n",
      "\tspeed: 0.0348s/iter; left time: 697.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 225 | Train Loss: 0.0233082 Vali Loss: 0.0324118 Test Loss: 0.0482034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0227333\n",
      "\tspeed: 0.1300s/iter; left time: 2589.4023s\n",
      "\titers: 200, epoch: 12 | loss: 0.0233488\n",
      "\tspeed: 0.0328s/iter; left time: 649.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 225 | Train Loss: 0.0232158 Vali Loss: 0.0323680 Test Loss: 0.0480370\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0221179\n",
      "\tspeed: 0.0814s/iter; left time: 1604.5093s\n",
      "\titers: 200, epoch: 13 | loss: 0.0217740\n",
      "\tspeed: 0.0567s/iter; left time: 1110.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 225 | Train Loss: 0.0231166 Vali Loss: 0.0324860 Test Loss: 0.0483295\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0239112\n",
      "\tspeed: 0.0686s/iter; left time: 1336.9318s\n",
      "\titers: 200, epoch: 14 | loss: 0.0226446\n",
      "\tspeed: 0.0337s/iter; left time: 652.8516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 225 | Train Loss: 0.0230206 Vali Loss: 0.0327152 Test Loss: 0.0488690\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0224236\n",
      "\tspeed: 0.0834s/iter; left time: 1604.9443s\n",
      "\titers: 200, epoch: 15 | loss: 0.0222827\n",
      "\tspeed: 0.0227s/iter; left time: 434.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0229603 Vali Loss: 0.0326154 Test Loss: 0.0486470\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0238628\n",
      "\tspeed: 0.0495s/iter; left time: 942.7203s\n",
      "\titers: 200, epoch: 16 | loss: 0.0237833\n",
      "\tspeed: 0.0212s/iter; left time: 400.9043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 225 | Train Loss: 0.0228710 Vali Loss: 0.0326586 Test Loss: 0.0487534\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0247075\n",
      "\tspeed: 0.0836s/iter; left time: 1570.8369s\n",
      "\titers: 200, epoch: 17 | loss: 0.0234942\n",
      "\tspeed: 0.0478s/iter; left time: 893.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 225 | Train Loss: 0.0228217 Vali Loss: 0.0326492 Test Loss: 0.0486032\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0229605\n",
      "\tspeed: 0.1296s/iter; left time: 2407.8405s\n",
      "\titers: 200, epoch: 18 | loss: 0.0239278\n",
      "\tspeed: 0.0473s/iter; left time: 873.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 225 | Train Loss: 0.0227531 Vali Loss: 0.0326073 Test Loss: 0.0483531\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0222851\n",
      "\tspeed: 0.1721s/iter; left time: 3158.0260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0235539\n",
      "\tspeed: 0.0485s/iter; left time: 886.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 225 | Train Loss: 0.0227298 Vali Loss: 0.0328842 Test Loss: 0.0493051\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0239972\n",
      "\tspeed: 0.1419s/iter; left time: 2572.1804s\n",
      "\titers: 200, epoch: 20 | loss: 0.0237402\n",
      "\tspeed: 0.0644s/iter; left time: 1160.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 225 | Train Loss: 0.0226613 Vali Loss: 0.0329440 Test Loss: 0.0493550\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04776432737708092, rmse:0.21855051815509796, mae:0.1530516892671585, rse:0.7577460408210754\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:48.85s\n",
      "Intermediate time for GB: 00h:18m:39.98s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0344858\n",
      "\tspeed: 0.0586s/iter; left time: 1317.9860s\n",
      "\titers: 200, epoch: 1 | loss: 0.0248702\n",
      "\tspeed: 0.0331s/iter; left time: 742.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.0371519 Vali Loss: 0.0223229 Test Loss: 0.0300770\n",
      "Validation loss decreased (inf --> 0.022323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0126206\n",
      "\tspeed: 0.0825s/iter; left time: 1837.7030s\n",
      "\titers: 200, epoch: 2 | loss: 0.0100498\n",
      "\tspeed: 0.0363s/iter; left time: 805.0051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 226 | Train Loss: 0.0132151 Vali Loss: 0.0098500 Test Loss: 0.0125102\n",
      "Validation loss decreased (0.022323 --> 0.009850).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0103429\n",
      "\tspeed: 0.1038s/iter; left time: 2288.8369s\n",
      "\titers: 200, epoch: 3 | loss: 0.0100795\n",
      "\tspeed: 0.0363s/iter; left time: 796.5311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 226 | Train Loss: 0.0103717 Vali Loss: 0.0093203 Test Loss: 0.0118425\n",
      "Validation loss decreased (0.009850 --> 0.009320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0096413\n",
      "\tspeed: 0.0780s/iter; left time: 1702.4721s\n",
      "\titers: 200, epoch: 4 | loss: 0.0083005\n",
      "\tspeed: 0.0362s/iter; left time: 787.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 226 | Train Loss: 0.0097180 Vali Loss: 0.0089005 Test Loss: 0.0113179\n",
      "Validation loss decreased (0.009320 --> 0.008900).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0097897\n",
      "\tspeed: 0.1184s/iter; left time: 2556.5842s\n",
      "\titers: 200, epoch: 5 | loss: 0.0100584\n",
      "\tspeed: 0.0438s/iter; left time: 942.4198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.74s\n",
      "Steps: 226 | Train Loss: 0.0092799 Vali Loss: 0.0086677 Test Loss: 0.0109406\n",
      "Validation loss decreased (0.008900 --> 0.008668).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0089060\n",
      "\tspeed: 0.0910s/iter; left time: 1944.6028s\n",
      "\titers: 200, epoch: 6 | loss: 0.0081647\n",
      "\tspeed: 0.0494s/iter; left time: 1050.5381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 226 | Train Loss: 0.0089618 Vali Loss: 0.0084586 Test Loss: 0.0106541\n",
      "Validation loss decreased (0.008668 --> 0.008459).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0075015\n",
      "\tspeed: 0.0816s/iter; left time: 1724.9503s\n",
      "\titers: 200, epoch: 7 | loss: 0.0088196\n",
      "\tspeed: 0.0356s/iter; left time: 749.9036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 226 | Train Loss: 0.0087471 Vali Loss: 0.0083825 Test Loss: 0.0105173\n",
      "Validation loss decreased (0.008459 --> 0.008382).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0080909\n",
      "\tspeed: 0.0974s/iter; left time: 2036.4737s\n",
      "\titers: 200, epoch: 8 | loss: 0.0087270\n",
      "\tspeed: 0.0367s/iter; left time: 764.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 226 | Train Loss: 0.0085740 Vali Loss: 0.0082854 Test Loss: 0.0104146\n",
      "Validation loss decreased (0.008382 --> 0.008285).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0079280\n",
      "\tspeed: 0.0860s/iter; left time: 1778.7867s\n",
      "\titers: 200, epoch: 9 | loss: 0.0090820\n",
      "\tspeed: 0.0367s/iter; left time: 755.8939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 226 | Train Loss: 0.0084567 Vali Loss: 0.0082317 Test Loss: 0.0103206\n",
      "Validation loss decreased (0.008285 --> 0.008232).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0085438\n",
      "\tspeed: 0.0975s/iter; left time: 1995.1632s\n",
      "\titers: 200, epoch: 10 | loss: 0.0085556\n",
      "\tspeed: 0.0371s/iter; left time: 756.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 226 | Train Loss: 0.0083482 Vali Loss: 0.0081226 Test Loss: 0.0101976\n",
      "Validation loss decreased (0.008232 --> 0.008123).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0075712\n",
      "\tspeed: 0.1200s/iter; left time: 2428.1962s\n",
      "\titers: 200, epoch: 11 | loss: 0.0083323\n",
      "\tspeed: 0.0532s/iter; left time: 1071.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 226 | Train Loss: 0.0082553 Vali Loss: 0.0080851 Test Loss: 0.0101538\n",
      "Validation loss decreased (0.008123 --> 0.008085).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0083999\n",
      "\tspeed: 0.0765s/iter; left time: 1531.4764s\n",
      "\titers: 200, epoch: 12 | loss: 0.0088925\n",
      "\tspeed: 0.0375s/iter; left time: 747.2862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 226 | Train Loss: 0.0081682 Vali Loss: 0.0080263 Test Loss: 0.0100752\n",
      "Validation loss decreased (0.008085 --> 0.008026).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0076128\n",
      "\tspeed: 0.1027s/iter; left time: 2031.5328s\n",
      "\titers: 200, epoch: 13 | loss: 0.0087484\n",
      "\tspeed: 0.0342s/iter; left time: 672.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 226 | Train Loss: 0.0080892 Vali Loss: 0.0079926 Test Loss: 0.0100276\n",
      "Validation loss decreased (0.008026 --> 0.007993).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0075470\n",
      "\tspeed: 0.0834s/iter; left time: 1632.1813s\n",
      "\titers: 200, epoch: 14 | loss: 0.0081287\n",
      "\tspeed: 0.0356s/iter; left time: 692.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.18s\n",
      "Steps: 226 | Train Loss: 0.0080240 Vali Loss: 0.0079453 Test Loss: 0.0099897\n",
      "Validation loss decreased (0.007993 --> 0.007945).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0072469\n",
      "\tspeed: 0.1014s/iter; left time: 1961.2359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0084926\n",
      "\tspeed: 0.0315s/iter; left time: 605.9885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 226 | Train Loss: 0.0079678 Vali Loss: 0.0079108 Test Loss: 0.0099600\n",
      "Validation loss decreased (0.007945 --> 0.007911).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0075845\n",
      "\tspeed: 0.0880s/iter; left time: 1682.6505s\n",
      "\titers: 200, epoch: 16 | loss: 0.0070598\n",
      "\tspeed: 0.0599s/iter; left time: 1137.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0079283 Vali Loss: 0.0079144 Test Loss: 0.0099446\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0067384\n",
      "\tspeed: 0.1023s/iter; left time: 1932.4217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0072390\n",
      "\tspeed: 0.0337s/iter; left time: 632.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 226 | Train Loss: 0.0078908 Vali Loss: 0.0078561 Test Loss: 0.0099173\n",
      "Validation loss decreased (0.007911 --> 0.007856).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0073018\n",
      "\tspeed: 0.0968s/iter; left time: 1806.9276s\n",
      "\titers: 200, epoch: 18 | loss: 0.0074447\n",
      "\tspeed: 0.0376s/iter; left time: 698.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.40s\n",
      "Steps: 226 | Train Loss: 0.0078563 Vali Loss: 0.0078118 Test Loss: 0.0098345\n",
      "Validation loss decreased (0.007856 --> 0.007812).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0085467\n",
      "\tspeed: 0.0538s/iter; left time: 990.9492s\n",
      "\titers: 200, epoch: 19 | loss: 0.0077147\n",
      "\tspeed: 0.0182s/iter; left time: 333.3859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0078181 Vali Loss: 0.0077873 Test Loss: 0.0098552\n",
      "Validation loss decreased (0.007812 --> 0.007787).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0075294\n",
      "\tspeed: 0.0468s/iter; left time: 851.3470s\n",
      "\titers: 200, epoch: 20 | loss: 0.0082452\n",
      "\tspeed: 0.0281s/iter; left time: 508.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.0078004 Vali Loss: 0.0077559 Test Loss: 0.0098293\n",
      "Validation loss decreased (0.007787 --> 0.007756).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0079917\n",
      "\tspeed: 0.0842s/iter; left time: 1513.5368s\n",
      "\titers: 200, epoch: 21 | loss: 0.0068666\n",
      "\tspeed: 0.0323s/iter; left time: 576.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 226 | Train Loss: 0.0077771 Vali Loss: 0.0078368 Test Loss: 0.0098692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0077353\n",
      "\tspeed: 0.0889s/iter; left time: 1577.8287s\n",
      "\titers: 200, epoch: 22 | loss: 0.0068657\n",
      "\tspeed: 0.0471s/iter; left time: 831.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.17s\n",
      "Steps: 226 | Train Loss: 0.0077436 Vali Loss: 0.0077783 Test Loss: 0.0098262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0081617\n",
      "\tspeed: 0.1120s/iter; left time: 1962.9438s\n",
      "\titers: 200, epoch: 23 | loss: 0.0074716\n",
      "\tspeed: 0.0316s/iter; left time: 550.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 226 | Train Loss: 0.0077267 Vali Loss: 0.0078055 Test Loss: 0.0098338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0069516\n",
      "\tspeed: 0.0802s/iter; left time: 1387.4038s\n",
      "\titers: 200, epoch: 24 | loss: 0.0089964\n",
      "\tspeed: 0.0335s/iter; left time: 576.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 226 | Train Loss: 0.0077165 Vali Loss: 0.0077400 Test Loss: 0.0097997\n",
      "Validation loss decreased (0.007756 --> 0.007740).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0072426\n",
      "\tspeed: 0.0914s/iter; left time: 1560.7434s\n",
      "\titers: 200, epoch: 25 | loss: 0.0081069\n",
      "\tspeed: 0.0356s/iter; left time: 605.0396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 226 | Train Loss: 0.0076998 Vali Loss: 0.0077898 Test Loss: 0.0098343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0074234\n",
      "\tspeed: 0.0812s/iter; left time: 1367.8907s\n",
      "\titers: 200, epoch: 26 | loss: 0.0075612\n",
      "\tspeed: 0.0378s/iter; left time: 633.6596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.0076881 Vali Loss: 0.0077471 Test Loss: 0.0097822\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0090928\n",
      "\tspeed: 0.0893s/iter; left time: 1483.8526s\n",
      "\titers: 200, epoch: 27 | loss: 0.0066571\n",
      "\tspeed: 0.0363s/iter; left time: 599.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.0076465 Vali Loss: 0.0077481 Test Loss: 0.0098086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0076121\n",
      "\tspeed: 0.0916s/iter; left time: 1502.1085s\n",
      "\titers: 200, epoch: 28 | loss: 0.0068969\n",
      "\tspeed: 0.0433s/iter; left time: 705.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.38s\n",
      "Steps: 226 | Train Loss: 0.0076703 Vali Loss: 0.0077220 Test Loss: 0.0097674\n",
      "Validation loss decreased (0.007740 --> 0.007722).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0082714\n",
      "\tspeed: 0.0915s/iter; left time: 1480.2814s\n",
      "\titers: 200, epoch: 29 | loss: 0.0075957\n",
      "\tspeed: 0.0354s/iter; left time: 568.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 226 | Train Loss: 0.0076475 Vali Loss: 0.0077353 Test Loss: 0.0097849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0068515\n",
      "\tspeed: 0.0765s/iter; left time: 1220.2614s\n",
      "\titers: 200, epoch: 30 | loss: 0.0069599\n",
      "\tspeed: 0.0322s/iter; left time: 510.8528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.0076292 Vali Loss: 0.0077237 Test Loss: 0.0097906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0075222\n",
      "\tspeed: 0.0819s/iter; left time: 1287.5022s\n",
      "\titers: 200, epoch: 31 | loss: 0.0075825\n",
      "\tspeed: 0.0348s/iter; left time: 543.7270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 226 | Train Loss: 0.0076272 Vali Loss: 0.0077313 Test Loss: 0.0097910\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0078725\n",
      "\tspeed: 0.0743s/iter; left time: 1150.6650s\n",
      "\titers: 200, epoch: 32 | loss: 0.0086332\n",
      "\tspeed: 0.0293s/iter; left time: 450.9699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0076108 Vali Loss: 0.0077107 Test Loss: 0.0097691\n",
      "Validation loss decreased (0.007722 --> 0.007711).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0079413\n",
      "\tspeed: 0.0801s/iter; left time: 1223.1830s\n",
      "\titers: 200, epoch: 33 | loss: 0.0084611\n",
      "\tspeed: 0.0341s/iter; left time: 517.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 226 | Train Loss: 0.0076104 Vali Loss: 0.0077472 Test Loss: 0.0097762\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0080443\n",
      "\tspeed: 0.0894s/iter; left time: 1344.5777s\n",
      "\titers: 200, epoch: 34 | loss: 0.0076971\n",
      "\tspeed: 0.0405s/iter; left time: 605.0621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 226 | Train Loss: 0.0076043 Vali Loss: 0.0077256 Test Loss: 0.0097612\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0085065\n",
      "\tspeed: 0.0728s/iter; left time: 1078.0853s\n",
      "\titers: 200, epoch: 35 | loss: 0.0081995\n",
      "\tspeed: 0.0331s/iter; left time: 487.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0075912 Vali Loss: 0.0077143 Test Loss: 0.0097552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0068593\n",
      "\tspeed: 0.0725s/iter; left time: 1057.8870s\n",
      "\titers: 200, epoch: 36 | loss: 0.0077889\n",
      "\tspeed: 0.0355s/iter; left time: 514.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 226 | Train Loss: 0.0075942 Vali Loss: 0.0077039 Test Loss: 0.0097492\n",
      "Validation loss decreased (0.007711 --> 0.007704).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0083970\n",
      "\tspeed: 0.0668s/iter; left time: 960.0787s\n",
      "\titers: 200, epoch: 37 | loss: 0.0081276\n",
      "\tspeed: 0.0272s/iter; left time: 387.4390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 226 | Train Loss: 0.0075800 Vali Loss: 0.0077205 Test Loss: 0.0097417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0066566\n",
      "\tspeed: 0.0689s/iter; left time: 973.6672s\n",
      "\titers: 200, epoch: 38 | loss: 0.0076736\n",
      "\tspeed: 0.0346s/iter; left time: 485.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 226 | Train Loss: 0.0075843 Vali Loss: 0.0077153 Test Loss: 0.0097522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0073878\n",
      "\tspeed: 0.0648s/iter; left time: 900.9520s\n",
      "\titers: 200, epoch: 39 | loss: 0.0068948\n",
      "\tspeed: 0.0268s/iter; left time: 370.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 226 | Train Loss: 0.0075843 Vali Loss: 0.0077071 Test Loss: 0.0097395\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0067716\n",
      "\tspeed: 0.0828s/iter; left time: 1132.7915s\n",
      "\titers: 200, epoch: 40 | loss: 0.0069292\n",
      "\tspeed: 0.0422s/iter; left time: 572.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 226 | Train Loss: 0.0075804 Vali Loss: 0.0077128 Test Loss: 0.0097463\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0087412\n",
      "\tspeed: 0.0829s/iter; left time: 1116.0052s\n",
      "\titers: 200, epoch: 41 | loss: 0.0085838\n",
      "\tspeed: 0.0267s/iter; left time: 356.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0075678 Vali Loss: 0.0076696 Test Loss: 0.0097519\n",
      "Validation loss decreased (0.007704 --> 0.007670).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0066021\n",
      "\tspeed: 0.0680s/iter; left time: 899.8087s\n",
      "\titers: 200, epoch: 42 | loss: 0.0081806\n",
      "\tspeed: 0.0253s/iter; left time: 331.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 226 | Train Loss: 0.0075720 Vali Loss: 0.0076917 Test Loss: 0.0097417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0064914\n",
      "\tspeed: 0.0693s/iter; left time: 901.4095s\n",
      "\titers: 200, epoch: 43 | loss: 0.0077684\n",
      "\tspeed: 0.0323s/iter; left time: 417.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.0075833 Vali Loss: 0.0077075 Test Loss: 0.0097418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0076977\n",
      "\tspeed: 0.0715s/iter; left time: 914.5500s\n",
      "\titers: 200, epoch: 44 | loss: 0.0064298\n",
      "\tspeed: 0.0252s/iter; left time: 319.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 226 | Train Loss: 0.0075701 Vali Loss: 0.0076917 Test Loss: 0.0097360\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0082549\n",
      "\tspeed: 0.0646s/iter; left time: 811.6309s\n",
      "\titers: 200, epoch: 45 | loss: 0.0081084\n",
      "\tspeed: 0.0309s/iter; left time: 385.3936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0075637 Vali Loss: 0.0077136 Test Loss: 0.0097361\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0077726\n",
      "\tspeed: 0.0839s/iter; left time: 1034.6099s\n",
      "\titers: 200, epoch: 46 | loss: 0.0061236\n",
      "\tspeed: 0.0348s/iter; left time: 425.2131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 226 | Train Loss: 0.0075685 Vali Loss: 0.0076890 Test Loss: 0.0097379\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0080226\n",
      "\tspeed: 0.0846s/iter; left time: 1024.1546s\n",
      "\titers: 200, epoch: 47 | loss: 0.0073111\n",
      "\tspeed: 0.0332s/iter; left time: 398.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 226 | Train Loss: 0.0075626 Vali Loss: 0.0076897 Test Loss: 0.0097352\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0077425\n",
      "\tspeed: 0.0723s/iter; left time: 858.9998s\n",
      "\titers: 200, epoch: 48 | loss: 0.0077390\n",
      "\tspeed: 0.0303s/iter; left time: 356.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0075654 Vali Loss: 0.0077054 Test Loss: 0.0097400\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0079935\n",
      "\tspeed: 0.0697s/iter; left time: 812.1396s\n",
      "\titers: 200, epoch: 49 | loss: 0.0078852\n",
      "\tspeed: 0.0286s/iter; left time: 330.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 226 | Train Loss: 0.0075531 Vali Loss: 0.0077219 Test Loss: 0.0097373\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0076052\n",
      "\tspeed: 0.0638s/iter; left time: 729.0553s\n",
      "\titers: 200, epoch: 50 | loss: 0.0080884\n",
      "\tspeed: 0.0307s/iter; left time: 347.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 226 | Train Loss: 0.0075651 Vali Loss: 0.0077060 Test Loss: 0.0097415\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0076148\n",
      "\tspeed: 0.0749s/iter; left time: 838.4543s\n",
      "\titers: 200, epoch: 51 | loss: 0.0078435\n",
      "\tspeed: 0.0270s/iter; left time: 299.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0075558 Vali Loss: 0.0077239 Test Loss: 0.0097382\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009751889854669571, rmse:0.09875165671110153, mae:0.06079358235001564, rse:0.29061415791511536\n",
      "Intermediate time for ES and pred_len 24: 00h:10m:14.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0385214\n",
      "\tspeed: 0.0833s/iter; left time: 1866.7780s\n",
      "\titers: 200, epoch: 1 | loss: 0.0321006\n",
      "\tspeed: 0.0363s/iter; left time: 809.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 225 | Train Loss: 0.0402985 Vali Loss: 0.0268622 Test Loss: 0.0364986\n",
      "Validation loss decreased (inf --> 0.026862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0202941\n",
      "\tspeed: 0.0986s/iter; left time: 2186.6123s\n",
      "\titers: 200, epoch: 2 | loss: 0.0176809\n",
      "\tspeed: 0.0383s/iter; left time: 846.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 225 | Train Loss: 0.0199497 Vali Loss: 0.0171759 Test Loss: 0.0222667\n",
      "Validation loss decreased (0.026862 --> 0.017176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0164886\n",
      "\tspeed: 0.0988s/iter; left time: 2169.5566s\n",
      "\titers: 200, epoch: 3 | loss: 0.0159799\n",
      "\tspeed: 0.0399s/iter; left time: 870.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 225 | Train Loss: 0.0171304 Vali Loss: 0.0158539 Test Loss: 0.0206034\n",
      "Validation loss decreased (0.017176 --> 0.015854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0139721\n",
      "\tspeed: 0.0899s/iter; left time: 1952.2639s\n",
      "\titers: 200, epoch: 4 | loss: 0.0155888\n",
      "\tspeed: 0.0408s/iter; left time: 882.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 225 | Train Loss: 0.0162038 Vali Loss: 0.0155706 Test Loss: 0.0199895\n",
      "Validation loss decreased (0.015854 --> 0.015571).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0160721\n",
      "\tspeed: 0.1031s/iter; left time: 2215.6828s\n",
      "\titers: 200, epoch: 5 | loss: 0.0148397\n",
      "\tspeed: 0.0516s/iter; left time: 1104.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.0157221 Vali Loss: 0.0152692 Test Loss: 0.0195936\n",
      "Validation loss decreased (0.015571 --> 0.015269).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0146115\n",
      "\tspeed: 0.1357s/iter; left time: 2888.1024s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144678\n",
      "\tspeed: 0.0323s/iter; left time: 683.7279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 225 | Train Loss: 0.0153876 Vali Loss: 0.0152303 Test Loss: 0.0194437\n",
      "Validation loss decreased (0.015269 --> 0.015230).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0142163\n",
      "\tspeed: 0.0478s/iter; left time: 1005.6234s\n",
      "\titers: 200, epoch: 7 | loss: 0.0141031\n",
      "\tspeed: 0.0247s/iter; left time: 517.0438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0151415 Vali Loss: 0.0150768 Test Loss: 0.0191790\n",
      "Validation loss decreased (0.015230 --> 0.015077).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0140387\n",
      "\tspeed: 0.0919s/iter; left time: 1913.4497s\n",
      "\titers: 200, epoch: 8 | loss: 0.0141506\n",
      "\tspeed: 0.0341s/iter; left time: 706.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 225 | Train Loss: 0.0149555 Vali Loss: 0.0150878 Test Loss: 0.0191487\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0142673\n",
      "\tspeed: 0.1078s/iter; left time: 2221.1984s\n",
      "\titers: 200, epoch: 9 | loss: 0.0143092\n",
      "\tspeed: 0.0485s/iter; left time: 994.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.68s\n",
      "Steps: 225 | Train Loss: 0.0148236 Vali Loss: 0.0148663 Test Loss: 0.0189639\n",
      "Validation loss decreased (0.015077 --> 0.014866).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0139251\n",
      "\tspeed: 0.0873s/iter; left time: 1779.8181s\n",
      "\titers: 200, epoch: 10 | loss: 0.0166310\n",
      "\tspeed: 0.0547s/iter; left time: 1109.0509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 225 | Train Loss: 0.0146813 Vali Loss: 0.0150752 Test Loss: 0.0190709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0141909\n",
      "\tspeed: 0.1272s/iter; left time: 2563.4074s\n",
      "\titers: 200, epoch: 11 | loss: 0.0153536\n",
      "\tspeed: 0.0197s/iter; left time: 394.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0145726 Vali Loss: 0.0148738 Test Loss: 0.0189073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0141518\n",
      "\tspeed: 0.0453s/iter; left time: 902.9086s\n",
      "\titers: 200, epoch: 12 | loss: 0.0146643\n",
      "\tspeed: 0.0243s/iter; left time: 482.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0144563 Vali Loss: 0.0147936 Test Loss: 0.0188262\n",
      "Validation loss decreased (0.014866 --> 0.014794).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0127954\n",
      "\tspeed: 0.0488s/iter; left time: 961.9703s\n",
      "\titers: 200, epoch: 13 | loss: 0.0135295\n",
      "\tspeed: 0.0303s/iter; left time: 593.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0143845 Vali Loss: 0.0148190 Test Loss: 0.0189337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0153766\n",
      "\tspeed: 0.0791s/iter; left time: 1541.4361s\n",
      "\titers: 200, epoch: 14 | loss: 0.0150153\n",
      "\tspeed: 0.0212s/iter; left time: 409.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0143134 Vali Loss: 0.0149541 Test Loss: 0.0189741\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0134031\n",
      "\tspeed: 0.0456s/iter; left time: 877.1835s\n",
      "\titers: 200, epoch: 15 | loss: 0.0160063\n",
      "\tspeed: 0.0202s/iter; left time: 387.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0142359 Vali Loss: 0.0148774 Test Loss: 0.0189182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0137937\n",
      "\tspeed: 0.1028s/iter; left time: 1954.9851s\n",
      "\titers: 200, epoch: 16 | loss: 0.0153615\n",
      "\tspeed: 0.0205s/iter; left time: 388.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 225 | Train Loss: 0.0141616 Vali Loss: 0.0148836 Test Loss: 0.0189698\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0141673\n",
      "\tspeed: 0.0435s/iter; left time: 817.5058s\n",
      "\titers: 200, epoch: 17 | loss: 0.0134428\n",
      "\tspeed: 0.0214s/iter; left time: 399.2837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0140956 Vali Loss: 0.0147340 Test Loss: 0.0188355\n",
      "Validation loss decreased (0.014794 --> 0.014734).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0139518\n",
      "\tspeed: 0.0526s/iter; left time: 978.0026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0137749\n",
      "\tspeed: 0.0361s/iter; left time: 666.3086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 225 | Train Loss: 0.0140458 Vali Loss: 0.0148421 Test Loss: 0.0189237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0140153\n",
      "\tspeed: 0.0714s/iter; left time: 1309.4177s\n",
      "\titers: 200, epoch: 19 | loss: 0.0141719\n",
      "\tspeed: 0.0222s/iter; left time: 404.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0139988 Vali Loss: 0.0146938 Test Loss: 0.0188097\n",
      "Validation loss decreased (0.014734 --> 0.014694).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0145078\n",
      "\tspeed: 0.0592s/iter; left time: 1072.6189s\n",
      "\titers: 200, epoch: 20 | loss: 0.0140767\n",
      "\tspeed: 0.0204s/iter; left time: 367.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0139585 Vali Loss: 0.0147689 Test Loss: 0.0188606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0134230\n",
      "\tspeed: 0.0571s/iter; left time: 1021.9898s\n",
      "\titers: 200, epoch: 21 | loss: 0.0123201\n",
      "\tspeed: 0.0291s/iter; left time: 517.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0139100 Vali Loss: 0.0148057 Test Loss: 0.0188332\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0146732\n",
      "\tspeed: 0.0608s/iter; left time: 1075.5546s\n",
      "\titers: 200, epoch: 22 | loss: 0.0162446\n",
      "\tspeed: 0.0191s/iter; left time: 336.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0138737 Vali Loss: 0.0148652 Test Loss: 0.0188741\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0149700\n",
      "\tspeed: 0.0469s/iter; left time: 818.4077s\n",
      "\titers: 200, epoch: 23 | loss: 0.0135929\n",
      "\tspeed: 0.0218s/iter; left time: 378.8562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 225 | Train Loss: 0.0138603 Vali Loss: 0.0147573 Test Loss: 0.0188534\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0130955\n",
      "\tspeed: 0.1010s/iter; left time: 1740.1626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0129737\n",
      "\tspeed: 0.0196s/iter; left time: 334.8176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 225 | Train Loss: 0.0138433 Vali Loss: 0.0147270 Test Loss: 0.0188300\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0143310\n",
      "\tspeed: 0.0431s/iter; left time: 733.4137s\n",
      "\titers: 200, epoch: 25 | loss: 0.0139837\n",
      "\tspeed: 0.0193s/iter; left time: 327.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0137946 Vali Loss: 0.0148280 Test Loss: 0.0188872\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0130300\n",
      "\tspeed: 0.0537s/iter; left time: 901.2312s\n",
      "\titers: 200, epoch: 26 | loss: 0.0136986\n",
      "\tspeed: 0.0490s/iter; left time: 817.6382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.94s\n",
      "Steps: 225 | Train Loss: 0.0137725 Vali Loss: 0.0147710 Test Loss: 0.0188353\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0146367\n",
      "\tspeed: 0.0541s/iter; left time: 895.3023s\n",
      "\titers: 200, epoch: 27 | loss: 0.0136573\n",
      "\tspeed: 0.0217s/iter; left time: 357.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 225 | Train Loss: 0.0137646 Vali Loss: 0.0147977 Test Loss: 0.0189136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0146420\n",
      "\tspeed: 0.0509s/iter; left time: 830.3653s\n",
      "\titers: 200, epoch: 28 | loss: 0.0124258\n",
      "\tspeed: 0.0311s/iter; left time: 503.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0137562 Vali Loss: 0.0147614 Test Loss: 0.0188549\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0153049\n",
      "\tspeed: 0.0791s/iter; left time: 1273.9197s\n",
      "\titers: 200, epoch: 29 | loss: 0.0134878\n",
      "\tspeed: 0.0185s/iter; left time: 296.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 225 | Train Loss: 0.0137445 Vali Loss: 0.0147277 Test Loss: 0.0188331\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018809732049703598, rmse:0.13714857399463654, mae:0.08826389908790588, rse:0.40290123224258423\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:14.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0418318\n",
      "\tspeed: 0.0686s/iter; left time: 1535.7814s\n",
      "\titers: 200, epoch: 1 | loss: 0.0310877\n",
      "\tspeed: 0.0289s/iter; left time: 645.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 225 | Train Loss: 0.0424433 Vali Loss: 0.0290079 Test Loss: 0.0391881\n",
      "Validation loss decreased (inf --> 0.029008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0218836\n",
      "\tspeed: 0.0559s/iter; left time: 1240.2360s\n",
      "\titers: 200, epoch: 2 | loss: 0.0210375\n",
      "\tspeed: 0.0226s/iter; left time: 499.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 225 | Train Loss: 0.0218081 Vali Loss: 0.0196624 Test Loss: 0.0247310\n",
      "Validation loss decreased (0.029008 --> 0.019662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185089\n",
      "\tspeed: 0.1102s/iter; left time: 2418.0889s\n",
      "\titers: 200, epoch: 3 | loss: 0.0187048\n",
      "\tspeed: 0.0242s/iter; left time: 529.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 225 | Train Loss: 0.0190434 Vali Loss: 0.0182646 Test Loss: 0.0228481\n",
      "Validation loss decreased (0.019662 --> 0.018265).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0182760\n",
      "\tspeed: 0.0615s/iter; left time: 1335.8476s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178577\n",
      "\tspeed: 0.0228s/iter; left time: 493.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 225 | Train Loss: 0.0180016 Vali Loss: 0.0176468 Test Loss: 0.0218411\n",
      "Validation loss decreased (0.018265 --> 0.017647).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0167117\n",
      "\tspeed: 0.1185s/iter; left time: 2547.2858s\n",
      "\titers: 200, epoch: 5 | loss: 0.0163538\n",
      "\tspeed: 0.0213s/iter; left time: 455.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 225 | Train Loss: 0.0174683 Vali Loss: 0.0175372 Test Loss: 0.0215410\n",
      "Validation loss decreased (0.017647 --> 0.017537).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0154899\n",
      "\tspeed: 0.0576s/iter; left time: 1226.5511s\n",
      "\titers: 200, epoch: 6 | loss: 0.0176745\n",
      "\tspeed: 0.0259s/iter; left time: 547.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0171330 Vali Loss: 0.0173297 Test Loss: 0.0213197\n",
      "Validation loss decreased (0.017537 --> 0.017330).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0173982\n",
      "\tspeed: 0.1044s/iter; left time: 2197.5805s\n",
      "\titers: 200, epoch: 7 | loss: 0.0163391\n",
      "\tspeed: 0.0251s/iter; left time: 525.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 225 | Train Loss: 0.0168822 Vali Loss: 0.0172685 Test Loss: 0.0212768\n",
      "Validation loss decreased (0.017330 --> 0.017269).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0175235\n",
      "\tspeed: 0.0601s/iter; left time: 1251.3915s\n",
      "\titers: 200, epoch: 8 | loss: 0.0173391\n",
      "\tspeed: 0.0359s/iter; left time: 744.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.12s\n",
      "Steps: 225 | Train Loss: 0.0166973 Vali Loss: 0.0172033 Test Loss: 0.0212305\n",
      "Validation loss decreased (0.017269 --> 0.017203).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0174077\n",
      "\tspeed: 0.0742s/iter; left time: 1528.0674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0177108\n",
      "\tspeed: 0.0291s/iter; left time: 596.6557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 225 | Train Loss: 0.0165517 Vali Loss: 0.0170777 Test Loss: 0.0211148\n",
      "Validation loss decreased (0.017203 --> 0.017078).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0160374\n",
      "\tspeed: 0.0759s/iter; left time: 1546.4363s\n",
      "\titers: 200, epoch: 10 | loss: 0.0152154\n",
      "\tspeed: 0.0259s/iter; left time: 524.8310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 225 | Train Loss: 0.0164015 Vali Loss: 0.0172799 Test Loss: 0.0212429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0165146\n",
      "\tspeed: 0.0697s/iter; left time: 1404.6440s\n",
      "\titers: 200, epoch: 11 | loss: 0.0169340\n",
      "\tspeed: 0.0366s/iter; left time: 733.3366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 225 | Train Loss: 0.0162799 Vali Loss: 0.0170245 Test Loss: 0.0211387\n",
      "Validation loss decreased (0.017078 --> 0.017025).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0174235\n",
      "\tspeed: 0.0649s/iter; left time: 1292.3864s\n",
      "\titers: 200, epoch: 12 | loss: 0.0168405\n",
      "\tspeed: 0.0163s/iter; left time: 322.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0161901 Vali Loss: 0.0170253 Test Loss: 0.0209918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0157391\n",
      "\tspeed: 0.0381s/iter; left time: 750.4034s\n",
      "\titers: 200, epoch: 13 | loss: 0.0155118\n",
      "\tspeed: 0.0171s/iter; left time: 335.4348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0160766 Vali Loss: 0.0171959 Test Loss: 0.0210651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0160115\n",
      "\tspeed: 0.0866s/iter; left time: 1687.1148s\n",
      "\titers: 200, epoch: 14 | loss: 0.0140521\n",
      "\tspeed: 0.0268s/iter; left time: 518.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 225 | Train Loss: 0.0159977 Vali Loss: 0.0171280 Test Loss: 0.0211238\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0158797\n",
      "\tspeed: 0.0711s/iter; left time: 1369.6018s\n",
      "\titers: 200, epoch: 15 | loss: 0.0149746\n",
      "\tspeed: 0.0553s/iter; left time: 1059.9531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 225 | Train Loss: 0.0159293 Vali Loss: 0.0171289 Test Loss: 0.0210804\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0157262\n",
      "\tspeed: 0.0535s/iter; left time: 1018.3351s\n",
      "\titers: 200, epoch: 16 | loss: 0.0152471\n",
      "\tspeed: 0.0257s/iter; left time: 486.7917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 225 | Train Loss: 0.0158684 Vali Loss: 0.0171377 Test Loss: 0.0211543\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0158248\n",
      "\tspeed: 0.0782s/iter; left time: 1469.9721s\n",
      "\titers: 200, epoch: 17 | loss: 0.0167456\n",
      "\tspeed: 0.0431s/iter; left time: 805.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 225 | Train Loss: 0.0157851 Vali Loss: 0.0171424 Test Loss: 0.0211536\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0142377\n",
      "\tspeed: 0.0663s/iter; left time: 1231.6919s\n",
      "\titers: 200, epoch: 18 | loss: 0.0154455\n",
      "\tspeed: 0.0357s/iter; left time: 659.3945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 225 | Train Loss: 0.0157332 Vali Loss: 0.0171524 Test Loss: 0.0210933\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0156443\n",
      "\tspeed: 0.0726s/iter; left time: 1332.6308s\n",
      "\titers: 200, epoch: 19 | loss: 0.0168023\n",
      "\tspeed: 0.0464s/iter; left time: 846.2397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 225 | Train Loss: 0.0156895 Vali Loss: 0.0171591 Test Loss: 0.0211719\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0153335\n",
      "\tspeed: 0.0819s/iter; left time: 1483.7848s\n",
      "\titers: 200, epoch: 20 | loss: 0.0163019\n",
      "\tspeed: 0.0254s/iter; left time: 458.3233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 225 | Train Loss: 0.0156480 Vali Loss: 0.0171658 Test Loss: 0.0211469\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0144234\n",
      "\tspeed: 0.0640s/iter; left time: 1145.1888s\n",
      "\titers: 200, epoch: 21 | loss: 0.0156189\n",
      "\tspeed: 0.0545s/iter; left time: 970.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 225 | Train Loss: 0.0156178 Vali Loss: 0.0171672 Test Loss: 0.0212086\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021138742566108704, rmse:0.14539168775081635, mae:0.0951080247759819, rse:0.42714768648147583\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:52.53s\n",
      "Intermediate time for ES: 00h:19m:22.06s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0214014\n",
      "\tspeed: 0.0465s/iter; left time: 1045.5679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0145572\n",
      "\tspeed: 0.0183s/iter; left time: 410.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 226 | Train Loss: 0.0225206 Vali Loss: 0.0184396 Test Loss: 0.0229489\n",
      "Validation loss decreased (inf --> 0.018440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0084885\n",
      "\tspeed: 0.0521s/iter; left time: 1161.2013s\n",
      "\titers: 200, epoch: 2 | loss: 0.0069146\n",
      "\tspeed: 0.0274s/iter; left time: 607.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0085904 Vali Loss: 0.0098390 Test Loss: 0.0112448\n",
      "Validation loss decreased (0.018440 --> 0.009839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0067327\n",
      "\tspeed: 0.0826s/iter; left time: 1820.3676s\n",
      "\titers: 200, epoch: 3 | loss: 0.0059661\n",
      "\tspeed: 0.0283s/iter; left time: 620.1351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0070147 Vali Loss: 0.0093701 Test Loss: 0.0107432\n",
      "Validation loss decreased (0.009839 --> 0.009370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0073707\n",
      "\tspeed: 0.0612s/iter; left time: 1336.4966s\n",
      "\titers: 200, epoch: 4 | loss: 0.0069606\n",
      "\tspeed: 0.0306s/iter; left time: 663.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 226 | Train Loss: 0.0066252 Vali Loss: 0.0089922 Test Loss: 0.0105075\n",
      "Validation loss decreased (0.009370 --> 0.008992).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0059994\n",
      "\tspeed: 0.0626s/iter; left time: 1352.6284s\n",
      "\titers: 200, epoch: 5 | loss: 0.0052356\n",
      "\tspeed: 0.0334s/iter; left time: 718.8642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0063918 Vali Loss: 0.0088446 Test Loss: 0.0103435\n",
      "Validation loss decreased (0.008992 --> 0.008845).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0059743\n",
      "\tspeed: 0.0718s/iter; left time: 1534.6728s\n",
      "\titers: 200, epoch: 6 | loss: 0.0054268\n",
      "\tspeed: 0.0243s/iter; left time: 516.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 226 | Train Loss: 0.0062265 Vali Loss: 0.0086468 Test Loss: 0.0102027\n",
      "Validation loss decreased (0.008845 --> 0.008647).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0064023\n",
      "\tspeed: 0.0604s/iter; left time: 1277.7380s\n",
      "\titers: 200, epoch: 7 | loss: 0.0064050\n",
      "\tspeed: 0.0283s/iter; left time: 595.7747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.02s\n",
      "Steps: 226 | Train Loss: 0.0061115 Vali Loss: 0.0086640 Test Loss: 0.0102161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0059183\n",
      "\tspeed: 0.0922s/iter; left time: 1928.2814s\n",
      "\titers: 200, epoch: 8 | loss: 0.0059890\n",
      "\tspeed: 0.0218s/iter; left time: 453.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 226 | Train Loss: 0.0060151 Vali Loss: 0.0086641 Test Loss: 0.0103460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0052437\n",
      "\tspeed: 0.0549s/iter; left time: 1135.2678s\n",
      "\titers: 200, epoch: 9 | loss: 0.0057425\n",
      "\tspeed: 0.0302s/iter; left time: 621.5328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 226 | Train Loss: 0.0059436 Vali Loss: 0.0084395 Test Loss: 0.0101464\n",
      "Validation loss decreased (0.008647 --> 0.008440).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0057585\n",
      "\tspeed: 0.0763s/iter; left time: 1562.2544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0061389\n",
      "\tspeed: 0.0331s/iter; left time: 674.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 226 | Train Loss: 0.0058756 Vali Loss: 0.0084618 Test Loss: 0.0100039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0055120\n",
      "\tspeed: 0.0616s/iter; left time: 1247.4301s\n",
      "\titers: 200, epoch: 11 | loss: 0.0054122\n",
      "\tspeed: 0.0354s/iter; left time: 713.9236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 226 | Train Loss: 0.0058268 Vali Loss: 0.0084441 Test Loss: 0.0100350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0066425\n",
      "\tspeed: 0.0534s/iter; left time: 1068.2266s\n",
      "\titers: 200, epoch: 12 | loss: 0.0056953\n",
      "\tspeed: 0.0302s/iter; left time: 601.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0057755 Vali Loss: 0.0083846 Test Loss: 0.0100768\n",
      "Validation loss decreased (0.008440 --> 0.008385).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0049884\n",
      "\tspeed: 0.0771s/iter; left time: 1526.0992s\n",
      "\titers: 200, epoch: 13 | loss: 0.0064530\n",
      "\tspeed: 0.0241s/iter; left time: 474.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 226 | Train Loss: 0.0057345 Vali Loss: 0.0083272 Test Loss: 0.0099970\n",
      "Validation loss decreased (0.008385 --> 0.008327).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0061710\n",
      "\tspeed: 0.0577s/iter; left time: 1128.0379s\n",
      "\titers: 200, epoch: 14 | loss: 0.0062265\n",
      "\tspeed: 0.0245s/iter; left time: 476.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0056927 Vali Loss: 0.0083816 Test Loss: 0.0100558\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0053974\n",
      "\tspeed: 0.1023s/iter; left time: 1977.2106s\n",
      "\titers: 200, epoch: 15 | loss: 0.0045167\n",
      "\tspeed: 0.0249s/iter; left time: 478.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 226 | Train Loss: 0.0056677 Vali Loss: 0.0083361 Test Loss: 0.0100202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0060043\n",
      "\tspeed: 0.0570s/iter; left time: 1089.8463s\n",
      "\titers: 200, epoch: 16 | loss: 0.0055771\n",
      "\tspeed: 0.0272s/iter; left time: 516.3875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 226 | Train Loss: 0.0056243 Vali Loss: 0.0083715 Test Loss: 0.0099776\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0055168\n",
      "\tspeed: 0.0740s/iter; left time: 1397.7394s\n",
      "\titers: 200, epoch: 17 | loss: 0.0054286\n",
      "\tspeed: 0.0322s/iter; left time: 604.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.0056142 Vali Loss: 0.0083595 Test Loss: 0.0100348\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0055352\n",
      "\tspeed: 0.0597s/iter; left time: 1114.3097s\n",
      "\titers: 200, epoch: 18 | loss: 0.0051048\n",
      "\tspeed: 0.0298s/iter; left time: 552.6135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 226 | Train Loss: 0.0055779 Vali Loss: 0.0083256 Test Loss: 0.0100114\n",
      "Validation loss decreased (0.008327 --> 0.008326).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0057776\n",
      "\tspeed: 0.0624s/iter; left time: 1151.0329s\n",
      "\titers: 200, epoch: 19 | loss: 0.0059579\n",
      "\tspeed: 0.0235s/iter; left time: 431.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 226 | Train Loss: 0.0055696 Vali Loss: 0.0082678 Test Loss: 0.0099987\n",
      "Validation loss decreased (0.008326 --> 0.008268).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0063669\n",
      "\tspeed: 0.0811s/iter; left time: 1476.2399s\n",
      "\titers: 200, epoch: 20 | loss: 0.0077393\n",
      "\tspeed: 0.0331s/iter; left time: 599.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.0055387 Vali Loss: 0.0082505 Test Loss: 0.0099721\n",
      "Validation loss decreased (0.008268 --> 0.008250).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0056185\n",
      "\tspeed: 0.0568s/iter; left time: 1021.5923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0054805\n",
      "\tspeed: 0.0220s/iter; left time: 392.9766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 226 | Train Loss: 0.0055185 Vali Loss: 0.0083284 Test Loss: 0.0100105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0052375\n",
      "\tspeed: 0.0749s/iter; left time: 1329.5299s\n",
      "\titers: 200, epoch: 22 | loss: 0.0058114\n",
      "\tspeed: 0.0356s/iter; left time: 628.6617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 226 | Train Loss: 0.0055146 Vali Loss: 0.0082659 Test Loss: 0.0099952\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0055529\n",
      "\tspeed: 0.0495s/iter; left time: 868.3212s\n",
      "\titers: 200, epoch: 23 | loss: 0.0053774\n",
      "\tspeed: 0.0188s/iter; left time: 328.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 226 | Train Loss: 0.0055039 Vali Loss: 0.0082733 Test Loss: 0.0099869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0058973\n",
      "\tspeed: 0.0514s/iter; left time: 889.0240s\n",
      "\titers: 200, epoch: 24 | loss: 0.0055044\n",
      "\tspeed: 0.0266s/iter; left time: 458.3838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 226 | Train Loss: 0.0054934 Vali Loss: 0.0082724 Test Loss: 0.0099753\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0055101\n",
      "\tspeed: 0.0631s/iter; left time: 1078.0938s\n",
      "\titers: 200, epoch: 25 | loss: 0.0062767\n",
      "\tspeed: 0.0336s/iter; left time: 571.0552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 226 | Train Loss: 0.0054823 Vali Loss: 0.0082438 Test Loss: 0.0099522\n",
      "Validation loss decreased (0.008250 --> 0.008244).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0058566\n",
      "\tspeed: 0.0744s/iter; left time: 1254.3010s\n",
      "\titers: 200, epoch: 26 | loss: 0.0056711\n",
      "\tspeed: 0.0246s/iter; left time: 412.1057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0054782 Vali Loss: 0.0082551 Test Loss: 0.0099774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0063704\n",
      "\tspeed: 0.0658s/iter; left time: 1094.6314s\n",
      "\titers: 200, epoch: 27 | loss: 0.0056807\n",
      "\tspeed: 0.0357s/iter; left time: 590.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0054562 Vali Loss: 0.0082273 Test Loss: 0.0099577\n",
      "Validation loss decreased (0.008244 --> 0.008227).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0051593\n",
      "\tspeed: 0.0674s/iter; left time: 1104.8162s\n",
      "\titers: 200, epoch: 28 | loss: 0.0049602\n",
      "\tspeed: 0.0292s/iter; left time: 475.7376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0054514 Vali Loss: 0.0082629 Test Loss: 0.0099501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0059183\n",
      "\tspeed: 0.0806s/iter; left time: 1302.7991s\n",
      "\titers: 200, epoch: 29 | loss: 0.0055221\n",
      "\tspeed: 0.0282s/iter; left time: 453.7541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 226 | Train Loss: 0.0054394 Vali Loss: 0.0082124 Test Loss: 0.0099311\n",
      "Validation loss decreased (0.008227 --> 0.008212).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0048695\n",
      "\tspeed: 0.0679s/iter; left time: 1082.1081s\n",
      "\titers: 200, epoch: 30 | loss: 0.0057108\n",
      "\tspeed: 0.0248s/iter; left time: 392.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0054387 Vali Loss: 0.0082322 Test Loss: 0.0099606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0055624\n",
      "\tspeed: 0.0740s/iter; left time: 1163.9512s\n",
      "\titers: 200, epoch: 31 | loss: 0.0064698\n",
      "\tspeed: 0.0255s/iter; left time: 397.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 226 | Train Loss: 0.0054343 Vali Loss: 0.0082022 Test Loss: 0.0099584\n",
      "Validation loss decreased (0.008212 --> 0.008202).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0054912\n",
      "\tspeed: 0.0617s/iter; left time: 955.7692s\n",
      "\titers: 200, epoch: 32 | loss: 0.0051729\n",
      "\tspeed: 0.0339s/iter; left time: 521.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.0054356 Vali Loss: 0.0082200 Test Loss: 0.0099480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0066934\n",
      "\tspeed: 0.0711s/iter; left time: 1084.9728s\n",
      "\titers: 200, epoch: 33 | loss: 0.0061226\n",
      "\tspeed: 0.0178s/iter; left time: 269.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 226 | Train Loss: 0.0054288 Vali Loss: 0.0082018 Test Loss: 0.0099535\n",
      "Validation loss decreased (0.008202 --> 0.008202).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0048274\n",
      "\tspeed: 0.0417s/iter; left time: 627.2623s\n",
      "\titers: 200, epoch: 34 | loss: 0.0058461\n",
      "\tspeed: 0.0167s/iter; left time: 250.1951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0054293 Vali Loss: 0.0082111 Test Loss: 0.0099458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0048740\n",
      "\tspeed: 0.0500s/iter; left time: 740.2860s\n",
      "\titers: 200, epoch: 35 | loss: 0.0052270\n",
      "\tspeed: 0.0274s/iter; left time: 402.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0054257 Vali Loss: 0.0082203 Test Loss: 0.0099352\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0060480\n",
      "\tspeed: 0.0671s/iter; left time: 978.6669s\n",
      "\titers: 200, epoch: 36 | loss: 0.0057200\n",
      "\tspeed: 0.0268s/iter; left time: 388.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0054139 Vali Loss: 0.0082122 Test Loss: 0.0099516\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0050441\n",
      "\tspeed: 0.0637s/iter; left time: 914.9044s\n",
      "\titers: 200, epoch: 37 | loss: 0.0059495\n",
      "\tspeed: 0.0318s/iter; left time: 453.1156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 226 | Train Loss: 0.0054095 Vali Loss: 0.0082246 Test Loss: 0.0099409\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0051967\n",
      "\tspeed: 0.0659s/iter; left time: 932.4604s\n",
      "\titers: 200, epoch: 38 | loss: 0.0059897\n",
      "\tspeed: 0.0320s/iter; left time: 448.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0053976 Vali Loss: 0.0082012 Test Loss: 0.0099508\n",
      "Validation loss decreased (0.008202 --> 0.008201).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0052787\n",
      "\tspeed: 0.0695s/iter; left time: 966.4156s\n",
      "\titers: 200, epoch: 39 | loss: 0.0047258\n",
      "\tspeed: 0.0318s/iter; left time: 439.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0054121 Vali Loss: 0.0082163 Test Loss: 0.0099372\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0047600\n",
      "\tspeed: 0.0667s/iter; left time: 913.5721s\n",
      "\titers: 200, epoch: 40 | loss: 0.0060419\n",
      "\tspeed: 0.0279s/iter; left time: 379.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 226 | Train Loss: 0.0054035 Vali Loss: 0.0082144 Test Loss: 0.0099391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0053946\n",
      "\tspeed: 0.0674s/iter; left time: 907.4149s\n",
      "\titers: 200, epoch: 41 | loss: 0.0048580\n",
      "\tspeed: 0.0308s/iter; left time: 411.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 226 | Train Loss: 0.0054028 Vali Loss: 0.0082137 Test Loss: 0.0099513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0053619\n",
      "\tspeed: 0.0728s/iter; left time: 963.1081s\n",
      "\titers: 200, epoch: 42 | loss: 0.0055491\n",
      "\tspeed: 0.0300s/iter; left time: 394.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 226 | Train Loss: 0.0054027 Vali Loss: 0.0081900 Test Loss: 0.0099411\n",
      "Validation loss decreased (0.008201 --> 0.008190).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0055729\n",
      "\tspeed: 0.0746s/iter; left time: 971.0289s\n",
      "\titers: 200, epoch: 43 | loss: 0.0051776\n",
      "\tspeed: 0.0278s/iter; left time: 359.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0054087 Vali Loss: 0.0082251 Test Loss: 0.0099428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0065977\n",
      "\tspeed: 0.0757s/iter; left time: 967.1938s\n",
      "\titers: 200, epoch: 44 | loss: 0.0057450\n",
      "\tspeed: 0.0321s/iter; left time: 406.8943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 226 | Train Loss: 0.0053970 Vali Loss: 0.0082129 Test Loss: 0.0099601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0049890\n",
      "\tspeed: 0.0751s/iter; left time: 942.9276s\n",
      "\titers: 200, epoch: 45 | loss: 0.0063225\n",
      "\tspeed: 0.0308s/iter; left time: 383.7337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 226 | Train Loss: 0.0053993 Vali Loss: 0.0082445 Test Loss: 0.0099413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0051483\n",
      "\tspeed: 0.0765s/iter; left time: 942.8198s\n",
      "\titers: 200, epoch: 46 | loss: 0.0049865\n",
      "\tspeed: 0.0303s/iter; left time: 370.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0053943 Vali Loss: 0.0082098 Test Loss: 0.0099457\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0052320\n",
      "\tspeed: 0.0796s/iter; left time: 964.0414s\n",
      "\titers: 200, epoch: 47 | loss: 0.0059659\n",
      "\tspeed: 0.0293s/iter; left time: 351.7331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0053895 Vali Loss: 0.0081924 Test Loss: 0.0099481\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0055492\n",
      "\tspeed: 0.0707s/iter; left time: 839.5113s\n",
      "\titers: 200, epoch: 48 | loss: 0.0043556\n",
      "\tspeed: 0.0293s/iter; left time: 345.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 226 | Train Loss: 0.0053922 Vali Loss: 0.0082154 Test Loss: 0.0099448\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0051179\n",
      "\tspeed: 0.0767s/iter; left time: 893.7971s\n",
      "\titers: 200, epoch: 49 | loss: 0.0056693\n",
      "\tspeed: 0.0318s/iter; left time: 366.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 226 | Train Loss: 0.0053863 Vali Loss: 0.0081961 Test Loss: 0.0099444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0054214\n",
      "\tspeed: 0.0731s/iter; left time: 835.1078s\n",
      "\titers: 200, epoch: 50 | loss: 0.0059862\n",
      "\tspeed: 0.0274s/iter; left time: 309.9842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 226 | Train Loss: 0.0053821 Vali Loss: 0.0082106 Test Loss: 0.0099440\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0053560\n",
      "\tspeed: 0.0720s/iter; left time: 806.7189s\n",
      "\titers: 200, epoch: 51 | loss: 0.0060457\n",
      "\tspeed: 0.0293s/iter; left time: 325.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.0053953 Vali Loss: 0.0082016 Test Loss: 0.0099440\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0059672\n",
      "\tspeed: 0.0650s/iter; left time: 712.8809s\n",
      "\titers: 200, epoch: 52 | loss: 0.0054211\n",
      "\tspeed: 0.0311s/iter; left time: 338.3667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0053981 Vali Loss: 0.0081929 Test Loss: 0.0099474\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009941143915057182, rmse:0.0997052863240242, mae:0.056643787771463394, rse:0.3846602439880371\n",
      "Intermediate time for FR and pred_len 24: 00h:08m:31.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0242119\n",
      "\tspeed: 0.0675s/iter; left time: 1512.1852s\n",
      "\titers: 200, epoch: 1 | loss: 0.0189905\n",
      "\tspeed: 0.0330s/iter; left time: 736.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 225 | Train Loss: 0.0249051 Vali Loss: 0.0217590 Test Loss: 0.0277699\n",
      "Validation loss decreased (inf --> 0.021759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0133864\n",
      "\tspeed: 0.0747s/iter; left time: 1657.5674s\n",
      "\titers: 200, epoch: 2 | loss: 0.0129357\n",
      "\tspeed: 0.0305s/iter; left time: 674.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 225 | Train Loss: 0.0133166 Vali Loss: 0.0155336 Test Loss: 0.0199100\n",
      "Validation loss decreased (0.021759 --> 0.015534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0114889\n",
      "\tspeed: 0.0740s/iter; left time: 1624.7860s\n",
      "\titers: 200, epoch: 3 | loss: 0.0128945\n",
      "\tspeed: 0.0365s/iter; left time: 797.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 225 | Train Loss: 0.0115833 Vali Loss: 0.0146534 Test Loss: 0.0191689\n",
      "Validation loss decreased (0.015534 --> 0.014653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0096506\n",
      "\tspeed: 0.0867s/iter; left time: 1883.9506s\n",
      "\titers: 200, epoch: 4 | loss: 0.0106959\n",
      "\tspeed: 0.0409s/iter; left time: 884.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 225 | Train Loss: 0.0110096 Vali Loss: 0.0143571 Test Loss: 0.0189645\n",
      "Validation loss decreased (0.014653 --> 0.014357).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0110854\n",
      "\tspeed: 0.0926s/iter; left time: 1990.0259s\n",
      "\titers: 200, epoch: 5 | loss: 0.0108944\n",
      "\tspeed: 0.0498s/iter; left time: 1066.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 225 | Train Loss: 0.0107397 Vali Loss: 0.0141109 Test Loss: 0.0188817\n",
      "Validation loss decreased (0.014357 --> 0.014111).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0105365\n",
      "\tspeed: 0.0972s/iter; left time: 2067.5188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0099358\n",
      "\tspeed: 0.0439s/iter; left time: 929.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.0105499 Vali Loss: 0.0140572 Test Loss: 0.0187163\n",
      "Validation loss decreased (0.014111 --> 0.014057).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0089927\n",
      "\tspeed: 0.0978s/iter; left time: 2057.8290s\n",
      "\titers: 200, epoch: 7 | loss: 0.0099737\n",
      "\tspeed: 0.0451s/iter; left time: 945.7169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.91s\n",
      "Steps: 225 | Train Loss: 0.0103798 Vali Loss: 0.0140918 Test Loss: 0.0186790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0118735\n",
      "\tspeed: 0.0945s/iter; left time: 1969.0095s\n",
      "\titers: 200, epoch: 8 | loss: 0.0107587\n",
      "\tspeed: 0.0449s/iter; left time: 930.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.89s\n",
      "Steps: 225 | Train Loss: 0.0102556 Vali Loss: 0.0141602 Test Loss: 0.0188255\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0094852\n",
      "\tspeed: 0.1207s/iter; left time: 2487.4936s\n",
      "\titers: 200, epoch: 9 | loss: 0.0104117\n",
      "\tspeed: 0.0472s/iter; left time: 967.2519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 225 | Train Loss: 0.0101461 Vali Loss: 0.0141134 Test Loss: 0.0188376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0100241\n",
      "\tspeed: 0.0948s/iter; left time: 1931.4085s\n",
      "\titers: 200, epoch: 10 | loss: 0.0114260\n",
      "\tspeed: 0.0498s/iter; left time: 1010.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.84s\n",
      "Steps: 225 | Train Loss: 0.0100464 Vali Loss: 0.0139718 Test Loss: 0.0186181\n",
      "Validation loss decreased (0.014057 --> 0.013972).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0092512\n",
      "\tspeed: 0.0860s/iter; left time: 1732.0959s\n",
      "\titers: 200, epoch: 11 | loss: 0.0105780\n",
      "\tspeed: 0.0528s/iter; left time: 1057.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.76s\n",
      "Steps: 225 | Train Loss: 0.0099659 Vali Loss: 0.0140622 Test Loss: 0.0185865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0095099\n",
      "\tspeed: 0.0871s/iter; left time: 1734.6307s\n",
      "\titers: 200, epoch: 12 | loss: 0.0113929\n",
      "\tspeed: 0.0470s/iter; left time: 932.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 225 | Train Loss: 0.0098971 Vali Loss: 0.0139690 Test Loss: 0.0185923\n",
      "Validation loss decreased (0.013972 --> 0.013969).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0089053\n",
      "\tspeed: 0.1034s/iter; left time: 2036.4028s\n",
      "\titers: 200, epoch: 13 | loss: 0.0110970\n",
      "\tspeed: 0.0519s/iter; left time: 1017.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 225 | Train Loss: 0.0098009 Vali Loss: 0.0139987 Test Loss: 0.0186758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0104156\n",
      "\tspeed: 0.0910s/iter; left time: 1772.4151s\n",
      "\titers: 200, epoch: 14 | loss: 0.0107352\n",
      "\tspeed: 0.0482s/iter; left time: 933.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 225 | Train Loss: 0.0097639 Vali Loss: 0.0139314 Test Loss: 0.0185757\n",
      "Validation loss decreased (0.013969 --> 0.013931).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0100680\n",
      "\tspeed: 0.0957s/iter; left time: 1842.1949s\n",
      "\titers: 200, epoch: 15 | loss: 0.0093769\n",
      "\tspeed: 0.0449s/iter; left time: 860.6688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.0097022 Vali Loss: 0.0140342 Test Loss: 0.0185551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0094552\n",
      "\tspeed: 0.1083s/iter; left time: 2060.6460s\n",
      "\titers: 200, epoch: 16 | loss: 0.0097943\n",
      "\tspeed: 0.0413s/iter; left time: 780.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 225 | Train Loss: 0.0096613 Vali Loss: 0.0140575 Test Loss: 0.0186617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0094170\n",
      "\tspeed: 0.0985s/iter; left time: 1851.9953s\n",
      "\titers: 200, epoch: 17 | loss: 0.0103829\n",
      "\tspeed: 0.0526s/iter; left time: 984.5678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 225 | Train Loss: 0.0096146 Vali Loss: 0.0140356 Test Loss: 0.0187498\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0102264\n",
      "\tspeed: 0.0952s/iter; left time: 1767.6326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0095341\n",
      "\tspeed: 0.0508s/iter; left time: 939.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.05s\n",
      "Steps: 225 | Train Loss: 0.0095707 Vali Loss: 0.0140555 Test Loss: 0.0185867\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0091605\n",
      "\tspeed: 0.0927s/iter; left time: 1700.7312s\n",
      "\titers: 200, epoch: 19 | loss: 0.0093767\n",
      "\tspeed: 0.0475s/iter; left time: 867.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.77s\n",
      "Steps: 225 | Train Loss: 0.0095344 Vali Loss: 0.0140573 Test Loss: 0.0187457\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0095285\n",
      "\tspeed: 0.0843s/iter; left time: 1528.6786s\n",
      "\titers: 200, epoch: 20 | loss: 0.0106554\n",
      "\tspeed: 0.0426s/iter; left time: 767.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 225 | Train Loss: 0.0095132 Vali Loss: 0.0140521 Test Loss: 0.0187558\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0086229\n",
      "\tspeed: 0.0999s/iter; left time: 1787.7186s\n",
      "\titers: 200, epoch: 21 | loss: 0.0081618\n",
      "\tspeed: 0.0500s/iter; left time: 890.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.98s\n",
      "Steps: 225 | Train Loss: 0.0094732 Vali Loss: 0.0140823 Test Loss: 0.0186404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0094810\n",
      "\tspeed: 0.1088s/iter; left time: 1923.6633s\n",
      "\titers: 200, epoch: 22 | loss: 0.0104590\n",
      "\tspeed: 0.0426s/iter; left time: 748.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 225 | Train Loss: 0.0094494 Vali Loss: 0.0140780 Test Loss: 0.0187164\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0111367\n",
      "\tspeed: 0.0701s/iter; left time: 1222.5957s\n",
      "\titers: 200, epoch: 23 | loss: 0.0086470\n",
      "\tspeed: 0.0457s/iter; left time: 792.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 225 | Train Loss: 0.0094175 Vali Loss: 0.0141186 Test Loss: 0.0186971\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0093648\n",
      "\tspeed: 0.0528s/iter; left time: 909.8051s\n",
      "\titers: 200, epoch: 24 | loss: 0.0095880\n",
      "\tspeed: 0.0164s/iter; left time: 281.6998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0093960 Vali Loss: 0.0141392 Test Loss: 0.0187757\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018575744703412056, rmse:0.13629285991191864, mae:0.08204299211502075, rse:0.5272170305252075\n",
      "Intermediate time for FR and pred_len 96: 00h:05m:32.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0265635\n",
      "\tspeed: 0.0575s/iter; left time: 1288.6036s\n",
      "\titers: 200, epoch: 1 | loss: 0.0194377\n",
      "\tspeed: 0.0637s/iter; left time: 1421.3725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.25s\n",
      "Steps: 225 | Train Loss: 0.0264126 Vali Loss: 0.0232208 Test Loss: 0.0288062\n",
      "Validation loss decreased (inf --> 0.023221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0166239\n",
      "\tspeed: 0.1232s/iter; left time: 2731.1538s\n",
      "\titers: 200, epoch: 2 | loss: 0.0140248\n",
      "\tspeed: 0.0609s/iter; left time: 1344.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 225 | Train Loss: 0.0148250 Vali Loss: 0.0169483 Test Loss: 0.0215553\n",
      "Validation loss decreased (0.023221 --> 0.016948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0114372\n",
      "\tspeed: 0.0983s/iter; left time: 2157.7028s\n",
      "\titers: 200, epoch: 3 | loss: 0.0119995\n",
      "\tspeed: 0.0625s/iter; left time: 1366.1036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.62s\n",
      "Steps: 225 | Train Loss: 0.0129030 Vali Loss: 0.0159594 Test Loss: 0.0209190\n",
      "Validation loss decreased (0.016948 --> 0.015959).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0142003\n",
      "\tspeed: 0.0995s/iter; left time: 2161.5971s\n",
      "\titers: 200, epoch: 4 | loss: 0.0132558\n",
      "\tspeed: 0.0528s/iter; left time: 1141.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 225 | Train Loss: 0.0122763 Vali Loss: 0.0157880 Test Loss: 0.0208853\n",
      "Validation loss decreased (0.015959 --> 0.015788).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0120211\n",
      "\tspeed: 0.0914s/iter; left time: 1964.7984s\n",
      "\titers: 200, epoch: 5 | loss: 0.0105536\n",
      "\tspeed: 0.0267s/iter; left time: 570.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 225 | Train Loss: 0.0119905 Vali Loss: 0.0156816 Test Loss: 0.0204916\n",
      "Validation loss decreased (0.015788 --> 0.015682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0112292\n",
      "\tspeed: 0.0656s/iter; left time: 1395.6634s\n",
      "\titers: 200, epoch: 6 | loss: 0.0134623\n",
      "\tspeed: 0.0334s/iter; left time: 706.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 225 | Train Loss: 0.0117887 Vali Loss: 0.0155945 Test Loss: 0.0205650\n",
      "Validation loss decreased (0.015682 --> 0.015595).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0112592\n",
      "\tspeed: 0.1344s/iter; left time: 2828.9337s\n",
      "\titers: 200, epoch: 7 | loss: 0.0118189\n",
      "\tspeed: 0.0585s/iter; left time: 1224.9963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 225 | Train Loss: 0.0116513 Vali Loss: 0.0155949 Test Loss: 0.0205162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0098861\n",
      "\tspeed: 0.1293s/iter; left time: 2692.5948s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110440\n",
      "\tspeed: 0.0488s/iter; left time: 1012.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.72s\n",
      "Steps: 225 | Train Loss: 0.0115205 Vali Loss: 0.0155843 Test Loss: 0.0205340\n",
      "Validation loss decreased (0.015595 --> 0.015584).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0120436\n",
      "\tspeed: 0.1436s/iter; left time: 2958.4088s\n",
      "\titers: 200, epoch: 9 | loss: 0.0117982\n",
      "\tspeed: 0.0414s/iter; left time: 848.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.97s\n",
      "Steps: 225 | Train Loss: 0.0114065 Vali Loss: 0.0155008 Test Loss: 0.0203243\n",
      "Validation loss decreased (0.015584 --> 0.015501).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0118167\n",
      "\tspeed: 0.1751s/iter; left time: 3568.7616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0113397\n",
      "\tspeed: 0.0390s/iter; left time: 789.7745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.05s\n",
      "Steps: 225 | Train Loss: 0.0113024 Vali Loss: 0.0155792 Test Loss: 0.0203798\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0119269\n",
      "\tspeed: 0.1243s/iter; left time: 2505.1871s\n",
      "\titers: 200, epoch: 11 | loss: 0.0098879\n",
      "\tspeed: 0.0551s/iter; left time: 1104.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0112100 Vali Loss: 0.0155863 Test Loss: 0.0206468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0109906\n",
      "\tspeed: 0.1021s/iter; left time: 2034.0708s\n",
      "\titers: 200, epoch: 12 | loss: 0.0112945\n",
      "\tspeed: 0.0530s/iter; left time: 1050.7848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.11s\n",
      "Steps: 225 | Train Loss: 0.0111068 Vali Loss: 0.0156394 Test Loss: 0.0207387\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0111686\n",
      "\tspeed: 0.1442s/iter; left time: 2841.0370s\n",
      "\titers: 200, epoch: 13 | loss: 0.0104042\n",
      "\tspeed: 0.0527s/iter; left time: 1033.8337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 225 | Train Loss: 0.0110203 Vali Loss: 0.0156567 Test Loss: 0.0205409\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0118282\n",
      "\tspeed: 0.1576s/iter; left time: 3070.3153s\n",
      "\titers: 200, epoch: 14 | loss: 0.0114619\n",
      "\tspeed: 0.0391s/iter; left time: 757.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 225 | Train Loss: 0.0109452 Vali Loss: 0.0157138 Test Loss: 0.0208073\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0103363\n",
      "\tspeed: 0.1424s/iter; left time: 2741.6020s\n",
      "\titers: 200, epoch: 15 | loss: 0.0099776\n",
      "\tspeed: 0.0421s/iter; left time: 805.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 225 | Train Loss: 0.0108966 Vali Loss: 0.0157213 Test Loss: 0.0208918\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0109692\n",
      "\tspeed: 0.1228s/iter; left time: 2336.9919s\n",
      "\titers: 200, epoch: 16 | loss: 0.0112045\n",
      "\tspeed: 0.0531s/iter; left time: 1004.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 225 | Train Loss: 0.0108314 Vali Loss: 0.0157334 Test Loss: 0.0208079\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0108547\n",
      "\tspeed: 0.1590s/iter; left time: 2989.3833s\n",
      "\titers: 200, epoch: 17 | loss: 0.0111214\n",
      "\tspeed: 0.0454s/iter; left time: 849.6576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 225 | Train Loss: 0.0107619 Vali Loss: 0.0157618 Test Loss: 0.0209842\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0103792\n",
      "\tspeed: 0.1284s/iter; left time: 2385.9108s\n",
      "\titers: 200, epoch: 18 | loss: 0.0104057\n",
      "\tspeed: 0.0278s/iter; left time: 513.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 225 | Train Loss: 0.0107229 Vali Loss: 0.0157928 Test Loss: 0.0209592\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0105714\n",
      "\tspeed: 0.1042s/iter; left time: 1911.7321s\n",
      "\titers: 200, epoch: 19 | loss: 0.0113793\n",
      "\tspeed: 0.0387s/iter; left time: 706.2586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.63s\n",
      "Steps: 225 | Train Loss: 0.0106709 Vali Loss: 0.0158113 Test Loss: 0.0211378\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020324300974607468, rmse:0.1425633281469345, mae:0.08861789107322693, rse:0.5521612763404846\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:31.76s\n",
      "Intermediate time for FR: 00h:19m:35.55s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0427644\n",
      "\tspeed: 0.0485s/iter; left time: 1090.3603s\n",
      "\titers: 200, epoch: 1 | loss: 0.0291665\n",
      "\tspeed: 0.0382s/iter; left time: 855.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 226 | Train Loss: 0.0426089 Vali Loss: 0.0234300 Test Loss: 0.0253591\n",
      "Validation loss decreased (inf --> 0.023430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0135666\n",
      "\tspeed: 0.0784s/iter; left time: 1746.0179s\n",
      "\titers: 200, epoch: 2 | loss: 0.0129317\n",
      "\tspeed: 0.0320s/iter; left time: 709.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.0153345 Vali Loss: 0.0111285 Test Loss: 0.0120855\n",
      "Validation loss decreased (0.023430 --> 0.011128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0125586\n",
      "\tspeed: 0.0749s/iter; left time: 1650.5465s\n",
      "\titers: 200, epoch: 3 | loss: 0.0112898\n",
      "\tspeed: 0.0305s/iter; left time: 669.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 226 | Train Loss: 0.0119622 Vali Loss: 0.0103058 Test Loss: 0.0113176\n",
      "Validation loss decreased (0.011128 --> 0.010306).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0107425\n",
      "\tspeed: 0.0881s/iter; left time: 1922.8519s\n",
      "\titers: 200, epoch: 4 | loss: 0.0094230\n",
      "\tspeed: 0.0280s/iter; left time: 607.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.0111439 Vali Loss: 0.0099383 Test Loss: 0.0109307\n",
      "Validation loss decreased (0.010306 --> 0.009938).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0119819\n",
      "\tspeed: 0.0759s/iter; left time: 1640.1053s\n",
      "\titers: 200, epoch: 5 | loss: 0.0102829\n",
      "\tspeed: 0.0475s/iter; left time: 1020.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 226 | Train Loss: 0.0106644 Vali Loss: 0.0096654 Test Loss: 0.0106351\n",
      "Validation loss decreased (0.009938 --> 0.009665).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0100474\n",
      "\tspeed: 0.0543s/iter; left time: 1160.2392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0094613\n",
      "\tspeed: 0.0169s/iter; left time: 360.1263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 226 | Train Loss: 0.0103493 Vali Loss: 0.0094481 Test Loss: 0.0103848\n",
      "Validation loss decreased (0.009665 --> 0.009448).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0118266\n",
      "\tspeed: 0.0504s/iter; left time: 1064.8666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0097277\n",
      "\tspeed: 0.0271s/iter; left time: 571.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 226 | Train Loss: 0.0101450 Vali Loss: 0.0094589 Test Loss: 0.0103997\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0095389\n",
      "\tspeed: 0.0705s/iter; left time: 1475.8192s\n",
      "\titers: 200, epoch: 8 | loss: 0.0106729\n",
      "\tspeed: 0.0472s/iter; left time: 982.7192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 226 | Train Loss: 0.0100044 Vali Loss: 0.0093035 Test Loss: 0.0102250\n",
      "Validation loss decreased (0.009448 --> 0.009303).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0097942\n",
      "\tspeed: 0.0720s/iter; left time: 1490.8777s\n",
      "\titers: 200, epoch: 9 | loss: 0.0097993\n",
      "\tspeed: 0.0329s/iter; left time: 677.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 226 | Train Loss: 0.0098369 Vali Loss: 0.0092346 Test Loss: 0.0102146\n",
      "Validation loss decreased (0.009303 --> 0.009235).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0099564\n",
      "\tspeed: 0.0960s/iter; left time: 1964.7149s\n",
      "\titers: 200, epoch: 10 | loss: 0.0102991\n",
      "\tspeed: 0.0246s/iter; left time: 501.4904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.0097580 Vali Loss: 0.0091586 Test Loss: 0.0100977\n",
      "Validation loss decreased (0.009235 --> 0.009159).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0086434\n",
      "\tspeed: 0.0542s/iter; left time: 1098.0237s\n",
      "\titers: 200, epoch: 11 | loss: 0.0096359\n",
      "\tspeed: 0.0195s/iter; left time: 392.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 226 | Train Loss: 0.0096705 Vali Loss: 0.0092086 Test Loss: 0.0101226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0111360\n",
      "\tspeed: 0.0692s/iter; left time: 1384.2870s\n",
      "\titers: 200, epoch: 12 | loss: 0.0106724\n",
      "\tspeed: 0.0313s/iter; left time: 623.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0096070 Vali Loss: 0.0090734 Test Loss: 0.0100747\n",
      "Validation loss decreased (0.009159 --> 0.009073).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0089536\n",
      "\tspeed: 0.0839s/iter; left time: 1661.1133s\n",
      "\titers: 200, epoch: 13 | loss: 0.0075973\n",
      "\tspeed: 0.0343s/iter; left time: 675.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 226 | Train Loss: 0.0095315 Vali Loss: 0.0090904 Test Loss: 0.0100318\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0101849\n",
      "\tspeed: 0.0684s/iter; left time: 1337.6736s\n",
      "\titers: 200, epoch: 14 | loss: 0.0094804\n",
      "\tspeed: 0.0323s/iter; left time: 628.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0094820 Vali Loss: 0.0090765 Test Loss: 0.0100181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0085579\n",
      "\tspeed: 0.0862s/iter; left time: 1666.6054s\n",
      "\titers: 200, epoch: 15 | loss: 0.0107631\n",
      "\tspeed: 0.0283s/iter; left time: 543.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0094281 Vali Loss: 0.0090492 Test Loss: 0.0100166\n",
      "Validation loss decreased (0.009073 --> 0.009049).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0101539\n",
      "\tspeed: 0.0720s/iter; left time: 1376.7790s\n",
      "\titers: 200, epoch: 16 | loss: 0.0084199\n",
      "\tspeed: 0.0500s/iter; left time: 950.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 226 | Train Loss: 0.0093823 Vali Loss: 0.0091001 Test Loss: 0.0100515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0090759\n",
      "\tspeed: 0.0736s/iter; left time: 1389.6985s\n",
      "\titers: 200, epoch: 17 | loss: 0.0091737\n",
      "\tspeed: 0.0274s/iter; left time: 514.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 226 | Train Loss: 0.0093435 Vali Loss: 0.0090378 Test Loss: 0.0099843\n",
      "Validation loss decreased (0.009049 --> 0.009038).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0101232\n",
      "\tspeed: 0.0948s/iter; left time: 1768.0497s\n",
      "\titers: 200, epoch: 18 | loss: 0.0084545\n",
      "\tspeed: 0.0276s/iter; left time: 512.0467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 226 | Train Loss: 0.0093282 Vali Loss: 0.0090161 Test Loss: 0.0099726\n",
      "Validation loss decreased (0.009038 --> 0.009016).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0101296\n",
      "\tspeed: 0.0672s/iter; left time: 1237.9290s\n",
      "\titers: 200, epoch: 19 | loss: 0.0081247\n",
      "\tspeed: 0.0481s/iter; left time: 881.0214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 226 | Train Loss: 0.0093000 Vali Loss: 0.0090169 Test Loss: 0.0099598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0085207\n",
      "\tspeed: 0.0729s/iter; left time: 1327.4617s\n",
      "\titers: 200, epoch: 20 | loss: 0.0106575\n",
      "\tspeed: 0.0293s/iter; left time: 530.2584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 226 | Train Loss: 0.0092577 Vali Loss: 0.0090158 Test Loss: 0.0099629\n",
      "Validation loss decreased (0.009016 --> 0.009016).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0096524\n",
      "\tspeed: 0.0881s/iter; left time: 1583.2618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0096965\n",
      "\tspeed: 0.0301s/iter; left time: 539.0862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 226 | Train Loss: 0.0092286 Vali Loss: 0.0090278 Test Loss: 0.0099740\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0085044\n",
      "\tspeed: 0.0778s/iter; left time: 1381.4710s\n",
      "\titers: 200, epoch: 22 | loss: 0.0097745\n",
      "\tspeed: 0.0318s/iter; left time: 560.9670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 226 | Train Loss: 0.0092048 Vali Loss: 0.0090266 Test Loss: 0.0099292\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0081876\n",
      "\tspeed: 0.0867s/iter; left time: 1518.9184s\n",
      "\titers: 200, epoch: 23 | loss: 0.0080436\n",
      "\tspeed: 0.0394s/iter; left time: 686.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 226 | Train Loss: 0.0091790 Vali Loss: 0.0089924 Test Loss: 0.0099458\n",
      "Validation loss decreased (0.009016 --> 0.008992).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0080196\n",
      "\tspeed: 0.0745s/iter; left time: 1289.3025s\n",
      "\titers: 200, epoch: 24 | loss: 0.0102902\n",
      "\tspeed: 0.0409s/iter; left time: 703.0702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.00s\n",
      "Steps: 226 | Train Loss: 0.0091637 Vali Loss: 0.0089613 Test Loss: 0.0099342\n",
      "Validation loss decreased (0.008992 --> 0.008961).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0088788\n",
      "\tspeed: 0.0683s/iter; left time: 1166.8872s\n",
      "\titers: 200, epoch: 25 | loss: 0.0095923\n",
      "\tspeed: 0.0273s/iter; left time: 463.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 226 | Train Loss: 0.0091597 Vali Loss: 0.0090058 Test Loss: 0.0099207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0080711\n",
      "\tspeed: 0.0949s/iter; left time: 1599.0179s\n",
      "\titers: 200, epoch: 26 | loss: 0.0104032\n",
      "\tspeed: 0.0285s/iter; left time: 476.6298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 226 | Train Loss: 0.0091317 Vali Loss: 0.0089826 Test Loss: 0.0099222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0088905\n",
      "\tspeed: 0.0767s/iter; left time: 1274.4187s\n",
      "\titers: 200, epoch: 27 | loss: 0.0105031\n",
      "\tspeed: 0.0455s/iter; left time: 751.4591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 226 | Train Loss: 0.0091199 Vali Loss: 0.0089627 Test Loss: 0.0099322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0093362\n",
      "\tspeed: 0.0723s/iter; left time: 1186.0515s\n",
      "\titers: 200, epoch: 28 | loss: 0.0086763\n",
      "\tspeed: 0.0279s/iter; left time: 455.4829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 226 | Train Loss: 0.0091062 Vali Loss: 0.0089637 Test Loss: 0.0099520\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0090730\n",
      "\tspeed: 0.0927s/iter; left time: 1498.8831s\n",
      "\titers: 200, epoch: 29 | loss: 0.0088845\n",
      "\tspeed: 0.0286s/iter; left time: 458.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 226 | Train Loss: 0.0090892 Vali Loss: 0.0089406 Test Loss: 0.0098978\n",
      "Validation loss decreased (0.008961 --> 0.008941).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0076724\n",
      "\tspeed: 0.0758s/iter; left time: 1208.3972s\n",
      "\titers: 200, epoch: 30 | loss: 0.0101498\n",
      "\tspeed: 0.0227s/iter; left time: 359.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0090841 Vali Loss: 0.0089625 Test Loss: 0.0099098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0089099\n",
      "\tspeed: 0.0460s/iter; left time: 723.2144s\n",
      "\titers: 200, epoch: 31 | loss: 0.0098940\n",
      "\tspeed: 0.0187s/iter; left time: 292.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 226 | Train Loss: 0.0090745 Vali Loss: 0.0089565 Test Loss: 0.0099237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0088118\n",
      "\tspeed: 0.0736s/iter; left time: 1140.6685s\n",
      "\titers: 200, epoch: 32 | loss: 0.0087904\n",
      "\tspeed: 0.0433s/iter; left time: 667.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.97s\n",
      "Steps: 226 | Train Loss: 0.0090637 Vali Loss: 0.0089329 Test Loss: 0.0099249\n",
      "Validation loss decreased (0.008941 --> 0.008933).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0092595\n",
      "\tspeed: 0.0701s/iter; left time: 1069.9731s\n",
      "\titers: 200, epoch: 33 | loss: 0.0082681\n",
      "\tspeed: 0.0255s/iter; left time: 386.6213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0090772 Vali Loss: 0.0089731 Test Loss: 0.0099125\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0079741\n",
      "\tspeed: 0.0814s/iter; left time: 1224.5307s\n",
      "\titers: 200, epoch: 34 | loss: 0.0097403\n",
      "\tspeed: 0.0221s/iter; left time: 330.0705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0090595 Vali Loss: 0.0089322 Test Loss: 0.0098990\n",
      "Validation loss decreased (0.008933 --> 0.008932).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0085803\n",
      "\tspeed: 0.0440s/iter; left time: 651.3799s\n",
      "\titers: 200, epoch: 35 | loss: 0.0098124\n",
      "\tspeed: 0.0167s/iter; left time: 246.1038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0090542 Vali Loss: 0.0089748 Test Loss: 0.0099321\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0090371\n",
      "\tspeed: 0.0579s/iter; left time: 844.3759s\n",
      "\titers: 200, epoch: 36 | loss: 0.0094171\n",
      "\tspeed: 0.0291s/iter; left time: 421.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 226 | Train Loss: 0.0090484 Vali Loss: 0.0089509 Test Loss: 0.0099013\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0090749\n",
      "\tspeed: 0.0663s/iter; left time: 952.4311s\n",
      "\titers: 200, epoch: 37 | loss: 0.0093885\n",
      "\tspeed: 0.0299s/iter; left time: 426.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 226 | Train Loss: 0.0090552 Vali Loss: 0.0089714 Test Loss: 0.0099124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0082394\n",
      "\tspeed: 0.0646s/iter; left time: 913.2864s\n",
      "\titers: 200, epoch: 38 | loss: 0.0093596\n",
      "\tspeed: 0.0284s/iter; left time: 398.0774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 226 | Train Loss: 0.0090332 Vali Loss: 0.0089565 Test Loss: 0.0099143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0078252\n",
      "\tspeed: 0.0658s/iter; left time: 915.5177s\n",
      "\titers: 200, epoch: 39 | loss: 0.0088208\n",
      "\tspeed: 0.0284s/iter; left time: 391.9578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0090471 Vali Loss: 0.0089371 Test Loss: 0.0099035\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0105462\n",
      "\tspeed: 0.0692s/iter; left time: 946.7984s\n",
      "\titers: 200, epoch: 40 | loss: 0.0090573\n",
      "\tspeed: 0.0267s/iter; left time: 362.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 226 | Train Loss: 0.0090234 Vali Loss: 0.0089457 Test Loss: 0.0099033\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0088055\n",
      "\tspeed: 0.0689s/iter; left time: 927.3560s\n",
      "\titers: 200, epoch: 41 | loss: 0.0104520\n",
      "\tspeed: 0.0307s/iter; left time: 409.8555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0090427 Vali Loss: 0.0089316 Test Loss: 0.0098993\n",
      "Validation loss decreased (0.008932 --> 0.008932).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0084742\n",
      "\tspeed: 0.0626s/iter; left time: 828.2486s\n",
      "\titers: 200, epoch: 42 | loss: 0.0093432\n",
      "\tspeed: 0.0293s/iter; left time: 384.9107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 226 | Train Loss: 0.0090335 Vali Loss: 0.0089267 Test Loss: 0.0098911\n",
      "Validation loss decreased (0.008932 --> 0.008927).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0097170\n",
      "\tspeed: 0.0640s/iter; left time: 832.3867s\n",
      "\titers: 200, epoch: 43 | loss: 0.0076540\n",
      "\tspeed: 0.0258s/iter; left time: 333.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0090321 Vali Loss: 0.0089353 Test Loss: 0.0099073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0092617\n",
      "\tspeed: 0.0661s/iter; left time: 844.9406s\n",
      "\titers: 200, epoch: 44 | loss: 0.0087024\n",
      "\tspeed: 0.0270s/iter; left time: 342.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 226 | Train Loss: 0.0090337 Vali Loss: 0.0089408 Test Loss: 0.0098926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0088285\n",
      "\tspeed: 0.0683s/iter; left time: 857.2198s\n",
      "\titers: 200, epoch: 45 | loss: 0.0092159\n",
      "\tspeed: 0.0281s/iter; left time: 350.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 226 | Train Loss: 0.0090323 Vali Loss: 0.0089285 Test Loss: 0.0098980\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0102098\n",
      "\tspeed: 0.0723s/iter; left time: 892.0211s\n",
      "\titers: 200, epoch: 46 | loss: 0.0079350\n",
      "\tspeed: 0.0298s/iter; left time: 364.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0090227 Vali Loss: 0.0089318 Test Loss: 0.0099059\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0093856\n",
      "\tspeed: 0.0618s/iter; left time: 747.8551s\n",
      "\titers: 200, epoch: 47 | loss: 0.0095248\n",
      "\tspeed: 0.0301s/iter; left time: 361.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 226 | Train Loss: 0.0090159 Vali Loss: 0.0089450 Test Loss: 0.0099015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0090503\n",
      "\tspeed: 0.0618s/iter; left time: 733.6224s\n",
      "\titers: 200, epoch: 48 | loss: 0.0091753\n",
      "\tspeed: 0.0255s/iter; left time: 300.4921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0090108 Vali Loss: 0.0089341 Test Loss: 0.0098960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0083525\n",
      "\tspeed: 0.0668s/iter; left time: 778.0072s\n",
      "\titers: 200, epoch: 49 | loss: 0.0098274\n",
      "\tspeed: 0.0252s/iter; left time: 290.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0090235 Vali Loss: 0.0089498 Test Loss: 0.0099027\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0091457\n",
      "\tspeed: 0.0693s/iter; left time: 792.4603s\n",
      "\titers: 200, epoch: 50 | loss: 0.0105588\n",
      "\tspeed: 0.0300s/iter; left time: 339.4670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0090247 Vali Loss: 0.0089380 Test Loss: 0.0098937\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0099731\n",
      "\tspeed: 0.0644s/iter; left time: 721.2085s\n",
      "\titers: 200, epoch: 51 | loss: 0.0085722\n",
      "\tspeed: 0.0298s/iter; left time: 331.1560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 226 | Train Loss: 0.0090074 Vali Loss: 0.0089378 Test Loss: 0.0098993\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0085397\n",
      "\tspeed: 0.0627s/iter; left time: 688.5853s\n",
      "\titers: 200, epoch: 52 | loss: 0.0099546\n",
      "\tspeed: 0.0294s/iter; left time: 319.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0090018 Vali Loss: 0.0089331 Test Loss: 0.0099019\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009891098365187645, rmse:0.09945400059223175, mae:0.05819772183895111, rse:0.3757877051830292\n",
      "Intermediate time for IT and pred_len 24: 00h:08m:58.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0462537\n",
      "\tspeed: 0.0689s/iter; left time: 1543.6157s\n",
      "\titers: 200, epoch: 1 | loss: 0.0364715\n",
      "\tspeed: 0.0280s/iter; left time: 625.0756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 225 | Train Loss: 0.0460628 Vali Loss: 0.0273578 Test Loss: 0.0298426\n",
      "Validation loss decreased (inf --> 0.027358).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0235899\n",
      "\tspeed: 0.0676s/iter; left time: 1498.9230s\n",
      "\titers: 200, epoch: 2 | loss: 0.0210041\n",
      "\tspeed: 0.0362s/iter; left time: 798.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 225 | Train Loss: 0.0232539 Vali Loss: 0.0176938 Test Loss: 0.0193522\n",
      "Validation loss decreased (0.027358 --> 0.017694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0189749\n",
      "\tspeed: 0.0678s/iter; left time: 1488.1416s\n",
      "\titers: 200, epoch: 3 | loss: 0.0182328\n",
      "\tspeed: 0.0338s/iter; left time: 738.0705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 225 | Train Loss: 0.0193855 Vali Loss: 0.0168231 Test Loss: 0.0184362\n",
      "Validation loss decreased (0.017694 --> 0.016823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0177972\n",
      "\tspeed: 0.0729s/iter; left time: 1583.3243s\n",
      "\titers: 200, epoch: 4 | loss: 0.0183742\n",
      "\tspeed: 0.0332s/iter; left time: 718.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 225 | Train Loss: 0.0185190 Vali Loss: 0.0164864 Test Loss: 0.0181530\n",
      "Validation loss decreased (0.016823 --> 0.016486).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0168590\n",
      "\tspeed: 0.0798s/iter; left time: 1714.9373s\n",
      "\titers: 200, epoch: 5 | loss: 0.0164473\n",
      "\tspeed: 0.0296s/iter; left time: 633.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 225 | Train Loss: 0.0180803 Vali Loss: 0.0164282 Test Loss: 0.0180659\n",
      "Validation loss decreased (0.016486 --> 0.016428).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0169709\n",
      "\tspeed: 0.0739s/iter; left time: 1572.3145s\n",
      "\titers: 200, epoch: 6 | loss: 0.0191333\n",
      "\tspeed: 0.0322s/iter; left time: 682.7761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 225 | Train Loss: 0.0177726 Vali Loss: 0.0161812 Test Loss: 0.0177180\n",
      "Validation loss decreased (0.016428 --> 0.016181).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0158284\n",
      "\tspeed: 0.0733s/iter; left time: 1542.2157s\n",
      "\titers: 200, epoch: 7 | loss: 0.0175322\n",
      "\tspeed: 0.0319s/iter; left time: 668.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 225 | Train Loss: 0.0175136 Vali Loss: 0.0161265 Test Loss: 0.0176915\n",
      "Validation loss decreased (0.016181 --> 0.016126).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0174552\n",
      "\tspeed: 0.0818s/iter; left time: 1702.6980s\n",
      "\titers: 200, epoch: 8 | loss: 0.0166485\n",
      "\tspeed: 0.0306s/iter; left time: 635.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 225 | Train Loss: 0.0173040 Vali Loss: 0.0160004 Test Loss: 0.0174142\n",
      "Validation loss decreased (0.016126 --> 0.016000).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0163455\n",
      "\tspeed: 0.0799s/iter; left time: 1646.4733s\n",
      "\titers: 200, epoch: 9 | loss: 0.0154967\n",
      "\tspeed: 0.0335s/iter; left time: 686.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 225 | Train Loss: 0.0171474 Vali Loss: 0.0159577 Test Loss: 0.0173985\n",
      "Validation loss decreased (0.016000 --> 0.015958).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0160120\n",
      "\tspeed: 0.0664s/iter; left time: 1353.1241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0178833\n",
      "\tspeed: 0.0409s/iter; left time: 829.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 225 | Train Loss: 0.0170059 Vali Loss: 0.0159840 Test Loss: 0.0174097\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0159951\n",
      "\tspeed: 0.0929s/iter; left time: 1871.6360s\n",
      "\titers: 200, epoch: 11 | loss: 0.0157917\n",
      "\tspeed: 0.0429s/iter; left time: 860.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 225 | Train Loss: 0.0169099 Vali Loss: 0.0159336 Test Loss: 0.0172732\n",
      "Validation loss decreased (0.015958 --> 0.015934).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0165329\n",
      "\tspeed: 0.0664s/iter; left time: 1323.1145s\n",
      "\titers: 200, epoch: 12 | loss: 0.0170412\n",
      "\tspeed: 0.0182s/iter; left time: 360.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0167639 Vali Loss: 0.0159042 Test Loss: 0.0173147\n",
      "Validation loss decreased (0.015934 --> 0.015904).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0180271\n",
      "\tspeed: 0.0814s/iter; left time: 1603.0954s\n",
      "\titers: 200, epoch: 13 | loss: 0.0178022\n",
      "\tspeed: 0.0400s/iter; left time: 783.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 225 | Train Loss: 0.0166703 Vali Loss: 0.0158887 Test Loss: 0.0171973\n",
      "Validation loss decreased (0.015904 --> 0.015889).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0176169\n",
      "\tspeed: 0.1266s/iter; left time: 2465.5381s\n",
      "\titers: 200, epoch: 14 | loss: 0.0166390\n",
      "\tspeed: 0.0494s/iter; left time: 956.5359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 225 | Train Loss: 0.0165915 Vali Loss: 0.0158640 Test Loss: 0.0172642\n",
      "Validation loss decreased (0.015889 --> 0.015864).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0162922\n",
      "\tspeed: 0.1073s/iter; left time: 2065.5748s\n",
      "\titers: 200, epoch: 15 | loss: 0.0161882\n",
      "\tspeed: 0.0380s/iter; left time: 727.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.32s\n",
      "Steps: 225 | Train Loss: 0.0165111 Vali Loss: 0.0159664 Test Loss: 0.0174457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0164338\n",
      "\tspeed: 0.0877s/iter; left time: 1668.2082s\n",
      "\titers: 200, epoch: 16 | loss: 0.0168174\n",
      "\tspeed: 0.0504s/iter; left time: 954.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 225 | Train Loss: 0.0164226 Vali Loss: 0.0158663 Test Loss: 0.0172530\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0158943\n",
      "\tspeed: 0.1024s/iter; left time: 1924.4480s\n",
      "\titers: 200, epoch: 17 | loss: 0.0164825\n",
      "\tspeed: 0.0454s/iter; left time: 849.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.34s\n",
      "Steps: 225 | Train Loss: 0.0163565 Vali Loss: 0.0159070 Test Loss: 0.0174244\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0174788\n",
      "\tspeed: 0.0993s/iter; left time: 1844.1894s\n",
      "\titers: 200, epoch: 18 | loss: 0.0145421\n",
      "\tspeed: 0.0266s/iter; left time: 490.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0162801 Vali Loss: 0.0158426 Test Loss: 0.0172457\n",
      "Validation loss decreased (0.015864 --> 0.015843).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0168303\n",
      "\tspeed: 0.0720s/iter; left time: 1320.7256s\n",
      "\titers: 200, epoch: 19 | loss: 0.0163630\n",
      "\tspeed: 0.0431s/iter; left time: 785.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 225 | Train Loss: 0.0162624 Vali Loss: 0.0157878 Test Loss: 0.0171725\n",
      "Validation loss decreased (0.015843 --> 0.015788).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0152932\n",
      "\tspeed: 0.1118s/iter; left time: 2026.0311s\n",
      "\titers: 200, epoch: 20 | loss: 0.0158245\n",
      "\tspeed: 0.0545s/iter; left time: 983.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:12.25s\n",
      "Steps: 225 | Train Loss: 0.0161951 Vali Loss: 0.0158540 Test Loss: 0.0172939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0160206\n",
      "\tspeed: 0.0957s/iter; left time: 1713.6502s\n",
      "\titers: 200, epoch: 21 | loss: 0.0143377\n",
      "\tspeed: 0.0489s/iter; left time: 870.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 225 | Train Loss: 0.0161581 Vali Loss: 0.0158551 Test Loss: 0.0173828\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0173990\n",
      "\tspeed: 0.1255s/iter; left time: 2218.2540s\n",
      "\titers: 200, epoch: 22 | loss: 0.0164247\n",
      "\tspeed: 0.0570s/iter; left time: 1002.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.20s\n",
      "Steps: 225 | Train Loss: 0.0161385 Vali Loss: 0.0158426 Test Loss: 0.0173311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0165023\n",
      "\tspeed: 0.1310s/iter; left time: 2286.8177s\n",
      "\titers: 200, epoch: 23 | loss: 0.0158310\n",
      "\tspeed: 0.0618s/iter; left time: 1071.5133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.71s\n",
      "Steps: 225 | Train Loss: 0.0160991 Vali Loss: 0.0158318 Test Loss: 0.0172664\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0162533\n",
      "\tspeed: 0.1002s/iter; left time: 1726.0865s\n",
      "\titers: 200, epoch: 24 | loss: 0.0154683\n",
      "\tspeed: 0.0392s/iter; left time: 671.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 225 | Train Loss: 0.0160415 Vali Loss: 0.0158316 Test Loss: 0.0173423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0155253\n",
      "\tspeed: 0.1592s/iter; left time: 2705.8815s\n",
      "\titers: 200, epoch: 25 | loss: 0.0173770\n",
      "\tspeed: 0.0411s/iter; left time: 694.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 225 | Train Loss: 0.0160281 Vali Loss: 0.0158332 Test Loss: 0.0173701\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0182681\n",
      "\tspeed: 0.1172s/iter; left time: 1966.5665s\n",
      "\titers: 200, epoch: 26 | loss: 0.0169437\n",
      "\tspeed: 0.0589s/iter; left time: 981.8063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 225 | Train Loss: 0.0159760 Vali Loss: 0.0158007 Test Loss: 0.0172860\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0168032\n",
      "\tspeed: 0.1253s/iter; left time: 2073.1897s\n",
      "\titers: 200, epoch: 27 | loss: 0.0156003\n",
      "\tspeed: 0.0590s/iter; left time: 970.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:12.08s\n",
      "Steps: 225 | Train Loss: 0.0159695 Vali Loss: 0.0158024 Test Loss: 0.0172899\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0167254\n",
      "\tspeed: 0.1086s/iter; left time: 1772.7258s\n",
      "\titers: 200, epoch: 28 | loss: 0.0156412\n",
      "\tspeed: 0.0438s/iter; left time: 711.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.0159519 Vali Loss: 0.0158223 Test Loss: 0.0174044\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0168503\n",
      "\tspeed: 0.1492s/iter; left time: 2402.5702s\n",
      "\titers: 200, epoch: 29 | loss: 0.0137340\n",
      "\tspeed: 0.0462s/iter; left time: 739.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:10.80s\n",
      "Steps: 225 | Train Loss: 0.0159480 Vali Loss: 0.0157722 Test Loss: 0.0172937\n",
      "Validation loss decreased (0.015788 --> 0.015772).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0163661\n",
      "\tspeed: 0.1377s/iter; left time: 2186.5077s\n",
      "\titers: 200, epoch: 30 | loss: 0.0171112\n",
      "\tspeed: 0.0534s/iter; left time: 843.0461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 225 | Train Loss: 0.0159193 Vali Loss: 0.0157847 Test Loss: 0.0173282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0153719\n",
      "\tspeed: 0.1280s/iter; left time: 2004.0865s\n",
      "\titers: 200, epoch: 31 | loss: 0.0155335\n",
      "\tspeed: 0.0505s/iter; left time: 785.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.18s\n",
      "Steps: 225 | Train Loss: 0.0159121 Vali Loss: 0.0157999 Test Loss: 0.0173632\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0156373\n",
      "\tspeed: 0.1244s/iter; left time: 1918.2645s\n",
      "\titers: 200, epoch: 32 | loss: 0.0162509\n",
      "\tspeed: 0.0240s/iter; left time: 368.1725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0158688 Vali Loss: 0.0157687 Test Loss: 0.0172948\n",
      "Validation loss decreased (0.015772 --> 0.015769).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0183278\n",
      "\tspeed: 0.0458s/iter; left time: 696.4836s\n",
      "\titers: 200, epoch: 33 | loss: 0.0169869\n",
      "\tspeed: 0.0160s/iter; left time: 242.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0158634 Vali Loss: 0.0157925 Test Loss: 0.0173219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0172865\n",
      "\tspeed: 0.0626s/iter; left time: 937.2979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0153092\n",
      "\tspeed: 0.0428s/iter; left time: 636.7960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 225 | Train Loss: 0.0158540 Vali Loss: 0.0158062 Test Loss: 0.0173842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0161870\n",
      "\tspeed: 0.1479s/iter; left time: 2182.1716s\n",
      "\titers: 200, epoch: 35 | loss: 0.0151124\n",
      "\tspeed: 0.0352s/iter; left time: 515.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 225 | Train Loss: 0.0158580 Vali Loss: 0.0157895 Test Loss: 0.0173378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0166946\n",
      "\tspeed: 0.0992s/iter; left time: 1440.3194s\n",
      "\titers: 200, epoch: 36 | loss: 0.0162752\n",
      "\tspeed: 0.0550s/iter; left time: 793.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:12.02s\n",
      "Steps: 225 | Train Loss: 0.0158467 Vali Loss: 0.0157970 Test Loss: 0.0173953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0172352\n",
      "\tspeed: 0.1000s/iter; left time: 1429.5845s\n",
      "\titers: 200, epoch: 37 | loss: 0.0143222\n",
      "\tspeed: 0.0514s/iter; left time: 730.6271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 225 | Train Loss: 0.0158265 Vali Loss: 0.0157891 Test Loss: 0.0173757\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0172777\n",
      "\tspeed: 0.1148s/iter; left time: 1615.3501s\n",
      "\titers: 200, epoch: 38 | loss: 0.0145041\n",
      "\tspeed: 0.0608s/iter; left time: 850.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 225 | Train Loss: 0.0158066 Vali Loss: 0.0157820 Test Loss: 0.0173516\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0138649\n",
      "\tspeed: 0.1076s/iter; left time: 1489.7403s\n",
      "\titers: 200, epoch: 39 | loss: 0.0156466\n",
      "\tspeed: 0.0451s/iter; left time: 619.9543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 225 | Train Loss: 0.0158153 Vali Loss: 0.0158029 Test Loss: 0.0173771\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0144005\n",
      "\tspeed: 0.1295s/iter; left time: 1765.1740s\n",
      "\titers: 200, epoch: 40 | loss: 0.0168604\n",
      "\tspeed: 0.0376s/iter; left time: 508.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 225 | Train Loss: 0.0158220 Vali Loss: 0.0157745 Test Loss: 0.0173589\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0143205\n",
      "\tspeed: 0.1196s/iter; left time: 1602.9526s\n",
      "\titers: 200, epoch: 41 | loss: 0.0147199\n",
      "\tspeed: 0.0420s/iter; left time: 558.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.58s\n",
      "Steps: 225 | Train Loss: 0.0158101 Vali Loss: 0.0157864 Test Loss: 0.0173573\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0171100\n",
      "\tspeed: 0.1009s/iter; left time: 1328.8184s\n",
      "\titers: 200, epoch: 42 | loss: 0.0152776\n",
      "\tspeed: 0.0591s/iter; left time: 773.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 225 | Train Loss: 0.0158103 Vali Loss: 0.0158030 Test Loss: 0.0174064\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01729476824402809, rmse:0.13150957226753235, mae:0.07975035905838013, rse:0.49725186824798584\n",
      "Intermediate time for IT and pred_len 96: 00h:10m:15.34s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0470817\n",
      "\tspeed: 0.0776s/iter; left time: 1739.1330s\n",
      "\titers: 200, epoch: 1 | loss: 0.0334309\n",
      "\tspeed: 0.0264s/iter; left time: 589.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 225 | Train Loss: 0.0477718 Vali Loss: 0.0284479 Test Loss: 0.0308728\n",
      "Validation loss decreased (inf --> 0.028448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0239116\n",
      "\tspeed: 0.0542s/iter; left time: 1201.2453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0233685\n",
      "\tspeed: 0.0288s/iter; left time: 636.7362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 225 | Train Loss: 0.0249409 Vali Loss: 0.0192272 Test Loss: 0.0207638\n",
      "Validation loss decreased (0.028448 --> 0.019227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0201211\n",
      "\tspeed: 0.0849s/iter; left time: 1863.3549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0224873\n",
      "\tspeed: 0.0449s/iter; left time: 981.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 225 | Train Loss: 0.0209690 Vali Loss: 0.0184162 Test Loss: 0.0194297\n",
      "Validation loss decreased (0.019227 --> 0.018416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0236589\n",
      "\tspeed: 0.0881s/iter; left time: 1914.0939s\n",
      "\titers: 200, epoch: 4 | loss: 0.0205874\n",
      "\tspeed: 0.0464s/iter; left time: 1003.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.03s\n",
      "Steps: 225 | Train Loss: 0.0201329 Vali Loss: 0.0180921 Test Loss: 0.0192037\n",
      "Validation loss decreased (0.018416 --> 0.018092).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0182775\n",
      "\tspeed: 0.0935s/iter; left time: 2010.1367s\n",
      "\titers: 200, epoch: 5 | loss: 0.0187295\n",
      "\tspeed: 0.0447s/iter; left time: 957.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.19s\n",
      "Steps: 225 | Train Loss: 0.0197307 Vali Loss: 0.0178989 Test Loss: 0.0190696\n",
      "Validation loss decreased (0.018092 --> 0.017899).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0189552\n",
      "\tspeed: 0.0739s/iter; left time: 1571.8617s\n",
      "\titers: 200, epoch: 6 | loss: 0.0199359\n",
      "\tspeed: 0.0454s/iter; left time: 960.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 225 | Train Loss: 0.0194634 Vali Loss: 0.0177294 Test Loss: 0.0189508\n",
      "Validation loss decreased (0.017899 --> 0.017729).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0199815\n",
      "\tspeed: 0.1056s/iter; left time: 2222.1892s\n",
      "\titers: 200, epoch: 7 | loss: 0.0189001\n",
      "\tspeed: 0.0324s/iter; left time: 679.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 225 | Train Loss: 0.0192553 Vali Loss: 0.0177561 Test Loss: 0.0189389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0165607\n",
      "\tspeed: 0.1290s/iter; left time: 2685.6895s\n",
      "\titers: 200, epoch: 8 | loss: 0.0194142\n",
      "\tspeed: 0.0294s/iter; left time: 608.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 225 | Train Loss: 0.0190906 Vali Loss: 0.0176011 Test Loss: 0.0187670\n",
      "Validation loss decreased (0.017729 --> 0.017601).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0192651\n",
      "\tspeed: 0.0936s/iter; left time: 1928.7353s\n",
      "\titers: 200, epoch: 9 | loss: 0.0187292\n",
      "\tspeed: 0.0274s/iter; left time: 560.8369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 225 | Train Loss: 0.0189444 Vali Loss: 0.0175180 Test Loss: 0.0188351\n",
      "Validation loss decreased (0.017601 --> 0.017518).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0185771\n",
      "\tspeed: 0.0422s/iter; left time: 859.4170s\n",
      "\titers: 200, epoch: 10 | loss: 0.0195553\n",
      "\tspeed: 0.0207s/iter; left time: 418.9505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0188059 Vali Loss: 0.0176197 Test Loss: 0.0188907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0188781\n",
      "\tspeed: 0.0523s/iter; left time: 1054.8610s\n",
      "\titers: 200, epoch: 11 | loss: 0.0185935\n",
      "\tspeed: 0.0335s/iter; left time: 672.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 225 | Train Loss: 0.0187199 Vali Loss: 0.0175749 Test Loss: 0.0188651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0184689\n",
      "\tspeed: 0.0752s/iter; left time: 1497.4903s\n",
      "\titers: 200, epoch: 12 | loss: 0.0183612\n",
      "\tspeed: 0.0443s/iter; left time: 878.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 225 | Train Loss: 0.0186157 Vali Loss: 0.0175330 Test Loss: 0.0188398\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0175366\n",
      "\tspeed: 0.0779s/iter; left time: 1533.9832s\n",
      "\titers: 200, epoch: 13 | loss: 0.0188624\n",
      "\tspeed: 0.0327s/iter; left time: 640.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 225 | Train Loss: 0.0185028 Vali Loss: 0.0174663 Test Loss: 0.0187327\n",
      "Validation loss decreased (0.017518 --> 0.017466).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0175015\n",
      "\tspeed: 0.1002s/iter; left time: 1951.3282s\n",
      "\titers: 200, epoch: 14 | loss: 0.0188210\n",
      "\tspeed: 0.0325s/iter; left time: 629.0999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 225 | Train Loss: 0.0184339 Vali Loss: 0.0175618 Test Loss: 0.0188765\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0180571\n",
      "\tspeed: 0.0714s/iter; left time: 1375.3754s\n",
      "\titers: 200, epoch: 15 | loss: 0.0174339\n",
      "\tspeed: 0.0338s/iter; left time: 648.0443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 225 | Train Loss: 0.0183563 Vali Loss: 0.0175691 Test Loss: 0.0188944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0190036\n",
      "\tspeed: 0.1002s/iter; left time: 1905.9641s\n",
      "\titers: 200, epoch: 16 | loss: 0.0194198\n",
      "\tspeed: 0.0333s/iter; left time: 630.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 225 | Train Loss: 0.0182919 Vali Loss: 0.0174588 Test Loss: 0.0187264\n",
      "Validation loss decreased (0.017466 --> 0.017459).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0162348\n",
      "\tspeed: 0.0945s/iter; left time: 1777.4391s\n",
      "\titers: 200, epoch: 17 | loss: 0.0178654\n",
      "\tspeed: 0.0395s/iter; left time: 738.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.35s\n",
      "Steps: 225 | Train Loss: 0.0182279 Vali Loss: 0.0174852 Test Loss: 0.0188695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0169097\n",
      "\tspeed: 0.0727s/iter; left time: 1349.8465s\n",
      "\titers: 200, epoch: 18 | loss: 0.0179845\n",
      "\tspeed: 0.0362s/iter; left time: 669.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.89s\n",
      "Steps: 225 | Train Loss: 0.0181624 Vali Loss: 0.0174539 Test Loss: 0.0188264\n",
      "Validation loss decreased (0.017459 --> 0.017454).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0169253\n",
      "\tspeed: 0.0989s/iter; left time: 1815.3184s\n",
      "\titers: 200, epoch: 19 | loss: 0.0200264\n",
      "\tspeed: 0.0326s/iter; left time: 594.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 225 | Train Loss: 0.0181152 Vali Loss: 0.0174486 Test Loss: 0.0187742\n",
      "Validation loss decreased (0.017454 --> 0.017449).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0178235\n",
      "\tspeed: 0.0966s/iter; left time: 1751.5849s\n",
      "\titers: 200, epoch: 20 | loss: 0.0182496\n",
      "\tspeed: 0.0385s/iter; left time: 694.1309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.74s\n",
      "Steps: 225 | Train Loss: 0.0180658 Vali Loss: 0.0174563 Test Loss: 0.0187698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0182403\n",
      "\tspeed: 0.0792s/iter; left time: 1416.8968s\n",
      "\titers: 200, epoch: 21 | loss: 0.0182276\n",
      "\tspeed: 0.0449s/iter; left time: 799.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 225 | Train Loss: 0.0180051 Vali Loss: 0.0174450 Test Loss: 0.0188208\n",
      "Validation loss decreased (0.017449 --> 0.017445).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0177208\n",
      "\tspeed: 0.0821s/iter; left time: 1451.4964s\n",
      "\titers: 200, epoch: 22 | loss: 0.0181698\n",
      "\tspeed: 0.0391s/iter; left time: 686.5119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 225 | Train Loss: 0.0179754 Vali Loss: 0.0174402 Test Loss: 0.0188235\n",
      "Validation loss decreased (0.017445 --> 0.017440).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0174111\n",
      "\tspeed: 0.1194s/iter; left time: 2083.9236s\n",
      "\titers: 200, epoch: 23 | loss: 0.0177269\n",
      "\tspeed: 0.0354s/iter; left time: 614.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 225 | Train Loss: 0.0179590 Vali Loss: 0.0174663 Test Loss: 0.0188353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0175101\n",
      "\tspeed: 0.0957s/iter; left time: 1647.6924s\n",
      "\titers: 200, epoch: 24 | loss: 0.0178409\n",
      "\tspeed: 0.0388s/iter; left time: 665.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 225 | Train Loss: 0.0179136 Vali Loss: 0.0174419 Test Loss: 0.0188890\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0191682\n",
      "\tspeed: 0.0868s/iter; left time: 1475.4563s\n",
      "\titers: 200, epoch: 25 | loss: 0.0188505\n",
      "\tspeed: 0.0479s/iter; left time: 808.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 225 | Train Loss: 0.0178740 Vali Loss: 0.0174738 Test Loss: 0.0188258\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0170615\n",
      "\tspeed: 0.0955s/iter; left time: 1602.4787s\n",
      "\titers: 200, epoch: 26 | loss: 0.0181179\n",
      "\tspeed: 0.0327s/iter; left time: 544.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 225 | Train Loss: 0.0178429 Vali Loss: 0.0174697 Test Loss: 0.0188988\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0179335\n",
      "\tspeed: 0.1142s/iter; left time: 1890.3786s\n",
      "\titers: 200, epoch: 27 | loss: 0.0182124\n",
      "\tspeed: 0.0369s/iter; left time: 607.0715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 225 | Train Loss: 0.0178122 Vali Loss: 0.0174661 Test Loss: 0.0188872\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0199118\n",
      "\tspeed: 0.0933s/iter; left time: 1523.8650s\n",
      "\titers: 200, epoch: 28 | loss: 0.0184817\n",
      "\tspeed: 0.0355s/iter; left time: 576.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 225 | Train Loss: 0.0177697 Vali Loss: 0.0174359 Test Loss: 0.0188458\n",
      "Validation loss decreased (0.017440 --> 0.017436).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0185850\n",
      "\tspeed: 0.0471s/iter; left time: 758.2170s\n",
      "\titers: 200, epoch: 29 | loss: 0.0159490\n",
      "\tspeed: 0.0194s/iter; left time: 309.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0177890 Vali Loss: 0.0174572 Test Loss: 0.0188938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0190641\n",
      "\tspeed: 0.0504s/iter; left time: 800.5204s\n",
      "\titers: 200, epoch: 30 | loss: 0.0184726\n",
      "\tspeed: 0.0402s/iter; left time: 633.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 225 | Train Loss: 0.0177593 Vali Loss: 0.0174437 Test Loss: 0.0188625\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0178892\n",
      "\tspeed: 0.0846s/iter; left time: 1324.2394s\n",
      "\titers: 200, epoch: 31 | loss: 0.0159046\n",
      "\tspeed: 0.0338s/iter; left time: 525.3135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 225 | Train Loss: 0.0177573 Vali Loss: 0.0174455 Test Loss: 0.0188721\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0162854\n",
      "\tspeed: 0.0765s/iter; left time: 1180.2324s\n",
      "\titers: 200, epoch: 32 | loss: 0.0192957\n",
      "\tspeed: 0.0369s/iter; left time: 565.7178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 225 | Train Loss: 0.0177434 Vali Loss: 0.0174310 Test Loss: 0.0188878\n",
      "Validation loss decreased (0.017436 --> 0.017431).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0186600\n",
      "\tspeed: 0.0809s/iter; left time: 1230.3704s\n",
      "\titers: 200, epoch: 33 | loss: 0.0190157\n",
      "\tspeed: 0.0298s/iter; left time: 449.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.73s\n",
      "Steps: 225 | Train Loss: 0.0177179 Vali Loss: 0.0174451 Test Loss: 0.0188824\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0177958\n",
      "\tspeed: 0.0857s/iter; left time: 1284.1060s\n",
      "\titers: 200, epoch: 34 | loss: 0.0167717\n",
      "\tspeed: 0.0323s/iter; left time: 480.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 225 | Train Loss: 0.0177123 Vali Loss: 0.0174233 Test Loss: 0.0188737\n",
      "Validation loss decreased (0.017431 --> 0.017423).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0172185\n",
      "\tspeed: 0.0882s/iter; left time: 1301.2977s\n",
      "\titers: 200, epoch: 35 | loss: 0.0184308\n",
      "\tspeed: 0.0374s/iter; left time: 547.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 225 | Train Loss: 0.0176920 Vali Loss: 0.0174605 Test Loss: 0.0188986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0180091\n",
      "\tspeed: 0.0877s/iter; left time: 1273.2713s\n",
      "\titers: 200, epoch: 36 | loss: 0.0181451\n",
      "\tspeed: 0.0382s/iter; left time: 550.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 225 | Train Loss: 0.0176895 Vali Loss: 0.0174417 Test Loss: 0.0189240\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0197505\n",
      "\tspeed: 0.0734s/iter; left time: 1050.0201s\n",
      "\titers: 200, epoch: 37 | loss: 0.0171026\n",
      "\tspeed: 0.0372s/iter; left time: 528.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 225 | Train Loss: 0.0176750 Vali Loss: 0.0174587 Test Loss: 0.0189393\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0182414\n",
      "\tspeed: 0.0830s/iter; left time: 1168.1594s\n",
      "\titers: 200, epoch: 38 | loss: 0.0174553\n",
      "\tspeed: 0.0418s/iter; left time: 583.7188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 225 | Train Loss: 0.0176732 Vali Loss: 0.0174202 Test Loss: 0.0189041\n",
      "Validation loss decreased (0.017423 --> 0.017420).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0179154\n",
      "\tspeed: 0.0932s/iter; left time: 1291.4824s\n",
      "\titers: 200, epoch: 39 | loss: 0.0177326\n",
      "\tspeed: 0.0364s/iter; left time: 500.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 225 | Train Loss: 0.0176698 Vali Loss: 0.0174568 Test Loss: 0.0188915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0167302\n",
      "\tspeed: 0.0873s/iter; left time: 1189.7488s\n",
      "\titers: 200, epoch: 40 | loss: 0.0172194\n",
      "\tspeed: 0.0368s/iter; left time: 497.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 225 | Train Loss: 0.0176391 Vali Loss: 0.0174383 Test Loss: 0.0188776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0164773\n",
      "\tspeed: 0.0867s/iter; left time: 1161.2019s\n",
      "\titers: 200, epoch: 41 | loss: 0.0188107\n",
      "\tspeed: 0.0380s/iter; left time: 506.1030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.04s\n",
      "Steps: 225 | Train Loss: 0.0176388 Vali Loss: 0.0174470 Test Loss: 0.0188990\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0169925\n",
      "\tspeed: 0.0812s/iter; left time: 1069.6559s\n",
      "\titers: 200, epoch: 42 | loss: 0.0179315\n",
      "\tspeed: 0.0341s/iter; left time: 445.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 225 | Train Loss: 0.0176362 Vali Loss: 0.0174358 Test Loss: 0.0189112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0172228\n",
      "\tspeed: 0.0771s/iter; left time: 998.7934s\n",
      "\titers: 200, epoch: 43 | loss: 0.0194211\n",
      "\tspeed: 0.0424s/iter; left time: 544.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 225 | Train Loss: 0.0176347 Vali Loss: 0.0174557 Test Loss: 0.0189262\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0177851\n",
      "\tspeed: 0.0768s/iter; left time: 977.8385s\n",
      "\titers: 200, epoch: 44 | loss: 0.0175024\n",
      "\tspeed: 0.0395s/iter; left time: 498.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.14s\n",
      "Steps: 225 | Train Loss: 0.0176328 Vali Loss: 0.0174426 Test Loss: 0.0189024\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0169976\n",
      "\tspeed: 0.0783s/iter; left time: 979.4436s\n",
      "\titers: 200, epoch: 45 | loss: 0.0195613\n",
      "\tspeed: 0.0383s/iter; left time: 475.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 225 | Train Loss: 0.0176215 Vali Loss: 0.0174558 Test Loss: 0.0189192\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0171266\n",
      "\tspeed: 0.0895s/iter; left time: 1099.2866s\n",
      "\titers: 200, epoch: 46 | loss: 0.0168313\n",
      "\tspeed: 0.0383s/iter; left time: 466.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 225 | Train Loss: 0.0176224 Vali Loss: 0.0174636 Test Loss: 0.0189049\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0155394\n",
      "\tspeed: 0.0776s/iter; left time: 934.7370s\n",
      "\titers: 200, epoch: 47 | loss: 0.0177897\n",
      "\tspeed: 0.0368s/iter; left time: 439.8636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 225 | Train Loss: 0.0176342 Vali Loss: 0.0174581 Test Loss: 0.0189175\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0182304\n",
      "\tspeed: 0.0784s/iter; left time: 926.6719s\n",
      "\titers: 200, epoch: 48 | loss: 0.0158067\n",
      "\tspeed: 0.0322s/iter; left time: 377.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 225 | Train Loss: 0.0176249 Vali Loss: 0.0174510 Test Loss: 0.0189265\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.018904151394963264, rmse:0.137492373585701, mae:0.08580073714256287, rse:0.5203565359115601\n",
      "Intermediate time for IT and pred_len 168: 00h:09m:48.80s\n",
      "Intermediate time for IT: 00h:29m:02.33s\n",
      "Total time: 01h:39m:31.65s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.0798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/21                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1447  0.0914\n",
       "        96            0.0366  0.1912  0.1298\n",
       "        168           0.0406  0.2015  0.1382\n",
       "GB      24            0.0252  0.1588  0.1029\n",
       "        96            0.0446  0.2112  0.1462\n",
       "        168           0.0478  0.2186  0.1531\n",
       "ES      24            0.0098  0.0988  0.0608\n",
       "        96            0.0188  0.1371  0.0883\n",
       "        168           0.0211  0.1454  0.0951\n",
       "FR      24            0.0099  0.0997  0.0566\n",
       "        96            0.0186  0.1363  0.0820\n",
       "        168           0.0203  0.1426  0.0886\n",
       "IT      24            0.0099  0.0995  0.0582\n",
       "        96            0.0173  0.1315  0.0798\n",
       "        168           0.0189  0.1375  0.0858"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "#os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "#os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False, itr=1)\n",
    "patchtst_df.drop(columns=['Iteration'], inplace=True)\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "#os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "#os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1369714\n",
      "\tspeed: 0.0541s/iter; left time: 1205.4753s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247781\n",
      "\tspeed: 0.0266s/iter; left time: 591.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.1417671 Vali Loss: 0.1297606 Test Loss: 0.1347090\n",
      "Validation loss decreased (inf --> 0.129761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869461\n",
      "\tspeed: 0.0521s/iter; left time: 1150.1137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833711\n",
      "\tspeed: 0.0267s/iter; left time: 587.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0896184 Vali Loss: 0.0936917 Test Loss: 0.0950095\n",
      "Validation loss decreased (0.129761 --> 0.093692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0781575\n",
      "\tspeed: 0.0518s/iter; left time: 1132.7286s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792153\n",
      "\tspeed: 0.0268s/iter; left time: 582.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0797606 Vali Loss: 0.0909321 Test Loss: 0.0923397\n",
      "Validation loss decreased (0.093692 --> 0.090932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807218\n",
      "\tspeed: 0.0511s/iter; left time: 1106.0893s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808649\n",
      "\tspeed: 0.0267s/iter; left time: 574.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0773325 Vali Loss: 0.0890039 Test Loss: 0.0909385\n",
      "Validation loss decreased (0.090932 --> 0.089004).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773130\n",
      "\tspeed: 0.0520s/iter; left time: 1112.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0740610\n",
      "\tspeed: 0.0267s/iter; left time: 569.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0885584 Test Loss: 0.0901798\n",
      "Validation loss decreased (0.089004 --> 0.088558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830306\n",
      "\tspeed: 0.0516s/iter; left time: 1093.4893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726725\n",
      "\tspeed: 0.0267s/iter; left time: 563.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0749306 Vali Loss: 0.0880955 Test Loss: 0.0901085\n",
      "Validation loss decreased (0.088558 --> 0.088095).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732605\n",
      "\tspeed: 0.0517s/iter; left time: 1082.8480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776332\n",
      "\tspeed: 0.0267s/iter; left time: 555.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0740759 Vali Loss: 0.0876682 Test Loss: 0.0896309\n",
      "Validation loss decreased (0.088095 --> 0.087668).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715202\n",
      "\tspeed: 0.0528s/iter; left time: 1093.9648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723670\n",
      "\tspeed: 0.0267s/iter; left time: 550.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0736438 Vali Loss: 0.0882936 Test Loss: 0.0894522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775626\n",
      "\tspeed: 0.0514s/iter; left time: 1054.5261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756080\n",
      "\tspeed: 0.0267s/iter; left time: 545.5887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0733198 Vali Loss: 0.0876187 Test Loss: 0.0892001\n",
      "Validation loss decreased (0.087668 --> 0.087619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0764146\n",
      "\tspeed: 0.0525s/iter; left time: 1064.7971s\n",
      "\titers: 200, epoch: 10 | loss: 0.0708030\n",
      "\tspeed: 0.0265s/iter; left time: 535.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0727986 Vali Loss: 0.0873704 Test Loss: 0.0889288\n",
      "Validation loss decreased (0.087619 --> 0.087370).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678855\n",
      "\tspeed: 0.0522s/iter; left time: 1048.0739s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720052\n",
      "\tspeed: 0.0268s/iter; left time: 534.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0725260 Vali Loss: 0.0871207 Test Loss: 0.0886076\n",
      "Validation loss decreased (0.087370 --> 0.087121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715223\n",
      "\tspeed: 0.0519s/iter; left time: 1030.5229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0742159\n",
      "\tspeed: 0.0266s/iter; left time: 524.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0722907 Vali Loss: 0.0866924 Test Loss: 0.0887910\n",
      "Validation loss decreased (0.087121 --> 0.086692).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0667619\n",
      "\tspeed: 0.0517s/iter; left time: 1013.0115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701735\n",
      "\tspeed: 0.0267s/iter; left time: 520.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0720069 Vali Loss: 0.0869621 Test Loss: 0.0883650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710825\n",
      "\tspeed: 0.0510s/iter; left time: 988.5146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727319\n",
      "\tspeed: 0.0266s/iter; left time: 512.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0718207 Vali Loss: 0.0862084 Test Loss: 0.0881200\n",
      "Validation loss decreased (0.086692 --> 0.086208).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721587\n",
      "\tspeed: 0.0518s/iter; left time: 993.4135s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660384\n",
      "\tspeed: 0.0267s/iter; left time: 509.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0716865 Vali Loss: 0.0862676 Test Loss: 0.0882083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0726189\n",
      "\tspeed: 0.0513s/iter; left time: 971.7333s\n",
      "\titers: 200, epoch: 16 | loss: 0.0699743\n",
      "\tspeed: 0.0266s/iter; left time: 500.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0715561 Vali Loss: 0.0862403 Test Loss: 0.0882708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734295\n",
      "\tspeed: 0.0508s/iter; left time: 950.7064s\n",
      "\titers: 200, epoch: 17 | loss: 0.0729700\n",
      "\tspeed: 0.0269s/iter; left time: 499.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0714500 Vali Loss: 0.0860131 Test Loss: 0.0878391\n",
      "Validation loss decreased (0.086208 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720860\n",
      "\tspeed: 0.0510s/iter; left time: 943.6124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807038\n",
      "\tspeed: 0.0285s/iter; left time: 524.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0712926 Vali Loss: 0.0858605 Test Loss: 0.0881299\n",
      "Validation loss decreased (0.086013 --> 0.085860).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0672827\n",
      "\tspeed: 0.0521s/iter; left time: 952.6361s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683527\n",
      "\tspeed: 0.0268s/iter; left time: 486.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0712880 Vali Loss: 0.0860396 Test Loss: 0.0881207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685089\n",
      "\tspeed: 0.0512s/iter; left time: 924.0535s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723603\n",
      "\tspeed: 0.0266s/iter; left time: 477.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0711309 Vali Loss: 0.0858991 Test Loss: 0.0879555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0669795\n",
      "\tspeed: 0.0510s/iter; left time: 908.4794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729611\n",
      "\tspeed: 0.0266s/iter; left time: 471.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0710612 Vali Loss: 0.0858557 Test Loss: 0.0878603\n",
      "Validation loss decreased (0.085860 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0644646\n",
      "\tspeed: 0.0516s/iter; left time: 908.2609s\n",
      "\titers: 200, epoch: 22 | loss: 0.0674015\n",
      "\tspeed: 0.0267s/iter; left time: 466.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0709746 Vali Loss: 0.0858742 Test Loss: 0.0879468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0715065\n",
      "\tspeed: 0.0506s/iter; left time: 878.9808s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664888\n",
      "\tspeed: 0.0266s/iter; left time: 459.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0708909 Vali Loss: 0.0858572 Test Loss: 0.0878468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697132\n",
      "\tspeed: 0.0514s/iter; left time: 881.7388s\n",
      "\titers: 200, epoch: 24 | loss: 0.0695731\n",
      "\tspeed: 0.0265s/iter; left time: 451.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0709061 Vali Loss: 0.0856822 Test Loss: 0.0878505\n",
      "Validation loss decreased (0.085856 --> 0.085682).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0698776\n",
      "\tspeed: 0.0509s/iter; left time: 862.2074s\n",
      "\titers: 200, epoch: 25 | loss: 0.0794153\n",
      "\tspeed: 0.0264s/iter; left time: 444.6524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0708391 Vali Loss: 0.0857899 Test Loss: 0.0877605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0693570\n",
      "\tspeed: 0.0507s/iter; left time: 847.0964s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686728\n",
      "\tspeed: 0.0267s/iter; left time: 442.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708132 Vali Loss: 0.0856289 Test Loss: 0.0876225\n",
      "Validation loss decreased (0.085682 --> 0.085629).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736588\n",
      "\tspeed: 0.0522s/iter; left time: 859.5258s\n",
      "\titers: 200, epoch: 27 | loss: 0.0751999\n",
      "\tspeed: 0.0266s/iter; left time: 435.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0706946 Vali Loss: 0.0857887 Test Loss: 0.0877622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681836\n",
      "\tspeed: 0.0513s/iter; left time: 834.2176s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738424\n",
      "\tspeed: 0.0267s/iter; left time: 430.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0707199 Vali Loss: 0.0856799 Test Loss: 0.0876857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0720591\n",
      "\tspeed: 0.0512s/iter; left time: 820.0638s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661264\n",
      "\tspeed: 0.0267s/iter; left time: 425.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0706302 Vali Loss: 0.0856200 Test Loss: 0.0876701\n",
      "Validation loss decreased (0.085629 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0764758\n",
      "\tspeed: 0.0525s/iter; left time: 829.9523s\n",
      "\titers: 200, epoch: 30 | loss: 0.0717371\n",
      "\tspeed: 0.0265s/iter; left time: 415.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0705703 Vali Loss: 0.0856172 Test Loss: 0.0877889\n",
      "Validation loss decreased (0.085620 --> 0.085617).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0694562\n",
      "\tspeed: 0.0528s/iter; left time: 823.0867s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669540\n",
      "\tspeed: 0.0271s/iter; left time: 420.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0705669 Vali Loss: 0.0855405 Test Loss: 0.0876212\n",
      "Validation loss decreased (0.085617 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648792\n",
      "\tspeed: 0.0519s/iter; left time: 796.4069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0739037\n",
      "\tspeed: 0.0265s/iter; left time: 403.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0705570 Vali Loss: 0.0856224 Test Loss: 0.0876501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760883\n",
      "\tspeed: 0.0509s/iter; left time: 769.5590s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659316\n",
      "\tspeed: 0.0264s/iter; left time: 397.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0705282 Vali Loss: 0.0856680 Test Loss: 0.0876398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700403\n",
      "\tspeed: 0.0509s/iter; left time: 758.6267s\n",
      "\titers: 200, epoch: 34 | loss: 0.0733599\n",
      "\tspeed: 0.0265s/iter; left time: 392.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0705505 Vali Loss: 0.0856534 Test Loss: 0.0876419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0716821\n",
      "\tspeed: 0.0509s/iter; left time: 747.2629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0660121\n",
      "\tspeed: 0.0267s/iter; left time: 389.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0704936 Vali Loss: 0.0856017 Test Loss: 0.0876743\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702281\n",
      "\tspeed: 0.0520s/iter; left time: 751.7426s\n",
      "\titers: 200, epoch: 36 | loss: 0.0758533\n",
      "\tspeed: 0.0268s/iter; left time: 385.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704848 Vali Loss: 0.0856520 Test Loss: 0.0876421\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0775575\n",
      "\tspeed: 0.0516s/iter; left time: 734.5360s\n",
      "\titers: 200, epoch: 37 | loss: 0.0730687\n",
      "\tspeed: 0.0267s/iter; left time: 377.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0705037 Vali Loss: 0.0856726 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0694183\n",
      "\tspeed: 0.0517s/iter; left time: 724.0252s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666340\n",
      "\tspeed: 0.0268s/iter; left time: 372.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704922 Vali Loss: 0.0855943 Test Loss: 0.0876738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0741279\n",
      "\tspeed: 0.0517s/iter; left time: 713.1725s\n",
      "\titers: 200, epoch: 39 | loss: 0.0680151\n",
      "\tspeed: 0.0268s/iter; left time: 366.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704478 Vali Loss: 0.0855522 Test Loss: 0.0876500\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0680514\n",
      "\tspeed: 0.0510s/iter; left time: 691.1667s\n",
      "\titers: 200, epoch: 40 | loss: 0.0764029\n",
      "\tspeed: 0.0265s/iter; left time: 356.5305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704099 Vali Loss: 0.0856432 Test Loss: 0.0876450\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0655310\n",
      "\tspeed: 0.0508s/iter; left time: 677.2596s\n",
      "\titers: 200, epoch: 41 | loss: 0.0691073\n",
      "\tspeed: 0.0268s/iter; left time: 355.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703985 Vali Loss: 0.0854845 Test Loss: 0.0875877\n",
      "Validation loss decreased (0.085541 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682409\n",
      "\tspeed: 0.0513s/iter; left time: 672.5361s\n",
      "\titers: 200, epoch: 42 | loss: 0.0763331\n",
      "\tspeed: 0.0265s/iter; left time: 345.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0704444 Vali Loss: 0.0856361 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755680\n",
      "\tspeed: 0.0513s/iter; left time: 661.0572s\n",
      "\titers: 200, epoch: 43 | loss: 0.0719940\n",
      "\tspeed: 0.0265s/iter; left time: 339.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704495 Vali Loss: 0.0855508 Test Loss: 0.0876172\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644201\n",
      "\tspeed: 0.0509s/iter; left time: 645.4822s\n",
      "\titers: 200, epoch: 44 | loss: 0.0712258\n",
      "\tspeed: 0.0265s/iter; left time: 333.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704013 Vali Loss: 0.0855588 Test Loss: 0.0876322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0704731\n",
      "\tspeed: 0.0520s/iter; left time: 647.4943s\n",
      "\titers: 200, epoch: 45 | loss: 0.0729366\n",
      "\tspeed: 0.0265s/iter; left time: 327.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703918 Vali Loss: 0.0855635 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0704228\n",
      "\tspeed: 0.0513s/iter; left time: 627.0158s\n",
      "\titers: 200, epoch: 46 | loss: 0.0755504\n",
      "\tspeed: 0.0266s/iter; left time: 323.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703368 Vali Loss: 0.0855913 Test Loss: 0.0876351\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0714861\n",
      "\tspeed: 0.0527s/iter; left time: 632.7437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0703084\n",
      "\tspeed: 0.0270s/iter; left time: 321.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0703858 Vali Loss: 0.0855839 Test Loss: 0.0876863\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0716547\n",
      "\tspeed: 0.0512s/iter; left time: 603.1520s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697001\n",
      "\tspeed: 0.0269s/iter; left time: 314.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703595 Vali Loss: 0.0855201 Test Loss: 0.0876336\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0721770\n",
      "\tspeed: 0.0514s/iter; left time: 593.2863s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752482\n",
      "\tspeed: 0.0269s/iter; left time: 308.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703970 Vali Loss: 0.0854210 Test Loss: 0.0876339\n",
      "Validation loss decreased (0.085485 --> 0.085421).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0676463\n",
      "\tspeed: 0.0513s/iter; left time: 580.5348s\n",
      "\titers: 200, epoch: 50 | loss: 0.0677730\n",
      "\tspeed: 0.0265s/iter; left time: 297.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703362 Vali Loss: 0.0856355 Test Loss: 0.0876200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0666008\n",
      "\tspeed: 0.0516s/iter; left time: 573.0979s\n",
      "\titers: 200, epoch: 51 | loss: 0.0702993\n",
      "\tspeed: 0.0268s/iter; left time: 294.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0703573 Vali Loss: 0.0855665 Test Loss: 0.0876208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0723010\n",
      "\tspeed: 0.0510s/iter; left time: 555.1316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758060\n",
      "\tspeed: 0.0265s/iter; left time: 285.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703259 Vali Loss: 0.0854868 Test Loss: 0.0876280\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0706884\n",
      "\tspeed: 0.0514s/iter; left time: 547.3564s\n",
      "\titers: 200, epoch: 53 | loss: 0.0751953\n",
      "\tspeed: 0.0265s/iter; left time: 280.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703530 Vali Loss: 0.0855637 Test Loss: 0.0876266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0702771\n",
      "\tspeed: 0.0513s/iter; left time: 535.4939s\n",
      "\titers: 200, epoch: 54 | loss: 0.0684877\n",
      "\tspeed: 0.0268s/iter; left time: 277.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703710 Vali Loss: 0.0855449 Test Loss: 0.0876197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688983\n",
      "\tspeed: 0.0514s/iter; left time: 524.3484s\n",
      "\titers: 200, epoch: 55 | loss: 0.0738532\n",
      "\tspeed: 0.0269s/iter; left time: 271.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703545 Vali Loss: 0.0854906 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0730539\n",
      "\tspeed: 0.0526s/iter; left time: 525.1879s\n",
      "\titers: 200, epoch: 56 | loss: 0.0674224\n",
      "\tspeed: 0.0266s/iter; left time: 263.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704173 Vali Loss: 0.0854536 Test Loss: 0.0876250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0707048\n",
      "\tspeed: 0.0513s/iter; left time: 500.7753s\n",
      "\titers: 200, epoch: 57 | loss: 0.0710349\n",
      "\tspeed: 0.0265s/iter; left time: 255.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703584 Vali Loss: 0.0855452 Test Loss: 0.0876381\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736169\n",
      "\tspeed: 0.0504s/iter; left time: 480.1522s\n",
      "\titers: 200, epoch: 58 | loss: 0.0741034\n",
      "\tspeed: 0.0266s/iter; left time: 250.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703132 Vali Loss: 0.0855490 Test Loss: 0.0876148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0710790\n",
      "\tspeed: 0.0514s/iter; left time: 478.3326s\n",
      "\titers: 200, epoch: 59 | loss: 0.0729701\n",
      "\tspeed: 0.0269s/iter; left time: 247.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703250 Vali Loss: 0.0855128 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020939357578754425, rmse:0.14470438659191132, mae:0.08763387054204941, rse:0.5106817483901978\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1389406\n",
      "\tspeed: 0.0286s/iter; left time: 637.3228s\n",
      "\titers: 200, epoch: 1 | loss: 0.1228134\n",
      "\tspeed: 0.0266s/iter; left time: 590.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1422911 Vali Loss: 0.1295809 Test Loss: 0.1351006\n",
      "Validation loss decreased (inf --> 0.129581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877811\n",
      "\tspeed: 0.0524s/iter; left time: 1157.5606s\n",
      "\titers: 200, epoch: 2 | loss: 0.0832211\n",
      "\tspeed: 0.0267s/iter; left time: 585.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0894358 Vali Loss: 0.0936241 Test Loss: 0.0940987\n",
      "Validation loss decreased (0.129581 --> 0.093624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775893\n",
      "\tspeed: 0.0529s/iter; left time: 1155.7753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735417\n",
      "\tspeed: 0.0268s/iter; left time: 582.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0796590 Vali Loss: 0.0902558 Test Loss: 0.0915840\n",
      "Validation loss decreased (0.093624 --> 0.090256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0772389\n",
      "\tspeed: 0.0535s/iter; left time: 1157.4906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764423\n",
      "\tspeed: 0.0267s/iter; left time: 575.2471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0774734 Vali Loss: 0.0893443 Test Loss: 0.0907840\n",
      "Validation loss decreased (0.090256 --> 0.089344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743019\n",
      "\tspeed: 0.0524s/iter; left time: 1122.3344s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750691\n",
      "\tspeed: 0.0266s/iter; left time: 566.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0761713 Vali Loss: 0.0888839 Test Loss: 0.0900800\n",
      "Validation loss decreased (0.089344 --> 0.088884).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0693859\n",
      "\tspeed: 0.0531s/iter; left time: 1125.5393s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754470\n",
      "\tspeed: 0.0268s/iter; left time: 564.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0751449 Vali Loss: 0.0878856 Test Loss: 0.0899183\n",
      "Validation loss decreased (0.088884 --> 0.087886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723351\n",
      "\tspeed: 0.0524s/iter; left time: 1098.0215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741934\n",
      "\tspeed: 0.0266s/iter; left time: 553.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0744148 Vali Loss: 0.0882161 Test Loss: 0.0896968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743478\n",
      "\tspeed: 0.0515s/iter; left time: 1067.8407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734460\n",
      "\tspeed: 0.0266s/iter; left time: 547.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0738465 Vali Loss: 0.0875170 Test Loss: 0.0890645\n",
      "Validation loss decreased (0.087886 --> 0.087517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690735\n",
      "\tspeed: 0.0529s/iter; left time: 1085.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759658\n",
      "\tspeed: 0.0267s/iter; left time: 545.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0733618 Vali Loss: 0.0870617 Test Loss: 0.0888512\n",
      "Validation loss decreased (0.087517 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763888\n",
      "\tspeed: 0.0540s/iter; left time: 1095.9059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748855\n",
      "\tspeed: 0.0267s/iter; left time: 538.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0729996 Vali Loss: 0.0868114 Test Loss: 0.0887925\n",
      "Validation loss decreased (0.087062 --> 0.086811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753090\n",
      "\tspeed: 0.0522s/iter; left time: 1047.6334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728513\n",
      "\tspeed: 0.0265s/iter; left time: 528.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0726921 Vali Loss: 0.0872061 Test Loss: 0.0885696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705457\n",
      "\tspeed: 0.0520s/iter; left time: 1031.3150s\n",
      "\titers: 200, epoch: 12 | loss: 0.0726305\n",
      "\tspeed: 0.0265s/iter; left time: 523.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723711 Vali Loss: 0.0864833 Test Loss: 0.0882598\n",
      "Validation loss decreased (0.086811 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700529\n",
      "\tspeed: 0.0524s/iter; left time: 1027.1079s\n",
      "\titers: 200, epoch: 13 | loss: 0.0684496\n",
      "\tspeed: 0.0267s/iter; left time: 520.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0721546 Vali Loss: 0.0865951 Test Loss: 0.0883359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748019\n",
      "\tspeed: 0.0529s/iter; left time: 1024.8560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713811\n",
      "\tspeed: 0.0270s/iter; left time: 520.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0719527 Vali Loss: 0.0866737 Test Loss: 0.0880236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713503\n",
      "\tspeed: 0.0521s/iter; left time: 999.2792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763744\n",
      "\tspeed: 0.0266s/iter; left time: 506.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0716899 Vali Loss: 0.0864420 Test Loss: 0.0880862\n",
      "Validation loss decreased (0.086483 --> 0.086442).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746533\n",
      "\tspeed: 0.0524s/iter; left time: 992.8871s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665798\n",
      "\tspeed: 0.0265s/iter; left time: 499.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0715671 Vali Loss: 0.0860693 Test Loss: 0.0879256\n",
      "Validation loss decreased (0.086442 --> 0.086069).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704673\n",
      "\tspeed: 0.0527s/iter; left time: 987.2801s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683351\n",
      "\tspeed: 0.0268s/iter; left time: 498.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0714092 Vali Loss: 0.0860398 Test Loss: 0.0881202\n",
      "Validation loss decreased (0.086069 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692278\n",
      "\tspeed: 0.0532s/iter; left time: 984.5075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706096\n",
      "\tspeed: 0.0265s/iter; left time: 487.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0713103 Vali Loss: 0.0860568 Test Loss: 0.0880662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711174\n",
      "\tspeed: 0.0527s/iter; left time: 963.1993s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707833\n",
      "\tspeed: 0.0265s/iter; left time: 480.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0711834 Vali Loss: 0.0858907 Test Loss: 0.0879579\n",
      "Validation loss decreased (0.086040 --> 0.085891).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700932\n",
      "\tspeed: 0.0527s/iter; left time: 951.2086s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701582\n",
      "\tspeed: 0.0268s/iter; left time: 480.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0710876 Vali Loss: 0.0862701 Test Loss: 0.0880781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699507\n",
      "\tspeed: 0.0528s/iter; left time: 940.8659s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683075\n",
      "\tspeed: 0.0267s/iter; left time: 473.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0710427 Vali Loss: 0.0861612 Test Loss: 0.0881739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0751726\n",
      "\tspeed: 0.0519s/iter; left time: 912.4235s\n",
      "\titers: 200, epoch: 22 | loss: 0.0686039\n",
      "\tspeed: 0.0265s/iter; left time: 464.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0709314 Vali Loss: 0.0859297 Test Loss: 0.0879431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740635\n",
      "\tspeed: 0.0530s/iter; left time: 920.0264s\n",
      "\titers: 200, epoch: 23 | loss: 0.0754669\n",
      "\tspeed: 0.0267s/iter; left time: 460.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0708511 Vali Loss: 0.0858247 Test Loss: 0.0877661\n",
      "Validation loss decreased (0.085891 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0669902\n",
      "\tspeed: 0.0531s/iter; left time: 911.2386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0699968\n",
      "\tspeed: 0.0264s/iter; left time: 450.4041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708038 Vali Loss: 0.0857948 Test Loss: 0.0880593\n",
      "Validation loss decreased (0.085825 --> 0.085795).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0710267\n",
      "\tspeed: 0.0519s/iter; left time: 878.6579s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701005\n",
      "\tspeed: 0.0265s/iter; left time: 445.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0707550 Vali Loss: 0.0858620 Test Loss: 0.0879302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0675721\n",
      "\tspeed: 0.0519s/iter; left time: 866.8273s\n",
      "\titers: 200, epoch: 26 | loss: 0.0723306\n",
      "\tspeed: 0.0266s/iter; left time: 441.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0707452 Vali Loss: 0.0857506 Test Loss: 0.0878565\n",
      "Validation loss decreased (0.085795 --> 0.085751).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725780\n",
      "\tspeed: 0.0528s/iter; left time: 869.7247s\n",
      "\titers: 200, epoch: 27 | loss: 0.0715543\n",
      "\tspeed: 0.0268s/iter; left time: 438.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0706913 Vali Loss: 0.0857717 Test Loss: 0.0878863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0656819\n",
      "\tspeed: 0.0536s/iter; left time: 870.6048s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728222\n",
      "\tspeed: 0.0269s/iter; left time: 434.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0706028 Vali Loss: 0.0855976 Test Loss: 0.0878353\n",
      "Validation loss decreased (0.085751 --> 0.085598).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716999\n",
      "\tspeed: 0.0531s/iter; left time: 850.3424s\n",
      "\titers: 200, epoch: 29 | loss: 0.0711410\n",
      "\tspeed: 0.0265s/iter; left time: 422.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0705973 Vali Loss: 0.0859616 Test Loss: 0.0878585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0745615\n",
      "\tspeed: 0.0523s/iter; left time: 827.2763s\n",
      "\titers: 200, epoch: 30 | loss: 0.0758140\n",
      "\tspeed: 0.0269s/iter; left time: 422.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705595 Vali Loss: 0.0856872 Test Loss: 0.0878131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0744614\n",
      "\tspeed: 0.0525s/iter; left time: 818.0931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0705624\n",
      "\tspeed: 0.0267s/iter; left time: 414.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705045 Vali Loss: 0.0857018 Test Loss: 0.0878923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0687968\n",
      "\tspeed: 0.0528s/iter; left time: 810.4927s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645319\n",
      "\tspeed: 0.0267s/iter; left time: 406.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0705371 Vali Loss: 0.0856552 Test Loss: 0.0878005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0692253\n",
      "\tspeed: 0.0522s/iter; left time: 790.4230s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719842\n",
      "\tspeed: 0.0267s/iter; left time: 401.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0704541 Vali Loss: 0.0857210 Test Loss: 0.0878580\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0711537\n",
      "\tspeed: 0.0519s/iter; left time: 773.8731s\n",
      "\titers: 200, epoch: 34 | loss: 0.0700859\n",
      "\tspeed: 0.0267s/iter; left time: 395.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704086 Vali Loss: 0.0857385 Test Loss: 0.0877898\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0727249\n",
      "\tspeed: 0.0525s/iter; left time: 771.6492s\n",
      "\titers: 200, epoch: 35 | loss: 0.0703164\n",
      "\tspeed: 0.0265s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0704289 Vali Loss: 0.0856548 Test Loss: 0.0878404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0692909\n",
      "\tspeed: 0.0518s/iter; left time: 749.3944s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745890\n",
      "\tspeed: 0.0265s/iter; left time: 380.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704170 Vali Loss: 0.0855795 Test Loss: 0.0877761\n",
      "Validation loss decreased (0.085598 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669411\n",
      "\tspeed: 0.0523s/iter; left time: 743.9817s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717780\n",
      "\tspeed: 0.0265s/iter; left time: 374.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703451 Vali Loss: 0.0857678 Test Loss: 0.0877872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0692922\n",
      "\tspeed: 0.0523s/iter; left time: 732.2128s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706012\n",
      "\tspeed: 0.0274s/iter; left time: 381.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0703509 Vali Loss: 0.0856808 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0644956\n",
      "\tspeed: 0.0523s/iter; left time: 721.3358s\n",
      "\titers: 200, epoch: 39 | loss: 0.0683517\n",
      "\tspeed: 0.0265s/iter; left time: 362.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0703036 Vali Loss: 0.0857069 Test Loss: 0.0877940\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712174\n",
      "\tspeed: 0.0528s/iter; left time: 716.0116s\n",
      "\titers: 200, epoch: 40 | loss: 0.0717972\n",
      "\tspeed: 0.0266s/iter; left time: 357.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703386 Vali Loss: 0.0855974 Test Loss: 0.0877805\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0709783\n",
      "\tspeed: 0.0521s/iter; left time: 694.8751s\n",
      "\titers: 200, epoch: 41 | loss: 0.0727384\n",
      "\tspeed: 0.0267s/iter; left time: 353.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703057 Vali Loss: 0.0855847 Test Loss: 0.0877485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0696685\n",
      "\tspeed: 0.0521s/iter; left time: 684.0514s\n",
      "\titers: 200, epoch: 42 | loss: 0.0708702\n",
      "\tspeed: 0.0266s/iter; left time: 345.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0702815 Vali Loss: 0.0856937 Test Loss: 0.0877606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755521\n",
      "\tspeed: 0.0524s/iter; left time: 675.6540s\n",
      "\titers: 200, epoch: 43 | loss: 0.0711717\n",
      "\tspeed: 0.0266s/iter; left time: 340.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0703419 Vali Loss: 0.0854786 Test Loss: 0.0877750\n",
      "Validation loss decreased (0.085579 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0711064\n",
      "\tspeed: 0.0524s/iter; left time: 664.3796s\n",
      "\titers: 200, epoch: 44 | loss: 0.0720553\n",
      "\tspeed: 0.0267s/iter; left time: 335.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703236 Vali Loss: 0.0856422 Test Loss: 0.0877193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0685135\n",
      "\tspeed: 0.0518s/iter; left time: 645.1912s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710313\n",
      "\tspeed: 0.0270s/iter; left time: 333.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703195 Vali Loss: 0.0855412 Test Loss: 0.0877509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0682689\n",
      "\tspeed: 0.0519s/iter; left time: 634.1017s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663539\n",
      "\tspeed: 0.0265s/iter; left time: 321.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702857 Vali Loss: 0.0856832 Test Loss: 0.0877343\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0781750\n",
      "\tspeed: 0.0532s/iter; left time: 637.8936s\n",
      "\titers: 200, epoch: 47 | loss: 0.0668642\n",
      "\tspeed: 0.0267s/iter; left time: 317.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0703067 Vali Loss: 0.0856037 Test Loss: 0.0877680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0757289\n",
      "\tspeed: 0.0527s/iter; left time: 620.0069s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714607\n",
      "\tspeed: 0.0265s/iter; left time: 309.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703030 Vali Loss: 0.0855959 Test Loss: 0.0877536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0738765\n",
      "\tspeed: 0.0524s/iter; left time: 605.3152s\n",
      "\titers: 200, epoch: 49 | loss: 0.0682928\n",
      "\tspeed: 0.0268s/iter; left time: 306.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703193 Vali Loss: 0.0856737 Test Loss: 0.0877642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0721883\n",
      "\tspeed: 0.0523s/iter; left time: 592.4528s\n",
      "\titers: 200, epoch: 50 | loss: 0.0696596\n",
      "\tspeed: 0.0266s/iter; left time: 298.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0702247 Vali Loss: 0.0856217 Test Loss: 0.0877349\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0724216\n",
      "\tspeed: 0.0521s/iter; left time: 578.8286s\n",
      "\titers: 200, epoch: 51 | loss: 0.0683385\n",
      "\tspeed: 0.0264s/iter; left time: 290.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0702224 Vali Loss: 0.0856550 Test Loss: 0.0877666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707191\n",
      "\tspeed: 0.0517s/iter; left time: 562.1389s\n",
      "\titers: 200, epoch: 52 | loss: 0.0697485\n",
      "\tspeed: 0.0265s/iter; left time: 285.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702648 Vali Loss: 0.0856051 Test Loss: 0.0877736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0723032\n",
      "\tspeed: 0.0528s/iter; left time: 562.8959s\n",
      "\titers: 200, epoch: 53 | loss: 0.0695717\n",
      "\tspeed: 0.0266s/iter; left time: 280.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0702753 Vali Loss: 0.0856733 Test Loss: 0.0877745\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020994756370782852, rmse:0.14489567279815674, mae:0.08777499943971634, rse:0.5113568902015686\n",
      "Intermediate time for DE and pred_len 24: 00h:14m:50.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487391\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1487s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375452\n",
      "\tspeed: 0.0269s/iter; left time: 598.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.1484455 Vali Loss: 0.1405499 Test Loss: 0.1490060\n",
      "Validation loss decreased (inf --> 0.140550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1194897\n",
      "\tspeed: 0.0533s/iter; left time: 1176.9588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064227\n",
      "\tspeed: 0.0268s/iter; left time: 588.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1145359 Vali Loss: 0.1213630 Test Loss: 0.1295630\n",
      "Validation loss decreased (0.140550 --> 0.121363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036745\n",
      "\tspeed: 0.0540s/iter; left time: 1179.6751s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068880\n",
      "\tspeed: 0.0268s/iter; left time: 583.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1064633 Vali Loss: 0.1195266 Test Loss: 0.1282235\n",
      "Validation loss decreased (0.121363 --> 0.119527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1044791\n",
      "\tspeed: 0.0537s/iter; left time: 1160.7622s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004268\n",
      "\tspeed: 0.0269s/iter; left time: 579.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1045039 Vali Loss: 0.1190653 Test Loss: 0.1280503\n",
      "Validation loss decreased (0.119527 --> 0.119065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030031\n",
      "\tspeed: 0.0531s/iter; left time: 1137.1471s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965900\n",
      "\tspeed: 0.0268s/iter; left time: 570.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1033400 Vali Loss: 0.1186632 Test Loss: 0.1276050\n",
      "Validation loss decreased (0.119065 --> 0.118663).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1102587\n",
      "\tspeed: 0.0538s/iter; left time: 1140.5733s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076527\n",
      "\tspeed: 0.0269s/iter; left time: 567.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1024590 Vali Loss: 0.1179634 Test Loss: 0.1265461\n",
      "Validation loss decreased (0.118663 --> 0.117963).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025728\n",
      "\tspeed: 0.0538s/iter; left time: 1126.7627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953970\n",
      "\tspeed: 0.0269s/iter; left time: 560.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1016823 Vali Loss: 0.1186003 Test Loss: 0.1277381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998731\n",
      "\tspeed: 0.0539s/iter; left time: 1116.5655s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977558\n",
      "\tspeed: 0.0267s/iter; left time: 551.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1010973 Vali Loss: 0.1182861 Test Loss: 0.1272469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0999197\n",
      "\tspeed: 0.0532s/iter; left time: 1090.9066s\n",
      "\titers: 200, epoch: 9 | loss: 0.1026386\n",
      "\tspeed: 0.0268s/iter; left time: 546.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1004929 Vali Loss: 0.1175796 Test Loss: 0.1266904\n",
      "Validation loss decreased (0.117963 --> 0.117580).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008377\n",
      "\tspeed: 0.0538s/iter; left time: 1091.6922s\n",
      "\titers: 200, epoch: 10 | loss: 0.0974689\n",
      "\tspeed: 0.0268s/iter; left time: 541.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1000229 Vali Loss: 0.1174014 Test Loss: 0.1273050\n",
      "Validation loss decreased (0.117580 --> 0.117401).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0975121\n",
      "\tspeed: 0.0536s/iter; left time: 1074.5040s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031677\n",
      "\tspeed: 0.0268s/iter; left time: 534.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0996410 Vali Loss: 0.1172269 Test Loss: 0.1274734\n",
      "Validation loss decreased (0.117401 --> 0.117227).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019047\n",
      "\tspeed: 0.0535s/iter; left time: 1062.0590s\n",
      "\titers: 200, epoch: 12 | loss: 0.0963887\n",
      "\tspeed: 0.0268s/iter; left time: 528.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0992125 Vali Loss: 0.1170878 Test Loss: 0.1278752\n",
      "Validation loss decreased (0.117227 --> 0.117088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961119\n",
      "\tspeed: 0.0544s/iter; left time: 1066.5978s\n",
      "\titers: 200, epoch: 13 | loss: 0.0989636\n",
      "\tspeed: 0.0268s/iter; left time: 523.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0988020 Vali Loss: 0.1168609 Test Loss: 0.1279964\n",
      "Validation loss decreased (0.117088 --> 0.116861).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0999261\n",
      "\tspeed: 0.0537s/iter; left time: 1040.9073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937633\n",
      "\tspeed: 0.0269s/iter; left time: 517.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0984957 Vali Loss: 0.1170542 Test Loss: 0.1275455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0966726\n",
      "\tspeed: 0.0539s/iter; left time: 1033.5501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981507\n",
      "\tspeed: 0.0270s/iter; left time: 515.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0981710 Vali Loss: 0.1166702 Test Loss: 0.1279635\n",
      "Validation loss decreased (0.116861 --> 0.116670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1011894\n",
      "\tspeed: 0.0547s/iter; left time: 1036.4337s\n",
      "\titers: 200, epoch: 16 | loss: 0.1026321\n",
      "\tspeed: 0.0271s/iter; left time: 510.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0978653 Vali Loss: 0.1167809 Test Loss: 0.1274564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973510\n",
      "\tspeed: 0.0535s/iter; left time: 1000.7220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0980666\n",
      "\tspeed: 0.0269s/iter; left time: 501.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0976454 Vali Loss: 0.1168894 Test Loss: 0.1274555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0964897\n",
      "\tspeed: 0.0535s/iter; left time: 989.2355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0915851\n",
      "\tspeed: 0.0269s/iter; left time: 494.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0973645 Vali Loss: 0.1169818 Test Loss: 0.1278145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0937841\n",
      "\tspeed: 0.0539s/iter; left time: 984.7285s\n",
      "\titers: 200, epoch: 19 | loss: 0.0945172\n",
      "\tspeed: 0.0268s/iter; left time: 486.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0971042 Vali Loss: 0.1170631 Test Loss: 0.1279219\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0976394\n",
      "\tspeed: 0.0532s/iter; left time: 959.2814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025702\n",
      "\tspeed: 0.0268s/iter; left time: 480.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0969481 Vali Loss: 0.1168795 Test Loss: 0.1282358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0984403\n",
      "\tspeed: 0.0539s/iter; left time: 960.3656s\n",
      "\titers: 200, epoch: 21 | loss: 0.0932305\n",
      "\tspeed: 0.0269s/iter; left time: 477.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0967456 Vali Loss: 0.1170377 Test Loss: 0.1280329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0958503\n",
      "\tspeed: 0.0537s/iter; left time: 945.1394s\n",
      "\titers: 200, epoch: 22 | loss: 0.0987119\n",
      "\tspeed: 0.0269s/iter; left time: 471.5420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0965442 Vali Loss: 0.1168456 Test Loss: 0.1277162\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0967639\n",
      "\tspeed: 0.0528s/iter; left time: 917.3884s\n",
      "\titers: 200, epoch: 23 | loss: 0.1017741\n",
      "\tspeed: 0.0268s/iter; left time: 463.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0964595 Vali Loss: 0.1169775 Test Loss: 0.1280533\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1019816\n",
      "\tspeed: 0.0538s/iter; left time: 922.2519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0947855\n",
      "\tspeed: 0.0269s/iter; left time: 458.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0962695 Vali Loss: 0.1168131 Test Loss: 0.1279567\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0958062\n",
      "\tspeed: 0.0530s/iter; left time: 897.5916s\n",
      "\titers: 200, epoch: 25 | loss: 0.0925729\n",
      "\tspeed: 0.0269s/iter; left time: 452.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961852 Vali Loss: 0.1169263 Test Loss: 0.1279396\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03738878667354584, rmse:0.1933618038892746, mae:0.12796346843242645, rse:0.6847332715988159\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1453122\n",
      "\tspeed: 0.0287s/iter; left time: 639.1908s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341071\n",
      "\tspeed: 0.0268s/iter; left time: 594.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1493950 Vali Loss: 0.1402512 Test Loss: 0.1483553\n",
      "Validation loss decreased (inf --> 0.140251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097633\n",
      "\tspeed: 0.0543s/iter; left time: 1198.2260s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095724\n",
      "\tspeed: 0.0269s/iter; left time: 591.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1142674 Vali Loss: 0.1222842 Test Loss: 0.1300744\n",
      "Validation loss decreased (0.140251 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055942\n",
      "\tspeed: 0.0555s/iter; left time: 1212.4990s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084602\n",
      "\tspeed: 0.0270s/iter; left time: 587.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1065267 Vali Loss: 0.1205910 Test Loss: 0.1294958\n",
      "Validation loss decreased (0.122284 --> 0.120591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018099\n",
      "\tspeed: 0.0542s/iter; left time: 1171.7338s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051938\n",
      "\tspeed: 0.0269s/iter; left time: 579.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1047808 Vali Loss: 0.1190739 Test Loss: 0.1283687\n",
      "Validation loss decreased (0.120591 --> 0.119074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018800\n",
      "\tspeed: 0.0539s/iter; left time: 1153.8204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956694\n",
      "\tspeed: 0.0267s/iter; left time: 569.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1035395 Vali Loss: 0.1188459 Test Loss: 0.1280372\n",
      "Validation loss decreased (0.119074 --> 0.118846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0991640\n",
      "\tspeed: 0.0546s/iter; left time: 1156.3359s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049700\n",
      "\tspeed: 0.0269s/iter; left time: 568.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1181803 Test Loss: 0.1279618\n",
      "Validation loss decreased (0.118846 --> 0.118180).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013687\n",
      "\tspeed: 0.0545s/iter; left time: 1142.8758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993038\n",
      "\tspeed: 0.0268s/iter; left time: 557.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1018238 Vali Loss: 0.1180655 Test Loss: 0.1277595\n",
      "Validation loss decreased (0.118180 --> 0.118066).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997346\n",
      "\tspeed: 0.0555s/iter; left time: 1150.8520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997878\n",
      "\tspeed: 0.0270s/iter; left time: 557.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1010508 Vali Loss: 0.1179035 Test Loss: 0.1281448\n",
      "Validation loss decreased (0.118066 --> 0.117903).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0988701\n",
      "\tspeed: 0.0563s/iter; left time: 1154.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0968515\n",
      "\tspeed: 0.0271s/iter; left time: 552.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1004422 Vali Loss: 0.1178284 Test Loss: 0.1291293\n",
      "Validation loss decreased (0.117903 --> 0.117828).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008913\n",
      "\tspeed: 0.0546s/iter; left time: 1108.5587s\n",
      "\titers: 200, epoch: 10 | loss: 0.0954883\n",
      "\tspeed: 0.0267s/iter; left time: 539.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0998062 Vali Loss: 0.1179435 Test Loss: 0.1273128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1016945\n",
      "\tspeed: 0.0525s/iter; left time: 1052.5954s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974247\n",
      "\tspeed: 0.0269s/iter; left time: 536.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0992023 Vali Loss: 0.1177902 Test Loss: 0.1276344\n",
      "Validation loss decreased (0.117828 --> 0.117790).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0978504\n",
      "\tspeed: 0.0552s/iter; left time: 1094.3827s\n",
      "\titers: 200, epoch: 12 | loss: 0.1006840\n",
      "\tspeed: 0.0270s/iter; left time: 533.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0986686 Vali Loss: 0.1178868 Test Loss: 0.1283520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029566\n",
      "\tspeed: 0.0534s/iter; left time: 1048.1343s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995638\n",
      "\tspeed: 0.0267s/iter; left time: 521.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0982064 Vali Loss: 0.1177266 Test Loss: 0.1271849\n",
      "Validation loss decreased (0.117790 --> 0.117727).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966322\n",
      "\tspeed: 0.0541s/iter; left time: 1048.6480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0939447\n",
      "\tspeed: 0.0271s/iter; left time: 521.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0977019 Vali Loss: 0.1176199 Test Loss: 0.1285766\n",
      "Validation loss decreased (0.117727 --> 0.117620).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0955380\n",
      "\tspeed: 0.0567s/iter; left time: 1086.8307s\n",
      "\titers: 200, epoch: 15 | loss: 0.0928111\n",
      "\tspeed: 0.0271s/iter; left time: 516.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0973574 Vali Loss: 0.1177496 Test Loss: 0.1279720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019763\n",
      "\tspeed: 0.0549s/iter; left time: 1039.6933s\n",
      "\titers: 200, epoch: 16 | loss: 0.1012777\n",
      "\tspeed: 0.0270s/iter; left time: 509.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0969753 Vali Loss: 0.1177540 Test Loss: 0.1296667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0968168\n",
      "\tspeed: 0.0551s/iter; left time: 1030.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0930788\n",
      "\tspeed: 0.0270s/iter; left time: 502.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0968140 Vali Loss: 0.1179194 Test Loss: 0.1291604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0877084\n",
      "\tspeed: 0.0546s/iter; left time: 1009.5318s\n",
      "\titers: 200, epoch: 18 | loss: 0.0964585\n",
      "\tspeed: 0.0271s/iter; left time: 497.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0964126 Vali Loss: 0.1179514 Test Loss: 0.1292164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978073\n",
      "\tspeed: 0.0549s/iter; left time: 1002.6800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927446\n",
      "\tspeed: 0.0270s/iter; left time: 491.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0961563 Vali Loss: 0.1180256 Test Loss: 0.1296065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997547\n",
      "\tspeed: 0.0541s/iter; left time: 976.4935s\n",
      "\titers: 200, epoch: 20 | loss: 0.0986387\n",
      "\tspeed: 0.0274s/iter; left time: 491.8739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0959443 Vali Loss: 0.1176773 Test Loss: 0.1286344\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0958655\n",
      "\tspeed: 0.0560s/iter; left time: 998.6060s\n",
      "\titers: 200, epoch: 21 | loss: 0.0964852\n",
      "\tspeed: 0.0270s/iter; left time: 478.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0957407 Vali Loss: 0.1176798 Test Loss: 0.1287229\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0942021\n",
      "\tspeed: 0.0553s/iter; left time: 972.3128s\n",
      "\titers: 200, epoch: 22 | loss: 0.0922590\n",
      "\tspeed: 0.0270s/iter; left time: 472.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0955422 Vali Loss: 0.1179530 Test Loss: 0.1288881\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0922816\n",
      "\tspeed: 0.0546s/iter; left time: 948.8017s\n",
      "\titers: 200, epoch: 23 | loss: 0.0962126\n",
      "\tspeed: 0.0273s/iter; left time: 471.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0954098 Vali Loss: 0.1179873 Test Loss: 0.1291286\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0962873\n",
      "\tspeed: 0.0545s/iter; left time: 933.8682s\n",
      "\titers: 200, epoch: 24 | loss: 0.0961054\n",
      "\tspeed: 0.0271s/iter; left time: 462.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0953075 Vali Loss: 0.1179708 Test Loss: 0.1295294\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037975143641233444, rmse:0.19487212598323822, mae:0.1285766065120697, rse:0.6900815963745117\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:50.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1511204\n",
      "\tspeed: 0.0547s/iter; left time: 1213.9765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396091\n",
      "\tspeed: 0.0271s/iter; left time: 598.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.1507847 Vali Loss: 0.1426704 Test Loss: 0.1519556\n",
      "Validation loss decreased (inf --> 0.142670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1238355\n",
      "\tspeed: 0.0542s/iter; left time: 1191.4815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123134\n",
      "\tspeed: 0.0274s/iter; left time: 599.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1200940 Vali Loss: 0.1261885 Test Loss: 0.1355995\n",
      "Validation loss decreased (0.142670 --> 0.126188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164904\n",
      "\tspeed: 0.0582s/iter; left time: 1265.1403s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123756\n",
      "\tspeed: 0.0274s/iter; left time: 593.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1126304 Vali Loss: 0.1248742 Test Loss: 0.1346599\n",
      "Validation loss decreased (0.126188 --> 0.124874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090264\n",
      "\tspeed: 0.0564s/iter; left time: 1214.2777s\n",
      "\titers: 200, epoch: 4 | loss: 0.1161850\n",
      "\tspeed: 0.0277s/iter; left time: 593.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1108241 Vali Loss: 0.1231168 Test Loss: 0.1345049\n",
      "Validation loss decreased (0.124874 --> 0.123117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1067239\n",
      "\tspeed: 0.0557s/iter; left time: 1187.0533s\n",
      "\titers: 200, epoch: 5 | loss: 0.1134487\n",
      "\tspeed: 0.0273s/iter; left time: 578.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1096404 Vali Loss: 0.1232052 Test Loss: 0.1344802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046681\n",
      "\tspeed: 0.0548s/iter; left time: 1154.7548s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130422\n",
      "\tspeed: 0.0273s/iter; left time: 573.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1086139 Vali Loss: 0.1229566 Test Loss: 0.1347695\n",
      "Validation loss decreased (0.123117 --> 0.122957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1078895\n",
      "\tspeed: 0.0562s/iter; left time: 1172.1359s\n",
      "\titers: 200, epoch: 7 | loss: 0.1087261\n",
      "\tspeed: 0.0273s/iter; left time: 566.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1077184 Vali Loss: 0.1223245 Test Loss: 0.1334847\n",
      "Validation loss decreased (0.122957 --> 0.122324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035181\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6720s\n",
      "\titers: 200, epoch: 8 | loss: 0.1118061\n",
      "\tspeed: 0.0274s/iter; left time: 562.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1069834 Vali Loss: 0.1218858 Test Loss: 0.1330454\n",
      "Validation loss decreased (0.122324 --> 0.121886).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1058632\n",
      "\tspeed: 0.0555s/iter; left time: 1132.6126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987647\n",
      "\tspeed: 0.0272s/iter; left time: 553.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1062651 Vali Loss: 0.1219982 Test Loss: 0.1338042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1030127\n",
      "\tspeed: 0.0538s/iter; left time: 1086.2314s\n",
      "\titers: 200, epoch: 10 | loss: 0.1031541\n",
      "\tspeed: 0.0273s/iter; left time: 548.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1056596 Vali Loss: 0.1220121 Test Loss: 0.1338617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1061721\n",
      "\tspeed: 0.0545s/iter; left time: 1089.1685s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000139\n",
      "\tspeed: 0.0286s/iter; left time: 568.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1051509 Vali Loss: 0.1223389 Test Loss: 0.1343730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1016918\n",
      "\tspeed: 0.0557s/iter; left time: 1099.9068s\n",
      "\titers: 200, epoch: 12 | loss: 0.1091376\n",
      "\tspeed: 0.0273s/iter; left time: 536.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.1046909 Vali Loss: 0.1220724 Test Loss: 0.1342280\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1095180\n",
      "\tspeed: 0.0545s/iter; left time: 1064.6654s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059984\n",
      "\tspeed: 0.0273s/iter; left time: 529.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1042259 Vali Loss: 0.1223401 Test Loss: 0.1342049\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0977468\n",
      "\tspeed: 0.0541s/iter; left time: 1045.0044s\n",
      "\titers: 200, epoch: 14 | loss: 0.1107927\n",
      "\tspeed: 0.0270s/iter; left time: 518.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1039162 Vali Loss: 0.1222137 Test Loss: 0.1342742\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1054508\n",
      "\tspeed: 0.0546s/iter; left time: 1042.4705s\n",
      "\titers: 200, epoch: 15 | loss: 0.1117989\n",
      "\tspeed: 0.0273s/iter; left time: 517.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035189 Vali Loss: 0.1224293 Test Loss: 0.1347673\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1062974\n",
      "\tspeed: 0.0547s/iter; left time: 1030.8627s\n",
      "\titers: 200, epoch: 16 | loss: 0.1125161\n",
      "\tspeed: 0.0272s/iter; left time: 511.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1031467 Vali Loss: 0.1224126 Test Loss: 0.1339886\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1029710\n",
      "\tspeed: 0.0545s/iter; left time: 1015.8779s\n",
      "\titers: 200, epoch: 17 | loss: 0.1050183\n",
      "\tspeed: 0.0273s/iter; left time: 505.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1029577 Vali Loss: 0.1227930 Test Loss: 0.1340047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1025430\n",
      "\tspeed: 0.0542s/iter; left time: 998.1419s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046702\n",
      "\tspeed: 0.0272s/iter; left time: 497.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1026303 Vali Loss: 0.1226197 Test Loss: 0.1343808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03874775022268295, rmse:0.19684448838233948, mae:0.13304544985294342, rse:0.6972389817237854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1546361\n",
      "\tspeed: 0.0298s/iter; left time: 662.3935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357865\n",
      "\tspeed: 0.0272s/iter; left time: 600.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1520326 Vali Loss: 0.1427907 Test Loss: 0.1520844\n",
      "Validation loss decreased (inf --> 0.142791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183958\n",
      "\tspeed: 0.0566s/iter; left time: 1243.1818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188114\n",
      "\tspeed: 0.0273s/iter; left time: 597.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1199734 Vali Loss: 0.1263667 Test Loss: 0.1363375\n",
      "Validation loss decreased (0.142791 --> 0.126367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1155362\n",
      "\tspeed: 0.0556s/iter; left time: 1208.6087s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098592\n",
      "\tspeed: 0.0272s/iter; left time: 588.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1126673 Vali Loss: 0.1251423 Test Loss: 0.1348121\n",
      "Validation loss decreased (0.126367 --> 0.125142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086826\n",
      "\tspeed: 0.0557s/iter; left time: 1199.5182s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126055\n",
      "\tspeed: 0.0274s/iter; left time: 587.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1106587 Vali Loss: 0.1242879 Test Loss: 0.1354954\n",
      "Validation loss decreased (0.125142 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1116844\n",
      "\tspeed: 0.0560s/iter; left time: 1194.1369s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103760\n",
      "\tspeed: 0.0274s/iter; left time: 580.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1092648 Vali Loss: 0.1238110 Test Loss: 0.1339414\n",
      "Validation loss decreased (0.124288 --> 0.123811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062780\n",
      "\tspeed: 0.0556s/iter; left time: 1172.0651s\n",
      "\titers: 200, epoch: 6 | loss: 0.1105472\n",
      "\tspeed: 0.0275s/iter; left time: 576.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1083813 Vali Loss: 0.1230377 Test Loss: 0.1344151\n",
      "Validation loss decreased (0.123811 --> 0.123038).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1100236\n",
      "\tspeed: 0.0563s/iter; left time: 1173.7410s\n",
      "\titers: 200, epoch: 7 | loss: 0.1094361\n",
      "\tspeed: 0.0271s/iter; left time: 563.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1075638 Vali Loss: 0.1233376 Test Loss: 0.1351425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1083931\n",
      "\tspeed: 0.0550s/iter; left time: 1135.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076261\n",
      "\tspeed: 0.0272s/iter; left time: 559.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1067569 Vali Loss: 0.1231392 Test Loss: 0.1350849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042043\n",
      "\tspeed: 0.0562s/iter; left time: 1148.2966s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087456\n",
      "\tspeed: 0.0286s/iter; left time: 580.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.1061874 Vali Loss: 0.1229115 Test Loss: 0.1347596\n",
      "Validation loss decreased (0.123038 --> 0.122912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047019\n",
      "\tspeed: 0.0569s/iter; left time: 1149.2216s\n",
      "\titers: 200, epoch: 10 | loss: 0.1098653\n",
      "\tspeed: 0.0274s/iter; left time: 551.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1054878 Vali Loss: 0.1231185 Test Loss: 0.1345507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1028828\n",
      "\tspeed: 0.0549s/iter; left time: 1096.4879s\n",
      "\titers: 200, epoch: 11 | loss: 0.1091575\n",
      "\tspeed: 0.0277s/iter; left time: 549.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1048839 Vali Loss: 0.1236878 Test Loss: 0.1354434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043799\n",
      "\tspeed: 0.0562s/iter; left time: 1109.6457s\n",
      "\titers: 200, epoch: 12 | loss: 0.1061269\n",
      "\tspeed: 0.0280s/iter; left time: 549.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.1043107 Vali Loss: 0.1239945 Test Loss: 0.1346901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1080359\n",
      "\tspeed: 0.0548s/iter; left time: 1070.4594s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058448\n",
      "\tspeed: 0.0271s/iter; left time: 527.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1037742 Vali Loss: 0.1241476 Test Loss: 0.1351113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1032596\n",
      "\tspeed: 0.0556s/iter; left time: 1073.1232s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017853\n",
      "\tspeed: 0.0273s/iter; left time: 523.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1033254 Vali Loss: 0.1241768 Test Loss: 0.1357941\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1011182\n",
      "\tspeed: 0.0548s/iter; left time: 1044.6235s\n",
      "\titers: 200, epoch: 15 | loss: 0.1017340\n",
      "\tspeed: 0.0272s/iter; left time: 516.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1029318 Vali Loss: 0.1242862 Test Loss: 0.1359198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1043327\n",
      "\tspeed: 0.0555s/iter; left time: 1046.7619s\n",
      "\titers: 200, epoch: 16 | loss: 0.1076296\n",
      "\tspeed: 0.0273s/iter; left time: 511.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1024750 Vali Loss: 0.1245145 Test Loss: 0.1355859\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003824\n",
      "\tspeed: 0.0549s/iter; left time: 1023.8289s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016187\n",
      "\tspeed: 0.0274s/iter; left time: 507.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1022286 Vali Loss: 0.1240813 Test Loss: 0.1352433\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041608\n",
      "\tspeed: 0.0561s/iter; left time: 1032.5608s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061510\n",
      "\tspeed: 0.0277s/iter; left time: 506.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1019955 Vali Loss: 0.1249169 Test Loss: 0.1354775\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1080255\n",
      "\tspeed: 0.0557s/iter; left time: 1013.8191s\n",
      "\titers: 200, epoch: 19 | loss: 0.0987023\n",
      "\tspeed: 0.0274s/iter; left time: 496.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1016865 Vali Loss: 0.1249771 Test Loss: 0.1352909\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03975802659988403, rmse:0.19939415156841278, mae:0.13475961983203888, rse:0.7062700986862183\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:20.07s\n",
      "Intermediate time for DE: 00h:27m:01.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1243801\n",
      "\tspeed: 0.0543s/iter; left time: 1211.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137652\n",
      "\tspeed: 0.0266s/iter; left time: 590.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.1302879 Vali Loss: 0.1216964 Test Loss: 0.1408504\n",
      "Validation loss decreased (inf --> 0.121696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0839070\n",
      "\tspeed: 0.0520s/iter; left time: 1147.3483s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818553\n",
      "\tspeed: 0.0265s/iter; left time: 583.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0865396 Vali Loss: 0.0920018 Test Loss: 0.1033591\n",
      "Validation loss decreased (0.121696 --> 0.092002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733085\n",
      "\tspeed: 0.0515s/iter; left time: 1125.3848s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821068\n",
      "\tspeed: 0.0267s/iter; left time: 581.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0793856 Vali Loss: 0.0900384 Test Loss: 0.1024917\n",
      "Validation loss decreased (0.092002 --> 0.090038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0750556\n",
      "\tspeed: 0.0518s/iter; left time: 1121.1212s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780856\n",
      "\tspeed: 0.0264s/iter; left time: 568.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0779691 Vali Loss: 0.0899016 Test Loss: 0.1022058\n",
      "Validation loss decreased (0.090038 --> 0.089902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758535\n",
      "\tspeed: 0.0517s/iter; left time: 1107.5445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757776\n",
      "\tspeed: 0.0267s/iter; left time: 568.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0769919 Vali Loss: 0.0893033 Test Loss: 0.1019564\n",
      "Validation loss decreased (0.089902 --> 0.089303).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798705\n",
      "\tspeed: 0.0522s/iter; left time: 1104.7398s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816744\n",
      "\tspeed: 0.0267s/iter; left time: 563.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0762630 Vali Loss: 0.0887678 Test Loss: 0.1014424\n",
      "Validation loss decreased (0.089303 --> 0.088768).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754332\n",
      "\tspeed: 0.0518s/iter; left time: 1085.2478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806607\n",
      "\tspeed: 0.0267s/iter; left time: 557.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0756519 Vali Loss: 0.0887744 Test Loss: 0.1014127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728288\n",
      "\tspeed: 0.0511s/iter; left time: 1059.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775176\n",
      "\tspeed: 0.0266s/iter; left time: 547.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0752004 Vali Loss: 0.0885392 Test Loss: 0.1006487\n",
      "Validation loss decreased (0.088768 --> 0.088539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738876\n",
      "\tspeed: 0.0528s/iter; left time: 1082.2772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792237\n",
      "\tspeed: 0.0268s/iter; left time: 546.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0748653 Vali Loss: 0.0884795 Test Loss: 0.1006068\n",
      "Validation loss decreased (0.088539 --> 0.088479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808073\n",
      "\tspeed: 0.0520s/iter; left time: 1054.3701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720843\n",
      "\tspeed: 0.0267s/iter; left time: 538.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0745151 Vali Loss: 0.0878042 Test Loss: 0.1009895\n",
      "Validation loss decreased (0.088479 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773240\n",
      "\tspeed: 0.0519s/iter; left time: 1041.0894s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738162\n",
      "\tspeed: 0.0267s/iter; left time: 531.9959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0742512 Vali Loss: 0.0880865 Test Loss: 0.1001864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778451\n",
      "\tspeed: 0.0510s/iter; left time: 1012.4607s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704564\n",
      "\tspeed: 0.0267s/iter; left time: 527.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0739914 Vali Loss: 0.0879424 Test Loss: 0.1007774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728143\n",
      "\tspeed: 0.0519s/iter; left time: 1018.4859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723630\n",
      "\tspeed: 0.0266s/iter; left time: 520.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0738506 Vali Loss: 0.0879685 Test Loss: 0.1000657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773398\n",
      "\tspeed: 0.0518s/iter; left time: 1004.9878s\n",
      "\titers: 200, epoch: 14 | loss: 0.0699778\n",
      "\tspeed: 0.0267s/iter; left time: 514.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0736961 Vali Loss: 0.0878420 Test Loss: 0.0999213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665786\n",
      "\tspeed: 0.0518s/iter; left time: 992.4915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0686087\n",
      "\tspeed: 0.0266s/iter; left time: 507.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0734943 Vali Loss: 0.0880088 Test Loss: 0.1000402\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704044\n",
      "\tspeed: 0.0525s/iter; left time: 993.4795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735029\n",
      "\tspeed: 0.0268s/iter; left time: 505.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0733230 Vali Loss: 0.0875390 Test Loss: 0.1002045\n",
      "Validation loss decreased (0.087804 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733052\n",
      "\tspeed: 0.0529s/iter; left time: 989.9356s\n",
      "\titers: 200, epoch: 17 | loss: 0.0776525\n",
      "\tspeed: 0.0267s/iter; left time: 496.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0732607 Vali Loss: 0.0874719 Test Loss: 0.0997542\n",
      "Validation loss decreased (0.087539 --> 0.087472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0733563\n",
      "\tspeed: 0.0528s/iter; left time: 976.5661s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740419\n",
      "\tspeed: 0.0269s/iter; left time: 493.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0731655 Vali Loss: 0.0875383 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0704366\n",
      "\tspeed: 0.0523s/iter; left time: 956.2087s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727878\n",
      "\tspeed: 0.0269s/iter; left time: 488.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0730607 Vali Loss: 0.0878342 Test Loss: 0.0998149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639565\n",
      "\tspeed: 0.0523s/iter; left time: 943.3723s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710644\n",
      "\tspeed: 0.0268s/iter; left time: 481.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0729284 Vali Loss: 0.0876287 Test Loss: 0.0996863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751909\n",
      "\tspeed: 0.0521s/iter; left time: 928.5994s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704616\n",
      "\tspeed: 0.0265s/iter; left time: 469.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0727867 Vali Loss: 0.0875195 Test Loss: 0.0996076\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0709846\n",
      "\tspeed: 0.0528s/iter; left time: 928.9821s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672187\n",
      "\tspeed: 0.0271s/iter; left time: 473.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0727850 Vali Loss: 0.0873734 Test Loss: 0.0995667\n",
      "Validation loss decreased (0.087472 --> 0.087373).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724984\n",
      "\tspeed: 0.0546s/iter; left time: 947.7766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0676599\n",
      "\tspeed: 0.0269s/iter; left time: 464.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0727007 Vali Loss: 0.0874452 Test Loss: 0.0995794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0710710\n",
      "\tspeed: 0.0533s/iter; left time: 914.8627s\n",
      "\titers: 200, epoch: 24 | loss: 0.0718718\n",
      "\tspeed: 0.0272s/iter; left time: 463.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0726696 Vali Loss: 0.0874877 Test Loss: 0.0994474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0733318\n",
      "\tspeed: 0.0538s/iter; left time: 909.7842s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770599\n",
      "\tspeed: 0.0271s/iter; left time: 456.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0726920 Vali Loss: 0.0873381 Test Loss: 0.0994857\n",
      "Validation loss decreased (0.087373 --> 0.087338).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0732230\n",
      "\tspeed: 0.0537s/iter; left time: 896.6000s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704290\n",
      "\tspeed: 0.0268s/iter; left time: 445.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0726002 Vali Loss: 0.0874241 Test Loss: 0.0995524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722607\n",
      "\tspeed: 0.0535s/iter; left time: 881.7593s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757692\n",
      "\tspeed: 0.0273s/iter; left time: 446.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0725308 Vali Loss: 0.0873835 Test Loss: 0.0995856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780362\n",
      "\tspeed: 0.0530s/iter; left time: 860.7019s\n",
      "\titers: 200, epoch: 28 | loss: 0.0754186\n",
      "\tspeed: 0.0269s/iter; left time: 433.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724948 Vali Loss: 0.0874800 Test Loss: 0.0996659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0755497\n",
      "\tspeed: 0.0534s/iter; left time: 856.6310s\n",
      "\titers: 200, epoch: 29 | loss: 0.0672095\n",
      "\tspeed: 0.0269s/iter; left time: 427.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724994 Vali Loss: 0.0873726 Test Loss: 0.0994512\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743681\n",
      "\tspeed: 0.0530s/iter; left time: 837.2495s\n",
      "\titers: 200, epoch: 30 | loss: 0.0714248\n",
      "\tspeed: 0.0268s/iter; left time: 421.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0724325 Vali Loss: 0.0874007 Test Loss: 0.0996015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670253\n",
      "\tspeed: 0.0540s/iter; left time: 840.9434s\n",
      "\titers: 200, epoch: 31 | loss: 0.0738778\n",
      "\tspeed: 0.0265s/iter; left time: 410.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723963 Vali Loss: 0.0873461 Test Loss: 0.0995764\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0729594\n",
      "\tspeed: 0.0534s/iter; left time: 820.6041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0743888\n",
      "\tspeed: 0.0268s/iter; left time: 409.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0724081 Vali Loss: 0.0872245 Test Loss: 0.0994373\n",
      "Validation loss decreased (0.087338 --> 0.087224).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723266\n",
      "\tspeed: 0.0541s/iter; left time: 818.1361s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713193\n",
      "\tspeed: 0.0269s/iter; left time: 404.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0723961 Vali Loss: 0.0874335 Test Loss: 0.0996177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0732763\n",
      "\tspeed: 0.0532s/iter; left time: 793.2879s\n",
      "\titers: 200, epoch: 34 | loss: 0.0748497\n",
      "\tspeed: 0.0268s/iter; left time: 396.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0723704 Vali Loss: 0.0873889 Test Loss: 0.0995195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779761\n",
      "\tspeed: 0.0529s/iter; left time: 776.7366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0753652\n",
      "\tspeed: 0.0268s/iter; left time: 390.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723036 Vali Loss: 0.0872547 Test Loss: 0.0995013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686231\n",
      "\tspeed: 0.0528s/iter; left time: 764.0125s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763031\n",
      "\tspeed: 0.0268s/iter; left time: 384.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722592 Vali Loss: 0.0874217 Test Loss: 0.0995324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755020\n",
      "\tspeed: 0.0527s/iter; left time: 750.5292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0714776\n",
      "\tspeed: 0.0268s/iter; left time: 378.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723462 Vali Loss: 0.0874196 Test Loss: 0.0995449\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0748234\n",
      "\tspeed: 0.0534s/iter; left time: 747.9698s\n",
      "\titers: 200, epoch: 38 | loss: 0.0689176\n",
      "\tspeed: 0.0268s/iter; left time: 373.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0723155 Vali Loss: 0.0872684 Test Loss: 0.0995207\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765601\n",
      "\tspeed: 0.0540s/iter; left time: 744.7602s\n",
      "\titers: 200, epoch: 39 | loss: 0.0677570\n",
      "\tspeed: 0.0268s/iter; left time: 366.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722663 Vali Loss: 0.0874316 Test Loss: 0.0995467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0654785\n",
      "\tspeed: 0.0528s/iter; left time: 716.1290s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748680\n",
      "\tspeed: 0.0265s/iter; left time: 356.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0723363 Vali Loss: 0.0873764 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700707\n",
      "\tspeed: 0.0531s/iter; left time: 708.0991s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708900\n",
      "\tspeed: 0.0270s/iter; left time: 356.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0722918 Vali Loss: 0.0873483 Test Loss: 0.0995223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721399\n",
      "\tspeed: 0.0532s/iter; left time: 697.5313s\n",
      "\titers: 200, epoch: 42 | loss: 0.0775154\n",
      "\tspeed: 0.0272s/iter; left time: 353.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0722849 Vali Loss: 0.0872172 Test Loss: 0.0995116\n",
      "Validation loss decreased (0.087224 --> 0.087217).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0751871\n",
      "\tspeed: 0.0535s/iter; left time: 689.5227s\n",
      "\titers: 200, epoch: 43 | loss: 0.0700004\n",
      "\tspeed: 0.0269s/iter; left time: 343.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722874 Vali Loss: 0.0872460 Test Loss: 0.0994964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0771745\n",
      "\tspeed: 0.0536s/iter; left time: 678.9808s\n",
      "\titers: 200, epoch: 44 | loss: 0.0732692\n",
      "\tspeed: 0.0268s/iter; left time: 336.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722729 Vali Loss: 0.0872457 Test Loss: 0.0994803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0702146\n",
      "\tspeed: 0.0527s/iter; left time: 656.2688s\n",
      "\titers: 200, epoch: 45 | loss: 0.0754088\n",
      "\tspeed: 0.0268s/iter; left time: 330.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0872447 Test Loss: 0.0994848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0695563\n",
      "\tspeed: 0.0525s/iter; left time: 641.3707s\n",
      "\titers: 200, epoch: 46 | loss: 0.0708172\n",
      "\tspeed: 0.0269s/iter; left time: 325.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722368 Vali Loss: 0.0872585 Test Loss: 0.0994719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0748870\n",
      "\tspeed: 0.0531s/iter; left time: 636.6953s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730831\n",
      "\tspeed: 0.0269s/iter; left time: 319.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722215 Vali Loss: 0.0873487 Test Loss: 0.0995225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0761661\n",
      "\tspeed: 0.0530s/iter; left time: 624.1234s\n",
      "\titers: 200, epoch: 48 | loss: 0.0745982\n",
      "\tspeed: 0.0268s/iter; left time: 312.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721901 Vali Loss: 0.0873764 Test Loss: 0.0994837\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0708556\n",
      "\tspeed: 0.0533s/iter; left time: 615.7655s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708657\n",
      "\tspeed: 0.0268s/iter; left time: 307.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722119 Vali Loss: 0.0872935 Test Loss: 0.0994825\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738270\n",
      "\tspeed: 0.0525s/iter; left time: 594.2805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0708394\n",
      "\tspeed: 0.0269s/iter; left time: 301.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721791 Vali Loss: 0.0872133 Test Loss: 0.0994824\n",
      "Validation loss decreased (0.087217 --> 0.087213).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0729056\n",
      "\tspeed: 0.0537s/iter; left time: 596.5067s\n",
      "\titers: 200, epoch: 51 | loss: 0.0680218\n",
      "\tspeed: 0.0268s/iter; left time: 294.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721853 Vali Loss: 0.0873186 Test Loss: 0.0994690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0694491\n",
      "\tspeed: 0.0528s/iter; left time: 574.4605s\n",
      "\titers: 200, epoch: 52 | loss: 0.0776386\n",
      "\tspeed: 0.0269s/iter; left time: 289.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0722179 Vali Loss: 0.0873789 Test Loss: 0.0994850\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0731650\n",
      "\tspeed: 0.0526s/iter; left time: 559.9777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0769954\n",
      "\tspeed: 0.0268s/iter; left time: 283.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721883 Vali Loss: 0.0873961 Test Loss: 0.0994792\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0745562\n",
      "\tspeed: 0.0537s/iter; left time: 559.6576s\n",
      "\titers: 200, epoch: 54 | loss: 0.0707905\n",
      "\tspeed: 0.0268s/iter; left time: 276.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722220 Vali Loss: 0.0872954 Test Loss: 0.0995034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0701514\n",
      "\tspeed: 0.0533s/iter; left time: 543.8353s\n",
      "\titers: 200, epoch: 55 | loss: 0.0714959\n",
      "\tspeed: 0.0271s/iter; left time: 274.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0873029 Test Loss: 0.0994843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0704450\n",
      "\tspeed: 0.0535s/iter; left time: 534.3546s\n",
      "\titers: 200, epoch: 56 | loss: 0.0675059\n",
      "\tspeed: 0.0269s/iter; left time: 266.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0721501 Vali Loss: 0.0873734 Test Loss: 0.0994912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0738333\n",
      "\tspeed: 0.0537s/iter; left time: 523.7482s\n",
      "\titers: 200, epoch: 57 | loss: 0.0705020\n",
      "\tspeed: 0.0269s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0722345 Vali Loss: 0.0874336 Test Loss: 0.0994758\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0767229\n",
      "\tspeed: 0.0527s/iter; left time: 502.0444s\n",
      "\titers: 200, epoch: 58 | loss: 0.0729605\n",
      "\tspeed: 0.0268s/iter; left time: 253.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722041 Vali Loss: 0.0873020 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0756847\n",
      "\tspeed: 0.0534s/iter; left time: 497.0981s\n",
      "\titers: 200, epoch: 59 | loss: 0.0757611\n",
      "\tspeed: 0.0268s/iter; left time: 247.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0721992 Vali Loss: 0.0872928 Test Loss: 0.0994752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0702965\n",
      "\tspeed: 0.0524s/iter; left time: 476.4810s\n",
      "\titers: 200, epoch: 60 | loss: 0.0741313\n",
      "\tspeed: 0.0268s/iter; left time: 240.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722097 Vali Loss: 0.0873115 Test Loss: 0.0994877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02502487227320671, rmse:0.15819251537322998, mae:0.09948243200778961, rse:0.54571932554245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1281256\n",
      "\tspeed: 0.0292s/iter; left time: 650.2233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1138560\n",
      "\tspeed: 0.0268s/iter; left time: 594.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1290584 Vali Loss: 0.1207433 Test Loss: 0.1395016\n",
      "Validation loss decreased (inf --> 0.120743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853941\n",
      "\tspeed: 0.0536s/iter; left time: 1182.5697s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847853\n",
      "\tspeed: 0.0269s/iter; left time: 590.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0861361 Vali Loss: 0.0918532 Test Loss: 0.1040095\n",
      "Validation loss decreased (0.120743 --> 0.091853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775025\n",
      "\tspeed: 0.0535s/iter; left time: 1169.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788021\n",
      "\tspeed: 0.0268s/iter; left time: 583.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0792676 Vali Loss: 0.0905056 Test Loss: 0.1025451\n",
      "Validation loss decreased (0.091853 --> 0.090506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744780\n",
      "\tspeed: 0.0530s/iter; left time: 1146.1907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797157\n",
      "\tspeed: 0.0268s/iter; left time: 576.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0780674 Vali Loss: 0.0906739 Test Loss: 0.1020297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770665\n",
      "\tspeed: 0.0537s/iter; left time: 1149.1107s\n",
      "\titers: 200, epoch: 5 | loss: 0.0766374\n",
      "\tspeed: 0.0268s/iter; left time: 571.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0769707 Vali Loss: 0.0894935 Test Loss: 0.1018222\n",
      "Validation loss decreased (0.090506 --> 0.089494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809719\n",
      "\tspeed: 0.0542s/iter; left time: 1148.6083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820128\n",
      "\tspeed: 0.0268s/iter; left time: 565.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0762634 Vali Loss: 0.0891491 Test Loss: 0.1013036\n",
      "Validation loss decreased (0.089494 --> 0.089149).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794357\n",
      "\tspeed: 0.0534s/iter; left time: 1119.2823s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746093\n",
      "\tspeed: 0.0269s/iter; left time: 560.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0757042 Vali Loss: 0.0887241 Test Loss: 0.1007391\n",
      "Validation loss decreased (0.089149 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761330\n",
      "\tspeed: 0.0535s/iter; left time: 1109.9562s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747115\n",
      "\tspeed: 0.0269s/iter; left time: 555.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0752742 Vali Loss: 0.0889610 Test Loss: 0.1005073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797194\n",
      "\tspeed: 0.0531s/iter; left time: 1089.4519s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733876\n",
      "\tspeed: 0.0269s/iter; left time: 548.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0748621 Vali Loss: 0.0881851 Test Loss: 0.1004349\n",
      "Validation loss decreased (0.088724 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750555\n",
      "\tspeed: 0.0529s/iter; left time: 1073.6207s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730892\n",
      "\tspeed: 0.0268s/iter; left time: 540.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0745724 Vali Loss: 0.0886613 Test Loss: 0.0999387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0729881\n",
      "\tspeed: 0.0534s/iter; left time: 1071.6187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750049\n",
      "\tspeed: 0.0268s/iter; left time: 534.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0742235 Vali Loss: 0.0879054 Test Loss: 0.1000553\n",
      "Validation loss decreased (0.088185 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0731180\n",
      "\tspeed: 0.0537s/iter; left time: 1065.7722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704911\n",
      "\tspeed: 0.0268s/iter; left time: 529.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0739811 Vali Loss: 0.0880940 Test Loss: 0.1000203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0734993\n",
      "\tspeed: 0.0533s/iter; left time: 1046.3170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0771078\n",
      "\tspeed: 0.0268s/iter; left time: 522.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0738054 Vali Loss: 0.0879598 Test Loss: 0.1001505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748501\n",
      "\tspeed: 0.0532s/iter; left time: 1031.9631s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740310\n",
      "\tspeed: 0.0269s/iter; left time: 518.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0736476 Vali Loss: 0.0878529 Test Loss: 0.1002746\n",
      "Validation loss decreased (0.087905 --> 0.087853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738298\n",
      "\tspeed: 0.0543s/iter; left time: 1041.4646s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762812\n",
      "\tspeed: 0.0269s/iter; left time: 513.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0735278 Vali Loss: 0.0878173 Test Loss: 0.1001467\n",
      "Validation loss decreased (0.087853 --> 0.087817).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707365\n",
      "\tspeed: 0.0534s/iter; left time: 1010.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745331\n",
      "\tspeed: 0.0269s/iter; left time: 505.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0732803 Vali Loss: 0.0877546 Test Loss: 0.0999003\n",
      "Validation loss decreased (0.087817 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0703407\n",
      "\tspeed: 0.0537s/iter; left time: 1005.2025s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806976\n",
      "\tspeed: 0.0270s/iter; left time: 501.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0732293 Vali Loss: 0.0877284 Test Loss: 0.1001207\n",
      "Validation loss decreased (0.087755 --> 0.087728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721018\n",
      "\tspeed: 0.0533s/iter; left time: 985.6505s\n",
      "\titers: 200, epoch: 18 | loss: 0.0723104\n",
      "\tspeed: 0.0268s/iter; left time: 493.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0730768 Vali Loss: 0.0877988 Test Loss: 0.0999179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0745736\n",
      "\tspeed: 0.0523s/iter; left time: 954.9691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709844\n",
      "\tspeed: 0.0268s/iter; left time: 486.2546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0729765 Vali Loss: 0.0877342 Test Loss: 0.0999373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700831\n",
      "\tspeed: 0.0528s/iter; left time: 951.9676s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720744\n",
      "\tspeed: 0.0268s/iter; left time: 480.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728975 Vali Loss: 0.0876718 Test Loss: 0.0999224\n",
      "Validation loss decreased (0.087728 --> 0.087672).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748239\n",
      "\tspeed: 0.0530s/iter; left time: 943.8389s\n",
      "\titers: 200, epoch: 21 | loss: 0.0763428\n",
      "\tspeed: 0.0268s/iter; left time: 474.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728158 Vali Loss: 0.0874219 Test Loss: 0.0997877\n",
      "Validation loss decreased (0.087672 --> 0.087422).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0726125\n",
      "\tspeed: 0.0535s/iter; left time: 941.3583s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784063\n",
      "\tspeed: 0.0267s/iter; left time: 467.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0727590 Vali Loss: 0.0874105 Test Loss: 0.0995382\n",
      "Validation loss decreased (0.087422 --> 0.087410).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0671866\n",
      "\tspeed: 0.0535s/iter; left time: 929.4445s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725489\n",
      "\tspeed: 0.0268s/iter; left time: 462.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0726649 Vali Loss: 0.0874186 Test Loss: 0.0996998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0776832\n",
      "\tspeed: 0.0533s/iter; left time: 913.3976s\n",
      "\titers: 200, epoch: 24 | loss: 0.0751887\n",
      "\tspeed: 0.0268s/iter; left time: 456.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0726117 Vali Loss: 0.0874993 Test Loss: 0.0999176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748994\n",
      "\tspeed: 0.0529s/iter; left time: 894.5695s\n",
      "\titers: 200, epoch: 25 | loss: 0.0756038\n",
      "\tspeed: 0.0265s/iter; left time: 446.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0725972 Vali Loss: 0.0874437 Test Loss: 0.0998308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704204\n",
      "\tspeed: 0.0528s/iter; left time: 881.4889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690703\n",
      "\tspeed: 0.0265s/iter; left time: 439.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0725073 Vali Loss: 0.0873915 Test Loss: 0.0997966\n",
      "Validation loss decreased (0.087410 --> 0.087391).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722938\n",
      "\tspeed: 0.0550s/iter; left time: 906.8522s\n",
      "\titers: 200, epoch: 27 | loss: 0.0707320\n",
      "\tspeed: 0.0269s/iter; left time: 440.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0724955 Vali Loss: 0.0874042 Test Loss: 0.0997572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708005\n",
      "\tspeed: 0.0524s/iter; left time: 852.1813s\n",
      "\titers: 200, epoch: 28 | loss: 0.0706717\n",
      "\tspeed: 0.0265s/iter; left time: 427.8731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0725039 Vali Loss: 0.0873560 Test Loss: 0.0996761\n",
      "Validation loss decreased (0.087391 --> 0.087356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742883\n",
      "\tspeed: 0.0536s/iter; left time: 859.0053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742773\n",
      "\tspeed: 0.0269s/iter; left time: 427.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724317 Vali Loss: 0.0874750 Test Loss: 0.0997233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733841\n",
      "\tspeed: 0.0534s/iter; left time: 844.4930s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713019\n",
      "\tspeed: 0.0268s/iter; left time: 421.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724177 Vali Loss: 0.0873239 Test Loss: 0.0995659\n",
      "Validation loss decreased (0.087356 --> 0.087324).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0728526\n",
      "\tspeed: 0.0535s/iter; left time: 834.2808s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712871\n",
      "\tspeed: 0.0268s/iter; left time: 414.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0723862 Vali Loss: 0.0873993 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745156\n",
      "\tspeed: 0.0529s/iter; left time: 811.9430s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705794\n",
      "\tspeed: 0.0267s/iter; left time: 407.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0723662 Vali Loss: 0.0874361 Test Loss: 0.0997775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0698627\n",
      "\tspeed: 0.0531s/iter; left time: 804.2879s\n",
      "\titers: 200, epoch: 33 | loss: 0.0744560\n",
      "\tspeed: 0.0267s/iter; left time: 401.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723162 Vali Loss: 0.0872565 Test Loss: 0.0996848\n",
      "Validation loss decreased (0.087324 --> 0.087256).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720458\n",
      "\tspeed: 0.0529s/iter; left time: 789.0979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0796783\n",
      "\tspeed: 0.0267s/iter; left time: 395.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722920 Vali Loss: 0.0873715 Test Loss: 0.0996110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0731819\n",
      "\tspeed: 0.0527s/iter; left time: 773.4842s\n",
      "\titers: 200, epoch: 35 | loss: 0.0786404\n",
      "\tspeed: 0.0267s/iter; left time: 389.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723127 Vali Loss: 0.0874032 Test Loss: 0.0996725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0717856\n",
      "\tspeed: 0.0527s/iter; left time: 761.5788s\n",
      "\titers: 200, epoch: 36 | loss: 0.0735888\n",
      "\tspeed: 0.0267s/iter; left time: 383.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723288 Vali Loss: 0.0872270 Test Loss: 0.0996796\n",
      "Validation loss decreased (0.087256 --> 0.087227).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752889\n",
      "\tspeed: 0.0529s/iter; left time: 753.7263s\n",
      "\titers: 200, epoch: 37 | loss: 0.0713401\n",
      "\tspeed: 0.0268s/iter; left time: 378.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723031 Vali Loss: 0.0874127 Test Loss: 0.0996993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0730377\n",
      "\tspeed: 0.0528s/iter; left time: 740.2937s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670286\n",
      "\tspeed: 0.0266s/iter; left time: 369.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0722490 Vali Loss: 0.0873063 Test Loss: 0.0996096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0739416\n",
      "\tspeed: 0.0528s/iter; left time: 727.5970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706054\n",
      "\tspeed: 0.0266s/iter; left time: 364.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0722615 Vali Loss: 0.0873521 Test Loss: 0.0996684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0689131\n",
      "\tspeed: 0.0538s/iter; left time: 729.3039s\n",
      "\titers: 200, epoch: 40 | loss: 0.0731106\n",
      "\tspeed: 0.0269s/iter; left time: 362.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722557 Vali Loss: 0.0874369 Test Loss: 0.0997051\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0715132\n",
      "\tspeed: 0.0532s/iter; left time: 710.0583s\n",
      "\titers: 200, epoch: 41 | loss: 0.0690387\n",
      "\tspeed: 0.0267s/iter; left time: 353.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722332 Vali Loss: 0.0872902 Test Loss: 0.0996747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0766864\n",
      "\tspeed: 0.0525s/iter; left time: 688.9114s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704855\n",
      "\tspeed: 0.0265s/iter; left time: 345.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0722141 Vali Loss: 0.0873723 Test Loss: 0.0996596\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0717274\n",
      "\tspeed: 0.0530s/iter; left time: 683.2456s\n",
      "\titers: 200, epoch: 43 | loss: 0.0687616\n",
      "\tspeed: 0.0274s/iter; left time: 350.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0721847 Vali Loss: 0.0872899 Test Loss: 0.0996401\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682925\n",
      "\tspeed: 0.0532s/iter; left time: 673.6730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0717148\n",
      "\tspeed: 0.0267s/iter; left time: 336.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722191 Vali Loss: 0.0873592 Test Loss: 0.0996715\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0739661\n",
      "\tspeed: 0.0526s/iter; left time: 654.3423s\n",
      "\titers: 200, epoch: 45 | loss: 0.0704421\n",
      "\tspeed: 0.0268s/iter; left time: 330.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721614 Vali Loss: 0.0873060 Test Loss: 0.0996651\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0744253\n",
      "\tspeed: 0.0525s/iter; left time: 642.1980s\n",
      "\titers: 200, epoch: 46 | loss: 0.0733730\n",
      "\tspeed: 0.0268s/iter; left time: 324.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0721902 Vali Loss: 0.0871615 Test Loss: 0.0996455\n",
      "Validation loss decreased (0.087227 --> 0.087162).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738844\n",
      "\tspeed: 0.0523s/iter; left time: 627.0182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0732504\n",
      "\tspeed: 0.0265s/iter; left time: 315.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0721966 Vali Loss: 0.0873352 Test Loss: 0.0996582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0738569\n",
      "\tspeed: 0.0522s/iter; left time: 615.0724s\n",
      "\titers: 200, epoch: 48 | loss: 0.0660235\n",
      "\tspeed: 0.0265s/iter; left time: 309.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721567 Vali Loss: 0.0874393 Test Loss: 0.0996577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700567\n",
      "\tspeed: 0.0530s/iter; left time: 611.5923s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708773\n",
      "\tspeed: 0.0268s/iter; left time: 306.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0721437 Vali Loss: 0.0873161 Test Loss: 0.0996556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0701776\n",
      "\tspeed: 0.0522s/iter; left time: 590.7105s\n",
      "\titers: 200, epoch: 50 | loss: 0.0751142\n",
      "\tspeed: 0.0267s/iter; left time: 299.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0721538 Vali Loss: 0.0873739 Test Loss: 0.0996439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0683126\n",
      "\tspeed: 0.0519s/iter; left time: 576.3710s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737489\n",
      "\tspeed: 0.0270s/iter; left time: 297.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721442 Vali Loss: 0.0874031 Test Loss: 0.0996389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0686506\n",
      "\tspeed: 0.0521s/iter; left time: 566.9737s\n",
      "\titers: 200, epoch: 52 | loss: 0.0714018\n",
      "\tspeed: 0.0266s/iter; left time: 286.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0872806 Test Loss: 0.0996446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0680443\n",
      "\tspeed: 0.0520s/iter; left time: 553.8117s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746092\n",
      "\tspeed: 0.0268s/iter; left time: 282.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0721653 Vali Loss: 0.0872594 Test Loss: 0.0996658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0697796\n",
      "\tspeed: 0.0522s/iter; left time: 544.4062s\n",
      "\titers: 200, epoch: 54 | loss: 0.0704911\n",
      "\tspeed: 0.0264s/iter; left time: 273.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721745 Vali Loss: 0.0874115 Test Loss: 0.0996338\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0660143\n",
      "\tspeed: 0.0517s/iter; left time: 527.2257s\n",
      "\titers: 200, epoch: 55 | loss: 0.0712318\n",
      "\tspeed: 0.0265s/iter; left time: 268.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721330 Vali Loss: 0.0873371 Test Loss: 0.0996511\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0705199\n",
      "\tspeed: 0.0519s/iter; left time: 518.3399s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784174\n",
      "\tspeed: 0.0265s/iter; left time: 262.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0721358 Vali Loss: 0.0872928 Test Loss: 0.0996450\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025020133703947067, rmse:0.15817753970623016, mae:0.09964548796415329, rse:0.5456676483154297\n",
      "Intermediate time for GB and pred_len 24: 00h:15m:37.54s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1362466\n",
      "\tspeed: 0.0553s/iter; left time: 1234.0899s\n",
      "\titers: 200, epoch: 1 | loss: 0.1315828\n",
      "\tspeed: 0.0268s/iter; left time: 594.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.1354785 Vali Loss: 0.1317148 Test Loss: 0.1549259\n",
      "Validation loss decreased (inf --> 0.131715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100148\n",
      "\tspeed: 0.0537s/iter; left time: 1185.5225s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011972\n",
      "\tspeed: 0.0269s/iter; left time: 590.6520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1090403 Vali Loss: 0.1182589 Test Loss: 0.1401924\n",
      "Validation loss decreased (0.131715 --> 0.118259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020023\n",
      "\tspeed: 0.0538s/iter; left time: 1174.9266s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028889\n",
      "\tspeed: 0.0270s/iter; left time: 586.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1039733 Vali Loss: 0.1175403 Test Loss: 0.1411576\n",
      "Validation loss decreased (0.118259 --> 0.117540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018276\n",
      "\tspeed: 0.0529s/iter; left time: 1143.3982s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026525\n",
      "\tspeed: 0.0270s/iter; left time: 581.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1026064 Vali Loss: 0.1166299 Test Loss: 0.1399759\n",
      "Validation loss decreased (0.117540 --> 0.116630).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026763\n",
      "\tspeed: 0.0534s/iter; left time: 1144.0695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0943075\n",
      "\tspeed: 0.0268s/iter; left time: 570.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1015074 Vali Loss: 0.1164241 Test Loss: 0.1412032\n",
      "Validation loss decreased (0.116630 --> 0.116424).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1025002\n",
      "\tspeed: 0.0531s/iter; left time: 1123.7738s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032541\n",
      "\tspeed: 0.0271s/iter; left time: 571.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1006094 Vali Loss: 0.1160348 Test Loss: 0.1397788\n",
      "Validation loss decreased (0.116424 --> 0.116035).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038390\n",
      "\tspeed: 0.0535s/iter; left time: 1121.2498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0969341\n",
      "\tspeed: 0.0268s/iter; left time: 559.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0997999 Vali Loss: 0.1159833 Test Loss: 0.1389591\n",
      "Validation loss decreased (0.116035 --> 0.115983).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006562\n",
      "\tspeed: 0.0540s/iter; left time: 1120.2872s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981172\n",
      "\tspeed: 0.0270s/iter; left time: 557.5209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0990484 Vali Loss: 0.1169135 Test Loss: 0.1407297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0989951\n",
      "\tspeed: 0.0535s/iter; left time: 1097.1081s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990440\n",
      "\tspeed: 0.0271s/iter; left time: 553.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0983205 Vali Loss: 0.1171196 Test Loss: 0.1430553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1003540\n",
      "\tspeed: 0.0529s/iter; left time: 1073.5132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0943393\n",
      "\tspeed: 0.0269s/iter; left time: 543.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0977161 Vali Loss: 0.1167704 Test Loss: 0.1415311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969625\n",
      "\tspeed: 0.0539s/iter; left time: 1081.2312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986367\n",
      "\tspeed: 0.0268s/iter; left time: 534.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0971241 Vali Loss: 0.1168764 Test Loss: 0.1429615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012906\n",
      "\tspeed: 0.0530s/iter; left time: 1051.5503s\n",
      "\titers: 200, epoch: 12 | loss: 0.0969430\n",
      "\tspeed: 0.0268s/iter; left time: 529.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0966664 Vali Loss: 0.1162381 Test Loss: 0.1405379\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961613\n",
      "\tspeed: 0.0536s/iter; left time: 1050.6042s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981514\n",
      "\tspeed: 0.0270s/iter; left time: 525.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0962394 Vali Loss: 0.1173263 Test Loss: 0.1436641\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0961513\n",
      "\tspeed: 0.0532s/iter; left time: 1031.3833s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940166\n",
      "\tspeed: 0.0269s/iter; left time: 518.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0958293 Vali Loss: 0.1172846 Test Loss: 0.1412998\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0907448\n",
      "\tspeed: 0.0530s/iter; left time: 1015.5836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0936777\n",
      "\tspeed: 0.0269s/iter; left time: 513.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0954853 Vali Loss: 0.1174681 Test Loss: 0.1431191\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0971071\n",
      "\tspeed: 0.0530s/iter; left time: 1004.5613s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991246\n",
      "\tspeed: 0.0270s/iter; left time: 508.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0951561 Vali Loss: 0.1177430 Test Loss: 0.1433660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0933138\n",
      "\tspeed: 0.0532s/iter; left time: 996.3669s\n",
      "\titers: 200, epoch: 17 | loss: 0.0953560\n",
      "\tspeed: 0.0270s/iter; left time: 502.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0948642 Vali Loss: 0.1173937 Test Loss: 0.1422419\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04156280308961868, rmse:0.20386956632137299, mae:0.138959139585495, rse:0.705009400844574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1342963\n",
      "\tspeed: 0.0294s/iter; left time: 655.5017s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212572\n",
      "\tspeed: 0.0270s/iter; left time: 598.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1354378 Vali Loss: 0.1306439 Test Loss: 0.1532763\n",
      "Validation loss decreased (inf --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1063669\n",
      "\tspeed: 0.0539s/iter; left time: 1190.0957s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015290\n",
      "\tspeed: 0.0268s/iter; left time: 588.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1090908 Vali Loss: 0.1179647 Test Loss: 0.1400083\n",
      "Validation loss decreased (0.130644 --> 0.117965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034727\n",
      "\tspeed: 0.0543s/iter; left time: 1186.3327s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050127\n",
      "\tspeed: 0.0268s/iter; left time: 582.9759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1041194 Vali Loss: 0.1176144 Test Loss: 0.1397710\n",
      "Validation loss decreased (0.117965 --> 0.117614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971245\n",
      "\tspeed: 0.0556s/iter; left time: 1202.5577s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046980\n",
      "\tspeed: 0.0271s/iter; left time: 583.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1028142 Vali Loss: 0.1171384 Test Loss: 0.1404998\n",
      "Validation loss decreased (0.117614 --> 0.117138).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977949\n",
      "\tspeed: 0.0553s/iter; left time: 1182.8713s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043665\n",
      "\tspeed: 0.0268s/iter; left time: 571.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1018217 Vali Loss: 0.1171914 Test Loss: 0.1403327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947371\n",
      "\tspeed: 0.0534s/iter; left time: 1131.0207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1068232\n",
      "\tspeed: 0.0268s/iter; left time: 564.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1010497 Vali Loss: 0.1167937 Test Loss: 0.1400926\n",
      "Validation loss decreased (0.117138 --> 0.116794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955816\n",
      "\tspeed: 0.0545s/iter; left time: 1143.1946s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973860\n",
      "\tspeed: 0.0267s/iter; left time: 557.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1002006 Vali Loss: 0.1169059 Test Loss: 0.1398973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982215\n",
      "\tspeed: 0.0550s/iter; left time: 1140.3708s\n",
      "\titers: 200, epoch: 8 | loss: 0.0986912\n",
      "\tspeed: 0.0269s/iter; left time: 555.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0995622 Vali Loss: 0.1171644 Test Loss: 0.1394792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0983291\n",
      "\tspeed: 0.0544s/iter; left time: 1115.5611s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015055\n",
      "\tspeed: 0.0267s/iter; left time: 544.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0990405 Vali Loss: 0.1170354 Test Loss: 0.1404738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0966749\n",
      "\tspeed: 0.0548s/iter; left time: 1111.2377s\n",
      "\titers: 200, epoch: 10 | loss: 0.0984571\n",
      "\tspeed: 0.0271s/iter; left time: 547.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0984118 Vali Loss: 0.1174196 Test Loss: 0.1405433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945642\n",
      "\tspeed: 0.0554s/iter; left time: 1111.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0937180\n",
      "\tspeed: 0.0268s/iter; left time: 534.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0979818 Vali Loss: 0.1171703 Test Loss: 0.1407737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0964229\n",
      "\tspeed: 0.0543s/iter; left time: 1077.2916s\n",
      "\titers: 200, epoch: 12 | loss: 0.1007808\n",
      "\tspeed: 0.0270s/iter; left time: 533.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0975590 Vali Loss: 0.1174397 Test Loss: 0.1414426\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0947333\n",
      "\tspeed: 0.0534s/iter; left time: 1048.2167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915383\n",
      "\tspeed: 0.0268s/iter; left time: 523.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0971209 Vali Loss: 0.1181216 Test Loss: 0.1418197\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0964207\n",
      "\tspeed: 0.0543s/iter; left time: 1053.2275s\n",
      "\titers: 200, epoch: 14 | loss: 0.0957182\n",
      "\tspeed: 0.0268s/iter; left time: 516.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0966924 Vali Loss: 0.1173833 Test Loss: 0.1408844\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0976923\n",
      "\tspeed: 0.0538s/iter; left time: 1031.1701s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943371\n",
      "\tspeed: 0.0268s/iter; left time: 511.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0964538 Vali Loss: 0.1180992 Test Loss: 0.1427835\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0937670\n",
      "\tspeed: 0.0538s/iter; left time: 1018.7485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0968458\n",
      "\tspeed: 0.0268s/iter; left time: 505.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961151 Vali Loss: 0.1176016 Test Loss: 0.1419638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04211575910449028, rmse:0.2052212506532669, mae:0.1400926262140274, rse:0.7096836566925049\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:39.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354124\n",
      "\tspeed: 0.0554s/iter; left time: 1229.6732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1269919\n",
      "\tspeed: 0.0271s/iter; left time: 599.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.1370751 Vali Loss: 0.1339571 Test Loss: 0.1580050\n",
      "Validation loss decreased (inf --> 0.133957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1144067\n",
      "\tspeed: 0.0538s/iter; left time: 1181.8960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070809\n",
      "\tspeed: 0.0271s/iter; left time: 593.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1134790 Vali Loss: 0.1227112 Test Loss: 0.1471968\n",
      "Validation loss decreased (0.133957 --> 0.122711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099978\n",
      "\tspeed: 0.0546s/iter; left time: 1186.9160s\n",
      "\titers: 200, epoch: 3 | loss: 0.1067006\n",
      "\tspeed: 0.0272s/iter; left time: 588.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1086630 Vali Loss: 0.1216847 Test Loss: 0.1465340\n",
      "Validation loss decreased (0.122711 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087929\n",
      "\tspeed: 0.0553s/iter; left time: 1189.7324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128875\n",
      "\tspeed: 0.0271s/iter; left time: 580.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1071564 Vali Loss: 0.1216329 Test Loss: 0.1464036\n",
      "Validation loss decreased (0.121685 --> 0.121633).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036660\n",
      "\tspeed: 0.0565s/iter; left time: 1204.0028s\n",
      "\titers: 200, epoch: 5 | loss: 0.1098936\n",
      "\tspeed: 0.0271s/iter; left time: 575.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1058232 Vali Loss: 0.1211363 Test Loss: 0.1468929\n",
      "Validation loss decreased (0.121633 --> 0.121136).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023184\n",
      "\tspeed: 0.0551s/iter; left time: 1162.4825s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047149\n",
      "\tspeed: 0.0272s/iter; left time: 570.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1045786 Vali Loss: 0.1214660 Test Loss: 0.1477442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1030283\n",
      "\tspeed: 0.0551s/iter; left time: 1148.7618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983301\n",
      "\tspeed: 0.0274s/iter; left time: 568.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035771 Vali Loss: 0.1215716 Test Loss: 0.1494350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1021642\n",
      "\tspeed: 0.0551s/iter; left time: 1137.1951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1072234\n",
      "\tspeed: 0.0274s/iter; left time: 562.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026726 Vali Loss: 0.1215428 Test Loss: 0.1478654\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027741\n",
      "\tspeed: 0.0555s/iter; left time: 1132.5589s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979295\n",
      "\tspeed: 0.0273s/iter; left time: 554.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1020552 Vali Loss: 0.1213815 Test Loss: 0.1498316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996236\n",
      "\tspeed: 0.0543s/iter; left time: 1096.0517s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013777\n",
      "\tspeed: 0.0273s/iter; left time: 548.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1013867 Vali Loss: 0.1220490 Test Loss: 0.1514326\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994694\n",
      "\tspeed: 0.0553s/iter; left time: 1104.2498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0999421\n",
      "\tspeed: 0.0274s/iter; left time: 543.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1007758 Vali Loss: 0.1213371 Test Loss: 0.1484833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966362\n",
      "\tspeed: 0.0549s/iter; left time: 1083.1968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990719\n",
      "\tspeed: 0.0273s/iter; left time: 535.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1002209 Vali Loss: 0.1218838 Test Loss: 0.1496712\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996767\n",
      "\tspeed: 0.0548s/iter; left time: 1070.0136s\n",
      "\titers: 200, epoch: 13 | loss: 0.1026959\n",
      "\tspeed: 0.0272s/iter; left time: 528.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0997564 Vali Loss: 0.1217964 Test Loss: 0.1501298\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0985504\n",
      "\tspeed: 0.0554s/iter; left time: 1068.8520s\n",
      "\titers: 200, epoch: 14 | loss: 0.0999128\n",
      "\tspeed: 0.0272s/iter; left time: 523.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0993586 Vali Loss: 0.1223004 Test Loss: 0.1509998\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021761\n",
      "\tspeed: 0.0548s/iter; left time: 1045.3280s\n",
      "\titers: 200, epoch: 15 | loss: 0.1022515\n",
      "\tspeed: 0.0273s/iter; left time: 517.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0989366 Vali Loss: 0.1226592 Test Loss: 0.1515421\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459306597709656, rmse:0.21117070317268372, mae:0.14689284563064575, rse:0.7321591973304749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343334\n",
      "\tspeed: 0.0304s/iter; left time: 675.5745s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274043\n",
      "\tspeed: 0.0273s/iter; left time: 604.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1373720 Vali Loss: 0.1342096 Test Loss: 0.1581728\n",
      "Validation loss decreased (inf --> 0.134210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1134263\n",
      "\tspeed: 0.0564s/iter; left time: 1240.0853s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105637\n",
      "\tspeed: 0.0276s/iter; left time: 603.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1132997 Vali Loss: 0.1233650 Test Loss: 0.1481477\n",
      "Validation loss decreased (0.134210 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1110428\n",
      "\tspeed: 0.0561s/iter; left time: 1219.9967s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082572\n",
      "\tspeed: 0.0271s/iter; left time: 587.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1087510 Vali Loss: 0.1223908 Test Loss: 0.1466880\n",
      "Validation loss decreased (0.123365 --> 0.122391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1091575\n",
      "\tspeed: 0.0577s/iter; left time: 1241.7612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072541\n",
      "\tspeed: 0.0274s/iter; left time: 587.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1072281 Vali Loss: 0.1221424 Test Loss: 0.1471605\n",
      "Validation loss decreased (0.122391 --> 0.122142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074684\n",
      "\tspeed: 0.0569s/iter; left time: 1212.2677s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056222\n",
      "\tspeed: 0.0274s/iter; left time: 581.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1056581 Vali Loss: 0.1219717 Test Loss: 0.1469719\n",
      "Validation loss decreased (0.122142 --> 0.121972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063322\n",
      "\tspeed: 0.0565s/iter; left time: 1192.2183s\n",
      "\titers: 200, epoch: 6 | loss: 0.1021206\n",
      "\tspeed: 0.0273s/iter; left time: 572.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1043592 Vali Loss: 0.1220159 Test Loss: 0.1479042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1007787\n",
      "\tspeed: 0.0559s/iter; left time: 1165.4247s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071176\n",
      "\tspeed: 0.0273s/iter; left time: 565.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1034426 Vali Loss: 0.1219470 Test Loss: 0.1468008\n",
      "Validation loss decreased (0.121972 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024007\n",
      "\tspeed: 0.0562s/iter; left time: 1159.3587s\n",
      "\titers: 200, epoch: 8 | loss: 0.1011106\n",
      "\tspeed: 0.0273s/iter; left time: 560.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026371 Vali Loss: 0.1226881 Test Loss: 0.1485755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010926\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1769s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037420\n",
      "\tspeed: 0.0273s/iter; left time: 555.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1018770 Vali Loss: 0.1230170 Test Loss: 0.1505015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995526\n",
      "\tspeed: 0.0558s/iter; left time: 1126.7199s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030146\n",
      "\tspeed: 0.0273s/iter; left time: 549.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1011918 Vali Loss: 0.1236346 Test Loss: 0.1512475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1019870\n",
      "\tspeed: 0.0558s/iter; left time: 1114.2898s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035597\n",
      "\tspeed: 0.0274s/iter; left time: 543.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1005595 Vali Loss: 0.1228452 Test Loss: 0.1502132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1003256\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7425s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002665\n",
      "\tspeed: 0.0273s/iter; left time: 537.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1000163 Vali Loss: 0.1234094 Test Loss: 0.1494783\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1022886\n",
      "\tspeed: 0.0564s/iter; left time: 1101.7633s\n",
      "\titers: 200, epoch: 13 | loss: 0.1002941\n",
      "\tspeed: 0.0274s/iter; left time: 531.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0994505 Vali Loss: 0.1235107 Test Loss: 0.1497943\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975255\n",
      "\tspeed: 0.0559s/iter; left time: 1078.1402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0986446\n",
      "\tspeed: 0.0274s/iter; left time: 526.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0990837 Vali Loss: 0.1231035 Test Loss: 0.1512404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982782\n",
      "\tspeed: 0.0557s/iter; left time: 1061.8515s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003537\n",
      "\tspeed: 0.0273s/iter; left time: 518.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0986666 Vali Loss: 0.1234591 Test Loss: 0.1508010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1010868\n",
      "\tspeed: 0.0562s/iter; left time: 1058.7894s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004014\n",
      "\tspeed: 0.0274s/iter; left time: 513.3969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0983119 Vali Loss: 0.1234264 Test Loss: 0.1515623\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973225\n",
      "\tspeed: 0.0560s/iter; left time: 1042.6396s\n",
      "\titers: 200, epoch: 17 | loss: 0.0972442\n",
      "\tspeed: 0.0271s/iter; left time: 502.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0979932 Vali Loss: 0.1239732 Test Loss: 0.1527091\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486566409468651, rmse:0.21181516349315643, mae:0.14680077135562897, rse:0.7343935966491699\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:39.74s\n",
      "Intermediate time for GB: 00h:24m:56.87s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1297289\n",
      "\tspeed: 0.0455s/iter; left time: 1015.3594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1126045\n",
      "\tspeed: 0.0178s/iter; left time: 395.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1356361 Vali Loss: 0.0979728 Test Loss: 0.1105253\n",
      "Validation loss decreased (inf --> 0.097973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740920\n",
      "\tspeed: 0.0365s/iter; left time: 805.5324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695283\n",
      "\tspeed: 0.0174s/iter; left time: 382.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0769994 Vali Loss: 0.0646745 Test Loss: 0.0711548\n",
      "Validation loss decreased (0.097973 --> 0.064675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641058\n",
      "\tspeed: 0.0361s/iter; left time: 789.8069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0647144\n",
      "\tspeed: 0.0174s/iter; left time: 378.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0655269 Vali Loss: 0.0602642 Test Loss: 0.0665508\n",
      "Validation loss decreased (0.064675 --> 0.060264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620353\n",
      "\tspeed: 0.0359s/iter; left time: 777.5343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641675\n",
      "\tspeed: 0.0180s/iter; left time: 386.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0622778 Vali Loss: 0.0589169 Test Loss: 0.0652260\n",
      "Validation loss decreased (0.060264 --> 0.058917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600411\n",
      "\tspeed: 0.0386s/iter; left time: 827.2866s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605951\n",
      "\tspeed: 0.0208s/iter; left time: 443.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0604136 Vali Loss: 0.0574598 Test Loss: 0.0637832\n",
      "Validation loss decreased (0.058917 --> 0.057460).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0576362\n",
      "\tspeed: 0.0362s/iter; left time: 767.1964s\n",
      "\titers: 200, epoch: 6 | loss: 0.0572372\n",
      "\tspeed: 0.0185s/iter; left time: 389.9134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0592250 Vali Loss: 0.0569232 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.057460 --> 0.056923).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0641758\n",
      "\tspeed: 0.0404s/iter; left time: 847.3156s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604304\n",
      "\tspeed: 0.0228s/iter; left time: 474.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0582727 Vali Loss: 0.0563158 Test Loss: 0.0624014\n",
      "Validation loss decreased (0.056923 --> 0.056316).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597004\n",
      "\tspeed: 0.0397s/iter; left time: 823.0412s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545038\n",
      "\tspeed: 0.0217s/iter; left time: 448.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0575341 Vali Loss: 0.0555614 Test Loss: 0.0619747\n",
      "Validation loss decreased (0.056316 --> 0.055561).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581241\n",
      "\tspeed: 0.0373s/iter; left time: 764.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0560733\n",
      "\tspeed: 0.0177s/iter; left time: 361.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0569077 Vali Loss: 0.0551520 Test Loss: 0.0613294\n",
      "Validation loss decreased (0.055561 --> 0.055152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600654\n",
      "\tspeed: 0.0369s/iter; left time: 748.1508s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543051\n",
      "\tspeed: 0.0173s/iter; left time: 349.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0564565 Vali Loss: 0.0552002 Test Loss: 0.0615373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0573782\n",
      "\tspeed: 0.0354s/iter; left time: 710.7419s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561891\n",
      "\tspeed: 0.0173s/iter; left time: 346.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0560166 Vali Loss: 0.0547021 Test Loss: 0.0608617\n",
      "Validation loss decreased (0.055152 --> 0.054702).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549166\n",
      "\tspeed: 0.0368s/iter; left time: 730.5754s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550303\n",
      "\tspeed: 0.0175s/iter; left time: 345.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0556077 Vali Loss: 0.0544642 Test Loss: 0.0607819\n",
      "Validation loss decreased (0.054702 --> 0.054464).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530001\n",
      "\tspeed: 0.0374s/iter; left time: 734.4276s\n",
      "\titers: 200, epoch: 13 | loss: 0.0505261\n",
      "\tspeed: 0.0172s/iter; left time: 336.1488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0553481 Vali Loss: 0.0544108 Test Loss: 0.0603867\n",
      "Validation loss decreased (0.054464 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576824\n",
      "\tspeed: 0.0382s/iter; left time: 741.3690s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537340\n",
      "\tspeed: 0.0180s/iter; left time: 347.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0550210 Vali Loss: 0.0542770 Test Loss: 0.0605504\n",
      "Validation loss decreased (0.054411 --> 0.054277).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0541440\n",
      "\tspeed: 0.0374s/iter; left time: 716.8168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551845\n",
      "\tspeed: 0.0176s/iter; left time: 336.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0547780 Vali Loss: 0.0540772 Test Loss: 0.0603587\n",
      "Validation loss decreased (0.054277 --> 0.054077).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509629\n",
      "\tspeed: 0.0377s/iter; left time: 714.1568s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555559\n",
      "\tspeed: 0.0201s/iter; left time: 379.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0545937 Vali Loss: 0.0540071 Test Loss: 0.0602936\n",
      "Validation loss decreased (0.054077 --> 0.054007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533449\n",
      "\tspeed: 0.0376s/iter; left time: 702.8441s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549480\n",
      "\tspeed: 0.0232s/iter; left time: 431.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543840 Vali Loss: 0.0535351 Test Loss: 0.0598909\n",
      "Validation loss decreased (0.054007 --> 0.053535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534377\n",
      "\tspeed: 0.0413s/iter; left time: 763.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519669\n",
      "\tspeed: 0.0180s/iter; left time: 330.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0541835 Vali Loss: 0.0535182 Test Loss: 0.0599301\n",
      "Validation loss decreased (0.053535 --> 0.053518).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546421\n",
      "\tspeed: 0.0365s/iter; left time: 666.7154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532574\n",
      "\tspeed: 0.0173s/iter; left time: 315.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0541097 Vali Loss: 0.0536294 Test Loss: 0.0598268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540954\n",
      "\tspeed: 0.0388s/iter; left time: 699.9337s\n",
      "\titers: 200, epoch: 20 | loss: 0.0566773\n",
      "\tspeed: 0.0218s/iter; left time: 391.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0538978 Vali Loss: 0.0535801 Test Loss: 0.0599190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0543947\n",
      "\tspeed: 0.0428s/iter; left time: 762.3693s\n",
      "\titers: 200, epoch: 21 | loss: 0.0548367\n",
      "\tspeed: 0.0209s/iter; left time: 369.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0537692 Vali Loss: 0.0534152 Test Loss: 0.0598009\n",
      "Validation loss decreased (0.053518 --> 0.053415).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549492\n",
      "\tspeed: 0.0444s/iter; left time: 780.6195s\n",
      "\titers: 200, epoch: 22 | loss: 0.0514017\n",
      "\tspeed: 0.0198s/iter; left time: 346.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0537207 Vali Loss: 0.0533374 Test Loss: 0.0596908\n",
      "Validation loss decreased (0.053415 --> 0.053337).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0534591\n",
      "\tspeed: 0.0393s/iter; left time: 682.3595s\n",
      "\titers: 200, epoch: 23 | loss: 0.0526582\n",
      "\tspeed: 0.0216s/iter; left time: 372.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0536544 Vali Loss: 0.0533163 Test Loss: 0.0596185\n",
      "Validation loss decreased (0.053337 --> 0.053316).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0538955\n",
      "\tspeed: 0.0382s/iter; left time: 655.3983s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538660\n",
      "\tspeed: 0.0208s/iter; left time: 354.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0535522 Vali Loss: 0.0532527 Test Loss: 0.0594967\n",
      "Validation loss decreased (0.053316 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573650\n",
      "\tspeed: 0.0380s/iter; left time: 643.7574s\n",
      "\titers: 200, epoch: 25 | loss: 0.0528080\n",
      "\tspeed: 0.0178s/iter; left time: 300.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0534546 Vali Loss: 0.0532459 Test Loss: 0.0595710\n",
      "Validation loss decreased (0.053253 --> 0.053246).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537234\n",
      "\tspeed: 0.0401s/iter; left time: 669.8796s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546586\n",
      "\tspeed: 0.0176s/iter; left time: 292.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0533645 Vali Loss: 0.0533376 Test Loss: 0.0595235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516834\n",
      "\tspeed: 0.0371s/iter; left time: 610.6094s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571585\n",
      "\tspeed: 0.0177s/iter; left time: 289.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0532839 Vali Loss: 0.0533172 Test Loss: 0.0594809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0494189\n",
      "\tspeed: 0.0375s/iter; left time: 610.2077s\n",
      "\titers: 200, epoch: 28 | loss: 0.0522387\n",
      "\tspeed: 0.0174s/iter; left time: 281.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0533023 Vali Loss: 0.0531314 Test Loss: 0.0593853\n",
      "Validation loss decreased (0.053246 --> 0.053131).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0519411\n",
      "\tspeed: 0.0371s/iter; left time: 594.9347s\n",
      "\titers: 200, epoch: 29 | loss: 0.0522147\n",
      "\tspeed: 0.0180s/iter; left time: 286.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0532008 Vali Loss: 0.0530601 Test Loss: 0.0593986\n",
      "Validation loss decreased (0.053131 --> 0.053060).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523858\n",
      "\tspeed: 0.0420s/iter; left time: 664.5347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0539169\n",
      "\tspeed: 0.0184s/iter; left time: 288.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0532031 Vali Loss: 0.0530461 Test Loss: 0.0593301\n",
      "Validation loss decreased (0.053060 --> 0.053046).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542132\n",
      "\tspeed: 0.0406s/iter; left time: 633.3297s\n",
      "\titers: 200, epoch: 31 | loss: 0.0558742\n",
      "\tspeed: 0.0176s/iter; left time: 272.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0531557 Vali Loss: 0.0529637 Test Loss: 0.0594197\n",
      "Validation loss decreased (0.053046 --> 0.052964).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531322\n",
      "\tspeed: 0.0409s/iter; left time: 627.4583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0507826\n",
      "\tspeed: 0.0204s/iter; left time: 310.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531287 Vali Loss: 0.0530666 Test Loss: 0.0593458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0550206\n",
      "\tspeed: 0.0367s/iter; left time: 555.3600s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542851\n",
      "\tspeed: 0.0176s/iter; left time: 264.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0531302 Vali Loss: 0.0529413 Test Loss: 0.0592580\n",
      "Validation loss decreased (0.052964 --> 0.052941).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0553355\n",
      "\tspeed: 0.0431s/iter; left time: 642.1845s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519135\n",
      "\tspeed: 0.0197s/iter; left time: 292.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0530112 Vali Loss: 0.0529859 Test Loss: 0.0593040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532875\n",
      "\tspeed: 0.0362s/iter; left time: 530.9979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0528023\n",
      "\tspeed: 0.0181s/iter; left time: 264.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0530626 Vali Loss: 0.0530781 Test Loss: 0.0593102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0557845\n",
      "\tspeed: 0.0373s/iter; left time: 539.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521810\n",
      "\tspeed: 0.0176s/iter; left time: 252.7647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529679 Vali Loss: 0.0529296 Test Loss: 0.0592321\n",
      "Validation loss decreased (0.052941 --> 0.052930).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0516731\n",
      "\tspeed: 0.0358s/iter; left time: 510.3623s\n",
      "\titers: 200, epoch: 37 | loss: 0.0540236\n",
      "\tspeed: 0.0172s/iter; left time: 243.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0529866 Vali Loss: 0.0529916 Test Loss: 0.0592840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0508000\n",
      "\tspeed: 0.0362s/iter; left time: 507.2096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547213\n",
      "\tspeed: 0.0175s/iter; left time: 244.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0529485 Vali Loss: 0.0529122 Test Loss: 0.0592196\n",
      "Validation loss decreased (0.052930 --> 0.052912).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0529043\n",
      "\tspeed: 0.0439s/iter; left time: 605.4128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516311\n",
      "\tspeed: 0.0246s/iter; left time: 337.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0528965 Test Loss: 0.0592480\n",
      "Validation loss decreased (0.052912 --> 0.052897).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0494722\n",
      "\tspeed: 0.0396s/iter; left time: 537.3741s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527704\n",
      "\tspeed: 0.0175s/iter; left time: 235.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528899 Vali Loss: 0.0529518 Test Loss: 0.0593059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0527010\n",
      "\tspeed: 0.0354s/iter; left time: 471.6542s\n",
      "\titers: 200, epoch: 41 | loss: 0.0523881\n",
      "\tspeed: 0.0176s/iter; left time: 232.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529096 Vali Loss: 0.0528782 Test Loss: 0.0592054\n",
      "Validation loss decreased (0.052897 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0550479\n",
      "\tspeed: 0.0420s/iter; left time: 550.5007s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528131\n",
      "\tspeed: 0.0175s/iter; left time: 227.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0529324 Vali Loss: 0.0529419 Test Loss: 0.0592431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511567\n",
      "\tspeed: 0.0449s/iter; left time: 578.9241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0510774\n",
      "\tspeed: 0.0215s/iter; left time: 275.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0528664 Vali Loss: 0.0529480 Test Loss: 0.0592471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547131\n",
      "\tspeed: 0.0377s/iter; left time: 478.0473s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535225\n",
      "\tspeed: 0.0176s/iter; left time: 220.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0529409 Vali Loss: 0.0529403 Test Loss: 0.0591982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0499585\n",
      "\tspeed: 0.0368s/iter; left time: 458.5532s\n",
      "\titers: 200, epoch: 45 | loss: 0.0560696\n",
      "\tspeed: 0.0211s/iter; left time: 260.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0528784 Vali Loss: 0.0529030 Test Loss: 0.0592152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0512092\n",
      "\tspeed: 0.0385s/iter; left time: 470.9820s\n",
      "\titers: 200, epoch: 46 | loss: 0.0548510\n",
      "\tspeed: 0.0178s/iter; left time: 216.1218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0528416 Vali Loss: 0.0529498 Test Loss: 0.0591846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0539514\n",
      "\tspeed: 0.0358s/iter; left time: 429.2966s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507728\n",
      "\tspeed: 0.0174s/iter; left time: 207.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0528806 Vali Loss: 0.0529439 Test Loss: 0.0591778\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547237\n",
      "\tspeed: 0.0360s/iter; left time: 423.9098s\n",
      "\titers: 200, epoch: 48 | loss: 0.0500909\n",
      "\tspeed: 0.0175s/iter; left time: 204.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0528072 Vali Loss: 0.0529146 Test Loss: 0.0592384\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0538362\n",
      "\tspeed: 0.0378s/iter; left time: 436.7830s\n",
      "\titers: 200, epoch: 49 | loss: 0.0551731\n",
      "\tspeed: 0.0176s/iter; left time: 201.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0528127 Vali Loss: 0.0528409 Test Loss: 0.0591774\n",
      "Validation loss decreased (0.052878 --> 0.052841).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547548\n",
      "\tspeed: 0.0363s/iter; left time: 410.5844s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522613\n",
      "\tspeed: 0.0175s/iter; left time: 196.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0528483 Vali Loss: 0.0529676 Test Loss: 0.0592235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0515651\n",
      "\tspeed: 0.0434s/iter; left time: 482.0306s\n",
      "\titers: 200, epoch: 51 | loss: 0.0519167\n",
      "\tspeed: 0.0205s/iter; left time: 225.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0528751 Vali Loss: 0.0528772 Test Loss: 0.0591687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0547058\n",
      "\tspeed: 0.0394s/iter; left time: 428.2818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0527426\n",
      "\tspeed: 0.0233s/iter; left time: 251.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0528348 Vali Loss: 0.0528290 Test Loss: 0.0591753\n",
      "Validation loss decreased (0.052841 --> 0.052829).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529373\n",
      "\tspeed: 0.0379s/iter; left time: 404.1027s\n",
      "\titers: 200, epoch: 53 | loss: 0.0567268\n",
      "\tspeed: 0.0182s/iter; left time: 192.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0528269 Vali Loss: 0.0528880 Test Loss: 0.0591835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0536679\n",
      "\tspeed: 0.0388s/iter; left time: 404.9540s\n",
      "\titers: 200, epoch: 54 | loss: 0.0512394\n",
      "\tspeed: 0.0189s/iter; left time: 195.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0527903 Vali Loss: 0.0528845 Test Loss: 0.0591716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0511981\n",
      "\tspeed: 0.0394s/iter; left time: 401.7271s\n",
      "\titers: 200, epoch: 55 | loss: 0.0518198\n",
      "\tspeed: 0.0175s/iter; left time: 176.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0527804 Vali Loss: 0.0528382 Test Loss: 0.0591643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0501965\n",
      "\tspeed: 0.0377s/iter; left time: 376.6580s\n",
      "\titers: 200, epoch: 56 | loss: 0.0531978\n",
      "\tspeed: 0.0177s/iter; left time: 175.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0528132 Vali Loss: 0.0529282 Test Loss: 0.0592545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0523530\n",
      "\tspeed: 0.0383s/iter; left time: 373.5001s\n",
      "\titers: 200, epoch: 57 | loss: 0.0532235\n",
      "\tspeed: 0.0188s/iter; left time: 181.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0528334 Vali Loss: 0.0528543 Test Loss: 0.0591806\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0517060\n",
      "\tspeed: 0.0385s/iter; left time: 367.0567s\n",
      "\titers: 200, epoch: 58 | loss: 0.0537203\n",
      "\tspeed: 0.0222s/iter; left time: 209.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0528633 Vali Loss: 0.0529062 Test Loss: 0.0591597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0542901\n",
      "\tspeed: 0.0444s/iter; left time: 413.4854s\n",
      "\titers: 200, epoch: 59 | loss: 0.0490207\n",
      "\tspeed: 0.0196s/iter; left time: 180.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0527814 Vali Loss: 0.0528723 Test Loss: 0.0591480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0534826\n",
      "\tspeed: 0.0398s/iter; left time: 361.2870s\n",
      "\titers: 200, epoch: 60 | loss: 0.0522820\n",
      "\tspeed: 0.0175s/iter; left time: 157.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0528065 Vali Loss: 0.0528880 Test Loss: 0.0591799\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0541162\n",
      "\tspeed: 0.0382s/iter; left time: 338.2691s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526189\n",
      "\tspeed: 0.0199s/iter; left time: 174.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0528557 Vali Loss: 0.0528851 Test Loss: 0.0591978\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0529211\n",
      "\tspeed: 0.0372s/iter; left time: 321.3345s\n",
      "\titers: 200, epoch: 62 | loss: 0.0479516\n",
      "\tspeed: 0.0172s/iter; left time: 147.0690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0527867 Vali Loss: 0.0529483 Test Loss: 0.0591934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009751381352543831, rmse:0.0987490862607956, mae:0.05917529761791229, rse:0.29060661792755127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337921\n",
      "\tspeed: 0.0206s/iter; left time: 458.7822s\n",
      "\titers: 200, epoch: 1 | loss: 0.1069674\n",
      "\tspeed: 0.0206s/iter; left time: 458.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1356587 Vali Loss: 0.0968538 Test Loss: 0.1094441\n",
      "Validation loss decreased (inf --> 0.096854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746105\n",
      "\tspeed: 0.0394s/iter; left time: 869.6349s\n",
      "\titers: 200, epoch: 2 | loss: 0.0701489\n",
      "\tspeed: 0.0175s/iter; left time: 385.2628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0639559 Test Loss: 0.0706353\n",
      "Validation loss decreased (0.096854 --> 0.063956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675678\n",
      "\tspeed: 0.0370s/iter; left time: 807.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0615702\n",
      "\tspeed: 0.0174s/iter; left time: 379.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0655629 Vali Loss: 0.0605291 Test Loss: 0.0668655\n",
      "Validation loss decreased (0.063956 --> 0.060529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629944\n",
      "\tspeed: 0.0368s/iter; left time: 795.4977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0648704\n",
      "\tspeed: 0.0183s/iter; left time: 393.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0625614 Vali Loss: 0.0589684 Test Loss: 0.0655182\n",
      "Validation loss decreased (0.060529 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588870\n",
      "\tspeed: 0.0402s/iter; left time: 860.9520s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.0176s/iter; left time: 375.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0606106 Vali Loss: 0.0578980 Test Loss: 0.0645265\n",
      "Validation loss decreased (0.058968 --> 0.057898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592575\n",
      "\tspeed: 0.0370s/iter; left time: 782.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571381\n",
      "\tspeed: 0.0175s/iter; left time: 368.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593913 Vali Loss: 0.0566761 Test Loss: 0.0631738\n",
      "Validation loss decreased (0.057898 --> 0.056676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611145\n",
      "\tspeed: 0.0367s/iter; left time: 769.3887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605097\n",
      "\tspeed: 0.0174s/iter; left time: 362.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0583720 Vali Loss: 0.0562617 Test Loss: 0.0624770\n",
      "Validation loss decreased (0.056676 --> 0.056262).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629369\n",
      "\tspeed: 0.0418s/iter; left time: 866.8303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618621\n",
      "\tspeed: 0.0217s/iter; left time: 447.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0576425 Vali Loss: 0.0556517 Test Loss: 0.0618897\n",
      "Validation loss decreased (0.056262 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606712\n",
      "\tspeed: 0.0427s/iter; left time: 875.6113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555764\n",
      "\tspeed: 0.0222s/iter; left time: 453.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0555573 Test Loss: 0.0616752\n",
      "Validation loss decreased (0.055652 --> 0.055557).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596933\n",
      "\tspeed: 0.0453s/iter; left time: 919.0482s\n",
      "\titers: 200, epoch: 10 | loss: 0.0554582\n",
      "\tspeed: 0.0227s/iter; left time: 457.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0565138 Vali Loss: 0.0551991 Test Loss: 0.0614132\n",
      "Validation loss decreased (0.055557 --> 0.055199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0616147\n",
      "\tspeed: 0.0387s/iter; left time: 776.9877s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578825\n",
      "\tspeed: 0.0174s/iter; left time: 348.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0561789 Vali Loss: 0.0549304 Test Loss: 0.0611437\n",
      "Validation loss decreased (0.055199 --> 0.054930).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0537045\n",
      "\tspeed: 0.0367s/iter; left time: 727.8192s\n",
      "\titers: 200, epoch: 12 | loss: 0.0578890\n",
      "\tspeed: 0.0176s/iter; left time: 347.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0557681 Vali Loss: 0.0547644 Test Loss: 0.0607991\n",
      "Validation loss decreased (0.054930 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570883\n",
      "\tspeed: 0.0426s/iter; left time: 835.6845s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543759\n",
      "\tspeed: 0.0178s/iter; left time: 347.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0554576 Vali Loss: 0.0546486 Test Loss: 0.0609315\n",
      "Validation loss decreased (0.054764 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559569\n",
      "\tspeed: 0.0405s/iter; left time: 784.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576939\n",
      "\tspeed: 0.0206s/iter; left time: 397.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0551173 Vali Loss: 0.0543713 Test Loss: 0.0607464\n",
      "Validation loss decreased (0.054649 --> 0.054371).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574309\n",
      "\tspeed: 0.0404s/iter; left time: 773.9555s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533791\n",
      "\tspeed: 0.0193s/iter; left time: 367.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0548902 Vali Loss: 0.0541163 Test Loss: 0.0603891\n",
      "Validation loss decreased (0.054371 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0560301\n",
      "\tspeed: 0.0400s/iter; left time: 758.5325s\n",
      "\titers: 200, epoch: 16 | loss: 0.0556359\n",
      "\tspeed: 0.0215s/iter; left time: 404.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0546661 Vali Loss: 0.0540735 Test Loss: 0.0603688\n",
      "Validation loss decreased (0.054116 --> 0.054073).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567861\n",
      "\tspeed: 0.0400s/iter; left time: 749.0467s\n",
      "\titers: 200, epoch: 17 | loss: 0.0534253\n",
      "\tspeed: 0.0173s/iter; left time: 321.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0545065 Vali Loss: 0.0539584 Test Loss: 0.0603209\n",
      "Validation loss decreased (0.054073 --> 0.053958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0544936\n",
      "\tspeed: 0.0390s/iter; left time: 721.0882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0505661\n",
      "\tspeed: 0.0215s/iter; left time: 394.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0542611 Vali Loss: 0.0537714 Test Loss: 0.0600516\n",
      "Validation loss decreased (0.053958 --> 0.053771).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572401\n",
      "\tspeed: 0.0395s/iter; left time: 720.9557s\n",
      "\titers: 200, epoch: 19 | loss: 0.0509766\n",
      "\tspeed: 0.0203s/iter; left time: 368.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541876 Vali Loss: 0.0537230 Test Loss: 0.0601269\n",
      "Validation loss decreased (0.053771 --> 0.053723).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0581672\n",
      "\tspeed: 0.0391s/iter; left time: 704.9706s\n",
      "\titers: 200, epoch: 20 | loss: 0.0560375\n",
      "\tspeed: 0.0176s/iter; left time: 316.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540584 Vali Loss: 0.0535869 Test Loss: 0.0598196\n",
      "Validation loss decreased (0.053723 --> 0.053587).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0489908\n",
      "\tspeed: 0.0382s/iter; left time: 680.8923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556523\n",
      "\tspeed: 0.0175s/iter; left time: 310.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0539873 Vali Loss: 0.0535157 Test Loss: 0.0598667\n",
      "Validation loss decreased (0.053587 --> 0.053516).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0564136\n",
      "\tspeed: 0.0368s/iter; left time: 647.5133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0507003\n",
      "\tspeed: 0.0175s/iter; left time: 305.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0538451 Vali Loss: 0.0534693 Test Loss: 0.0597156\n",
      "Validation loss decreased (0.053516 --> 0.053469).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0500772\n",
      "\tspeed: 0.0375s/iter; left time: 651.1026s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531840\n",
      "\tspeed: 0.0175s/iter; left time: 301.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0537557 Vali Loss: 0.0533803 Test Loss: 0.0598192\n",
      "Validation loss decreased (0.053469 --> 0.053380).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0520380\n",
      "\tspeed: 0.0453s/iter; left time: 776.9973s\n",
      "\titers: 200, epoch: 24 | loss: 0.0564743\n",
      "\tspeed: 0.0176s/iter; left time: 300.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0536120 Vali Loss: 0.0534145 Test Loss: 0.0596311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0510081\n",
      "\tspeed: 0.0377s/iter; left time: 638.7096s\n",
      "\titers: 200, epoch: 25 | loss: 0.0502159\n",
      "\tspeed: 0.0174s/iter; left time: 293.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0535521 Vali Loss: 0.0534059 Test Loss: 0.0596591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0510387\n",
      "\tspeed: 0.0371s/iter; left time: 620.4239s\n",
      "\titers: 200, epoch: 26 | loss: 0.0527924\n",
      "\tspeed: 0.0177s/iter; left time: 293.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0534718 Vali Loss: 0.0533074 Test Loss: 0.0596614\n",
      "Validation loss decreased (0.053380 --> 0.053307).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0546484\n",
      "\tspeed: 0.0363s/iter; left time: 597.5156s\n",
      "\titers: 200, epoch: 27 | loss: 0.0502867\n",
      "\tspeed: 0.0173s/iter; left time: 283.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0534427 Vali Loss: 0.0532914 Test Loss: 0.0595673\n",
      "Validation loss decreased (0.053307 --> 0.053291).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513472\n",
      "\tspeed: 0.0380s/iter; left time: 617.8899s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544608\n",
      "\tspeed: 0.0177s/iter; left time: 286.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0534265 Vali Loss: 0.0533097 Test Loss: 0.0595132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543246\n",
      "\tspeed: 0.0378s/iter; left time: 606.4173s\n",
      "\titers: 200, epoch: 29 | loss: 0.0545000\n",
      "\tspeed: 0.0175s/iter; left time: 278.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0533031 Vali Loss: 0.0533129 Test Loss: 0.0596252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578123\n",
      "\tspeed: 0.0384s/iter; left time: 606.5506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523473\n",
      "\tspeed: 0.0175s/iter; left time: 275.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0532915 Vali Loss: 0.0531913 Test Loss: 0.0594889\n",
      "Validation loss decreased (0.053291 --> 0.053191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544150\n",
      "\tspeed: 0.0371s/iter; left time: 578.5391s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515520\n",
      "\tspeed: 0.0175s/iter; left time: 270.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0532813 Vali Loss: 0.0531744 Test Loss: 0.0595354\n",
      "Validation loss decreased (0.053191 --> 0.053174).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559174\n",
      "\tspeed: 0.0378s/iter; left time: 580.8415s\n",
      "\titers: 200, epoch: 32 | loss: 0.0526729\n",
      "\tspeed: 0.0173s/iter; left time: 264.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0532091 Vali Loss: 0.0531425 Test Loss: 0.0594587\n",
      "Validation loss decreased (0.053174 --> 0.053143).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0532093\n",
      "\tspeed: 0.0366s/iter; left time: 553.8593s\n",
      "\titers: 200, epoch: 33 | loss: 0.0478663\n",
      "\tspeed: 0.0173s/iter; left time: 259.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0531877 Vali Loss: 0.0531788 Test Loss: 0.0594424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0499334\n",
      "\tspeed: 0.0370s/iter; left time: 551.6185s\n",
      "\titers: 200, epoch: 34 | loss: 0.0506587\n",
      "\tspeed: 0.0175s/iter; left time: 259.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0531430 Vali Loss: 0.0531837 Test Loss: 0.0594441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517330\n",
      "\tspeed: 0.0424s/iter; left time: 622.5793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0551342\n",
      "\tspeed: 0.0203s/iter; left time: 295.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0531663 Vali Loss: 0.0531581 Test Loss: 0.0594528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506947\n",
      "\tspeed: 0.0403s/iter; left time: 582.4848s\n",
      "\titers: 200, epoch: 36 | loss: 0.0583177\n",
      "\tspeed: 0.0203s/iter; left time: 291.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531392 Vali Loss: 0.0531340 Test Loss: 0.0594451\n",
      "Validation loss decreased (0.053143 --> 0.053134).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542479\n",
      "\tspeed: 0.0454s/iter; left time: 646.6699s\n",
      "\titers: 200, epoch: 37 | loss: 0.0510775\n",
      "\tspeed: 0.0217s/iter; left time: 306.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0530918 Vali Loss: 0.0530867 Test Loss: 0.0593737\n",
      "Validation loss decreased (0.053134 --> 0.053087).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556557\n",
      "\tspeed: 0.0396s/iter; left time: 554.6645s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513426\n",
      "\tspeed: 0.0202s/iter; left time: 281.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0530756 Vali Loss: 0.0531610 Test Loss: 0.0594667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526359\n",
      "\tspeed: 0.0394s/iter; left time: 543.4934s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522014\n",
      "\tspeed: 0.0172s/iter; left time: 235.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0530237 Vali Loss: 0.0530525 Test Loss: 0.0593700\n",
      "Validation loss decreased (0.053087 --> 0.053052).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0489786\n",
      "\tspeed: 0.0409s/iter; left time: 554.8960s\n",
      "\titers: 200, epoch: 40 | loss: 0.0538423\n",
      "\tspeed: 0.0191s/iter; left time: 257.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0530496 Vali Loss: 0.0531109 Test Loss: 0.0593490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0539034\n",
      "\tspeed: 0.0382s/iter; left time: 508.9971s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502612\n",
      "\tspeed: 0.0201s/iter; left time: 266.3523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0529953 Vali Loss: 0.0531376 Test Loss: 0.0593575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509308\n",
      "\tspeed: 0.0407s/iter; left time: 533.3291s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528011\n",
      "\tspeed: 0.0203s/iter; left time: 264.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0530408 Vali Loss: 0.0531074 Test Loss: 0.0593930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536508\n",
      "\tspeed: 0.0398s/iter; left time: 513.6043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0535419\n",
      "\tspeed: 0.0209s/iter; left time: 267.6998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0530064 Vali Loss: 0.0531483 Test Loss: 0.0593524\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0534231\n",
      "\tspeed: 0.0422s/iter; left time: 534.2851s\n",
      "\titers: 200, epoch: 44 | loss: 0.0485632\n",
      "\tspeed: 0.0199s/iter; left time: 250.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0529402 Vali Loss: 0.0530934 Test Loss: 0.0593843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504932\n",
      "\tspeed: 0.0404s/iter; left time: 502.4356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0521229\n",
      "\tspeed: 0.0174s/iter; left time: 214.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0530215 Vali Loss: 0.0530575 Test Loss: 0.0593451\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0538279\n",
      "\tspeed: 0.0362s/iter; left time: 442.9136s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554503\n",
      "\tspeed: 0.0174s/iter; left time: 211.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529353 Vali Loss: 0.0530863 Test Loss: 0.0592994\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0534511\n",
      "\tspeed: 0.0370s/iter; left time: 444.1844s\n",
      "\titers: 200, epoch: 47 | loss: 0.0537172\n",
      "\tspeed: 0.0176s/iter; left time: 208.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0529956 Vali Loss: 0.0529808 Test Loss: 0.0593239\n",
      "Validation loss decreased (0.053052 --> 0.052981).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0545642\n",
      "\tspeed: 0.0414s/iter; left time: 487.0466s\n",
      "\titers: 200, epoch: 48 | loss: 0.0503907\n",
      "\tspeed: 0.0176s/iter; left time: 205.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0529698 Vali Loss: 0.0530103 Test Loss: 0.0593279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0509437\n",
      "\tspeed: 0.0385s/iter; left time: 444.9423s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518087\n",
      "\tspeed: 0.0175s/iter; left time: 200.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0529407 Vali Loss: 0.0531188 Test Loss: 0.0594364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0541317\n",
      "\tspeed: 0.0405s/iter; left time: 458.9719s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539311\n",
      "\tspeed: 0.0204s/iter; left time: 228.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0529140 Vali Loss: 0.0530143 Test Loss: 0.0593071\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0535859\n",
      "\tspeed: 0.0379s/iter; left time: 421.0638s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555147\n",
      "\tspeed: 0.0172s/iter; left time: 189.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0529585 Vali Loss: 0.0530431 Test Loss: 0.0593245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0542467\n",
      "\tspeed: 0.0359s/iter; left time: 390.8151s\n",
      "\titers: 200, epoch: 52 | loss: 0.0480840\n",
      "\tspeed: 0.0176s/iter; left time: 189.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0530876 Test Loss: 0.0593659\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0522306\n",
      "\tspeed: 0.0385s/iter; left time: 410.1747s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510478\n",
      "\tspeed: 0.0195s/iter; left time: 205.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0529877 Vali Loss: 0.0530985 Test Loss: 0.0593327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0538847\n",
      "\tspeed: 0.0378s/iter; left time: 394.1452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0531133\n",
      "\tspeed: 0.0174s/iter; left time: 179.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0529167 Vali Loss: 0.0530712 Test Loss: 0.0593545\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534907\n",
      "\tspeed: 0.0399s/iter; left time: 407.1084s\n",
      "\titers: 200, epoch: 55 | loss: 0.0500412\n",
      "\tspeed: 0.0200s/iter; left time: 202.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0529414 Vali Loss: 0.0530433 Test Loss: 0.0593276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0530696\n",
      "\tspeed: 0.0400s/iter; left time: 398.8456s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546860\n",
      "\tspeed: 0.0176s/iter; left time: 173.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0529148 Vali Loss: 0.0530499 Test Loss: 0.0593268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0518850\n",
      "\tspeed: 0.0382s/iter; left time: 372.5004s\n",
      "\titers: 200, epoch: 57 | loss: 0.0534603\n",
      "\tspeed: 0.0229s/iter; left time: 221.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0529192 Vali Loss: 0.0530396 Test Loss: 0.0593469\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009775502607226372, rmse:0.0988711416721344, mae:0.05932391434907913, rse:0.29096582531929016\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:39.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1329530\n",
      "\tspeed: 0.0443s/iter; left time: 987.1059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160002\n",
      "\tspeed: 0.0176s/iter; left time: 390.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1391902 Vali Loss: 0.1071772 Test Loss: 0.1206293\n",
      "Validation loss decreased (inf --> 0.107177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0942523\n",
      "\tspeed: 0.0385s/iter; left time: 850.8737s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861847\n",
      "\tspeed: 0.0185s/iter; left time: 406.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0945715 Vali Loss: 0.0842465 Test Loss: 0.0952013\n",
      "Validation loss decreased (0.107177 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845243\n",
      "\tspeed: 0.0382s/iter; left time: 834.0629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815090\n",
      "\tspeed: 0.0181s/iter; left time: 393.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0807858 Test Loss: 0.0915264\n",
      "Validation loss decreased (0.084247 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820356\n",
      "\tspeed: 0.0378s/iter; left time: 816.7261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805881\n",
      "\tspeed: 0.0176s/iter; left time: 378.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0823000 Vali Loss: 0.0797732 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.080786 --> 0.079773).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798331\n",
      "\tspeed: 0.0379s/iter; left time: 810.5959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755010\n",
      "\tspeed: 0.0177s/iter; left time: 376.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0804131 Vali Loss: 0.0779141 Test Loss: 0.0881555\n",
      "Validation loss decreased (0.079773 --> 0.077914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0796704\n",
      "\tspeed: 0.0375s/iter; left time: 793.5661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799784\n",
      "\tspeed: 0.0176s/iter; left time: 371.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0789057 Vali Loss: 0.0770733 Test Loss: 0.0876542\n",
      "Validation loss decreased (0.077914 --> 0.077073).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788884\n",
      "\tspeed: 0.0376s/iter; left time: 788.3541s\n",
      "\titers: 200, epoch: 7 | loss: 0.0752197\n",
      "\tspeed: 0.0177s/iter; left time: 368.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777904 Vali Loss: 0.0771061 Test Loss: 0.0872416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774317\n",
      "\tspeed: 0.0376s/iter; left time: 779.7228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751686\n",
      "\tspeed: 0.0205s/iter; left time: 423.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0770810 Vali Loss: 0.0767934 Test Loss: 0.0870996\n",
      "Validation loss decreased (0.077073 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771739\n",
      "\tspeed: 0.0401s/iter; left time: 823.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746005\n",
      "\tspeed: 0.0182s/iter; left time: 372.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0765222 Vali Loss: 0.0760892 Test Loss: 0.0869368\n",
      "Validation loss decreased (0.076793 --> 0.076089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779370\n",
      "\tspeed: 0.0435s/iter; left time: 882.3856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787978\n",
      "\tspeed: 0.0186s/iter; left time: 375.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0760347 Vali Loss: 0.0766135 Test Loss: 0.0868480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761426\n",
      "\tspeed: 0.0382s/iter; left time: 765.4540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789521\n",
      "\tspeed: 0.0178s/iter; left time: 355.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0756286 Vali Loss: 0.0763626 Test Loss: 0.0866961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0761763\n",
      "\tspeed: 0.0373s/iter; left time: 740.3132s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757204\n",
      "\tspeed: 0.0178s/iter; left time: 352.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0753164 Vali Loss: 0.0763749 Test Loss: 0.0863272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718356\n",
      "\tspeed: 0.0375s/iter; left time: 735.7471s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752915\n",
      "\tspeed: 0.0178s/iter; left time: 348.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0749505 Vali Loss: 0.0764924 Test Loss: 0.0864433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712507\n",
      "\tspeed: 0.0413s/iter; left time: 800.9626s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751940\n",
      "\tspeed: 0.0204s/iter; left time: 393.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0747298 Vali Loss: 0.0763432 Test Loss: 0.0865515\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0714074\n",
      "\tspeed: 0.0389s/iter; left time: 746.0339s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769075\n",
      "\tspeed: 0.0179s/iter; left time: 340.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0744110 Vali Loss: 0.0763409 Test Loss: 0.0860551\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736857\n",
      "\tspeed: 0.0390s/iter; left time: 738.2485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0758855\n",
      "\tspeed: 0.0179s/iter; left time: 336.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0741638 Vali Loss: 0.0763573 Test Loss: 0.0862534\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732683\n",
      "\tspeed: 0.0372s/iter; left time: 696.4759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766605\n",
      "\tspeed: 0.0178s/iter; left time: 332.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0739782 Vali Loss: 0.0760687 Test Loss: 0.0860618\n",
      "Validation loss decreased (0.076089 --> 0.076069).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758949\n",
      "\tspeed: 0.0420s/iter; left time: 775.8797s\n",
      "\titers: 200, epoch: 18 | loss: 0.0741989\n",
      "\tspeed: 0.0201s/iter; left time: 369.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0738317 Vali Loss: 0.0758029 Test Loss: 0.0859767\n",
      "Validation loss decreased (0.076069 --> 0.075803).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731899\n",
      "\tspeed: 0.0400s/iter; left time: 730.6615s\n",
      "\titers: 200, epoch: 19 | loss: 0.0783558\n",
      "\tspeed: 0.0180s/iter; left time: 326.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0736161 Vali Loss: 0.0767120 Test Loss: 0.0861842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724703\n",
      "\tspeed: 0.0395s/iter; left time: 713.2295s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739780\n",
      "\tspeed: 0.0187s/iter; left time: 335.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0735227 Vali Loss: 0.0763454 Test Loss: 0.0858723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0736979\n",
      "\tspeed: 0.0383s/iter; left time: 681.9721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0692475\n",
      "\tspeed: 0.0176s/iter; left time: 312.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733244 Vali Loss: 0.0759520 Test Loss: 0.0858447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0742377\n",
      "\tspeed: 0.0378s/iter; left time: 664.7089s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738283\n",
      "\tspeed: 0.0177s/iter; left time: 309.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0732371 Vali Loss: 0.0761869 Test Loss: 0.0859049\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716027\n",
      "\tspeed: 0.0386s/iter; left time: 671.2958s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768406\n",
      "\tspeed: 0.0176s/iter; left time: 304.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0730942 Vali Loss: 0.0761952 Test Loss: 0.0858184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739905\n",
      "\tspeed: 0.0375s/iter; left time: 643.1647s\n",
      "\titers: 200, epoch: 24 | loss: 0.0714365\n",
      "\tspeed: 0.0177s/iter; left time: 300.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0729818 Vali Loss: 0.0762859 Test Loss: 0.0857470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0700301\n",
      "\tspeed: 0.0383s/iter; left time: 648.7693s\n",
      "\titers: 200, epoch: 25 | loss: 0.0753928\n",
      "\tspeed: 0.0181s/iter; left time: 303.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0729328 Vali Loss: 0.0763261 Test Loss: 0.0859215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696138\n",
      "\tspeed: 0.0382s/iter; left time: 637.6291s\n",
      "\titers: 200, epoch: 26 | loss: 0.0715025\n",
      "\tspeed: 0.0196s/iter; left time: 325.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0728175 Vali Loss: 0.0762029 Test Loss: 0.0858192\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725613\n",
      "\tspeed: 0.0370s/iter; left time: 610.2925s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719680\n",
      "\tspeed: 0.0185s/iter; left time: 302.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0727753 Vali Loss: 0.0761756 Test Loss: 0.0857254\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751431\n",
      "\tspeed: 0.0390s/iter; left time: 634.0645s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738966\n",
      "\tspeed: 0.0178s/iter; left time: 287.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0727138 Vali Loss: 0.0765646 Test Loss: 0.0857118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01854773983359337, rmse:0.13619008660316467, mae:0.08597671240568161, rse:0.4000854790210724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1367538\n",
      "\tspeed: 0.0223s/iter; left time: 496.8574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153385\n",
      "\tspeed: 0.0233s/iter; left time: 517.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1400050 Vali Loss: 0.1071248 Test Loss: 0.1205454\n",
      "Validation loss decreased (inf --> 0.107125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936913\n",
      "\tspeed: 0.0460s/iter; left time: 1015.9851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879241\n",
      "\tspeed: 0.0176s/iter; left time: 387.3446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0942411 Vali Loss: 0.0843040 Test Loss: 0.0953580\n",
      "Validation loss decreased (0.107125 --> 0.084304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803946\n",
      "\tspeed: 0.0403s/iter; left time: 880.0693s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812021\n",
      "\tspeed: 0.0178s/iter; left time: 386.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0852106 Vali Loss: 0.0801856 Test Loss: 0.0912001\n",
      "Validation loss decreased (0.084304 --> 0.080186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788692\n",
      "\tspeed: 0.0415s/iter; left time: 898.5903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0762093\n",
      "\tspeed: 0.0216s/iter; left time: 466.0767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0821201 Vali Loss: 0.0789561 Test Loss: 0.0895967\n",
      "Validation loss decreased (0.080186 --> 0.078956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793223\n",
      "\tspeed: 0.0421s/iter; left time: 900.2679s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773962\n",
      "\tspeed: 0.0193s/iter; left time: 410.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802467 Vali Loss: 0.0778591 Test Loss: 0.0884357\n",
      "Validation loss decreased (0.078956 --> 0.077859).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816932\n",
      "\tspeed: 0.0403s/iter; left time: 853.8364s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778644\n",
      "\tspeed: 0.0177s/iter; left time: 373.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0790325 Vali Loss: 0.0767959 Test Loss: 0.0875439\n",
      "Validation loss decreased (0.077859 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745961\n",
      "\tspeed: 0.0387s/iter; left time: 810.0707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834768\n",
      "\tspeed: 0.0178s/iter; left time: 371.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0781038 Vali Loss: 0.0762627 Test Loss: 0.0873462\n",
      "Validation loss decreased (0.076796 --> 0.076263).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800848\n",
      "\tspeed: 0.0400s/iter; left time: 829.6929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742644\n",
      "\tspeed: 0.0178s/iter; left time: 367.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0773239 Vali Loss: 0.0775152 Test Loss: 0.0874873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721739\n",
      "\tspeed: 0.0381s/iter; left time: 780.9902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794274\n",
      "\tspeed: 0.0209s/iter; left time: 426.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0767547 Vali Loss: 0.0763608 Test Loss: 0.0870005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758219\n",
      "\tspeed: 0.0409s/iter; left time: 828.6589s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767745\n",
      "\tspeed: 0.0189s/iter; left time: 381.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0761915 Vali Loss: 0.0771433 Test Loss: 0.0867632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747136\n",
      "\tspeed: 0.0450s/iter; left time: 903.2435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756405\n",
      "\tspeed: 0.0197s/iter; left time: 394.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0757717 Vali Loss: 0.0765610 Test Loss: 0.0865518\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0714020\n",
      "\tspeed: 0.0425s/iter; left time: 843.1375s\n",
      "\titers: 200, epoch: 12 | loss: 0.0774138\n",
      "\tspeed: 0.0219s/iter; left time: 431.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0754335 Vali Loss: 0.0767363 Test Loss: 0.0865050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722883\n",
      "\tspeed: 0.0396s/iter; left time: 775.7284s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759881\n",
      "\tspeed: 0.0175s/iter; left time: 341.8679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0751549 Vali Loss: 0.0761463 Test Loss: 0.0862424\n",
      "Validation loss decreased (0.076263 --> 0.076146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745482\n",
      "\tspeed: 0.0412s/iter; left time: 799.4890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0744093\n",
      "\tspeed: 0.0245s/iter; left time: 471.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0747696 Vali Loss: 0.0762650 Test Loss: 0.0862187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720881\n",
      "\tspeed: 0.0400s/iter; left time: 765.8024s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781316\n",
      "\tspeed: 0.0174s/iter; left time: 331.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0745868 Vali Loss: 0.0765290 Test Loss: 0.0860522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0727114\n",
      "\tspeed: 0.0412s/iter; left time: 779.4685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736387\n",
      "\tspeed: 0.0179s/iter; left time: 337.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0743449 Vali Loss: 0.0765852 Test Loss: 0.0860310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706794\n",
      "\tspeed: 0.0388s/iter; left time: 726.9777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752406\n",
      "\tspeed: 0.0205s/iter; left time: 381.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0741923 Vali Loss: 0.0764369 Test Loss: 0.0859239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0744676\n",
      "\tspeed: 0.0419s/iter; left time: 775.4276s\n",
      "\titers: 200, epoch: 18 | loss: 0.0762818\n",
      "\tspeed: 0.0202s/iter; left time: 371.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0740024 Vali Loss: 0.0767829 Test Loss: 0.0857268\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720721\n",
      "\tspeed: 0.0437s/iter; left time: 797.7713s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713664\n",
      "\tspeed: 0.0189s/iter; left time: 342.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0738495 Vali Loss: 0.0765352 Test Loss: 0.0859384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717330\n",
      "\tspeed: 0.0413s/iter; left time: 745.2349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795915\n",
      "\tspeed: 0.0205s/iter; left time: 368.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0736705 Vali Loss: 0.0764407 Test Loss: 0.0857348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724586\n",
      "\tspeed: 0.0392s/iter; left time: 697.8497s\n",
      "\titers: 200, epoch: 21 | loss: 0.0760887\n",
      "\tspeed: 0.0186s/iter; left time: 329.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0735496 Vali Loss: 0.0764364 Test Loss: 0.0857035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712291\n",
      "\tspeed: 0.0433s/iter; left time: 762.3607s\n",
      "\titers: 200, epoch: 22 | loss: 0.0771685\n",
      "\tspeed: 0.0197s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0734158 Vali Loss: 0.0766588 Test Loss: 0.0858466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0699845\n",
      "\tspeed: 0.0433s/iter; left time: 751.8209s\n",
      "\titers: 200, epoch: 23 | loss: 0.0729147\n",
      "\tspeed: 0.0220s/iter; left time: 380.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0733128 Vali Loss: 0.0762644 Test Loss: 0.0857591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018521282821893692, rmse:0.1360929161310196, mae:0.08624237030744553, rse:0.39980003237724304\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:11.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1373530\n",
      "\tspeed: 0.0465s/iter; left time: 1032.9857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231130\n",
      "\tspeed: 0.0178s/iter; left time: 392.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1409036 Vali Loss: 0.1098791 Test Loss: 0.1227950\n",
      "Validation loss decreased (inf --> 0.109879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0984424\n",
      "\tspeed: 0.0383s/iter; left time: 841.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898476\n",
      "\tspeed: 0.0182s/iter; left time: 398.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0985992 Vali Loss: 0.0892979 Test Loss: 0.1007477\n",
      "Validation loss decreased (0.109879 --> 0.089298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924045\n",
      "\tspeed: 0.0405s/iter; left time: 880.7054s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917421\n",
      "\tspeed: 0.0180s/iter; left time: 389.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0898567 Vali Loss: 0.0863748 Test Loss: 0.0964161\n",
      "Validation loss decreased (0.089298 --> 0.086375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892772\n",
      "\tspeed: 0.0398s/iter; left time: 856.7383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851799\n",
      "\tspeed: 0.0179s/iter; left time: 383.3302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0869219 Vali Loss: 0.0845703 Test Loss: 0.0945225\n",
      "Validation loss decreased (0.086375 --> 0.084570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874058\n",
      "\tspeed: 0.0391s/iter; left time: 832.4707s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828013\n",
      "\tspeed: 0.0178s/iter; left time: 377.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0849152 Vali Loss: 0.0836334 Test Loss: 0.0937513\n",
      "Validation loss decreased (0.084570 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0815478\n",
      "\tspeed: 0.0387s/iter; left time: 816.1537s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822768\n",
      "\tspeed: 0.0180s/iter; left time: 377.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0835952 Vali Loss: 0.0829994 Test Loss: 0.0932573\n",
      "Validation loss decreased (0.083633 --> 0.082999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838339\n",
      "\tspeed: 0.0395s/iter; left time: 823.9421s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832751\n",
      "\tspeed: 0.0178s/iter; left time: 370.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0826350 Vali Loss: 0.0830178 Test Loss: 0.0929825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780568\n",
      "\tspeed: 0.0390s/iter; left time: 803.9680s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825638\n",
      "\tspeed: 0.0203s/iter; left time: 417.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0819650 Vali Loss: 0.0831217 Test Loss: 0.0930658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0815612\n",
      "\tspeed: 0.0383s/iter; left time: 782.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793496\n",
      "\tspeed: 0.0184s/iter; left time: 373.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0814262 Vali Loss: 0.0825041 Test Loss: 0.0924428\n",
      "Validation loss decreased (0.082999 --> 0.082504).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0814151\n",
      "\tspeed: 0.0392s/iter; left time: 790.9053s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819548\n",
      "\tspeed: 0.0179s/iter; left time: 360.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0809147 Vali Loss: 0.0830627 Test Loss: 0.0926520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803450\n",
      "\tspeed: 0.0384s/iter; left time: 767.3787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782218\n",
      "\tspeed: 0.0181s/iter; left time: 360.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0805403 Vali Loss: 0.0824139 Test Loss: 0.0921823\n",
      "Validation loss decreased (0.082504 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775920\n",
      "\tspeed: 0.0397s/iter; left time: 784.6760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816294\n",
      "\tspeed: 0.0182s/iter; left time: 357.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0801135 Vali Loss: 0.0824283 Test Loss: 0.0917523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782452\n",
      "\tspeed: 0.0407s/iter; left time: 794.1000s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793490\n",
      "\tspeed: 0.0190s/iter; left time: 369.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0797442 Vali Loss: 0.0824807 Test Loss: 0.0922180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785616\n",
      "\tspeed: 0.0401s/iter; left time: 773.2075s\n",
      "\titers: 200, epoch: 14 | loss: 0.0811015\n",
      "\tspeed: 0.0178s/iter; left time: 342.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0794834 Vali Loss: 0.0825382 Test Loss: 0.0917946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793498\n",
      "\tspeed: 0.0381s/iter; left time: 726.5424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0845542\n",
      "\tspeed: 0.0178s/iter; left time: 337.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0791975 Vali Loss: 0.0827265 Test Loss: 0.0922221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800094\n",
      "\tspeed: 0.0381s/iter; left time: 719.1809s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803068\n",
      "\tspeed: 0.0181s/iter; left time: 340.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0789066 Vali Loss: 0.0829194 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777317\n",
      "\tspeed: 0.0381s/iter; left time: 710.2658s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769415\n",
      "\tspeed: 0.0178s/iter; left time: 329.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0787117 Vali Loss: 0.0828620 Test Loss: 0.0919372\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754707\n",
      "\tspeed: 0.0418s/iter; left time: 769.0558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807448\n",
      "\tspeed: 0.0184s/iter; left time: 336.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0784592 Vali Loss: 0.0827428 Test Loss: 0.0919137\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788248\n",
      "\tspeed: 0.0387s/iter; left time: 703.3631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779088\n",
      "\tspeed: 0.0180s/iter; left time: 325.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0783152 Vali Loss: 0.0827719 Test Loss: 0.0921597\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814836\n",
      "\tspeed: 0.0378s/iter; left time: 678.8644s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774235\n",
      "\tspeed: 0.0178s/iter; left time: 317.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0781401 Vali Loss: 0.0830398 Test Loss: 0.0921266\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0771261\n",
      "\tspeed: 0.0382s/iter; left time: 677.8467s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789094\n",
      "\tspeed: 0.0178s/iter; left time: 314.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0780248 Vali Loss: 0.0829910 Test Loss: 0.0919375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020852474495768547, rmse:0.1444038599729538, mae:0.09218230098485947, rse:0.42424553632736206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1372358\n",
      "\tspeed: 0.0202s/iter; left time: 449.2328s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189031\n",
      "\tspeed: 0.0179s/iter; left time: 395.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1425659 Vali Loss: 0.1109068 Test Loss: 0.1238196\n",
      "Validation loss decreased (inf --> 0.110907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962597\n",
      "\tspeed: 0.0425s/iter; left time: 935.0872s\n",
      "\titers: 200, epoch: 2 | loss: 0.0892632\n",
      "\tspeed: 0.0180s/iter; left time: 393.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0986520 Vali Loss: 0.0897229 Test Loss: 0.1013632\n",
      "Validation loss decreased (0.110907 --> 0.089723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895527\n",
      "\tspeed: 0.0434s/iter; left time: 943.5019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0907336\n",
      "\tspeed: 0.0201s/iter; left time: 435.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0899338 Vali Loss: 0.0860113 Test Loss: 0.0964112\n",
      "Validation loss decreased (0.089723 --> 0.086011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0877847\n",
      "\tspeed: 0.0397s/iter; left time: 854.1758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873513\n",
      "\tspeed: 0.0179s/iter; left time: 383.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0867699 Vali Loss: 0.0845652 Test Loss: 0.0945405\n",
      "Validation loss decreased (0.086011 --> 0.084565).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860343\n",
      "\tspeed: 0.0392s/iter; left time: 834.4113s\n",
      "\titers: 200, epoch: 5 | loss: 0.0856858\n",
      "\tspeed: 0.0179s/iter; left time: 380.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0848098 Vali Loss: 0.0831996 Test Loss: 0.0935732\n",
      "Validation loss decreased (0.084565 --> 0.083200).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817515\n",
      "\tspeed: 0.0383s/iter; left time: 807.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0839486\n",
      "\tspeed: 0.0178s/iter; left time: 374.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0835718 Vali Loss: 0.0824345 Test Loss: 0.0923223\n",
      "Validation loss decreased (0.083200 --> 0.082434).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821306\n",
      "\tspeed: 0.0427s/iter; left time: 891.5068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817424\n",
      "\tspeed: 0.0198s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0828282 Vali Loss: 0.0827731 Test Loss: 0.0922567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816821\n",
      "\tspeed: 0.0384s/iter; left time: 791.9485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851653\n",
      "\tspeed: 0.0178s/iter; left time: 366.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0822374 Vali Loss: 0.0825162 Test Loss: 0.0923592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792334\n",
      "\tspeed: 0.0387s/iter; left time: 789.8722s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820873\n",
      "\tspeed: 0.0177s/iter; left time: 360.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0817259 Vali Loss: 0.0824933 Test Loss: 0.0925659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0831882\n",
      "\tspeed: 0.0420s/iter; left time: 848.0628s\n",
      "\titers: 200, epoch: 10 | loss: 0.0840190\n",
      "\tspeed: 0.0204s/iter; left time: 410.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0812772 Vali Loss: 0.0824480 Test Loss: 0.0920063\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844629\n",
      "\tspeed: 0.0422s/iter; left time: 842.0142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0821361\n",
      "\tspeed: 0.0217s/iter; left time: 430.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0809295 Vali Loss: 0.0831282 Test Loss: 0.0924046\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819720\n",
      "\tspeed: 0.0393s/iter; left time: 775.8412s\n",
      "\titers: 200, epoch: 12 | loss: 0.0770248\n",
      "\tspeed: 0.0181s/iter; left time: 356.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0805377 Vali Loss: 0.0823976 Test Loss: 0.0917684\n",
      "Validation loss decreased (0.082434 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825309\n",
      "\tspeed: 0.0393s/iter; left time: 768.1248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808482\n",
      "\tspeed: 0.0178s/iter; left time: 346.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0802130 Vali Loss: 0.0822795 Test Loss: 0.0915192\n",
      "Validation loss decreased (0.082398 --> 0.082279).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787355\n",
      "\tspeed: 0.0396s/iter; left time: 764.3940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800075\n",
      "\tspeed: 0.0178s/iter; left time: 341.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0799463 Vali Loss: 0.0827081 Test Loss: 0.0917543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0808903\n",
      "\tspeed: 0.0406s/iter; left time: 775.0545s\n",
      "\titers: 200, epoch: 15 | loss: 0.0780651\n",
      "\tspeed: 0.0209s/iter; left time: 397.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0796282 Vali Loss: 0.0825399 Test Loss: 0.0913055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823017\n",
      "\tspeed: 0.0437s/iter; left time: 823.8916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0812932\n",
      "\tspeed: 0.0181s/iter; left time: 339.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0794008 Vali Loss: 0.0822595 Test Loss: 0.0912687\n",
      "Validation loss decreased (0.082279 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0768999\n",
      "\tspeed: 0.0397s/iter; left time: 740.5874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793285\n",
      "\tspeed: 0.0182s/iter; left time: 337.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0792046 Vali Loss: 0.0824286 Test Loss: 0.0913005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0811558\n",
      "\tspeed: 0.0422s/iter; left time: 776.8880s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767288\n",
      "\tspeed: 0.0186s/iter; left time: 341.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0790217 Vali Loss: 0.0826947 Test Loss: 0.0914750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766188\n",
      "\tspeed: 0.0383s/iter; left time: 696.5783s\n",
      "\titers: 200, epoch: 19 | loss: 0.0823196\n",
      "\tspeed: 0.0180s/iter; left time: 325.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0788044 Vali Loss: 0.0827591 Test Loss: 0.0914700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801984\n",
      "\tspeed: 0.0382s/iter; left time: 686.2105s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807184\n",
      "\tspeed: 0.0179s/iter; left time: 319.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0786730 Vali Loss: 0.0820548 Test Loss: 0.0909845\n",
      "Validation loss decreased (0.082259 --> 0.082055).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0805757\n",
      "\tspeed: 0.0410s/iter; left time: 726.6098s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777372\n",
      "\tspeed: 0.0185s/iter; left time: 325.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0785318 Vali Loss: 0.0824276 Test Loss: 0.0911584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793678\n",
      "\tspeed: 0.0398s/iter; left time: 697.4270s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783650\n",
      "\tspeed: 0.0185s/iter; left time: 322.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0784128 Vali Loss: 0.0825987 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0799742\n",
      "\tspeed: 0.0389s/iter; left time: 673.1967s\n",
      "\titers: 200, epoch: 23 | loss: 0.0794193\n",
      "\tspeed: 0.0180s/iter; left time: 308.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0825067 Test Loss: 0.0911256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0774844\n",
      "\tspeed: 0.0408s/iter; left time: 695.8240s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797026\n",
      "\tspeed: 0.0187s/iter; left time: 317.2155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0781464 Vali Loss: 0.0826594 Test Loss: 0.0912149\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770763\n",
      "\tspeed: 0.0453s/iter; left time: 763.6968s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791379\n",
      "\tspeed: 0.0215s/iter; left time: 359.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0780359 Vali Loss: 0.0827667 Test Loss: 0.0911917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812251\n",
      "\tspeed: 0.0463s/iter; left time: 769.7062s\n",
      "\titers: 200, epoch: 26 | loss: 0.0773855\n",
      "\tspeed: 0.0217s/iter; left time: 358.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0779974 Vali Loss: 0.0827996 Test Loss: 0.0910253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775638\n",
      "\tspeed: 0.0450s/iter; left time: 737.7617s\n",
      "\titers: 200, epoch: 27 | loss: 0.0749843\n",
      "\tspeed: 0.0213s/iter; left time: 346.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0779365 Vali Loss: 0.0824053 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0782782\n",
      "\tspeed: 0.0427s/iter; left time: 691.0858s\n",
      "\titers: 200, epoch: 28 | loss: 0.0794728\n",
      "\tspeed: 0.0213s/iter; left time: 342.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0778237 Vali Loss: 0.0824167 Test Loss: 0.0909431\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744470\n",
      "\tspeed: 0.0498s/iter; left time: 794.5243s\n",
      "\titers: 200, epoch: 29 | loss: 0.0743873\n",
      "\tspeed: 0.0229s/iter; left time: 363.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0778208 Vali Loss: 0.0826677 Test Loss: 0.0910047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778956\n",
      "\tspeed: 0.0468s/iter; left time: 736.4441s\n",
      "\titers: 200, epoch: 30 | loss: 0.0735903\n",
      "\tspeed: 0.0199s/iter; left time: 311.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0826702 Test Loss: 0.0909662\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02058718539774418, rmse:0.14348235726356506, mae:0.09098456054925919, rse:0.42153823375701904\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:15.25s\n",
      "Intermediate time for ES: 00h:22m:06.03s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0923198\n",
      "\tspeed: 0.0471s/iter; left time: 1050.7328s\n",
      "\titers: 200, epoch: 1 | loss: 0.0812700\n",
      "\tspeed: 0.0175s/iter; left time: 389.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0997137 Vali Loss: 0.0826080 Test Loss: 0.0894115\n",
      "Validation loss decreased (inf --> 0.082608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0530040\n",
      "\tspeed: 0.0374s/iter; left time: 825.2455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500890\n",
      "\tspeed: 0.0176s/iter; left time: 386.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0568332 Vali Loss: 0.0584304 Test Loss: 0.0615740\n",
      "Validation loss decreased (0.082608 --> 0.058430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0495541\n",
      "\tspeed: 0.0390s/iter; left time: 852.1089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0470994\n",
      "\tspeed: 0.0178s/iter; left time: 386.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0492891 Vali Loss: 0.0561867 Test Loss: 0.0599419\n",
      "Validation loss decreased (0.058430 --> 0.056187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472196\n",
      "\tspeed: 0.0373s/iter; left time: 805.7826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496854\n",
      "\tspeed: 0.0175s/iter; left time: 375.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0474948 Vali Loss: 0.0547214 Test Loss: 0.0583943\n",
      "Validation loss decreased (0.056187 --> 0.054721).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0445898\n",
      "\tspeed: 0.0379s/iter; left time: 811.0635s\n",
      "\titers: 200, epoch: 5 | loss: 0.0486444\n",
      "\tspeed: 0.0175s/iter; left time: 373.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462286 Vali Loss: 0.0537535 Test Loss: 0.0576479\n",
      "Validation loss decreased (0.054721 --> 0.053753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0466075\n",
      "\tspeed: 0.0384s/iter; left time: 813.6643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427133\n",
      "\tspeed: 0.0173s/iter; left time: 364.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0453936 Vali Loss: 0.0532484 Test Loss: 0.0574954\n",
      "Validation loss decreased (0.053753 --> 0.053248).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0491663\n",
      "\tspeed: 0.0406s/iter; left time: 851.6473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448862\n",
      "\tspeed: 0.0174s/iter; left time: 362.2701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0447000 Vali Loss: 0.0526119 Test Loss: 0.0567984\n",
      "Validation loss decreased (0.053248 --> 0.052612).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0448391\n",
      "\tspeed: 0.0388s/iter; left time: 803.6487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0443497\n",
      "\tspeed: 0.0175s/iter; left time: 361.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0441658 Vali Loss: 0.0528287 Test Loss: 0.0566366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0405296\n",
      "\tspeed: 0.0380s/iter; left time: 779.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0458015\n",
      "\tspeed: 0.0173s/iter; left time: 354.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0437640 Vali Loss: 0.0521360 Test Loss: 0.0564570\n",
      "Validation loss decreased (0.052612 --> 0.052136).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441886\n",
      "\tspeed: 0.0407s/iter; left time: 826.5387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0448638\n",
      "\tspeed: 0.0206s/iter; left time: 415.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0434143 Vali Loss: 0.0517792 Test Loss: 0.0561378\n",
      "Validation loss decreased (0.052136 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440236\n",
      "\tspeed: 0.0429s/iter; left time: 861.3392s\n",
      "\titers: 200, epoch: 11 | loss: 0.0420616\n",
      "\tspeed: 0.0212s/iter; left time: 423.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0431010 Vali Loss: 0.0520836 Test Loss: 0.0564000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0403346\n",
      "\tspeed: 0.0366s/iter; left time: 726.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0413291\n",
      "\tspeed: 0.0175s/iter; left time: 345.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0428325 Vali Loss: 0.0517494 Test Loss: 0.0560631\n",
      "Validation loss decreased (0.051779 --> 0.051749).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406433\n",
      "\tspeed: 0.0376s/iter; left time: 737.7125s\n",
      "\titers: 200, epoch: 13 | loss: 0.0392740\n",
      "\tspeed: 0.0175s/iter; left time: 342.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0425714 Vali Loss: 0.0517062 Test Loss: 0.0557897\n",
      "Validation loss decreased (0.051749 --> 0.051706).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0407032\n",
      "\tspeed: 0.0399s/iter; left time: 773.5516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0415839\n",
      "\tspeed: 0.0184s/iter; left time: 355.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0424152 Vali Loss: 0.0514950 Test Loss: 0.0557442\n",
      "Validation loss decreased (0.051706 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0427796\n",
      "\tspeed: 0.0377s/iter; left time: 723.2441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0386341\n",
      "\tspeed: 0.0173s/iter; left time: 330.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0422304 Vali Loss: 0.0514152 Test Loss: 0.0555388\n",
      "Validation loss decreased (0.051495 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407047\n",
      "\tspeed: 0.0367s/iter; left time: 695.1301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0395314\n",
      "\tspeed: 0.0197s/iter; left time: 370.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0421071 Vali Loss: 0.0514455 Test Loss: 0.0555331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0455639\n",
      "\tspeed: 0.0411s/iter; left time: 768.5792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0418858\n",
      "\tspeed: 0.0178s/iter; left time: 331.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0419426 Vali Loss: 0.0512198 Test Loss: 0.0553853\n",
      "Validation loss decreased (0.051415 --> 0.051220).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0401110\n",
      "\tspeed: 0.0382s/iter; left time: 706.4201s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410072\n",
      "\tspeed: 0.0177s/iter; left time: 326.4655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418059 Vali Loss: 0.0510725 Test Loss: 0.0553629\n",
      "Validation loss decreased (0.051220 --> 0.051072).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0397940\n",
      "\tspeed: 0.0400s/iter; left time: 730.7567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415944\n",
      "\tspeed: 0.0209s/iter; left time: 378.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0416938 Vali Loss: 0.0510424 Test Loss: 0.0552553\n",
      "Validation loss decreased (0.051072 --> 0.051042).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0410033\n",
      "\tspeed: 0.0427s/iter; left time: 770.8388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0419177\n",
      "\tspeed: 0.0181s/iter; left time: 324.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0416170 Vali Loss: 0.0509896 Test Loss: 0.0552562\n",
      "Validation loss decreased (0.051042 --> 0.050990).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414350\n",
      "\tspeed: 0.0380s/iter; left time: 677.0998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0406842\n",
      "\tspeed: 0.0174s/iter; left time: 307.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0415393 Vali Loss: 0.0508995 Test Loss: 0.0550967\n",
      "Validation loss decreased (0.050990 --> 0.050899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0403014\n",
      "\tspeed: 0.0401s/iter; left time: 705.8079s\n",
      "\titers: 200, epoch: 22 | loss: 0.0367226\n",
      "\tspeed: 0.0178s/iter; left time: 310.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0414575 Vali Loss: 0.0509838 Test Loss: 0.0551132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0409429\n",
      "\tspeed: 0.0398s/iter; left time: 691.6798s\n",
      "\titers: 200, epoch: 23 | loss: 0.0429620\n",
      "\tspeed: 0.0223s/iter; left time: 385.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413607 Vali Loss: 0.0509441 Test Loss: 0.0551800\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404058\n",
      "\tspeed: 0.0397s/iter; left time: 681.0152s\n",
      "\titers: 200, epoch: 24 | loss: 0.0405565\n",
      "\tspeed: 0.0222s/iter; left time: 378.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0413338 Vali Loss: 0.0509188 Test Loss: 0.0551000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423914\n",
      "\tspeed: 0.0407s/iter; left time: 688.4196s\n",
      "\titers: 200, epoch: 25 | loss: 0.0413437\n",
      "\tspeed: 0.0197s/iter; left time: 330.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0412619 Vali Loss: 0.0509029 Test Loss: 0.0551642\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0389570\n",
      "\tspeed: 0.0380s/iter; left time: 634.0786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0388686\n",
      "\tspeed: 0.0176s/iter; left time: 292.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0412201 Vali Loss: 0.0509290 Test Loss: 0.0551733\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0415587\n",
      "\tspeed: 0.0369s/iter; left time: 607.7228s\n",
      "\titers: 200, epoch: 27 | loss: 0.0423500\n",
      "\tspeed: 0.0197s/iter; left time: 322.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0411406 Vali Loss: 0.0508458 Test Loss: 0.0550130\n",
      "Validation loss decreased (0.050899 --> 0.050846).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0435844\n",
      "\tspeed: 0.0411s/iter; left time: 668.6772s\n",
      "\titers: 200, epoch: 28 | loss: 0.0385247\n",
      "\tspeed: 0.0200s/iter; left time: 322.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0411405 Vali Loss: 0.0508347 Test Loss: 0.0550222\n",
      "Validation loss decreased (0.050846 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0420762\n",
      "\tspeed: 0.0368s/iter; left time: 589.5002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0388678\n",
      "\tspeed: 0.0175s/iter; left time: 278.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0411094 Vali Loss: 0.0508880 Test Loss: 0.0549905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0427229\n",
      "\tspeed: 0.0421s/iter; left time: 665.9101s\n",
      "\titers: 200, epoch: 30 | loss: 0.0388344\n",
      "\tspeed: 0.0202s/iter; left time: 317.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0410763 Vali Loss: 0.0508937 Test Loss: 0.0550308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0407782\n",
      "\tspeed: 0.0365s/iter; left time: 568.3944s\n",
      "\titers: 200, epoch: 31 | loss: 0.0419291\n",
      "\tspeed: 0.0195s/iter; left time: 302.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0410766 Vali Loss: 0.0506749 Test Loss: 0.0550058\n",
      "Validation loss decreased (0.050835 --> 0.050675).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0414399\n",
      "\tspeed: 0.0382s/iter; left time: 586.8291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421118\n",
      "\tspeed: 0.0199s/iter; left time: 303.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0410319 Vali Loss: 0.0507480 Test Loss: 0.0549598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0422271\n",
      "\tspeed: 0.0365s/iter; left time: 552.3449s\n",
      "\titers: 200, epoch: 33 | loss: 0.0414499\n",
      "\tspeed: 0.0175s/iter; left time: 263.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0409737 Vali Loss: 0.0507774 Test Loss: 0.0549851\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0413024\n",
      "\tspeed: 0.0361s/iter; left time: 538.2906s\n",
      "\titers: 200, epoch: 34 | loss: 0.0401151\n",
      "\tspeed: 0.0174s/iter; left time: 256.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0409406 Vali Loss: 0.0506703 Test Loss: 0.0549519\n",
      "Validation loss decreased (0.050675 --> 0.050670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0408263\n",
      "\tspeed: 0.0391s/iter; left time: 574.3639s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405118\n",
      "\tspeed: 0.0176s/iter; left time: 256.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0409528 Vali Loss: 0.0507586 Test Loss: 0.0549365\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0392115\n",
      "\tspeed: 0.0370s/iter; left time: 534.8904s\n",
      "\titers: 200, epoch: 36 | loss: 0.0404948\n",
      "\tspeed: 0.0175s/iter; left time: 251.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409394 Vali Loss: 0.0507388 Test Loss: 0.0549210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0423826\n",
      "\tspeed: 0.0361s/iter; left time: 513.9982s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399949\n",
      "\tspeed: 0.0187s/iter; left time: 264.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0409280 Vali Loss: 0.0507797 Test Loss: 0.0549513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0420419\n",
      "\tspeed: 0.0364s/iter; left time: 509.5619s\n",
      "\titers: 200, epoch: 38 | loss: 0.0414468\n",
      "\tspeed: 0.0180s/iter; left time: 250.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0408825 Vali Loss: 0.0506685 Test Loss: 0.0549180\n",
      "Validation loss decreased (0.050670 --> 0.050669).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0411821\n",
      "\tspeed: 0.0397s/iter; left time: 546.7866s\n",
      "\titers: 200, epoch: 39 | loss: 0.0366663\n",
      "\tspeed: 0.0173s/iter; left time: 236.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0409059 Vali Loss: 0.0507391 Test Loss: 0.0549399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0391978\n",
      "\tspeed: 0.0413s/iter; left time: 560.1932s\n",
      "\titers: 200, epoch: 40 | loss: 0.0425756\n",
      "\tspeed: 0.0195s/iter; left time: 263.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0409207 Vali Loss: 0.0506791 Test Loss: 0.0549067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416604\n",
      "\tspeed: 0.0367s/iter; left time: 489.4409s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402725\n",
      "\tspeed: 0.0173s/iter; left time: 228.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0408218 Vali Loss: 0.0507860 Test Loss: 0.0549271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0415616\n",
      "\tspeed: 0.0356s/iter; left time: 466.7670s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426821\n",
      "\tspeed: 0.0174s/iter; left time: 226.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0408661 Vali Loss: 0.0506999 Test Loss: 0.0549061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0412373\n",
      "\tspeed: 0.0362s/iter; left time: 466.9375s\n",
      "\titers: 200, epoch: 43 | loss: 0.0388965\n",
      "\tspeed: 0.0175s/iter; left time: 224.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408737 Vali Loss: 0.0507067 Test Loss: 0.0549184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0409356\n",
      "\tspeed: 0.0366s/iter; left time: 463.4980s\n",
      "\titers: 200, epoch: 44 | loss: 0.0419919\n",
      "\tspeed: 0.0175s/iter; left time: 220.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0407900 Vali Loss: 0.0507195 Test Loss: 0.0548893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0395876\n",
      "\tspeed: 0.0357s/iter; left time: 444.3419s\n",
      "\titers: 200, epoch: 45 | loss: 0.0424386\n",
      "\tspeed: 0.0176s/iter; left time: 217.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408467 Vali Loss: 0.0507040 Test Loss: 0.0548965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400761\n",
      "\tspeed: 0.0384s/iter; left time: 468.8836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0398946\n",
      "\tspeed: 0.0200s/iter; left time: 242.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0407960 Vali Loss: 0.0507497 Test Loss: 0.0548866\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393914\n",
      "\tspeed: 0.0370s/iter; left time: 443.4982s\n",
      "\titers: 200, epoch: 47 | loss: 0.0387283\n",
      "\tspeed: 0.0223s/iter; left time: 265.7545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408184 Vali Loss: 0.0507020 Test Loss: 0.0548986\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393765\n",
      "\tspeed: 0.0409s/iter; left time: 481.1759s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420225\n",
      "\tspeed: 0.0176s/iter; left time: 205.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0408080 Vali Loss: 0.0507258 Test Loss: 0.0548816\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010047451592981815, rmse:0.10023697465658188, mae:0.05491799861192703, rse:0.3867114782333374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0935595\n",
      "\tspeed: 0.0249s/iter; left time: 554.6922s\n",
      "\titers: 200, epoch: 1 | loss: 0.0815350\n",
      "\tspeed: 0.0238s/iter; left time: 529.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0985673 Vali Loss: 0.0815828 Test Loss: 0.0878835\n",
      "Validation loss decreased (inf --> 0.081583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0546182\n",
      "\tspeed: 0.0405s/iter; left time: 894.5638s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524375\n",
      "\tspeed: 0.0177s/iter; left time: 388.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0564773 Vali Loss: 0.0585265 Test Loss: 0.0620153\n",
      "Validation loss decreased (0.081583 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0516169\n",
      "\tspeed: 0.0405s/iter; left time: 883.9750s\n",
      "\titers: 200, epoch: 3 | loss: 0.0538712\n",
      "\tspeed: 0.0176s/iter; left time: 383.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0494922 Vali Loss: 0.0564595 Test Loss: 0.0600532\n",
      "Validation loss decreased (0.058526 --> 0.056460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0500758\n",
      "\tspeed: 0.0409s/iter; left time: 884.1769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0470287\n",
      "\tspeed: 0.0173s/iter; left time: 372.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0476510 Vali Loss: 0.0550841 Test Loss: 0.0591046\n",
      "Validation loss decreased (0.056460 --> 0.055084).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476657\n",
      "\tspeed: 0.0393s/iter; left time: 840.3386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0453900\n",
      "\tspeed: 0.0175s/iter; left time: 372.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0462703 Vali Loss: 0.0539240 Test Loss: 0.0578887\n",
      "Validation loss decreased (0.055084 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0436470\n",
      "\tspeed: 0.0385s/iter; left time: 815.6399s\n",
      "\titers: 200, epoch: 6 | loss: 0.0469544\n",
      "\tspeed: 0.0179s/iter; left time: 377.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0453504 Vali Loss: 0.0534992 Test Loss: 0.0576763\n",
      "Validation loss decreased (0.053924 --> 0.053499).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0498019\n",
      "\tspeed: 0.0372s/iter; left time: 780.1501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0435070\n",
      "\tspeed: 0.0173s/iter; left time: 361.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0447041 Vali Loss: 0.0528023 Test Loss: 0.0570895\n",
      "Validation loss decreased (0.053499 --> 0.052802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433632\n",
      "\tspeed: 0.0385s/iter; left time: 797.2715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472117\n",
      "\tspeed: 0.0184s/iter; left time: 380.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0442430 Vali Loss: 0.0525080 Test Loss: 0.0565417\n",
      "Validation loss decreased (0.052802 --> 0.052508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442935\n",
      "\tspeed: 0.0381s/iter; left time: 780.5073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439991\n",
      "\tspeed: 0.0181s/iter; left time: 369.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0437869 Vali Loss: 0.0521499 Test Loss: 0.0563267\n",
      "Validation loss decreased (0.052508 --> 0.052150).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457982\n",
      "\tspeed: 0.0375s/iter; left time: 761.0894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0451140\n",
      "\tspeed: 0.0175s/iter; left time: 354.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0434726 Vali Loss: 0.0523196 Test Loss: 0.0562200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0418626\n",
      "\tspeed: 0.0373s/iter; left time: 747.8968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0411332\n",
      "\tspeed: 0.0176s/iter; left time: 350.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0431422 Vali Loss: 0.0519555 Test Loss: 0.0562363\n",
      "Validation loss decreased (0.052150 --> 0.051955).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414568\n",
      "\tspeed: 0.0397s/iter; left time: 787.3697s\n",
      "\titers: 200, epoch: 12 | loss: 0.0442729\n",
      "\tspeed: 0.0185s/iter; left time: 365.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0429151 Vali Loss: 0.0517021 Test Loss: 0.0557212\n",
      "Validation loss decreased (0.051955 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0447191\n",
      "\tspeed: 0.0423s/iter; left time: 829.6593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0452590\n",
      "\tspeed: 0.0227s/iter; left time: 443.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0426312 Vali Loss: 0.0516790 Test Loss: 0.0557699\n",
      "Validation loss decreased (0.051702 --> 0.051679).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0460300\n",
      "\tspeed: 0.0378s/iter; left time: 732.2859s\n",
      "\titers: 200, epoch: 14 | loss: 0.0424465\n",
      "\tspeed: 0.0174s/iter; left time: 335.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0424535 Vali Loss: 0.0514955 Test Loss: 0.0555738\n",
      "Validation loss decreased (0.051679 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425895\n",
      "\tspeed: 0.0379s/iter; left time: 725.9930s\n",
      "\titers: 200, epoch: 15 | loss: 0.0400014\n",
      "\tspeed: 0.0199s/iter; left time: 379.4924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0422823 Vali Loss: 0.0517129 Test Loss: 0.0555978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0436068\n",
      "\tspeed: 0.0389s/iter; left time: 736.5599s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415642\n",
      "\tspeed: 0.0175s/iter; left time: 330.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0421010 Vali Loss: 0.0514501 Test Loss: 0.0553953\n",
      "Validation loss decreased (0.051495 --> 0.051450).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0403893\n",
      "\tspeed: 0.0378s/iter; left time: 707.0198s\n",
      "\titers: 200, epoch: 17 | loss: 0.0428705\n",
      "\tspeed: 0.0175s/iter; left time: 326.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0419437 Vali Loss: 0.0512283 Test Loss: 0.0553973\n",
      "Validation loss decreased (0.051450 --> 0.051228).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435594\n",
      "\tspeed: 0.0374s/iter; left time: 691.4029s\n",
      "\titers: 200, epoch: 18 | loss: 0.0430981\n",
      "\tspeed: 0.0176s/iter; left time: 323.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418711 Vali Loss: 0.0511208 Test Loss: 0.0552354\n",
      "Validation loss decreased (0.051228 --> 0.051121).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0425317\n",
      "\tspeed: 0.0388s/iter; left time: 708.5180s\n",
      "\titers: 200, epoch: 19 | loss: 0.0425620\n",
      "\tspeed: 0.0178s/iter; left time: 322.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0417220 Vali Loss: 0.0513766 Test Loss: 0.0552269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0389410\n",
      "\tspeed: 0.0386s/iter; left time: 696.3162s\n",
      "\titers: 200, epoch: 20 | loss: 0.0418354\n",
      "\tspeed: 0.0176s/iter; left time: 316.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0416325 Vali Loss: 0.0510026 Test Loss: 0.0550833\n",
      "Validation loss decreased (0.051121 --> 0.051003).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0438422\n",
      "\tspeed: 0.0370s/iter; left time: 659.7459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0418498\n",
      "\tspeed: 0.0176s/iter; left time: 311.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0415382 Vali Loss: 0.0509244 Test Loss: 0.0550689\n",
      "Validation loss decreased (0.051003 --> 0.050924).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414739\n",
      "\tspeed: 0.0399s/iter; left time: 701.7967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0414515\n",
      "\tspeed: 0.0176s/iter; left time: 307.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0414551 Vali Loss: 0.0509189 Test Loss: 0.0550239\n",
      "Validation loss decreased (0.050924 --> 0.050919).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412667\n",
      "\tspeed: 0.0418s/iter; left time: 726.3481s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385480\n",
      "\tspeed: 0.0183s/iter; left time: 316.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0414020 Vali Loss: 0.0509293 Test Loss: 0.0549526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404608\n",
      "\tspeed: 0.0433s/iter; left time: 742.8594s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383370\n",
      "\tspeed: 0.0182s/iter; left time: 310.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0413754 Vali Loss: 0.0509873 Test Loss: 0.0550544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0416779\n",
      "\tspeed: 0.0377s/iter; left time: 638.7238s\n",
      "\titers: 200, epoch: 25 | loss: 0.0415474\n",
      "\tspeed: 0.0176s/iter; left time: 295.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0412857 Vali Loss: 0.0509787 Test Loss: 0.0549485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0422339\n",
      "\tspeed: 0.0382s/iter; left time: 638.6748s\n",
      "\titers: 200, epoch: 26 | loss: 0.0430234\n",
      "\tspeed: 0.0173s/iter; left time: 287.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0412502 Vali Loss: 0.0510159 Test Loss: 0.0549871\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0391803\n",
      "\tspeed: 0.0425s/iter; left time: 699.8363s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413634\n",
      "\tspeed: 0.0215s/iter; left time: 351.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0412082 Vali Loss: 0.0509350 Test Loss: 0.0548990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0405897\n",
      "\tspeed: 0.0418s/iter; left time: 679.4927s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397338\n",
      "\tspeed: 0.0213s/iter; left time: 344.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0411314 Vali Loss: 0.0508925 Test Loss: 0.0549294\n",
      "Validation loss decreased (0.050919 --> 0.050893).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0437130\n",
      "\tspeed: 0.0387s/iter; left time: 619.6992s\n",
      "\titers: 200, epoch: 29 | loss: 0.0453305\n",
      "\tspeed: 0.0173s/iter; left time: 276.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0410808 Vali Loss: 0.0508684 Test Loss: 0.0549480\n",
      "Validation loss decreased (0.050893 --> 0.050868).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0404034\n",
      "\tspeed: 0.0374s/iter; left time: 591.2247s\n",
      "\titers: 200, epoch: 30 | loss: 0.0408411\n",
      "\tspeed: 0.0175s/iter; left time: 274.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0410524 Vali Loss: 0.0508277 Test Loss: 0.0548504\n",
      "Validation loss decreased (0.050868 --> 0.050828).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0427010\n",
      "\tspeed: 0.0380s/iter; left time: 592.4086s\n",
      "\titers: 200, epoch: 31 | loss: 0.0425292\n",
      "\tspeed: 0.0176s/iter; left time: 271.9788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0410449 Vali Loss: 0.0508885 Test Loss: 0.0548904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403372\n",
      "\tspeed: 0.0369s/iter; left time: 566.6934s\n",
      "\titers: 200, epoch: 32 | loss: 0.0405556\n",
      "\tspeed: 0.0175s/iter; left time: 266.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0410464 Vali Loss: 0.0508567 Test Loss: 0.0548694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0431220\n",
      "\tspeed: 0.0385s/iter; left time: 582.1933s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424416\n",
      "\tspeed: 0.0190s/iter; left time: 286.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0410148 Vali Loss: 0.0507454 Test Loss: 0.0548886\n",
      "Validation loss decreased (0.050828 --> 0.050745).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425253\n",
      "\tspeed: 0.0384s/iter; left time: 572.9638s\n",
      "\titers: 200, epoch: 34 | loss: 0.0445072\n",
      "\tspeed: 0.0176s/iter; left time: 260.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409694 Vali Loss: 0.0507921 Test Loss: 0.0548382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0386003\n",
      "\tspeed: 0.0386s/iter; left time: 567.2513s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397497\n",
      "\tspeed: 0.0178s/iter; left time: 259.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0409914 Vali Loss: 0.0507661 Test Loss: 0.0548480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0463726\n",
      "\tspeed: 0.0379s/iter; left time: 547.6972s\n",
      "\titers: 200, epoch: 36 | loss: 0.0397050\n",
      "\tspeed: 0.0176s/iter; left time: 252.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0409164 Vali Loss: 0.0508233 Test Loss: 0.0548441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0409133\n",
      "\tspeed: 0.0376s/iter; left time: 534.7156s\n",
      "\titers: 200, epoch: 37 | loss: 0.0423615\n",
      "\tspeed: 0.0175s/iter; left time: 247.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409337 Vali Loss: 0.0508035 Test Loss: 0.0548229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0406316\n",
      "\tspeed: 0.0387s/iter; left time: 542.5981s\n",
      "\titers: 200, epoch: 38 | loss: 0.0397512\n",
      "\tspeed: 0.0189s/iter; left time: 263.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0409042 Vali Loss: 0.0507964 Test Loss: 0.0548444\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0381033\n",
      "\tspeed: 0.0399s/iter; left time: 550.0490s\n",
      "\titers: 200, epoch: 39 | loss: 0.0382526\n",
      "\tspeed: 0.0173s/iter; left time: 236.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409219 Vali Loss: 0.0508203 Test Loss: 0.0548079\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0409601\n",
      "\tspeed: 0.0444s/iter; left time: 602.0461s\n",
      "\titers: 200, epoch: 40 | loss: 0.0414687\n",
      "\tspeed: 0.0204s/iter; left time: 274.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0408627 Vali Loss: 0.0507907 Test Loss: 0.0547983\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0436835\n",
      "\tspeed: 0.0442s/iter; left time: 590.2730s\n",
      "\titers: 200, epoch: 41 | loss: 0.0395844\n",
      "\tspeed: 0.0205s/iter; left time: 271.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0408995 Vali Loss: 0.0507025 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050745 --> 0.050702).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0397279\n",
      "\tspeed: 0.0438s/iter; left time: 574.0071s\n",
      "\titers: 200, epoch: 42 | loss: 0.0432200\n",
      "\tspeed: 0.0203s/iter; left time: 264.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408592 Vali Loss: 0.0507363 Test Loss: 0.0547963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0390139\n",
      "\tspeed: 0.0385s/iter; left time: 496.0208s\n",
      "\titers: 200, epoch: 43 | loss: 0.0416165\n",
      "\tspeed: 0.0176s/iter; left time: 225.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0409098 Vali Loss: 0.0507644 Test Loss: 0.0547888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0394929\n",
      "\tspeed: 0.0378s/iter; left time: 478.8054s\n",
      "\titers: 200, epoch: 44 | loss: 0.0391143\n",
      "\tspeed: 0.0177s/iter; left time: 222.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0408876 Vali Loss: 0.0507556 Test Loss: 0.0547861\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0385056\n",
      "\tspeed: 0.0373s/iter; left time: 463.8164s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418280\n",
      "\tspeed: 0.0176s/iter; left time: 216.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0408062 Vali Loss: 0.0506480 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050702 --> 0.050648).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0404662\n",
      "\tspeed: 0.0407s/iter; left time: 496.9452s\n",
      "\titers: 200, epoch: 46 | loss: 0.0425981\n",
      "\tspeed: 0.0212s/iter; left time: 257.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0408597 Vali Loss: 0.0507410 Test Loss: 0.0547948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0412951\n",
      "\tspeed: 0.0371s/iter; left time: 445.5673s\n",
      "\titers: 200, epoch: 47 | loss: 0.0460205\n",
      "\tspeed: 0.0176s/iter; left time: 209.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0408051 Vali Loss: 0.0507380 Test Loss: 0.0547790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0396187\n",
      "\tspeed: 0.0385s/iter; left time: 453.1386s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420261\n",
      "\tspeed: 0.0177s/iter; left time: 206.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0408679 Vali Loss: 0.0508199 Test Loss: 0.0547630\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0402250\n",
      "\tspeed: 0.0394s/iter; left time: 455.5809s\n",
      "\titers: 200, epoch: 49 | loss: 0.0436193\n",
      "\tspeed: 0.0194s/iter; left time: 222.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0408469 Vali Loss: 0.0507091 Test Loss: 0.0547697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0362207\n",
      "\tspeed: 0.0371s/iter; left time: 420.3064s\n",
      "\titers: 200, epoch: 50 | loss: 0.0385387\n",
      "\tspeed: 0.0175s/iter; left time: 196.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408548 Vali Loss: 0.0506502 Test Loss: 0.0547767\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440735\n",
      "\tspeed: 0.0385s/iter; left time: 427.6925s\n",
      "\titers: 200, epoch: 51 | loss: 0.0387501\n",
      "\tspeed: 0.0181s/iter; left time: 199.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0408112 Vali Loss: 0.0507077 Test Loss: 0.0547609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0404372\n",
      "\tspeed: 0.0432s/iter; left time: 470.1337s\n",
      "\titers: 200, epoch: 52 | loss: 0.0423694\n",
      "\tspeed: 0.0177s/iter; left time: 190.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408257 Vali Loss: 0.0507446 Test Loss: 0.0547665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0421164\n",
      "\tspeed: 0.0409s/iter; left time: 435.6301s\n",
      "\titers: 200, epoch: 53 | loss: 0.0415824\n",
      "\tspeed: 0.0186s/iter; left time: 196.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0408422 Vali Loss: 0.0507633 Test Loss: 0.0547696\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0443786\n",
      "\tspeed: 0.0368s/iter; left time: 383.9620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0391313\n",
      "\tspeed: 0.0175s/iter; left time: 181.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408320 Vali Loss: 0.0507100 Test Loss: 0.0547600\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0417649\n",
      "\tspeed: 0.0400s/iter; left time: 408.2279s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409617\n",
      "\tspeed: 0.0212s/iter; left time: 214.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408236 Vali Loss: 0.0506238 Test Loss: 0.0547631\n",
      "Validation loss decreased (0.050648 --> 0.050624).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0360162\n",
      "\tspeed: 0.0393s/iter; left time: 392.0179s\n",
      "\titers: 200, epoch: 56 | loss: 0.0408644\n",
      "\tspeed: 0.0177s/iter; left time: 174.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0407994 Vali Loss: 0.0507128 Test Loss: 0.0547610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0406955\n",
      "\tspeed: 0.0369s/iter; left time: 359.5597s\n",
      "\titers: 200, epoch: 57 | loss: 0.0420306\n",
      "\tspeed: 0.0176s/iter; left time: 170.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408128 Vali Loss: 0.0507455 Test Loss: 0.0547706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0457876\n",
      "\tspeed: 0.0364s/iter; left time: 346.5785s\n",
      "\titers: 200, epoch: 58 | loss: 0.0406639\n",
      "\tspeed: 0.0176s/iter; left time: 166.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0408230 Vali Loss: 0.0506479 Test Loss: 0.0547651\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0408023\n",
      "\tspeed: 0.0401s/iter; left time: 373.1203s\n",
      "\titers: 200, epoch: 59 | loss: 0.0427719\n",
      "\tspeed: 0.0178s/iter; left time: 163.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0407709 Vali Loss: 0.0507367 Test Loss: 0.0547671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0425067\n",
      "\tspeed: 0.0369s/iter; left time: 335.6411s\n",
      "\titers: 200, epoch: 60 | loss: 0.0396171\n",
      "\tspeed: 0.0190s/iter; left time: 170.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0408547 Vali Loss: 0.0507473 Test Loss: 0.0547641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0417092\n",
      "\tspeed: 0.0435s/iter; left time: 385.4814s\n",
      "\titers: 200, epoch: 61 | loss: 0.0407552\n",
      "\tspeed: 0.0225s/iter; left time: 196.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0408172 Vali Loss: 0.0507417 Test Loss: 0.0547586\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394446\n",
      "\tspeed: 0.0441s/iter; left time: 380.7387s\n",
      "\titers: 200, epoch: 62 | loss: 0.0394354\n",
      "\tspeed: 0.0205s/iter; left time: 174.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408144 Vali Loss: 0.0506968 Test Loss: 0.0547682\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0409796\n",
      "\tspeed: 0.0377s/iter; left time: 316.9350s\n",
      "\titers: 200, epoch: 63 | loss: 0.0429062\n",
      "\tspeed: 0.0180s/iter; left time: 149.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408127 Vali Loss: 0.0507607 Test Loss: 0.0547640\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0448329\n",
      "\tspeed: 0.0409s/iter; left time: 334.5994s\n",
      "\titers: 200, epoch: 64 | loss: 0.0424715\n",
      "\tspeed: 0.0195s/iter; left time: 157.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408103 Vali Loss: 0.0507010 Test Loss: 0.0547563\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0428965\n",
      "\tspeed: 0.0388s/iter; left time: 309.0573s\n",
      "\titers: 200, epoch: 65 | loss: 0.0406603\n",
      "\tspeed: 0.0200s/iter; left time: 156.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0407825 Vali Loss: 0.0506624 Test Loss: 0.0547556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009938369505107403, rmse:0.09969136863946915, mae:0.05476314201951027, rse:0.3846065402030945\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:01.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0980609\n",
      "\tspeed: 0.0442s/iter; left time: 986.0843s\n",
      "\titers: 200, epoch: 1 | loss: 0.0871001\n",
      "\tspeed: 0.0176s/iter; left time: 391.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1031007 Vali Loss: 0.0901211 Test Loss: 0.0987843\n",
      "Validation loss decreased (inf --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744202\n",
      "\tspeed: 0.0399s/iter; left time: 880.2678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0627046\n",
      "\tspeed: 0.0176s/iter; left time: 387.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0707878 Vali Loss: 0.0750685 Test Loss: 0.0840957\n",
      "Validation loss decreased (0.090121 --> 0.075069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646639\n",
      "\tspeed: 0.0380s/iter; left time: 829.7925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631343\n",
      "\tspeed: 0.0185s/iter; left time: 403.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0642391 Vali Loss: 0.0723593 Test Loss: 0.0822695\n",
      "Validation loss decreased (0.075069 --> 0.072359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610678\n",
      "\tspeed: 0.0388s/iter; left time: 838.9979s\n",
      "\titers: 200, epoch: 4 | loss: 0.0642769\n",
      "\tspeed: 0.0196s/iter; left time: 421.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0623806 Vali Loss: 0.0713594 Test Loss: 0.0812874\n",
      "Validation loss decreased (0.072359 --> 0.071359).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621786\n",
      "\tspeed: 0.0390s/iter; left time: 835.2215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588774\n",
      "\tspeed: 0.0199s/iter; left time: 424.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0612256 Vali Loss: 0.0713809 Test Loss: 0.0812414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647122\n",
      "\tspeed: 0.0367s/iter; left time: 776.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587326\n",
      "\tspeed: 0.0176s/iter; left time: 371.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0604238 Vali Loss: 0.0708679 Test Loss: 0.0803343\n",
      "Validation loss decreased (0.071359 --> 0.070868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0619604\n",
      "\tspeed: 0.0379s/iter; left time: 793.8591s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573329\n",
      "\tspeed: 0.0176s/iter; left time: 367.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0597714 Vali Loss: 0.0706334 Test Loss: 0.0803544\n",
      "Validation loss decreased (0.070868 --> 0.070633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0618974\n",
      "\tspeed: 0.0390s/iter; left time: 809.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577334\n",
      "\tspeed: 0.0230s/iter; left time: 475.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0593515 Vali Loss: 0.0705784 Test Loss: 0.0799828\n",
      "Validation loss decreased (0.070633 --> 0.070578).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578773\n",
      "\tspeed: 0.0423s/iter; left time: 866.8690s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587067\n",
      "\tspeed: 0.0201s/iter; left time: 411.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0589615 Vali Loss: 0.0703924 Test Loss: 0.0804243\n",
      "Validation loss decreased (0.070578 --> 0.070392).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590116\n",
      "\tspeed: 0.0401s/iter; left time: 813.8909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0577656\n",
      "\tspeed: 0.0204s/iter; left time: 410.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0585875 Vali Loss: 0.0701964 Test Loss: 0.0800692\n",
      "Validation loss decreased (0.070392 --> 0.070196).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595273\n",
      "\tspeed: 0.0388s/iter; left time: 777.9013s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568395\n",
      "\tspeed: 0.0190s/iter; left time: 379.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0582978 Vali Loss: 0.0700665 Test Loss: 0.0801848\n",
      "Validation loss decreased (0.070196 --> 0.070066).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0578398\n",
      "\tspeed: 0.0400s/iter; left time: 792.9082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565718\n",
      "\tspeed: 0.0179s/iter; left time: 352.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0580421 Vali Loss: 0.0702680 Test Loss: 0.0803339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582126\n",
      "\tspeed: 0.0399s/iter; left time: 783.3161s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575784\n",
      "\tspeed: 0.0212s/iter; left time: 414.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0577998 Vali Loss: 0.0704259 Test Loss: 0.0806946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0567649\n",
      "\tspeed: 0.0372s/iter; left time: 721.7618s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573596\n",
      "\tspeed: 0.0178s/iter; left time: 342.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0575422 Vali Loss: 0.0701961 Test Loss: 0.0797991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537720\n",
      "\tspeed: 0.0373s/iter; left time: 714.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.0601896\n",
      "\tspeed: 0.0177s/iter; left time: 338.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0573678 Vali Loss: 0.0700427 Test Loss: 0.0800929\n",
      "Validation loss decreased (0.070066 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578917\n",
      "\tspeed: 0.0399s/iter; left time: 756.3327s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594120\n",
      "\tspeed: 0.0189s/iter; left time: 355.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0571036 Vali Loss: 0.0701092 Test Loss: 0.0802814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0561508\n",
      "\tspeed: 0.0362s/iter; left time: 677.5379s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588087\n",
      "\tspeed: 0.0178s/iter; left time: 330.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0697514 Test Loss: 0.0801798\n",
      "Validation loss decreased (0.070043 --> 0.069751).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570127\n",
      "\tspeed: 0.0401s/iter; left time: 741.0149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0550547\n",
      "\tspeed: 0.0204s/iter; left time: 374.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0568377 Vali Loss: 0.0700514 Test Loss: 0.0800432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0599390\n",
      "\tspeed: 0.0424s/iter; left time: 773.9867s\n",
      "\titers: 200, epoch: 19 | loss: 0.0592506\n",
      "\tspeed: 0.0201s/iter; left time: 365.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0566340 Vali Loss: 0.0700143 Test Loss: 0.0800947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0555497\n",
      "\tspeed: 0.0402s/iter; left time: 725.6980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594845\n",
      "\tspeed: 0.0177s/iter; left time: 317.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0565479 Vali Loss: 0.0699431 Test Loss: 0.0799722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0595895\n",
      "\tspeed: 0.0426s/iter; left time: 758.6109s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514547\n",
      "\tspeed: 0.0180s/iter; left time: 319.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0564134 Vali Loss: 0.0699077 Test Loss: 0.0799024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0577438\n",
      "\tspeed: 0.0406s/iter; left time: 713.9933s\n",
      "\titers: 200, epoch: 22 | loss: 0.0570781\n",
      "\tspeed: 0.0180s/iter; left time: 315.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0562344 Vali Loss: 0.0699412 Test Loss: 0.0799161\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543055\n",
      "\tspeed: 0.0374s/iter; left time: 650.0469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0568372\n",
      "\tspeed: 0.0178s/iter; left time: 307.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0561991 Vali Loss: 0.0698163 Test Loss: 0.0800117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0562022\n",
      "\tspeed: 0.0401s/iter; left time: 687.3905s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531656\n",
      "\tspeed: 0.0196s/iter; left time: 334.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560687 Vali Loss: 0.0699291 Test Loss: 0.0799469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552870\n",
      "\tspeed: 0.0384s/iter; left time: 650.0462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552926\n",
      "\tspeed: 0.0192s/iter; left time: 322.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0560483 Vali Loss: 0.0698628 Test Loss: 0.0803341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0539591\n",
      "\tspeed: 0.0398s/iter; left time: 663.8899s\n",
      "\titers: 200, epoch: 26 | loss: 0.0611918\n",
      "\tspeed: 0.0195s/iter; left time: 323.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0559247 Vali Loss: 0.0697493 Test Loss: 0.0802485\n",
      "Validation loss decreased (0.069751 --> 0.069749).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0552940\n",
      "\tspeed: 0.0390s/iter; left time: 643.2036s\n",
      "\titers: 200, epoch: 27 | loss: 0.0568207\n",
      "\tspeed: 0.0177s/iter; left time: 290.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0558538 Vali Loss: 0.0698645 Test Loss: 0.0802962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553827\n",
      "\tspeed: 0.0366s/iter; left time: 595.1012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0563543\n",
      "\tspeed: 0.0176s/iter; left time: 283.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0558139 Vali Loss: 0.0699737 Test Loss: 0.0799117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0549611\n",
      "\tspeed: 0.0382s/iter; left time: 612.8983s\n",
      "\titers: 200, epoch: 29 | loss: 0.0588496\n",
      "\tspeed: 0.0220s/iter; left time: 350.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0557804 Vali Loss: 0.0698076 Test Loss: 0.0803077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0569736\n",
      "\tspeed: 0.0406s/iter; left time: 642.2532s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523944\n",
      "\tspeed: 0.0191s/iter; left time: 300.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0556698 Vali Loss: 0.0699552 Test Loss: 0.0799103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0591903\n",
      "\tspeed: 0.0438s/iter; left time: 682.9421s\n",
      "\titers: 200, epoch: 31 | loss: 0.0563744\n",
      "\tspeed: 0.0195s/iter; left time: 302.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0557028 Vali Loss: 0.0698280 Test Loss: 0.0799427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0564075\n",
      "\tspeed: 0.0367s/iter; left time: 563.8824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564259\n",
      "\tspeed: 0.0178s/iter; left time: 271.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0556475 Vali Loss: 0.0699557 Test Loss: 0.0800001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0571123\n",
      "\tspeed: 0.0371s/iter; left time: 561.7987s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562876\n",
      "\tspeed: 0.0178s/iter; left time: 267.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0555754 Vali Loss: 0.0698408 Test Loss: 0.0799727\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0549147\n",
      "\tspeed: 0.0368s/iter; left time: 549.0334s\n",
      "\titers: 200, epoch: 34 | loss: 0.0569688\n",
      "\tspeed: 0.0176s/iter; left time: 260.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0555628 Vali Loss: 0.0698081 Test Loss: 0.0801774\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539672\n",
      "\tspeed: 0.0394s/iter; left time: 577.9793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0568721\n",
      "\tspeed: 0.0178s/iter; left time: 259.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0555678 Vali Loss: 0.0698511 Test Loss: 0.0800220\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0555374\n",
      "\tspeed: 0.0413s/iter; left time: 596.6173s\n",
      "\titers: 200, epoch: 36 | loss: 0.0540787\n",
      "\tspeed: 0.0202s/iter; left time: 289.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0554807 Vali Loss: 0.0698264 Test Loss: 0.0801089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019129442051053047, rmse:0.13830922544002533, mae:0.08024851232767105, rse:0.5350168347358704\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0993653\n",
      "\tspeed: 0.0221s/iter; left time: 493.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925130\n",
      "\tspeed: 0.0200s/iter; left time: 443.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1028261 Vali Loss: 0.0896393 Test Loss: 0.0984749\n",
      "Validation loss decreased (inf --> 0.089639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0716707\n",
      "\tspeed: 0.0402s/iter; left time: 888.0405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649474\n",
      "\tspeed: 0.0206s/iter; left time: 452.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0706721 Vali Loss: 0.0753703 Test Loss: 0.0839644\n",
      "Validation loss decreased (0.089639 --> 0.075370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619266\n",
      "\tspeed: 0.0440s/iter; left time: 960.5970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0610446\n",
      "\tspeed: 0.0202s/iter; left time: 438.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0645758 Vali Loss: 0.0726078 Test Loss: 0.0825484\n",
      "Validation loss decreased (0.075370 --> 0.072608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586112\n",
      "\tspeed: 0.0396s/iter; left time: 856.5662s\n",
      "\titers: 200, epoch: 4 | loss: 0.0566655\n",
      "\tspeed: 0.0199s/iter; left time: 429.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0626355 Vali Loss: 0.0717694 Test Loss: 0.0815929\n",
      "Validation loss decreased (0.072608 --> 0.071769).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629928\n",
      "\tspeed: 0.0434s/iter; left time: 928.5031s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631500\n",
      "\tspeed: 0.0198s/iter; left time: 421.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0614584 Vali Loss: 0.0710907 Test Loss: 0.0806131\n",
      "Validation loss decreased (0.071769 --> 0.071091).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608282\n",
      "\tspeed: 0.0438s/iter; left time: 928.3181s\n",
      "\titers: 200, epoch: 6 | loss: 0.0621219\n",
      "\tspeed: 0.0202s/iter; left time: 425.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0605699 Vali Loss: 0.0708390 Test Loss: 0.0803163\n",
      "Validation loss decreased (0.071091 --> 0.070839).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0545628\n",
      "\tspeed: 0.0392s/iter; left time: 820.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0180s/iter; left time: 375.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0599846 Vali Loss: 0.0707349 Test Loss: 0.0810065\n",
      "Validation loss decreased (0.070839 --> 0.070735).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596696\n",
      "\tspeed: 0.0429s/iter; left time: 889.9808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551469\n",
      "\tspeed: 0.0199s/iter; left time: 409.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0594251 Vali Loss: 0.0704187 Test Loss: 0.0808286\n",
      "Validation loss decreased (0.070735 --> 0.070419).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0601396\n",
      "\tspeed: 0.0434s/iter; left time: 889.6753s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632646\n",
      "\tspeed: 0.0244s/iter; left time: 497.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0589964 Vali Loss: 0.0704514 Test Loss: 0.0805737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0605195\n",
      "\tspeed: 0.0416s/iter; left time: 844.5786s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591787\n",
      "\tspeed: 0.0232s/iter; left time: 467.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0585768 Vali Loss: 0.0702656 Test Loss: 0.0809564\n",
      "Validation loss decreased (0.070419 --> 0.070266).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585001\n",
      "\tspeed: 0.0410s/iter; left time: 822.7208s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562668\n",
      "\tspeed: 0.0186s/iter; left time: 371.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0582614 Vali Loss: 0.0702181 Test Loss: 0.0812004\n",
      "Validation loss decreased (0.070266 --> 0.070218).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0563077\n",
      "\tspeed: 0.0414s/iter; left time: 821.1961s\n",
      "\titers: 200, epoch: 12 | loss: 0.0616315\n",
      "\tspeed: 0.0200s/iter; left time: 395.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0579842 Vali Loss: 0.0700841 Test Loss: 0.0812889\n",
      "Validation loss decreased (0.070218 --> 0.070084).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0610500\n",
      "\tspeed: 0.0430s/iter; left time: 843.5268s\n",
      "\titers: 200, epoch: 13 | loss: 0.0572273\n",
      "\tspeed: 0.0196s/iter; left time: 381.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0576614 Vali Loss: 0.0702207 Test Loss: 0.0815973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575464\n",
      "\tspeed: 0.0443s/iter; left time: 859.2950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597506\n",
      "\tspeed: 0.0186s/iter; left time: 359.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0574103 Vali Loss: 0.0701746 Test Loss: 0.0815515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0539393\n",
      "\tspeed: 0.0410s/iter; left time: 785.1048s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575244\n",
      "\tspeed: 0.0180s/iter; left time: 343.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0571507 Vali Loss: 0.0700377 Test Loss: 0.0809218\n",
      "Validation loss decreased (0.070084 --> 0.070038).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0552823\n",
      "\tspeed: 0.0431s/iter; left time: 816.5003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567672\n",
      "\tspeed: 0.0242s/iter; left time: 456.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0569635 Vali Loss: 0.0699133 Test Loss: 0.0814106\n",
      "Validation loss decreased (0.070038 --> 0.069913).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533414\n",
      "\tspeed: 0.0426s/iter; left time: 796.9191s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565612\n",
      "\tspeed: 0.0203s/iter; left time: 377.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0567306 Vali Loss: 0.0700455 Test Loss: 0.0815984\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608345\n",
      "\tspeed: 0.0403s/iter; left time: 745.6117s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592519\n",
      "\tspeed: 0.0183s/iter; left time: 335.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0566090 Vali Loss: 0.0699562 Test Loss: 0.0814214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0590397\n",
      "\tspeed: 0.0403s/iter; left time: 735.9679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541783\n",
      "\tspeed: 0.0202s/iter; left time: 367.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0564276 Vali Loss: 0.0701004 Test Loss: 0.0813950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572432\n",
      "\tspeed: 0.0412s/iter; left time: 742.9460s\n",
      "\titers: 200, epoch: 20 | loss: 0.0551385\n",
      "\tspeed: 0.0200s/iter; left time: 358.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0562702 Vali Loss: 0.0701160 Test Loss: 0.0818849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536732\n",
      "\tspeed: 0.0392s/iter; left time: 698.7143s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556528\n",
      "\tspeed: 0.0213s/iter; left time: 378.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0561357 Vali Loss: 0.0701280 Test Loss: 0.0817430\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0569166\n",
      "\tspeed: 0.0418s/iter; left time: 734.7146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534606\n",
      "\tspeed: 0.0236s/iter; left time: 413.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0559808 Vali Loss: 0.0702114 Test Loss: 0.0819262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0560534\n",
      "\tspeed: 0.0420s/iter; left time: 729.4056s\n",
      "\titers: 200, epoch: 23 | loss: 0.0574485\n",
      "\tspeed: 0.0224s/iter; left time: 386.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0559322 Vali Loss: 0.0700866 Test Loss: 0.0819694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0585243\n",
      "\tspeed: 0.0422s/iter; left time: 724.4744s\n",
      "\titers: 200, epoch: 24 | loss: 0.0549269\n",
      "\tspeed: 0.0235s/iter; left time: 400.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0557595 Vali Loss: 0.0701298 Test Loss: 0.0818227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0532516\n",
      "\tspeed: 0.0463s/iter; left time: 783.6475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0586018\n",
      "\tspeed: 0.0249s/iter; left time: 419.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0557496 Vali Loss: 0.0702347 Test Loss: 0.0820146\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552508\n",
      "\tspeed: 0.0463s/iter; left time: 772.7935s\n",
      "\titers: 200, epoch: 26 | loss: 0.0518143\n",
      "\tspeed: 0.0206s/iter; left time: 342.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0555888 Vali Loss: 0.0702477 Test Loss: 0.0821850\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019507648423314095, rmse:0.13966979086399078, mae:0.08141053467988968, rse:0.5402798652648926\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:24.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1048215\n",
      "\tspeed: 0.0448s/iter; left time: 993.6942s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905720\n",
      "\tspeed: 0.0178s/iter; left time: 393.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.1048050 Vali Loss: 0.0926501 Test Loss: 0.1004419\n",
      "Validation loss decreased (inf --> 0.092650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0787801\n",
      "\tspeed: 0.0392s/iter; left time: 860.8228s\n",
      "\titers: 200, epoch: 2 | loss: 0.0704006\n",
      "\tspeed: 0.0178s/iter; left time: 390.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0745573 Vali Loss: 0.0786099 Test Loss: 0.0878751\n",
      "Validation loss decreased (0.092650 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726460\n",
      "\tspeed: 0.0391s/iter; left time: 849.8043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645619\n",
      "\tspeed: 0.0178s/iter; left time: 386.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0679619 Vali Loss: 0.0757840 Test Loss: 0.0871083\n",
      "Validation loss decreased (0.078610 --> 0.075784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659405\n",
      "\tspeed: 0.0392s/iter; left time: 844.1832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0691877\n",
      "\tspeed: 0.0180s/iter; left time: 385.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0661932 Vali Loss: 0.0753940 Test Loss: 0.0867535\n",
      "Validation loss decreased (0.075784 --> 0.075394).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0673685\n",
      "\tspeed: 0.0386s/iter; left time: 823.0725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653306\n",
      "\tspeed: 0.0184s/iter; left time: 390.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0651771 Vali Loss: 0.0749387 Test Loss: 0.0866767\n",
      "Validation loss decreased (0.075394 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0621401\n",
      "\tspeed: 0.0391s/iter; left time: 825.2142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653071\n",
      "\tspeed: 0.0183s/iter; left time: 385.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0644035 Vali Loss: 0.0745415 Test Loss: 0.0861986\n",
      "Validation loss decreased (0.074939 --> 0.074541).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0668753\n",
      "\tspeed: 0.0396s/iter; left time: 826.2922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647811\n",
      "\tspeed: 0.0181s/iter; left time: 376.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0638201 Vali Loss: 0.0746210 Test Loss: 0.0858707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0590196\n",
      "\tspeed: 0.0405s/iter; left time: 835.0479s\n",
      "\titers: 200, epoch: 8 | loss: 0.0675284\n",
      "\tspeed: 0.0182s/iter; left time: 374.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0633939 Vali Loss: 0.0744509 Test Loss: 0.0864062\n",
      "Validation loss decreased (0.074541 --> 0.074451).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666170\n",
      "\tspeed: 0.0394s/iter; left time: 805.2458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584317\n",
      "\tspeed: 0.0178s/iter; left time: 360.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0629750 Vali Loss: 0.0741344 Test Loss: 0.0858306\n",
      "Validation loss decreased (0.074451 --> 0.074134).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615673\n",
      "\tspeed: 0.0384s/iter; left time: 775.9894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0612158\n",
      "\tspeed: 0.0178s/iter; left time: 357.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0626131 Vali Loss: 0.0743963 Test Loss: 0.0868935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669771\n",
      "\tspeed: 0.0389s/iter; left time: 776.3254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0583333\n",
      "\tspeed: 0.0182s/iter; left time: 360.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0622680 Vali Loss: 0.0740912 Test Loss: 0.0864191\n",
      "Validation loss decreased (0.074134 --> 0.074091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0600857\n",
      "\tspeed: 0.0398s/iter; left time: 785.8133s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624289\n",
      "\tspeed: 0.0182s/iter; left time: 357.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0620072 Vali Loss: 0.0738088 Test Loss: 0.0868813\n",
      "Validation loss decreased (0.074091 --> 0.073809).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0633508\n",
      "\tspeed: 0.0382s/iter; left time: 746.2036s\n",
      "\titers: 200, epoch: 13 | loss: 0.0622426\n",
      "\tspeed: 0.0177s/iter; left time: 344.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0617034 Vali Loss: 0.0738194 Test Loss: 0.0859601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0624652\n",
      "\tspeed: 0.0432s/iter; left time: 833.1308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0640134\n",
      "\tspeed: 0.0223s/iter; left time: 428.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0614224 Vali Loss: 0.0735637 Test Loss: 0.0866766\n",
      "Validation loss decreased (0.073809 --> 0.073564).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0592811\n",
      "\tspeed: 0.0412s/iter; left time: 786.3647s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659775\n",
      "\tspeed: 0.0198s/iter; left time: 375.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0612476 Vali Loss: 0.0735167 Test Loss: 0.0868006\n",
      "Validation loss decreased (0.073564 --> 0.073517).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0644561\n",
      "\tspeed: 0.0412s/iter; left time: 777.3279s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619274\n",
      "\tspeed: 0.0179s/iter; left time: 336.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0610197 Vali Loss: 0.0734734 Test Loss: 0.0862646\n",
      "Validation loss decreased (0.073517 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604587\n",
      "\tspeed: 0.0385s/iter; left time: 717.5171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619207\n",
      "\tspeed: 0.0182s/iter; left time: 337.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0608512 Vali Loss: 0.0734382 Test Loss: 0.0864064\n",
      "Validation loss decreased (0.073473 --> 0.073438).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621410\n",
      "\tspeed: 0.0444s/iter; left time: 816.7679s\n",
      "\titers: 200, epoch: 18 | loss: 0.0610293\n",
      "\tspeed: 0.0209s/iter; left time: 382.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0606406 Vali Loss: 0.0735055 Test Loss: 0.0865836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0594858\n",
      "\tspeed: 0.0395s/iter; left time: 717.9466s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603400\n",
      "\tspeed: 0.0225s/iter; left time: 407.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0604943 Vali Loss: 0.0733934 Test Loss: 0.0866218\n",
      "Validation loss decreased (0.073438 --> 0.073393).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621189\n",
      "\tspeed: 0.0405s/iter; left time: 726.9494s\n",
      "\titers: 200, epoch: 20 | loss: 0.0579614\n",
      "\tspeed: 0.0179s/iter; left time: 320.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0603450 Vali Loss: 0.0734274 Test Loss: 0.0866431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0576071\n",
      "\tspeed: 0.0397s/iter; left time: 705.1230s\n",
      "\titers: 200, epoch: 21 | loss: 0.0587716\n",
      "\tspeed: 0.0182s/iter; left time: 320.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0602134 Vali Loss: 0.0735609 Test Loss: 0.0867124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0592390\n",
      "\tspeed: 0.0411s/iter; left time: 719.6329s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672747\n",
      "\tspeed: 0.0205s/iter; left time: 357.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0601358 Vali Loss: 0.0734848 Test Loss: 0.0864877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0589457\n",
      "\tspeed: 0.0420s/iter; left time: 727.1040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600802\n",
      "\tspeed: 0.0195s/iter; left time: 334.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0600169 Vali Loss: 0.0735971 Test Loss: 0.0867336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0622105\n",
      "\tspeed: 0.0390s/iter; left time: 665.8311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0587972\n",
      "\tspeed: 0.0185s/iter; left time: 314.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0599399 Vali Loss: 0.0733272 Test Loss: 0.0868346\n",
      "Validation loss decreased (0.073393 --> 0.073327).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0618487\n",
      "\tspeed: 0.0408s/iter; left time: 686.9191s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623286\n",
      "\tspeed: 0.0199s/iter; left time: 332.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0598832 Vali Loss: 0.0733698 Test Loss: 0.0870481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628185\n",
      "\tspeed: 0.0403s/iter; left time: 669.1997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600777\n",
      "\tspeed: 0.0178s/iter; left time: 294.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0597476 Vali Loss: 0.0735480 Test Loss: 0.0870731\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584035\n",
      "\tspeed: 0.0386s/iter; left time: 633.3759s\n",
      "\titers: 200, epoch: 27 | loss: 0.0596758\n",
      "\tspeed: 0.0178s/iter; left time: 290.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0597152 Vali Loss: 0.0735673 Test Loss: 0.0869513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0575937\n",
      "\tspeed: 0.0411s/iter; left time: 664.7704s\n",
      "\titers: 200, epoch: 28 | loss: 0.0598191\n",
      "\tspeed: 0.0194s/iter; left time: 311.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0596151 Vali Loss: 0.0735890 Test Loss: 0.0869191\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602850\n",
      "\tspeed: 0.0385s/iter; left time: 614.2782s\n",
      "\titers: 200, epoch: 29 | loss: 0.0603580\n",
      "\tspeed: 0.0199s/iter; left time: 315.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0595701 Vali Loss: 0.0735271 Test Loss: 0.0868389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0609483\n",
      "\tspeed: 0.0398s/iter; left time: 625.4291s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605431\n",
      "\tspeed: 0.0178s/iter; left time: 277.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0595073 Vali Loss: 0.0735774 Test Loss: 0.0868500\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565855\n",
      "\tspeed: 0.0380s/iter; left time: 588.8619s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568368\n",
      "\tspeed: 0.0178s/iter; left time: 273.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0594662 Vali Loss: 0.0736190 Test Loss: 0.0867959\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585387\n",
      "\tspeed: 0.0384s/iter; left time: 586.9124s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621870\n",
      "\tspeed: 0.0179s/iter; left time: 271.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0594207 Vali Loss: 0.0734954 Test Loss: 0.0867695\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0560987\n",
      "\tspeed: 0.0403s/iter; left time: 607.2936s\n",
      "\titers: 200, epoch: 33 | loss: 0.0594956\n",
      "\tspeed: 0.0179s/iter; left time: 267.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0594061 Vali Loss: 0.0736040 Test Loss: 0.0867877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592257\n",
      "\tspeed: 0.0398s/iter; left time: 590.9892s\n",
      "\titers: 200, epoch: 34 | loss: 0.0612799\n",
      "\tspeed: 0.0178s/iter; left time: 262.3133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0593490 Vali Loss: 0.0734889 Test Loss: 0.0869637\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021609371528029442, rmse:0.1470012664794922, mae:0.08683455735445023, rse:0.5693498253822327\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1029223\n",
      "\tspeed: 0.0243s/iter; left time: 539.9811s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873014\n",
      "\tspeed: 0.0203s/iter; left time: 449.2947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.1060672 Vali Loss: 0.0924755 Test Loss: 0.1004355\n",
      "Validation loss decreased (inf --> 0.092476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753753\n",
      "\tspeed: 0.0444s/iter; left time: 975.9962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723152\n",
      "\tspeed: 0.0240s/iter; left time: 525.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0746971 Vali Loss: 0.0789733 Test Loss: 0.0883853\n",
      "Validation loss decreased (0.092476 --> 0.078973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749349\n",
      "\tspeed: 0.0390s/iter; left time: 849.2280s\n",
      "\titers: 200, epoch: 3 | loss: 0.0635487\n",
      "\tspeed: 0.0181s/iter; left time: 391.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0682782 Vali Loss: 0.0764451 Test Loss: 0.0874010\n",
      "Validation loss decreased (0.078973 --> 0.076445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650547\n",
      "\tspeed: 0.0431s/iter; left time: 927.6328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0675071\n",
      "\tspeed: 0.0189s/iter; left time: 404.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0665174 Vali Loss: 0.0751456 Test Loss: 0.0865133\n",
      "Validation loss decreased (0.076445 --> 0.075146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633389\n",
      "\tspeed: 0.0399s/iter; left time: 850.2645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628508\n",
      "\tspeed: 0.0180s/iter; left time: 380.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0653938 Vali Loss: 0.0750249 Test Loss: 0.0866540\n",
      "Validation loss decreased (0.075146 --> 0.075025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610570\n",
      "\tspeed: 0.0435s/iter; left time: 916.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0691948\n",
      "\tspeed: 0.0227s/iter; left time: 476.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0645714 Vali Loss: 0.0748224 Test Loss: 0.0866774\n",
      "Validation loss decreased (0.075025 --> 0.074822).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0635364\n",
      "\tspeed: 0.0438s/iter; left time: 913.4307s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676383\n",
      "\tspeed: 0.0196s/iter; left time: 405.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0640450 Vali Loss: 0.0747084 Test Loss: 0.0860682\n",
      "Validation loss decreased (0.074822 --> 0.074708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0642655\n",
      "\tspeed: 0.0433s/iter; left time: 894.1643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633054\n",
      "\tspeed: 0.0209s/iter; left time: 430.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0635069 Vali Loss: 0.0743306 Test Loss: 0.0875940\n",
      "Validation loss decreased (0.074708 --> 0.074331).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672177\n",
      "\tspeed: 0.0429s/iter; left time: 874.8904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657890\n",
      "\tspeed: 0.0209s/iter; left time: 424.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0630452 Vali Loss: 0.0741678 Test Loss: 0.0868630\n",
      "Validation loss decreased (0.074331 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632034\n",
      "\tspeed: 0.0434s/iter; left time: 876.3151s\n",
      "\titers: 200, epoch: 10 | loss: 0.0645544\n",
      "\tspeed: 0.0202s/iter; left time: 404.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0627409 Vali Loss: 0.0743513 Test Loss: 0.0880571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0636334\n",
      "\tspeed: 0.0404s/iter; left time: 806.8377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602807\n",
      "\tspeed: 0.0178s/iter; left time: 353.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0623453 Vali Loss: 0.0742074 Test Loss: 0.0878647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583318\n",
      "\tspeed: 0.0410s/iter; left time: 808.9365s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650040\n",
      "\tspeed: 0.0179s/iter; left time: 352.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0620972 Vali Loss: 0.0737038 Test Loss: 0.0867297\n",
      "Validation loss decreased (0.074168 --> 0.073704).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0613920\n",
      "\tspeed: 0.0414s/iter; left time: 808.6399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0611318\n",
      "\tspeed: 0.0182s/iter; left time: 353.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0618523 Vali Loss: 0.0738235 Test Loss: 0.0875536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0610238\n",
      "\tspeed: 0.0386s/iter; left time: 744.5537s\n",
      "\titers: 200, epoch: 14 | loss: 0.0601860\n",
      "\tspeed: 0.0179s/iter; left time: 343.8556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0615380 Vali Loss: 0.0738372 Test Loss: 0.0877525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598381\n",
      "\tspeed: 0.0387s/iter; left time: 738.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0587940\n",
      "\tspeed: 0.0178s/iter; left time: 338.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0612895 Vali Loss: 0.0739167 Test Loss: 0.0872995\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566209\n",
      "\tspeed: 0.0421s/iter; left time: 794.7425s\n",
      "\titers: 200, epoch: 16 | loss: 0.0571298\n",
      "\tspeed: 0.0183s/iter; left time: 343.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0611391 Vali Loss: 0.0740395 Test Loss: 0.0877071\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624488\n",
      "\tspeed: 0.0436s/iter; left time: 813.1598s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577584\n",
      "\tspeed: 0.0198s/iter; left time: 367.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0609111 Vali Loss: 0.0737153 Test Loss: 0.0876156\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0645408\n",
      "\tspeed: 0.0412s/iter; left time: 758.7901s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614708\n",
      "\tspeed: 0.0182s/iter; left time: 332.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0607212 Vali Loss: 0.0740565 Test Loss: 0.0879836\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0585145\n",
      "\tspeed: 0.0441s/iter; left time: 802.3411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603509\n",
      "\tspeed: 0.0209s/iter; left time: 378.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0606192 Vali Loss: 0.0737144 Test Loss: 0.0875244\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0605584\n",
      "\tspeed: 0.0389s/iter; left time: 698.6056s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584688\n",
      "\tspeed: 0.0180s/iter; left time: 321.6657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0604933 Vali Loss: 0.0737341 Test Loss: 0.0881607\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0649967\n",
      "\tspeed: 0.0399s/iter; left time: 707.6438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591727\n",
      "\tspeed: 0.0178s/iter; left time: 314.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0603355 Vali Loss: 0.0738130 Test Loss: 0.0877827\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593023\n",
      "\tspeed: 0.0445s/iter; left time: 779.7140s\n",
      "\titers: 200, epoch: 22 | loss: 0.0619041\n",
      "\tspeed: 0.0183s/iter; left time: 319.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0601923 Vali Loss: 0.0737966 Test Loss: 0.0876334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021043021231889725, rmse:0.1450621336698532, mae:0.08672972023487091, rse:0.5618393421173096\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:46.06s\n",
      "Intermediate time for FR: 00h:23m:12.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1379552\n",
      "\tspeed: 0.0457s/iter; left time: 1019.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160477\n",
      "\tspeed: 0.0178s/iter; left time: 394.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1433041 Vali Loss: 0.0977655 Test Loss: 0.1001861\n",
      "Validation loss decreased (inf --> 0.097766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780573\n",
      "\tspeed: 0.0397s/iter; left time: 877.4531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670697\n",
      "\tspeed: 0.0178s/iter; left time: 390.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0783016 Vali Loss: 0.0630192 Test Loss: 0.0662496\n",
      "Validation loss decreased (0.097766 --> 0.063019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0623454\n",
      "\tspeed: 0.0369s/iter; left time: 805.5581s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655507\n",
      "\tspeed: 0.0175s/iter; left time: 381.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0659248 Vali Loss: 0.0605475 Test Loss: 0.0632674\n",
      "Validation loss decreased (0.063019 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630882\n",
      "\tspeed: 0.0372s/iter; left time: 805.2769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0590766\n",
      "\tspeed: 0.0177s/iter; left time: 380.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628566 Vali Loss: 0.0584909 Test Loss: 0.0608319\n",
      "Validation loss decreased (0.060548 --> 0.058491).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0591956\n",
      "\tspeed: 0.0442s/iter; left time: 946.6197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0613977\n",
      "\tspeed: 0.0240s/iter; left time: 510.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0611276 Vali Loss: 0.0580106 Test Loss: 0.0599504\n",
      "Validation loss decreased (0.058491 --> 0.058011).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577363\n",
      "\tspeed: 0.0466s/iter; left time: 987.1521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0550658\n",
      "\tspeed: 0.0258s/iter; left time: 543.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0599828 Vali Loss: 0.0571707 Test Loss: 0.0595299\n",
      "Validation loss decreased (0.058011 --> 0.057171).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0601596\n",
      "\tspeed: 0.0470s/iter; left time: 985.0367s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558117\n",
      "\tspeed: 0.0244s/iter; left time: 508.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0591725 Vali Loss: 0.0566996 Test Loss: 0.0588407\n",
      "Validation loss decreased (0.057171 --> 0.056700).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567679\n",
      "\tspeed: 0.0453s/iter; left time: 938.7148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577220\n",
      "\tspeed: 0.0207s/iter; left time: 427.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0585837 Vali Loss: 0.0563851 Test Loss: 0.0587719\n",
      "Validation loss decreased (0.056700 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0536918\n",
      "\tspeed: 0.0433s/iter; left time: 888.3929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0593248\n",
      "\tspeed: 0.0202s/iter; left time: 412.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0579274 Vali Loss: 0.0560959 Test Loss: 0.0584001\n",
      "Validation loss decreased (0.056385 --> 0.056096).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576015\n",
      "\tspeed: 0.0392s/iter; left time: 795.0024s\n",
      "\titers: 200, epoch: 10 | loss: 0.0572641\n",
      "\tspeed: 0.0197s/iter; left time: 397.1217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0574487 Vali Loss: 0.0561246 Test Loss: 0.0586067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603743\n",
      "\tspeed: 0.0446s/iter; left time: 894.4247s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529461\n",
      "\tspeed: 0.0243s/iter; left time: 485.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0571570 Vali Loss: 0.0558561 Test Loss: 0.0580777\n",
      "Validation loss decreased (0.056096 --> 0.055856).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538307\n",
      "\tspeed: 0.0408s/iter; left time: 809.1254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0569894\n",
      "\tspeed: 0.0203s/iter; left time: 401.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0567255 Vali Loss: 0.0555736 Test Loss: 0.0576931\n",
      "Validation loss decreased (0.055856 --> 0.055574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559114\n",
      "\tspeed: 0.0453s/iter; left time: 888.4679s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570156\n",
      "\tspeed: 0.0183s/iter; left time: 357.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0564412 Vali Loss: 0.0555875 Test Loss: 0.0576721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608026\n",
      "\tspeed: 0.0409s/iter; left time: 793.3031s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548942\n",
      "\tspeed: 0.0202s/iter; left time: 389.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0562439 Vali Loss: 0.0556266 Test Loss: 0.0576045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0568721\n",
      "\tspeed: 0.0432s/iter; left time: 828.8342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553573\n",
      "\tspeed: 0.0237s/iter; left time: 452.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0559618 Vali Loss: 0.0554153 Test Loss: 0.0574718\n",
      "Validation loss decreased (0.055574 --> 0.055415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573713\n",
      "\tspeed: 0.0398s/iter; left time: 754.3022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561678\n",
      "\tspeed: 0.0175s/iter; left time: 329.9052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0558215 Vali Loss: 0.0551744 Test Loss: 0.0573095\n",
      "Validation loss decreased (0.055415 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589329\n",
      "\tspeed: 0.0376s/iter; left time: 703.8887s\n",
      "\titers: 200, epoch: 17 | loss: 0.0574918\n",
      "\tspeed: 0.0179s/iter; left time: 332.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0556505 Vali Loss: 0.0550482 Test Loss: 0.0572504\n",
      "Validation loss decreased (0.055174 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534935\n",
      "\tspeed: 0.0414s/iter; left time: 765.8245s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574331\n",
      "\tspeed: 0.0198s/iter; left time: 364.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0554857 Vali Loss: 0.0549875 Test Loss: 0.0572133\n",
      "Validation loss decreased (0.055048 --> 0.054988).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556992\n",
      "\tspeed: 0.0385s/iter; left time: 704.2454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604655\n",
      "\tspeed: 0.0240s/iter; left time: 435.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0553156 Vali Loss: 0.0548461 Test Loss: 0.0571244\n",
      "Validation loss decreased (0.054988 --> 0.054846).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546956\n",
      "\tspeed: 0.0414s/iter; left time: 746.4803s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543233\n",
      "\tspeed: 0.0245s/iter; left time: 440.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0551500 Vali Loss: 0.0548050 Test Loss: 0.0570001\n",
      "Validation loss decreased (0.054846 --> 0.054805).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0572998\n",
      "\tspeed: 0.0456s/iter; left time: 812.4846s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540240\n",
      "\tspeed: 0.0193s/iter; left time: 341.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0551207 Vali Loss: 0.0548231 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534088\n",
      "\tspeed: 0.0378s/iter; left time: 664.9020s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502284\n",
      "\tspeed: 0.0173s/iter; left time: 302.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0549312 Vali Loss: 0.0548708 Test Loss: 0.0570204\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0540605\n",
      "\tspeed: 0.0385s/iter; left time: 668.9097s\n",
      "\titers: 200, epoch: 23 | loss: 0.0507261\n",
      "\tspeed: 0.0178s/iter; left time: 306.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0548571 Vali Loss: 0.0547824 Test Loss: 0.0569985\n",
      "Validation loss decreased (0.054805 --> 0.054782).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583674\n",
      "\tspeed: 0.0442s/iter; left time: 758.5964s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544730\n",
      "\tspeed: 0.0176s/iter; left time: 299.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0547987 Vali Loss: 0.0546288 Test Loss: 0.0570315\n",
      "Validation loss decreased (0.054782 --> 0.054629).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508277\n",
      "\tspeed: 0.0373s/iter; left time: 631.7015s\n",
      "\titers: 200, epoch: 25 | loss: 0.0581925\n",
      "\tspeed: 0.0194s/iter; left time: 327.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0547711 Vali Loss: 0.0544805 Test Loss: 0.0568517\n",
      "Validation loss decreased (0.054629 --> 0.054480).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556801\n",
      "\tspeed: 0.0391s/iter; left time: 653.4126s\n",
      "\titers: 200, epoch: 26 | loss: 0.0554455\n",
      "\tspeed: 0.0195s/iter; left time: 323.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0546281 Vali Loss: 0.0546029 Test Loss: 0.0568632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572915\n",
      "\tspeed: 0.0379s/iter; left time: 623.7133s\n",
      "\titers: 200, epoch: 27 | loss: 0.0576790\n",
      "\tspeed: 0.0253s/iter; left time: 414.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0545952 Vali Loss: 0.0546437 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563810\n",
      "\tspeed: 0.0466s/iter; left time: 756.6862s\n",
      "\titers: 200, epoch: 28 | loss: 0.0515816\n",
      "\tspeed: 0.0244s/iter; left time: 393.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0545041 Vali Loss: 0.0544355 Test Loss: 0.0567258\n",
      "Validation loss decreased (0.054480 --> 0.054436).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0575383\n",
      "\tspeed: 0.0415s/iter; left time: 665.5287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0517639\n",
      "\tspeed: 0.0202s/iter; left time: 321.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0544492 Vali Loss: 0.0544463 Test Loss: 0.0569202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0554202\n",
      "\tspeed: 0.0422s/iter; left time: 667.1427s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573169\n",
      "\tspeed: 0.0204s/iter; left time: 320.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0544512 Vali Loss: 0.0544945 Test Loss: 0.0567682\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525765\n",
      "\tspeed: 0.0452s/iter; left time: 704.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568761\n",
      "\tspeed: 0.0243s/iter; left time: 375.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0543604 Vali Loss: 0.0544442 Test Loss: 0.0567680\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0544155\n",
      "\tspeed: 0.0463s/iter; left time: 711.2055s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564592\n",
      "\tspeed: 0.0197s/iter; left time: 301.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0543330 Vali Loss: 0.0544301 Test Loss: 0.0567419\n",
      "Validation loss decreased (0.054436 --> 0.054430).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549597\n",
      "\tspeed: 0.0429s/iter; left time: 648.7709s\n",
      "\titers: 200, epoch: 33 | loss: 0.0541910\n",
      "\tspeed: 0.0181s/iter; left time: 272.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0543469 Vali Loss: 0.0543835 Test Loss: 0.0567440\n",
      "Validation loss decreased (0.054430 --> 0.054384).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0571987\n",
      "\tspeed: 0.0416s/iter; left time: 620.5499s\n",
      "\titers: 200, epoch: 34 | loss: 0.0567482\n",
      "\tspeed: 0.0201s/iter; left time: 297.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0543108 Vali Loss: 0.0543652 Test Loss: 0.0567222\n",
      "Validation loss decreased (0.054384 --> 0.054365).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535260\n",
      "\tspeed: 0.0423s/iter; left time: 621.8226s\n",
      "\titers: 200, epoch: 35 | loss: 0.0561866\n",
      "\tspeed: 0.0193s/iter; left time: 281.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0542972 Vali Loss: 0.0544265 Test Loss: 0.0567667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0549961\n",
      "\tspeed: 0.0410s/iter; left time: 593.5670s\n",
      "\titers: 200, epoch: 36 | loss: 0.0541536\n",
      "\tspeed: 0.0192s/iter; left time: 275.6673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0542406 Vali Loss: 0.0544166 Test Loss: 0.0566596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532916\n",
      "\tspeed: 0.0400s/iter; left time: 569.6183s\n",
      "\titers: 200, epoch: 37 | loss: 0.0511241\n",
      "\tspeed: 0.0198s/iter; left time: 280.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0542641 Vali Loss: 0.0543706 Test Loss: 0.0566760\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0539109\n",
      "\tspeed: 0.0399s/iter; left time: 558.4617s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564077\n",
      "\tspeed: 0.0205s/iter; left time: 285.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0541845 Vali Loss: 0.0543355 Test Loss: 0.0566975\n",
      "Validation loss decreased (0.054365 --> 0.054336).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503076\n",
      "\tspeed: 0.0409s/iter; left time: 563.8564s\n",
      "\titers: 200, epoch: 39 | loss: 0.0562198\n",
      "\tspeed: 0.0200s/iter; left time: 273.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0541782 Vali Loss: 0.0543724 Test Loss: 0.0566402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552053\n",
      "\tspeed: 0.0407s/iter; left time: 552.2094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0516493\n",
      "\tspeed: 0.0199s/iter; left time: 267.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0543906 Test Loss: 0.0566315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0556425\n",
      "\tspeed: 0.0412s/iter; left time: 550.0056s\n",
      "\titers: 200, epoch: 41 | loss: 0.0509712\n",
      "\tspeed: 0.0201s/iter; left time: 266.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0541427 Vali Loss: 0.0543536 Test Loss: 0.0566362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523108\n",
      "\tspeed: 0.0422s/iter; left time: 553.7186s\n",
      "\titers: 200, epoch: 42 | loss: 0.0576750\n",
      "\tspeed: 0.0195s/iter; left time: 253.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0541833 Vali Loss: 0.0542894 Test Loss: 0.0566669\n",
      "Validation loss decreased (0.054336 --> 0.054289).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0529656\n",
      "\tspeed: 0.0435s/iter; left time: 561.1621s\n",
      "\titers: 200, epoch: 43 | loss: 0.0502761\n",
      "\tspeed: 0.0229s/iter; left time: 292.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0541143 Vali Loss: 0.0543694 Test Loss: 0.0566259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537367\n",
      "\tspeed: 0.0447s/iter; left time: 566.3745s\n",
      "\titers: 200, epoch: 44 | loss: 0.0559055\n",
      "\tspeed: 0.0200s/iter; left time: 251.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0541310 Vali Loss: 0.0542568 Test Loss: 0.0566117\n",
      "Validation loss decreased (0.054289 --> 0.054257).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0569029\n",
      "\tspeed: 0.0405s/iter; left time: 504.4566s\n",
      "\titers: 200, epoch: 45 | loss: 0.0579741\n",
      "\tspeed: 0.0183s/iter; left time: 225.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0541451 Vali Loss: 0.0543393 Test Loss: 0.0566353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0510111\n",
      "\tspeed: 0.0435s/iter; left time: 531.5669s\n",
      "\titers: 200, epoch: 46 | loss: 0.0570540\n",
      "\tspeed: 0.0194s/iter; left time: 235.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0543384 Test Loss: 0.0565993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0603271\n",
      "\tspeed: 0.0408s/iter; left time: 489.8614s\n",
      "\titers: 200, epoch: 47 | loss: 0.0489362\n",
      "\tspeed: 0.0221s/iter; left time: 262.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0541158 Vali Loss: 0.0542949 Test Loss: 0.0566084\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0562014\n",
      "\tspeed: 0.0430s/iter; left time: 506.5203s\n",
      "\titers: 200, epoch: 48 | loss: 0.0527634\n",
      "\tspeed: 0.0175s/iter; left time: 204.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0541052 Vali Loss: 0.0542426 Test Loss: 0.0566221\n",
      "Validation loss decreased (0.054257 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0550343\n",
      "\tspeed: 0.0405s/iter; left time: 468.1700s\n",
      "\titers: 200, epoch: 49 | loss: 0.0519099\n",
      "\tspeed: 0.0199s/iter; left time: 227.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0540786 Vali Loss: 0.0543246 Test Loss: 0.0566017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0535444\n",
      "\tspeed: 0.0454s/iter; left time: 514.6661s\n",
      "\titers: 200, epoch: 50 | loss: 0.0502683\n",
      "\tspeed: 0.0237s/iter; left time: 265.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0540946 Vali Loss: 0.0542993 Test Loss: 0.0566170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525270\n",
      "\tspeed: 0.0416s/iter; left time: 462.1014s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515277\n",
      "\tspeed: 0.0226s/iter; left time: 248.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0542633 Test Loss: 0.0566191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0528202\n",
      "\tspeed: 0.0388s/iter; left time: 422.3969s\n",
      "\titers: 200, epoch: 52 | loss: 0.0524368\n",
      "\tspeed: 0.0174s/iter; left time: 187.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0540361 Vali Loss: 0.0542905 Test Loss: 0.0565996\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548940\n",
      "\tspeed: 0.0396s/iter; left time: 421.7677s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519573\n",
      "\tspeed: 0.0204s/iter; left time: 214.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0541037 Vali Loss: 0.0542877 Test Loss: 0.0566198\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533164\n",
      "\tspeed: 0.0430s/iter; left time: 448.0185s\n",
      "\titers: 200, epoch: 54 | loss: 0.0578958\n",
      "\tspeed: 0.0241s/iter; left time: 249.1271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0540474 Vali Loss: 0.0542890 Test Loss: 0.0566051\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548727\n",
      "\tspeed: 0.0412s/iter; left time: 419.9655s\n",
      "\titers: 200, epoch: 55 | loss: 0.0566967\n",
      "\tspeed: 0.0198s/iter; left time: 200.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0540961 Vali Loss: 0.0543088 Test Loss: 0.0566188\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0531577\n",
      "\tspeed: 0.0392s/iter; left time: 391.2384s\n",
      "\titers: 200, epoch: 56 | loss: 0.0580916\n",
      "\tspeed: 0.0175s/iter; left time: 173.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0540501 Vali Loss: 0.0543088 Test Loss: 0.0566136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0559601\n",
      "\tspeed: 0.0367s/iter; left time: 358.4146s\n",
      "\titers: 200, epoch: 57 | loss: 0.0543095\n",
      "\tspeed: 0.0174s/iter; left time: 167.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0540529 Vali Loss: 0.0542350 Test Loss: 0.0566049\n",
      "Validation loss decreased (0.054243 --> 0.054235).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538715\n",
      "\tspeed: 0.0394s/iter; left time: 375.2252s\n",
      "\titers: 200, epoch: 58 | loss: 0.0555631\n",
      "\tspeed: 0.0176s/iter; left time: 165.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0540707 Vali Loss: 0.0542733 Test Loss: 0.0566099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0560754\n",
      "\tspeed: 0.0395s/iter; left time: 367.5105s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519199\n",
      "\tspeed: 0.0216s/iter; left time: 199.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0540248 Vali Loss: 0.0542616 Test Loss: 0.0566028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0571120\n",
      "\tspeed: 0.0394s/iter; left time: 358.0110s\n",
      "\titers: 200, epoch: 60 | loss: 0.0582117\n",
      "\tspeed: 0.0174s/iter; left time: 156.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0542328 Test Loss: 0.0565980\n",
      "Validation loss decreased (0.054235 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0584766\n",
      "\tspeed: 0.0408s/iter; left time: 361.3126s\n",
      "\titers: 200, epoch: 61 | loss: 0.0535091\n",
      "\tspeed: 0.0177s/iter; left time: 154.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0540387 Vali Loss: 0.0543091 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0581197\n",
      "\tspeed: 0.0361s/iter; left time: 312.1834s\n",
      "\titers: 200, epoch: 62 | loss: 0.0556779\n",
      "\tspeed: 0.0181s/iter; left time: 154.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0540725 Vali Loss: 0.0543238 Test Loss: 0.0566121\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0515098\n",
      "\tspeed: 0.0379s/iter; left time: 318.9160s\n",
      "\titers: 200, epoch: 63 | loss: 0.0547690\n",
      "\tspeed: 0.0175s/iter; left time: 145.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0539889 Vali Loss: 0.0542935 Test Loss: 0.0566016\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0558435\n",
      "\tspeed: 0.0362s/iter; left time: 296.3327s\n",
      "\titers: 200, epoch: 64 | loss: 0.0558558\n",
      "\tspeed: 0.0176s/iter; left time: 141.9768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0540476 Vali Loss: 0.0542764 Test Loss: 0.0566100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546813\n",
      "\tspeed: 0.0395s/iter; left time: 314.6030s\n",
      "\titers: 200, epoch: 65 | loss: 0.0554467\n",
      "\tspeed: 0.0175s/iter; left time: 137.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540326 Vali Loss: 0.0543010 Test Loss: 0.0565934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0568983\n",
      "\tspeed: 0.0397s/iter; left time: 306.9717s\n",
      "\titers: 200, epoch: 66 | loss: 0.0544441\n",
      "\tspeed: 0.0206s/iter; left time: 157.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0540953 Vali Loss: 0.0543162 Test Loss: 0.0565933\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0554599\n",
      "\tspeed: 0.0427s/iter; left time: 321.0730s\n",
      "\titers: 200, epoch: 67 | loss: 0.0513533\n",
      "\tspeed: 0.0207s/iter; left time: 153.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0543076 Test Loss: 0.0566009\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0543297\n",
      "\tspeed: 0.0370s/iter; left time: 269.8459s\n",
      "\titers: 200, epoch: 68 | loss: 0.0517003\n",
      "\tspeed: 0.0173s/iter; left time: 124.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0540420 Vali Loss: 0.0542774 Test Loss: 0.0566046\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0578591\n",
      "\tspeed: 0.0356s/iter; left time: 251.9135s\n",
      "\titers: 200, epoch: 69 | loss: 0.0572697\n",
      "\tspeed: 0.0175s/iter; left time: 121.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0540791 Vali Loss: 0.0542371 Test Loss: 0.0566058\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0537115\n",
      "\tspeed: 0.0371s/iter; left time: 253.6271s\n",
      "\titers: 200, epoch: 70 | loss: 0.0505972\n",
      "\tspeed: 0.0210s/iter; left time: 141.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0540482 Vali Loss: 0.0542732 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083218105137348, rmse:0.10041522979736328, mae:0.0565979890525341, rse:0.3794197142124176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1359126\n",
      "\tspeed: 0.0225s/iter; left time: 502.7281s\n",
      "\titers: 200, epoch: 1 | loss: 0.1098680\n",
      "\tspeed: 0.0213s/iter; left time: 473.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1422349 Vali Loss: 0.0974500 Test Loss: 0.0992706\n",
      "Validation loss decreased (inf --> 0.097450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754588\n",
      "\tspeed: 0.0417s/iter; left time: 921.0493s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673907\n",
      "\tspeed: 0.0174s/iter; left time: 382.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0780355 Vali Loss: 0.0627294 Test Loss: 0.0657381\n",
      "Validation loss decreased (0.097450 --> 0.062729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637678\n",
      "\tspeed: 0.0431s/iter; left time: 942.5154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663196\n",
      "\tspeed: 0.0196s/iter; left time: 425.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0660164 Vali Loss: 0.0599926 Test Loss: 0.0628002\n",
      "Validation loss decreased (0.062729 --> 0.059993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638419\n",
      "\tspeed: 0.0413s/iter; left time: 893.2220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635814\n",
      "\tspeed: 0.0202s/iter; left time: 435.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0630481 Vali Loss: 0.0586561 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.059993 --> 0.058656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630238\n",
      "\tspeed: 0.0430s/iter; left time: 921.1678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610638\n",
      "\tspeed: 0.0176s/iter; left time: 373.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0612143 Vali Loss: 0.0575957 Test Loss: 0.0601869\n",
      "Validation loss decreased (0.058656 --> 0.057596).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0648216\n",
      "\tspeed: 0.0375s/iter; left time: 794.3087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634050\n",
      "\tspeed: 0.0176s/iter; left time: 370.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0601831 Vali Loss: 0.0573942 Test Loss: 0.0597799\n",
      "Validation loss decreased (0.057596 --> 0.057394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599069\n",
      "\tspeed: 0.0371s/iter; left time: 778.1308s\n",
      "\titers: 200, epoch: 7 | loss: 0.0612065\n",
      "\tspeed: 0.0175s/iter; left time: 364.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593155 Vali Loss: 0.0566541 Test Loss: 0.0591102\n",
      "Validation loss decreased (0.057394 --> 0.056654).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542986\n",
      "\tspeed: 0.0415s/iter; left time: 859.8482s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572991\n",
      "\tspeed: 0.0223s/iter; left time: 460.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0585377 Vali Loss: 0.0566305 Test Loss: 0.0588562\n",
      "Validation loss decreased (0.056654 --> 0.056631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0640263\n",
      "\tspeed: 0.0471s/iter; left time: 966.1459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615080\n",
      "\tspeed: 0.0202s/iter; left time: 412.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0579915 Vali Loss: 0.0559572 Test Loss: 0.0582891\n",
      "Validation loss decreased (0.056631 --> 0.055957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577642\n",
      "\tspeed: 0.0505s/iter; left time: 1025.0210s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594756\n",
      "\tspeed: 0.0264s/iter; left time: 532.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0575409 Vali Loss: 0.0558674 Test Loss: 0.0583287\n",
      "Validation loss decreased (0.055957 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579124\n",
      "\tspeed: 0.0448s/iter; left time: 899.5653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581660\n",
      "\tspeed: 0.0204s/iter; left time: 406.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0571616 Vali Loss: 0.0555863 Test Loss: 0.0582007\n",
      "Validation loss decreased (0.055867 --> 0.055586).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0618948\n",
      "\tspeed: 0.0424s/iter; left time: 840.9896s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521666\n",
      "\tspeed: 0.0205s/iter; left time: 405.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0569079 Vali Loss: 0.0554603 Test Loss: 0.0577516\n",
      "Validation loss decreased (0.055586 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0548473\n",
      "\tspeed: 0.0413s/iter; left time: 809.2691s\n",
      "\titers: 200, epoch: 13 | loss: 0.0552182\n",
      "\tspeed: 0.0208s/iter; left time: 405.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0565429 Vali Loss: 0.0553249 Test Loss: 0.0574627\n",
      "Validation loss decreased (0.055460 --> 0.055325).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554208\n",
      "\tspeed: 0.0444s/iter; left time: 861.4926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0541941\n",
      "\tspeed: 0.0230s/iter; left time: 443.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0562538 Vali Loss: 0.0553683 Test Loss: 0.0575624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0557231\n",
      "\tspeed: 0.0443s/iter; left time: 848.9220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574080\n",
      "\tspeed: 0.0209s/iter; left time: 397.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0560413 Vali Loss: 0.0551291 Test Loss: 0.0575157\n",
      "Validation loss decreased (0.055325 --> 0.055129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575104\n",
      "\tspeed: 0.0396s/iter; left time: 749.1542s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551079\n",
      "\tspeed: 0.0208s/iter; left time: 392.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0557593 Vali Loss: 0.0548837 Test Loss: 0.0574590\n",
      "Validation loss decreased (0.055129 --> 0.054884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595915\n",
      "\tspeed: 0.0407s/iter; left time: 761.5210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584150\n",
      "\tspeed: 0.0174s/iter; left time: 323.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0556200 Vali Loss: 0.0549069 Test Loss: 0.0572072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0574168\n",
      "\tspeed: 0.0400s/iter; left time: 740.2444s\n",
      "\titers: 200, epoch: 18 | loss: 0.0581237\n",
      "\tspeed: 0.0177s/iter; left time: 326.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0554449 Vali Loss: 0.0550244 Test Loss: 0.0573702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542099\n",
      "\tspeed: 0.0398s/iter; left time: 726.2855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559456\n",
      "\tspeed: 0.0176s/iter; left time: 319.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0553786 Vali Loss: 0.0548329 Test Loss: 0.0571894\n",
      "Validation loss decreased (0.054884 --> 0.054833).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572355\n",
      "\tspeed: 0.0380s/iter; left time: 686.2173s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561926\n",
      "\tspeed: 0.0173s/iter; left time: 310.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0551821 Vali Loss: 0.0546544 Test Loss: 0.0570234\n",
      "Validation loss decreased (0.054833 --> 0.054654).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563121\n",
      "\tspeed: 0.0377s/iter; left time: 671.9930s\n",
      "\titers: 200, epoch: 21 | loss: 0.0511623\n",
      "\tspeed: 0.0173s/iter; left time: 307.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0551742 Vali Loss: 0.0547604 Test Loss: 0.0571249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0555600\n",
      "\tspeed: 0.0370s/iter; left time: 651.3281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0522842\n",
      "\tspeed: 0.0177s/iter; left time: 309.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0550073 Vali Loss: 0.0546179 Test Loss: 0.0571097\n",
      "Validation loss decreased (0.054654 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0549146\n",
      "\tspeed: 0.0380s/iter; left time: 660.0129s\n",
      "\titers: 200, epoch: 23 | loss: 0.0585962\n",
      "\tspeed: 0.0176s/iter; left time: 303.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0548645 Vali Loss: 0.0546012 Test Loss: 0.0568507\n",
      "Validation loss decreased (0.054618 --> 0.054601).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522619\n",
      "\tspeed: 0.0411s/iter; left time: 705.5859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523071\n",
      "\tspeed: 0.0209s/iter; left time: 356.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0547287 Vali Loss: 0.0545045 Test Loss: 0.0567771\n",
      "Validation loss decreased (0.054601 --> 0.054504).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524549\n",
      "\tspeed: 0.0374s/iter; left time: 632.9479s\n",
      "\titers: 200, epoch: 25 | loss: 0.0523958\n",
      "\tspeed: 0.0175s/iter; left time: 294.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0546907 Vali Loss: 0.0543925 Test Loss: 0.0568053\n",
      "Validation loss decreased (0.054504 --> 0.054393).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0491656\n",
      "\tspeed: 0.0375s/iter; left time: 627.0800s\n",
      "\titers: 200, epoch: 26 | loss: 0.0519010\n",
      "\tspeed: 0.0187s/iter; left time: 309.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0546669 Vali Loss: 0.0544461 Test Loss: 0.0568800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0501324\n",
      "\tspeed: 0.0378s/iter; left time: 622.8373s\n",
      "\titers: 200, epoch: 27 | loss: 0.0555143\n",
      "\tspeed: 0.0176s/iter; left time: 287.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0545846 Vali Loss: 0.0543533 Test Loss: 0.0567463\n",
      "Validation loss decreased (0.054393 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0519045\n",
      "\tspeed: 0.0415s/iter; left time: 674.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0593164\n",
      "\tspeed: 0.0198s/iter; left time: 319.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0545893 Vali Loss: 0.0543581 Test Loss: 0.0567341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0529863\n",
      "\tspeed: 0.0364s/iter; left time: 583.2380s\n",
      "\titers: 200, epoch: 29 | loss: 0.0542369\n",
      "\tspeed: 0.0178s/iter; left time: 282.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0544853 Vali Loss: 0.0542986 Test Loss: 0.0568295\n",
      "Validation loss decreased (0.054353 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555674\n",
      "\tspeed: 0.0386s/iter; left time: 609.8705s\n",
      "\titers: 200, epoch: 30 | loss: 0.0536577\n",
      "\tspeed: 0.0180s/iter; left time: 283.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0544743 Vali Loss: 0.0543639 Test Loss: 0.0568086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0559736\n",
      "\tspeed: 0.0426s/iter; left time: 664.2999s\n",
      "\titers: 200, epoch: 31 | loss: 0.0530356\n",
      "\tspeed: 0.0198s/iter; left time: 307.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0543727 Vali Loss: 0.0542804 Test Loss: 0.0567701\n",
      "Validation loss decreased (0.054299 --> 0.054280).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506607\n",
      "\tspeed: 0.0423s/iter; left time: 648.9617s\n",
      "\titers: 200, epoch: 32 | loss: 0.0552089\n",
      "\tspeed: 0.0197s/iter; left time: 301.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543940 Vali Loss: 0.0542822 Test Loss: 0.0566895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0566098\n",
      "\tspeed: 0.0416s/iter; left time: 628.8243s\n",
      "\titers: 200, epoch: 33 | loss: 0.0505462\n",
      "\tspeed: 0.0176s/iter; left time: 264.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0543382 Vali Loss: 0.0542966 Test Loss: 0.0567221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0536274\n",
      "\tspeed: 0.0372s/iter; left time: 554.7289s\n",
      "\titers: 200, epoch: 34 | loss: 0.0556459\n",
      "\tspeed: 0.0177s/iter; left time: 262.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0542882 Vali Loss: 0.0541794 Test Loss: 0.0567122\n",
      "Validation loss decreased (0.054280 --> 0.054179).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517977\n",
      "\tspeed: 0.0418s/iter; left time: 614.2475s\n",
      "\titers: 200, epoch: 35 | loss: 0.0515377\n",
      "\tspeed: 0.0187s/iter; left time: 272.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0542845 Vali Loss: 0.0542402 Test Loss: 0.0566953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0548994\n",
      "\tspeed: 0.0390s/iter; left time: 564.5106s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516339\n",
      "\tspeed: 0.0174s/iter; left time: 249.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0543297 Vali Loss: 0.0541653 Test Loss: 0.0567088\n",
      "Validation loss decreased (0.054179 --> 0.054165).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532896\n",
      "\tspeed: 0.0374s/iter; left time: 532.2474s\n",
      "\titers: 200, epoch: 37 | loss: 0.0552534\n",
      "\tspeed: 0.0173s/iter; left time: 245.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0542318 Vali Loss: 0.0542396 Test Loss: 0.0566283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0579502\n",
      "\tspeed: 0.0363s/iter; left time: 509.2660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564580\n",
      "\tspeed: 0.0174s/iter; left time: 241.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0541829 Vali Loss: 0.0542048 Test Loss: 0.0566276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0524793\n",
      "\tspeed: 0.0436s/iter; left time: 601.4429s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540179\n",
      "\tspeed: 0.0233s/iter; left time: 319.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0542241 Vali Loss: 0.0542069 Test Loss: 0.0566297\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0576975\n",
      "\tspeed: 0.0376s/iter; left time: 509.5911s\n",
      "\titers: 200, epoch: 40 | loss: 0.0566987\n",
      "\tspeed: 0.0200s/iter; left time: 269.4703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0542656 Vali Loss: 0.0541664 Test Loss: 0.0566543\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545915\n",
      "\tspeed: 0.0367s/iter; left time: 489.2609s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532811\n",
      "\tspeed: 0.0210s/iter; left time: 277.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0542114 Vali Loss: 0.0541793 Test Loss: 0.0566813\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551827\n",
      "\tspeed: 0.0411s/iter; left time: 539.2438s\n",
      "\titers: 200, epoch: 42 | loss: 0.0532943\n",
      "\tspeed: 0.0185s/iter; left time: 241.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0541279 Vali Loss: 0.0542011 Test Loss: 0.0566544\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552357\n",
      "\tspeed: 0.0401s/iter; left time: 517.6390s\n",
      "\titers: 200, epoch: 43 | loss: 0.0531659\n",
      "\tspeed: 0.0226s/iter; left time: 288.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541679 Vali Loss: 0.0542149 Test Loss: 0.0566875\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508406\n",
      "\tspeed: 0.0397s/iter; left time: 502.6425s\n",
      "\titers: 200, epoch: 44 | loss: 0.0489071\n",
      "\tspeed: 0.0176s/iter; left time: 220.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0541656 Vali Loss: 0.0542703 Test Loss: 0.0566778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571226\n",
      "\tspeed: 0.0372s/iter; left time: 463.0165s\n",
      "\titers: 200, epoch: 45 | loss: 0.0516223\n",
      "\tspeed: 0.0175s/iter; left time: 216.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0541900 Test Loss: 0.0566624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0533346\n",
      "\tspeed: 0.0367s/iter; left time: 448.1339s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554680\n",
      "\tspeed: 0.0176s/iter; left time: 213.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0541046 Vali Loss: 0.0542059 Test Loss: 0.0566667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010069291107356548, rmse:0.10034585744142532, mae:0.05670879781246185, rse:0.37915757298469543\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:52.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1438253\n",
      "\tspeed: 0.0460s/iter; left time: 1024.9099s\n",
      "\titers: 200, epoch: 1 | loss: 0.1208758\n",
      "\tspeed: 0.0179s/iter; left time: 397.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1473302 Vali Loss: 0.1059266 Test Loss: 0.1091740\n",
      "Validation loss decreased (inf --> 0.105927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936386\n",
      "\tspeed: 0.0392s/iter; left time: 865.1550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860985\n",
      "\tspeed: 0.0179s/iter; left time: 392.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0960414 Vali Loss: 0.0816183 Test Loss: 0.0868534\n",
      "Validation loss decreased (0.105927 --> 0.081618).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0869685\n",
      "\tspeed: 0.0384s/iter; left time: 839.2529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824700\n",
      "\tspeed: 0.0177s/iter; left time: 384.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0850344 Vali Loss: 0.0794767 Test Loss: 0.0840807\n",
      "Validation loss decreased (0.081618 --> 0.079477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0811073\n",
      "\tspeed: 0.0395s/iter; left time: 854.8521s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803189\n",
      "\tspeed: 0.0192s/iter; left time: 413.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823571 Vali Loss: 0.0782248 Test Loss: 0.0828857\n",
      "Validation loss decreased (0.079477 --> 0.078225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829862\n",
      "\tspeed: 0.0391s/iter; left time: 837.2694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771629\n",
      "\tspeed: 0.0180s/iter; left time: 383.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0807140 Vali Loss: 0.0776065 Test Loss: 0.0829133\n",
      "Validation loss decreased (0.078225 --> 0.077606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808049\n",
      "\tspeed: 0.0381s/iter; left time: 806.9387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791209\n",
      "\tspeed: 0.0175s/iter; left time: 369.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0796624 Vali Loss: 0.0771222 Test Loss: 0.0819657\n",
      "Validation loss decreased (0.077606 --> 0.077122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0809408\n",
      "\tspeed: 0.0381s/iter; left time: 797.8413s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773605\n",
      "\tspeed: 0.0179s/iter; left time: 373.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0788298 Vali Loss: 0.0770251 Test Loss: 0.0816225\n",
      "Validation loss decreased (0.077122 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780101\n",
      "\tspeed: 0.0386s/iter; left time: 800.1361s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734982\n",
      "\tspeed: 0.0178s/iter; left time: 366.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0781991 Vali Loss: 0.0765766 Test Loss: 0.0813183\n",
      "Validation loss decreased (0.077025 --> 0.076577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775502\n",
      "\tspeed: 0.0390s/iter; left time: 800.2133s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727340\n",
      "\tspeed: 0.0179s/iter; left time: 365.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0776098 Vali Loss: 0.0765785 Test Loss: 0.0815433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0742046\n",
      "\tspeed: 0.0384s/iter; left time: 778.6754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804574\n",
      "\tspeed: 0.0179s/iter; left time: 361.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0770741 Vali Loss: 0.0760664 Test Loss: 0.0814565\n",
      "Validation loss decreased (0.076577 --> 0.076066).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781170\n",
      "\tspeed: 0.0385s/iter; left time: 771.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763606\n",
      "\tspeed: 0.0177s/iter; left time: 354.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0766591 Vali Loss: 0.0762633 Test Loss: 0.0814268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0788421\n",
      "\tspeed: 0.0386s/iter; left time: 765.1212s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785553\n",
      "\tspeed: 0.0186s/iter; left time: 367.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0762871 Vali Loss: 0.0763303 Test Loss: 0.0807374\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767044\n",
      "\tspeed: 0.0405s/iter; left time: 794.2752s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790308\n",
      "\tspeed: 0.0190s/iter; left time: 370.3604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0760010 Vali Loss: 0.0760269 Test Loss: 0.0811383\n",
      "Validation loss decreased (0.076066 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738585\n",
      "\tspeed: 0.0382s/iter; left time: 740.1297s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735675\n",
      "\tspeed: 0.0175s/iter; left time: 337.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0756241 Vali Loss: 0.0759628 Test Loss: 0.0812599\n",
      "Validation loss decreased (0.076027 --> 0.075963).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746233\n",
      "\tspeed: 0.0403s/iter; left time: 773.2452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766651\n",
      "\tspeed: 0.0178s/iter; left time: 340.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0754588 Vali Loss: 0.0756437 Test Loss: 0.0810107\n",
      "Validation loss decreased (0.075963 --> 0.075644).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0798216\n",
      "\tspeed: 0.0379s/iter; left time: 718.3975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763530\n",
      "\tspeed: 0.0177s/iter; left time: 333.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0750988 Vali Loss: 0.0756608 Test Loss: 0.0809585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749412\n",
      "\tspeed: 0.0400s/iter; left time: 748.7746s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748506\n",
      "\tspeed: 0.0177s/iter; left time: 329.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0748632 Vali Loss: 0.0757296 Test Loss: 0.0809511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732470\n",
      "\tspeed: 0.0383s/iter; left time: 708.6400s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771152\n",
      "\tspeed: 0.0177s/iter; left time: 325.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0746712 Vali Loss: 0.0759519 Test Loss: 0.0808242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716322\n",
      "\tspeed: 0.0374s/iter; left time: 682.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0734277\n",
      "\tspeed: 0.0175s/iter; left time: 318.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0744779 Vali Loss: 0.0757884 Test Loss: 0.0807449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720630\n",
      "\tspeed: 0.0396s/iter; left time: 714.6965s\n",
      "\titers: 200, epoch: 20 | loss: 0.0764352\n",
      "\tspeed: 0.0176s/iter; left time: 315.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0742645 Vali Loss: 0.0756426 Test Loss: 0.0808228\n",
      "Validation loss decreased (0.075644 --> 0.075643).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752152\n",
      "\tspeed: 0.0425s/iter; left time: 757.8532s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683738\n",
      "\tspeed: 0.0190s/iter; left time: 336.3019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0741271 Vali Loss: 0.0756992 Test Loss: 0.0806643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747552\n",
      "\tspeed: 0.0387s/iter; left time: 680.3511s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740042\n",
      "\tspeed: 0.0178s/iter; left time: 311.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0740510 Vali Loss: 0.0756657 Test Loss: 0.0808825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729785\n",
      "\tspeed: 0.0379s/iter; left time: 658.7155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724722\n",
      "\tspeed: 0.0175s/iter; left time: 302.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0738833 Vali Loss: 0.0756935 Test Loss: 0.0808874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741584\n",
      "\tspeed: 0.0379s/iter; left time: 650.3920s\n",
      "\titers: 200, epoch: 24 | loss: 0.0702976\n",
      "\tspeed: 0.0176s/iter; left time: 299.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0737572 Vali Loss: 0.0755926 Test Loss: 0.0806114\n",
      "Validation loss decreased (0.075643 --> 0.075593).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0726041\n",
      "\tspeed: 0.0387s/iter; left time: 654.9765s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721414\n",
      "\tspeed: 0.0177s/iter; left time: 297.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0735935 Vali Loss: 0.0755621 Test Loss: 0.0806927\n",
      "Validation loss decreased (0.075593 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0734444\n",
      "\tspeed: 0.0385s/iter; left time: 643.0189s\n",
      "\titers: 200, epoch: 26 | loss: 0.0754302\n",
      "\tspeed: 0.0175s/iter; left time: 291.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0735225 Vali Loss: 0.0756676 Test Loss: 0.0805907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747007\n",
      "\tspeed: 0.0378s/iter; left time: 623.2643s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694138\n",
      "\tspeed: 0.0177s/iter; left time: 290.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0734549 Vali Loss: 0.0755092 Test Loss: 0.0805312\n",
      "Validation loss decreased (0.075562 --> 0.075509).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0760770\n",
      "\tspeed: 0.0391s/iter; left time: 635.0650s\n",
      "\titers: 200, epoch: 28 | loss: 0.0724863\n",
      "\tspeed: 0.0178s/iter; left time: 287.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0733856 Vali Loss: 0.0755548 Test Loss: 0.0805923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0735273\n",
      "\tspeed: 0.0381s/iter; left time: 610.0264s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731055\n",
      "\tspeed: 0.0177s/iter; left time: 281.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0733169 Vali Loss: 0.0754803 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.075509 --> 0.075480).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0725225\n",
      "\tspeed: 0.0388s/iter; left time: 613.0244s\n",
      "\titers: 200, epoch: 30 | loss: 0.0722679\n",
      "\tspeed: 0.0177s/iter; left time: 278.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0732621 Vali Loss: 0.0754730 Test Loss: 0.0806382\n",
      "Validation loss decreased (0.075480 --> 0.075473).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0735552\n",
      "\tspeed: 0.0406s/iter; left time: 632.5392s\n",
      "\titers: 200, epoch: 31 | loss: 0.0696184\n",
      "\tspeed: 0.0177s/iter; left time: 273.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0732522 Vali Loss: 0.0753299 Test Loss: 0.0805189\n",
      "Validation loss decreased (0.075473 --> 0.075330).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0748394\n",
      "\tspeed: 0.0394s/iter; left time: 605.2338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749177\n",
      "\tspeed: 0.0178s/iter; left time: 271.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0731558 Vali Loss: 0.0754113 Test Loss: 0.0805488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731158\n",
      "\tspeed: 0.0415s/iter; left time: 628.1651s\n",
      "\titers: 200, epoch: 33 | loss: 0.0764134\n",
      "\tspeed: 0.0190s/iter; left time: 285.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0731354 Vali Loss: 0.0754464 Test Loss: 0.0805663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720409\n",
      "\tspeed: 0.0380s/iter; left time: 566.4270s\n",
      "\titers: 200, epoch: 34 | loss: 0.0738428\n",
      "\tspeed: 0.0178s/iter; left time: 262.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0730683 Vali Loss: 0.0754058 Test Loss: 0.0804376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0698061\n",
      "\tspeed: 0.0400s/iter; left time: 587.5626s\n",
      "\titers: 200, epoch: 35 | loss: 0.0759599\n",
      "\tspeed: 0.0194s/iter; left time: 283.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0730275 Vali Loss: 0.0754564 Test Loss: 0.0805740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716557\n",
      "\tspeed: 0.0385s/iter; left time: 557.2221s\n",
      "\titers: 200, epoch: 36 | loss: 0.0711207\n",
      "\tspeed: 0.0175s/iter; left time: 251.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0730016 Vali Loss: 0.0754517 Test Loss: 0.0805066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755870\n",
      "\tspeed: 0.0383s/iter; left time: 545.3388s\n",
      "\titers: 200, epoch: 37 | loss: 0.0734674\n",
      "\tspeed: 0.0181s/iter; left time: 255.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0729387 Vali Loss: 0.0754124 Test Loss: 0.0805279\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0684947\n",
      "\tspeed: 0.0376s/iter; left time: 526.9358s\n",
      "\titers: 200, epoch: 38 | loss: 0.0758405\n",
      "\tspeed: 0.0177s/iter; left time: 245.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0729181 Vali Loss: 0.0754555 Test Loss: 0.0805209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0743821\n",
      "\tspeed: 0.0375s/iter; left time: 517.0128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711856\n",
      "\tspeed: 0.0175s/iter; left time: 239.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0728928 Vali Loss: 0.0753763 Test Loss: 0.0805926\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0773584\n",
      "\tspeed: 0.0425s/iter; left time: 576.3701s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719035\n",
      "\tspeed: 0.0231s/iter; left time: 311.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0729117 Vali Loss: 0.0754172 Test Loss: 0.0805385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0723396\n",
      "\tspeed: 0.0413s/iter; left time: 551.6058s\n",
      "\titers: 200, epoch: 41 | loss: 0.0712304\n",
      "\tspeed: 0.0176s/iter; left time: 232.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0729427 Vali Loss: 0.0753424 Test Loss: 0.0805553\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678918480873108, rmse:0.13667084276676178, mae:0.08051890879869461, rse:0.5167672038078308\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446110\n",
      "\tspeed: 0.0221s/iter; left time: 493.8308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1253999\n",
      "\tspeed: 0.0199s/iter; left time: 441.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1496909 Vali Loss: 0.1045320 Test Loss: 0.1075368\n",
      "Validation loss decreased (inf --> 0.104532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924727\n",
      "\tspeed: 0.0412s/iter; left time: 910.6740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894741\n",
      "\tspeed: 0.0178s/iter; left time: 390.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0954484 Vali Loss: 0.0817993 Test Loss: 0.0867445\n",
      "Validation loss decreased (0.104532 --> 0.081799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0847295\n",
      "\tspeed: 0.0402s/iter; left time: 878.0263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0820517\n",
      "\tspeed: 0.0180s/iter; left time: 391.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0846861 Vali Loss: 0.0795831 Test Loss: 0.0841799\n",
      "Validation loss decreased (0.081799 --> 0.079583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826818\n",
      "\tspeed: 0.0404s/iter; left time: 873.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826001\n",
      "\tspeed: 0.0179s/iter; left time: 386.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823463 Vali Loss: 0.0784222 Test Loss: 0.0830313\n",
      "Validation loss decreased (0.079583 --> 0.078422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0834706\n",
      "\tspeed: 0.0389s/iter; left time: 833.0787s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793772\n",
      "\tspeed: 0.0177s/iter; left time: 376.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0808059 Vali Loss: 0.0778977 Test Loss: 0.0820265\n",
      "Validation loss decreased (0.078422 --> 0.077898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793130\n",
      "\tspeed: 0.0408s/iter; left time: 863.3459s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798471\n",
      "\tspeed: 0.0182s/iter; left time: 382.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0797353 Vali Loss: 0.0771687 Test Loss: 0.0820218\n",
      "Validation loss decreased (0.077898 --> 0.077169).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792806\n",
      "\tspeed: 0.0394s/iter; left time: 825.4901s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804888\n",
      "\tspeed: 0.0179s/iter; left time: 373.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0788949 Vali Loss: 0.0769688 Test Loss: 0.0814737\n",
      "Validation loss decreased (0.077169 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805822\n",
      "\tspeed: 0.0417s/iter; left time: 865.1671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799717\n",
      "\tspeed: 0.0187s/iter; left time: 385.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0782915 Vali Loss: 0.0768342 Test Loss: 0.0813357\n",
      "Validation loss decreased (0.076969 --> 0.076834).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787869\n",
      "\tspeed: 0.0384s/iter; left time: 787.5092s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796126\n",
      "\tspeed: 0.0176s/iter; left time: 358.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777337 Vali Loss: 0.0765885 Test Loss: 0.0811092\n",
      "Validation loss decreased (0.076834 --> 0.076589).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0715174\n",
      "\tspeed: 0.0388s/iter; left time: 786.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0793800\n",
      "\tspeed: 0.0177s/iter; left time: 358.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0773026 Vali Loss: 0.0766290 Test Loss: 0.0812185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754477\n",
      "\tspeed: 0.0381s/iter; left time: 764.6416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789837\n",
      "\tspeed: 0.0178s/iter; left time: 354.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0767757 Vali Loss: 0.0764785 Test Loss: 0.0808268\n",
      "Validation loss decreased (0.076589 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715470\n",
      "\tspeed: 0.0443s/iter; left time: 879.6698s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762711\n",
      "\tspeed: 0.0199s/iter; left time: 392.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0764457 Vali Loss: 0.0764530 Test Loss: 0.0807678\n",
      "Validation loss decreased (0.076479 --> 0.076453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757492\n",
      "\tspeed: 0.0450s/iter; left time: 883.5416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821893\n",
      "\tspeed: 0.0204s/iter; left time: 397.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0761522 Vali Loss: 0.0763963 Test Loss: 0.0806580\n",
      "Validation loss decreased (0.076453 --> 0.076396).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764003\n",
      "\tspeed: 0.0461s/iter; left time: 894.1181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738080\n",
      "\tspeed: 0.0196s/iter; left time: 378.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0758944 Vali Loss: 0.0761132 Test Loss: 0.0809184\n",
      "Validation loss decreased (0.076396 --> 0.076113).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746748\n",
      "\tspeed: 0.0406s/iter; left time: 778.9004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0724435\n",
      "\tspeed: 0.0194s/iter; left time: 370.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0755759 Vali Loss: 0.0764618 Test Loss: 0.0805427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719663\n",
      "\tspeed: 0.0390s/iter; left time: 737.9347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0697170\n",
      "\tspeed: 0.0178s/iter; left time: 335.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0753819 Vali Loss: 0.0761848 Test Loss: 0.0806028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727296\n",
      "\tspeed: 0.0406s/iter; left time: 760.1802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727161\n",
      "\tspeed: 0.0177s/iter; left time: 330.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0750679 Vali Loss: 0.0762574 Test Loss: 0.0805783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725658\n",
      "\tspeed: 0.0381s/iter; left time: 703.8773s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764599\n",
      "\tspeed: 0.0178s/iter; left time: 327.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0748732 Vali Loss: 0.0761443 Test Loss: 0.0805745\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0747242\n",
      "\tspeed: 0.0466s/iter; left time: 851.3817s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744604\n",
      "\tspeed: 0.0214s/iter; left time: 388.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0746945 Vali Loss: 0.0761027 Test Loss: 0.0805595\n",
      "Validation loss decreased (0.076113 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739140\n",
      "\tspeed: 0.0443s/iter; left time: 798.5066s\n",
      "\titers: 200, epoch: 20 | loss: 0.0799948\n",
      "\tspeed: 0.0225s/iter; left time: 403.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0745287 Vali Loss: 0.0761509 Test Loss: 0.0804114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0718822\n",
      "\tspeed: 0.0403s/iter; left time: 719.0455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0686560\n",
      "\tspeed: 0.0197s/iter; left time: 348.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0743691 Vali Loss: 0.0761282 Test Loss: 0.0804886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756082\n",
      "\tspeed: 0.0382s/iter; left time: 671.8549s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743395\n",
      "\tspeed: 0.0176s/iter; left time: 307.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0742769 Vali Loss: 0.0762186 Test Loss: 0.0808756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802817\n",
      "\tspeed: 0.0395s/iter; left time: 686.2851s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747382\n",
      "\tspeed: 0.0194s/iter; left time: 334.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0740906 Vali Loss: 0.0761006 Test Loss: 0.0809374\n",
      "Validation loss decreased (0.076103 --> 0.076101).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0721726\n",
      "\tspeed: 0.0388s/iter; left time: 665.4127s\n",
      "\titers: 200, epoch: 24 | loss: 0.0764399\n",
      "\tspeed: 0.0179s/iter; left time: 305.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0739739 Vali Loss: 0.0763183 Test Loss: 0.0805535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0713016\n",
      "\tspeed: 0.0377s/iter; left time: 638.2618s\n",
      "\titers: 200, epoch: 25 | loss: 0.0763350\n",
      "\tspeed: 0.0177s/iter; left time: 297.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0739049 Vali Loss: 0.0761669 Test Loss: 0.0804498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704296\n",
      "\tspeed: 0.0396s/iter; left time: 661.2235s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738422\n",
      "\tspeed: 0.0211s/iter; left time: 350.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0737833 Vali Loss: 0.0761739 Test Loss: 0.0806323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736066\n",
      "\tspeed: 0.0397s/iter; left time: 654.4782s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724954\n",
      "\tspeed: 0.0181s/iter; left time: 295.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0737053 Vali Loss: 0.0761146 Test Loss: 0.0805858\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708030\n",
      "\tspeed: 0.0417s/iter; left time: 678.2211s\n",
      "\titers: 200, epoch: 28 | loss: 0.0726346\n",
      "\tspeed: 0.0224s/iter; left time: 361.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0736342 Vali Loss: 0.0761730 Test Loss: 0.0805067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0736985\n",
      "\tspeed: 0.0394s/iter; left time: 631.5932s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757324\n",
      "\tspeed: 0.0175s/iter; left time: 279.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0736515 Vali Loss: 0.0762277 Test Loss: 0.0805709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0738680\n",
      "\tspeed: 0.0382s/iter; left time: 604.3951s\n",
      "\titers: 200, epoch: 30 | loss: 0.0754899\n",
      "\tspeed: 0.0175s/iter; left time: 275.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0735729 Vali Loss: 0.0761100 Test Loss: 0.0804291\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0771352\n",
      "\tspeed: 0.0394s/iter; left time: 614.2084s\n",
      "\titers: 200, epoch: 31 | loss: 0.0740414\n",
      "\tspeed: 0.0175s/iter; left time: 271.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0734717 Vali Loss: 0.0763483 Test Loss: 0.0805765\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0702331\n",
      "\tspeed: 0.0375s/iter; left time: 576.6210s\n",
      "\titers: 200, epoch: 32 | loss: 0.0758914\n",
      "\tspeed: 0.0181s/iter; left time: 276.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0734446 Vali Loss: 0.0761305 Test Loss: 0.0804661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723481\n",
      "\tspeed: 0.0372s/iter; left time: 563.5045s\n",
      "\titers: 200, epoch: 33 | loss: 0.0725820\n",
      "\tspeed: 0.0176s/iter; left time: 264.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0733762 Vali Loss: 0.0761667 Test Loss: 0.0805655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018912920728325844, rmse:0.13752426207065582, mae:0.08093737810850143, rse:0.5199940204620361\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:21.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423216\n",
      "\tspeed: 0.0461s/iter; left time: 1023.0411s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238418\n",
      "\tspeed: 0.0180s/iter; left time: 397.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1487374 Vali Loss: 0.1077961 Test Loss: 0.1103803\n",
      "Validation loss decreased (inf --> 0.107796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939423\n",
      "\tspeed: 0.0391s/iter; left time: 860.2094s\n",
      "\titers: 200, epoch: 2 | loss: 0.0893055\n",
      "\tspeed: 0.0179s/iter; left time: 392.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0994013 Vali Loss: 0.0860546 Test Loss: 0.0906314\n",
      "Validation loss decreased (0.107796 --> 0.086055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925718\n",
      "\tspeed: 0.0395s/iter; left time: 859.8668s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874189\n",
      "\tspeed: 0.0179s/iter; left time: 387.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0890840 Vali Loss: 0.0842465 Test Loss: 0.0879599\n",
      "Validation loss decreased (0.086055 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881069\n",
      "\tspeed: 0.0411s/iter; left time: 885.5673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0894828\n",
      "\tspeed: 0.0193s/iter; left time: 413.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0864151 Vali Loss: 0.0837157 Test Loss: 0.0879383\n",
      "Validation loss decreased (0.084247 --> 0.083716).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829716\n",
      "\tspeed: 0.0404s/iter; left time: 860.1269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826994\n",
      "\tspeed: 0.0179s/iter; left time: 379.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0848429 Vali Loss: 0.0827259 Test Loss: 0.0875212\n",
      "Validation loss decreased (0.083716 --> 0.082726).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817767\n",
      "\tspeed: 0.0409s/iter; left time: 861.8152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862948\n",
      "\tspeed: 0.0193s/iter; left time: 404.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0836924 Vali Loss: 0.0822996 Test Loss: 0.0872402\n",
      "Validation loss decreased (0.082726 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838116\n",
      "\tspeed: 0.0392s/iter; left time: 818.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848943\n",
      "\tspeed: 0.0179s/iter; left time: 370.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0827538 Vali Loss: 0.0820797 Test Loss: 0.0871094\n",
      "Validation loss decreased (0.082300 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825785\n",
      "\tspeed: 0.0387s/iter; left time: 799.7960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793753\n",
      "\tspeed: 0.0179s/iter; left time: 366.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0820263 Vali Loss: 0.0822556 Test Loss: 0.0876831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795462\n",
      "\tspeed: 0.0425s/iter; left time: 868.7222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789129\n",
      "\tspeed: 0.0228s/iter; left time: 464.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0815050 Vali Loss: 0.0815729 Test Loss: 0.0867696\n",
      "Validation loss decreased (0.082080 --> 0.081573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811481\n",
      "\tspeed: 0.0412s/iter; left time: 831.2948s\n",
      "\titers: 200, epoch: 10 | loss: 0.0825071\n",
      "\tspeed: 0.0183s/iter; left time: 368.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0810133 Vali Loss: 0.0817944 Test Loss: 0.0868367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0821963\n",
      "\tspeed: 0.0398s/iter; left time: 794.0686s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761625\n",
      "\tspeed: 0.0208s/iter; left time: 413.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0805028 Vali Loss: 0.0818734 Test Loss: 0.0874601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0790672\n",
      "\tspeed: 0.0383s/iter; left time: 756.6160s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799741\n",
      "\tspeed: 0.0178s/iter; left time: 350.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0801906 Vali Loss: 0.0817134 Test Loss: 0.0878104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782696\n",
      "\tspeed: 0.0420s/iter; left time: 820.3538s\n",
      "\titers: 200, epoch: 13 | loss: 0.0798471\n",
      "\tspeed: 0.0206s/iter; left time: 400.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0798508 Vali Loss: 0.0815302 Test Loss: 0.0871841\n",
      "Validation loss decreased (0.081573 --> 0.081530).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773299\n",
      "\tspeed: 0.0454s/iter; left time: 876.7918s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797019\n",
      "\tspeed: 0.0185s/iter; left time: 354.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0794928 Vali Loss: 0.0817144 Test Loss: 0.0871146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0791878\n",
      "\tspeed: 0.0386s/iter; left time: 736.6542s\n",
      "\titers: 200, epoch: 15 | loss: 0.0850011\n",
      "\tspeed: 0.0180s/iter; left time: 341.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0791677 Vali Loss: 0.0815923 Test Loss: 0.0870508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0806760\n",
      "\tspeed: 0.0414s/iter; left time: 779.9618s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801392\n",
      "\tspeed: 0.0179s/iter; left time: 336.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0789298 Vali Loss: 0.0816933 Test Loss: 0.0873272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782162\n",
      "\tspeed: 0.0394s/iter; left time: 734.2989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770024\n",
      "\tspeed: 0.0182s/iter; left time: 337.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0786994 Vali Loss: 0.0814644 Test Loss: 0.0871423\n",
      "Validation loss decreased (0.081530 --> 0.081464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750689\n",
      "\tspeed: 0.0393s/iter; left time: 723.2489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0791912\n",
      "\tspeed: 0.0179s/iter; left time: 326.9713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0784913 Vali Loss: 0.0817581 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772508\n",
      "\tspeed: 0.0385s/iter; left time: 700.3244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0785425\n",
      "\tspeed: 0.0179s/iter; left time: 323.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0782302 Vali Loss: 0.0813190 Test Loss: 0.0870724\n",
      "Validation loss decreased (0.081464 --> 0.081319).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0796085\n",
      "\tspeed: 0.0418s/iter; left time: 750.8243s\n",
      "\titers: 200, epoch: 20 | loss: 0.0747003\n",
      "\tspeed: 0.0179s/iter; left time: 319.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0780742 Vali Loss: 0.0815029 Test Loss: 0.0872391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0798976\n",
      "\tspeed: 0.0385s/iter; left time: 682.9507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783784\n",
      "\tspeed: 0.0205s/iter; left time: 360.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0778642 Vali Loss: 0.0814129 Test Loss: 0.0872288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798767\n",
      "\tspeed: 0.0401s/iter; left time: 701.9505s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798330\n",
      "\tspeed: 0.0185s/iter; left time: 323.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0777549 Vali Loss: 0.0814658 Test Loss: 0.0875085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0734261\n",
      "\tspeed: 0.0395s/iter; left time: 683.3050s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779886\n",
      "\tspeed: 0.0181s/iter; left time: 311.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0775775 Vali Loss: 0.0814620 Test Loss: 0.0873106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789265\n",
      "\tspeed: 0.0384s/iter; left time: 655.8847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768867\n",
      "\tspeed: 0.0181s/iter; left time: 306.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0774439 Vali Loss: 0.0814374 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0773396\n",
      "\tspeed: 0.0389s/iter; left time: 655.6546s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760351\n",
      "\tspeed: 0.0185s/iter; left time: 310.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0773691 Vali Loss: 0.0813845 Test Loss: 0.0871841\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796533\n",
      "\tspeed: 0.0399s/iter; left time: 662.7052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0774103\n",
      "\tspeed: 0.0180s/iter; left time: 297.4635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0771835 Vali Loss: 0.0814663 Test Loss: 0.0871791\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742327\n",
      "\tspeed: 0.0372s/iter; left time: 610.6163s\n",
      "\titers: 200, epoch: 27 | loss: 0.0805335\n",
      "\tspeed: 0.0178s/iter; left time: 289.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0771259 Vali Loss: 0.0814744 Test Loss: 0.0872126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0766790\n",
      "\tspeed: 0.0381s/iter; left time: 616.6928s\n",
      "\titers: 200, epoch: 28 | loss: 0.0775495\n",
      "\tspeed: 0.0179s/iter; left time: 288.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0770471 Vali Loss: 0.0813009 Test Loss: 0.0870816\n",
      "Validation loss decreased (0.081319 --> 0.081301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0757094\n",
      "\tspeed: 0.0408s/iter; left time: 650.4701s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760654\n",
      "\tspeed: 0.0180s/iter; left time: 285.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0769555 Vali Loss: 0.0812396 Test Loss: 0.0871117\n",
      "Validation loss decreased (0.081301 --> 0.081240).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0767229\n",
      "\tspeed: 0.0404s/iter; left time: 635.6768s\n",
      "\titers: 200, epoch: 30 | loss: 0.0786787\n",
      "\tspeed: 0.0180s/iter; left time: 282.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0768584 Vali Loss: 0.0815030 Test Loss: 0.0869776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778194\n",
      "\tspeed: 0.0383s/iter; left time: 594.6005s\n",
      "\titers: 200, epoch: 31 | loss: 0.0778298\n",
      "\tspeed: 0.0178s/iter; left time: 274.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0767776 Vali Loss: 0.0813545 Test Loss: 0.0871082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0754501\n",
      "\tspeed: 0.0407s/iter; left time: 622.4346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764830\n",
      "\tspeed: 0.0179s/iter; left time: 272.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0767559 Vali Loss: 0.0812562 Test Loss: 0.0870397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0755639\n",
      "\tspeed: 0.0414s/iter; left time: 624.0858s\n",
      "\titers: 200, epoch: 33 | loss: 0.0777980\n",
      "\tspeed: 0.0204s/iter; left time: 305.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0767118 Vali Loss: 0.0814427 Test Loss: 0.0868835\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754135\n",
      "\tspeed: 0.0393s/iter; left time: 583.4103s\n",
      "\titers: 200, epoch: 34 | loss: 0.0785940\n",
      "\tspeed: 0.0180s/iter; left time: 264.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0766594 Vali Loss: 0.0814381 Test Loss: 0.0870054\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776752\n",
      "\tspeed: 0.0433s/iter; left time: 633.2336s\n",
      "\titers: 200, epoch: 35 | loss: 0.0752889\n",
      "\tspeed: 0.0219s/iter; left time: 318.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0766568 Vali Loss: 0.0813767 Test Loss: 0.0870404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0754985\n",
      "\tspeed: 0.0434s/iter; left time: 624.6602s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774933\n",
      "\tspeed: 0.0183s/iter; left time: 261.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0765844 Vali Loss: 0.0814429 Test Loss: 0.0870331\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0767131\n",
      "\tspeed: 0.0404s/iter; left time: 572.0861s\n",
      "\titers: 200, epoch: 37 | loss: 0.0771547\n",
      "\tspeed: 0.0180s/iter; left time: 253.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0765541 Vali Loss: 0.0814060 Test Loss: 0.0868510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0774624\n",
      "\tspeed: 0.0379s/iter; left time: 528.8624s\n",
      "\titers: 200, epoch: 38 | loss: 0.0765092\n",
      "\tspeed: 0.0180s/iter; left time: 249.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0765164 Vali Loss: 0.0814066 Test Loss: 0.0870728\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0766422\n",
      "\tspeed: 0.0387s/iter; left time: 531.8544s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785535\n",
      "\tspeed: 0.0204s/iter; left time: 278.2109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0765010 Vali Loss: 0.0812689 Test Loss: 0.0869280\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02109212428331375, rmse:0.14523127675056458, mae:0.08711174875497818, rse:0.5496454238891602\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1449288\n",
      "\tspeed: 0.0237s/iter; left time: 527.1092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275386\n",
      "\tspeed: 0.0189s/iter; left time: 416.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1514120 Vali Loss: 0.1083481 Test Loss: 0.1111070\n",
      "Validation loss decreased (inf --> 0.108348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964038\n",
      "\tspeed: 0.0406s/iter; left time: 891.5062s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950081\n",
      "\tspeed: 0.0182s/iter; left time: 397.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0995364 Vali Loss: 0.0861125 Test Loss: 0.0903715\n",
      "Validation loss decreased (0.108348 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903619\n",
      "\tspeed: 0.0439s/iter; left time: 955.2516s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892618\n",
      "\tspeed: 0.0180s/iter; left time: 388.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0891035 Vali Loss: 0.0844135 Test Loss: 0.0887872\n",
      "Validation loss decreased (0.086113 --> 0.084413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915347\n",
      "\tspeed: 0.0401s/iter; left time: 863.5181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848709\n",
      "\tspeed: 0.0179s/iter; left time: 384.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0866611 Vali Loss: 0.0836004 Test Loss: 0.0878691\n",
      "Validation loss decreased (0.084413 --> 0.083600).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874841\n",
      "\tspeed: 0.0425s/iter; left time: 906.4325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0879956\n",
      "\tspeed: 0.0203s/iter; left time: 430.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0851195 Vali Loss: 0.0828480 Test Loss: 0.0873044\n",
      "Validation loss decreased (0.083600 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839838\n",
      "\tspeed: 0.0420s/iter; left time: 885.0919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821068\n",
      "\tspeed: 0.0179s/iter; left time: 375.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0839008 Vali Loss: 0.0822585 Test Loss: 0.0870409\n",
      "Validation loss decreased (0.082848 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821517\n",
      "\tspeed: 0.0422s/iter; left time: 879.5556s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844231\n",
      "\tspeed: 0.0184s/iter; left time: 381.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0830070 Vali Loss: 0.0822771 Test Loss: 0.0872937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803021\n",
      "\tspeed: 0.0392s/iter; left time: 809.3280s\n",
      "\titers: 200, epoch: 8 | loss: 0.0812417\n",
      "\tspeed: 0.0180s/iter; left time: 368.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0822285 Vali Loss: 0.0821905 Test Loss: 0.0874587\n",
      "Validation loss decreased (0.082259 --> 0.082190).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808798\n",
      "\tspeed: 0.0417s/iter; left time: 851.4096s\n",
      "\titers: 200, epoch: 9 | loss: 0.0797862\n",
      "\tspeed: 0.0180s/iter; left time: 364.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0815818 Vali Loss: 0.0818749 Test Loss: 0.0877508\n",
      "Validation loss decreased (0.082190 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799902\n",
      "\tspeed: 0.0440s/iter; left time: 888.7792s\n",
      "\titers: 200, epoch: 10 | loss: 0.0788336\n",
      "\tspeed: 0.0186s/iter; left time: 372.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0810375 Vali Loss: 0.0815037 Test Loss: 0.0872590\n",
      "Validation loss decreased (0.081875 --> 0.081504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795319\n",
      "\tspeed: 0.0391s/iter; left time: 780.5435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794025\n",
      "\tspeed: 0.0180s/iter; left time: 357.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0806232 Vali Loss: 0.0819767 Test Loss: 0.0874538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821759\n",
      "\tspeed: 0.0420s/iter; left time: 829.3506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778371\n",
      "\tspeed: 0.0198s/iter; left time: 388.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0801564 Vali Loss: 0.0814462 Test Loss: 0.0873747\n",
      "Validation loss decreased (0.081504 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842263\n",
      "\tspeed: 0.0417s/iter; left time: 814.4622s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809889\n",
      "\tspeed: 0.0182s/iter; left time: 352.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0797804 Vali Loss: 0.0816962 Test Loss: 0.0877320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0751703\n",
      "\tspeed: 0.0421s/iter; left time: 811.9402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763598\n",
      "\tspeed: 0.0207s/iter; left time: 397.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0794535 Vali Loss: 0.0814359 Test Loss: 0.0876379\n",
      "Validation loss decreased (0.081446 --> 0.081436).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0789681\n",
      "\tspeed: 0.0400s/iter; left time: 763.7075s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766760\n",
      "\tspeed: 0.0180s/iter; left time: 342.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0791543 Vali Loss: 0.0809303 Test Loss: 0.0873543\n",
      "Validation loss decreased (0.081436 --> 0.080930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803362\n",
      "\tspeed: 0.0399s/iter; left time: 753.0844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774697\n",
      "\tspeed: 0.0182s/iter; left time: 341.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0788688 Vali Loss: 0.0816369 Test Loss: 0.0876021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0793249\n",
      "\tspeed: 0.0407s/iter; left time: 757.9852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790591\n",
      "\tspeed: 0.0200s/iter; left time: 370.2881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0786432 Vali Loss: 0.0810094 Test Loss: 0.0877025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760391\n",
      "\tspeed: 0.0409s/iter; left time: 753.7718s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795988\n",
      "\tspeed: 0.0204s/iter; left time: 374.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0784823 Vali Loss: 0.0814446 Test Loss: 0.0877750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0790216\n",
      "\tspeed: 0.0412s/iter; left time: 749.6815s\n",
      "\titers: 200, epoch: 19 | loss: 0.0839612\n",
      "\tspeed: 0.0182s/iter; left time: 328.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0782333 Vali Loss: 0.0810218 Test Loss: 0.0872108\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764522\n",
      "\tspeed: 0.0399s/iter; left time: 716.8600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756822\n",
      "\tspeed: 0.0180s/iter; left time: 321.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0780890 Vali Loss: 0.0807879 Test Loss: 0.0873520\n",
      "Validation loss decreased (0.080930 --> 0.080788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766985\n",
      "\tspeed: 0.0389s/iter; left time: 689.3043s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789640\n",
      "\tspeed: 0.0181s/iter; left time: 319.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0778664 Vali Loss: 0.0809161 Test Loss: 0.0873467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0807523\n",
      "\tspeed: 0.0377s/iter; left time: 660.2344s\n",
      "\titers: 200, epoch: 22 | loss: 0.0760726\n",
      "\tspeed: 0.0180s/iter; left time: 313.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0777179 Vali Loss: 0.0807275 Test Loss: 0.0872172\n",
      "Validation loss decreased (0.080788 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772732\n",
      "\tspeed: 0.0393s/iter; left time: 680.4143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791408\n",
      "\tspeed: 0.0183s/iter; left time: 314.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0775855 Vali Loss: 0.0809376 Test Loss: 0.0875355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0792675\n",
      "\tspeed: 0.0397s/iter; left time: 677.4338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0806082\n",
      "\tspeed: 0.0195s/iter; left time: 331.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0774288 Vali Loss: 0.0809761 Test Loss: 0.0873712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786049\n",
      "\tspeed: 0.0395s/iter; left time: 665.1974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782466\n",
      "\tspeed: 0.0180s/iter; left time: 301.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0773741 Vali Loss: 0.0809126 Test Loss: 0.0873566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797315\n",
      "\tspeed: 0.0417s/iter; left time: 694.0438s\n",
      "\titers: 200, epoch: 26 | loss: 0.0777119\n",
      "\tspeed: 0.0210s/iter; left time: 347.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0772352 Vali Loss: 0.0808808 Test Loss: 0.0872862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776568\n",
      "\tspeed: 0.0410s/iter; left time: 671.8824s\n",
      "\titers: 200, epoch: 27 | loss: 0.0756376\n",
      "\tspeed: 0.0179s/iter; left time: 291.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0771665 Vali Loss: 0.0809822 Test Loss: 0.0873216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762978\n",
      "\tspeed: 0.0376s/iter; left time: 608.6421s\n",
      "\titers: 200, epoch: 28 | loss: 0.0765274\n",
      "\tspeed: 0.0178s/iter; left time: 286.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0770732 Vali Loss: 0.0810418 Test Loss: 0.0872446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0719681\n",
      "\tspeed: 0.0379s/iter; left time: 605.4086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788069\n",
      "\tspeed: 0.0182s/iter; left time: 288.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0769719 Vali Loss: 0.0809646 Test Loss: 0.0873285\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789183\n",
      "\tspeed: 0.0404s/iter; left time: 635.3260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782066\n",
      "\tspeed: 0.0180s/iter; left time: 281.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0769468 Vali Loss: 0.0807314 Test Loss: 0.0870685\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808447\n",
      "\tspeed: 0.0380s/iter; left time: 589.4340s\n",
      "\titers: 200, epoch: 31 | loss: 0.0765283\n",
      "\tspeed: 0.0181s/iter; left time: 278.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0768495 Vali Loss: 0.0806943 Test Loss: 0.0872749\n",
      "Validation loss decreased (0.080727 --> 0.080694).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761573\n",
      "\tspeed: 0.0438s/iter; left time: 668.9799s\n",
      "\titers: 200, epoch: 32 | loss: 0.0757153\n",
      "\tspeed: 0.0182s/iter; left time: 276.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0768053 Vali Loss: 0.0808349 Test Loss: 0.0872295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775786\n",
      "\tspeed: 0.0419s/iter; left time: 631.6551s\n",
      "\titers: 200, epoch: 33 | loss: 0.0767409\n",
      "\tspeed: 0.0190s/iter; left time: 283.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0767355 Vali Loss: 0.0808667 Test Loss: 0.0871681\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757100\n",
      "\tspeed: 0.0388s/iter; left time: 576.0192s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774558\n",
      "\tspeed: 0.0180s/iter; left time: 265.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0767543 Vali Loss: 0.0808929 Test Loss: 0.0871076\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778735\n",
      "\tspeed: 0.0407s/iter; left time: 594.7343s\n",
      "\titers: 200, epoch: 35 | loss: 0.0775153\n",
      "\tspeed: 0.0189s/iter; left time: 274.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0766747 Vali Loss: 0.0807420 Test Loss: 0.0872145\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0747025\n",
      "\tspeed: 0.0386s/iter; left time: 555.6579s\n",
      "\titers: 200, epoch: 36 | loss: 0.0751638\n",
      "\tspeed: 0.0182s/iter; left time: 260.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766659 Vali Loss: 0.0808573 Test Loss: 0.0873167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0759581\n",
      "\tspeed: 0.0399s/iter; left time: 565.5094s\n",
      "\titers: 200, epoch: 37 | loss: 0.0804632\n",
      "\tspeed: 0.0189s/iter; left time: 265.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0766658 Vali Loss: 0.0808365 Test Loss: 0.0872206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0759550\n",
      "\tspeed: 0.0397s/iter; left time: 554.0831s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777812\n",
      "\tspeed: 0.0181s/iter; left time: 251.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766106 Vali Loss: 0.0808862 Test Loss: 0.0872444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806029\n",
      "\tspeed: 0.0399s/iter; left time: 548.0181s\n",
      "\titers: 200, epoch: 39 | loss: 0.0741781\n",
      "\tspeed: 0.0183s/iter; left time: 248.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0765723 Vali Loss: 0.0807692 Test Loss: 0.0871365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0759363\n",
      "\tspeed: 0.0406s/iter; left time: 548.8343s\n",
      "\titers: 200, epoch: 40 | loss: 0.0809224\n",
      "\tspeed: 0.0184s/iter; left time: 246.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0764995 Vali Loss: 0.0808269 Test Loss: 0.0872263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0751095\n",
      "\tspeed: 0.0400s/iter; left time: 531.8427s\n",
      "\titers: 200, epoch: 41 | loss: 0.0726962\n",
      "\tspeed: 0.0206s/iter; left time: 271.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0764408 Vali Loss: 0.0807421 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020868754014372826, rmse:0.14446021616458893, mae:0.08727487176656723, rse:0.5467272400856018\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:06.28s\n",
      "Intermediate time for IT: 00h:27m:20.07s\n",
      "Total time: 02h:04m:37.46s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1448  0.0877\n",
       "        96            0.0377  0.1941  0.1283\n",
       "        168           0.0393  0.1981  0.1339\n",
       "ES      24            0.0098  0.0988  0.0592\n",
       "        96            0.0185  0.1361  0.0861\n",
       "        168           0.0207  0.1439  0.0916\n",
       "FR      24            0.0100  0.1000  0.0548\n",
       "        96            0.0193  0.1390  0.0808\n",
       "        168           0.0213  0.1460  0.0868\n",
       "GB      24            0.0250  0.1582  0.0996\n",
       "        96            0.0418  0.2045  0.1395\n",
       "        168           0.0447  0.2115  0.1468\n",
       "IT      24            0.0101  0.1004  0.0567\n",
       "        96            0.0188  0.1371  0.0807\n",
       "        168           0.0210  0.1448  0.0872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_512.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1321916\n",
      "\tspeed: 0.0728s/iter; left time: 1615.8326s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232382\n",
      "\tspeed: 0.0406s/iter; left time: 897.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 223 | Train Loss: 0.1358311 Vali Loss: 0.1260650 Test Loss: 0.1311714\n",
      "Validation loss decreased (inf --> 0.126065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869880\n",
      "\tspeed: 0.0734s/iter; left time: 1612.4742s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813422\n",
      "\tspeed: 0.0409s/iter; left time: 895.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0881644 Vali Loss: 0.0929616 Test Loss: 0.0951003\n",
      "Validation loss decreased (0.126065 --> 0.092962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0751677\n",
      "\tspeed: 0.0736s/iter; left time: 1600.3763s\n",
      "\titers: 200, epoch: 3 | loss: 0.0759952\n",
      "\tspeed: 0.0407s/iter; left time: 881.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0788886 Vali Loss: 0.0895641 Test Loss: 0.0921896\n",
      "Validation loss decreased (0.092962 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0797120\n",
      "\tspeed: 0.0735s/iter; left time: 1581.5937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827803\n",
      "\tspeed: 0.0406s/iter; left time: 870.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0885940 Test Loss: 0.0909947\n",
      "Validation loss decreased (0.089564 --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754906\n",
      "\tspeed: 0.0734s/iter; left time: 1563.9432s\n",
      "\titers: 200, epoch: 5 | loss: 0.0719414\n",
      "\tspeed: 0.0407s/iter; left time: 862.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0754300 Vali Loss: 0.0888515 Test Loss: 0.0910340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0806468\n",
      "\tspeed: 0.0728s/iter; left time: 1534.8053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0765860\n",
      "\tspeed: 0.0419s/iter; left time: 879.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0744171 Vali Loss: 0.0882697 Test Loss: 0.0900209\n",
      "Validation loss decreased (0.088594 --> 0.088270).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731639\n",
      "\tspeed: 0.0734s/iter; left time: 1530.8374s\n",
      "\titers: 200, epoch: 7 | loss: 0.0712213\n",
      "\tspeed: 0.0409s/iter; left time: 848.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0736002 Vali Loss: 0.0882780 Test Loss: 0.0900862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0723158\n",
      "\tspeed: 0.0753s/iter; left time: 1553.8959s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739186\n",
      "\tspeed: 0.0408s/iter; left time: 838.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0730063 Vali Loss: 0.0872233 Test Loss: 0.0892780\n",
      "Validation loss decreased (0.088270 --> 0.087223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0720197\n",
      "\tspeed: 0.0736s/iter; left time: 1502.4429s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719693\n",
      "\tspeed: 0.0413s/iter; left time: 839.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0725142 Vali Loss: 0.0873214 Test Loss: 0.0893505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0731357\n",
      "\tspeed: 0.0740s/iter; left time: 1493.4336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688657\n",
      "\tspeed: 0.0408s/iter; left time: 819.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0721618 Vali Loss: 0.0870030 Test Loss: 0.0891919\n",
      "Validation loss decreased (0.087223 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0748033\n",
      "\tspeed: 0.0759s/iter; left time: 1515.2200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748860\n",
      "\tspeed: 0.0417s/iter; left time: 829.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0719345 Vali Loss: 0.0867141 Test Loss: 0.0886792\n",
      "Validation loss decreased (0.087003 --> 0.086714).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0690829\n",
      "\tspeed: 0.0745s/iter; left time: 1470.9406s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754002\n",
      "\tspeed: 0.0429s/iter; left time: 842.0450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0716603 Vali Loss: 0.0863255 Test Loss: 0.0886338\n",
      "Validation loss decreased (0.086714 --> 0.086325).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659539\n",
      "\tspeed: 0.0744s/iter; left time: 1452.1265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692490\n",
      "\tspeed: 0.0412s/iter; left time: 799.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713583 Vali Loss: 0.0861463 Test Loss: 0.0882640\n",
      "Validation loss decreased (0.086325 --> 0.086146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732110\n",
      "\tspeed: 0.0779s/iter; left time: 1503.5926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664269\n",
      "\tspeed: 0.0411s/iter; left time: 788.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0712298 Vali Loss: 0.0862440 Test Loss: 0.0883915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0712718\n",
      "\tspeed: 0.0763s/iter; left time: 1455.3356s\n",
      "\titers: 200, epoch: 15 | loss: 0.0668620\n",
      "\tspeed: 0.0410s/iter; left time: 777.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0710672 Vali Loss: 0.0864471 Test Loss: 0.0887082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0729668\n",
      "\tspeed: 0.0740s/iter; left time: 1395.5402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0765959\n",
      "\tspeed: 0.0422s/iter; left time: 792.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0708319 Vali Loss: 0.0861513 Test Loss: 0.0883979\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704609\n",
      "\tspeed: 0.0735s/iter; left time: 1369.5178s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766587\n",
      "\tspeed: 0.0433s/iter; left time: 802.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707372 Vali Loss: 0.0861647 Test Loss: 0.0883205\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0681143\n",
      "\tspeed: 0.0750s/iter; left time: 1381.5339s\n",
      "\titers: 200, epoch: 18 | loss: 0.0640077\n",
      "\tspeed: 0.0409s/iter; left time: 749.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0706291 Vali Loss: 0.0860309 Test Loss: 0.0882354\n",
      "Validation loss decreased (0.086146 --> 0.086031).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720396\n",
      "\tspeed: 0.0783s/iter; left time: 1423.7136s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769060\n",
      "\tspeed: 0.0409s/iter; left time: 740.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0705093 Vali Loss: 0.0859334 Test Loss: 0.0882176\n",
      "Validation loss decreased (0.086031 --> 0.085933).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0715498\n",
      "\tspeed: 0.0772s/iter; left time: 1386.4974s\n",
      "\titers: 200, epoch: 20 | loss: 0.0696223\n",
      "\tspeed: 0.0410s/iter; left time: 732.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0704253 Vali Loss: 0.0860697 Test Loss: 0.0881779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699663\n",
      "\tspeed: 0.0728s/iter; left time: 1291.4193s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732786\n",
      "\tspeed: 0.0431s/iter; left time: 759.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0703514 Vali Loss: 0.0858988 Test Loss: 0.0881333\n",
      "Validation loss decreased (0.085933 --> 0.085899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0708477\n",
      "\tspeed: 0.0742s/iter; left time: 1300.1863s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705403\n",
      "\tspeed: 0.0415s/iter; left time: 722.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0702229 Vali Loss: 0.0858154 Test Loss: 0.0882537\n",
      "Validation loss decreased (0.085899 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0727449\n",
      "\tspeed: 0.0758s/iter; left time: 1310.7424s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709735\n",
      "\tspeed: 0.0411s/iter; left time: 705.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0702576 Vali Loss: 0.0857304 Test Loss: 0.0880756\n",
      "Validation loss decreased (0.085815 --> 0.085730).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739099\n",
      "\tspeed: 0.0758s/iter; left time: 1294.2116s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680970\n",
      "\tspeed: 0.0412s/iter; left time: 699.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0701341 Vali Loss: 0.0857846 Test Loss: 0.0882640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0694140\n",
      "\tspeed: 0.0753s/iter; left time: 1268.9373s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655354\n",
      "\tspeed: 0.0419s/iter; left time: 702.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0700403 Vali Loss: 0.0856874 Test Loss: 0.0880371\n",
      "Validation loss decreased (0.085730 --> 0.085687).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680513\n",
      "\tspeed: 0.0729s/iter; left time: 1211.8735s\n",
      "\titers: 200, epoch: 26 | loss: 0.0614008\n",
      "\tspeed: 0.0422s/iter; left time: 697.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0699876 Vali Loss: 0.0857602 Test Loss: 0.0880605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0681010\n",
      "\tspeed: 0.0737s/iter; left time: 1209.0005s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719286\n",
      "\tspeed: 0.0409s/iter; left time: 666.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699794 Vali Loss: 0.0856203 Test Loss: 0.0880215\n",
      "Validation loss decreased (0.085687 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0715455\n",
      "\tspeed: 0.0777s/iter; left time: 1257.7111s\n",
      "\titers: 200, epoch: 28 | loss: 0.0702468\n",
      "\tspeed: 0.0411s/iter; left time: 661.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0698950 Vali Loss: 0.0855330 Test Loss: 0.0880139\n",
      "Validation loss decreased (0.085620 --> 0.085533).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0714828\n",
      "\tspeed: 0.0763s/iter; left time: 1217.9411s\n",
      "\titers: 200, epoch: 29 | loss: 0.0706265\n",
      "\tspeed: 0.0408s/iter; left time: 647.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0698917 Vali Loss: 0.0855195 Test Loss: 0.0880248\n",
      "Validation loss decreased (0.085533 --> 0.085519).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0714619\n",
      "\tspeed: 0.0742s/iter; left time: 1168.2092s\n",
      "\titers: 200, epoch: 30 | loss: 0.0664505\n",
      "\tspeed: 0.0418s/iter; left time: 654.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0698095 Vali Loss: 0.0856531 Test Loss: 0.0880330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0732058\n",
      "\tspeed: 0.0729s/iter; left time: 1130.9088s\n",
      "\titers: 200, epoch: 31 | loss: 0.0680768\n",
      "\tspeed: 0.0425s/iter; left time: 655.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0698472 Vali Loss: 0.0855296 Test Loss: 0.0879514\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0710819\n",
      "\tspeed: 0.0745s/iter; left time: 1138.8016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0653720\n",
      "\tspeed: 0.0412s/iter; left time: 625.7304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0697666 Vali Loss: 0.0855339 Test Loss: 0.0879451\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689314\n",
      "\tspeed: 0.0769s/iter; left time: 1158.4537s\n",
      "\titers: 200, epoch: 33 | loss: 0.0689489\n",
      "\tspeed: 0.0411s/iter; left time: 614.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0697218 Vali Loss: 0.0855810 Test Loss: 0.0879584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0722149\n",
      "\tspeed: 0.0771s/iter; left time: 1144.5327s\n",
      "\titers: 200, epoch: 34 | loss: 0.0753755\n",
      "\tspeed: 0.0413s/iter; left time: 609.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0697024 Vali Loss: 0.0854558 Test Loss: 0.0879442\n",
      "Validation loss decreased (0.085519 --> 0.085456).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0695830\n",
      "\tspeed: 0.0736s/iter; left time: 1075.5888s\n",
      "\titers: 200, epoch: 35 | loss: 0.0714961\n",
      "\tspeed: 0.0434s/iter; left time: 630.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0696798 Vali Loss: 0.0855717 Test Loss: 0.0879177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0646781\n",
      "\tspeed: 0.0730s/iter; left time: 1051.0720s\n",
      "\titers: 200, epoch: 36 | loss: 0.0619496\n",
      "\tspeed: 0.0418s/iter; left time: 597.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0697064 Vali Loss: 0.0855166 Test Loss: 0.0879396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669930\n",
      "\tspeed: 0.0744s/iter; left time: 1054.2108s\n",
      "\titers: 200, epoch: 37 | loss: 0.0625971\n",
      "\tspeed: 0.0409s/iter; left time: 575.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0696672 Vali Loss: 0.0855014 Test Loss: 0.0879528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0678924\n",
      "\tspeed: 0.0749s/iter; left time: 1045.0660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0688178\n",
      "\tspeed: 0.0409s/iter; left time: 566.8978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696622 Vali Loss: 0.0855257 Test Loss: 0.0879750\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0701673\n",
      "\tspeed: 0.0754s/iter; left time: 1034.4748s\n",
      "\titers: 200, epoch: 39 | loss: 0.0690970\n",
      "\tspeed: 0.0415s/iter; left time: 565.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0696282 Vali Loss: 0.0855480 Test Loss: 0.0879980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0651396\n",
      "\tspeed: 0.0732s/iter; left time: 988.9090s\n",
      "\titers: 200, epoch: 40 | loss: 0.0684225\n",
      "\tspeed: 0.0432s/iter; left time: 579.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0696272 Vali Loss: 0.0855301 Test Loss: 0.0879082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700838\n",
      "\tspeed: 0.0731s/iter; left time: 971.4658s\n",
      "\titers: 200, epoch: 41 | loss: 0.0650603\n",
      "\tspeed: 0.0412s/iter; left time: 543.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696333 Vali Loss: 0.0853576 Test Loss: 0.0879209\n",
      "Validation loss decreased (0.085456 --> 0.085358).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721609\n",
      "\tspeed: 0.0791s/iter; left time: 1033.0047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0683571\n",
      "\tspeed: 0.0411s/iter; left time: 532.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0696497 Vali Loss: 0.0856114 Test Loss: 0.0879269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0659273\n",
      "\tspeed: 0.0750s/iter; left time: 962.9138s\n",
      "\titers: 200, epoch: 43 | loss: 0.0703276\n",
      "\tspeed: 0.0411s/iter; left time: 523.3529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0696177 Vali Loss: 0.0855228 Test Loss: 0.0879306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0707573\n",
      "\tspeed: 0.0740s/iter; left time: 933.1694s\n",
      "\titers: 200, epoch: 44 | loss: 0.0708191\n",
      "\tspeed: 0.0429s/iter; left time: 536.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0695830 Vali Loss: 0.0854188 Test Loss: 0.0879598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0725420\n",
      "\tspeed: 0.0733s/iter; left time: 908.7304s\n",
      "\titers: 200, epoch: 45 | loss: 0.0703637\n",
      "\tspeed: 0.0423s/iter; left time: 519.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696023 Vali Loss: 0.0854171 Test Loss: 0.0879375\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0657321\n",
      "\tspeed: 0.0741s/iter; left time: 901.0396s\n",
      "\titers: 200, epoch: 46 | loss: 0.0639107\n",
      "\tspeed: 0.0410s/iter; left time: 495.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0695614 Vali Loss: 0.0854853 Test Loss: 0.0879773\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0717126\n",
      "\tspeed: 0.0775s/iter; left time: 926.1534s\n",
      "\titers: 200, epoch: 47 | loss: 0.0683041\n",
      "\tspeed: 0.0410s/iter; left time: 485.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0695458 Vali Loss: 0.0855225 Test Loss: 0.0879506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0647682\n",
      "\tspeed: 0.0748s/iter; left time: 876.1091s\n",
      "\titers: 200, epoch: 48 | loss: 0.0752877\n",
      "\tspeed: 0.0412s/iter; left time: 479.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0695764 Vali Loss: 0.0855578 Test Loss: 0.0879192\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0669895\n",
      "\tspeed: 0.0739s/iter; left time: 849.1132s\n",
      "\titers: 200, epoch: 49 | loss: 0.0671645\n",
      "\tspeed: 0.0441s/iter; left time: 502.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0695500 Vali Loss: 0.0854582 Test Loss: 0.0879122\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0681623\n",
      "\tspeed: 0.0729s/iter; left time: 822.0261s\n",
      "\titers: 200, epoch: 50 | loss: 0.0670224\n",
      "\tspeed: 0.0411s/iter; left time: 459.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0695453 Vali Loss: 0.0854244 Test Loss: 0.0879608\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0734773\n",
      "\tspeed: 0.0750s/iter; left time: 828.5580s\n",
      "\titers: 200, epoch: 51 | loss: 0.0709416\n",
      "\tspeed: 0.0409s/iter; left time: 447.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0694864 Vali Loss: 0.0854223 Test Loss: 0.0879430\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02090967260301113, rmse:0.14460177719593048, mae:0.08792086690664291, rse:0.5103196501731873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1313960\n",
      "\tspeed: 0.0426s/iter; left time: 946.2350s\n",
      "\titers: 200, epoch: 1 | loss: 0.1188500\n",
      "\tspeed: 0.0409s/iter; left time: 903.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.1354943 Vali Loss: 0.1248697 Test Loss: 0.1301842\n",
      "Validation loss decreased (inf --> 0.124870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870410\n",
      "\tspeed: 0.0759s/iter; left time: 1669.0927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790940\n",
      "\tspeed: 0.0408s/iter; left time: 893.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0881939 Vali Loss: 0.0920127 Test Loss: 0.0943350\n",
      "Validation loss decreased (0.124870 --> 0.092013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0822242\n",
      "\tspeed: 0.0751s/iter; left time: 1634.8448s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795212\n",
      "\tspeed: 0.0421s/iter; left time: 912.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0792196 Vali Loss: 0.0897547 Test Loss: 0.0930960\n",
      "Validation loss decreased (0.092013 --> 0.089755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744526\n",
      "\tspeed: 0.0744s/iter; left time: 1602.0627s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765585\n",
      "\tspeed: 0.0431s/iter; left time: 922.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0770492 Vali Loss: 0.0888159 Test Loss: 0.0912558\n",
      "Validation loss decreased (0.089755 --> 0.088816).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0781723\n",
      "\tspeed: 0.0752s/iter; left time: 1602.5429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787505\n",
      "\tspeed: 0.0411s/iter; left time: 872.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0755762 Vali Loss: 0.0882391 Test Loss: 0.0905145\n",
      "Validation loss decreased (0.088816 --> 0.088239).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734662\n",
      "\tspeed: 0.0779s/iter; left time: 1642.4975s\n",
      "\titers: 200, epoch: 6 | loss: 0.0701560\n",
      "\tspeed: 0.0412s/iter; left time: 865.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0744702 Vali Loss: 0.0880928 Test Loss: 0.0901387\n",
      "Validation loss decreased (0.088239 --> 0.088093).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758411\n",
      "\tspeed: 0.0762s/iter; left time: 1589.9836s\n",
      "\titers: 200, epoch: 7 | loss: 0.0725631\n",
      "\tspeed: 0.0411s/iter; left time: 853.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0737651 Vali Loss: 0.0871508 Test Loss: 0.0891528\n",
      "Validation loss decreased (0.088093 --> 0.087151).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0738654\n",
      "\tspeed: 0.0756s/iter; left time: 1561.2701s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790533\n",
      "\tspeed: 0.0418s/iter; left time: 859.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0730526 Vali Loss: 0.0870921 Test Loss: 0.0889390\n",
      "Validation loss decreased (0.087151 --> 0.087092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0699977\n",
      "\tspeed: 0.0750s/iter; left time: 1531.8871s\n",
      "\titers: 200, epoch: 9 | loss: 0.0693552\n",
      "\tspeed: 0.0424s/iter; left time: 862.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0725657 Vali Loss: 0.0867596 Test Loss: 0.0892174\n",
      "Validation loss decreased (0.087092 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688242\n",
      "\tspeed: 0.0754s/iter; left time: 1522.1999s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768644\n",
      "\tspeed: 0.0416s/iter; left time: 836.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0722564 Vali Loss: 0.0868287 Test Loss: 0.0888822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0725663\n",
      "\tspeed: 0.0791s/iter; left time: 1580.5377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708728\n",
      "\tspeed: 0.0410s/iter; left time: 814.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0719054 Vali Loss: 0.0862284 Test Loss: 0.0885692\n",
      "Validation loss decreased (0.086760 --> 0.086228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754657\n",
      "\tspeed: 0.0760s/iter; left time: 1500.0768s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690805\n",
      "\tspeed: 0.0418s/iter; left time: 821.9923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0715601 Vali Loss: 0.0863634 Test Loss: 0.0886728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0692426\n",
      "\tspeed: 0.0739s/iter; left time: 1443.7657s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709148\n",
      "\tspeed: 0.0431s/iter; left time: 836.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713889 Vali Loss: 0.0865801 Test Loss: 0.0886077\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719159\n",
      "\tspeed: 0.0740s/iter; left time: 1427.5372s\n",
      "\titers: 200, epoch: 14 | loss: 0.0689385\n",
      "\tspeed: 0.0410s/iter; left time: 786.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0711120 Vali Loss: 0.0861776 Test Loss: 0.0885576\n",
      "Validation loss decreased (0.086228 --> 0.086178).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719024\n",
      "\tspeed: 0.0813s/iter; left time: 1550.3733s\n",
      "\titers: 200, epoch: 15 | loss: 0.0737916\n",
      "\tspeed: 0.0410s/iter; left time: 777.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0709302 Vali Loss: 0.0860182 Test Loss: 0.0885886\n",
      "Validation loss decreased (0.086178 --> 0.086018).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717600\n",
      "\tspeed: 0.0776s/iter; left time: 1464.1638s\n",
      "\titers: 200, epoch: 16 | loss: 0.0704221\n",
      "\tspeed: 0.0413s/iter; left time: 775.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707807 Vali Loss: 0.0859530 Test Loss: 0.0883362\n",
      "Validation loss decreased (0.086018 --> 0.085953).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685674\n",
      "\tspeed: 0.0748s/iter; left time: 1392.9540s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712534\n",
      "\tspeed: 0.0428s/iter; left time: 793.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0706162 Vali Loss: 0.0860626 Test Loss: 0.0882613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0664355\n",
      "\tspeed: 0.0736s/iter; left time: 1355.5983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0718288\n",
      "\tspeed: 0.0425s/iter; left time: 778.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0704577 Vali Loss: 0.0858960 Test Loss: 0.0883355\n",
      "Validation loss decreased (0.085953 --> 0.085896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726624\n",
      "\tspeed: 0.0749s/iter; left time: 1363.0548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683349\n",
      "\tspeed: 0.0410s/iter; left time: 741.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0703722 Vali Loss: 0.0862532 Test Loss: 0.0885259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739421\n",
      "\tspeed: 0.0768s/iter; left time: 1378.8048s\n",
      "\titers: 200, epoch: 20 | loss: 0.0741002\n",
      "\tspeed: 0.0422s/iter; left time: 753.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0702616 Vali Loss: 0.0857343 Test Loss: 0.0880173\n",
      "Validation loss decreased (0.085896 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0670575\n",
      "\tspeed: 0.0768s/iter; left time: 1363.3505s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731600\n",
      "\tspeed: 0.0413s/iter; left time: 728.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0701356 Vali Loss: 0.0856524 Test Loss: 0.0883831\n",
      "Validation loss decreased (0.085734 --> 0.085652).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0671976\n",
      "\tspeed: 0.0771s/iter; left time: 1350.7183s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740734\n",
      "\tspeed: 0.0431s/iter; left time: 751.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0701010 Vali Loss: 0.0857823 Test Loss: 0.0880972\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758784\n",
      "\tspeed: 0.0743s/iter; left time: 1285.6170s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709538\n",
      "\tspeed: 0.0424s/iter; left time: 729.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0700068 Vali Loss: 0.0856148 Test Loss: 0.0881205\n",
      "Validation loss decreased (0.085652 --> 0.085615).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0685787\n",
      "\tspeed: 0.0758s/iter; left time: 1294.4500s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710734\n",
      "\tspeed: 0.0412s/iter; left time: 699.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699610 Vali Loss: 0.0856896 Test Loss: 0.0881782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0676588\n",
      "\tspeed: 0.0764s/iter; left time: 1288.0852s\n",
      "\titers: 200, epoch: 25 | loss: 0.0711828\n",
      "\tspeed: 0.0412s/iter; left time: 689.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0698800 Vali Loss: 0.0855946 Test Loss: 0.0882437\n",
      "Validation loss decreased (0.085615 --> 0.085595).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0661857\n",
      "\tspeed: 0.0764s/iter; left time: 1269.5660s\n",
      "\titers: 200, epoch: 26 | loss: 0.0734557\n",
      "\tspeed: 0.0415s/iter; left time: 685.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0698155 Vali Loss: 0.0855840 Test Loss: 0.0880812\n",
      "Validation loss decreased (0.085595 --> 0.085584).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697222\n",
      "\tspeed: 0.0741s/iter; left time: 1215.0588s\n",
      "\titers: 200, epoch: 27 | loss: 0.0661289\n",
      "\tspeed: 0.0433s/iter; left time: 706.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0697875 Vali Loss: 0.0856633 Test Loss: 0.0882748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0737358\n",
      "\tspeed: 0.0768s/iter; left time: 1242.1764s\n",
      "\titers: 200, epoch: 28 | loss: 0.0681898\n",
      "\tspeed: 0.0414s/iter; left time: 665.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696683 Vali Loss: 0.0855569 Test Loss: 0.0882192\n",
      "Validation loss decreased (0.085584 --> 0.085557).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0692833\n",
      "\tspeed: 0.0779s/iter; left time: 1243.7463s\n",
      "\titers: 200, epoch: 29 | loss: 0.0726246\n",
      "\tspeed: 0.0413s/iter; left time: 655.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696357 Vali Loss: 0.0855218 Test Loss: 0.0881251\n",
      "Validation loss decreased (0.085557 --> 0.085522).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0657860\n",
      "\tspeed: 0.0770s/iter; left time: 1211.4838s\n",
      "\titers: 200, epoch: 30 | loss: 0.0708374\n",
      "\tspeed: 0.0408s/iter; left time: 638.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696056 Vali Loss: 0.0855264 Test Loss: 0.0880535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0701524\n",
      "\tspeed: 0.0745s/iter; left time: 1155.6664s\n",
      "\titers: 200, epoch: 31 | loss: 0.0725639\n",
      "\tspeed: 0.0423s/iter; left time: 651.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0695799 Vali Loss: 0.0855524 Test Loss: 0.0881440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0713260\n",
      "\tspeed: 0.0742s/iter; left time: 1133.8718s\n",
      "\titers: 200, epoch: 32 | loss: 0.0717980\n",
      "\tspeed: 0.0442s/iter; left time: 671.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0695398 Vali Loss: 0.0854926 Test Loss: 0.0880160\n",
      "Validation loss decreased (0.085522 --> 0.085493).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0683134\n",
      "\tspeed: 0.0759s/iter; left time: 1143.2825s\n",
      "\titers: 200, epoch: 33 | loss: 0.0729751\n",
      "\tspeed: 0.0419s/iter; left time: 626.3768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0695101 Vali Loss: 0.0854646 Test Loss: 0.0880804\n",
      "Validation loss decreased (0.085493 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0691466\n",
      "\tspeed: 0.0784s/iter; left time: 1164.2330s\n",
      "\titers: 200, epoch: 34 | loss: 0.0703526\n",
      "\tspeed: 0.0408s/iter; left time: 601.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0695376 Vali Loss: 0.0855198 Test Loss: 0.0880577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776221\n",
      "\tspeed: 0.0764s/iter; left time: 1116.7155s\n",
      "\titers: 200, epoch: 35 | loss: 0.0695363\n",
      "\tspeed: 0.0417s/iter; left time: 605.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0694531 Vali Loss: 0.0854499 Test Loss: 0.0880845\n",
      "Validation loss decreased (0.085465 --> 0.085450).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697098\n",
      "\tspeed: 0.0761s/iter; left time: 1094.8774s\n",
      "\titers: 200, epoch: 36 | loss: 0.0732048\n",
      "\tspeed: 0.0423s/iter; left time: 604.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0694773 Vali Loss: 0.0854531 Test Loss: 0.0880837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0732422\n",
      "\tspeed: 0.0739s/iter; left time: 1047.1660s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698277\n",
      "\tspeed: 0.0425s/iter; left time: 597.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0695019 Vali Loss: 0.0854309 Test Loss: 0.0880640\n",
      "Validation loss decreased (0.085450 --> 0.085431).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0662249\n",
      "\tspeed: 0.0747s/iter; left time: 1042.3577s\n",
      "\titers: 200, epoch: 38 | loss: 0.0669574\n",
      "\tspeed: 0.0411s/iter; left time: 569.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0694807 Vali Loss: 0.0854503 Test Loss: 0.0881496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0675080\n",
      "\tspeed: 0.0781s/iter; left time: 1072.2160s\n",
      "\titers: 200, epoch: 39 | loss: 0.0717927\n",
      "\tspeed: 0.0413s/iter; left time: 562.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0694395 Vali Loss: 0.0855308 Test Loss: 0.0881241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0681171\n",
      "\tspeed: 0.0763s/iter; left time: 1030.3686s\n",
      "\titers: 200, epoch: 40 | loss: 0.0687452\n",
      "\tspeed: 0.0418s/iter; left time: 559.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0694168 Vali Loss: 0.0854836 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0687454\n",
      "\tspeed: 0.0746s/iter; left time: 991.3941s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672896\n",
      "\tspeed: 0.0430s/iter; left time: 566.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0693724 Vali Loss: 0.0854263 Test Loss: 0.0880959\n",
      "Validation loss decreased (0.085431 --> 0.085426).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0690397\n",
      "\tspeed: 0.0747s/iter; left time: 975.1047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0734327\n",
      "\tspeed: 0.0412s/iter; left time: 533.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0693399 Vali Loss: 0.0855006 Test Loss: 0.0881062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0726071\n",
      "\tspeed: 0.0752s/iter; left time: 965.0980s\n",
      "\titers: 200, epoch: 43 | loss: 0.0722188\n",
      "\tspeed: 0.0411s/iter; left time: 523.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0693658 Vali Loss: 0.0854671 Test Loss: 0.0881068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0688466\n",
      "\tspeed: 0.0761s/iter; left time: 960.0431s\n",
      "\titers: 200, epoch: 44 | loss: 0.0752073\n",
      "\tspeed: 0.0427s/iter; left time: 534.0069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0694005 Vali Loss: 0.0854169 Test Loss: 0.0880969\n",
      "Validation loss decreased (0.085426 --> 0.085417).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0694189\n",
      "\tspeed: 0.0771s/iter; left time: 955.1548s\n",
      "\titers: 200, epoch: 45 | loss: 0.0663738\n",
      "\tspeed: 0.0411s/iter; left time: 505.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693401 Vali Loss: 0.0854222 Test Loss: 0.0881163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0687163\n",
      "\tspeed: 0.0740s/iter; left time: 900.7709s\n",
      "\titers: 200, epoch: 46 | loss: 0.0681874\n",
      "\tspeed: 0.0429s/iter; left time: 517.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693499 Vali Loss: 0.0854475 Test Loss: 0.0880975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0698357\n",
      "\tspeed: 0.0733s/iter; left time: 875.7307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0708191\n",
      "\tspeed: 0.0421s/iter; left time: 498.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693365 Vali Loss: 0.0854302 Test Loss: 0.0880839\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0703154\n",
      "\tspeed: 0.0770s/iter; left time: 902.2628s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697617\n",
      "\tspeed: 0.0409s/iter; left time: 475.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0693081 Vali Loss: 0.0854606 Test Loss: 0.0881088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0689715\n",
      "\tspeed: 0.0781s/iter; left time: 898.0791s\n",
      "\titers: 200, epoch: 49 | loss: 0.0643823\n",
      "\tspeed: 0.0409s/iter; left time: 465.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0693539 Vali Loss: 0.0854463 Test Loss: 0.0881050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0739108\n",
      "\tspeed: 0.0755s/iter; left time: 851.3720s\n",
      "\titers: 200, epoch: 50 | loss: 0.0687575\n",
      "\tspeed: 0.0411s/iter; left time: 459.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693257 Vali Loss: 0.0853803 Test Loss: 0.0880668\n",
      "Validation loss decreased (0.085417 --> 0.085380).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0741657\n",
      "\tspeed: 0.0741s/iter; left time: 819.4238s\n",
      "\titers: 200, epoch: 51 | loss: 0.0745502\n",
      "\tspeed: 0.0424s/iter; left time: 464.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0693099 Vali Loss: 0.0854465 Test Loss: 0.0880877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0701798\n",
      "\tspeed: 0.0752s/iter; left time: 814.4153s\n",
      "\titers: 200, epoch: 52 | loss: 0.0675897\n",
      "\tspeed: 0.0407s/iter; left time: 437.0012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0692942 Vali Loss: 0.0854767 Test Loss: 0.0881183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0710436\n",
      "\tspeed: 0.0766s/iter; left time: 812.8227s\n",
      "\titers: 200, epoch: 53 | loss: 0.0713551\n",
      "\tspeed: 0.0412s/iter; left time: 432.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0693223 Vali Loss: 0.0854564 Test Loss: 0.0880729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0713452\n",
      "\tspeed: 0.0751s/iter; left time: 779.1887s\n",
      "\titers: 200, epoch: 54 | loss: 0.0682029\n",
      "\tspeed: 0.0412s/iter; left time: 423.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693280 Vali Loss: 0.0854152 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0675052\n",
      "\tspeed: 0.0767s/iter; left time: 779.4137s\n",
      "\titers: 200, epoch: 55 | loss: 0.0720875\n",
      "\tspeed: 0.0431s/iter; left time: 433.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0692830 Vali Loss: 0.0854154 Test Loss: 0.0880911\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0677626\n",
      "\tspeed: 0.0738s/iter; left time: 732.9327s\n",
      "\titers: 200, epoch: 56 | loss: 0.0691914\n",
      "\tspeed: 0.0426s/iter; left time: 418.7587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693142 Vali Loss: 0.0854138 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0713836\n",
      "\tspeed: 0.0741s/iter; left time: 719.9243s\n",
      "\titers: 200, epoch: 57 | loss: 0.0689744\n",
      "\tspeed: 0.0409s/iter; left time: 392.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0692971 Vali Loss: 0.0853321 Test Loss: 0.0880808\n",
      "Validation loss decreased (0.085380 --> 0.085332).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0728526\n",
      "\tspeed: 0.0785s/iter; left time: 744.8295s\n",
      "\titers: 200, epoch: 58 | loss: 0.0730912\n",
      "\tspeed: 0.0415s/iter; left time: 389.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693028 Vali Loss: 0.0854990 Test Loss: 0.0880816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0685177\n",
      "\tspeed: 0.0763s/iter; left time: 706.6706s\n",
      "\titers: 200, epoch: 59 | loss: 0.0764130\n",
      "\tspeed: 0.0410s/iter; left time: 376.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0693449 Vali Loss: 0.0854073 Test Loss: 0.0880793\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0652238\n",
      "\tspeed: 0.0748s/iter; left time: 676.4479s\n",
      "\titers: 200, epoch: 60 | loss: 0.0730409\n",
      "\tspeed: 0.0425s/iter; left time: 380.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693224 Vali Loss: 0.0854565 Test Loss: 0.0880748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0622156\n",
      "\tspeed: 0.0740s/iter; left time: 652.8614s\n",
      "\titers: 200, epoch: 61 | loss: 0.0695777\n",
      "\tspeed: 0.0423s/iter; left time: 369.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0693130 Vali Loss: 0.0853348 Test Loss: 0.0880779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0691958\n",
      "\tspeed: 0.0746s/iter; left time: 641.5221s\n",
      "\titers: 200, epoch: 62 | loss: 0.0696925\n",
      "\tspeed: 0.0411s/iter; left time: 348.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0692719 Vali Loss: 0.0854249 Test Loss: 0.0880714\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0646419\n",
      "\tspeed: 0.0767s/iter; left time: 642.4102s\n",
      "\titers: 200, epoch: 63 | loss: 0.0696922\n",
      "\tspeed: 0.0415s/iter; left time: 343.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0692963 Vali Loss: 0.0855429 Test Loss: 0.0881021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0697859\n",
      "\tspeed: 0.0767s/iter; left time: 625.5754s\n",
      "\titers: 200, epoch: 64 | loss: 0.0695441\n",
      "\tspeed: 0.0416s/iter; left time: 334.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0693159 Vali Loss: 0.0854452 Test Loss: 0.0880868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0718862\n",
      "\tspeed: 0.0746s/iter; left time: 591.8343s\n",
      "\titers: 200, epoch: 65 | loss: 0.0714731\n",
      "\tspeed: 0.0427s/iter; left time: 334.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0692911 Vali Loss: 0.0855044 Test Loss: 0.0880898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0747009\n",
      "\tspeed: 0.0740s/iter; left time: 570.0327s\n",
      "\titers: 200, epoch: 66 | loss: 0.0683450\n",
      "\tspeed: 0.0414s/iter; left time: 315.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0692636 Vali Loss: 0.0854475 Test Loss: 0.0880977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0644507\n",
      "\tspeed: 0.0754s/iter; left time: 564.0547s\n",
      "\titers: 200, epoch: 67 | loss: 0.0695106\n",
      "\tspeed: 0.0409s/iter; left time: 301.6847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0692449 Vali Loss: 0.0854787 Test Loss: 0.0881008\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021135743707418442, rmse:0.1453813761472702, mae:0.08808080106973648, rse:0.5130710005760193\n",
      "Intermediate time for DE and pred_len 24: 00h:23m:13.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0689s/iter; left time: 1523.7622s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272170\n",
      "\tspeed: 0.0429s/iter; left time: 943.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 222 | Train Loss: 0.1436296 Vali Loss: 0.1367209 Test Loss: 0.1443836\n",
      "Validation loss decreased (inf --> 0.136721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1119428\n",
      "\tspeed: 0.0752s/iter; left time: 1645.3605s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102052\n",
      "\tspeed: 0.0433s/iter; left time: 942.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1122322 Vali Loss: 0.1209552 Test Loss: 0.1276630\n",
      "Validation loss decreased (0.136721 --> 0.120955).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019009\n",
      "\tspeed: 0.0775s/iter; left time: 1678.0483s\n",
      "\titers: 200, epoch: 3 | loss: 0.1073653\n",
      "\tspeed: 0.0414s/iter; left time: 893.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1050740 Vali Loss: 0.1188224 Test Loss: 0.1261629\n",
      "Validation loss decreased (0.120955 --> 0.118822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991714\n",
      "\tspeed: 0.0787s/iter; left time: 1687.2832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1060414\n",
      "\tspeed: 0.0412s/iter; left time: 879.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1032394 Vali Loss: 0.1185098 Test Loss: 0.1264228\n",
      "Validation loss decreased (0.118822 --> 0.118510).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1070811\n",
      "\tspeed: 0.0785s/iter; left time: 1664.3113s\n",
      "\titers: 200, epoch: 5 | loss: 0.1010344\n",
      "\tspeed: 0.0413s/iter; left time: 872.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1018696 Vali Loss: 0.1173460 Test Loss: 0.1256864\n",
      "Validation loss decreased (0.118510 --> 0.117346).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0988520\n",
      "\tspeed: 0.0769s/iter; left time: 1613.7952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993529\n",
      "\tspeed: 0.0432s/iter; left time: 902.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1007471 Vali Loss: 0.1172743 Test Loss: 0.1250511\n",
      "Validation loss decreased (0.117346 --> 0.117274).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983264\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1289s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031795\n",
      "\tspeed: 0.0416s/iter; left time: 860.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0996418 Vali Loss: 0.1161049 Test Loss: 0.1247776\n",
      "Validation loss decreased (0.117274 --> 0.116105).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0968254\n",
      "\tspeed: 0.0767s/iter; left time: 1576.2278s\n",
      "\titers: 200, epoch: 8 | loss: 0.0976769\n",
      "\tspeed: 0.0433s/iter; left time: 885.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0990161 Vali Loss: 0.1161650 Test Loss: 0.1246663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0972535\n",
      "\tspeed: 0.0757s/iter; left time: 1538.0982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927693\n",
      "\tspeed: 0.0424s/iter; left time: 856.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.0982024 Vali Loss: 0.1159731 Test Loss: 0.1244971\n",
      "Validation loss decreased (0.116105 --> 0.115973).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004171\n",
      "\tspeed: 0.0787s/iter; left time: 1581.5480s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019848\n",
      "\tspeed: 0.0417s/iter; left time: 833.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0975692 Vali Loss: 0.1164706 Test Loss: 0.1259885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969026\n",
      "\tspeed: 0.0806s/iter; left time: 1602.3917s\n",
      "\titers: 200, epoch: 11 | loss: 0.0972415\n",
      "\tspeed: 0.0417s/iter; left time: 825.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0970848 Vali Loss: 0.1161472 Test Loss: 0.1248178\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0945826\n",
      "\tspeed: 0.0765s/iter; left time: 1502.9973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0900184\n",
      "\tspeed: 0.0430s/iter; left time: 840.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0966333 Vali Loss: 0.1163193 Test Loss: 0.1255104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0919880\n",
      "\tspeed: 0.0762s/iter; left time: 1481.9078s\n",
      "\titers: 200, epoch: 13 | loss: 0.0924623\n",
      "\tspeed: 0.0448s/iter; left time: 866.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.0962716 Vali Loss: 0.1166060 Test Loss: 0.1256381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920922\n",
      "\tspeed: 0.0769s/iter; left time: 1478.2532s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965592\n",
      "\tspeed: 0.0415s/iter; left time: 792.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0958053 Vali Loss: 0.1166250 Test Loss: 0.1259447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982206\n",
      "\tspeed: 0.0792s/iter; left time: 1504.5394s\n",
      "\titers: 200, epoch: 15 | loss: 0.0993863\n",
      "\tspeed: 0.0412s/iter; left time: 777.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.0955025 Vali Loss: 0.1164518 Test Loss: 0.1254893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0987729\n",
      "\tspeed: 0.0787s/iter; left time: 1477.8527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0852301\n",
      "\tspeed: 0.0420s/iter; left time: 784.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0951404 Vali Loss: 0.1169241 Test Loss: 0.1264961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0946120\n",
      "\tspeed: 0.0763s/iter; left time: 1415.3852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0943329\n",
      "\tspeed: 0.0438s/iter; left time: 808.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0948563 Vali Loss: 0.1167530 Test Loss: 0.1260772\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0961872\n",
      "\tspeed: 0.0765s/iter; left time: 1402.3126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899222\n",
      "\tspeed: 0.0421s/iter; left time: 767.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0945491 Vali Loss: 0.1170323 Test Loss: 0.1264428\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0923800\n",
      "\tspeed: 0.0759s/iter; left time: 1373.4559s\n",
      "\titers: 200, epoch: 19 | loss: 0.0921431\n",
      "\tspeed: 0.0416s/iter; left time: 749.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0942993 Vali Loss: 0.1170631 Test Loss: 0.1265067\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03561720997095108, rmse:0.18872521817684174, mae:0.12449711561203003, rse:0.6683141589164734\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1400388\n",
      "\tspeed: 0.0437s/iter; left time: 964.9514s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282806\n",
      "\tspeed: 0.0418s/iter; left time: 920.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1451481 Vali Loss: 0.1368056 Test Loss: 0.1443637\n",
      "Validation loss decreased (inf --> 0.136806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1109583\n",
      "\tspeed: 0.0795s/iter; left time: 1738.7939s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087150\n",
      "\tspeed: 0.0413s/iter; left time: 898.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1123508 Vali Loss: 0.1206324 Test Loss: 0.1275795\n",
      "Validation loss decreased (0.136806 --> 0.120632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1061414\n",
      "\tspeed: 0.0774s/iter; left time: 1676.6510s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020828\n",
      "\tspeed: 0.0427s/iter; left time: 921.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1054388 Vali Loss: 0.1195631 Test Loss: 0.1275751\n",
      "Validation loss decreased (0.120632 --> 0.119563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1002767\n",
      "\tspeed: 0.0766s/iter; left time: 1640.9971s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011909\n",
      "\tspeed: 0.0444s/iter; left time: 947.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 222 | Train Loss: 0.1036856 Vali Loss: 0.1177835 Test Loss: 0.1259473\n",
      "Validation loss decreased (0.119563 --> 0.117784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005678\n",
      "\tspeed: 0.0804s/iter; left time: 1704.5139s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012293\n",
      "\tspeed: 0.0422s/iter; left time: 892.0216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1022701 Vali Loss: 0.1182866 Test Loss: 0.1259687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041436\n",
      "\tspeed: 0.0799s/iter; left time: 1677.0377s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036419\n",
      "\tspeed: 0.0416s/iter; left time: 868.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1011227 Vali Loss: 0.1171968 Test Loss: 0.1266128\n",
      "Validation loss decreased (0.117784 --> 0.117197).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0986257\n",
      "\tspeed: 0.0798s/iter; left time: 1657.7720s\n",
      "\titers: 200, epoch: 7 | loss: 0.0996775\n",
      "\tspeed: 0.0414s/iter; left time: 856.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1001962 Vali Loss: 0.1165839 Test Loss: 0.1266569\n",
      "Validation loss decreased (0.117197 --> 0.116584).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0976779\n",
      "\tspeed: 0.0806s/iter; left time: 1656.7433s\n",
      "\titers: 200, epoch: 8 | loss: 0.0970001\n",
      "\tspeed: 0.0439s/iter; left time: 897.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 222 | Train Loss: 0.0992992 Vali Loss: 0.1167001 Test Loss: 0.1258703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027840\n",
      "\tspeed: 0.0771s/iter; left time: 1566.7971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060535\n",
      "\tspeed: 0.0430s/iter; left time: 869.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0985650 Vali Loss: 0.1167805 Test Loss: 0.1263607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0944021\n",
      "\tspeed: 0.0790s/iter; left time: 1588.0037s\n",
      "\titers: 200, epoch: 10 | loss: 0.1016151\n",
      "\tspeed: 0.0413s/iter; left time: 825.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.0980308 Vali Loss: 0.1163658 Test Loss: 0.1254943\n",
      "Validation loss decreased (0.116584 --> 0.116366).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0977273\n",
      "\tspeed: 0.0795s/iter; left time: 1581.0516s\n",
      "\titers: 200, epoch: 11 | loss: 0.0998444\n",
      "\tspeed: 0.0419s/iter; left time: 829.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0972910 Vali Loss: 0.1168659 Test Loss: 0.1263906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0961552\n",
      "\tspeed: 0.0790s/iter; left time: 1552.8094s\n",
      "\titers: 200, epoch: 12 | loss: 0.0945634\n",
      "\tspeed: 0.0428s/iter; left time: 836.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.0967934 Vali Loss: 0.1168394 Test Loss: 0.1271407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0975530\n",
      "\tspeed: 0.0768s/iter; left time: 1493.3065s\n",
      "\titers: 200, epoch: 13 | loss: 0.0979478\n",
      "\tspeed: 0.0447s/iter; left time: 864.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.0963015 Vali Loss: 0.1170192 Test Loss: 0.1264434\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0950694\n",
      "\tspeed: 0.0771s/iter; left time: 1481.7566s\n",
      "\titers: 200, epoch: 14 | loss: 0.0953018\n",
      "\tspeed: 0.0414s/iter; left time: 790.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 222 | Train Loss: 0.0958852 Vali Loss: 0.1174900 Test Loss: 0.1265704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0917451\n",
      "\tspeed: 0.0798s/iter; left time: 1516.0533s\n",
      "\titers: 200, epoch: 15 | loss: 0.0947973\n",
      "\tspeed: 0.0414s/iter; left time: 781.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.0954877 Vali Loss: 0.1173866 Test Loss: 0.1267025\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0963200\n",
      "\tspeed: 0.0788s/iter; left time: 1478.6512s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930423\n",
      "\tspeed: 0.0423s/iter; left time: 789.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0950855 Vali Loss: 0.1175980 Test Loss: 0.1277074\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0916373\n",
      "\tspeed: 0.0815s/iter; left time: 1511.0478s\n",
      "\titers: 200, epoch: 17 | loss: 0.0967468\n",
      "\tspeed: 0.0506s/iter; left time: 933.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.78s\n",
      "Steps: 222 | Train Loss: 0.0947534 Vali Loss: 0.1174741 Test Loss: 0.1267105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0973670\n",
      "\tspeed: 0.0786s/iter; left time: 1440.3332s\n",
      "\titers: 200, epoch: 18 | loss: 0.0952947\n",
      "\tspeed: 0.0429s/iter; left time: 782.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 222 | Train Loss: 0.0943828 Vali Loss: 0.1179385 Test Loss: 0.1270582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973220\n",
      "\tspeed: 0.0781s/iter; left time: 1414.1248s\n",
      "\titers: 200, epoch: 19 | loss: 0.0969161\n",
      "\tspeed: 0.0420s/iter; left time: 756.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0941494 Vali Loss: 0.1176506 Test Loss: 0.1271805\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0945372\n",
      "\tspeed: 0.0828s/iter; left time: 1481.0696s\n",
      "\titers: 200, epoch: 20 | loss: 0.0925670\n",
      "\tspeed: 0.0417s/iter; left time: 741.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0939146 Vali Loss: 0.1181242 Test Loss: 0.1272864\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036110397428274155, rmse:0.1900273561477661, mae:0.12549425661563873, rse:0.6729252934455872\n",
      "Intermediate time for DE and pred_len 96: 00h:08m:04.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1397623\n",
      "\tspeed: 0.0685s/iter; left time: 1512.8747s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311453\n",
      "\tspeed: 0.0443s/iter; left time: 975.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 222 | Train Loss: 0.1455157 Vali Loss: 0.1382303 Test Loss: 0.1469418\n",
      "Validation loss decreased (inf --> 0.138230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1118676\n",
      "\tspeed: 0.0769s/iter; left time: 1681.6863s\n",
      "\titers: 200, epoch: 2 | loss: 0.1124648\n",
      "\tspeed: 0.0422s/iter; left time: 918.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1173347 Vali Loss: 0.1244901 Test Loss: 0.1326688\n",
      "Validation loss decreased (0.138230 --> 0.124490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142889\n",
      "\tspeed: 0.0829s/iter; left time: 1795.9465s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112246\n",
      "\tspeed: 0.0419s/iter; left time: 903.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.1107566 Vali Loss: 0.1233068 Test Loss: 0.1331108\n",
      "Validation loss decreased (0.124490 --> 0.123307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125001\n",
      "\tspeed: 0.0796s/iter; left time: 1705.7956s\n",
      "\titers: 200, epoch: 4 | loss: 0.1047679\n",
      "\tspeed: 0.0422s/iter; left time: 900.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1088656 Vali Loss: 0.1225500 Test Loss: 0.1325692\n",
      "Validation loss decreased (0.123307 --> 0.122550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1045422\n",
      "\tspeed: 0.0778s/iter; left time: 1651.2061s\n",
      "\titers: 200, epoch: 5 | loss: 0.1108324\n",
      "\tspeed: 0.0443s/iter; left time: 934.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.1072662 Vali Loss: 0.1221504 Test Loss: 0.1329006\n",
      "Validation loss decreased (0.122550 --> 0.122150).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041857\n",
      "\tspeed: 0.0778s/iter; left time: 1632.2456s\n",
      "\titers: 200, epoch: 6 | loss: 0.1052786\n",
      "\tspeed: 0.0448s/iter; left time: 936.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1058854 Vali Loss: 0.1215441 Test Loss: 0.1320615\n",
      "Validation loss decreased (0.122150 --> 0.121544).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038428\n",
      "\tspeed: 0.0791s/iter; left time: 1641.9992s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040158\n",
      "\tspeed: 0.0420s/iter; left time: 868.4266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1048011 Vali Loss: 0.1215408 Test Loss: 0.1310547\n",
      "Validation loss decreased (0.121544 --> 0.121541).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035512\n",
      "\tspeed: 0.0793s/iter; left time: 1629.1195s\n",
      "\titers: 200, epoch: 8 | loss: 0.1044740\n",
      "\tspeed: 0.0429s/iter; left time: 877.8017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1037952 Vali Loss: 0.1215836 Test Loss: 0.1319724\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043236\n",
      "\tspeed: 0.0805s/iter; left time: 1636.7817s\n",
      "\titers: 200, epoch: 9 | loss: 0.1052697\n",
      "\tspeed: 0.0427s/iter; left time: 862.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1029094 Vali Loss: 0.1222514 Test Loss: 0.1315340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996455\n",
      "\tspeed: 0.0792s/iter; left time: 1591.9196s\n",
      "\titers: 200, epoch: 10 | loss: 0.1033757\n",
      "\tspeed: 0.0422s/iter; left time: 843.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1021399 Vali Loss: 0.1226193 Test Loss: 0.1322068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1056792\n",
      "\tspeed: 0.0812s/iter; left time: 1613.7792s\n",
      "\titers: 200, epoch: 11 | loss: 0.1029007\n",
      "\tspeed: 0.0430s/iter; left time: 849.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 222 | Train Loss: 0.1013839 Vali Loss: 0.1223948 Test Loss: 0.1326800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1031876\n",
      "\tspeed: 0.0785s/iter; left time: 1543.2386s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028955\n",
      "\tspeed: 0.0448s/iter; left time: 876.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 222 | Train Loss: 0.1008144 Vali Loss: 0.1228269 Test Loss: 0.1327951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0969489\n",
      "\tspeed: 0.0775s/iter; left time: 1506.6652s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018683\n",
      "\tspeed: 0.0420s/iter; left time: 811.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1002138 Vali Loss: 0.1231768 Test Loss: 0.1335167\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0958620\n",
      "\tspeed: 0.0823s/iter; left time: 1582.0268s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960994\n",
      "\tspeed: 0.0425s/iter; left time: 812.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0996247 Vali Loss: 0.1232097 Test Loss: 0.1334005\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0970920\n",
      "\tspeed: 0.0815s/iter; left time: 1547.0298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0992540\n",
      "\tspeed: 0.0424s/iter; left time: 800.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 222 | Train Loss: 0.0991395 Vali Loss: 0.1234243 Test Loss: 0.1337967\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0988758\n",
      "\tspeed: 0.0778s/iter; left time: 1460.0914s\n",
      "\titers: 200, epoch: 16 | loss: 0.1006009\n",
      "\tspeed: 0.0429s/iter; left time: 801.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.0986473 Vali Loss: 0.1236352 Test Loss: 0.1343386\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0987671\n",
      "\tspeed: 0.0773s/iter; left time: 1434.3332s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016840\n",
      "\tspeed: 0.0433s/iter; left time: 798.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0981912 Vali Loss: 0.1233611 Test Loss: 0.1350610\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.037683311849832535, rmse:0.19412189722061157, mae:0.13105474412441254, rse:0.6875953674316406\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1464187\n",
      "\tspeed: 0.0438s/iter; left time: 969.1262s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341484\n",
      "\tspeed: 0.0436s/iter; left time: 958.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1460951 Vali Loss: 0.1378723 Test Loss: 0.1467569\n",
      "Validation loss decreased (inf --> 0.137872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1244008\n",
      "\tspeed: 0.0783s/iter; left time: 1714.2119s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136181\n",
      "\tspeed: 0.0421s/iter; left time: 917.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1175792 Vali Loss: 0.1241931 Test Loss: 0.1332423\n",
      "Validation loss decreased (0.137872 --> 0.124193).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168221\n",
      "\tspeed: 0.0842s/iter; left time: 1822.6471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108454\n",
      "\tspeed: 0.0422s/iter; left time: 908.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1109203 Vali Loss: 0.1232760 Test Loss: 0.1326479\n",
      "Validation loss decreased (0.124193 --> 0.123276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1095669\n",
      "\tspeed: 0.0842s/iter; left time: 1805.3797s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056824\n",
      "\tspeed: 0.0417s/iter; left time: 889.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1091623 Vali Loss: 0.1222856 Test Loss: 0.1327749\n",
      "Validation loss decreased (0.123276 --> 0.122286).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129397\n",
      "\tspeed: 0.0839s/iter; left time: 1779.1501s\n",
      "\titers: 200, epoch: 5 | loss: 0.1075838\n",
      "\tspeed: 0.0417s/iter; left time: 880.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1076867 Vali Loss: 0.1218808 Test Loss: 0.1322782\n",
      "Validation loss decreased (0.122286 --> 0.121881).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021544\n",
      "\tspeed: 0.0803s/iter; left time: 1684.8417s\n",
      "\titers: 200, epoch: 6 | loss: 0.1099828\n",
      "\tspeed: 0.0436s/iter; left time: 911.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.1062730 Vali Loss: 0.1218795 Test Loss: 0.1329139\n",
      "Validation loss decreased (0.121881 --> 0.121879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1045288\n",
      "\tspeed: 0.0787s/iter; left time: 1635.3227s\n",
      "\titers: 200, epoch: 7 | loss: 0.1049782\n",
      "\tspeed: 0.0442s/iter; left time: 912.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 222 | Train Loss: 0.1051721 Vali Loss: 0.1218529 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.121879 --> 0.121853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054067\n",
      "\tspeed: 0.0791s/iter; left time: 1625.8461s\n",
      "\titers: 200, epoch: 8 | loss: 0.1061499\n",
      "\tspeed: 0.0419s/iter; left time: 857.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1041193 Vali Loss: 0.1218142 Test Loss: 0.1342641\n",
      "Validation loss decreased (0.121853 --> 0.121814).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012625\n",
      "\tspeed: 0.0818s/iter; left time: 1661.8316s\n",
      "\titers: 200, epoch: 9 | loss: 0.1050227\n",
      "\tspeed: 0.0420s/iter; left time: 848.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1032028 Vali Loss: 0.1221258 Test Loss: 0.1326769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1042934\n",
      "\tspeed: 0.0803s/iter; left time: 1613.4620s\n",
      "\titers: 200, epoch: 10 | loss: 0.0979124\n",
      "\tspeed: 0.0422s/iter; left time: 843.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.1022348 Vali Loss: 0.1229397 Test Loss: 0.1328034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0992723\n",
      "\tspeed: 0.0782s/iter; left time: 1553.8170s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031113\n",
      "\tspeed: 0.0429s/iter; left time: 848.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.1014518 Vali Loss: 0.1221524 Test Loss: 0.1333573\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0981024\n",
      "\tspeed: 0.0796s/iter; left time: 1564.1103s\n",
      "\titers: 200, epoch: 12 | loss: 0.1039329\n",
      "\tspeed: 0.0420s/iter; left time: 820.8737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1004923 Vali Loss: 0.1232195 Test Loss: 0.1345381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996970\n",
      "\tspeed: 0.0800s/iter; left time: 1554.3746s\n",
      "\titers: 200, epoch: 13 | loss: 0.1020393\n",
      "\tspeed: 0.0420s/iter; left time: 812.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0998807 Vali Loss: 0.1230378 Test Loss: 0.1335723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1020292\n",
      "\tspeed: 0.0789s/iter; left time: 1515.2191s\n",
      "\titers: 200, epoch: 14 | loss: 0.0983770\n",
      "\tspeed: 0.0429s/iter; left time: 819.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 222 | Train Loss: 0.0993128 Vali Loss: 0.1233723 Test Loss: 0.1334894\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1019369\n",
      "\tspeed: 0.0786s/iter; left time: 1493.1534s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003085\n",
      "\tspeed: 0.0438s/iter; left time: 827.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986477 Vali Loss: 0.1239124 Test Loss: 0.1339220\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990376\n",
      "\tspeed: 0.0780s/iter; left time: 1463.5393s\n",
      "\titers: 200, epoch: 16 | loss: 0.0996671\n",
      "\tspeed: 0.0421s/iter; left time: 785.9176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0981405 Vali Loss: 0.1236752 Test Loss: 0.1338171\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0997125\n",
      "\tspeed: 0.0809s/iter; left time: 1500.4029s\n",
      "\titers: 200, epoch: 17 | loss: 0.0991643\n",
      "\tspeed: 0.0419s/iter; left time: 773.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0977311 Vali Loss: 0.1242002 Test Loss: 0.1341292\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0960976\n",
      "\tspeed: 0.0808s/iter; left time: 1481.3266s\n",
      "\titers: 200, epoch: 18 | loss: 0.0957674\n",
      "\tspeed: 0.0422s/iter; left time: 769.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 222 | Train Loss: 0.0973472 Vali Loss: 0.1244612 Test Loss: 0.1344188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03982341289520264, rmse:0.1995580494403839, mae:0.13426414132118225, rse:0.7068506479263306\n",
      "Intermediate time for DE and pred_len 168: 00h:07m:24.55s\n",
      "Intermediate time for DE: 00h:38m:43.17s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1188304\n",
      "\tspeed: 0.0652s/iter; left time: 1447.7247s\n",
      "\titers: 200, epoch: 1 | loss: 0.1158463\n",
      "\tspeed: 0.0436s/iter; left time: 964.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.1253345 Vali Loss: 0.1194196 Test Loss: 0.1384884\n",
      "Validation loss decreased (inf --> 0.119420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869500\n",
      "\tspeed: 0.0763s/iter; left time: 1677.7030s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823559\n",
      "\tspeed: 0.0412s/iter; left time: 901.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0858117 Vali Loss: 0.0921554 Test Loss: 0.1034357\n",
      "Validation loss decreased (0.119420 --> 0.092155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806272\n",
      "\tspeed: 0.0785s/iter; left time: 1708.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.0780588\n",
      "\tspeed: 0.0411s/iter; left time: 889.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0789248 Vali Loss: 0.0894574 Test Loss: 0.1027660\n",
      "Validation loss decreased (0.092155 --> 0.089457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818409\n",
      "\tspeed: 0.0777s/iter; left time: 1672.5881s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826696\n",
      "\tspeed: 0.0420s/iter; left time: 900.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0773095 Vali Loss: 0.0896718 Test Loss: 0.1028447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730246\n",
      "\tspeed: 0.0752s/iter; left time: 1601.9405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0735860\n",
      "\tspeed: 0.0431s/iter; left time: 913.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0762145 Vali Loss: 0.0891013 Test Loss: 0.1017014\n",
      "Validation loss decreased (0.089457 --> 0.089101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0732028\n",
      "\tspeed: 0.0745s/iter; left time: 1570.1271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779525\n",
      "\tspeed: 0.0428s/iter; left time: 898.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0755551 Vali Loss: 0.0885052 Test Loss: 0.1005966\n",
      "Validation loss decreased (0.089101 --> 0.088505).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749436\n",
      "\tspeed: 0.0767s/iter; left time: 1599.9896s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747769\n",
      "\tspeed: 0.0415s/iter; left time: 861.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0749858 Vali Loss: 0.0884487 Test Loss: 0.1012087\n",
      "Validation loss decreased (0.088505 --> 0.088449).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772606\n",
      "\tspeed: 0.0781s/iter; left time: 1611.0026s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730566\n",
      "\tspeed: 0.0413s/iter; left time: 847.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0745392 Vali Loss: 0.0878225 Test Loss: 0.1004115\n",
      "Validation loss decreased (0.088449 --> 0.087823).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728021\n",
      "\tspeed: 0.0764s/iter; left time: 1560.4706s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704910\n",
      "\tspeed: 0.0421s/iter; left time: 855.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0741072 Vali Loss: 0.0878454 Test Loss: 0.0995688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727380\n",
      "\tspeed: 0.0741s/iter; left time: 1497.3165s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768265\n",
      "\tspeed: 0.0429s/iter; left time: 862.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0736922 Vali Loss: 0.0878476 Test Loss: 0.1003193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0790198\n",
      "\tspeed: 0.0768s/iter; left time: 1532.9696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737132\n",
      "\tspeed: 0.0415s/iter; left time: 823.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0733805 Vali Loss: 0.0875606 Test Loss: 0.1003940\n",
      "Validation loss decreased (0.087823 --> 0.087561).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0658553\n",
      "\tspeed: 0.0744s/iter; left time: 1469.1125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785903\n",
      "\tspeed: 0.0411s/iter; left time: 807.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0731744 Vali Loss: 0.0876214 Test Loss: 0.0995508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719233\n",
      "\tspeed: 0.0767s/iter; left time: 1498.4702s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742535\n",
      "\tspeed: 0.0416s/iter; left time: 808.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0729265 Vali Loss: 0.0874835 Test Loss: 0.0995281\n",
      "Validation loss decreased (0.087561 --> 0.087484).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0725279\n",
      "\tspeed: 0.0758s/iter; left time: 1464.0409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0729276\n",
      "\tspeed: 0.0411s/iter; left time: 788.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0727757 Vali Loss: 0.0875945 Test Loss: 0.0995237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0727914\n",
      "\tspeed: 0.0749s/iter; left time: 1429.1084s\n",
      "\titers: 200, epoch: 15 | loss: 0.0719108\n",
      "\tspeed: 0.0424s/iter; left time: 804.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0725818 Vali Loss: 0.0873662 Test Loss: 0.0992842\n",
      "Validation loss decreased (0.087484 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703028\n",
      "\tspeed: 0.0752s/iter; left time: 1418.1670s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679876\n",
      "\tspeed: 0.0425s/iter; left time: 797.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0724623 Vali Loss: 0.0873758 Test Loss: 0.0991852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0762972\n",
      "\tspeed: 0.0754s/iter; left time: 1404.1466s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740745\n",
      "\tspeed: 0.0412s/iter; left time: 763.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0722771 Vali Loss: 0.0871907 Test Loss: 0.0993153\n",
      "Validation loss decreased (0.087366 --> 0.087191).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713437\n",
      "\tspeed: 0.0771s/iter; left time: 1419.2108s\n",
      "\titers: 200, epoch: 18 | loss: 0.0711351\n",
      "\tspeed: 0.0411s/iter; left time: 752.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0721830 Vali Loss: 0.0871974 Test Loss: 0.0992790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728786\n",
      "\tspeed: 0.0752s/iter; left time: 1366.7758s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766083\n",
      "\tspeed: 0.0418s/iter; left time: 756.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0720670 Vali Loss: 0.0873282 Test Loss: 0.0991362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0707023\n",
      "\tspeed: 0.0757s/iter; left time: 1360.3913s\n",
      "\titers: 200, epoch: 20 | loss: 0.0659706\n",
      "\tspeed: 0.0420s/iter; left time: 751.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0719200 Vali Loss: 0.0872897 Test Loss: 0.0990334\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683376\n",
      "\tspeed: 0.0744s/iter; left time: 1319.2726s\n",
      "\titers: 200, epoch: 21 | loss: 0.0744315\n",
      "\tspeed: 0.0418s/iter; left time: 738.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0718971 Vali Loss: 0.0872003 Test Loss: 0.0991050\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723205\n",
      "\tspeed: 0.0751s/iter; left time: 1315.7646s\n",
      "\titers: 200, epoch: 22 | loss: 0.0718565\n",
      "\tspeed: 0.0412s/iter; left time: 717.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0717617 Vali Loss: 0.0871217 Test Loss: 0.0991213\n",
      "Validation loss decreased (0.087191 --> 0.087122).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0754515\n",
      "\tspeed: 0.0776s/iter; left time: 1341.6347s\n",
      "\titers: 200, epoch: 23 | loss: 0.0666656\n",
      "\tspeed: 0.0417s/iter; left time: 716.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0717673 Vali Loss: 0.0870475 Test Loss: 0.0990244\n",
      "Validation loss decreased (0.087122 --> 0.087047).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0736613\n",
      "\tspeed: 0.0762s/iter; left time: 1300.7520s\n",
      "\titers: 200, epoch: 24 | loss: 0.0732239\n",
      "\tspeed: 0.0417s/iter; left time: 708.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716505 Vali Loss: 0.0871460 Test Loss: 0.0991912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0745001\n",
      "\tspeed: 0.0744s/iter; left time: 1253.5139s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714629\n",
      "\tspeed: 0.0430s/iter; left time: 719.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716034 Vali Loss: 0.0873583 Test Loss: 0.0990945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680236\n",
      "\tspeed: 0.0750s/iter; left time: 1246.2728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0676734\n",
      "\tspeed: 0.0411s/iter; left time: 679.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0715778 Vali Loss: 0.0872454 Test Loss: 0.0990852\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0735137\n",
      "\tspeed: 0.0766s/iter; left time: 1255.7564s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742956\n",
      "\tspeed: 0.0412s/iter; left time: 671.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0714903 Vali Loss: 0.0869934 Test Loss: 0.0989545\n",
      "Validation loss decreased (0.087047 --> 0.086993).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0663206\n",
      "\tspeed: 0.0771s/iter; left time: 1247.1326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0772928\n",
      "\tspeed: 0.0411s/iter; left time: 660.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0714377 Vali Loss: 0.0872516 Test Loss: 0.0991254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742304\n",
      "\tspeed: 0.0751s/iter; left time: 1197.9225s\n",
      "\titers: 200, epoch: 29 | loss: 0.0696663\n",
      "\tspeed: 0.0418s/iter; left time: 663.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714469 Vali Loss: 0.0871852 Test Loss: 0.0990446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0752319\n",
      "\tspeed: 0.0737s/iter; left time: 1160.2209s\n",
      "\titers: 200, epoch: 30 | loss: 0.0767607\n",
      "\tspeed: 0.0421s/iter; left time: 657.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714359 Vali Loss: 0.0872758 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0697839\n",
      "\tspeed: 0.0761s/iter; left time: 1180.0293s\n",
      "\titers: 200, epoch: 31 | loss: 0.0737064\n",
      "\tspeed: 0.0418s/iter; left time: 644.8325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0713810 Vali Loss: 0.0870711 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0747602\n",
      "\tspeed: 0.0786s/iter; left time: 1201.8673s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749984\n",
      "\tspeed: 0.0408s/iter; left time: 620.2149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0713382 Vali Loss: 0.0871204 Test Loss: 0.0990219\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0712683\n",
      "\tspeed: 0.0751s/iter; left time: 1130.8837s\n",
      "\titers: 200, epoch: 33 | loss: 0.0691796\n",
      "\tspeed: 0.0413s/iter; left time: 618.4426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713131 Vali Loss: 0.0871258 Test Loss: 0.0989417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0684355\n",
      "\tspeed: 0.0743s/iter; left time: 1103.0916s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734600\n",
      "\tspeed: 0.0426s/iter; left time: 627.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0713078 Vali Loss: 0.0871348 Test Loss: 0.0989215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735072\n",
      "\tspeed: 0.0742s/iter; left time: 1084.6726s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741483\n",
      "\tspeed: 0.0473s/iter; left time: 686.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0713056 Vali Loss: 0.0871275 Test Loss: 0.0989961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0728918\n",
      "\tspeed: 0.0826s/iter; left time: 1188.9078s\n",
      "\titers: 200, epoch: 36 | loss: 0.0666929\n",
      "\tspeed: 0.0412s/iter; left time: 589.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0712683 Vali Loss: 0.0871395 Test Loss: 0.0990887\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0745390\n",
      "\tspeed: 0.0750s/iter; left time: 1062.3159s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715760\n",
      "\tspeed: 0.0411s/iter; left time: 578.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0712489 Vali Loss: 0.0871422 Test Loss: 0.0990047\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02461354248225689, rmse:0.15688703954219818, mae:0.09895447641611099, rse:0.5412158370018005\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1241236\n",
      "\tspeed: 0.0443s/iter; left time: 984.5030s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141754\n",
      "\tspeed: 0.0409s/iter; left time: 903.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.1244885 Vali Loss: 0.1183953 Test Loss: 0.1381955\n",
      "Validation loss decreased (inf --> 0.118395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0812800\n",
      "\tspeed: 0.0752s/iter; left time: 1651.8621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813031\n",
      "\tspeed: 0.0428s/iter; left time: 935.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0860217 Vali Loss: 0.0911778 Test Loss: 0.1037141\n",
      "Validation loss decreased (0.118395 --> 0.091178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0854152\n",
      "\tspeed: 0.0753s/iter; left time: 1638.5817s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821180\n",
      "\tspeed: 0.0424s/iter; left time: 918.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0792323 Vali Loss: 0.0901997 Test Loss: 0.1024127\n",
      "Validation loss decreased (0.091178 --> 0.090200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771382\n",
      "\tspeed: 0.0779s/iter; left time: 1677.9186s\n",
      "\titers: 200, epoch: 4 | loss: 0.0748695\n",
      "\tspeed: 0.0417s/iter; left time: 892.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0776143 Vali Loss: 0.0893536 Test Loss: 0.1021961\n",
      "Validation loss decreased (0.090200 --> 0.089354).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746484\n",
      "\tspeed: 0.0788s/iter; left time: 1679.8393s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762351\n",
      "\tspeed: 0.0423s/iter; left time: 897.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0765393 Vali Loss: 0.0895949 Test Loss: 0.1016256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0704589\n",
      "\tspeed: 0.0762s/iter; left time: 1607.5950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779320\n",
      "\tspeed: 0.0453s/iter; left time: 949.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.0757048 Vali Loss: 0.0887313 Test Loss: 0.1005883\n",
      "Validation loss decreased (0.089354 --> 0.088731).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787142\n",
      "\tspeed: 0.0764s/iter; left time: 1594.4792s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723651\n",
      "\tspeed: 0.0421s/iter; left time: 874.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0752229 Vali Loss: 0.0888143 Test Loss: 0.1010623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749634\n",
      "\tspeed: 0.0752s/iter; left time: 1552.5956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0779372\n",
      "\tspeed: 0.0415s/iter; left time: 851.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0746250 Vali Loss: 0.0880766 Test Loss: 0.0999531\n",
      "Validation loss decreased (0.088731 --> 0.088077).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0755208\n",
      "\tspeed: 0.0779s/iter; left time: 1590.5388s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692909\n",
      "\tspeed: 0.0418s/iter; left time: 848.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0741197 Vali Loss: 0.0877385 Test Loss: 0.1002419\n",
      "Validation loss decreased (0.088077 --> 0.087739).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735870\n",
      "\tspeed: 0.0833s/iter; left time: 1682.1019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762803\n",
      "\tspeed: 0.0456s/iter; left time: 915.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 223 | Train Loss: 0.0737935 Vali Loss: 0.0875983 Test Loss: 0.0999065\n",
      "Validation loss decreased (0.087739 --> 0.087598).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739966\n",
      "\tspeed: 0.0797s/iter; left time: 1590.8784s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750790\n",
      "\tspeed: 0.0411s/iter; left time: 817.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0734880 Vali Loss: 0.0874614 Test Loss: 0.0996489\n",
      "Validation loss decreased (0.087598 --> 0.087461).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0765056\n",
      "\tspeed: 0.0749s/iter; left time: 1479.6047s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719574\n",
      "\tspeed: 0.0430s/iter; left time: 844.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0731832 Vali Loss: 0.0875553 Test Loss: 0.0998995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0682084\n",
      "\tspeed: 0.0759s/iter; left time: 1482.3639s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720051\n",
      "\tspeed: 0.0425s/iter; left time: 825.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0729966 Vali Loss: 0.0875060 Test Loss: 0.0998122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706566\n",
      "\tspeed: 0.0761s/iter; left time: 1468.0225s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754816\n",
      "\tspeed: 0.0429s/iter; left time: 823.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0728083 Vali Loss: 0.0875992 Test Loss: 0.0995544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706279\n",
      "\tspeed: 0.0773s/iter; left time: 1475.5315s\n",
      "\titers: 200, epoch: 15 | loss: 0.0750840\n",
      "\tspeed: 0.0413s/iter; left time: 783.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0726432 Vali Loss: 0.0872414 Test Loss: 0.0996507\n",
      "Validation loss decreased (0.087461 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0797694\n",
      "\tspeed: 0.0765s/iter; left time: 1442.0772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691095\n",
      "\tspeed: 0.0415s/iter; left time: 778.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0724336 Vali Loss: 0.0874647 Test Loss: 0.0995680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0743775\n",
      "\tspeed: 0.0749s/iter; left time: 1394.9423s\n",
      "\titers: 200, epoch: 17 | loss: 0.0741325\n",
      "\tspeed: 0.0427s/iter; left time: 790.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0723469 Vali Loss: 0.0873769 Test Loss: 0.0993158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726027\n",
      "\tspeed: 0.0748s/iter; left time: 1377.1837s\n",
      "\titers: 200, epoch: 18 | loss: 0.0659239\n",
      "\tspeed: 0.0414s/iter; left time: 757.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0721854 Vali Loss: 0.0872896 Test Loss: 0.0991555\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711987\n",
      "\tspeed: 0.0784s/iter; left time: 1426.3078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0673086\n",
      "\tspeed: 0.0418s/iter; left time: 756.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0721364 Vali Loss: 0.0871735 Test Loss: 0.0992202\n",
      "Validation loss decreased (0.087241 --> 0.087173).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731464\n",
      "\tspeed: 0.0767s/iter; left time: 1378.0725s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776331\n",
      "\tspeed: 0.0412s/iter; left time: 736.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0720103 Vali Loss: 0.0872837 Test Loss: 0.0991743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711740\n",
      "\tspeed: 0.0755s/iter; left time: 1339.7905s\n",
      "\titers: 200, epoch: 21 | loss: 0.0753554\n",
      "\tspeed: 0.0427s/iter; left time: 752.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0719040 Vali Loss: 0.0871968 Test Loss: 0.0992067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0715744\n",
      "\tspeed: 0.0759s/iter; left time: 1328.8578s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681315\n",
      "\tspeed: 0.0428s/iter; left time: 744.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0718549 Vali Loss: 0.0871228 Test Loss: 0.0991327\n",
      "Validation loss decreased (0.087173 --> 0.087123).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0704514\n",
      "\tspeed: 0.0766s/iter; left time: 1323.9731s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714713\n",
      "\tspeed: 0.0415s/iter; left time: 713.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0717374 Vali Loss: 0.0870542 Test Loss: 0.0989956\n",
      "Validation loss decreased (0.087123 --> 0.087054).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0751139\n",
      "\tspeed: 0.0781s/iter; left time: 1332.4945s\n",
      "\titers: 200, epoch: 24 | loss: 0.0752301\n",
      "\tspeed: 0.0419s/iter; left time: 711.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0716789 Vali Loss: 0.0870215 Test Loss: 0.0990368\n",
      "Validation loss decreased (0.087054 --> 0.087022).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0707601\n",
      "\tspeed: 0.0786s/iter; left time: 1324.3908s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697482\n",
      "\tspeed: 0.0426s/iter; left time: 713.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 223 | Train Loss: 0.0716772 Vali Loss: 0.0870498 Test Loss: 0.0989855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0707332\n",
      "\tspeed: 0.0748s/iter; left time: 1242.8210s\n",
      "\titers: 200, epoch: 26 | loss: 0.0765021\n",
      "\tspeed: 0.0425s/iter; left time: 702.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0716127 Vali Loss: 0.0868681 Test Loss: 0.0989585\n",
      "Validation loss decreased (0.087022 --> 0.086868).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0703442\n",
      "\tspeed: 0.0753s/iter; left time: 1234.9448s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724373\n",
      "\tspeed: 0.0416s/iter; left time: 677.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0715412 Vali Loss: 0.0870464 Test Loss: 0.0989664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0742472\n",
      "\tspeed: 0.0774s/iter; left time: 1252.0073s\n",
      "\titers: 200, epoch: 28 | loss: 0.0691978\n",
      "\tspeed: 0.0415s/iter; left time: 666.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0714920 Vali Loss: 0.0870631 Test Loss: 0.0991097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0707679\n",
      "\tspeed: 0.0762s/iter; left time: 1216.6364s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695740\n",
      "\tspeed: 0.0421s/iter; left time: 667.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0714264 Vali Loss: 0.0870037 Test Loss: 0.0989200\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0688290\n",
      "\tspeed: 0.0779s/iter; left time: 1225.5661s\n",
      "\titers: 200, epoch: 30 | loss: 0.0660956\n",
      "\tspeed: 0.0414s/iter; left time: 647.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0714084 Vali Loss: 0.0869053 Test Loss: 0.0989998\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0729475\n",
      "\tspeed: 0.0776s/iter; left time: 1204.0116s\n",
      "\titers: 200, epoch: 31 | loss: 0.0695744\n",
      "\tspeed: 0.0431s/iter; left time: 664.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0713882 Vali Loss: 0.0870360 Test Loss: 0.0989691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0672238\n",
      "\tspeed: 0.0760s/iter; left time: 1162.2643s\n",
      "\titers: 200, epoch: 32 | loss: 0.0767676\n",
      "\tspeed: 0.0418s/iter; left time: 634.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0714459 Vali Loss: 0.0869485 Test Loss: 0.0989849\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0716598\n",
      "\tspeed: 0.0799s/iter; left time: 1203.7757s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718821\n",
      "\tspeed: 0.0415s/iter; left time: 621.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713694 Vali Loss: 0.0869131 Test Loss: 0.0990300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0780078\n",
      "\tspeed: 0.0773s/iter; left time: 1147.5751s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725512\n",
      "\tspeed: 0.0423s/iter; left time: 623.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0713690 Vali Loss: 0.0870174 Test Loss: 0.0990362\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0721319\n",
      "\tspeed: 0.0758s/iter; left time: 1108.1308s\n",
      "\titers: 200, epoch: 35 | loss: 0.0699476\n",
      "\tspeed: 0.0417s/iter; left time: 605.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0713216 Vali Loss: 0.0868933 Test Loss: 0.0989647\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0715593\n",
      "\tspeed: 0.0743s/iter; left time: 1068.9621s\n",
      "\titers: 200, epoch: 36 | loss: 0.0704235\n",
      "\tspeed: 0.0422s/iter; left time: 603.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0713195 Vali Loss: 0.0871119 Test Loss: 0.0989298\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024664107710123062, rmse:0.15704810619354248, mae:0.09895854443311691, rse:0.5417714715003967\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:36.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1304873\n",
      "\tspeed: 0.0668s/iter; left time: 1476.8440s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175975\n",
      "\tspeed: 0.0416s/iter; left time: 914.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1310178 Vali Loss: 0.1288243 Test Loss: 0.1522491\n",
      "Validation loss decreased (inf --> 0.128824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1069379\n",
      "\tspeed: 0.0775s/iter; left time: 1694.8193s\n",
      "\titers: 200, epoch: 2 | loss: 0.1099608\n",
      "\tspeed: 0.0416s/iter; left time: 905.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1079090 Vali Loss: 0.1167949 Test Loss: 0.1385253\n",
      "Validation loss decreased (0.128824 --> 0.116795).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1021708\n",
      "\tspeed: 0.0785s/iter; left time: 1699.0059s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059996\n",
      "\tspeed: 0.0429s/iter; left time: 924.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1029873 Vali Loss: 0.1158553 Test Loss: 0.1394041\n",
      "Validation loss decreased (0.116795 --> 0.115855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966939\n",
      "\tspeed: 0.0764s/iter; left time: 1638.0518s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026029\n",
      "\tspeed: 0.0422s/iter; left time: 900.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1014688 Vali Loss: 0.1153081 Test Loss: 0.1391761\n",
      "Validation loss decreased (0.115855 --> 0.115308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027995\n",
      "\tspeed: 0.0787s/iter; left time: 1669.7876s\n",
      "\titers: 200, epoch: 5 | loss: 0.1021266\n",
      "\tspeed: 0.0419s/iter; left time: 885.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004789 Vali Loss: 0.1146756 Test Loss: 0.1379868\n",
      "Validation loss decreased (0.115308 --> 0.114676).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0975265\n",
      "\tspeed: 0.0800s/iter; left time: 1679.8588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993915\n",
      "\tspeed: 0.0419s/iter; left time: 875.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.0995412 Vali Loss: 0.1150273 Test Loss: 0.1383243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968614\n",
      "\tspeed: 0.0781s/iter; left time: 1622.8290s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959852\n",
      "\tspeed: 0.0430s/iter; left time: 888.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986773 Vali Loss: 0.1150765 Test Loss: 0.1379591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994884\n",
      "\tspeed: 0.0775s/iter; left time: 1591.3927s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979322\n",
      "\tspeed: 0.0417s/iter; left time: 852.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0979208 Vali Loss: 0.1156444 Test Loss: 0.1380379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0953856\n",
      "\tspeed: 0.0769s/iter; left time: 1563.0344s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962101\n",
      "\tspeed: 0.0413s/iter; left time: 836.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0971903 Vali Loss: 0.1157434 Test Loss: 0.1375536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941000\n",
      "\tspeed: 0.0782s/iter; left time: 1573.0348s\n",
      "\titers: 200, epoch: 10 | loss: 0.0939218\n",
      "\tspeed: 0.0415s/iter; left time: 829.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.0965265 Vali Loss: 0.1158402 Test Loss: 0.1391500\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0948607\n",
      "\tspeed: 0.0780s/iter; left time: 1551.6565s\n",
      "\titers: 200, epoch: 11 | loss: 0.0935992\n",
      "\tspeed: 0.0417s/iter; left time: 824.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0959107 Vali Loss: 0.1162248 Test Loss: 0.1396610\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0920896\n",
      "\tspeed: 0.0750s/iter; left time: 1474.6129s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940504\n",
      "\tspeed: 0.0425s/iter; left time: 830.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0953595 Vali Loss: 0.1159682 Test Loss: 0.1396242\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0913273\n",
      "\tspeed: 0.0759s/iter; left time: 1476.0173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0974089\n",
      "\tspeed: 0.0413s/iter; left time: 798.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0947790 Vali Loss: 0.1162849 Test Loss: 0.1413390\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0933513\n",
      "\tspeed: 0.0777s/iter; left time: 1493.3694s\n",
      "\titers: 200, epoch: 14 | loss: 0.0954880\n",
      "\tspeed: 0.0418s/iter; left time: 799.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0943125 Vali Loss: 0.1169559 Test Loss: 0.1414862\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0993926\n",
      "\tspeed: 0.0776s/iter; left time: 1474.3737s\n",
      "\titers: 200, epoch: 15 | loss: 0.0961179\n",
      "\tspeed: 0.0415s/iter; left time: 783.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.0938692 Vali Loss: 0.1164688 Test Loss: 0.1422094\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.040224574506282806, rmse:0.20056064426898956, mae:0.13798677921295166, rse:0.6935666799545288\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1305858\n",
      "\tspeed: 0.0446s/iter; left time: 986.5156s\n",
      "\titers: 200, epoch: 1 | loss: 0.1279940\n",
      "\tspeed: 0.0419s/iter; left time: 920.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1310129 Vali Loss: 0.1287763 Test Loss: 0.1517726\n",
      "Validation loss decreased (inf --> 0.128776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1047999\n",
      "\tspeed: 0.0773s/iter; left time: 1691.8110s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011871\n",
      "\tspeed: 0.0423s/iter; left time: 922.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1081233 Vali Loss: 0.1171175 Test Loss: 0.1384159\n",
      "Validation loss decreased (0.128776 --> 0.117118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041322\n",
      "\tspeed: 0.0768s/iter; left time: 1662.2105s\n",
      "\titers: 200, epoch: 3 | loss: 0.0997675\n",
      "\tspeed: 0.0435s/iter; left time: 936.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1030756 Vali Loss: 0.1154505 Test Loss: 0.1378653\n",
      "Validation loss decreased (0.117118 --> 0.115451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1052338\n",
      "\tspeed: 0.0782s/iter; left time: 1676.5682s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011579\n",
      "\tspeed: 0.0418s/iter; left time: 891.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1016301 Vali Loss: 0.1150195 Test Loss: 0.1379458\n",
      "Validation loss decreased (0.115451 --> 0.115019).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0983982\n",
      "\tspeed: 0.0802s/iter; left time: 1702.1037s\n",
      "\titers: 200, epoch: 5 | loss: 0.0970867\n",
      "\tspeed: 0.0416s/iter; left time: 877.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004418 Vali Loss: 0.1147584 Test Loss: 0.1383713\n",
      "Validation loss decreased (0.115019 --> 0.114758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1006362\n",
      "\tspeed: 0.0793s/iter; left time: 1664.9695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0965790\n",
      "\tspeed: 0.0416s/iter; left time: 868.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0992838 Vali Loss: 0.1148322 Test Loss: 0.1393588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966187\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1368s\n",
      "\titers: 200, epoch: 7 | loss: 0.0989298\n",
      "\tspeed: 0.0425s/iter; left time: 878.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0983812 Vali Loss: 0.1146387 Test Loss: 0.1399318\n",
      "Validation loss decreased (0.114758 --> 0.114639).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0930875\n",
      "\tspeed: 0.0778s/iter; left time: 1598.6296s\n",
      "\titers: 200, epoch: 8 | loss: 0.0929199\n",
      "\tspeed: 0.0429s/iter; left time: 877.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.0972934 Vali Loss: 0.1146473 Test Loss: 0.1403886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951188\n",
      "\tspeed: 0.0772s/iter; left time: 1568.9761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0949333\n",
      "\tspeed: 0.0414s/iter; left time: 838.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0964337 Vali Loss: 0.1151828 Test Loss: 0.1416367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989180\n",
      "\tspeed: 0.0785s/iter; left time: 1577.9541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0938160\n",
      "\tspeed: 0.0416s/iter; left time: 831.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0956362 Vali Loss: 0.1152233 Test Loss: 0.1418035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0915988\n",
      "\tspeed: 0.0785s/iter; left time: 1560.3960s\n",
      "\titers: 200, epoch: 11 | loss: 0.0964191\n",
      "\tspeed: 0.0415s/iter; left time: 820.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0949925 Vali Loss: 0.1158287 Test Loss: 0.1423944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0963742\n",
      "\tspeed: 0.0773s/iter; left time: 1519.4097s\n",
      "\titers: 200, epoch: 12 | loss: 0.0933959\n",
      "\tspeed: 0.0423s/iter; left time: 827.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.0941572 Vali Loss: 0.1160542 Test Loss: 0.1424110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961953\n",
      "\tspeed: 0.0762s/iter; left time: 1480.6556s\n",
      "\titers: 200, epoch: 13 | loss: 0.0965029\n",
      "\tspeed: 0.0421s/iter; left time: 814.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0936945 Vali Loss: 0.1154687 Test Loss: 0.1416178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0912792\n",
      "\tspeed: 0.0774s/iter; left time: 1486.3895s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940753\n",
      "\tspeed: 0.0413s/iter; left time: 789.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0929719 Vali Loss: 0.1157708 Test Loss: 0.1427507\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0968269\n",
      "\tspeed: 0.0794s/iter; left time: 1507.9914s\n",
      "\titers: 200, epoch: 15 | loss: 0.0915315\n",
      "\tspeed: 0.0417s/iter; left time: 787.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0925117 Vali Loss: 0.1161520 Test Loss: 0.1430477\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0888845\n",
      "\tspeed: 0.0785s/iter; left time: 1474.0309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930691\n",
      "\tspeed: 0.0414s/iter; left time: 772.2440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0921011 Vali Loss: 0.1164447 Test Loss: 0.1432250\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0904549\n",
      "\tspeed: 0.0771s/iter; left time: 1431.0215s\n",
      "\titers: 200, epoch: 17 | loss: 0.0925897\n",
      "\tspeed: 0.0430s/iter; left time: 792.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0916482 Vali Loss: 0.1165479 Test Loss: 0.1434288\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041966523975133896, rmse:0.20485731959342957, mae:0.13993188738822937, rse:0.7084251642227173\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:36.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1260497\n",
      "\tspeed: 0.0661s/iter; left time: 1461.0643s\n",
      "\titers: 200, epoch: 1 | loss: 0.1233853\n",
      "\tspeed: 0.0420s/iter; left time: 924.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1326778 Vali Loss: 0.1309269 Test Loss: 0.1548633\n",
      "Validation loss decreased (inf --> 0.130927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1094469\n",
      "\tspeed: 0.0794s/iter; left time: 1737.2973s\n",
      "\titers: 200, epoch: 2 | loss: 0.1086948\n",
      "\tspeed: 0.0417s/iter; left time: 908.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1121342 Vali Loss: 0.1213708 Test Loss: 0.1448956\n",
      "Validation loss decreased (0.130927 --> 0.121371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085828\n",
      "\tspeed: 0.0805s/iter; left time: 1744.2921s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110668\n",
      "\tspeed: 0.0420s/iter; left time: 905.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1075699 Vali Loss: 0.1199603 Test Loss: 0.1443719\n",
      "Validation loss decreased (0.121371 --> 0.119960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1096162\n",
      "\tspeed: 0.0780s/iter; left time: 1671.4152s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028981\n",
      "\tspeed: 0.0438s/iter; left time: 934.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1060007 Vali Loss: 0.1197756 Test Loss: 0.1440592\n",
      "Validation loss decreased (0.119960 --> 0.119776).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043223\n",
      "\tspeed: 0.0785s/iter; left time: 1664.7745s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071000\n",
      "\tspeed: 0.0431s/iter; left time: 908.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1046242 Vali Loss: 0.1203860 Test Loss: 0.1448624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994743\n",
      "\tspeed: 0.0777s/iter; left time: 1630.2978s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044898\n",
      "\tspeed: 0.0422s/iter; left time: 881.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.1033739 Vali Loss: 0.1210232 Test Loss: 0.1450372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1018771\n",
      "\tspeed: 0.0785s/iter; left time: 1630.0362s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027877\n",
      "\tspeed: 0.0421s/iter; left time: 869.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1023430 Vali Loss: 0.1218093 Test Loss: 0.1471738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995843\n",
      "\tspeed: 0.0778s/iter; left time: 1599.1551s\n",
      "\titers: 200, epoch: 8 | loss: 0.0966036\n",
      "\tspeed: 0.0417s/iter; left time: 853.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1014311 Vali Loss: 0.1216973 Test Loss: 0.1467350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010340\n",
      "\tspeed: 0.0765s/iter; left time: 1554.9552s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001390\n",
      "\tspeed: 0.0433s/iter; left time: 875.0557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1004857 Vali Loss: 0.1226195 Test Loss: 0.1462484\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983590\n",
      "\tspeed: 0.0768s/iter; left time: 1543.3019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0999743\n",
      "\tspeed: 0.0422s/iter; left time: 844.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.0997015 Vali Loss: 0.1216679 Test Loss: 0.1459581\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025495\n",
      "\tspeed: 0.0789s/iter; left time: 1567.7444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974560\n",
      "\tspeed: 0.0419s/iter; left time: 828.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.0988213 Vali Loss: 0.1222738 Test Loss: 0.1464456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1022936\n",
      "\tspeed: 0.0794s/iter; left time: 1561.1810s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971468\n",
      "\tspeed: 0.0421s/iter; left time: 823.0657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0980070 Vali Loss: 0.1221250 Test Loss: 0.1460842\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0957897\n",
      "\tspeed: 0.0791s/iter; left time: 1537.1685s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973659\n",
      "\tspeed: 0.0420s/iter; left time: 811.4997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0972951 Vali Loss: 0.1227004 Test Loss: 0.1479962\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920695\n",
      "\tspeed: 0.0766s/iter; left time: 1471.0401s\n",
      "\titers: 200, epoch: 14 | loss: 0.0948682\n",
      "\tspeed: 0.0431s/iter; left time: 823.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0966523 Vali Loss: 0.1230309 Test Loss: 0.1473147\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04283905029296875, rmse:0.20697596669197083, mae:0.14405910670757294, rse:0.7176154255867004\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354174\n",
      "\tspeed: 0.0440s/iter; left time: 971.9497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272134\n",
      "\tspeed: 0.0429s/iter; left time: 944.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.1335480 Vali Loss: 0.1309509 Test Loss: 0.1545976\n",
      "Validation loss decreased (inf --> 0.130951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1133488\n",
      "\tspeed: 0.0801s/iter; left time: 1753.2463s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126153\n",
      "\tspeed: 0.0433s/iter; left time: 942.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1122327 Vali Loss: 0.1214331 Test Loss: 0.1448028\n",
      "Validation loss decreased (0.130951 --> 0.121433).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069784\n",
      "\tspeed: 0.0798s/iter; left time: 1727.5802s\n",
      "\titers: 200, epoch: 3 | loss: 0.1111818\n",
      "\tspeed: 0.0419s/iter; left time: 903.1948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1077125 Vali Loss: 0.1202011 Test Loss: 0.1457766\n",
      "Validation loss decreased (0.121433 --> 0.120201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072374\n",
      "\tspeed: 0.0850s/iter; left time: 1821.7096s\n",
      "\titers: 200, epoch: 4 | loss: 0.1061509\n",
      "\tspeed: 0.0422s/iter; left time: 901.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.1062208 Vali Loss: 0.1202800 Test Loss: 0.1458177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077023\n",
      "\tspeed: 0.0798s/iter; left time: 1693.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043039\n",
      "\tspeed: 0.0420s/iter; left time: 886.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.1048119 Vali Loss: 0.1204090 Test Loss: 0.1450815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1053132\n",
      "\tspeed: 0.0778s/iter; left time: 1633.7682s\n",
      "\titers: 200, epoch: 6 | loss: 0.1045556\n",
      "\tspeed: 0.0430s/iter; left time: 897.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1033933 Vali Loss: 0.1211432 Test Loss: 0.1460922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1010433\n",
      "\tspeed: 0.0777s/iter; left time: 1614.5203s\n",
      "\titers: 200, epoch: 7 | loss: 0.0984273\n",
      "\tspeed: 0.0427s/iter; left time: 883.2299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1019883 Vali Loss: 0.1219406 Test Loss: 0.1475383\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1020061\n",
      "\tspeed: 0.0777s/iter; left time: 1596.4580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0999632\n",
      "\tspeed: 0.0422s/iter; left time: 862.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1006895 Vali Loss: 0.1223867 Test Loss: 0.1473340\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0978350\n",
      "\tspeed: 0.0805s/iter; left time: 1636.4255s\n",
      "\titers: 200, epoch: 9 | loss: 0.0947712\n",
      "\tspeed: 0.0417s/iter; left time: 843.6268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0993827 Vali Loss: 0.1230524 Test Loss: 0.1467847\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975076\n",
      "\tspeed: 0.0788s/iter; left time: 1583.7119s\n",
      "\titers: 200, epoch: 10 | loss: 0.0976299\n",
      "\tspeed: 0.0428s/iter; left time: 856.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.0981397 Vali Loss: 0.1236404 Test Loss: 0.1466535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0939989\n",
      "\tspeed: 0.0793s/iter; left time: 1575.7932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0989537\n",
      "\tspeed: 0.0428s/iter; left time: 846.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0970986 Vali Loss: 0.1238450 Test Loss: 0.1473410\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0958038\n",
      "\tspeed: 0.0792s/iter; left time: 1556.7527s\n",
      "\titers: 200, epoch: 12 | loss: 0.0997026\n",
      "\tspeed: 0.0424s/iter; left time: 829.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0961723 Vali Loss: 0.1241202 Test Loss: 0.1478169\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0963423\n",
      "\tspeed: 0.0793s/iter; left time: 1542.2571s\n",
      "\titers: 200, epoch: 13 | loss: 0.0922489\n",
      "\tspeed: 0.0446s/iter; left time: 861.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 222 | Train Loss: 0.0953029 Vali Loss: 0.1242875 Test Loss: 0.1478923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0440988764166832, rmse:0.20999732613563538, mae:0.14577659964561462, rse:0.7280909419059753\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:42.00s\n",
      "Intermediate time for GB: 00h:26m:55.22s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1177848\n",
      "\tspeed: 0.0475s/iter; left time: 1054.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1059930\n",
      "\tspeed: 0.0268s/iter; left time: 591.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.1258416 Vali Loss: 0.0933806 Test Loss: 0.1067235\n",
      "Validation loss decreased (inf --> 0.093381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721758\n",
      "\tspeed: 0.0526s/iter; left time: 1155.1685s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688074\n",
      "\tspeed: 0.0265s/iter; left time: 578.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0746695 Vali Loss: 0.0630054 Test Loss: 0.0701760\n",
      "Validation loss decreased (0.093381 --> 0.063005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640021\n",
      "\tspeed: 0.0541s/iter; left time: 1177.7243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631628\n",
      "\tspeed: 0.0266s/iter; left time: 575.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0643662 Vali Loss: 0.0596727 Test Loss: 0.0664817\n",
      "Validation loss decreased (0.063005 --> 0.059673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0633358\n",
      "\tspeed: 0.0522s/iter; left time: 1123.8531s\n",
      "\titers: 200, epoch: 4 | loss: 0.0598588\n",
      "\tspeed: 0.0274s/iter; left time: 587.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0616559 Vali Loss: 0.0577069 Test Loss: 0.0649258\n",
      "Validation loss decreased (0.059673 --> 0.057707).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600730\n",
      "\tspeed: 0.0542s/iter; left time: 1154.8282s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604561\n",
      "\tspeed: 0.0269s/iter; left time: 569.8563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0598165 Vali Loss: 0.0575377 Test Loss: 0.0640054\n",
      "Validation loss decreased (0.057707 --> 0.057538).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0562785\n",
      "\tspeed: 0.0525s/iter; left time: 1107.4072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0579553\n",
      "\tspeed: 0.0270s/iter; left time: 566.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0587862 Vali Loss: 0.0562634 Test Loss: 0.0629574\n",
      "Validation loss decreased (0.057538 --> 0.056263).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542753\n",
      "\tspeed: 0.0552s/iter; left time: 1152.4921s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573975\n",
      "\tspeed: 0.0267s/iter; left time: 554.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0578910 Vali Loss: 0.0557560 Test Loss: 0.0622238\n",
      "Validation loss decreased (0.056263 --> 0.055756).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0539824\n",
      "\tspeed: 0.0533s/iter; left time: 1100.2134s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542981\n",
      "\tspeed: 0.0279s/iter; left time: 572.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0572106 Vali Loss: 0.0555416 Test Loss: 0.0623640\n",
      "Validation loss decreased (0.055756 --> 0.055542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0544912\n",
      "\tspeed: 0.0526s/iter; left time: 1073.0902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0562044\n",
      "\tspeed: 0.0275s/iter; left time: 558.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0565972 Vali Loss: 0.0552657 Test Loss: 0.0625549\n",
      "Validation loss decreased (0.055542 --> 0.055266).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573178\n",
      "\tspeed: 0.0530s/iter; left time: 1070.0248s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550786\n",
      "\tspeed: 0.0288s/iter; left time: 577.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0561248 Vali Loss: 0.0548072 Test Loss: 0.0617649\n",
      "Validation loss decreased (0.055266 --> 0.054807).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0549671\n",
      "\tspeed: 0.0519s/iter; left time: 1037.4837s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561140\n",
      "\tspeed: 0.0264s/iter; left time: 525.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0556483 Vali Loss: 0.0546315 Test Loss: 0.0615806\n",
      "Validation loss decreased (0.054807 --> 0.054632).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561196\n",
      "\tspeed: 0.0520s/iter; left time: 1025.9605s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555787\n",
      "\tspeed: 0.0272s/iter; left time: 533.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0552293 Vali Loss: 0.0543794 Test Loss: 0.0613876\n",
      "Validation loss decreased (0.054632 --> 0.054379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533709\n",
      "\tspeed: 0.0533s/iter; left time: 1041.6509s\n",
      "\titers: 200, epoch: 13 | loss: 0.0539893\n",
      "\tspeed: 0.0267s/iter; left time: 517.7904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0549254 Vali Loss: 0.0543318 Test Loss: 0.0609576\n",
      "Validation loss decreased (0.054379 --> 0.054332).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530030\n",
      "\tspeed: 0.0521s/iter; left time: 1006.1253s\n",
      "\titers: 200, epoch: 14 | loss: 0.0533630\n",
      "\tspeed: 0.0285s/iter; left time: 547.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0545588 Vali Loss: 0.0541453 Test Loss: 0.0611451\n",
      "Validation loss decreased (0.054332 --> 0.054145).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500635\n",
      "\tspeed: 0.0516s/iter; left time: 985.3657s\n",
      "\titers: 200, epoch: 15 | loss: 0.0591192\n",
      "\tspeed: 0.0266s/iter; left time: 504.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0543057 Vali Loss: 0.0539221 Test Loss: 0.0611182\n",
      "Validation loss decreased (0.054145 --> 0.053922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566576\n",
      "\tspeed: 0.0524s/iter; left time: 987.9545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502781\n",
      "\tspeed: 0.0268s/iter; left time: 502.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0540829 Vali Loss: 0.0538061 Test Loss: 0.0607462\n",
      "Validation loss decreased (0.053922 --> 0.053806).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0566290\n",
      "\tspeed: 0.0521s/iter; left time: 971.4521s\n",
      "\titers: 200, epoch: 17 | loss: 0.0503884\n",
      "\tspeed: 0.0265s/iter; left time: 490.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0539302 Vali Loss: 0.0534953 Test Loss: 0.0605199\n",
      "Validation loss decreased (0.053806 --> 0.053495).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572149\n",
      "\tspeed: 0.0537s/iter; left time: 988.0298s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543917\n",
      "\tspeed: 0.0265s/iter; left time: 485.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0537375 Vali Loss: 0.0535588 Test Loss: 0.0605998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0552805\n",
      "\tspeed: 0.0514s/iter; left time: 935.1159s\n",
      "\titers: 200, epoch: 19 | loss: 0.0523237\n",
      "\tspeed: 0.0263s/iter; left time: 474.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0535796 Vali Loss: 0.0535295 Test Loss: 0.0603616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545848\n",
      "\tspeed: 0.0537s/iter; left time: 965.2525s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549286\n",
      "\tspeed: 0.0268s/iter; left time: 478.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0534138 Vali Loss: 0.0532950 Test Loss: 0.0604182\n",
      "Validation loss decreased (0.053495 --> 0.053295).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0529836\n",
      "\tspeed: 0.0532s/iter; left time: 944.3567s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538217\n",
      "\tspeed: 0.0264s/iter; left time: 465.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533455 Vali Loss: 0.0530735 Test Loss: 0.0601349\n",
      "Validation loss decreased (0.053295 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533596\n",
      "\tspeed: 0.0563s/iter; left time: 986.5509s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551906\n",
      "\tspeed: 0.0264s/iter; left time: 459.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0531747 Vali Loss: 0.0531457 Test Loss: 0.0603495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0533368\n",
      "\tspeed: 0.0512s/iter; left time: 885.7195s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566950\n",
      "\tspeed: 0.0280s/iter; left time: 481.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0530683 Vali Loss: 0.0531179 Test Loss: 0.0601824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560505\n",
      "\tspeed: 0.0540s/iter; left time: 922.4103s\n",
      "\titers: 200, epoch: 24 | loss: 0.0509092\n",
      "\tspeed: 0.0274s/iter; left time: 465.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0529976 Vali Loss: 0.0531084 Test Loss: 0.0601074\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0558175\n",
      "\tspeed: 0.0519s/iter; left time: 873.8136s\n",
      "\titers: 200, epoch: 25 | loss: 0.0517861\n",
      "\tspeed: 0.0268s/iter; left time: 449.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0529033 Vali Loss: 0.0531205 Test Loss: 0.0602300\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513149\n",
      "\tspeed: 0.0511s/iter; left time: 849.6052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0500016\n",
      "\tspeed: 0.0263s/iter; left time: 434.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0528154 Vali Loss: 0.0529059 Test Loss: 0.0601533\n",
      "Validation loss decreased (0.053073 --> 0.052906).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0518654\n",
      "\tspeed: 0.0519s/iter; left time: 851.0316s\n",
      "\titers: 200, epoch: 27 | loss: 0.0523646\n",
      "\tspeed: 0.0278s/iter; left time: 453.0433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0527788 Vali Loss: 0.0531640 Test Loss: 0.0602123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0533427\n",
      "\tspeed: 0.0525s/iter; left time: 849.6665s\n",
      "\titers: 200, epoch: 28 | loss: 0.0546841\n",
      "\tspeed: 0.0264s/iter; left time: 424.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0527124 Vali Loss: 0.0528726 Test Loss: 0.0599036\n",
      "Validation loss decreased (0.052906 --> 0.052873).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0509959\n",
      "\tspeed: 0.0522s/iter; left time: 833.0148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0543811\n",
      "\tspeed: 0.0274s/iter; left time: 435.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0526367 Vali Loss: 0.0528099 Test Loss: 0.0598749\n",
      "Validation loss decreased (0.052873 --> 0.052810).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0536711\n",
      "\tspeed: 0.0540s/iter; left time: 849.1549s\n",
      "\titers: 200, epoch: 30 | loss: 0.0521599\n",
      "\tspeed: 0.0265s/iter; left time: 414.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525897 Vali Loss: 0.0528667 Test Loss: 0.0601898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525367\n",
      "\tspeed: 0.0504s/iter; left time: 781.6923s\n",
      "\titers: 200, epoch: 31 | loss: 0.0528346\n",
      "\tspeed: 0.0267s/iter; left time: 411.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525614 Vali Loss: 0.0528139 Test Loss: 0.0600230\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510059\n",
      "\tspeed: 0.0549s/iter; left time: 839.7299s\n",
      "\titers: 200, epoch: 32 | loss: 0.0555225\n",
      "\tspeed: 0.0267s/iter; left time: 405.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0525297 Vali Loss: 0.0528147 Test Loss: 0.0600315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553756\n",
      "\tspeed: 0.0517s/iter; left time: 778.7115s\n",
      "\titers: 200, epoch: 33 | loss: 0.0561647\n",
      "\tspeed: 0.0269s/iter; left time: 402.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0524675 Vali Loss: 0.0527943 Test Loss: 0.0599646\n",
      "Validation loss decreased (0.052810 --> 0.052794).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547888\n",
      "\tspeed: 0.0546s/iter; left time: 810.3476s\n",
      "\titers: 200, epoch: 34 | loss: 0.0502540\n",
      "\tspeed: 0.0264s/iter; left time: 389.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0524123 Vali Loss: 0.0527812 Test Loss: 0.0600052\n",
      "Validation loss decreased (0.052794 --> 0.052781).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539715\n",
      "\tspeed: 0.0522s/iter; left time: 763.3288s\n",
      "\titers: 200, epoch: 35 | loss: 0.0542529\n",
      "\tspeed: 0.0288s/iter; left time: 417.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0523824 Vali Loss: 0.0526560 Test Loss: 0.0598498\n",
      "Validation loss decreased (0.052781 --> 0.052656).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0540629\n",
      "\tspeed: 0.0551s/iter; left time: 793.6323s\n",
      "\titers: 200, epoch: 36 | loss: 0.0535191\n",
      "\tspeed: 0.0267s/iter; left time: 381.9144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0523539 Vali Loss: 0.0526808 Test Loss: 0.0598498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0506244\n",
      "\tspeed: 0.0521s/iter; left time: 738.5504s\n",
      "\titers: 200, epoch: 37 | loss: 0.0530473\n",
      "\tspeed: 0.0274s/iter; left time: 385.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523549 Vali Loss: 0.0526425 Test Loss: 0.0598658\n",
      "Validation loss decreased (0.052656 --> 0.052643).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0527134\n",
      "\tspeed: 0.0556s/iter; left time: 775.5018s\n",
      "\titers: 200, epoch: 38 | loss: 0.0536440\n",
      "\tspeed: 0.0265s/iter; left time: 366.8005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523354 Vali Loss: 0.0528015 Test Loss: 0.0598641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0523238\n",
      "\tspeed: 0.0513s/iter; left time: 704.6534s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517573\n",
      "\tspeed: 0.0294s/iter; left time: 400.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0523230 Vali Loss: 0.0526925 Test Loss: 0.0598390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0538465\n",
      "\tspeed: 0.0518s/iter; left time: 699.8013s\n",
      "\titers: 200, epoch: 40 | loss: 0.0512804\n",
      "\tspeed: 0.0268s/iter; left time: 359.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522718 Vali Loss: 0.0526854 Test Loss: 0.0598257\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530373\n",
      "\tspeed: 0.0519s/iter; left time: 689.1349s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532438\n",
      "\tspeed: 0.0281s/iter; left time: 370.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522268 Vali Loss: 0.0526668 Test Loss: 0.0599239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0498807\n",
      "\tspeed: 0.0514s/iter; left time: 670.6596s\n",
      "\titers: 200, epoch: 42 | loss: 0.0523962\n",
      "\tspeed: 0.0267s/iter; left time: 346.4268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522847 Vali Loss: 0.0526407 Test Loss: 0.0598294\n",
      "Validation loss decreased (0.052643 --> 0.052641).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0534996\n",
      "\tspeed: 0.0540s/iter; left time: 692.4492s\n",
      "\titers: 200, epoch: 43 | loss: 0.0532958\n",
      "\tspeed: 0.0271s/iter; left time: 345.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0523306 Vali Loss: 0.0525946 Test Loss: 0.0597619\n",
      "Validation loss decreased (0.052641 --> 0.052595).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526985\n",
      "\tspeed: 0.0521s/iter; left time: 656.6391s\n",
      "\titers: 200, epoch: 44 | loss: 0.0511877\n",
      "\tspeed: 0.0270s/iter; left time: 337.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0521692 Vali Loss: 0.0526428 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556191\n",
      "\tspeed: 0.0533s/iter; left time: 660.9343s\n",
      "\titers: 200, epoch: 45 | loss: 0.0514222\n",
      "\tspeed: 0.0284s/iter; left time: 349.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0522454 Vali Loss: 0.0526971 Test Loss: 0.0597938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0529044\n",
      "\tspeed: 0.0522s/iter; left time: 635.0330s\n",
      "\titers: 200, epoch: 46 | loss: 0.0533347\n",
      "\tspeed: 0.0263s/iter; left time: 316.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0522511 Vali Loss: 0.0526150 Test Loss: 0.0598379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0525579\n",
      "\tspeed: 0.0556s/iter; left time: 663.7137s\n",
      "\titers: 200, epoch: 47 | loss: 0.0559584\n",
      "\tspeed: 0.0270s/iter; left time: 319.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522442 Vali Loss: 0.0526613 Test Loss: 0.0597907\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522379\n",
      "\tspeed: 0.0513s/iter; left time: 601.7284s\n",
      "\titers: 200, epoch: 48 | loss: 0.0542752\n",
      "\tspeed: 0.0267s/iter; left time: 310.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0521854 Vali Loss: 0.0526289 Test Loss: 0.0597892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549363\n",
      "\tspeed: 0.0526s/iter; left time: 604.4033s\n",
      "\titers: 200, epoch: 49 | loss: 0.0465775\n",
      "\tspeed: 0.0264s/iter; left time: 300.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0522630 Vali Loss: 0.0526140 Test Loss: 0.0598117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0494051\n",
      "\tspeed: 0.0507s/iter; left time: 571.0883s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522640\n",
      "\tspeed: 0.0267s/iter; left time: 298.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0522751 Vali Loss: 0.0526901 Test Loss: 0.0599105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0573033\n",
      "\tspeed: 0.0538s/iter; left time: 594.8035s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508314\n",
      "\tspeed: 0.0268s/iter; left time: 293.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521932 Vali Loss: 0.0526688 Test Loss: 0.0598051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0495923\n",
      "\tspeed: 0.0525s/iter; left time: 568.0226s\n",
      "\titers: 200, epoch: 52 | loss: 0.0519124\n",
      "\tspeed: 0.0267s/iter; left time: 286.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522027 Vali Loss: 0.0526402 Test Loss: 0.0598215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548224\n",
      "\tspeed: 0.0537s/iter; left time: 569.8401s\n",
      "\titers: 200, epoch: 53 | loss: 0.0511640\n",
      "\tspeed: 0.0267s/iter; left time: 280.9340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521802 Vali Loss: 0.0526538 Test Loss: 0.0598073\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009856260381639004, rmse:0.09927870333194733, mae:0.059761930257081985, rse:0.29216518998146057\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1225064\n",
      "\tspeed: 0.0293s/iter; left time: 649.8441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1018515\n",
      "\tspeed: 0.0285s/iter; left time: 630.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1260264 Vali Loss: 0.0930495 Test Loss: 0.1065131\n",
      "Validation loss decreased (inf --> 0.093049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0733656\n",
      "\tspeed: 0.0531s/iter; left time: 1166.1485s\n",
      "\titers: 200, epoch: 2 | loss: 0.0689993\n",
      "\tspeed: 0.0264s/iter; left time: 578.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0747297 Vali Loss: 0.0627035 Test Loss: 0.0696848\n",
      "Validation loss decreased (0.093049 --> 0.062703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641976\n",
      "\tspeed: 0.0527s/iter; left time: 1147.3285s\n",
      "\titers: 200, epoch: 3 | loss: 0.0600092\n",
      "\tspeed: 0.0267s/iter; left time: 577.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0643813 Vali Loss: 0.0594397 Test Loss: 0.0659568\n",
      "Validation loss decreased (0.062703 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0578316\n",
      "\tspeed: 0.0529s/iter; left time: 1139.9557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639258\n",
      "\tspeed: 0.0266s/iter; left time: 570.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0614354 Vali Loss: 0.0580388 Test Loss: 0.0646078\n",
      "Validation loss decreased (0.059440 --> 0.058039).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601949\n",
      "\tspeed: 0.0529s/iter; left time: 1127.1254s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646062\n",
      "\tspeed: 0.0263s/iter; left time: 557.4764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0598467 Vali Loss: 0.0574702 Test Loss: 0.0642393\n",
      "Validation loss decreased (0.058039 --> 0.057470).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582525\n",
      "\tspeed: 0.0531s/iter; left time: 1120.5297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598998\n",
      "\tspeed: 0.0264s/iter; left time: 554.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0587508 Vali Loss: 0.0564080 Test Loss: 0.0630445\n",
      "Validation loss decreased (0.057470 --> 0.056408).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556834\n",
      "\tspeed: 0.0529s/iter; left time: 1104.6372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605512\n",
      "\tspeed: 0.0266s/iter; left time: 552.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0577860 Vali Loss: 0.0561291 Test Loss: 0.0630853\n",
      "Validation loss decreased (0.056408 --> 0.056129).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0619714\n",
      "\tspeed: 0.0538s/iter; left time: 1110.8849s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560631\n",
      "\tspeed: 0.0274s/iter; left time: 563.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570553 Vali Loss: 0.0551744 Test Loss: 0.0620771\n",
      "Validation loss decreased (0.056129 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543769\n",
      "\tspeed: 0.0527s/iter; left time: 1076.3225s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573231\n",
      "\tspeed: 0.0267s/iter; left time: 542.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0564490 Vali Loss: 0.0553923 Test Loss: 0.0621985\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564896\n",
      "\tspeed: 0.0536s/iter; left time: 1082.7952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550005\n",
      "\tspeed: 0.0266s/iter; left time: 533.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0559311 Vali Loss: 0.0548954 Test Loss: 0.0616808\n",
      "Validation loss decreased (0.055174 --> 0.054895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559047\n",
      "\tspeed: 0.0522s/iter; left time: 1042.0117s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561010\n",
      "\tspeed: 0.0267s/iter; left time: 530.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0554993 Vali Loss: 0.0547145 Test Loss: 0.0616678\n",
      "Validation loss decreased (0.054895 --> 0.054715).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549887\n",
      "\tspeed: 0.0530s/iter; left time: 1046.4545s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535350\n",
      "\tspeed: 0.0274s/iter; left time: 537.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0550779 Vali Loss: 0.0541503 Test Loss: 0.0611615\n",
      "Validation loss decreased (0.054715 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564112\n",
      "\tspeed: 0.0521s/iter; left time: 1016.2813s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547302\n",
      "\tspeed: 0.0267s/iter; left time: 518.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0548484 Vali Loss: 0.0540437 Test Loss: 0.0611038\n",
      "Validation loss decreased (0.054150 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563114\n",
      "\tspeed: 0.0555s/iter; left time: 1071.2768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546800\n",
      "\tspeed: 0.0265s/iter; left time: 508.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0545632 Vali Loss: 0.0538223 Test Loss: 0.0608727\n",
      "Validation loss decreased (0.054044 --> 0.053822).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582940\n",
      "\tspeed: 0.0523s/iter; left time: 997.0774s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569442\n",
      "\tspeed: 0.0268s/iter; left time: 507.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0542870 Vali Loss: 0.0536832 Test Loss: 0.0606616\n",
      "Validation loss decreased (0.053822 --> 0.053683).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569478\n",
      "\tspeed: 0.0532s/iter; left time: 1003.7836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538614\n",
      "\tspeed: 0.0274s/iter; left time: 513.2290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0540642 Vali Loss: 0.0534916 Test Loss: 0.0607154\n",
      "Validation loss decreased (0.053683 --> 0.053492).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0559539\n",
      "\tspeed: 0.0518s/iter; left time: 965.5459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532772\n",
      "\tspeed: 0.0265s/iter; left time: 491.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0538495 Vali Loss: 0.0537074 Test Loss: 0.0608297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547949\n",
      "\tspeed: 0.0536s/iter; left time: 986.6825s\n",
      "\titers: 200, epoch: 18 | loss: 0.0560665\n",
      "\tspeed: 0.0266s/iter; left time: 486.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0536505 Vali Loss: 0.0534455 Test Loss: 0.0606475\n",
      "Validation loss decreased (0.053492 --> 0.053446).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0518258\n",
      "\tspeed: 0.0518s/iter; left time: 942.7260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0533621\n",
      "\tspeed: 0.0271s/iter; left time: 489.3186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0534612 Vali Loss: 0.0531519 Test Loss: 0.0604471\n",
      "Validation loss decreased (0.053446 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0547985\n",
      "\tspeed: 0.0555s/iter; left time: 997.1039s\n",
      "\titers: 200, epoch: 20 | loss: 0.0515255\n",
      "\tspeed: 0.0269s/iter; left time: 480.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0534055 Vali Loss: 0.0532615 Test Loss: 0.0602668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0534183\n",
      "\tspeed: 0.0526s/iter; left time: 932.3127s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536347\n",
      "\tspeed: 0.0276s/iter; left time: 487.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0532890 Vali Loss: 0.0531846 Test Loss: 0.0605303\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549916\n",
      "\tspeed: 0.0541s/iter; left time: 947.9029s\n",
      "\titers: 200, epoch: 22 | loss: 0.0554341\n",
      "\tspeed: 0.0266s/iter; left time: 462.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0531466 Vali Loss: 0.0528900 Test Loss: 0.0601454\n",
      "Validation loss decreased (0.053152 --> 0.052890).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513683\n",
      "\tspeed: 0.0526s/iter; left time: 909.7789s\n",
      "\titers: 200, epoch: 23 | loss: 0.0579329\n",
      "\tspeed: 0.0269s/iter; left time: 463.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0530312 Vali Loss: 0.0530480 Test Loss: 0.0602246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499048\n",
      "\tspeed: 0.0535s/iter; left time: 913.9284s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510843\n",
      "\tspeed: 0.0267s/iter; left time: 453.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0529737 Vali Loss: 0.0528694 Test Loss: 0.0602031\n",
      "Validation loss decreased (0.052890 --> 0.052869).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0577566\n",
      "\tspeed: 0.0523s/iter; left time: 881.3431s\n",
      "\titers: 200, epoch: 25 | loss: 0.0551628\n",
      "\tspeed: 0.0270s/iter; left time: 451.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0528067 Vali Loss: 0.0529870 Test Loss: 0.0601069\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513571\n",
      "\tspeed: 0.0522s/iter; left time: 867.8912s\n",
      "\titers: 200, epoch: 26 | loss: 0.0499296\n",
      "\tspeed: 0.0266s/iter; left time: 438.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0527925 Vali Loss: 0.0529492 Test Loss: 0.0600720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0509044\n",
      "\tspeed: 0.0517s/iter; left time: 848.6226s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493349\n",
      "\tspeed: 0.0272s/iter; left time: 443.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0527369 Vali Loss: 0.0528136 Test Loss: 0.0599594\n",
      "Validation loss decreased (0.052869 --> 0.052814).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532001\n",
      "\tspeed: 0.0525s/iter; left time: 849.3808s\n",
      "\titers: 200, epoch: 28 | loss: 0.0511784\n",
      "\tspeed: 0.0267s/iter; left time: 430.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526384 Vali Loss: 0.0528487 Test Loss: 0.0599587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0495770\n",
      "\tspeed: 0.0530s/iter; left time: 844.9906s\n",
      "\titers: 200, epoch: 29 | loss: 0.0464556\n",
      "\tspeed: 0.0269s/iter; left time: 427.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526565 Vali Loss: 0.0527931 Test Loss: 0.0599919\n",
      "Validation loss decreased (0.052814 --> 0.052793).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0552674\n",
      "\tspeed: 0.0517s/iter; left time: 813.9372s\n",
      "\titers: 200, epoch: 30 | loss: 0.0527033\n",
      "\tspeed: 0.0268s/iter; left time: 418.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0525646 Vali Loss: 0.0527250 Test Loss: 0.0599071\n",
      "Validation loss decreased (0.052793 --> 0.052725).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544455\n",
      "\tspeed: 0.0538s/iter; left time: 834.2253s\n",
      "\titers: 200, epoch: 31 | loss: 0.0547280\n",
      "\tspeed: 0.0275s/iter; left time: 424.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0525626 Vali Loss: 0.0527098 Test Loss: 0.0599193\n",
      "Validation loss decreased (0.052725 --> 0.052710).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0535513\n",
      "\tspeed: 0.0526s/iter; left time: 804.2974s\n",
      "\titers: 200, epoch: 32 | loss: 0.0491902\n",
      "\tspeed: 0.0270s/iter; left time: 409.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0524858 Vali Loss: 0.0527489 Test Loss: 0.0599410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0548159\n",
      "\tspeed: 0.0537s/iter; left time: 809.7204s\n",
      "\titers: 200, epoch: 33 | loss: 0.0534750\n",
      "\tspeed: 0.0265s/iter; left time: 396.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0524737 Vali Loss: 0.0526946 Test Loss: 0.0599220\n",
      "Validation loss decreased (0.052710 --> 0.052695).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547238\n",
      "\tspeed: 0.0519s/iter; left time: 770.9554s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526712\n",
      "\tspeed: 0.0265s/iter; left time: 390.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0524465 Vali Loss: 0.0526699 Test Loss: 0.0598708\n",
      "Validation loss decreased (0.052695 --> 0.052670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548534\n",
      "\tspeed: 0.0549s/iter; left time: 802.6370s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521703\n",
      "\tspeed: 0.0267s/iter; left time: 387.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0524024 Vali Loss: 0.0526626 Test Loss: 0.0597937\n",
      "Validation loss decreased (0.052670 --> 0.052663).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0503881\n",
      "\tspeed: 0.0526s/iter; left time: 757.2531s\n",
      "\titers: 200, epoch: 36 | loss: 0.0522587\n",
      "\tspeed: 0.0269s/iter; left time: 384.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523866 Vali Loss: 0.0526656 Test Loss: 0.0598915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0512503\n",
      "\tspeed: 0.0535s/iter; left time: 758.3364s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500938\n",
      "\tspeed: 0.0262s/iter; left time: 368.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0523500 Vali Loss: 0.0526616 Test Loss: 0.0599231\n",
      "Validation loss decreased (0.052663 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0501655\n",
      "\tspeed: 0.0518s/iter; left time: 722.8999s\n",
      "\titers: 200, epoch: 38 | loss: 0.0534852\n",
      "\tspeed: 0.0268s/iter; left time: 371.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523321 Vali Loss: 0.0527160 Test Loss: 0.0598248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0514224\n",
      "\tspeed: 0.0545s/iter; left time: 748.3258s\n",
      "\titers: 200, epoch: 39 | loss: 0.0514188\n",
      "\tspeed: 0.0269s/iter; left time: 366.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0523240 Vali Loss: 0.0526534 Test Loss: 0.0597652\n",
      "Validation loss decreased (0.052662 --> 0.052653).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0530570\n",
      "\tspeed: 0.0540s/iter; left time: 729.2703s\n",
      "\titers: 200, epoch: 40 | loss: 0.0543625\n",
      "\tspeed: 0.0265s/iter; left time: 355.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523358 Vali Loss: 0.0526050 Test Loss: 0.0597801\n",
      "Validation loss decreased (0.052653 --> 0.052605).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0526280\n",
      "\tspeed: 0.0538s/iter; left time: 714.3920s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502842\n",
      "\tspeed: 0.0269s/iter; left time: 354.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523034 Vali Loss: 0.0525962 Test Loss: 0.0597211\n",
      "Validation loss decreased (0.052605 --> 0.052596).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0504601\n",
      "\tspeed: 0.0519s/iter; left time: 677.2080s\n",
      "\titers: 200, epoch: 42 | loss: 0.0522450\n",
      "\tspeed: 0.0267s/iter; left time: 346.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522315 Vali Loss: 0.0525362 Test Loss: 0.0597368\n",
      "Validation loss decreased (0.052596 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511504\n",
      "\tspeed: 0.0536s/iter; left time: 687.5830s\n",
      "\titers: 200, epoch: 43 | loss: 0.0488503\n",
      "\tspeed: 0.0271s/iter; left time: 344.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0522311 Vali Loss: 0.0525445 Test Loss: 0.0597039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0522164\n",
      "\tspeed: 0.0529s/iter; left time: 667.3444s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535703\n",
      "\tspeed: 0.0284s/iter; left time: 354.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522388 Vali Loss: 0.0525645 Test Loss: 0.0597437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495954\n",
      "\tspeed: 0.0542s/iter; left time: 671.1270s\n",
      "\titers: 200, epoch: 45 | loss: 0.0532957\n",
      "\tspeed: 0.0266s/iter; left time: 327.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0521830 Vali Loss: 0.0525358 Test Loss: 0.0597217\n",
      "Validation loss decreased (0.052536 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547444\n",
      "\tspeed: 0.0524s/iter; left time: 637.6216s\n",
      "\titers: 200, epoch: 46 | loss: 0.0496140\n",
      "\tspeed: 0.0269s/iter; left time: 324.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521675 Vali Loss: 0.0525339 Test Loss: 0.0597081\n",
      "Validation loss decreased (0.052536 --> 0.052534).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0506746\n",
      "\tspeed: 0.0548s/iter; left time: 654.9451s\n",
      "\titers: 200, epoch: 47 | loss: 0.0512049\n",
      "\tspeed: 0.0264s/iter; left time: 313.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522126 Vali Loss: 0.0525633 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0528504\n",
      "\tspeed: 0.0519s/iter; left time: 608.0480s\n",
      "\titers: 200, epoch: 48 | loss: 0.0515653\n",
      "\tspeed: 0.0264s/iter; left time: 306.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 223 | Train Loss: 0.0522133 Vali Loss: 0.0525448 Test Loss: 0.0597099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0548897\n",
      "\tspeed: 0.0561s/iter; left time: 644.8778s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546200\n",
      "\tspeed: 0.0264s/iter; left time: 301.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521772 Vali Loss: 0.0526311 Test Loss: 0.0597383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0529519\n",
      "\tspeed: 0.0521s/iter; left time: 586.9512s\n",
      "\titers: 200, epoch: 50 | loss: 0.0546627\n",
      "\tspeed: 0.0266s/iter; left time: 297.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0522163 Vali Loss: 0.0525349 Test Loss: 0.0597257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0562787\n",
      "\tspeed: 0.0549s/iter; left time: 606.1844s\n",
      "\titers: 200, epoch: 51 | loss: 0.0525578\n",
      "\tspeed: 0.0263s/iter; left time: 288.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522028 Vali Loss: 0.0525564 Test Loss: 0.0597158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0567538\n",
      "\tspeed: 0.0519s/iter; left time: 561.7646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0543848\n",
      "\tspeed: 0.0270s/iter; left time: 289.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521792 Vali Loss: 0.0525038 Test Loss: 0.0596972\n",
      "Validation loss decreased (0.052534 --> 0.052504).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0541374\n",
      "\tspeed: 0.0558s/iter; left time: 591.2647s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519631\n",
      "\tspeed: 0.0267s/iter; left time: 280.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525617 Test Loss: 0.0597053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0510549\n",
      "\tspeed: 0.0519s/iter; left time: 538.9647s\n",
      "\titers: 200, epoch: 54 | loss: 0.0498644\n",
      "\tspeed: 0.0276s/iter; left time: 283.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0521371 Vali Loss: 0.0525328 Test Loss: 0.0597132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0494472\n",
      "\tspeed: 0.0524s/iter; left time: 532.0514s\n",
      "\titers: 200, epoch: 55 | loss: 0.0542947\n",
      "\tspeed: 0.0265s/iter; left time: 266.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521456 Vali Loss: 0.0525355 Test Loss: 0.0597412\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0560386\n",
      "\tspeed: 0.0519s/iter; left time: 515.1972s\n",
      "\titers: 200, epoch: 56 | loss: 0.0490938\n",
      "\tspeed: 0.0275s/iter; left time: 270.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0521942 Vali Loss: 0.0525360 Test Loss: 0.0596775\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0516569\n",
      "\tspeed: 0.0533s/iter; left time: 517.2387s\n",
      "\titers: 200, epoch: 57 | loss: 0.0514586\n",
      "\tspeed: 0.0265s/iter; left time: 255.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521401 Vali Loss: 0.0525131 Test Loss: 0.0596987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0532000\n",
      "\tspeed: 0.0516s/iter; left time: 490.0769s\n",
      "\titers: 200, epoch: 58 | loss: 0.0498075\n",
      "\tspeed: 0.0280s/iter; left time: 263.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521895 Vali Loss: 0.0524485 Test Loss: 0.0596977\n",
      "Validation loss decreased (0.052504 --> 0.052448).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0487121\n",
      "\tspeed: 0.0521s/iter; left time: 482.9457s\n",
      "\titers: 200, epoch: 59 | loss: 0.0520011\n",
      "\tspeed: 0.0263s/iter; left time: 241.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0520815 Vali Loss: 0.0525329 Test Loss: 0.0597163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0499147\n",
      "\tspeed: 0.0515s/iter; left time: 465.4498s\n",
      "\titers: 200, epoch: 60 | loss: 0.0494750\n",
      "\tspeed: 0.0274s/iter; left time: 245.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525106 Test Loss: 0.0596920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0571291\n",
      "\tspeed: 0.0513s/iter; left time: 452.4577s\n",
      "\titers: 200, epoch: 61 | loss: 0.0492495\n",
      "\tspeed: 0.0267s/iter; left time: 232.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0520912 Vali Loss: 0.0525052 Test Loss: 0.0597109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0515710\n",
      "\tspeed: 0.0543s/iter; left time: 467.0255s\n",
      "\titers: 200, epoch: 62 | loss: 0.0511826\n",
      "\tspeed: 0.0270s/iter; left time: 229.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0521550 Vali Loss: 0.0525164 Test Loss: 0.0596776\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0522274\n",
      "\tspeed: 0.0521s/iter; left time: 436.1762s\n",
      "\titers: 200, epoch: 63 | loss: 0.0504325\n",
      "\tspeed: 0.0266s/iter; left time: 220.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521259 Vali Loss: 0.0525472 Test Loss: 0.0597064\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0529144\n",
      "\tspeed: 0.0533s/iter; left time: 434.1040s\n",
      "\titers: 200, epoch: 64 | loss: 0.0512218\n",
      "\tspeed: 0.0271s/iter; left time: 218.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0521278 Vali Loss: 0.0525165 Test Loss: 0.0596788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0476370\n",
      "\tspeed: 0.0525s/iter; left time: 416.5912s\n",
      "\titers: 200, epoch: 65 | loss: 0.0538774\n",
      "\tspeed: 0.0265s/iter; left time: 207.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521600 Vali Loss: 0.0525308 Test Loss: 0.0596834\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0497716\n",
      "\tspeed: 0.0539s/iter; left time: 415.6925s\n",
      "\titers: 200, epoch: 66 | loss: 0.0530621\n",
      "\tspeed: 0.0270s/iter; left time: 205.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0521674 Vali Loss: 0.0524973 Test Loss: 0.0596974\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499892\n",
      "\tspeed: 0.0513s/iter; left time: 383.7247s\n",
      "\titers: 200, epoch: 67 | loss: 0.0548931\n",
      "\tspeed: 0.0257s/iter; left time: 190.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0520809 Vali Loss: 0.0525215 Test Loss: 0.0597028\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0492604\n",
      "\tspeed: 0.0538s/iter; left time: 390.9405s\n",
      "\titers: 200, epoch: 68 | loss: 0.0565043\n",
      "\tspeed: 0.0269s/iter; left time: 192.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521187 Vali Loss: 0.0525102 Test Loss: 0.0596645\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009862316772341728, rmse:0.09930919855833054, mae:0.0596977174282074, rse:0.2922549545764923\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:15.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265439\n",
      "\tspeed: 0.0400s/iter; left time: 884.7212s\n",
      "\titers: 200, epoch: 1 | loss: 0.1094258\n",
      "\tspeed: 0.0289s/iter; left time: 636.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.1312871 Vali Loss: 0.1025756 Test Loss: 0.1179928\n",
      "Validation loss decreased (inf --> 0.102576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907331\n",
      "\tspeed: 0.0535s/iter; left time: 1170.6404s\n",
      "\titers: 200, epoch: 2 | loss: 0.0867114\n",
      "\tspeed: 0.0266s/iter; left time: 579.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0917246 Vali Loss: 0.0830300 Test Loss: 0.0950562\n",
      "Validation loss decreased (0.102576 --> 0.083030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829765\n",
      "\tspeed: 0.0554s/iter; left time: 1198.8487s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798829\n",
      "\tspeed: 0.0265s/iter; left time: 571.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.0835803 Vali Loss: 0.0801783 Test Loss: 0.0919009\n",
      "Validation loss decreased (0.083030 --> 0.080178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0821674\n",
      "\tspeed: 0.0559s/iter; left time: 1197.5539s\n",
      "\titers: 200, epoch: 4 | loss: 0.0791295\n",
      "\tspeed: 0.0266s/iter; left time: 567.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0809995 Vali Loss: 0.0792776 Test Loss: 0.0911379\n",
      "Validation loss decreased (0.080178 --> 0.079278).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795954\n",
      "\tspeed: 0.0537s/iter; left time: 1138.2492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775064\n",
      "\tspeed: 0.0284s/iter; left time: 600.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0793633 Vali Loss: 0.0774794 Test Loss: 0.0889028\n",
      "Validation loss decreased (0.079278 --> 0.077479).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782045\n",
      "\tspeed: 0.0539s/iter; left time: 1131.9822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778508\n",
      "\tspeed: 0.0279s/iter; left time: 583.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0779934 Vali Loss: 0.0769796 Test Loss: 0.0893228\n",
      "Validation loss decreased (0.077479 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745626\n",
      "\tspeed: 0.0550s/iter; left time: 1143.0104s\n",
      "\titers: 200, epoch: 7 | loss: 0.0762473\n",
      "\tspeed: 0.0267s/iter; left time: 552.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 222 | Train Loss: 0.0769873 Vali Loss: 0.0768754 Test Loss: 0.0889773\n",
      "Validation loss decreased (0.076980 --> 0.076875).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770923\n",
      "\tspeed: 0.0562s/iter; left time: 1155.5033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742162\n",
      "\tspeed: 0.0270s/iter; left time: 552.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0761248 Vali Loss: 0.0765266 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.076875 --> 0.076527).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738049\n",
      "\tspeed: 0.0546s/iter; left time: 1110.0115s\n",
      "\titers: 200, epoch: 9 | loss: 0.0768474\n",
      "\tspeed: 0.0268s/iter; left time: 542.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0753436 Vali Loss: 0.0767246 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751446\n",
      "\tspeed: 0.0528s/iter; left time: 1061.9707s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730382\n",
      "\tspeed: 0.0278s/iter; left time: 556.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0746837 Vali Loss: 0.0759690 Test Loss: 0.0876617\n",
      "Validation loss decreased (0.076527 --> 0.075969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0742704\n",
      "\tspeed: 0.0547s/iter; left time: 1088.1799s\n",
      "\titers: 200, epoch: 11 | loss: 0.0734047\n",
      "\tspeed: 0.0283s/iter; left time: 558.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0740411 Vali Loss: 0.0764244 Test Loss: 0.0878260\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752044\n",
      "\tspeed: 0.0543s/iter; left time: 1066.5819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0752981\n",
      "\tspeed: 0.0268s/iter; left time: 523.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0736232 Vali Loss: 0.0767008 Test Loss: 0.0877754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0746256\n",
      "\tspeed: 0.0564s/iter; left time: 1096.2401s\n",
      "\titers: 200, epoch: 13 | loss: 0.0724523\n",
      "\tspeed: 0.0268s/iter; left time: 518.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0732229 Vali Loss: 0.0764604 Test Loss: 0.0875878\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758144\n",
      "\tspeed: 0.0548s/iter; left time: 1053.8924s\n",
      "\titers: 200, epoch: 14 | loss: 0.0700375\n",
      "\tspeed: 0.0271s/iter; left time: 518.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0728587 Vali Loss: 0.0766782 Test Loss: 0.0877830\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706620\n",
      "\tspeed: 0.0543s/iter; left time: 1030.7524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763170\n",
      "\tspeed: 0.0296s/iter; left time: 559.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0725805 Vali Loss: 0.0769847 Test Loss: 0.0880434\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0747856\n",
      "\tspeed: 0.0537s/iter; left time: 1007.8252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682468\n",
      "\tspeed: 0.0276s/iter; left time: 515.9298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0722561 Vali Loss: 0.0771711 Test Loss: 0.0879989\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0709803\n",
      "\tspeed: 0.0552s/iter; left time: 1024.6003s\n",
      "\titers: 200, epoch: 17 | loss: 0.0700381\n",
      "\tspeed: 0.0273s/iter; left time: 503.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0719847 Vali Loss: 0.0766064 Test Loss: 0.0875815\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710720\n",
      "\tspeed: 0.0554s/iter; left time: 1014.6048s\n",
      "\titers: 200, epoch: 18 | loss: 0.0727012\n",
      "\tspeed: 0.0283s/iter; left time: 516.3897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0717268 Vali Loss: 0.0767684 Test Loss: 0.0876820\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0743508\n",
      "\tspeed: 0.0547s/iter; left time: 989.5579s\n",
      "\titers: 200, epoch: 19 | loss: 0.0689420\n",
      "\tspeed: 0.0275s/iter; left time: 494.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0715864 Vali Loss: 0.0769818 Test Loss: 0.0876034\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733923\n",
      "\tspeed: 0.0529s/iter; left time: 946.8320s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733492\n",
      "\tspeed: 0.0284s/iter; left time: 505.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0712923 Vali Loss: 0.0767117 Test Loss: 0.0876483\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018943050876259804, rmse:0.13763375580310822, mae:0.08766170591115952, rse:0.40432655811309814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1253982\n",
      "\tspeed: 0.0289s/iter; left time: 638.4441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141047\n",
      "\tspeed: 0.0291s/iter; left time: 639.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1341000 Vali Loss: 0.1022669 Test Loss: 0.1178293\n",
      "Validation loss decreased (inf --> 0.102267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0919906\n",
      "\tspeed: 0.0538s/iter; left time: 1177.6209s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841853\n",
      "\tspeed: 0.0281s/iter; left time: 612.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0917120 Vali Loss: 0.0828372 Test Loss: 0.0952215\n",
      "Validation loss decreased (0.102267 --> 0.082837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804817\n",
      "\tspeed: 0.0553s/iter; left time: 1197.2060s\n",
      "\titers: 200, epoch: 3 | loss: 0.0846727\n",
      "\tspeed: 0.0272s/iter; left time: 585.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0834201 Vali Loss: 0.0801691 Test Loss: 0.0913734\n",
      "Validation loss decreased (0.082837 --> 0.080169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814359\n",
      "\tspeed: 0.0549s/iter; left time: 1177.4784s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801016\n",
      "\tspeed: 0.0268s/iter; left time: 570.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0809782 Vali Loss: 0.0786221 Test Loss: 0.0896895\n",
      "Validation loss decreased (0.080169 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773623\n",
      "\tspeed: 0.0557s/iter; left time: 1181.5318s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807470\n",
      "\tspeed: 0.0269s/iter; left time: 567.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0791465 Vali Loss: 0.0776870 Test Loss: 0.0884282\n",
      "Validation loss decreased (0.078622 --> 0.077687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764767\n",
      "\tspeed: 0.0557s/iter; left time: 1168.8908s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776939\n",
      "\tspeed: 0.0288s/iter; left time: 601.9911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0779017 Vali Loss: 0.0774003 Test Loss: 0.0885492\n",
      "Validation loss decreased (0.077687 --> 0.077400).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0810065\n",
      "\tspeed: 0.0550s/iter; left time: 1142.0334s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755886\n",
      "\tspeed: 0.0274s/iter; left time: 566.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0769723 Vali Loss: 0.0767423 Test Loss: 0.0886906\n",
      "Validation loss decreased (0.077400 --> 0.076742).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772487\n",
      "\tspeed: 0.0547s/iter; left time: 1123.3866s\n",
      "\titers: 200, epoch: 8 | loss: 0.0774471\n",
      "\tspeed: 0.0271s/iter; left time: 555.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0761289 Vali Loss: 0.0762937 Test Loss: 0.0885289\n",
      "Validation loss decreased (0.076742 --> 0.076294).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766210\n",
      "\tspeed: 0.0558s/iter; left time: 1134.4816s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749435\n",
      "\tspeed: 0.0269s/iter; left time: 544.2993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0755007 Vali Loss: 0.0760306 Test Loss: 0.0880587\n",
      "Validation loss decreased (0.076294 --> 0.076031).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0746958\n",
      "\tspeed: 0.0559s/iter; left time: 1123.7180s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730645\n",
      "\tspeed: 0.0275s/iter; left time: 550.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0748742 Vali Loss: 0.0756054 Test Loss: 0.0881646\n",
      "Validation loss decreased (0.076031 --> 0.075605).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0716690\n",
      "\tspeed: 0.0534s/iter; left time: 1061.9451s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740186\n",
      "\tspeed: 0.0284s/iter; left time: 561.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0743888 Vali Loss: 0.0763426 Test Loss: 0.0880540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0735602\n",
      "\tspeed: 0.0538s/iter; left time: 1057.8847s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751355\n",
      "\tspeed: 0.0281s/iter; left time: 549.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0739728 Vali Loss: 0.0759540 Test Loss: 0.0883263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0716493\n",
      "\tspeed: 0.0541s/iter; left time: 1051.5080s\n",
      "\titers: 200, epoch: 13 | loss: 0.0773238\n",
      "\tspeed: 0.0267s/iter; left time: 515.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0734238 Vali Loss: 0.0758260 Test Loss: 0.0877946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0718031\n",
      "\tspeed: 0.0554s/iter; left time: 1064.5978s\n",
      "\titers: 200, epoch: 14 | loss: 0.0764564\n",
      "\tspeed: 0.0270s/iter; left time: 516.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0731561 Vali Loss: 0.0764050 Test Loss: 0.0881921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733460\n",
      "\tspeed: 0.0543s/iter; left time: 1032.1122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0726849\n",
      "\tspeed: 0.0273s/iter; left time: 515.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0728082 Vali Loss: 0.0762584 Test Loss: 0.0878794\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713056\n",
      "\tspeed: 0.0524s/iter; left time: 982.8385s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673408\n",
      "\tspeed: 0.0280s/iter; left time: 523.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0725102 Vali Loss: 0.0764893 Test Loss: 0.0877887\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0729090\n",
      "\tspeed: 0.0530s/iter; left time: 982.7459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736606\n",
      "\tspeed: 0.0270s/iter; left time: 498.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0722571 Vali Loss: 0.0764543 Test Loss: 0.0877635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0751263\n",
      "\tspeed: 0.0551s/iter; left time: 1010.3302s\n",
      "\titers: 200, epoch: 18 | loss: 0.0732667\n",
      "\tspeed: 0.0264s/iter; left time: 480.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0720145 Vali Loss: 0.0763173 Test Loss: 0.0881959\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0712821\n",
      "\tspeed: 0.0561s/iter; left time: 1015.0635s\n",
      "\titers: 200, epoch: 19 | loss: 0.0737556\n",
      "\tspeed: 0.0275s/iter; left time: 494.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0717988 Vali Loss: 0.0764204 Test Loss: 0.0878492\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0701951\n",
      "\tspeed: 0.0559s/iter; left time: 1000.3240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730100\n",
      "\tspeed: 0.0292s/iter; left time: 519.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0715539 Vali Loss: 0.0763633 Test Loss: 0.0877618\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01899096928536892, rmse:0.1378077268600464, mae:0.08816458284854889, rse:0.40483760833740234\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:36.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1250355\n",
      "\tspeed: 0.0545s/iter; left time: 1204.7699s\n",
      "\titers: 200, epoch: 1 | loss: 0.1118319\n",
      "\tspeed: 0.0281s/iter; left time: 617.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 222 | Train Loss: 0.1330013 Vali Loss: 0.1052809 Test Loss: 0.1202528\n",
      "Validation loss decreased (inf --> 0.105281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916071\n",
      "\tspeed: 0.0549s/iter; left time: 1200.7462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897428\n",
      "\tspeed: 0.0272s/iter; left time: 591.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0956554 Vali Loss: 0.0879480 Test Loss: 0.1003329\n",
      "Validation loss decreased (0.105281 --> 0.087948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0914022\n",
      "\tspeed: 0.0579s/iter; left time: 1254.3048s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906762\n",
      "\tspeed: 0.0270s/iter; left time: 582.6198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0882966 Vali Loss: 0.0851394 Test Loss: 0.0968764\n",
      "Validation loss decreased (0.087948 --> 0.085139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0883625\n",
      "\tspeed: 0.0564s/iter; left time: 1209.4570s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835357\n",
      "\tspeed: 0.0272s/iter; left time: 580.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0856180 Vali Loss: 0.0840554 Test Loss: 0.0959844\n",
      "Validation loss decreased (0.085139 --> 0.084055).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803824\n",
      "\tspeed: 0.0554s/iter; left time: 1175.9016s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853965\n",
      "\tspeed: 0.0286s/iter; left time: 603.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0838570 Vali Loss: 0.0833926 Test Loss: 0.0951348\n",
      "Validation loss decreased (0.084055 --> 0.083393).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797744\n",
      "\tspeed: 0.0533s/iter; left time: 1118.2968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826659\n",
      "\tspeed: 0.0287s/iter; left time: 600.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0822528 Vali Loss: 0.0830472 Test Loss: 0.0943015\n",
      "Validation loss decreased (0.083393 --> 0.083047).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828038\n",
      "\tspeed: 0.0536s/iter; left time: 1112.2997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825458\n",
      "\tspeed: 0.0272s/iter; left time: 562.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0811129 Vali Loss: 0.0834605 Test Loss: 0.0947691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0849840\n",
      "\tspeed: 0.0559s/iter; left time: 1148.1936s\n",
      "\titers: 200, epoch: 8 | loss: 0.0815625\n",
      "\tspeed: 0.0274s/iter; left time: 559.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0801981 Vali Loss: 0.0829874 Test Loss: 0.0947762\n",
      "Validation loss decreased (0.083047 --> 0.082987).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0781479\n",
      "\tspeed: 0.0549s/iter; left time: 1115.8102s\n",
      "\titers: 200, epoch: 9 | loss: 0.0818327\n",
      "\tspeed: 0.0275s/iter; left time: 555.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0794156 Vali Loss: 0.0829935 Test Loss: 0.0946946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794938\n",
      "\tspeed: 0.0533s/iter; left time: 1071.4783s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774823\n",
      "\tspeed: 0.0288s/iter; left time: 576.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0786948 Vali Loss: 0.0832779 Test Loss: 0.0945250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782731\n",
      "\tspeed: 0.0537s/iter; left time: 1068.0314s\n",
      "\titers: 200, epoch: 11 | loss: 0.0724275\n",
      "\tspeed: 0.0286s/iter; left time: 565.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0781504 Vali Loss: 0.0839142 Test Loss: 0.0944648\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0773756\n",
      "\tspeed: 0.0547s/iter; left time: 1075.9521s\n",
      "\titers: 200, epoch: 12 | loss: 0.0790120\n",
      "\tspeed: 0.0270s/iter; left time: 528.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0776322 Vali Loss: 0.0839175 Test Loss: 0.0947209\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0759633\n",
      "\tspeed: 0.0562s/iter; left time: 1091.6846s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766064\n",
      "\tspeed: 0.0270s/iter; left time: 522.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0772161 Vali Loss: 0.0840464 Test Loss: 0.0945042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0776728\n",
      "\tspeed: 0.0551s/iter; left time: 1058.3260s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716171\n",
      "\tspeed: 0.0279s/iter; left time: 533.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0768410 Vali Loss: 0.0839806 Test Loss: 0.0951329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770181\n",
      "\tspeed: 0.0529s/iter; left time: 1004.0617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740275\n",
      "\tspeed: 0.0280s/iter; left time: 529.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0765493 Vali Loss: 0.0842260 Test Loss: 0.0949700\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0760478\n",
      "\tspeed: 0.0558s/iter; left time: 1047.1025s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732501\n",
      "\tspeed: 0.0275s/iter; left time: 512.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0762004 Vali Loss: 0.0838910 Test Loss: 0.0946376\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0764160\n",
      "\tspeed: 0.0565s/iter; left time: 1047.8797s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790075\n",
      "\tspeed: 0.0273s/iter; left time: 504.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0759705 Vali Loss: 0.0844240 Test Loss: 0.0951427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0746448\n",
      "\tspeed: 0.0552s/iter; left time: 1012.1262s\n",
      "\titers: 200, epoch: 18 | loss: 0.0749086\n",
      "\tspeed: 0.0282s/iter; left time: 513.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0756720 Vali Loss: 0.0843374 Test Loss: 0.0958508\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021302737295627594, rmse:0.14595457911491394, mae:0.0947762206196785, rse:0.42880141735076904\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1263854\n",
      "\tspeed: 0.0309s/iter; left time: 682.9684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1156874\n",
      "\tspeed: 0.0276s/iter; left time: 606.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1330581 Vali Loss: 0.1057428 Test Loss: 0.1209379\n",
      "Validation loss decreased (inf --> 0.105743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964121\n",
      "\tspeed: 0.0557s/iter; left time: 1218.0535s\n",
      "\titers: 200, epoch: 2 | loss: 0.0929709\n",
      "\tspeed: 0.0288s/iter; left time: 628.1006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0959172 Vali Loss: 0.0880870 Test Loss: 0.1012052\n",
      "Validation loss decreased (0.105743 --> 0.088087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0905122\n",
      "\tspeed: 0.0563s/iter; left time: 1219.2802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0891663\n",
      "\tspeed: 0.0291s/iter; left time: 628.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0886181 Vali Loss: 0.0859668 Test Loss: 0.0981919\n",
      "Validation loss decreased (0.088087 --> 0.085967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836552\n",
      "\tspeed: 0.0574s/iter; left time: 1231.0096s\n",
      "\titers: 200, epoch: 4 | loss: 0.0862615\n",
      "\tspeed: 0.0272s/iter; left time: 580.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0859728 Vali Loss: 0.0844449 Test Loss: 0.0958727\n",
      "Validation loss decreased (0.085967 --> 0.084445).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788982\n",
      "\tspeed: 0.0583s/iter; left time: 1237.0605s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824617\n",
      "\tspeed: 0.0274s/iter; left time: 577.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0840970 Vali Loss: 0.0829465 Test Loss: 0.0956325\n",
      "Validation loss decreased (0.084445 --> 0.082947).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843147\n",
      "\tspeed: 0.0562s/iter; left time: 1179.0831s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826297\n",
      "\tspeed: 0.0283s/iter; left time: 591.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0826575 Vali Loss: 0.0833131 Test Loss: 0.0959734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0814445\n",
      "\tspeed: 0.0537s/iter; left time: 1115.2986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826768\n",
      "\tspeed: 0.0289s/iter; left time: 597.0329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0814408 Vali Loss: 0.0830539 Test Loss: 0.0944358\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832167\n",
      "\tspeed: 0.0560s/iter; left time: 1149.8094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797981\n",
      "\tspeed: 0.0274s/iter; left time: 560.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0804610 Vali Loss: 0.0830255 Test Loss: 0.0940806\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808557\n",
      "\tspeed: 0.0570s/iter; left time: 1159.0573s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788599\n",
      "\tspeed: 0.0269s/iter; left time: 544.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0795982 Vali Loss: 0.0830813 Test Loss: 0.0943129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793939\n",
      "\tspeed: 0.0553s/iter; left time: 1112.2653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804769\n",
      "\tspeed: 0.0272s/iter; left time: 543.1426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0789372 Vali Loss: 0.0844544 Test Loss: 0.0946267\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0799205\n",
      "\tspeed: 0.0563s/iter; left time: 1120.1130s\n",
      "\titers: 200, epoch: 11 | loss: 0.0787828\n",
      "\tspeed: 0.0275s/iter; left time: 543.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0783694 Vali Loss: 0.0832267 Test Loss: 0.0936449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794356\n",
      "\tspeed: 0.0537s/iter; left time: 1055.5499s\n",
      "\titers: 200, epoch: 12 | loss: 0.0780849\n",
      "\tspeed: 0.0296s/iter; left time: 579.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0777887 Vali Loss: 0.0834535 Test Loss: 0.0943098\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0778237\n",
      "\tspeed: 0.0542s/iter; left time: 1054.2259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0756606\n",
      "\tspeed: 0.0274s/iter; left time: 529.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0773796 Vali Loss: 0.0838258 Test Loss: 0.0945887\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0753599\n",
      "\tspeed: 0.0570s/iter; left time: 1094.4866s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772503\n",
      "\tspeed: 0.0280s/iter; left time: 534.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0769784 Vali Loss: 0.0844897 Test Loss: 0.0947630\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747140\n",
      "\tspeed: 0.0574s/iter; left time: 1090.5105s\n",
      "\titers: 200, epoch: 15 | loss: 0.0749678\n",
      "\tspeed: 0.0272s/iter; left time: 514.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0766025 Vali Loss: 0.0839631 Test Loss: 0.0942935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021356923505663872, rmse:0.14614008367061615, mae:0.09563247114419937, rse:0.4293464124202728\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:47.34s\n",
      "Intermediate time for ES: 00h:26m:39.90s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0843132\n",
      "\tspeed: 0.0528s/iter; left time: 1172.4564s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826993\n",
      "\tspeed: 0.0273s/iter; left time: 602.6090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0928899 Vali Loss: 0.0809973 Test Loss: 0.0874650\n",
      "Validation loss decreased (inf --> 0.080997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0540009\n",
      "\tspeed: 0.0541s/iter; left time: 1189.4851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0534995\n",
      "\tspeed: 0.0274s/iter; left time: 599.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0554808 Vali Loss: 0.0583653 Test Loss: 0.0612634\n",
      "Validation loss decreased (0.080997 --> 0.058365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0485997\n",
      "\tspeed: 0.0511s/iter; left time: 1112.2014s\n",
      "\titers: 200, epoch: 3 | loss: 0.0472784\n",
      "\tspeed: 0.0265s/iter; left time: 574.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0488961 Vali Loss: 0.0559211 Test Loss: 0.0598280\n",
      "Validation loss decreased (0.058365 --> 0.055921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495222\n",
      "\tspeed: 0.0554s/iter; left time: 1193.9438s\n",
      "\titers: 200, epoch: 4 | loss: 0.0483923\n",
      "\tspeed: 0.0266s/iter; left time: 569.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0470500 Vali Loss: 0.0548929 Test Loss: 0.0586228\n",
      "Validation loss decreased (0.055921 --> 0.054893).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0458255\n",
      "\tspeed: 0.0540s/iter; left time: 1151.1256s\n",
      "\titers: 200, epoch: 5 | loss: 0.0433537\n",
      "\tspeed: 0.0277s/iter; left time: 587.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0458443 Vali Loss: 0.0543292 Test Loss: 0.0576505\n",
      "Validation loss decreased (0.054893 --> 0.054329).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0430197\n",
      "\tspeed: 0.0517s/iter; left time: 1090.1838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0458188\n",
      "\tspeed: 0.0268s/iter; left time: 562.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0450522 Vali Loss: 0.0533698 Test Loss: 0.0574189\n",
      "Validation loss decreased (0.054329 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0436309\n",
      "\tspeed: 0.0533s/iter; left time: 1111.0120s\n",
      "\titers: 200, epoch: 7 | loss: 0.0437001\n",
      "\tspeed: 0.0274s/iter; left time: 568.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0443619 Vali Loss: 0.0534138 Test Loss: 0.0570331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0455056\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6775s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435005\n",
      "\tspeed: 0.0267s/iter; left time: 547.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0438976 Vali Loss: 0.0529732 Test Loss: 0.0568599\n",
      "Validation loss decreased (0.053370 --> 0.052973).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0422169\n",
      "\tspeed: 0.0547s/iter; left time: 1116.5035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0433253\n",
      "\tspeed: 0.0267s/iter; left time: 542.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0434878 Vali Loss: 0.0527236 Test Loss: 0.0561925\n",
      "Validation loss decreased (0.052973 --> 0.052724).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0444294\n",
      "\tspeed: 0.0521s/iter; left time: 1051.5519s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413240\n",
      "\tspeed: 0.0280s/iter; left time: 562.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0431111 Vali Loss: 0.0524848 Test Loss: 0.0564840\n",
      "Validation loss decreased (0.052724 --> 0.052485).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0447372\n",
      "\tspeed: 0.0547s/iter; left time: 1091.9684s\n",
      "\titers: 200, epoch: 11 | loss: 0.0443235\n",
      "\tspeed: 0.0272s/iter; left time: 539.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0428224 Vali Loss: 0.0525295 Test Loss: 0.0564360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0440985\n",
      "\tspeed: 0.0526s/iter; left time: 1039.4210s\n",
      "\titers: 200, epoch: 12 | loss: 0.0438725\n",
      "\tspeed: 0.0282s/iter; left time: 553.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0425661 Vali Loss: 0.0519805 Test Loss: 0.0558995\n",
      "Validation loss decreased (0.052485 --> 0.051981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0421945\n",
      "\tspeed: 0.0540s/iter; left time: 1054.1201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0413549\n",
      "\tspeed: 0.0263s/iter; left time: 511.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0423398 Vali Loss: 0.0518698 Test Loss: 0.0560660\n",
      "Validation loss decreased (0.051981 --> 0.051870).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0388299\n",
      "\tspeed: 0.0537s/iter; left time: 1036.0091s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418125\n",
      "\tspeed: 0.0280s/iter; left time: 538.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0421227 Vali Loss: 0.0520392 Test Loss: 0.0560852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425634\n",
      "\tspeed: 0.0541s/iter; left time: 1032.7221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422673\n",
      "\tspeed: 0.0281s/iter; left time: 532.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0419951 Vali Loss: 0.0516969 Test Loss: 0.0556645\n",
      "Validation loss decreased (0.051870 --> 0.051697).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0408609\n",
      "\tspeed: 0.0569s/iter; left time: 1073.5040s\n",
      "\titers: 200, epoch: 16 | loss: 0.0428541\n",
      "\tspeed: 0.0264s/iter; left time: 495.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0417983 Vali Loss: 0.0516113 Test Loss: 0.0556568\n",
      "Validation loss decreased (0.051697 --> 0.051611).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0433161\n",
      "\tspeed: 0.0539s/iter; left time: 1004.8645s\n",
      "\titers: 200, epoch: 17 | loss: 0.0422571\n",
      "\tspeed: 0.0269s/iter; left time: 497.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0416500 Vali Loss: 0.0514052 Test Loss: 0.0555000\n",
      "Validation loss decreased (0.051611 --> 0.051405).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0451433\n",
      "\tspeed: 0.0543s/iter; left time: 1000.5573s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420981\n",
      "\tspeed: 0.0266s/iter; left time: 487.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0415242 Vali Loss: 0.0517223 Test Loss: 0.0556480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0410448\n",
      "\tspeed: 0.0513s/iter; left time: 932.6076s\n",
      "\titers: 200, epoch: 19 | loss: 0.0432532\n",
      "\tspeed: 0.0282s/iter; left time: 509.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0414556 Vali Loss: 0.0513815 Test Loss: 0.0556669\n",
      "Validation loss decreased (0.051405 --> 0.051381).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0432690\n",
      "\tspeed: 0.0525s/iter; left time: 942.6680s\n",
      "\titers: 200, epoch: 20 | loss: 0.0416686\n",
      "\tspeed: 0.0271s/iter; left time: 484.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0412836 Vali Loss: 0.0514204 Test Loss: 0.0554169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0411735\n",
      "\tspeed: 0.0527s/iter; left time: 935.6835s\n",
      "\titers: 200, epoch: 21 | loss: 0.0403434\n",
      "\tspeed: 0.0275s/iter; left time: 485.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0411740 Vali Loss: 0.0512162 Test Loss: 0.0553809\n",
      "Validation loss decreased (0.051381 --> 0.051216).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410238\n",
      "\tspeed: 0.0536s/iter; left time: 939.4560s\n",
      "\titers: 200, epoch: 22 | loss: 0.0431798\n",
      "\tspeed: 0.0267s/iter; left time: 464.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0411241 Vali Loss: 0.0512545 Test Loss: 0.0554124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0430400\n",
      "\tspeed: 0.0530s/iter; left time: 916.0372s\n",
      "\titers: 200, epoch: 23 | loss: 0.0405390\n",
      "\tspeed: 0.0280s/iter; left time: 481.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0410707 Vali Loss: 0.0511939 Test Loss: 0.0553393\n",
      "Validation loss decreased (0.051216 --> 0.051194).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0420456\n",
      "\tspeed: 0.0517s/iter; left time: 882.1424s\n",
      "\titers: 200, epoch: 24 | loss: 0.0422551\n",
      "\tspeed: 0.0284s/iter; left time: 482.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0409819 Vali Loss: 0.0512411 Test Loss: 0.0552675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0419776\n",
      "\tspeed: 0.0554s/iter; left time: 933.9544s\n",
      "\titers: 200, epoch: 25 | loss: 0.0394762\n",
      "\tspeed: 0.0267s/iter; left time: 447.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0409476 Vali Loss: 0.0512755 Test Loss: 0.0553754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0415562\n",
      "\tspeed: 0.0537s/iter; left time: 893.2178s\n",
      "\titers: 200, epoch: 26 | loss: 0.0394714\n",
      "\tspeed: 0.0278s/iter; left time: 459.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408676 Vali Loss: 0.0510152 Test Loss: 0.0553677\n",
      "Validation loss decreased (0.051194 --> 0.051015).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0425590\n",
      "\tspeed: 0.0547s/iter; left time: 897.5023s\n",
      "\titers: 200, epoch: 27 | loss: 0.0395341\n",
      "\tspeed: 0.0267s/iter; left time: 435.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408256 Vali Loss: 0.0510102 Test Loss: 0.0553386\n",
      "Validation loss decreased (0.051015 --> 0.051010).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0406038\n",
      "\tspeed: 0.0527s/iter; left time: 853.1032s\n",
      "\titers: 200, epoch: 28 | loss: 0.0398112\n",
      "\tspeed: 0.0281s/iter; left time: 452.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0407815 Vali Loss: 0.0511237 Test Loss: 0.0552632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0404074\n",
      "\tspeed: 0.0522s/iter; left time: 832.5402s\n",
      "\titers: 200, epoch: 29 | loss: 0.0439339\n",
      "\tspeed: 0.0265s/iter; left time: 419.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0407395 Vali Loss: 0.0510612 Test Loss: 0.0552591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0436032\n",
      "\tspeed: 0.0548s/iter; left time: 861.7810s\n",
      "\titers: 200, epoch: 30 | loss: 0.0381865\n",
      "\tspeed: 0.0266s/iter; left time: 415.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0406719 Vali Loss: 0.0511291 Test Loss: 0.0551437\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0385469\n",
      "\tspeed: 0.0521s/iter; left time: 808.2974s\n",
      "\titers: 200, epoch: 31 | loss: 0.0384711\n",
      "\tspeed: 0.0265s/iter; left time: 408.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0406380 Vali Loss: 0.0509718 Test Loss: 0.0551497\n",
      "Validation loss decreased (0.051010 --> 0.050972).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0395896\n",
      "\tspeed: 0.0563s/iter; left time: 860.3259s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421091\n",
      "\tspeed: 0.0276s/iter; left time: 419.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0406369 Vali Loss: 0.0510668 Test Loss: 0.0552206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0381517\n",
      "\tspeed: 0.0534s/iter; left time: 805.1249s\n",
      "\titers: 200, epoch: 33 | loss: 0.0395394\n",
      "\tspeed: 0.0287s/iter; left time: 429.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0406346 Vali Loss: 0.0509685 Test Loss: 0.0552220\n",
      "Validation loss decreased (0.050972 --> 0.050968).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0390877\n",
      "\tspeed: 0.0529s/iter; left time: 784.9570s\n",
      "\titers: 200, epoch: 34 | loss: 0.0426558\n",
      "\tspeed: 0.0271s/iter; left time: 399.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0406084 Vali Loss: 0.0509817 Test Loss: 0.0551818\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0396101\n",
      "\tspeed: 0.0550s/iter; left time: 804.7154s\n",
      "\titers: 200, epoch: 35 | loss: 0.0452002\n",
      "\tspeed: 0.0268s/iter; left time: 388.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0405750 Vali Loss: 0.0510232 Test Loss: 0.0551961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0396727\n",
      "\tspeed: 0.0535s/iter; left time: 770.7884s\n",
      "\titers: 200, epoch: 36 | loss: 0.0376845\n",
      "\tspeed: 0.0274s/iter; left time: 391.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0405536 Vali Loss: 0.0509294 Test Loss: 0.0551972\n",
      "Validation loss decreased (0.050968 --> 0.050929).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0383235\n",
      "\tspeed: 0.0553s/iter; left time: 784.1062s\n",
      "\titers: 200, epoch: 37 | loss: 0.0379358\n",
      "\tspeed: 0.0283s/iter; left time: 398.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0405320 Vali Loss: 0.0509095 Test Loss: 0.0551600\n",
      "Validation loss decreased (0.050929 --> 0.050909).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0440550\n",
      "\tspeed: 0.0517s/iter; left time: 721.2223s\n",
      "\titers: 200, epoch: 38 | loss: 0.0409360\n",
      "\tspeed: 0.0271s/iter; left time: 375.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0405302 Vali Loss: 0.0509632 Test Loss: 0.0551483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0424551\n",
      "\tspeed: 0.0544s/iter; left time: 746.2891s\n",
      "\titers: 200, epoch: 39 | loss: 0.0407349\n",
      "\tspeed: 0.0268s/iter; left time: 364.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404400 Vali Loss: 0.0509475 Test Loss: 0.0551755\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0399665\n",
      "\tspeed: 0.0539s/iter; left time: 727.9944s\n",
      "\titers: 200, epoch: 40 | loss: 0.0386363\n",
      "\tspeed: 0.0276s/iter; left time: 370.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0405515 Vali Loss: 0.0509822 Test Loss: 0.0551663\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0414642\n",
      "\tspeed: 0.0536s/iter; left time: 711.4697s\n",
      "\titers: 200, epoch: 41 | loss: 0.0414216\n",
      "\tspeed: 0.0270s/iter; left time: 356.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0405032 Vali Loss: 0.0509070 Test Loss: 0.0551836\n",
      "Validation loss decreased (0.050909 --> 0.050907).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0396513\n",
      "\tspeed: 0.0547s/iter; left time: 714.2081s\n",
      "\titers: 200, epoch: 42 | loss: 0.0407175\n",
      "\tspeed: 0.0273s/iter; left time: 354.3178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0404501 Vali Loss: 0.0509050 Test Loss: 0.0551621\n",
      "Validation loss decreased (0.050907 --> 0.050905).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0419802\n",
      "\tspeed: 0.0522s/iter; left time: 669.5941s\n",
      "\titers: 200, epoch: 43 | loss: 0.0435936\n",
      "\tspeed: 0.0268s/iter; left time: 341.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0404785 Vali Loss: 0.0510068 Test Loss: 0.0551562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0377414\n",
      "\tspeed: 0.0557s/iter; left time: 702.0427s\n",
      "\titers: 200, epoch: 44 | loss: 0.0404162\n",
      "\tspeed: 0.0268s/iter; left time: 335.1467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0404870 Vali Loss: 0.0509230 Test Loss: 0.0551347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0397641\n",
      "\tspeed: 0.0534s/iter; left time: 661.6692s\n",
      "\titers: 200, epoch: 45 | loss: 0.0363073\n",
      "\tspeed: 0.0280s/iter; left time: 343.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0404352 Vali Loss: 0.0509129 Test Loss: 0.0551449\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0382217\n",
      "\tspeed: 0.0512s/iter; left time: 622.3970s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383492\n",
      "\tspeed: 0.0275s/iter; left time: 331.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0404233 Vali Loss: 0.0509525 Test Loss: 0.0551411\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0375880\n",
      "\tspeed: 0.0539s/iter; left time: 644.2997s\n",
      "\titers: 200, epoch: 47 | loss: 0.0388351\n",
      "\tspeed: 0.0276s/iter; left time: 326.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404278 Vali Loss: 0.0509438 Test Loss: 0.0551423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0394593\n",
      "\tspeed: 0.0537s/iter; left time: 628.9858s\n",
      "\titers: 200, epoch: 48 | loss: 0.0419493\n",
      "\tspeed: 0.0263s/iter; left time: 305.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0404258 Vali Loss: 0.0509123 Test Loss: 0.0551539\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0434436\n",
      "\tspeed: 0.0508s/iter; left time: 584.4281s\n",
      "\titers: 200, epoch: 49 | loss: 0.0394077\n",
      "\tspeed: 0.0265s/iter; left time: 301.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404041 Vali Loss: 0.0509195 Test Loss: 0.0551415\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0392535\n",
      "\tspeed: 0.0513s/iter; left time: 577.8123s\n",
      "\titers: 200, epoch: 50 | loss: 0.0380202\n",
      "\tspeed: 0.0285s/iter; left time: 318.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404302 Vali Loss: 0.0509391 Test Loss: 0.0551524\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440110\n",
      "\tspeed: 0.0531s/iter; left time: 586.7326s\n",
      "\titers: 200, epoch: 51 | loss: 0.0394740\n",
      "\tspeed: 0.0266s/iter; left time: 291.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0404130 Vali Loss: 0.0508948 Test Loss: 0.0551422\n",
      "Validation loss decreased (0.050905 --> 0.050895).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0448568\n",
      "\tspeed: 0.0530s/iter; left time: 573.4647s\n",
      "\titers: 200, epoch: 52 | loss: 0.0377624\n",
      "\tspeed: 0.0274s/iter; left time: 294.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403924 Vali Loss: 0.0509185 Test Loss: 0.0551236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0432277\n",
      "\tspeed: 0.0544s/iter; left time: 577.3631s\n",
      "\titers: 200, epoch: 53 | loss: 0.0382022\n",
      "\tspeed: 0.0266s/iter; left time: 278.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0403406 Vali Loss: 0.0509090 Test Loss: 0.0551386\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0392583\n",
      "\tspeed: 0.0539s/iter; left time: 559.1625s\n",
      "\titers: 200, epoch: 54 | loss: 0.0379959\n",
      "\tspeed: 0.0282s/iter; left time: 289.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0403821 Vali Loss: 0.0509590 Test Loss: 0.0551205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0424123\n",
      "\tspeed: 0.0516s/iter; left time: 524.5061s\n",
      "\titers: 200, epoch: 55 | loss: 0.0390990\n",
      "\tspeed: 0.0277s/iter; left time: 278.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404026 Vali Loss: 0.0508852 Test Loss: 0.0551308\n",
      "Validation loss decreased (0.050895 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0409146\n",
      "\tspeed: 0.0545s/iter; left time: 541.4831s\n",
      "\titers: 200, epoch: 56 | loss: 0.0394938\n",
      "\tspeed: 0.0264s/iter; left time: 259.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403666 Vali Loss: 0.0509080 Test Loss: 0.0551149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0383278\n",
      "\tspeed: 0.0563s/iter; left time: 546.3756s\n",
      "\titers: 200, epoch: 57 | loss: 0.0380404\n",
      "\tspeed: 0.0269s/iter; left time: 258.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0403914 Vali Loss: 0.0508964 Test Loss: 0.0551263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0374241\n",
      "\tspeed: 0.0562s/iter; left time: 533.1406s\n",
      "\titers: 200, epoch: 58 | loss: 0.0384800\n",
      "\tspeed: 0.0266s/iter; left time: 250.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0404106 Vali Loss: 0.0509074 Test Loss: 0.0551193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0425259\n",
      "\tspeed: 0.0510s/iter; left time: 472.3618s\n",
      "\titers: 200, epoch: 59 | loss: 0.0383911\n",
      "\tspeed: 0.0300s/iter; left time: 275.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0403796 Vali Loss: 0.0508939 Test Loss: 0.0551248\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0411102\n",
      "\tspeed: 0.0529s/iter; left time: 478.6612s\n",
      "\titers: 200, epoch: 60 | loss: 0.0403990\n",
      "\tspeed: 0.0263s/iter; left time: 235.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0403918 Vali Loss: 0.0508964 Test Loss: 0.0551259\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0418877\n",
      "\tspeed: 0.0570s/iter; left time: 502.4903s\n",
      "\titers: 200, epoch: 61 | loss: 0.0403620\n",
      "\tspeed: 0.0272s/iter; left time: 236.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0403829 Vali Loss: 0.0509169 Test Loss: 0.0551298\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394381\n",
      "\tspeed: 0.0554s/iter; left time: 476.7332s\n",
      "\titers: 200, epoch: 62 | loss: 0.0413030\n",
      "\tspeed: 0.0270s/iter; left time: 229.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403858 Vali Loss: 0.0509289 Test Loss: 0.0551388\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0361456\n",
      "\tspeed: 0.0547s/iter; left time: 458.4112s\n",
      "\titers: 200, epoch: 63 | loss: 0.0410837\n",
      "\tspeed: 0.0283s/iter; left time: 234.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403752 Vali Loss: 0.0509146 Test Loss: 0.0551340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0410504\n",
      "\tspeed: 0.0519s/iter; left time: 422.6970s\n",
      "\titers: 200, epoch: 64 | loss: 0.0393771\n",
      "\tspeed: 0.0273s/iter; left time: 220.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0403604 Vali Loss: 0.0509011 Test Loss: 0.0551318\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0404327\n",
      "\tspeed: 0.0566s/iter; left time: 448.6071s\n",
      "\titers: 200, epoch: 65 | loss: 0.0426011\n",
      "\tspeed: 0.0267s/iter; left time: 209.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0403942 Vali Loss: 0.0509536 Test Loss: 0.0551359\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010024277493357658, rmse:0.10012131184339523, mae:0.055130843073129654, rse:0.38626524806022644\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0906341\n",
      "\tspeed: 0.0301s/iter; left time: 667.8155s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826328\n",
      "\tspeed: 0.0263s/iter; left time: 582.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0938272 Vali Loss: 0.0805418 Test Loss: 0.0871429\n",
      "Validation loss decreased (inf --> 0.080542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0551709\n",
      "\tspeed: 0.0576s/iter; left time: 1265.1429s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524309\n",
      "\tspeed: 0.0271s/iter; left time: 592.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0558666 Vali Loss: 0.0584886 Test Loss: 0.0616178\n",
      "Validation loss decreased (0.080542 --> 0.058489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486506\n",
      "\tspeed: 0.0536s/iter; left time: 1166.1015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0469318\n",
      "\tspeed: 0.0284s/iter; left time: 615.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0488140 Vali Loss: 0.0560299 Test Loss: 0.0600615\n",
      "Validation loss decreased (0.058489 --> 0.056030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0490200\n",
      "\tspeed: 0.0527s/iter; left time: 1134.7966s\n",
      "\titers: 200, epoch: 4 | loss: 0.0490843\n",
      "\tspeed: 0.0289s/iter; left time: 619.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0470409 Vali Loss: 0.0548938 Test Loss: 0.0585970\n",
      "Validation loss decreased (0.056030 --> 0.054894).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0493169\n",
      "\tspeed: 0.0564s/iter; left time: 1202.6886s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423416\n",
      "\tspeed: 0.0264s/iter; left time: 560.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0458134 Vali Loss: 0.0537671 Test Loss: 0.0576985\n",
      "Validation loss decreased (0.054894 --> 0.053767).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0481958\n",
      "\tspeed: 0.0571s/iter; left time: 1204.8272s\n",
      "\titers: 200, epoch: 6 | loss: 0.0447032\n",
      "\tspeed: 0.0268s/iter; left time: 561.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0449244 Vali Loss: 0.0531660 Test Loss: 0.0571905\n",
      "Validation loss decreased (0.053767 --> 0.053166).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0444714\n",
      "\tspeed: 0.0541s/iter; left time: 1128.9689s\n",
      "\titers: 200, epoch: 7 | loss: 0.0447756\n",
      "\tspeed: 0.0277s/iter; left time: 575.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0443288 Vali Loss: 0.0529909 Test Loss: 0.0570281\n",
      "Validation loss decreased (0.053166 --> 0.052991).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460659\n",
      "\tspeed: 0.0543s/iter; left time: 1119.9415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0454672\n",
      "\tspeed: 0.0291s/iter; left time: 598.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0438346 Vali Loss: 0.0530107 Test Loss: 0.0570792\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458995\n",
      "\tspeed: 0.0516s/iter; left time: 1054.2843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0426223\n",
      "\tspeed: 0.0270s/iter; left time: 548.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0434338 Vali Loss: 0.0526153 Test Loss: 0.0565650\n",
      "Validation loss decreased (0.052991 --> 0.052615).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0406584\n",
      "\tspeed: 0.0555s/iter; left time: 1121.0964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0479837\n",
      "\tspeed: 0.0265s/iter; left time: 533.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0430610 Vali Loss: 0.0523429 Test Loss: 0.0565098\n",
      "Validation loss decreased (0.052615 --> 0.052343).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441144\n",
      "\tspeed: 0.0565s/iter; left time: 1127.7538s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424211\n",
      "\tspeed: 0.0273s/iter; left time: 543.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0427796 Vali Loss: 0.0520273 Test Loss: 0.0561341\n",
      "Validation loss decreased (0.052343 --> 0.052027).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0395642\n",
      "\tspeed: 0.0539s/iter; left time: 1064.6384s\n",
      "\titers: 200, epoch: 12 | loss: 0.0417812\n",
      "\tspeed: 0.0275s/iter; left time: 541.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0424066 Vali Loss: 0.0522500 Test Loss: 0.0566746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465006\n",
      "\tspeed: 0.0542s/iter; left time: 1057.6991s\n",
      "\titers: 200, epoch: 13 | loss: 0.0409592\n",
      "\tspeed: 0.0280s/iter; left time: 543.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0422092 Vali Loss: 0.0518321 Test Loss: 0.0560570\n",
      "Validation loss decreased (0.052027 --> 0.051832).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417979\n",
      "\tspeed: 0.0529s/iter; left time: 1020.2572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418281\n",
      "\tspeed: 0.0271s/iter; left time: 520.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0420007 Vali Loss: 0.0518557 Test Loss: 0.0559012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0409619\n",
      "\tspeed: 0.0591s/iter; left time: 1127.5658s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422560\n",
      "\tspeed: 0.0264s/iter; left time: 501.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0418025 Vali Loss: 0.0515299 Test Loss: 0.0558530\n",
      "Validation loss decreased (0.051832 --> 0.051530).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0418751\n",
      "\tspeed: 0.0557s/iter; left time: 1050.5298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0431925\n",
      "\tspeed: 0.0278s/iter; left time: 521.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0416322 Vali Loss: 0.0516220 Test Loss: 0.0559839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0416599\n",
      "\tspeed: 0.0536s/iter; left time: 998.4634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0385930\n",
      "\tspeed: 0.0288s/iter; left time: 533.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0415159 Vali Loss: 0.0515925 Test Loss: 0.0557896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0403570\n",
      "\tspeed: 0.0546s/iter; left time: 1005.0983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0396579\n",
      "\tspeed: 0.0271s/iter; left time: 496.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0413374 Vali Loss: 0.0514856 Test Loss: 0.0555889\n",
      "Validation loss decreased (0.051530 --> 0.051486).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426625\n",
      "\tspeed: 0.0550s/iter; left time: 999.9825s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415856\n",
      "\tspeed: 0.0267s/iter; left time: 483.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0412477 Vali Loss: 0.0512750 Test Loss: 0.0556268\n",
      "Validation loss decreased (0.051486 --> 0.051275).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0406603\n",
      "\tspeed: 0.0572s/iter; left time: 1027.6752s\n",
      "\titers: 200, epoch: 20 | loss: 0.0444297\n",
      "\tspeed: 0.0266s/iter; left time: 475.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0412201 Vali Loss: 0.0512715 Test Loss: 0.0556442\n",
      "Validation loss decreased (0.051275 --> 0.051271).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0446360\n",
      "\tspeed: 0.0541s/iter; left time: 959.2371s\n",
      "\titers: 200, epoch: 21 | loss: 0.0451247\n",
      "\tspeed: 0.0288s/iter; left time: 508.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0410562 Vali Loss: 0.0510677 Test Loss: 0.0556257\n",
      "Validation loss decreased (0.051271 --> 0.051068).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0413175\n",
      "\tspeed: 0.0525s/iter; left time: 920.2055s\n",
      "\titers: 200, epoch: 22 | loss: 0.0406883\n",
      "\tspeed: 0.0282s/iter; left time: 491.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0409632 Vali Loss: 0.0511050 Test Loss: 0.0554848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0413638\n",
      "\tspeed: 0.0532s/iter; left time: 920.3822s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385806\n",
      "\tspeed: 0.0282s/iter; left time: 485.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0408717 Vali Loss: 0.0511044 Test Loss: 0.0554944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0418123\n",
      "\tspeed: 0.0560s/iter; left time: 956.3025s\n",
      "\titers: 200, epoch: 24 | loss: 0.0407323\n",
      "\tspeed: 0.0265s/iter; left time: 450.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0408074 Vali Loss: 0.0511794 Test Loss: 0.0554869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0389306\n",
      "\tspeed: 0.0548s/iter; left time: 924.0469s\n",
      "\titers: 200, epoch: 25 | loss: 0.0398802\n",
      "\tspeed: 0.0273s/iter; left time: 457.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0407822 Vali Loss: 0.0511632 Test Loss: 0.0554472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0406251\n",
      "\tspeed: 0.0514s/iter; left time: 854.9484s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404109\n",
      "\tspeed: 0.0297s/iter; left time: 491.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0406947 Vali Loss: 0.0510870 Test Loss: 0.0554563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0426260\n",
      "\tspeed: 0.0533s/iter; left time: 873.7834s\n",
      "\titers: 200, epoch: 27 | loss: 0.0422118\n",
      "\tspeed: 0.0264s/iter; left time: 430.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0406440 Vali Loss: 0.0510169 Test Loss: 0.0554277\n",
      "Validation loss decreased (0.051068 --> 0.051017).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0433261\n",
      "\tspeed: 0.0584s/iter; left time: 944.4422s\n",
      "\titers: 200, epoch: 28 | loss: 0.0414303\n",
      "\tspeed: 0.0272s/iter; left time: 438.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0406054 Vali Loss: 0.0510836 Test Loss: 0.0553864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0386375\n",
      "\tspeed: 0.0533s/iter; left time: 849.9980s\n",
      "\titers: 200, epoch: 29 | loss: 0.0398392\n",
      "\tspeed: 0.0267s/iter; left time: 422.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0405403 Vali Loss: 0.0510816 Test Loss: 0.0554030\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0395849\n",
      "\tspeed: 0.0570s/iter; left time: 897.0832s\n",
      "\titers: 200, epoch: 30 | loss: 0.0434685\n",
      "\tspeed: 0.0287s/iter; left time: 447.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0405472 Vali Loss: 0.0509714 Test Loss: 0.0553758\n",
      "Validation loss decreased (0.051017 --> 0.050971).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0404055\n",
      "\tspeed: 0.0524s/iter; left time: 812.5939s\n",
      "\titers: 200, epoch: 31 | loss: 0.0423716\n",
      "\tspeed: 0.0274s/iter; left time: 422.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0404917 Vali Loss: 0.0509903 Test Loss: 0.0553255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0410218\n",
      "\tspeed: 0.0558s/iter; left time: 853.0859s\n",
      "\titers: 200, epoch: 32 | loss: 0.0379313\n",
      "\tspeed: 0.0265s/iter; left time: 403.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0404833 Vali Loss: 0.0509146 Test Loss: 0.0553534\n",
      "Validation loss decreased (0.050971 --> 0.050915).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0403348\n",
      "\tspeed: 0.0554s/iter; left time: 834.4094s\n",
      "\titers: 200, epoch: 33 | loss: 0.0399958\n",
      "\tspeed: 0.0270s/iter; left time: 404.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0404073 Vali Loss: 0.0508854 Test Loss: 0.0553828\n",
      "Validation loss decreased (0.050915 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0402859\n",
      "\tspeed: 0.0528s/iter; left time: 784.3565s\n",
      "\titers: 200, epoch: 34 | loss: 0.0393198\n",
      "\tspeed: 0.0278s/iter; left time: 410.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404330 Vali Loss: 0.0509054 Test Loss: 0.0553213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0399488\n",
      "\tspeed: 0.0524s/iter; left time: 766.7168s\n",
      "\titers: 200, epoch: 35 | loss: 0.0390085\n",
      "\tspeed: 0.0271s/iter; left time: 392.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403941 Vali Loss: 0.0509035 Test Loss: 0.0553123\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0437253\n",
      "\tspeed: 0.0543s/iter; left time: 781.3251s\n",
      "\titers: 200, epoch: 36 | loss: 0.0389777\n",
      "\tspeed: 0.0265s/iter; left time: 379.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0403536 Vali Loss: 0.0508838 Test Loss: 0.0553374\n",
      "Validation loss decreased (0.050885 --> 0.050884).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0410785\n",
      "\tspeed: 0.0546s/iter; left time: 773.2454s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399544\n",
      "\tspeed: 0.0268s/iter; left time: 377.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0403515 Vali Loss: 0.0509292 Test Loss: 0.0553296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0391543\n",
      "\tspeed: 0.0525s/iter; left time: 732.7616s\n",
      "\titers: 200, epoch: 38 | loss: 0.0413559\n",
      "\tspeed: 0.0273s/iter; left time: 378.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0403439 Vali Loss: 0.0508500 Test Loss: 0.0553205\n",
      "Validation loss decreased (0.050884 --> 0.050850).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0417169\n",
      "\tspeed: 0.0569s/iter; left time: 780.8474s\n",
      "\titers: 200, epoch: 39 | loss: 0.0405512\n",
      "\tspeed: 0.0267s/iter; left time: 363.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0403442 Vali Loss: 0.0508796 Test Loss: 0.0553248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0447844\n",
      "\tspeed: 0.0542s/iter; left time: 731.6767s\n",
      "\titers: 200, epoch: 40 | loss: 0.0395523\n",
      "\tspeed: 0.0269s/iter; left time: 360.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0403389 Vali Loss: 0.0507638 Test Loss: 0.0552910\n",
      "Validation loss decreased (0.050850 --> 0.050764).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0417288\n",
      "\tspeed: 0.0538s/iter; left time: 714.9267s\n",
      "\titers: 200, epoch: 41 | loss: 0.0412049\n",
      "\tspeed: 0.0273s/iter; left time: 359.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0403560 Vali Loss: 0.0508435 Test Loss: 0.0553101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0378692\n",
      "\tspeed: 0.0529s/iter; left time: 690.6556s\n",
      "\titers: 200, epoch: 42 | loss: 0.0401617\n",
      "\tspeed: 0.0272s/iter; left time: 351.9640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403200 Vali Loss: 0.0508418 Test Loss: 0.0553548\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0384229\n",
      "\tspeed: 0.0534s/iter; left time: 685.2592s\n",
      "\titers: 200, epoch: 43 | loss: 0.0370391\n",
      "\tspeed: 0.0282s/iter; left time: 359.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0402477 Vali Loss: 0.0508064 Test Loss: 0.0553414\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0432439\n",
      "\tspeed: 0.0566s/iter; left time: 713.6192s\n",
      "\titers: 200, epoch: 44 | loss: 0.0400607\n",
      "\tspeed: 0.0265s/iter; left time: 331.6480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0402985 Vali Loss: 0.0508538 Test Loss: 0.0553522\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0387721\n",
      "\tspeed: 0.0530s/iter; left time: 656.5277s\n",
      "\titers: 200, epoch: 45 | loss: 0.0426491\n",
      "\tspeed: 0.0284s/iter; left time: 349.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0402648 Vali Loss: 0.0508805 Test Loss: 0.0553688\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0391906\n",
      "\tspeed: 0.0538s/iter; left time: 654.6966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383839\n",
      "\tspeed: 0.0274s/iter; left time: 331.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0401979 Vali Loss: 0.0508143 Test Loss: 0.0553381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0380304\n",
      "\tspeed: 0.0531s/iter; left time: 634.4437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0415097\n",
      "\tspeed: 0.0281s/iter; left time: 332.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0402226 Vali Loss: 0.0507866 Test Loss: 0.0553593\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0386002\n",
      "\tspeed: 0.0554s/iter; left time: 649.1937s\n",
      "\titers: 200, epoch: 48 | loss: 0.0388776\n",
      "\tspeed: 0.0274s/iter; left time: 318.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0401984 Vali Loss: 0.0508578 Test Loss: 0.0553353\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0421254\n",
      "\tspeed: 0.0550s/iter; left time: 632.6324s\n",
      "\titers: 200, epoch: 49 | loss: 0.0385936\n",
      "\tspeed: 0.0279s/iter; left time: 318.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0402498 Vali Loss: 0.0508001 Test Loss: 0.0553192\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0405090\n",
      "\tspeed: 0.0519s/iter; left time: 584.6391s\n",
      "\titers: 200, epoch: 50 | loss: 0.0411080\n",
      "\tspeed: 0.0275s/iter; left time: 307.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0402468 Vali Loss: 0.0508563 Test Loss: 0.0553059\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010074619203805923, rmse:0.10037240386009216, mae:0.055291011929512024, rse:0.3872339427471161\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:47.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0946442\n",
      "\tspeed: 0.0544s/iter; left time: 1201.8179s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807172\n",
      "\tspeed: 0.0280s/iter; left time: 615.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.0976983 Vali Loss: 0.0885321 Test Loss: 0.0971842\n",
      "Validation loss decreased (inf --> 0.088532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0547s/iter; left time: 1197.6152s\n",
      "\titers: 200, epoch: 2 | loss: 0.0639201\n",
      "\tspeed: 0.0271s/iter; left time: 589.6803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0691408 Vali Loss: 0.0740071 Test Loss: 0.0823792\n",
      "Validation loss decreased (0.088532 --> 0.074007).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0629653\n",
      "\tspeed: 0.0547s/iter; left time: 1183.5931s\n",
      "\titers: 200, epoch: 3 | loss: 0.0609960\n",
      "\tspeed: 0.0295s/iter; left time: 635.9466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0631580 Vali Loss: 0.0724165 Test Loss: 0.0810770\n",
      "Validation loss decreased (0.074007 --> 0.072416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0591992\n",
      "\tspeed: 0.0530s/iter; left time: 1135.7080s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622611\n",
      "\tspeed: 0.0286s/iter; left time: 609.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0616025 Vali Loss: 0.0718696 Test Loss: 0.0810709\n",
      "Validation loss decreased (0.072416 --> 0.071870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633924\n",
      "\tspeed: 0.0580s/iter; left time: 1231.3352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584497\n",
      "\tspeed: 0.0269s/iter; left time: 567.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0605206 Vali Loss: 0.0706461 Test Loss: 0.0808803\n",
      "Validation loss decreased (0.071870 --> 0.070646).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0617116\n",
      "\tspeed: 0.0574s/iter; left time: 1203.8881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603344\n",
      "\tspeed: 0.0279s/iter; left time: 581.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0597658 Vali Loss: 0.0708851 Test Loss: 0.0804708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572835\n",
      "\tspeed: 0.0551s/iter; left time: 1143.7419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595429\n",
      "\tspeed: 0.0276s/iter; left time: 569.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0592192 Vali Loss: 0.0702724 Test Loss: 0.0811357\n",
      "Validation loss decreased (0.070646 --> 0.070272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0600042\n",
      "\tspeed: 0.0542s/iter; left time: 1114.4691s\n",
      "\titers: 200, epoch: 8 | loss: 0.0576544\n",
      "\tspeed: 0.0292s/iter; left time: 597.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0586930 Vali Loss: 0.0699404 Test Loss: 0.0809467\n",
      "Validation loss decreased (0.070272 --> 0.069940).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0586163\n",
      "\tspeed: 0.0551s/iter; left time: 1119.9328s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577755\n",
      "\tspeed: 0.0277s/iter; left time: 560.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0582909 Vali Loss: 0.0698899 Test Loss: 0.0808146\n",
      "Validation loss decreased (0.069940 --> 0.069890).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633654\n",
      "\tspeed: 0.0606s/iter; left time: 1218.7369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593716\n",
      "\tspeed: 0.0269s/iter; left time: 537.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0578296 Vali Loss: 0.0697316 Test Loss: 0.0806795\n",
      "Validation loss decreased (0.069890 --> 0.069732).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0568299\n",
      "\tspeed: 0.0564s/iter; left time: 1121.0738s\n",
      "\titers: 200, epoch: 11 | loss: 0.0571765\n",
      "\tspeed: 0.0281s/iter; left time: 556.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 222 | Train Loss: 0.0575434 Vali Loss: 0.0695331 Test Loss: 0.0808393\n",
      "Validation loss decreased (0.069732 --> 0.069533).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0532095\n",
      "\tspeed: 0.0540s/iter; left time: 1061.8762s\n",
      "\titers: 200, epoch: 12 | loss: 0.0552783\n",
      "\tspeed: 0.0286s/iter; left time: 559.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0572077 Vali Loss: 0.0695406 Test Loss: 0.0809313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564464\n",
      "\tspeed: 0.0544s/iter; left time: 1058.2301s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570819\n",
      "\tspeed: 0.0273s/iter; left time: 527.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0568615 Vali Loss: 0.0693137 Test Loss: 0.0810390\n",
      "Validation loss decreased (0.069533 --> 0.069314).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0539912\n",
      "\tspeed: 0.0568s/iter; left time: 1090.8423s\n",
      "\titers: 200, epoch: 14 | loss: 0.0568080\n",
      "\tspeed: 0.0266s/iter; left time: 507.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0565855 Vali Loss: 0.0695845 Test Loss: 0.0809268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0593582\n",
      "\tspeed: 0.0516s/iter; left time: 979.2710s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566474\n",
      "\tspeed: 0.0271s/iter; left time: 511.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0563461 Vali Loss: 0.0693047 Test Loss: 0.0811887\n",
      "Validation loss decreased (0.069314 --> 0.069305).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0594476\n",
      "\tspeed: 0.0555s/iter; left time: 1040.9186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0533540\n",
      "\tspeed: 0.0293s/iter; left time: 546.7886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0560892 Vali Loss: 0.0693481 Test Loss: 0.0814752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0553667\n",
      "\tspeed: 0.0528s/iter; left time: 979.3788s\n",
      "\titers: 200, epoch: 17 | loss: 0.0557630\n",
      "\tspeed: 0.0302s/iter; left time: 556.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.0558328 Vali Loss: 0.0694838 Test Loss: 0.0814889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601683\n",
      "\tspeed: 0.0535s/iter; left time: 980.2696s\n",
      "\titers: 200, epoch: 18 | loss: 0.0555220\n",
      "\tspeed: 0.0278s/iter; left time: 506.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0556501 Vali Loss: 0.0696565 Test Loss: 0.0816849\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0553780\n",
      "\tspeed: 0.0552s/iter; left time: 999.6674s\n",
      "\titers: 200, epoch: 19 | loss: 0.0562586\n",
      "\tspeed: 0.0275s/iter; left time: 495.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0554732 Vali Loss: 0.0695040 Test Loss: 0.0815747\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0575418\n",
      "\tspeed: 0.0550s/iter; left time: 983.9110s\n",
      "\titers: 200, epoch: 20 | loss: 0.0529493\n",
      "\tspeed: 0.0278s/iter; left time: 494.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0552923 Vali Loss: 0.0695789 Test Loss: 0.0819936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0552874\n",
      "\tspeed: 0.0537s/iter; left time: 949.1304s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571044\n",
      "\tspeed: 0.0302s/iter; left time: 530.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0551806 Vali Loss: 0.0696505 Test Loss: 0.0819064\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523697\n",
      "\tspeed: 0.0560s/iter; left time: 975.7897s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539634\n",
      "\tspeed: 0.0272s/iter; left time: 471.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0550097 Vali Loss: 0.0697481 Test Loss: 0.0818706\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570134\n",
      "\tspeed: 0.0566s/iter; left time: 973.8350s\n",
      "\titers: 200, epoch: 23 | loss: 0.0503240\n",
      "\tspeed: 0.0277s/iter; left time: 473.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0549191 Vali Loss: 0.0695426 Test Loss: 0.0819507\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0564718\n",
      "\tspeed: 0.0544s/iter; left time: 924.8548s\n",
      "\titers: 200, epoch: 24 | loss: 0.0560874\n",
      "\tspeed: 0.0284s/iter; left time: 479.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0547920 Vali Loss: 0.0694288 Test Loss: 0.0827027\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0538619\n",
      "\tspeed: 0.0546s/iter; left time: 916.5744s\n",
      "\titers: 200, epoch: 25 | loss: 0.0557052\n",
      "\tspeed: 0.0294s/iter; left time: 490.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0546779 Vali Loss: 0.0694937 Test Loss: 0.0824538\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019583983346819878, rmse:0.13994278013706207, mae:0.08118870854377747, rse:0.5413358807563782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0952129\n",
      "\tspeed: 0.0302s/iter; left time: 667.3766s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885167\n",
      "\tspeed: 0.0308s/iter; left time: 677.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0985027 Vali Loss: 0.0886972 Test Loss: 0.0972691\n",
      "Validation loss decreased (inf --> 0.088697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0681498\n",
      "\tspeed: 0.0563s/iter; left time: 1232.1622s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649547\n",
      "\tspeed: 0.0270s/iter; left time: 587.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0695079 Vali Loss: 0.0742967 Test Loss: 0.0827173\n",
      "Validation loss decreased (0.088697 --> 0.074297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636618\n",
      "\tspeed: 0.0621s/iter; left time: 1344.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675858\n",
      "\tspeed: 0.0272s/iter; left time: 585.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0632788 Vali Loss: 0.0724602 Test Loss: 0.0818352\n",
      "Validation loss decreased (0.074297 --> 0.072460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0607947\n",
      "\tspeed: 0.0583s/iter; left time: 1248.7349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615927\n",
      "\tspeed: 0.0288s/iter; left time: 613.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0616307 Vali Loss: 0.0715656 Test Loss: 0.0804375\n",
      "Validation loss decreased (0.072460 --> 0.071566).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622085\n",
      "\tspeed: 0.0546s/iter; left time: 1158.1798s\n",
      "\titers: 200, epoch: 5 | loss: 0.0607410\n",
      "\tspeed: 0.0310s/iter; left time: 653.6964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0605575 Vali Loss: 0.0711619 Test Loss: 0.0811173\n",
      "Validation loss decreased (0.071566 --> 0.071162).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583275\n",
      "\tspeed: 0.0554s/iter; left time: 1163.7437s\n",
      "\titers: 200, epoch: 6 | loss: 0.0605036\n",
      "\tspeed: 0.0276s/iter; left time: 576.9671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0598762 Vali Loss: 0.0707136 Test Loss: 0.0810201\n",
      "Validation loss decreased (0.071162 --> 0.070714).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571717\n",
      "\tspeed: 0.0581s/iter; left time: 1205.9736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580162\n",
      "\tspeed: 0.0270s/iter; left time: 558.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0591734 Vali Loss: 0.0701467 Test Loss: 0.0805756\n",
      "Validation loss decreased (0.070714 --> 0.070147).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549409\n",
      "\tspeed: 0.0596s/iter; left time: 1225.5543s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589893\n",
      "\tspeed: 0.0269s/iter; left time: 549.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0587496 Vali Loss: 0.0706592 Test Loss: 0.0805735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562943\n",
      "\tspeed: 0.0540s/iter; left time: 1097.0223s\n",
      "\titers: 200, epoch: 9 | loss: 0.0623835\n",
      "\tspeed: 0.0310s/iter; left time: 626.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.0582612 Vali Loss: 0.0701556 Test Loss: 0.0809764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0560510\n",
      "\tspeed: 0.0546s/iter; left time: 1098.6045s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569311\n",
      "\tspeed: 0.0277s/iter; left time: 553.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0579194 Vali Loss: 0.0698631 Test Loss: 0.0805883\n",
      "Validation loss decreased (0.070147 --> 0.069863).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552880\n",
      "\tspeed: 0.0576s/iter; left time: 1145.5217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567831\n",
      "\tspeed: 0.0276s/iter; left time: 546.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0575630 Vali Loss: 0.0698857 Test Loss: 0.0814239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0589652\n",
      "\tspeed: 0.0585s/iter; left time: 1149.6359s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571650\n",
      "\tspeed: 0.0272s/iter; left time: 531.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0572331 Vali Loss: 0.0696580 Test Loss: 0.0805479\n",
      "Validation loss decreased (0.069863 --> 0.069658).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596699\n",
      "\tspeed: 0.0590s/iter; left time: 1146.2923s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586063\n",
      "\tspeed: 0.0274s/iter; left time: 529.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0569622 Vali Loss: 0.0694498 Test Loss: 0.0804356\n",
      "Validation loss decreased (0.069658 --> 0.069450).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589501\n",
      "\tspeed: 0.0537s/iter; left time: 1032.2106s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569431\n",
      "\tspeed: 0.0325s/iter; left time: 620.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0566912 Vali Loss: 0.0693219 Test Loss: 0.0799958\n",
      "Validation loss decreased (0.069450 --> 0.069322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506507\n",
      "\tspeed: 0.0546s/iter; left time: 1037.9295s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569483\n",
      "\tspeed: 0.0267s/iter; left time: 503.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0564393 Vali Loss: 0.0695112 Test Loss: 0.0806874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580912\n",
      "\tspeed: 0.0570s/iter; left time: 1069.7731s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560368\n",
      "\tspeed: 0.0276s/iter; left time: 514.8626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0562285 Vali Loss: 0.0692488 Test Loss: 0.0806654\n",
      "Validation loss decreased (0.069322 --> 0.069249).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0560966\n",
      "\tspeed: 0.0579s/iter; left time: 1074.1554s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546358\n",
      "\tspeed: 0.0272s/iter; left time: 501.0310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0560600 Vali Loss: 0.0693445 Test Loss: 0.0808701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0536982\n",
      "\tspeed: 0.0545s/iter; left time: 998.5697s\n",
      "\titers: 200, epoch: 18 | loss: 0.0576510\n",
      "\tspeed: 0.0297s/iter; left time: 541.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0558209 Vali Loss: 0.0692960 Test Loss: 0.0809055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0568429\n",
      "\tspeed: 0.0538s/iter; left time: 974.8709s\n",
      "\titers: 200, epoch: 19 | loss: 0.0548730\n",
      "\tspeed: 0.0272s/iter; left time: 488.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0556284 Vali Loss: 0.0691479 Test Loss: 0.0808090\n",
      "Validation loss decreased (0.069249 --> 0.069148).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542075\n",
      "\tspeed: 0.0588s/iter; left time: 1052.1349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543660\n",
      "\tspeed: 0.0270s/iter; left time: 480.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0555214 Vali Loss: 0.0692614 Test Loss: 0.0808009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560614\n",
      "\tspeed: 0.0583s/iter; left time: 1029.5537s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538527\n",
      "\tspeed: 0.0276s/iter; left time: 483.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0553980 Vali Loss: 0.0693827 Test Loss: 0.0812554\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0574554\n",
      "\tspeed: 0.0532s/iter; left time: 927.7367s\n",
      "\titers: 200, epoch: 22 | loss: 0.0532297\n",
      "\tspeed: 0.0295s/iter; left time: 511.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0552347 Vali Loss: 0.0692179 Test Loss: 0.0811274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0512069\n",
      "\tspeed: 0.0557s/iter; left time: 958.7464s\n",
      "\titers: 200, epoch: 23 | loss: 0.0576784\n",
      "\tspeed: 0.0279s/iter; left time: 476.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0551042 Vali Loss: 0.0693131 Test Loss: 0.0809331\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0545038\n",
      "\tspeed: 0.0566s/iter; left time: 961.7671s\n",
      "\titers: 200, epoch: 24 | loss: 0.0525213\n",
      "\tspeed: 0.0287s/iter; left time: 484.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0549631 Vali Loss: 0.0693683 Test Loss: 0.0808207\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0531886\n",
      "\tspeed: 0.0581s/iter; left time: 974.3355s\n",
      "\titers: 200, epoch: 25 | loss: 0.0607770\n",
      "\tspeed: 0.0270s/iter; left time: 450.1486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0548838 Vali Loss: 0.0693077 Test Loss: 0.0809227\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0545997\n",
      "\tspeed: 0.0576s/iter; left time: 953.2549s\n",
      "\titers: 200, epoch: 26 | loss: 0.0549107\n",
      "\tspeed: 0.0294s/iter; left time: 483.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0547993 Vali Loss: 0.0692610 Test Loss: 0.0812203\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0559376\n",
      "\tspeed: 0.0530s/iter; left time: 865.3901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532648\n",
      "\tspeed: 0.0288s/iter; left time: 467.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0547550 Vali Loss: 0.0691140 Test Loss: 0.0808653\n",
      "Validation loss decreased (0.069148 --> 0.069114).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0582528\n",
      "\tspeed: 0.0569s/iter; left time: 915.8264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525920\n",
      "\tspeed: 0.0273s/iter; left time: 436.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0546527 Vali Loss: 0.0690959 Test Loss: 0.0806358\n",
      "Validation loss decreased (0.069114 --> 0.069096).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0547554\n",
      "\tspeed: 0.0570s/iter; left time: 905.6622s\n",
      "\titers: 200, epoch: 29 | loss: 0.0558492\n",
      "\tspeed: 0.0281s/iter; left time: 444.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0545580 Vali Loss: 0.0692201 Test Loss: 0.0810624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0513949\n",
      "\tspeed: 0.0554s/iter; left time: 867.4813s\n",
      "\titers: 200, epoch: 30 | loss: 0.0538825\n",
      "\tspeed: 0.0268s/iter; left time: 417.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0545313 Vali Loss: 0.0691521 Test Loss: 0.0810161\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517632\n",
      "\tspeed: 0.0559s/iter; left time: 862.8661s\n",
      "\titers: 200, epoch: 31 | loss: 0.0539208\n",
      "\tspeed: 0.0308s/iter; left time: 472.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0545053 Vali Loss: 0.0692572 Test Loss: 0.0809226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0550982\n",
      "\tspeed: 0.0542s/iter; left time: 824.9185s\n",
      "\titers: 200, epoch: 32 | loss: 0.0533233\n",
      "\tspeed: 0.0273s/iter; left time: 412.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0544201 Vali Loss: 0.0691529 Test Loss: 0.0810605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533810\n",
      "\tspeed: 0.0567s/iter; left time: 850.9174s\n",
      "\titers: 200, epoch: 33 | loss: 0.0557891\n",
      "\tspeed: 0.0270s/iter; left time: 402.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0543391 Vali Loss: 0.0690889 Test Loss: 0.0809323\n",
      "Validation loss decreased (0.069096 --> 0.069089).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0543540\n",
      "\tspeed: 0.0533s/iter; left time: 787.3487s\n",
      "\titers: 200, epoch: 34 | loss: 0.0501789\n",
      "\tspeed: 0.0319s/iter; left time: 467.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0543403 Vali Loss: 0.0692075 Test Loss: 0.0809898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572097\n",
      "\tspeed: 0.0542s/iter; left time: 789.1576s\n",
      "\titers: 200, epoch: 35 | loss: 0.0554948\n",
      "\tspeed: 0.0274s/iter; left time: 396.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0543257 Vali Loss: 0.0691925 Test Loss: 0.0809306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536229\n",
      "\tspeed: 0.0581s/iter; left time: 832.6273s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524175\n",
      "\tspeed: 0.0276s/iter; left time: 392.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0542763 Vali Loss: 0.0691631 Test Loss: 0.0809931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568595\n",
      "\tspeed: 0.0557s/iter; left time: 786.2092s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558364\n",
      "\tspeed: 0.0270s/iter; left time: 378.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0542079 Vali Loss: 0.0692795 Test Loss: 0.0810558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0523561\n",
      "\tspeed: 0.0560s/iter; left time: 777.7551s\n",
      "\titers: 200, epoch: 38 | loss: 0.0541448\n",
      "\tspeed: 0.0290s/iter; left time: 400.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0541932 Vali Loss: 0.0691731 Test Loss: 0.0809929\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0515040\n",
      "\tspeed: 0.0532s/iter; left time: 727.3661s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538739\n",
      "\tspeed: 0.0318s/iter; left time: 430.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 222 | Train Loss: 0.0542231 Vali Loss: 0.0692040 Test Loss: 0.0808713\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0547240\n",
      "\tspeed: 0.0587s/iter; left time: 789.4755s\n",
      "\titers: 200, epoch: 40 | loss: 0.0544746\n",
      "\tspeed: 0.0281s/iter; left time: 374.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0541712 Vali Loss: 0.0691869 Test Loss: 0.0810898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535738\n",
      "\tspeed: 0.0576s/iter; left time: 762.1386s\n",
      "\titers: 200, epoch: 41 | loss: 0.0521586\n",
      "\tspeed: 0.0274s/iter; left time: 359.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0541541 Vali Loss: 0.0692053 Test Loss: 0.0810138\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0560169\n",
      "\tspeed: 0.0569s/iter; left time: 739.6913s\n",
      "\titers: 200, epoch: 42 | loss: 0.0550496\n",
      "\tspeed: 0.0286s/iter; left time: 368.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0541010 Vali Loss: 0.0692285 Test Loss: 0.0811099\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0485699\n",
      "\tspeed: 0.0567s/iter; left time: 724.9226s\n",
      "\titers: 200, epoch: 43 | loss: 0.0563646\n",
      "\tspeed: 0.0295s/iter; left time: 374.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0541447 Vali Loss: 0.0692108 Test Loss: 0.0810611\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019895073026418686, rmse:0.14104989171028137, mae:0.08093231916427612, rse:0.54561847448349\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:44.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0938556\n",
      "\tspeed: 0.0537s/iter; left time: 1187.7679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0854498\n",
      "\tspeed: 0.0275s/iter; left time: 605.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0996454 Vali Loss: 0.0909195 Test Loss: 0.0982277\n",
      "Validation loss decreased (inf --> 0.090919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0675109\n",
      "\tspeed: 0.0616s/iter; left time: 1348.6246s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670425\n",
      "\tspeed: 0.0271s/iter; left time: 591.2223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0727755 Vali Loss: 0.0776914 Test Loss: 0.0867592\n",
      "Validation loss decreased (0.090919 --> 0.077691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0661314\n",
      "\tspeed: 0.0576s/iter; left time: 1247.1888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0677241\n",
      "\tspeed: 0.0282s/iter; left time: 608.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0669249 Vali Loss: 0.0761548 Test Loss: 0.0854462\n",
      "Validation loss decreased (0.077691 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0679322\n",
      "\tspeed: 0.0568s/iter; left time: 1217.4635s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632045\n",
      "\tspeed: 0.0299s/iter; left time: 637.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0654356 Vali Loss: 0.0749669 Test Loss: 0.0855714\n",
      "Validation loss decreased (0.076155 --> 0.074967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612492\n",
      "\tspeed: 0.0552s/iter; left time: 1171.6811s\n",
      "\titers: 200, epoch: 5 | loss: 0.0665668\n",
      "\tspeed: 0.0289s/iter; left time: 609.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 222 | Train Loss: 0.0643432 Vali Loss: 0.0746899 Test Loss: 0.0860002\n",
      "Validation loss decreased (0.074967 --> 0.074690).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619588\n",
      "\tspeed: 0.0563s/iter; left time: 1181.4707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662285\n",
      "\tspeed: 0.0271s/iter; left time: 566.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0634915 Vali Loss: 0.0741637 Test Loss: 0.0862336\n",
      "Validation loss decreased (0.074690 --> 0.074164).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630885\n",
      "\tspeed: 0.0599s/iter; left time: 1244.1855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668416\n",
      "\tspeed: 0.0271s/iter; left time: 560.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0628616 Vali Loss: 0.0739373 Test Loss: 0.0866496\n",
      "Validation loss decreased (0.074164 --> 0.073937).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0633949\n",
      "\tspeed: 0.0595s/iter; left time: 1222.1403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0597458\n",
      "\tspeed: 0.0301s/iter; left time: 615.7145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 222 | Train Loss: 0.0622367 Vali Loss: 0.0738674 Test Loss: 0.0874078\n",
      "Validation loss decreased (0.073937 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600061\n",
      "\tspeed: 0.0550s/iter; left time: 1118.5541s\n",
      "\titers: 200, epoch: 9 | loss: 0.0622538\n",
      "\tspeed: 0.0301s/iter; left time: 608.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0617032 Vali Loss: 0.0734540 Test Loss: 0.0876739\n",
      "Validation loss decreased (0.073867 --> 0.073454).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591503\n",
      "\tspeed: 0.0574s/iter; left time: 1153.2995s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608495\n",
      "\tspeed: 0.0293s/iter; left time: 585.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0612152 Vali Loss: 0.0735651 Test Loss: 0.0878582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628291\n",
      "\tspeed: 0.0580s/iter; left time: 1152.1630s\n",
      "\titers: 200, epoch: 11 | loss: 0.0591405\n",
      "\tspeed: 0.0276s/iter; left time: 546.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0608145 Vali Loss: 0.0734721 Test Loss: 0.0884252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628089\n",
      "\tspeed: 0.0565s/iter; left time: 1110.0706s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601851\n",
      "\tspeed: 0.0275s/iter; left time: 537.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0604573 Vali Loss: 0.0732824 Test Loss: 0.0882674\n",
      "Validation loss decreased (0.073454 --> 0.073282).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586489\n",
      "\tspeed: 0.0549s/iter; left time: 1067.0806s\n",
      "\titers: 200, epoch: 13 | loss: 0.0620482\n",
      "\tspeed: 0.0302s/iter; left time: 583.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0600379 Vali Loss: 0.0735289 Test Loss: 0.0874406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0555771\n",
      "\tspeed: 0.0543s/iter; left time: 1044.1961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605145\n",
      "\tspeed: 0.0276s/iter; left time: 527.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0596907 Vali Loss: 0.0732599 Test Loss: 0.0885390\n",
      "Validation loss decreased (0.073282 --> 0.073260).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584461\n",
      "\tspeed: 0.0618s/iter; left time: 1173.1642s\n",
      "\titers: 200, epoch: 15 | loss: 0.0568878\n",
      "\tspeed: 0.0271s/iter; left time: 511.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0593595 Vali Loss: 0.0733622 Test Loss: 0.0882639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593707\n",
      "\tspeed: 0.0574s/iter; left time: 1076.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0584661\n",
      "\tspeed: 0.0274s/iter; left time: 512.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0590356 Vali Loss: 0.0734783 Test Loss: 0.0876160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0588905\n",
      "\tspeed: 0.0564s/iter; left time: 1045.8583s\n",
      "\titers: 200, epoch: 17 | loss: 0.0621994\n",
      "\tspeed: 0.0304s/iter; left time: 560.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0587787 Vali Loss: 0.0732299 Test Loss: 0.0877349\n",
      "Validation loss decreased (0.073260 --> 0.073230).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621530\n",
      "\tspeed: 0.0544s/iter; left time: 996.3035s\n",
      "\titers: 200, epoch: 18 | loss: 0.0605658\n",
      "\tspeed: 0.0306s/iter; left time: 556.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0585481 Vali Loss: 0.0734606 Test Loss: 0.0877434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0583042\n",
      "\tspeed: 0.0553s/iter; left time: 1000.5556s\n",
      "\titers: 200, epoch: 19 | loss: 0.0605425\n",
      "\tspeed: 0.0278s/iter; left time: 500.8201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0582981 Vali Loss: 0.0732683 Test Loss: 0.0879471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0579087\n",
      "\tspeed: 0.0598s/iter; left time: 1069.7862s\n",
      "\titers: 200, epoch: 20 | loss: 0.0559152\n",
      "\tspeed: 0.0272s/iter; left time: 484.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0581190 Vali Loss: 0.0734302 Test Loss: 0.0868313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0566728\n",
      "\tspeed: 0.0571s/iter; left time: 1009.1655s\n",
      "\titers: 200, epoch: 21 | loss: 0.0573363\n",
      "\tspeed: 0.0278s/iter; left time: 488.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 222 | Train Loss: 0.0579168 Vali Loss: 0.0733025 Test Loss: 0.0868867\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0599002\n",
      "\tspeed: 0.0547s/iter; left time: 953.8582s\n",
      "\titers: 200, epoch: 22 | loss: 0.0579244\n",
      "\tspeed: 0.0308s/iter; left time: 534.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0577381 Vali Loss: 0.0734787 Test Loss: 0.0877282\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0576215\n",
      "\tspeed: 0.0563s/iter; left time: 968.5148s\n",
      "\titers: 200, epoch: 23 | loss: 0.0555970\n",
      "\tspeed: 0.0275s/iter; left time: 471.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0576474 Vali Loss: 0.0734664 Test Loss: 0.0873497\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0549140\n",
      "\tspeed: 0.0574s/iter; left time: 976.1575s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565494\n",
      "\tspeed: 0.0277s/iter; left time: 467.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0575239 Vali Loss: 0.0731563 Test Loss: 0.0869676\n",
      "Validation loss decreased (0.073230 --> 0.073156).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0596233\n",
      "\tspeed: 0.0578s/iter; left time: 968.7979s\n",
      "\titers: 200, epoch: 25 | loss: 0.0541902\n",
      "\tspeed: 0.0281s/iter; left time: 468.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0573391 Vali Loss: 0.0734023 Test Loss: 0.0868268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0555391\n",
      "\tspeed: 0.0544s/iter; left time: 900.2221s\n",
      "\titers: 200, epoch: 26 | loss: 0.0553594\n",
      "\tspeed: 0.0313s/iter; left time: 514.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0572754 Vali Loss: 0.0733688 Test Loss: 0.0870272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0564770\n",
      "\tspeed: 0.0558s/iter; left time: 910.6911s\n",
      "\titers: 200, epoch: 27 | loss: 0.0569422\n",
      "\tspeed: 0.0281s/iter; left time: 455.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0571740 Vali Loss: 0.0734585 Test Loss: 0.0868808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0568383\n",
      "\tspeed: 0.0574s/iter; left time: 923.9326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0575890\n",
      "\tspeed: 0.0276s/iter; left time: 442.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0571011 Vali Loss: 0.0735396 Test Loss: 0.0867445\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602893\n",
      "\tspeed: 0.0554s/iter; left time: 879.4234s\n",
      "\titers: 200, epoch: 29 | loss: 0.0582584\n",
      "\tspeed: 0.0274s/iter; left time: 432.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0570145 Vali Loss: 0.0735997 Test Loss: 0.0871782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537078\n",
      "\tspeed: 0.0572s/iter; left time: 896.0460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0555406\n",
      "\tspeed: 0.0280s/iter; left time: 436.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0569776 Vali Loss: 0.0735232 Test Loss: 0.0871077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0557368\n",
      "\tspeed: 0.0533s/iter; left time: 822.2656s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554728\n",
      "\tspeed: 0.0318s/iter; left time: 488.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 222 | Train Loss: 0.0569504 Vali Loss: 0.0735121 Test Loss: 0.0870237\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584505\n",
      "\tspeed: 0.0546s/iter; left time: 831.0824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0585560\n",
      "\tspeed: 0.0277s/iter; left time: 419.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0568485 Vali Loss: 0.0734587 Test Loss: 0.0867984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0601608\n",
      "\tspeed: 0.0571s/iter; left time: 855.6341s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542788\n",
      "\tspeed: 0.0279s/iter; left time: 416.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0568110 Vali Loss: 0.0735852 Test Loss: 0.0870490\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0593282\n",
      "\tspeed: 0.0565s/iter; left time: 834.2108s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566462\n",
      "\tspeed: 0.0280s/iter; left time: 410.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0568219 Vali Loss: 0.0735635 Test Loss: 0.0869921\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02209530398249626, rmse:0.14864489436149597, mae:0.0869675725698471, rse:0.5757157206535339\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0926753\n",
      "\tspeed: 0.0322s/iter; left time: 711.0785s\n",
      "\titers: 200, epoch: 1 | loss: 0.0864850\n",
      "\tspeed: 0.0273s/iter; left time: 601.1498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0998092 Vali Loss: 0.0912169 Test Loss: 0.0984884\n",
      "Validation loss decreased (inf --> 0.091217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0706366\n",
      "\tspeed: 0.0576s/iter; left time: 1260.3439s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685956\n",
      "\tspeed: 0.0308s/iter; left time: 670.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0732876 Vali Loss: 0.0785562 Test Loss: 0.0867374\n",
      "Validation loss decreased (0.091217 --> 0.078556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0673651\n",
      "\tspeed: 0.0541s/iter; left time: 1171.8726s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663863\n",
      "\tspeed: 0.0280s/iter; left time: 604.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0673279 Vali Loss: 0.0765334 Test Loss: 0.0856419\n",
      "Validation loss decreased (0.078556 --> 0.076533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0669243\n",
      "\tspeed: 0.0600s/iter; left time: 1286.9608s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647952\n",
      "\tspeed: 0.0271s/iter; left time: 578.9654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0655516 Vali Loss: 0.0755698 Test Loss: 0.0860987\n",
      "Validation loss decreased (0.076533 --> 0.075570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0669611\n",
      "\tspeed: 0.0548s/iter; left time: 1161.8915s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653353\n",
      "\tspeed: 0.0279s/iter; left time: 588.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0644662 Vali Loss: 0.0751957 Test Loss: 0.0860627\n",
      "Validation loss decreased (0.075570 --> 0.075196).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651973\n",
      "\tspeed: 0.0596s/iter; left time: 1250.0752s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602959\n",
      "\tspeed: 0.0282s/iter; left time: 589.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0636211 Vali Loss: 0.0742472 Test Loss: 0.0868280\n",
      "Validation loss decreased (0.075196 --> 0.074247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0617981\n",
      "\tspeed: 0.0553s/iter; left time: 1148.7227s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661122\n",
      "\tspeed: 0.0295s/iter; left time: 609.3023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0629225 Vali Loss: 0.0737034 Test Loss: 0.0874572\n",
      "Validation loss decreased (0.074247 --> 0.073703).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658991\n",
      "\tspeed: 0.0551s/iter; left time: 1132.5147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613267\n",
      "\tspeed: 0.0280s/iter; left time: 571.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0623983 Vali Loss: 0.0734330 Test Loss: 0.0871008\n",
      "Validation loss decreased (0.073703 --> 0.073433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0611679\n",
      "\tspeed: 0.0582s/iter; left time: 1182.8415s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620157\n",
      "\tspeed: 0.0271s/iter; left time: 547.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0617476 Vali Loss: 0.0734691 Test Loss: 0.0874490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0648440\n",
      "\tspeed: 0.0565s/iter; left time: 1135.3078s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623541\n",
      "\tspeed: 0.0273s/iter; left time: 546.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0612791 Vali Loss: 0.0735913 Test Loss: 0.0876361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0566490\n",
      "\tspeed: 0.0557s/iter; left time: 1106.8575s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592110\n",
      "\tspeed: 0.0281s/iter; left time: 555.7768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0607181 Vali Loss: 0.0732275 Test Loss: 0.0882248\n",
      "Validation loss decreased (0.073433 --> 0.073228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0632455\n",
      "\tspeed: 0.0554s/iter; left time: 1089.5562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584063\n",
      "\tspeed: 0.0298s/iter; left time: 582.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0603093 Vali Loss: 0.0735247 Test Loss: 0.0875141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0591289\n",
      "\tspeed: 0.0542s/iter; left time: 1053.2718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0583428\n",
      "\tspeed: 0.0280s/iter; left time: 540.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0599433 Vali Loss: 0.0735825 Test Loss: 0.0874094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605066\n",
      "\tspeed: 0.0570s/iter; left time: 1095.4285s\n",
      "\titers: 200, epoch: 14 | loss: 0.0622422\n",
      "\tspeed: 0.0276s/iter; left time: 526.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0595383 Vali Loss: 0.0733542 Test Loss: 0.0877012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0608642\n",
      "\tspeed: 0.0570s/iter; left time: 1083.1895s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595879\n",
      "\tspeed: 0.0279s/iter; left time: 526.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0591768 Vali Loss: 0.0733836 Test Loss: 0.0872333\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593759\n",
      "\tspeed: 0.0561s/iter; left time: 1053.7193s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591774\n",
      "\tspeed: 0.0282s/iter; left time: 527.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0589033 Vali Loss: 0.0735029 Test Loss: 0.0868597\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616219\n",
      "\tspeed: 0.0540s/iter; left time: 1001.4667s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582787\n",
      "\tspeed: 0.0291s/iter; left time: 536.0442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0586167 Vali Loss: 0.0735510 Test Loss: 0.0873291\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608582\n",
      "\tspeed: 0.0538s/iter; left time: 986.6374s\n",
      "\titers: 200, epoch: 18 | loss: 0.0558169\n",
      "\tspeed: 0.0274s/iter; left time: 499.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0583472 Vali Loss: 0.0736005 Test Loss: 0.0866306\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0579800\n",
      "\tspeed: 0.0574s/iter; left time: 1039.8457s\n",
      "\titers: 200, epoch: 19 | loss: 0.0586734\n",
      "\tspeed: 0.0274s/iter; left time: 492.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0581088 Vali Loss: 0.0736148 Test Loss: 0.0869817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582891\n",
      "\tspeed: 0.0546s/iter; left time: 976.7968s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546571\n",
      "\tspeed: 0.0274s/iter; left time: 487.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0578948 Vali Loss: 0.0738315 Test Loss: 0.0869170\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569176\n",
      "\tspeed: 0.0556s/iter; left time: 982.4490s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584212\n",
      "\tspeed: 0.0285s/iter; left time: 499.6546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0577929 Vali Loss: 0.0737043 Test Loss: 0.0868128\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02231057547032833, rmse:0.14936724305152893, mae:0.08822478353977203, rse:0.578513503074646\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:00.54s\n",
      "Intermediate time for FR: 00h:33m:33.22s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1220752\n",
      "\tspeed: 0.0509s/iter; left time: 1130.2764s\n",
      "\titers: 200, epoch: 1 | loss: 0.1124015\n",
      "\tspeed: 0.0281s/iter; left time: 622.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.1325993 Vali Loss: 0.0942944 Test Loss: 0.0955565\n",
      "Validation loss decreased (inf --> 0.094294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693890\n",
      "\tspeed: 0.0528s/iter; left time: 1159.9153s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668445\n",
      "\tspeed: 0.0266s/iter; left time: 582.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0759136 Vali Loss: 0.0627112 Test Loss: 0.0656406\n",
      "Validation loss decreased (0.094294 --> 0.062711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662491\n",
      "\tspeed: 0.0544s/iter; left time: 1183.8244s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660577\n",
      "\tspeed: 0.0273s/iter; left time: 591.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0650764 Vali Loss: 0.0596654 Test Loss: 0.0621885\n",
      "Validation loss decreased (0.062711 --> 0.059665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611442\n",
      "\tspeed: 0.0533s/iter; left time: 1147.3704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643807\n",
      "\tspeed: 0.0267s/iter; left time: 571.7833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0621614 Vali Loss: 0.0590315 Test Loss: 0.0613040\n",
      "Validation loss decreased (0.059665 --> 0.059032).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575514\n",
      "\tspeed: 0.0530s/iter; left time: 1129.6298s\n",
      "\titers: 200, epoch: 5 | loss: 0.0622045\n",
      "\tspeed: 0.0281s/iter; left time: 596.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0607118 Vali Loss: 0.0582237 Test Loss: 0.0606797\n",
      "Validation loss decreased (0.059032 --> 0.058224).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0604667\n",
      "\tspeed: 0.0516s/iter; left time: 1088.1781s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586946\n",
      "\tspeed: 0.0273s/iter; left time: 572.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0596630 Vali Loss: 0.0575096 Test Loss: 0.0601424\n",
      "Validation loss decreased (0.058224 --> 0.057510).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605737\n",
      "\tspeed: 0.0555s/iter; left time: 1157.0877s\n",
      "\titers: 200, epoch: 7 | loss: 0.0577191\n",
      "\tspeed: 0.0267s/iter; left time: 553.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0587539 Vali Loss: 0.0573150 Test Loss: 0.0599158\n",
      "Validation loss decreased (0.057510 --> 0.057315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569133\n",
      "\tspeed: 0.0554s/iter; left time: 1144.2128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609494\n",
      "\tspeed: 0.0269s/iter; left time: 552.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0581800 Vali Loss: 0.0571470 Test Loss: 0.0595391\n",
      "Validation loss decreased (0.057315 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543008\n",
      "\tspeed: 0.0537s/iter; left time: 1096.9061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0545223\n",
      "\tspeed: 0.0267s/iter; left time: 542.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0575996 Vali Loss: 0.0566902 Test Loss: 0.0590270\n",
      "Validation loss decreased (0.057147 --> 0.056690).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564065\n",
      "\tspeed: 0.0527s/iter; left time: 1064.7117s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549191\n",
      "\tspeed: 0.0283s/iter; left time: 569.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0571505 Vali Loss: 0.0567421 Test Loss: 0.0591187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0562808\n",
      "\tspeed: 0.0510s/iter; left time: 1019.5154s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546165\n",
      "\tspeed: 0.0269s/iter; left time: 533.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0566563 Vali Loss: 0.0563506 Test Loss: 0.0590622\n",
      "Validation loss decreased (0.056690 --> 0.056351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594916\n",
      "\tspeed: 0.0541s/iter; left time: 1068.2255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550755\n",
      "\tspeed: 0.0265s/iter; left time: 520.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0563721 Vali Loss: 0.0559727 Test Loss: 0.0584474\n",
      "Validation loss decreased (0.056351 --> 0.055973).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533181\n",
      "\tspeed: 0.0545s/iter; left time: 1064.3111s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591052\n",
      "\tspeed: 0.0266s/iter; left time: 516.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0560483 Vali Loss: 0.0560773 Test Loss: 0.0585655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576542\n",
      "\tspeed: 0.0512s/iter; left time: 988.1637s\n",
      "\titers: 200, epoch: 14 | loss: 0.0536710\n",
      "\tspeed: 0.0273s/iter; left time: 524.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0557588 Vali Loss: 0.0557475 Test Loss: 0.0584036\n",
      "Validation loss decreased (0.055973 --> 0.055747).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0577584\n",
      "\tspeed: 0.0550s/iter; left time: 1048.6455s\n",
      "\titers: 200, epoch: 15 | loss: 0.0573185\n",
      "\tspeed: 0.0283s/iter; left time: 536.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0554317 Vali Loss: 0.0554833 Test Loss: 0.0582388\n",
      "Validation loss decreased (0.055747 --> 0.055483).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574488\n",
      "\tspeed: 0.0530s/iter; left time: 998.9107s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597576\n",
      "\tspeed: 0.0268s/iter; left time: 502.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0553067 Vali Loss: 0.0555447 Test Loss: 0.0582300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0528388\n",
      "\tspeed: 0.0548s/iter; left time: 1020.4668s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528586\n",
      "\tspeed: 0.0266s/iter; left time: 492.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0550844 Vali Loss: 0.0555010 Test Loss: 0.0580867\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0575727\n",
      "\tspeed: 0.0531s/iter; left time: 978.1223s\n",
      "\titers: 200, epoch: 18 | loss: 0.0554257\n",
      "\tspeed: 0.0283s/iter; left time: 518.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0548954 Vali Loss: 0.0554527 Test Loss: 0.0580303\n",
      "Validation loss decreased (0.055483 --> 0.055453).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0514130\n",
      "\tspeed: 0.0530s/iter; left time: 964.1856s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547660\n",
      "\tspeed: 0.0275s/iter; left time: 496.5606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0548206 Vali Loss: 0.0552508 Test Loss: 0.0577160\n",
      "Validation loss decreased (0.055453 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535157\n",
      "\tspeed: 0.0514s/iter; left time: 923.5797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577883\n",
      "\tspeed: 0.0279s/iter; left time: 498.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0545696 Vali Loss: 0.0552697 Test Loss: 0.0577830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555147\n",
      "\tspeed: 0.0520s/iter; left time: 923.1396s\n",
      "\titers: 200, epoch: 21 | loss: 0.0544950\n",
      "\tspeed: 0.0266s/iter; left time: 469.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0544441 Vali Loss: 0.0549807 Test Loss: 0.0576976\n",
      "Validation loss decreased (0.055251 --> 0.054981).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534422\n",
      "\tspeed: 0.0547s/iter; left time: 957.8440s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564228\n",
      "\tspeed: 0.0264s/iter; left time: 459.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0543254 Vali Loss: 0.0550190 Test Loss: 0.0575762\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0517031\n",
      "\tspeed: 0.0519s/iter; left time: 897.4414s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587856\n",
      "\tspeed: 0.0267s/iter; left time: 458.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0543248 Vali Loss: 0.0550559 Test Loss: 0.0577396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560705\n",
      "\tspeed: 0.0509s/iter; left time: 869.2080s\n",
      "\titers: 200, epoch: 24 | loss: 0.0528798\n",
      "\tspeed: 0.0286s/iter; left time: 486.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0541613 Vali Loss: 0.0549477 Test Loss: 0.0576477\n",
      "Validation loss decreased (0.054981 --> 0.054948).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0560655\n",
      "\tspeed: 0.0556s/iter; left time: 937.5092s\n",
      "\titers: 200, epoch: 25 | loss: 0.0542304\n",
      "\tspeed: 0.0268s/iter; left time: 448.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0541076 Vali Loss: 0.0548136 Test Loss: 0.0576309\n",
      "Validation loss decreased (0.054948 --> 0.054814).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548747\n",
      "\tspeed: 0.0533s/iter; left time: 885.5314s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538855\n",
      "\tspeed: 0.0266s/iter; left time: 439.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0540087 Vali Loss: 0.0549526 Test Loss: 0.0575554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517120\n",
      "\tspeed: 0.0527s/iter; left time: 864.8934s\n",
      "\titers: 200, epoch: 27 | loss: 0.0527826\n",
      "\tspeed: 0.0266s/iter; left time: 434.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0539188 Vali Loss: 0.0549253 Test Loss: 0.0575773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0549809\n",
      "\tspeed: 0.0516s/iter; left time: 835.4098s\n",
      "\titers: 200, epoch: 28 | loss: 0.0554980\n",
      "\tspeed: 0.0271s/iter; left time: 435.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538956 Vali Loss: 0.0548986 Test Loss: 0.0574903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0527975\n",
      "\tspeed: 0.0508s/iter; left time: 809.8721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0547849\n",
      "\tspeed: 0.0276s/iter; left time: 437.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0538247 Vali Loss: 0.0547120 Test Loss: 0.0574399\n",
      "Validation loss decreased (0.054814 --> 0.054712).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0507995\n",
      "\tspeed: 0.0515s/iter; left time: 809.8363s\n",
      "\titers: 200, epoch: 30 | loss: 0.0500010\n",
      "\tspeed: 0.0266s/iter; left time: 415.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0537853 Vali Loss: 0.0547885 Test Loss: 0.0574554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550639\n",
      "\tspeed: 0.0535s/iter; left time: 829.3732s\n",
      "\titers: 200, epoch: 31 | loss: 0.0518903\n",
      "\tspeed: 0.0264s/iter; left time: 407.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0537086 Vali Loss: 0.0547136 Test Loss: 0.0574395\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559142\n",
      "\tspeed: 0.0537s/iter; left time: 820.9508s\n",
      "\titers: 200, epoch: 32 | loss: 0.0563869\n",
      "\tspeed: 0.0273s/iter; left time: 415.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0537152 Vali Loss: 0.0546903 Test Loss: 0.0574024\n",
      "Validation loss decreased (0.054712 --> 0.054690).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0501247\n",
      "\tspeed: 0.0517s/iter; left time: 779.3576s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544526\n",
      "\tspeed: 0.0277s/iter; left time: 413.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0536137 Vali Loss: 0.0547255 Test Loss: 0.0573914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0529143\n",
      "\tspeed: 0.0514s/iter; left time: 762.4844s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530024\n",
      "\tspeed: 0.0265s/iter; left time: 389.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0535995 Vali Loss: 0.0547244 Test Loss: 0.0574674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510959\n",
      "\tspeed: 0.0529s/iter; left time: 773.3129s\n",
      "\titers: 200, epoch: 35 | loss: 0.0544512\n",
      "\tspeed: 0.0266s/iter; left time: 385.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0535950 Vali Loss: 0.0546488 Test Loss: 0.0574228\n",
      "Validation loss decreased (0.054690 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0535187\n",
      "\tspeed: 0.0517s/iter; left time: 743.7813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0523912\n",
      "\tspeed: 0.0271s/iter; left time: 386.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0535439 Vali Loss: 0.0546921 Test Loss: 0.0573547\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519122\n",
      "\tspeed: 0.0512s/iter; left time: 726.0438s\n",
      "\titers: 200, epoch: 37 | loss: 0.0526450\n",
      "\tspeed: 0.0276s/iter; left time: 388.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535251 Vali Loss: 0.0546742 Test Loss: 0.0573575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0550824\n",
      "\tspeed: 0.0506s/iter; left time: 705.9884s\n",
      "\titers: 200, epoch: 38 | loss: 0.0517140\n",
      "\tspeed: 0.0267s/iter; left time: 370.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0535045 Vali Loss: 0.0546824 Test Loss: 0.0573583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0504631\n",
      "\tspeed: 0.0538s/iter; left time: 737.9139s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540452\n",
      "\tspeed: 0.0267s/iter; left time: 364.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0535086 Vali Loss: 0.0546178 Test Loss: 0.0573389\n",
      "Validation loss decreased (0.054649 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0553547\n",
      "\tspeed: 0.0533s/iter; left time: 719.5076s\n",
      "\titers: 200, epoch: 40 | loss: 0.0607494\n",
      "\tspeed: 0.0266s/iter; left time: 355.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0534950 Vali Loss: 0.0546346 Test Loss: 0.0573255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535479\n",
      "\tspeed: 0.0517s/iter; left time: 686.2660s\n",
      "\titers: 200, epoch: 41 | loss: 0.0538877\n",
      "\tspeed: 0.0283s/iter; left time: 373.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0534341 Vali Loss: 0.0546129 Test Loss: 0.0573383\n",
      "Validation loss decreased (0.054618 --> 0.054613).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0530539\n",
      "\tspeed: 0.0519s/iter; left time: 677.9868s\n",
      "\titers: 200, epoch: 42 | loss: 0.0503627\n",
      "\tspeed: 0.0266s/iter; left time: 344.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534945 Vali Loss: 0.0546511 Test Loss: 0.0573564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522355\n",
      "\tspeed: 0.0524s/iter; left time: 672.6512s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554015\n",
      "\tspeed: 0.0266s/iter; left time: 338.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0534944 Vali Loss: 0.0545573 Test Loss: 0.0572970\n",
      "Validation loss decreased (0.054613 --> 0.054557).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508118\n",
      "\tspeed: 0.0527s/iter; left time: 664.7909s\n",
      "\titers: 200, epoch: 44 | loss: 0.0487365\n",
      "\tspeed: 0.0265s/iter; left time: 331.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0534317 Vali Loss: 0.0546139 Test Loss: 0.0573201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0559016\n",
      "\tspeed: 0.0525s/iter; left time: 650.4442s\n",
      "\titers: 200, epoch: 45 | loss: 0.0545299\n",
      "\tspeed: 0.0274s/iter; left time: 336.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533953 Vali Loss: 0.0546057 Test Loss: 0.0572799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0540960\n",
      "\tspeed: 0.0502s/iter; left time: 611.0743s\n",
      "\titers: 200, epoch: 46 | loss: 0.0512552\n",
      "\tspeed: 0.0266s/iter; left time: 321.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533736 Vali Loss: 0.0546207 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0561732\n",
      "\tspeed: 0.0534s/iter; left time: 637.7349s\n",
      "\titers: 200, epoch: 47 | loss: 0.0581061\n",
      "\tspeed: 0.0267s/iter; left time: 316.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0533965 Vali Loss: 0.0546026 Test Loss: 0.0573136\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520449\n",
      "\tspeed: 0.0535s/iter; left time: 627.0966s\n",
      "\titers: 200, epoch: 48 | loss: 0.0524969\n",
      "\tspeed: 0.0268s/iter; left time: 311.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0534021 Vali Loss: 0.0545990 Test Loss: 0.0572868\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543634\n",
      "\tspeed: 0.0521s/iter; left time: 599.3406s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546120\n",
      "\tspeed: 0.0273s/iter; left time: 311.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533844 Vali Loss: 0.0545882 Test Loss: 0.0572972\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0534620\n",
      "\tspeed: 0.0506s/iter; left time: 570.4850s\n",
      "\titers: 200, epoch: 50 | loss: 0.0547533\n",
      "\tspeed: 0.0275s/iter; left time: 307.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0533451 Vali Loss: 0.0545814 Test Loss: 0.0573124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0546054\n",
      "\tspeed: 0.0523s/iter; left time: 578.0639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510880\n",
      "\tspeed: 0.0267s/iter; left time: 292.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533503 Vali Loss: 0.0546255 Test Loss: 0.0573027\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0514563\n",
      "\tspeed: 0.0527s/iter; left time: 570.8214s\n",
      "\titers: 200, epoch: 52 | loss: 0.0495366\n",
      "\tspeed: 0.0267s/iter; left time: 286.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0533897 Vali Loss: 0.0545539 Test Loss: 0.0572905\n",
      "Validation loss decreased (0.054557 --> 0.054554).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0526214\n",
      "\tspeed: 0.0521s/iter; left time: 552.3314s\n",
      "\titers: 200, epoch: 53 | loss: 0.0528501\n",
      "\tspeed: 0.0272s/iter; left time: 285.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533348 Vali Loss: 0.0545499 Test Loss: 0.0572744\n",
      "Validation loss decreased (0.054554 --> 0.054550).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0534821\n",
      "\tspeed: 0.0511s/iter; left time: 530.3323s\n",
      "\titers: 200, epoch: 54 | loss: 0.0502692\n",
      "\tspeed: 0.0278s/iter; left time: 286.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533270 Vali Loss: 0.0546059 Test Loss: 0.0572837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0566965\n",
      "\tspeed: 0.0525s/iter; left time: 533.3248s\n",
      "\titers: 200, epoch: 55 | loss: 0.0537091\n",
      "\tspeed: 0.0265s/iter; left time: 266.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0533742 Vali Loss: 0.0545576 Test Loss: 0.0572765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0570078\n",
      "\tspeed: 0.0548s/iter; left time: 544.3453s\n",
      "\titers: 200, epoch: 56 | loss: 0.0543868\n",
      "\tspeed: 0.0266s/iter; left time: 262.0291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533093 Vali Loss: 0.0545547 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0484664\n",
      "\tspeed: 0.0542s/iter; left time: 526.0091s\n",
      "\titers: 200, epoch: 57 | loss: 0.0509104\n",
      "\tspeed: 0.0266s/iter; left time: 255.6188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533533 Vali Loss: 0.0545238 Test Loss: 0.0572867\n",
      "Validation loss decreased (0.054550 --> 0.054524).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0565883\n",
      "\tspeed: 0.0532s/iter; left time: 505.2635s\n",
      "\titers: 200, epoch: 58 | loss: 0.0582136\n",
      "\tspeed: 0.0271s/iter; left time: 254.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533185 Vali Loss: 0.0546001 Test Loss: 0.0572918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0523805\n",
      "\tspeed: 0.0508s/iter; left time: 470.7098s\n",
      "\titers: 200, epoch: 59 | loss: 0.0535988\n",
      "\tspeed: 0.0265s/iter; left time: 242.7708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533365 Vali Loss: 0.0545593 Test Loss: 0.0572962\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0546732\n",
      "\tspeed: 0.0535s/iter; left time: 483.9101s\n",
      "\titers: 200, epoch: 60 | loss: 0.0520667\n",
      "\tspeed: 0.0265s/iter; left time: 237.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533063 Vali Loss: 0.0545351 Test Loss: 0.0572758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0580502\n",
      "\tspeed: 0.0526s/iter; left time: 464.3747s\n",
      "\titers: 200, epoch: 61 | loss: 0.0520758\n",
      "\tspeed: 0.0265s/iter; left time: 230.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0533507 Vali Loss: 0.0545636 Test Loss: 0.0572944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0565598\n",
      "\tspeed: 0.0535s/iter; left time: 460.1389s\n",
      "\titers: 200, epoch: 62 | loss: 0.0505943\n",
      "\tspeed: 0.0289s/iter; left time: 245.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0533690 Vali Loss: 0.0546163 Test Loss: 0.0573110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0569731\n",
      "\tspeed: 0.0512s/iter; left time: 428.7700s\n",
      "\titers: 200, epoch: 63 | loss: 0.0532570\n",
      "\tspeed: 0.0279s/iter; left time: 230.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0533448 Vali Loss: 0.0545721 Test Loss: 0.0572936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0568857\n",
      "\tspeed: 0.0515s/iter; left time: 419.9548s\n",
      "\titers: 200, epoch: 64 | loss: 0.0522906\n",
      "\tspeed: 0.0266s/iter; left time: 214.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0533268 Vali Loss: 0.0545559 Test Loss: 0.0572829\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0549613\n",
      "\tspeed: 0.0542s/iter; left time: 429.4227s\n",
      "\titers: 200, epoch: 65 | loss: 0.0547876\n",
      "\tspeed: 0.0264s/iter; left time: 206.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0533261 Vali Loss: 0.0546123 Test Loss: 0.0572819\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0571021\n",
      "\tspeed: 0.0533s/iter; left time: 410.3956s\n",
      "\titers: 200, epoch: 66 | loss: 0.0556666\n",
      "\tspeed: 0.0267s/iter; left time: 203.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0533458 Vali Loss: 0.0545249 Test Loss: 0.0572845\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0536378\n",
      "\tspeed: 0.0511s/iter; left time: 382.4235s\n",
      "\titers: 200, epoch: 67 | loss: 0.0556360\n",
      "\tspeed: 0.0278s/iter; left time: 205.4955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0533135 Vali Loss: 0.0545504 Test Loss: 0.0572871\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01012159138917923, rmse:0.10060612112283707, mae:0.057286690920591354, rse:0.3801409900188446\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248728\n",
      "\tspeed: 0.0282s/iter; left time: 626.4181s\n",
      "\titers: 200, epoch: 1 | loss: 0.1110343\n",
      "\tspeed: 0.0278s/iter; left time: 615.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1324539 Vali Loss: 0.0937511 Test Loss: 0.0949556\n",
      "Validation loss decreased (inf --> 0.093751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0720905\n",
      "\tspeed: 0.0539s/iter; left time: 1184.2051s\n",
      "\titers: 200, epoch: 2 | loss: 0.0645590\n",
      "\tspeed: 0.0274s/iter; left time: 599.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0755588 Vali Loss: 0.0620441 Test Loss: 0.0650663\n",
      "Validation loss decreased (0.093751 --> 0.062044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640341\n",
      "\tspeed: 0.0545s/iter; left time: 1186.3514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0612153\n",
      "\tspeed: 0.0269s/iter; left time: 582.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0647354 Vali Loss: 0.0599341 Test Loss: 0.0626789\n",
      "Validation loss decreased (0.062044 --> 0.059934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0636144\n",
      "\tspeed: 0.0552s/iter; left time: 1188.4956s\n",
      "\titers: 200, epoch: 4 | loss: 0.0610736\n",
      "\tspeed: 0.0266s/iter; left time: 569.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0622370 Vali Loss: 0.0586477 Test Loss: 0.0611086\n",
      "Validation loss decreased (0.059934 --> 0.058648).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597302\n",
      "\tspeed: 0.0525s/iter; left time: 1118.1597s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593400\n",
      "\tspeed: 0.0267s/iter; left time: 565.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0605518 Vali Loss: 0.0583430 Test Loss: 0.0606032\n",
      "Validation loss decreased (0.058648 --> 0.058343).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601675\n",
      "\tspeed: 0.0519s/iter; left time: 1094.6959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0591417\n",
      "\tspeed: 0.0276s/iter; left time: 580.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0595355 Vali Loss: 0.0577077 Test Loss: 0.0602866\n",
      "Validation loss decreased (0.058343 --> 0.057708).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0616218\n",
      "\tspeed: 0.0527s/iter; left time: 1100.1340s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583670\n",
      "\tspeed: 0.0267s/iter; left time: 554.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0587154 Vali Loss: 0.0572509 Test Loss: 0.0596006\n",
      "Validation loss decreased (0.057708 --> 0.057251).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568723\n",
      "\tspeed: 0.0575s/iter; left time: 1187.0474s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633062\n",
      "\tspeed: 0.0266s/iter; left time: 545.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0581127 Vali Loss: 0.0571833 Test Loss: 0.0592898\n",
      "Validation loss decreased (0.057251 --> 0.057183).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551414\n",
      "\tspeed: 0.0534s/iter; left time: 1090.9052s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602552\n",
      "\tspeed: 0.0265s/iter; left time: 538.2335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0575728 Vali Loss: 0.0565193 Test Loss: 0.0591429\n",
      "Validation loss decreased (0.057183 --> 0.056519).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0542222\n",
      "\tspeed: 0.0522s/iter; left time: 1053.9653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0603032\n",
      "\tspeed: 0.0276s/iter; left time: 554.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570322 Vali Loss: 0.0563715 Test Loss: 0.0591157\n",
      "Validation loss decreased (0.056519 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0570678\n",
      "\tspeed: 0.0515s/iter; left time: 1029.4251s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550144\n",
      "\tspeed: 0.0277s/iter; left time: 550.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0566705 Vali Loss: 0.0562801 Test Loss: 0.0587650\n",
      "Validation loss decreased (0.056372 --> 0.056280).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0574326\n",
      "\tspeed: 0.0526s/iter; left time: 1038.9030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546103\n",
      "\tspeed: 0.0268s/iter; left time: 527.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0563215 Vali Loss: 0.0561686 Test Loss: 0.0584310\n",
      "Validation loss decreased (0.056280 --> 0.056169).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0557495\n",
      "\tspeed: 0.0545s/iter; left time: 1063.4217s\n",
      "\titers: 200, epoch: 13 | loss: 0.0531652\n",
      "\tspeed: 0.0266s/iter; left time: 516.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0559293 Vali Loss: 0.0560087 Test Loss: 0.0585652\n",
      "Validation loss decreased (0.056169 --> 0.056009).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552769\n",
      "\tspeed: 0.0533s/iter; left time: 1029.0034s\n",
      "\titers: 200, epoch: 14 | loss: 0.0531435\n",
      "\tspeed: 0.0268s/iter; left time: 515.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0556957 Vali Loss: 0.0558831 Test Loss: 0.0582514\n",
      "Validation loss decreased (0.056009 --> 0.055883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521481\n",
      "\tspeed: 0.0524s/iter; left time: 999.6095s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553430\n",
      "\tspeed: 0.0283s/iter; left time: 536.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0555145 Vali Loss: 0.0557019 Test Loss: 0.0581627\n",
      "Validation loss decreased (0.055883 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609594\n",
      "\tspeed: 0.0527s/iter; left time: 993.4804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542896\n",
      "\tspeed: 0.0272s/iter; left time: 509.3344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0552573 Vali Loss: 0.0554980 Test Loss: 0.0579392\n",
      "Validation loss decreased (0.055702 --> 0.055498).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0568106\n",
      "\tspeed: 0.0542s/iter; left time: 1009.8471s\n",
      "\titers: 200, epoch: 17 | loss: 0.0526110\n",
      "\tspeed: 0.0264s/iter; left time: 489.3135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0551050 Vali Loss: 0.0555646 Test Loss: 0.0581667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543328\n",
      "\tspeed: 0.0534s/iter; left time: 982.9672s\n",
      "\titers: 200, epoch: 18 | loss: 0.0529872\n",
      "\tspeed: 0.0265s/iter; left time: 484.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0549972 Vali Loss: 0.0554904 Test Loss: 0.0578824\n",
      "Validation loss decreased (0.055498 --> 0.055490).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0561036\n",
      "\tspeed: 0.0511s/iter; left time: 929.3392s\n",
      "\titers: 200, epoch: 19 | loss: 0.0585789\n",
      "\tspeed: 0.0269s/iter; left time: 486.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0547228 Vali Loss: 0.0551855 Test Loss: 0.0576403\n",
      "Validation loss decreased (0.055490 --> 0.055185).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0551048\n",
      "\tspeed: 0.0535s/iter; left time: 961.2267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0540609\n",
      "\tspeed: 0.0283s/iter; left time: 505.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0546380 Vali Loss: 0.0555217 Test Loss: 0.0577946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0542702\n",
      "\tspeed: 0.0516s/iter; left time: 916.2719s\n",
      "\titers: 200, epoch: 21 | loss: 0.0512278\n",
      "\tspeed: 0.0263s/iter; left time: 464.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0545288 Vali Loss: 0.0553299 Test Loss: 0.0576920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0561697\n",
      "\tspeed: 0.0550s/iter; left time: 962.6244s\n",
      "\titers: 200, epoch: 22 | loss: 0.0527409\n",
      "\tspeed: 0.0268s/iter; left time: 466.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0544019 Vali Loss: 0.0552929 Test Loss: 0.0575224\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529760\n",
      "\tspeed: 0.0534s/iter; left time: 923.4529s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520137\n",
      "\tspeed: 0.0270s/iter; left time: 463.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0542588 Vali Loss: 0.0552379 Test Loss: 0.0575204\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0544704\n",
      "\tspeed: 0.0515s/iter; left time: 878.6230s\n",
      "\titers: 200, epoch: 24 | loss: 0.0581453\n",
      "\tspeed: 0.0287s/iter; left time: 486.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0542069 Vali Loss: 0.0551895 Test Loss: 0.0574684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0549121\n",
      "\tspeed: 0.0518s/iter; left time: 872.9043s\n",
      "\titers: 200, epoch: 25 | loss: 0.0512915\n",
      "\tspeed: 0.0269s/iter; left time: 450.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0541660 Vali Loss: 0.0550061 Test Loss: 0.0575668\n",
      "Validation loss decreased (0.055185 --> 0.055006).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0542531\n",
      "\tspeed: 0.0547s/iter; left time: 910.0617s\n",
      "\titers: 200, epoch: 26 | loss: 0.0534555\n",
      "\tspeed: 0.0271s/iter; left time: 447.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0540092 Vali Loss: 0.0549437 Test Loss: 0.0573728\n",
      "Validation loss decreased (0.055006 --> 0.054944).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0522741\n",
      "\tspeed: 0.0547s/iter; left time: 897.5644s\n",
      "\titers: 200, epoch: 27 | loss: 0.0540177\n",
      "\tspeed: 0.0269s/iter; left time: 438.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0539847 Vali Loss: 0.0550816 Test Loss: 0.0574916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0527179\n",
      "\tspeed: 0.0518s/iter; left time: 838.5554s\n",
      "\titers: 200, epoch: 28 | loss: 0.0534733\n",
      "\tspeed: 0.0276s/iter; left time: 443.3765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0539413 Vali Loss: 0.0550135 Test Loss: 0.0575341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0502411\n",
      "\tspeed: 0.0513s/iter; left time: 819.2275s\n",
      "\titers: 200, epoch: 29 | loss: 0.0528361\n",
      "\tspeed: 0.0275s/iter; left time: 435.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538017 Vali Loss: 0.0548889 Test Loss: 0.0573778\n",
      "Validation loss decreased (0.054944 --> 0.054889).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0518792\n",
      "\tspeed: 0.0524s/iter; left time: 824.7375s\n",
      "\titers: 200, epoch: 30 | loss: 0.0557014\n",
      "\tspeed: 0.0265s/iter; left time: 414.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0537871 Vali Loss: 0.0549768 Test Loss: 0.0574409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0499483\n",
      "\tspeed: 0.0546s/iter; left time: 847.1963s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548199\n",
      "\tspeed: 0.0265s/iter; left time: 408.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0537241 Vali Loss: 0.0548849 Test Loss: 0.0573524\n",
      "Validation loss decreased (0.054889 --> 0.054885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0519677\n",
      "\tspeed: 0.0530s/iter; left time: 809.8001s\n",
      "\titers: 200, epoch: 32 | loss: 0.0509725\n",
      "\tspeed: 0.0269s/iter; left time: 408.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0537428 Vali Loss: 0.0548889 Test Loss: 0.0573561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0516712\n",
      "\tspeed: 0.0519s/iter; left time: 781.2646s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521875\n",
      "\tspeed: 0.0286s/iter; left time: 428.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536519 Vali Loss: 0.0549251 Test Loss: 0.0573139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525791\n",
      "\tspeed: 0.0522s/iter; left time: 775.0032s\n",
      "\titers: 200, epoch: 34 | loss: 0.0539121\n",
      "\tspeed: 0.0266s/iter; left time: 392.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0536618 Vali Loss: 0.0548495 Test Loss: 0.0573276\n",
      "Validation loss decreased (0.054885 --> 0.054850).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548193\n",
      "\tspeed: 0.0559s/iter; left time: 817.7348s\n",
      "\titers: 200, epoch: 35 | loss: 0.0560694\n",
      "\tspeed: 0.0269s/iter; left time: 390.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0536223 Vali Loss: 0.0549313 Test Loss: 0.0573653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0531555\n",
      "\tspeed: 0.0537s/iter; left time: 772.3500s\n",
      "\titers: 200, epoch: 36 | loss: 0.0529074\n",
      "\tspeed: 0.0270s/iter; left time: 385.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0535724 Vali Loss: 0.0548796 Test Loss: 0.0573130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542191\n",
      "\tspeed: 0.0515s/iter; left time: 729.6216s\n",
      "\titers: 200, epoch: 37 | loss: 0.0521309\n",
      "\tspeed: 0.0284s/iter; left time: 399.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536354 Vali Loss: 0.0548213 Test Loss: 0.0573156\n",
      "Validation loss decreased (0.054850 --> 0.054821).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0513455\n",
      "\tspeed: 0.0514s/iter; left time: 716.9502s\n",
      "\titers: 200, epoch: 38 | loss: 0.0484909\n",
      "\tspeed: 0.0283s/iter; left time: 391.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0535302 Vali Loss: 0.0548031 Test Loss: 0.0572883\n",
      "Validation loss decreased (0.054821 --> 0.054803).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0567436\n",
      "\tspeed: 0.0533s/iter; left time: 731.9007s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543030\n",
      "\tspeed: 0.0268s/iter; left time: 364.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0535580 Vali Loss: 0.0548298 Test Loss: 0.0572565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0577767\n",
      "\tspeed: 0.0542s/iter; left time: 731.7697s\n",
      "\titers: 200, epoch: 40 | loss: 0.0489657\n",
      "\tspeed: 0.0265s/iter; left time: 355.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535311 Vali Loss: 0.0547384 Test Loss: 0.0572284\n",
      "Validation loss decreased (0.054803 --> 0.054738).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0492260\n",
      "\tspeed: 0.0523s/iter; left time: 695.0258s\n",
      "\titers: 200, epoch: 41 | loss: 0.0530771\n",
      "\tspeed: 0.0274s/iter; left time: 361.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0535195 Vali Loss: 0.0547555 Test Loss: 0.0572335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536120\n",
      "\tspeed: 0.0524s/iter; left time: 683.8322s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539439\n",
      "\tspeed: 0.0290s/iter; left time: 375.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0535063 Vali Loss: 0.0547998 Test Loss: 0.0572487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0516886\n",
      "\tspeed: 0.0513s/iter; left time: 659.0389s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514923\n",
      "\tspeed: 0.0263s/iter; left time: 335.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0534249 Vali Loss: 0.0548376 Test Loss: 0.0572255\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0577250\n",
      "\tspeed: 0.0549s/iter; left time: 692.4608s\n",
      "\titers: 200, epoch: 44 | loss: 0.0516380\n",
      "\tspeed: 0.0269s/iter; left time: 336.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0534548 Vali Loss: 0.0547533 Test Loss: 0.0572155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551903\n",
      "\tspeed: 0.0531s/iter; left time: 657.8252s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587276\n",
      "\tspeed: 0.0268s/iter; left time: 329.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0534890 Vali Loss: 0.0547240 Test Loss: 0.0572646\n",
      "Validation loss decreased (0.054738 --> 0.054724).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0569799\n",
      "\tspeed: 0.0520s/iter; left time: 632.1113s\n",
      "\titers: 200, epoch: 46 | loss: 0.0528706\n",
      "\tspeed: 0.0281s/iter; left time: 339.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0534028 Vali Loss: 0.0548343 Test Loss: 0.0572270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0535365\n",
      "\tspeed: 0.0521s/iter; left time: 622.7815s\n",
      "\titers: 200, epoch: 47 | loss: 0.0522014\n",
      "\tspeed: 0.0276s/iter; left time: 327.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0534371 Vali Loss: 0.0548092 Test Loss: 0.0572257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0540526\n",
      "\tspeed: 0.0528s/iter; left time: 618.2454s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521358\n",
      "\tspeed: 0.0267s/iter; left time: 309.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534032 Vali Loss: 0.0547515 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0514734\n",
      "\tspeed: 0.0548s/iter; left time: 630.1869s\n",
      "\titers: 200, epoch: 49 | loss: 0.0515570\n",
      "\tspeed: 0.0268s/iter; left time: 305.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0533995 Vali Loss: 0.0547729 Test Loss: 0.0572376\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0553200\n",
      "\tspeed: 0.0539s/iter; left time: 607.7663s\n",
      "\titers: 200, epoch: 50 | loss: 0.0507628\n",
      "\tspeed: 0.0283s/iter; left time: 316.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0534180 Vali Loss: 0.0548830 Test Loss: 0.0572152\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0522079\n",
      "\tspeed: 0.0516s/iter; left time: 570.3257s\n",
      "\titers: 200, epoch: 51 | loss: 0.0526080\n",
      "\tspeed: 0.0291s/iter; left time: 319.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0533703 Vali Loss: 0.0547865 Test Loss: 0.0572359\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0549524\n",
      "\tspeed: 0.0527s/iter; left time: 570.7138s\n",
      "\titers: 200, epoch: 52 | loss: 0.0532417\n",
      "\tspeed: 0.0268s/iter; left time: 287.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0534304 Vali Loss: 0.0547305 Test Loss: 0.0572217\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0537086\n",
      "\tspeed: 0.0548s/iter; left time: 580.8395s\n",
      "\titers: 200, epoch: 53 | loss: 0.0529253\n",
      "\tspeed: 0.0266s/iter; left time: 279.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0533663 Vali Loss: 0.0548078 Test Loss: 0.0572288\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0523412\n",
      "\tspeed: 0.0540s/iter; left time: 560.4656s\n",
      "\titers: 200, epoch: 54 | loss: 0.0549152\n",
      "\tspeed: 0.0271s/iter; left time: 278.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 223 | Train Loss: 0.0533426 Vali Loss: 0.0547861 Test Loss: 0.0572313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0475683\n",
      "\tspeed: 0.0546s/iter; left time: 554.5516s\n",
      "\titers: 200, epoch: 55 | loss: 0.0524945\n",
      "\tspeed: 0.0275s/iter; left time: 276.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0534049 Vali Loss: 0.0548184 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083268396556377, rmse:0.10041547566652298, mae:0.05726462975144386, rse:0.3794206380844116\n",
      "Intermediate time for IT and pred_len 24: 00h:16m:28.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1321838\n",
      "\tspeed: 0.0528s/iter; left time: 1166.6778s\n",
      "\titers: 200, epoch: 1 | loss: 0.1144970\n",
      "\tspeed: 0.0271s/iter; left time: 597.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1387064 Vali Loss: 0.1032817 Test Loss: 0.1052682\n",
      "Validation loss decreased (inf --> 0.103282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853616\n",
      "\tspeed: 0.0561s/iter; left time: 1228.0293s\n",
      "\titers: 200, epoch: 2 | loss: 0.0828326\n",
      "\tspeed: 0.0272s/iter; left time: 592.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932694 Vali Loss: 0.0822700 Test Loss: 0.0855554\n",
      "Validation loss decreased (0.103282 --> 0.082270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840157\n",
      "\tspeed: 0.0575s/iter; left time: 1245.1145s\n",
      "\titers: 200, epoch: 3 | loss: 0.0772976\n",
      "\tspeed: 0.0294s/iter; left time: 633.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0837174 Vali Loss: 0.0802281 Test Loss: 0.0841231\n",
      "Validation loss decreased (0.082270 --> 0.080228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776535\n",
      "\tspeed: 0.0538s/iter; left time: 1152.2520s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804181\n",
      "\tspeed: 0.0279s/iter; left time: 595.0900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0811037 Vali Loss: 0.0788419 Test Loss: 0.0832654\n",
      "Validation loss decreased (0.080228 --> 0.078842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817597\n",
      "\tspeed: 0.0555s/iter; left time: 1177.6018s\n",
      "\titers: 200, epoch: 5 | loss: 0.0780218\n",
      "\tspeed: 0.0272s/iter; left time: 573.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0794239 Vali Loss: 0.0786723 Test Loss: 0.0830877\n",
      "Validation loss decreased (0.078842 --> 0.078672).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774737\n",
      "\tspeed: 0.0564s/iter; left time: 1183.8263s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789120\n",
      "\tspeed: 0.0275s/iter; left time: 574.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0783094 Vali Loss: 0.0786543 Test Loss: 0.0826141\n",
      "Validation loss decreased (0.078672 --> 0.078654).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756353\n",
      "\tspeed: 0.0550s/iter; left time: 1142.9273s\n",
      "\titers: 200, epoch: 7 | loss: 0.0770764\n",
      "\tspeed: 0.0279s/iter; left time: 577.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0773383 Vali Loss: 0.0779212 Test Loss: 0.0822634\n",
      "Validation loss decreased (0.078654 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771187\n",
      "\tspeed: 0.0532s/iter; left time: 1092.8138s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760235\n",
      "\tspeed: 0.0281s/iter; left time: 574.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0764953 Vali Loss: 0.0783359 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729671\n",
      "\tspeed: 0.0537s/iter; left time: 1091.8457s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753743\n",
      "\tspeed: 0.0275s/iter; left time: 555.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0758295 Vali Loss: 0.0776675 Test Loss: 0.0825013\n",
      "Validation loss decreased (0.077921 --> 0.077668).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0795718\n",
      "\tspeed: 0.0567s/iter; left time: 1138.8475s\n",
      "\titers: 200, epoch: 10 | loss: 0.0746166\n",
      "\tspeed: 0.0272s/iter; left time: 543.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0753310 Vali Loss: 0.0781949 Test Loss: 0.0824108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762351\n",
      "\tspeed: 0.0550s/iter; left time: 1093.5082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735926\n",
      "\tspeed: 0.0272s/iter; left time: 537.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0748693 Vali Loss: 0.0781084 Test Loss: 0.0827782\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725338\n",
      "\tspeed: 0.0526s/iter; left time: 1033.7681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0750147\n",
      "\tspeed: 0.0284s/iter; left time: 555.6160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0743695 Vali Loss: 0.0778181 Test Loss: 0.0824795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0748884\n",
      "\tspeed: 0.0529s/iter; left time: 1028.8589s\n",
      "\titers: 200, epoch: 13 | loss: 0.0768396\n",
      "\tspeed: 0.0279s/iter; left time: 539.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0740004 Vali Loss: 0.0777673 Test Loss: 0.0825389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0698381\n",
      "\tspeed: 0.0549s/iter; left time: 1055.0927s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717925\n",
      "\tspeed: 0.0269s/iter; left time: 513.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0736021 Vali Loss: 0.0778859 Test Loss: 0.0826246\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0710938\n",
      "\tspeed: 0.0559s/iter; left time: 1062.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687255\n",
      "\tspeed: 0.0270s/iter; left time: 510.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0732304 Vali Loss: 0.0778723 Test Loss: 0.0830562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0749232\n",
      "\tspeed: 0.0533s/iter; left time: 1000.4663s\n",
      "\titers: 200, epoch: 16 | loss: 0.0746401\n",
      "\tspeed: 0.0276s/iter; left time: 516.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0729620 Vali Loss: 0.0777781 Test Loss: 0.0827808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733482\n",
      "\tspeed: 0.0528s/iter; left time: 979.8157s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715483\n",
      "\tspeed: 0.0288s/iter; left time: 531.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0726490 Vali Loss: 0.0779078 Test Loss: 0.0832266\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739253\n",
      "\tspeed: 0.0536s/iter; left time: 981.6920s\n",
      "\titers: 200, epoch: 18 | loss: 0.0751582\n",
      "\tspeed: 0.0272s/iter; left time: 495.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0724323 Vali Loss: 0.0774746 Test Loss: 0.0825534\n",
      "Validation loss decreased (0.077668 --> 0.077475).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730057\n",
      "\tspeed: 0.0590s/iter; left time: 1068.9870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744534\n",
      "\tspeed: 0.0269s/iter; left time: 484.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0721436 Vali Loss: 0.0777745 Test Loss: 0.0828253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0702813\n",
      "\tspeed: 0.0554s/iter; left time: 989.9029s\n",
      "\titers: 200, epoch: 20 | loss: 0.0714406\n",
      "\tspeed: 0.0274s/iter; left time: 486.6499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0719519 Vali Loss: 0.0777934 Test Loss: 0.0831720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752490\n",
      "\tspeed: 0.0530s/iter; left time: 936.4262s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729214\n",
      "\tspeed: 0.0297s/iter; left time: 522.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0717573 Vali Loss: 0.0775301 Test Loss: 0.0829119\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0729312\n",
      "\tspeed: 0.0534s/iter; left time: 930.4178s\n",
      "\titers: 200, epoch: 22 | loss: 0.0712821\n",
      "\tspeed: 0.0279s/iter; left time: 483.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0716219 Vali Loss: 0.0775715 Test Loss: 0.0831647\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0745800\n",
      "\tspeed: 0.0545s/iter; left time: 939.0949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0710693\n",
      "\tspeed: 0.0268s/iter; left time: 458.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0714176 Vali Loss: 0.0774375 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.077475 --> 0.077438).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0726332\n",
      "\tspeed: 0.0550s/iter; left time: 934.8110s\n",
      "\titers: 200, epoch: 24 | loss: 0.0703410\n",
      "\tspeed: 0.0270s/iter; left time: 455.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0712783 Vali Loss: 0.0776950 Test Loss: 0.0831947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0688102\n",
      "\tspeed: 0.0542s/iter; left time: 908.8879s\n",
      "\titers: 200, epoch: 25 | loss: 0.0745878\n",
      "\tspeed: 0.0288s/iter; left time: 480.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0710946 Vali Loss: 0.0775712 Test Loss: 0.0831804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0722734\n",
      "\tspeed: 0.0529s/iter; left time: 874.8612s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690523\n",
      "\tspeed: 0.0284s/iter; left time: 467.9860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0710367 Vali Loss: 0.0774692 Test Loss: 0.0832843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0757137\n",
      "\tspeed: 0.0539s/iter; left time: 880.8381s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672927\n",
      "\tspeed: 0.0275s/iter; left time: 445.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0709873 Vali Loss: 0.0775369 Test Loss: 0.0832190\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734061\n",
      "\tspeed: 0.0564s/iter; left time: 908.3009s\n",
      "\titers: 200, epoch: 28 | loss: 0.0689125\n",
      "\tspeed: 0.0269s/iter; left time: 430.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0708438 Vali Loss: 0.0776351 Test Loss: 0.0832205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0706797\n",
      "\tspeed: 0.0549s/iter; left time: 871.6611s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731136\n",
      "\tspeed: 0.0278s/iter; left time: 439.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0707727 Vali Loss: 0.0773896 Test Loss: 0.0832303\n",
      "Validation loss decreased (0.077438 --> 0.077390).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0717404\n",
      "\tspeed: 0.0534s/iter; left time: 835.9623s\n",
      "\titers: 200, epoch: 30 | loss: 0.0729116\n",
      "\tspeed: 0.0290s/iter; left time: 451.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0706910 Vali Loss: 0.0774434 Test Loss: 0.0832887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0757121\n",
      "\tspeed: 0.0534s/iter; left time: 825.1587s\n",
      "\titers: 200, epoch: 31 | loss: 0.0711617\n",
      "\tspeed: 0.0271s/iter; left time: 415.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0706033 Vali Loss: 0.0776396 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712611\n",
      "\tspeed: 0.0575s/iter; left time: 874.6293s\n",
      "\titers: 200, epoch: 32 | loss: 0.0727751\n",
      "\tspeed: 0.0272s/iter; left time: 411.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0705892 Vali Loss: 0.0775814 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0709131\n",
      "\tspeed: 0.0545s/iter; left time: 817.8930s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718555\n",
      "\tspeed: 0.0271s/iter; left time: 403.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0705573 Vali Loss: 0.0772810 Test Loss: 0.0833159\n",
      "Validation loss decreased (0.077390 --> 0.077281).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0690060\n",
      "\tspeed: 0.0518s/iter; left time: 765.6173s\n",
      "\titers: 200, epoch: 34 | loss: 0.0711988\n",
      "\tspeed: 0.0280s/iter; left time: 410.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0705202 Vali Loss: 0.0774535 Test Loss: 0.0832982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732094\n",
      "\tspeed: 0.0534s/iter; left time: 776.4035s\n",
      "\titers: 200, epoch: 35 | loss: 0.0739846\n",
      "\tspeed: 0.0278s/iter; left time: 401.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0704378 Vali Loss: 0.0774655 Test Loss: 0.0832758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0734195\n",
      "\tspeed: 0.0536s/iter; left time: 768.0877s\n",
      "\titers: 200, epoch: 36 | loss: 0.0688326\n",
      "\tspeed: 0.0276s/iter; left time: 393.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0703314 Vali Loss: 0.0775375 Test Loss: 0.0834405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0667930\n",
      "\tspeed: 0.0559s/iter; left time: 788.8954s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698663\n",
      "\tspeed: 0.0271s/iter; left time: 379.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0703407 Vali Loss: 0.0774669 Test Loss: 0.0833736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0679398\n",
      "\tspeed: 0.0555s/iter; left time: 771.3706s\n",
      "\titers: 200, epoch: 38 | loss: 0.0724612\n",
      "\tspeed: 0.0274s/iter; left time: 377.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0703553 Vali Loss: 0.0775958 Test Loss: 0.0833337\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0718481\n",
      "\tspeed: 0.0526s/iter; left time: 718.1055s\n",
      "\titers: 200, epoch: 39 | loss: 0.0735828\n",
      "\tspeed: 0.0286s/iter; left time: 388.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702385 Vali Loss: 0.0774214 Test Loss: 0.0832950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0657273\n",
      "\tspeed: 0.0537s/iter; left time: 722.4613s\n",
      "\titers: 200, epoch: 40 | loss: 0.0679445\n",
      "\tspeed: 0.0268s/iter; left time: 357.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0702638 Vali Loss: 0.0775013 Test Loss: 0.0834430\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673170\n",
      "\tspeed: 0.0568s/iter; left time: 750.9906s\n",
      "\titers: 200, epoch: 41 | loss: 0.0687927\n",
      "\tspeed: 0.0269s/iter; left time: 352.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0702658 Vali Loss: 0.0773642 Test Loss: 0.0834067\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0763263\n",
      "\tspeed: 0.0575s/iter; left time: 746.9921s\n",
      "\titers: 200, epoch: 42 | loss: 0.0653355\n",
      "\tspeed: 0.0279s/iter; left time: 359.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0701891 Vali Loss: 0.0775082 Test Loss: 0.0834283\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0718496\n",
      "\tspeed: 0.0548s/iter; left time: 700.0664s\n",
      "\titers: 200, epoch: 43 | loss: 0.0727848\n",
      "\tspeed: 0.0281s/iter; left time: 355.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702348 Vali Loss: 0.0775226 Test Loss: 0.0834311\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019748352468013763, rmse:0.1405288279056549, mae:0.0833158940076828, rse:0.5313546657562256\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1307300\n",
      "\tspeed: 0.0299s/iter; left time: 661.4012s\n",
      "\titers: 200, epoch: 1 | loss: 0.1169153\n",
      "\tspeed: 0.0295s/iter; left time: 649.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.1395382 Vali Loss: 0.1032388 Test Loss: 0.1049907\n",
      "Validation loss decreased (inf --> 0.103239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0917928\n",
      "\tspeed: 0.0557s/iter; left time: 1217.6038s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827175\n",
      "\tspeed: 0.0287s/iter; left time: 624.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932693 Vali Loss: 0.0824907 Test Loss: 0.0859276\n",
      "Validation loss decreased (0.103239 --> 0.082491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872422\n",
      "\tspeed: 0.0548s/iter; left time: 1186.2276s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782116\n",
      "\tspeed: 0.0270s/iter; left time: 582.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0836970 Vali Loss: 0.0801819 Test Loss: 0.0838659\n",
      "Validation loss decreased (0.082491 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816273\n",
      "\tspeed: 0.0592s/iter; left time: 1268.5184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826085\n",
      "\tspeed: 0.0267s/iter; left time: 569.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0810833 Vali Loss: 0.0788540 Test Loss: 0.0829947\n",
      "Validation loss decreased (0.080182 --> 0.078854).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0761694\n",
      "\tspeed: 0.0566s/iter; left time: 1201.0110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798683\n",
      "\tspeed: 0.0270s/iter; left time: 569.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0795185 Vali Loss: 0.0781875 Test Loss: 0.0825942\n",
      "Validation loss decreased (0.078854 --> 0.078187).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777261\n",
      "\tspeed: 0.0551s/iter; left time: 1156.6782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0814498\n",
      "\tspeed: 0.0286s/iter; left time: 598.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0783964 Vali Loss: 0.0775421 Test Loss: 0.0821851\n",
      "Validation loss decreased (0.078187 --> 0.077542).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739338\n",
      "\tspeed: 0.0550s/iter; left time: 1142.5101s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811702\n",
      "\tspeed: 0.0280s/iter; left time: 578.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0774509 Vali Loss: 0.0783391 Test Loss: 0.0824711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753421\n",
      "\tspeed: 0.0553s/iter; left time: 1136.8596s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756552\n",
      "\tspeed: 0.0269s/iter; left time: 550.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0767014 Vali Loss: 0.0771883 Test Loss: 0.0820175\n",
      "Validation loss decreased (0.077542 --> 0.077188).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738878\n",
      "\tspeed: 0.0593s/iter; left time: 1204.7930s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749177\n",
      "\tspeed: 0.0268s/iter; left time: 542.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0760252 Vali Loss: 0.0781950 Test Loss: 0.0820919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0755344\n",
      "\tspeed: 0.0569s/iter; left time: 1143.6002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751255\n",
      "\tspeed: 0.0270s/iter; left time: 539.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0755306 Vali Loss: 0.0778631 Test Loss: 0.0822712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782155\n",
      "\tspeed: 0.0549s/iter; left time: 1091.8220s\n",
      "\titers: 200, epoch: 11 | loss: 0.0755833\n",
      "\tspeed: 0.0290s/iter; left time: 573.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0749816 Vali Loss: 0.0776737 Test Loss: 0.0817804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0693621\n",
      "\tspeed: 0.0548s/iter; left time: 1077.9669s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719745\n",
      "\tspeed: 0.0273s/iter; left time: 533.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0745667 Vali Loss: 0.0779224 Test Loss: 0.0818569\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0694613\n",
      "\tspeed: 0.0573s/iter; left time: 1113.5811s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725119\n",
      "\tspeed: 0.0269s/iter; left time: 521.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0740950 Vali Loss: 0.0777880 Test Loss: 0.0819785\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0775695\n",
      "\tspeed: 0.0581s/iter; left time: 1115.6870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0681774\n",
      "\tspeed: 0.0270s/iter; left time: 516.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0736995 Vali Loss: 0.0773107 Test Loss: 0.0820360\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733372\n",
      "\tspeed: 0.0569s/iter; left time: 1081.2037s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732900\n",
      "\tspeed: 0.0273s/iter; left time: 516.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0734037 Vali Loss: 0.0772424 Test Loss: 0.0821582\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713919\n",
      "\tspeed: 0.0549s/iter; left time: 1030.8488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0709377\n",
      "\tspeed: 0.0313s/iter; left time: 583.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0731161 Vali Loss: 0.0773405 Test Loss: 0.0820549\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754753\n",
      "\tspeed: 0.0540s/iter; left time: 1001.8352s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705882\n",
      "\tspeed: 0.0272s/iter; left time: 501.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0728018 Vali Loss: 0.0775164 Test Loss: 0.0821095\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0719491\n",
      "\tspeed: 0.0591s/iter; left time: 1083.3750s\n",
      "\titers: 200, epoch: 18 | loss: 0.0699536\n",
      "\tspeed: 0.0275s/iter; left time: 500.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0726074 Vali Loss: 0.0776926 Test Loss: 0.0821289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01836535520851612, rmse:0.13551883399486542, mae:0.08201750367879868, rse:0.51241135597229\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:37.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1298100\n",
      "\tspeed: 0.0534s/iter; left time: 1180.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.1176691\n",
      "\tspeed: 0.0292s/iter; left time: 643.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.1401385 Vali Loss: 0.1051041 Test Loss: 0.1060515\n",
      "Validation loss decreased (inf --> 0.105104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0925689\n",
      "\tspeed: 0.0530s/iter; left time: 1158.9939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0874640\n",
      "\tspeed: 0.0274s/iter; left time: 597.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0966582 Vali Loss: 0.0868458 Test Loss: 0.0894829\n",
      "Validation loss decreased (0.105104 --> 0.086846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0902038\n",
      "\tspeed: 0.0607s/iter; left time: 1313.8809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0879562\n",
      "\tspeed: 0.0273s/iter; left time: 588.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0874138 Vali Loss: 0.0842694 Test Loss: 0.0879542\n",
      "Validation loss decreased (0.086846 --> 0.084269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857633\n",
      "\tspeed: 0.0538s/iter; left time: 1153.1748s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834477\n",
      "\tspeed: 0.0272s/iter; left time: 580.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0846647 Vali Loss: 0.0835778 Test Loss: 0.0880411\n",
      "Validation loss decreased (0.084269 --> 0.083578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838752\n",
      "\tspeed: 0.0540s/iter; left time: 1144.7333s\n",
      "\titers: 200, epoch: 5 | loss: 0.0841271\n",
      "\tspeed: 0.0300s/iter; left time: 632.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0829673 Vali Loss: 0.0838262 Test Loss: 0.0883332\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0792901\n",
      "\tspeed: 0.0527s/iter; left time: 1106.0900s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827553\n",
      "\tspeed: 0.0281s/iter; left time: 587.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0816290 Vali Loss: 0.0842234 Test Loss: 0.0882273\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829263\n",
      "\tspeed: 0.0550s/iter; left time: 1142.8870s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831176\n",
      "\tspeed: 0.0273s/iter; left time: 563.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0805962 Vali Loss: 0.0847038 Test Loss: 0.0883791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816610\n",
      "\tspeed: 0.0575s/iter; left time: 1181.3405s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787463\n",
      "\tspeed: 0.0276s/iter; left time: 564.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0797245 Vali Loss: 0.0845396 Test Loss: 0.0883748\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766695\n",
      "\tspeed: 0.0528s/iter; left time: 1073.0838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811797\n",
      "\tspeed: 0.0309s/iter; left time: 625.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0790013 Vali Loss: 0.0842658 Test Loss: 0.0882581\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0773436\n",
      "\tspeed: 0.0541s/iter; left time: 1086.6544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0750153\n",
      "\tspeed: 0.0282s/iter; left time: 563.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0784806 Vali Loss: 0.0848489 Test Loss: 0.0890048\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781072\n",
      "\tspeed: 0.0543s/iter; left time: 1079.4039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776325\n",
      "\tspeed: 0.0273s/iter; left time: 540.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0778847 Vali Loss: 0.0847653 Test Loss: 0.0893754\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0796271\n",
      "\tspeed: 0.0551s/iter; left time: 1082.2326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788494\n",
      "\tspeed: 0.0272s/iter; left time: 532.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0774273 Vali Loss: 0.0847762 Test Loss: 0.0897269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719526\n",
      "\tspeed: 0.0518s/iter; left time: 1006.1097s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759829\n",
      "\tspeed: 0.0291s/iter; left time: 562.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0770110 Vali Loss: 0.0850721 Test Loss: 0.0895426\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745691\n",
      "\tspeed: 0.0531s/iter; left time: 1020.3689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722817\n",
      "\tspeed: 0.0281s/iter; left time: 537.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0765886 Vali Loss: 0.0847122 Test Loss: 0.0897249\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0201936773955822, rmse:0.14210446178913116, mae:0.08804111182689667, rse:0.5378115773200989\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1329002\n",
      "\tspeed: 0.0291s/iter; left time: 642.7910s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175623\n",
      "\tspeed: 0.0281s/iter; left time: 619.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1417617 Vali Loss: 0.1047845 Test Loss: 0.1055077\n",
      "Validation loss decreased (inf --> 0.104784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0927295\n",
      "\tspeed: 0.0578s/iter; left time: 1264.0138s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941170\n",
      "\tspeed: 0.0277s/iter; left time: 604.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0963996 Vali Loss: 0.0871643 Test Loss: 0.0895704\n",
      "Validation loss decreased (0.104784 --> 0.087164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878410\n",
      "\tspeed: 0.0590s/iter; left time: 1278.2876s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902920\n",
      "\tspeed: 0.0280s/iter; left time: 603.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0870747 Vali Loss: 0.0847243 Test Loss: 0.0878319\n",
      "Validation loss decreased (0.087164 --> 0.084724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853640\n",
      "\tspeed: 0.0566s/iter; left time: 1213.5422s\n",
      "\titers: 200, epoch: 4 | loss: 0.0840227\n",
      "\tspeed: 0.0282s/iter; left time: 601.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0846555 Vali Loss: 0.0835151 Test Loss: 0.0876056\n",
      "Validation loss decreased (0.084724 --> 0.083515).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0851938\n",
      "\tspeed: 0.0580s/iter; left time: 1229.8414s\n",
      "\titers: 200, epoch: 5 | loss: 0.0813548\n",
      "\tspeed: 0.0306s/iter; left time: 645.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0830201 Vali Loss: 0.0840696 Test Loss: 0.0879182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0852846\n",
      "\tspeed: 0.0531s/iter; left time: 1114.5854s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810560\n",
      "\tspeed: 0.0272s/iter; left time: 567.2324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0818896 Vali Loss: 0.0842003 Test Loss: 0.0879094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0802038\n",
      "\tspeed: 0.0572s/iter; left time: 1187.9462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809201\n",
      "\tspeed: 0.0271s/iter; left time: 559.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0808258 Vali Loss: 0.0832934 Test Loss: 0.0873938\n",
      "Validation loss decreased (0.083515 --> 0.083293).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792483\n",
      "\tspeed: 0.0624s/iter; left time: 1281.8376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819951\n",
      "\tspeed: 0.0279s/iter; left time: 570.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 222 | Train Loss: 0.0800518 Vali Loss: 0.0839962 Test Loss: 0.0880267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774117\n",
      "\tspeed: 0.0541s/iter; left time: 1098.8363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0775325\n",
      "\tspeed: 0.0285s/iter; left time: 576.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0793224 Vali Loss: 0.0844191 Test Loss: 0.0877155\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0806580\n",
      "\tspeed: 0.0556s/iter; left time: 1116.7889s\n",
      "\titers: 200, epoch: 10 | loss: 0.0799583\n",
      "\tspeed: 0.0277s/iter; left time: 555.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0787225 Vali Loss: 0.0840966 Test Loss: 0.0883957\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771481\n",
      "\tspeed: 0.0573s/iter; left time: 1138.9736s\n",
      "\titers: 200, epoch: 11 | loss: 0.0804428\n",
      "\tspeed: 0.0278s/iter; left time: 549.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0780882 Vali Loss: 0.0844000 Test Loss: 0.0881920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0766762\n",
      "\tspeed: 0.0586s/iter; left time: 1151.7988s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793117\n",
      "\tspeed: 0.0274s/iter; left time: 535.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0776378 Vali Loss: 0.0840316 Test Loss: 0.0880184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769361\n",
      "\tspeed: 0.0577s/iter; left time: 1121.7394s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785047\n",
      "\tspeed: 0.0276s/iter; left time: 532.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0771586 Vali Loss: 0.0841548 Test Loss: 0.0880232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0777556\n",
      "\tspeed: 0.0529s/iter; left time: 1017.3781s\n",
      "\titers: 200, epoch: 14 | loss: 0.0767437\n",
      "\tspeed: 0.0300s/iter; left time: 573.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0767452 Vali Loss: 0.0836313 Test Loss: 0.0883247\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787518\n",
      "\tspeed: 0.0534s/iter; left time: 1014.7503s\n",
      "\titers: 200, epoch: 15 | loss: 0.0794870\n",
      "\tspeed: 0.0274s/iter; left time: 518.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0763562 Vali Loss: 0.0837894 Test Loss: 0.0880314\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0768457\n",
      "\tspeed: 0.0613s/iter; left time: 1150.8829s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772194\n",
      "\tspeed: 0.0280s/iter; left time: 523.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0760031 Vali Loss: 0.0840183 Test Loss: 0.0883679\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0778723\n",
      "\tspeed: 0.0571s/iter; left time: 1058.7481s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730445\n",
      "\tspeed: 0.0282s/iter; left time: 519.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0756556 Vali Loss: 0.0837157 Test Loss: 0.0881411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020205043256282806, rmse:0.14214444160461426, mae:0.08739381283521652, rse:0.5379629135131836\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:33.10s\n",
      "Intermediate time for IT: 00h:29m:38.75s\n",
      "Total time: 02h:35m:30.27s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.0827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1450  0.0880\n",
       "        96            0.0359  0.1894  0.1250\n",
       "        168           0.0388  0.1968  0.1327\n",
       "ES      24            0.0099  0.0993  0.0597\n",
       "        96            0.0190  0.1377  0.0879\n",
       "        168           0.0213  0.1460  0.0952\n",
       "FR      24            0.0100  0.1002  0.0552\n",
       "        96            0.0197  0.1405  0.0811\n",
       "        168           0.0222  0.1490  0.0876\n",
       "GB      24            0.0246  0.1570  0.0990\n",
       "        96            0.0411  0.2027  0.1390\n",
       "        168           0.0435  0.2085  0.1449\n",
       "IT      24            0.0101  0.1005  0.0573\n",
       "        96            0.0191  0.1380  0.0827\n",
       "        168           0.0202  0.1421  0.0877"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
