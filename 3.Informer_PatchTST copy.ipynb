{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 336](#3-patchtst-336)\n",
    "- [4. PatchTST 512](#4-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with seq_len = 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['IT']\n",
    "num_cols = [3]\n",
    "seq_len = 168\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE 24\n",
    "Scaled mse:0.025699591264128685, rmse:0.16031092405319214, mae:0.10348266363143921, rse:0.5661423206329346\n",
    "Scaled mse:0.023365361616015434, rmse:0.15285731852054596, mae:0.10056539624929428, rse:0.5398197770118713\n",
    "\n",
    "DE 96\n",
    "Scaled mse:0.04860777407884598, rmse:0.22047170996665955, mae:0.14964795112609863, rse:0.7807348966598511\n",
    "Scaled mse:0.05066155269742012, rmse:0.22508122026920319, mae:0.1532352715730667, rse:0.79705810546875\n",
    "\n",
    "DE 168\n",
    "Scaled mse:0.054843734949827194, rmse:0.23418739438056946, mae:0.15871629118919373, rse:0.8296554088592529\n",
    "Scaled mse:0.05288044735789299, rmse:0.2299574911594391, mae:0.15663425624370575, rse:0.814670205116272\n",
    "\n",
    "GB 24\n",
    "Scaled mse:0.046120475977659225, rmse:0.2147567868232727, mae:0.1404818892478943, rse:0.7404764294624329\n",
    "Scaled mse:0.039505913853645325, rmse:0.19876094162464142, mae:0.13264088332653046, rse:0.6853231191635132\n",
    "\n",
    "GB 96\n",
    "Scaled mse:0.05855736881494522, rmse:0.24198630452156067, mae:0.16477428376674652, rse:0.8368223309516907\n",
    "Scaled mse:0.05540859326720238, rmse:0.235390305519104, mae:0.16324692964553833, rse:0.8140124678611755\n",
    "\n",
    "GB 168\n",
    "Scaled mse:0.06292843818664551, rmse:0.250855416059494, mae:0.17068493366241455, rse:0.8696832656860352\n",
    "Scaled mse:0.06641010195016861, rmse:0.257701575756073, mae:0.177326962351799, rse:0.8934180736541748\n",
    "\n",
    "ES 24\n",
    "Scaled mse:0.027730144560337067, rmse:0.16652370989322662, mae:0.10189637541770935, rse:0.4892970025539398\n",
    "Scaled mse:0.03074352815747261, rmse:0.17533832788467407, mae:0.10366739332675934, rse:0.5151970386505127\n",
    "\n",
    "ES 96\n",
    "Scaled mse:0.048280902206897736, rmse:0.21972915530204773, mae:0.13662198185920715, rse:0.6454980969429016\n",
    "Scaled mse:0.05975188687443733, rmse:0.24444198608398438, mae:0.1502540409564972, rse:0.7180969715118408\n",
    "\n",
    "ES 168\n",
    "Scaled mse:0.07949484884738922, rmse:0.2819482982158661, mae:0.1783347725868225, rse:0.828172504901886\n",
    "Scaled mse:0.0831800326704979, rmse:0.2884095013141632, mae:0.18242256343364716, rse:0.8471510410308838\n",
    "\n",
    "FR 24\n",
    "Scaled mse:0.012692660093307495, rmse:0.1126617044210434, mae:0.06498495489358902, rse:0.4347411096096039\n",
    "Scaled mse:0.013476599007844925, rmse:0.11608875542879105, mae:0.06680411100387573, rse:0.44796544313430786\n",
    "\n",
    "FR 96\n",
    "Scaled mse:0.022180521860718727, rmse:0.14893126487731934, mae:0.09044930338859558, rse:0.5761057138442993\n",
    "Scaled mse:0.02346043847501278, rmse:0.15316800773143768, mae:0.09117613732814789, rse:0.592494547367096\n",
    "\n",
    "FR 168\n",
    "Scaled mse:0.026063205674290657, rmse:0.16144102811813354, mae:0.10040990263223648, rse:0.6252502799034119\n",
    "Scaled mse:0.026005728170275688, rmse:0.16126291453838348, mae:0.10041678696870804, rse:0.6245604753494263\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2237253\n",
      "\tspeed: 0.0686s/iter; left time: 1233.0448s\n",
      "\titers: 200, epoch: 1 | loss: 0.2078324\n",
      "\tspeed: 0.0540s/iter; left time: 966.3858s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026997\n",
      "\tspeed: 0.0539s/iter; left time: 957.5317s\n",
      "\titers: 400, epoch: 1 | loss: 0.1845515\n",
      "\tspeed: 0.0539s/iter; left time: 952.7025s\n",
      "\titers: 500, epoch: 1 | loss: 0.1742399\n",
      "\tspeed: 0.0523s/iter; left time: 919.5012s\n",
      "\titers: 600, epoch: 1 | loss: 0.1764468\n",
      "\tspeed: 0.0512s/iter; left time: 895.0978s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656507\n",
      "\tspeed: 0.0460s/iter; left time: 798.8489s\n",
      "\titers: 800, epoch: 1 | loss: 0.1624510\n",
      "\tspeed: 0.0462s/iter; left time: 797.8938s\n",
      "\titers: 900, epoch: 1 | loss: 0.1670737\n",
      "\tspeed: 0.0484s/iter; left time: 832.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.89s\n",
      "Steps: 904 | Train Loss: 0.1883325 Vali Loss: 0.1648801 Test Loss: 0.1759902\n",
      "Validation loss decreased (inf --> 0.164880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1292697\n",
      "\tspeed: 0.1313s/iter; left time: 2242.1432s\n",
      "\titers: 200, epoch: 2 | loss: 0.1303454\n",
      "\tspeed: 0.0481s/iter; left time: 816.6175s\n",
      "\titers: 300, epoch: 2 | loss: 0.1064350\n",
      "\tspeed: 0.0486s/iter; left time: 819.9074s\n",
      "\titers: 400, epoch: 2 | loss: 0.1127212\n",
      "\tspeed: 0.0494s/iter; left time: 828.7243s\n",
      "\titers: 500, epoch: 2 | loss: 0.1001529\n",
      "\tspeed: 0.0499s/iter; left time: 831.5628s\n",
      "\titers: 600, epoch: 2 | loss: 0.1055134\n",
      "\tspeed: 0.0481s/iter; left time: 796.6545s\n",
      "\titers: 700, epoch: 2 | loss: 0.0919262\n",
      "\tspeed: 0.0485s/iter; left time: 798.3171s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938795\n",
      "\tspeed: 0.0504s/iter; left time: 824.9737s\n",
      "\titers: 900, epoch: 2 | loss: 0.1008889\n",
      "\tspeed: 0.0504s/iter; left time: 820.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.82s\n",
      "Steps: 904 | Train Loss: 0.1132814 Vali Loss: 0.1137326 Test Loss: 0.1172100\n",
      "Validation loss decreased (0.164880 --> 0.113733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023724\n",
      "\tspeed: 0.1327s/iter; left time: 2146.6916s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914004\n",
      "\tspeed: 0.0506s/iter; left time: 813.8122s\n",
      "\titers: 300, epoch: 3 | loss: 0.1016963\n",
      "\tspeed: 0.0481s/iter; left time: 767.5460s\n",
      "\titers: 400, epoch: 3 | loss: 0.0880007\n",
      "\tspeed: 0.0489s/iter; left time: 776.2225s\n",
      "\titers: 500, epoch: 3 | loss: 0.0886729\n",
      "\tspeed: 0.0496s/iter; left time: 782.1501s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933941\n",
      "\tspeed: 0.0500s/iter; left time: 783.2863s\n",
      "\titers: 700, epoch: 3 | loss: 0.0821497\n",
      "\tspeed: 0.0494s/iter; left time: 769.5763s\n",
      "\titers: 800, epoch: 3 | loss: 0.0784431\n",
      "\tspeed: 0.0477s/iter; left time: 738.6048s\n",
      "\titers: 900, epoch: 3 | loss: 0.0871597\n",
      "\tspeed: 0.0490s/iter; left time: 753.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.82s\n",
      "Steps: 904 | Train Loss: 0.0889036 Vali Loss: 0.1077861 Test Loss: 0.1100062\n",
      "Validation loss decreased (0.113733 --> 0.107786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1000021\n",
      "\tspeed: 0.1324s/iter; left time: 2021.7735s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851760\n",
      "\tspeed: 0.0496s/iter; left time: 752.3224s\n",
      "\titers: 300, epoch: 4 | loss: 0.0780067\n",
      "\tspeed: 0.0498s/iter; left time: 750.2267s\n",
      "\titers: 400, epoch: 4 | loss: 0.0840204\n",
      "\tspeed: 0.0481s/iter; left time: 719.9614s\n",
      "\titers: 500, epoch: 4 | loss: 0.0891868\n",
      "\tspeed: 0.0481s/iter; left time: 715.7272s\n",
      "\titers: 600, epoch: 4 | loss: 0.0871442\n",
      "\tspeed: 0.0463s/iter; left time: 683.2650s\n",
      "\titers: 700, epoch: 4 | loss: 0.0766105\n",
      "\tspeed: 0.0472s/iter; left time: 691.9794s\n",
      "\titers: 800, epoch: 4 | loss: 0.0846739\n",
      "\tspeed: 0.0505s/iter; left time: 735.3355s\n",
      "\titers: 900, epoch: 4 | loss: 0.0937868\n",
      "\tspeed: 0.0500s/iter; left time: 723.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.49s\n",
      "Steps: 904 | Train Loss: 0.0839007 Vali Loss: 0.1048517 Test Loss: 0.1127895\n",
      "Validation loss decreased (0.107786 --> 0.104852).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748998\n",
      "\tspeed: 0.1307s/iter; left time: 1877.0840s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792407\n",
      "\tspeed: 0.0492s/iter; left time: 701.7189s\n",
      "\titers: 300, epoch: 5 | loss: 0.0793407\n",
      "\tspeed: 0.0481s/iter; left time: 681.3338s\n",
      "\titers: 400, epoch: 5 | loss: 0.0788237\n",
      "\tspeed: 0.0471s/iter; left time: 662.0402s\n",
      "\titers: 500, epoch: 5 | loss: 0.0657325\n",
      "\tspeed: 0.0487s/iter; left time: 680.4426s\n",
      "\titers: 600, epoch: 5 | loss: 0.0717637\n",
      "\tspeed: 0.0485s/iter; left time: 672.2396s\n",
      "\titers: 700, epoch: 5 | loss: 0.0805544\n",
      "\tspeed: 0.0482s/iter; left time: 664.0835s\n",
      "\titers: 800, epoch: 5 | loss: 0.0765882\n",
      "\tspeed: 0.0477s/iter; left time: 651.6884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0785381\n",
      "\tspeed: 0.0475s/iter; left time: 644.8451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.95s\n",
      "Steps: 904 | Train Loss: 0.0763340 Vali Loss: 0.0987668 Test Loss: 0.1006400\n",
      "Validation loss decreased (0.104852 --> 0.098767).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0726907\n",
      "\tspeed: 0.1290s/iter; left time: 1736.0982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0700620\n",
      "\tspeed: 0.0472s/iter; left time: 630.0260s\n",
      "\titers: 300, epoch: 6 | loss: 0.0627781\n",
      "\tspeed: 0.0468s/iter; left time: 620.5827s\n",
      "\titers: 400, epoch: 6 | loss: 0.0723309\n",
      "\tspeed: 0.0480s/iter; left time: 632.2476s\n",
      "\titers: 500, epoch: 6 | loss: 0.0695192\n",
      "\tspeed: 0.0481s/iter; left time: 628.3902s\n",
      "\titers: 600, epoch: 6 | loss: 0.0784702\n",
      "\tspeed: 0.0487s/iter; left time: 631.6719s\n",
      "\titers: 700, epoch: 6 | loss: 0.0676117\n",
      "\tspeed: 0.0477s/iter; left time: 613.1214s\n",
      "\titers: 800, epoch: 6 | loss: 0.0666713\n",
      "\tspeed: 0.0486s/iter; left time: 619.6773s\n",
      "\titers: 900, epoch: 6 | loss: 0.0725636\n",
      "\tspeed: 0.0496s/iter; left time: 628.2768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.76s\n",
      "Steps: 904 | Train Loss: 0.0708122 Vali Loss: 0.0981035 Test Loss: 0.1036226\n",
      "Validation loss decreased (0.098767 --> 0.098104).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0670227\n",
      "\tspeed: 0.1307s/iter; left time: 1641.6260s\n",
      "\titers: 200, epoch: 7 | loss: 0.0758528\n",
      "\tspeed: 0.0452s/iter; left time: 563.6699s\n",
      "\titers: 300, epoch: 7 | loss: 0.0658267\n",
      "\tspeed: 0.0449s/iter; left time: 554.8375s\n",
      "\titers: 400, epoch: 7 | loss: 0.0668069\n",
      "\tspeed: 0.0510s/iter; left time: 625.3521s\n",
      "\titers: 500, epoch: 7 | loss: 0.0651610\n",
      "\tspeed: 0.0505s/iter; left time: 614.0471s\n",
      "\titers: 600, epoch: 7 | loss: 0.0605209\n",
      "\tspeed: 0.0491s/iter; left time: 591.4556s\n",
      "\titers: 700, epoch: 7 | loss: 0.0691002\n",
      "\tspeed: 0.0504s/iter; left time: 602.5005s\n",
      "\titers: 800, epoch: 7 | loss: 0.0671415\n",
      "\tspeed: 0.0496s/iter; left time: 587.7246s\n",
      "\titers: 900, epoch: 7 | loss: 0.0634724\n",
      "\tspeed: 0.0500s/iter; left time: 587.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.41s\n",
      "Steps: 904 | Train Loss: 0.0675068 Vali Loss: 0.0995243 Test Loss: 0.1057006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0625426\n",
      "\tspeed: 0.1287s/iter; left time: 1499.3820s\n",
      "\titers: 200, epoch: 8 | loss: 0.0654075\n",
      "\tspeed: 0.0517s/iter; left time: 597.3226s\n",
      "\titers: 300, epoch: 8 | loss: 0.0636932\n",
      "\tspeed: 0.0522s/iter; left time: 597.3036s\n",
      "\titers: 400, epoch: 8 | loss: 0.0640644\n",
      "\tspeed: 0.0495s/iter; left time: 562.4126s\n",
      "\titers: 500, epoch: 8 | loss: 0.0597918\n",
      "\tspeed: 0.0483s/iter; left time: 544.0262s\n",
      "\titers: 600, epoch: 8 | loss: 0.0550925\n",
      "\tspeed: 0.0465s/iter; left time: 518.7813s\n",
      "\titers: 700, epoch: 8 | loss: 0.0650288\n",
      "\tspeed: 0.0468s/iter; left time: 517.4803s\n",
      "\titers: 800, epoch: 8 | loss: 0.0659823\n",
      "\tspeed: 0.0502s/iter; left time: 549.8316s\n",
      "\titers: 900, epoch: 8 | loss: 0.0654528\n",
      "\tspeed: 0.0508s/iter; left time: 551.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.00s\n",
      "Steps: 904 | Train Loss: 0.0644291 Vali Loss: 0.1003632 Test Loss: 0.1062918\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0686418\n",
      "\tspeed: 0.1260s/iter; left time: 1354.2660s\n",
      "\titers: 200, epoch: 9 | loss: 0.0604094\n",
      "\tspeed: 0.0496s/iter; left time: 528.5315s\n",
      "\titers: 300, epoch: 9 | loss: 0.0632912\n",
      "\tspeed: 0.0515s/iter; left time: 543.6620s\n",
      "\titers: 400, epoch: 9 | loss: 0.0558523\n",
      "\tspeed: 0.0504s/iter; left time: 527.1201s\n",
      "\titers: 500, epoch: 9 | loss: 0.0671359\n",
      "\tspeed: 0.0479s/iter; left time: 495.3332s\n",
      "\titers: 600, epoch: 9 | loss: 0.0572487\n",
      "\tspeed: 0.0469s/iter; left time: 480.6392s\n",
      "\titers: 700, epoch: 9 | loss: 0.0529645\n",
      "\tspeed: 0.0472s/iter; left time: 479.5144s\n",
      "\titers: 800, epoch: 9 | loss: 0.0692128\n",
      "\tspeed: 0.0476s/iter; left time: 478.1484s\n",
      "\titers: 900, epoch: 9 | loss: 0.0573754\n",
      "\tspeed: 0.0498s/iter; left time: 495.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.29s\n",
      "Steps: 904 | Train Loss: 0.0615838 Vali Loss: 0.0992900 Test Loss: 0.1105427\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658520\n",
      "\tspeed: 0.1269s/iter; left time: 1249.1314s\n",
      "\titers: 200, epoch: 10 | loss: 0.0621088\n",
      "\tspeed: 0.0466s/iter; left time: 453.7895s\n",
      "\titers: 300, epoch: 10 | loss: 0.0611764\n",
      "\tspeed: 0.0492s/iter; left time: 474.8446s\n",
      "\titers: 400, epoch: 10 | loss: 0.0561155\n",
      "\tspeed: 0.0488s/iter; left time: 465.6267s\n",
      "\titers: 500, epoch: 10 | loss: 0.0647239\n",
      "\tspeed: 0.0491s/iter; left time: 463.9614s\n",
      "\titers: 600, epoch: 10 | loss: 0.0557827\n",
      "\tspeed: 0.0446s/iter; left time: 416.7990s\n",
      "\titers: 700, epoch: 10 | loss: 0.0560749\n",
      "\tspeed: 0.0474s/iter; left time: 438.3304s\n",
      "\titers: 800, epoch: 10 | loss: 0.0608029\n",
      "\tspeed: 0.0487s/iter; left time: 445.4043s\n",
      "\titers: 900, epoch: 10 | loss: 0.0624404\n",
      "\tspeed: 0.0491s/iter; left time: 443.8028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:43.61s\n",
      "Steps: 904 | Train Loss: 0.0590161 Vali Loss: 0.1013912 Test Loss: 0.1093063\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0592587\n",
      "\tspeed: 0.1263s/iter; left time: 1128.8654s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598371\n",
      "\tspeed: 0.0487s/iter; left time: 430.9090s\n",
      "\titers: 300, epoch: 11 | loss: 0.0538193\n",
      "\tspeed: 0.0476s/iter; left time: 415.8083s\n",
      "\titers: 400, epoch: 11 | loss: 0.0501705\n",
      "\tspeed: 0.0475s/iter; left time: 410.5600s\n",
      "\titers: 500, epoch: 11 | loss: 0.0594286\n",
      "\tspeed: 0.0466s/iter; left time: 397.6339s\n",
      "\titers: 600, epoch: 11 | loss: 0.0581484\n",
      "\tspeed: 0.0489s/iter; left time: 412.5334s\n",
      "\titers: 700, epoch: 11 | loss: 0.0562719\n",
      "\tspeed: 0.0500s/iter; left time: 417.2114s\n",
      "\titers: 800, epoch: 11 | loss: 0.0525803\n",
      "\tspeed: 0.0486s/iter; left time: 400.4798s\n",
      "\titers: 900, epoch: 11 | loss: 0.0525555\n",
      "\tspeed: 0.0492s/iter; left time: 400.6877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:43.91s\n",
      "Steps: 904 | Train Loss: 0.0566675 Vali Loss: 0.1017976 Test Loss: 0.1155055\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025699591264128685, rmse:0.16031092405319214, mae:0.10348266363143921, rse:0.5661423206329346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2315448\n",
      "\tspeed: 0.0550s/iter; left time: 988.5092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1870095\n",
      "\tspeed: 0.0508s/iter; left time: 907.5998s\n",
      "\titers: 300, epoch: 1 | loss: 0.1853559\n",
      "\tspeed: 0.0491s/iter; left time: 872.7102s\n",
      "\titers: 400, epoch: 1 | loss: 0.1861934\n",
      "\tspeed: 0.0491s/iter; left time: 867.9690s\n",
      "\titers: 500, epoch: 1 | loss: 0.1746625\n",
      "\tspeed: 0.0501s/iter; left time: 879.9760s\n",
      "\titers: 600, epoch: 1 | loss: 0.1736583\n",
      "\tspeed: 0.0478s/iter; left time: 835.5740s\n",
      "\titers: 700, epoch: 1 | loss: 0.1636848\n",
      "\tspeed: 0.0477s/iter; left time: 829.5034s\n",
      "\titers: 800, epoch: 1 | loss: 0.1572584\n",
      "\tspeed: 0.0468s/iter; left time: 808.9079s\n",
      "\titers: 900, epoch: 1 | loss: 0.1623689\n",
      "\tspeed: 0.0492s/iter; left time: 845.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.81s\n",
      "Steps: 904 | Train Loss: 0.1874959 Vali Loss: 0.1601834 Test Loss: 0.1728109\n",
      "Validation loss decreased (inf --> 0.160183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1442371\n",
      "\tspeed: 0.1383s/iter; left time: 2361.4903s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242099\n",
      "\tspeed: 0.0504s/iter; left time: 855.0232s\n",
      "\titers: 300, epoch: 2 | loss: 0.1189800\n",
      "\tspeed: 0.0491s/iter; left time: 828.0476s\n",
      "\titers: 400, epoch: 2 | loss: 0.1133306\n",
      "\tspeed: 0.0497s/iter; left time: 833.1930s\n",
      "\titers: 500, epoch: 2 | loss: 0.0881876\n",
      "\tspeed: 0.0452s/iter; left time: 753.2781s\n",
      "\titers: 600, epoch: 2 | loss: 0.1003774\n",
      "\tspeed: 0.0440s/iter; left time: 729.4449s\n",
      "\titers: 700, epoch: 2 | loss: 0.0960758\n",
      "\tspeed: 0.0465s/iter; left time: 765.6182s\n",
      "\titers: 800, epoch: 2 | loss: 0.0832910\n",
      "\tspeed: 0.0470s/iter; left time: 769.9599s\n",
      "\titers: 900, epoch: 2 | loss: 0.0849561\n",
      "\tspeed: 0.0483s/iter; left time: 785.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.61s\n",
      "Steps: 904 | Train Loss: 0.1108848 Vali Loss: 0.1030598 Test Loss: 0.1049514\n",
      "Validation loss decreased (0.160183 --> 0.103060).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0986554\n",
      "\tspeed: 0.1323s/iter; left time: 2139.7684s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938896\n",
      "\tspeed: 0.0491s/iter; left time: 789.2657s\n",
      "\titers: 300, epoch: 3 | loss: 0.0741805\n",
      "\tspeed: 0.0477s/iter; left time: 761.1219s\n",
      "\titers: 400, epoch: 3 | loss: 0.0870180\n",
      "\tspeed: 0.0464s/iter; left time: 735.7264s\n",
      "\titers: 500, epoch: 3 | loss: 0.0836230\n",
      "\tspeed: 0.0494s/iter; left time: 778.6260s\n",
      "\titers: 600, epoch: 3 | loss: 0.0710492\n",
      "\tspeed: 0.0476s/iter; left time: 745.9856s\n",
      "\titers: 700, epoch: 3 | loss: 0.0908635\n",
      "\tspeed: 0.0474s/iter; left time: 738.1028s\n",
      "\titers: 800, epoch: 3 | loss: 0.0742608\n",
      "\tspeed: 0.0450s/iter; left time: 695.7696s\n",
      "\titers: 900, epoch: 3 | loss: 0.0708854\n",
      "\tspeed: 0.0462s/iter; left time: 710.5009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.0834889 Vali Loss: 0.1005139 Test Loss: 0.1062188\n",
      "Validation loss decreased (0.103060 --> 0.100514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727788\n",
      "\tspeed: 0.1317s/iter; left time: 2010.2571s\n",
      "\titers: 200, epoch: 4 | loss: 0.0778070\n",
      "\tspeed: 0.0478s/iter; left time: 725.6620s\n",
      "\titers: 300, epoch: 4 | loss: 0.0725788\n",
      "\tspeed: 0.0488s/iter; left time: 735.3850s\n",
      "\titers: 400, epoch: 4 | loss: 0.0721342\n",
      "\tspeed: 0.0459s/iter; left time: 686.8147s\n",
      "\titers: 500, epoch: 4 | loss: 0.0775696\n",
      "\tspeed: 0.0501s/iter; left time: 744.6809s\n",
      "\titers: 600, epoch: 4 | loss: 0.0726275\n",
      "\tspeed: 0.0483s/iter; left time: 713.7810s\n",
      "\titers: 700, epoch: 4 | loss: 0.0924465\n",
      "\tspeed: 0.0495s/iter; left time: 725.5518s\n",
      "\titers: 800, epoch: 4 | loss: 0.0744018\n",
      "\tspeed: 0.0501s/iter; left time: 729.8708s\n",
      "\titers: 900, epoch: 4 | loss: 0.0749104\n",
      "\tspeed: 0.0491s/iter; left time: 710.5545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 904 | Train Loss: 0.0775101 Vali Loss: 0.0944325 Test Loss: 0.1005489\n",
      "Validation loss decreased (0.100514 --> 0.094433).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0704054\n",
      "\tspeed: 0.1330s/iter; left time: 1910.1045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822688\n",
      "\tspeed: 0.0512s/iter; left time: 730.4563s\n",
      "\titers: 300, epoch: 5 | loss: 0.0771133\n",
      "\tspeed: 0.0482s/iter; left time: 683.3547s\n",
      "\titers: 400, epoch: 5 | loss: 0.0935729\n",
      "\tspeed: 0.0488s/iter; left time: 685.8009s\n",
      "\titers: 500, epoch: 5 | loss: 0.0731310\n",
      "\tspeed: 0.0489s/iter; left time: 683.2919s\n",
      "\titers: 600, epoch: 5 | loss: 0.0828237\n",
      "\tspeed: 0.0493s/iter; left time: 684.1938s\n",
      "\titers: 700, epoch: 5 | loss: 0.0765573\n",
      "\tspeed: 0.0509s/iter; left time: 700.0163s\n",
      "\titers: 800, epoch: 5 | loss: 0.0680927\n",
      "\tspeed: 0.0487s/iter; left time: 666.0774s\n",
      "\titers: 900, epoch: 5 | loss: 0.0752320\n",
      "\tspeed: 0.0476s/iter; left time: 645.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.96s\n",
      "Steps: 904 | Train Loss: 0.0728386 Vali Loss: 0.0945967 Test Loss: 0.1001754\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0832520\n",
      "\tspeed: 0.1299s/iter; left time: 1749.1711s\n",
      "\titers: 200, epoch: 6 | loss: 0.0753487\n",
      "\tspeed: 0.0487s/iter; left time: 651.3454s\n",
      "\titers: 300, epoch: 6 | loss: 0.0644185\n",
      "\tspeed: 0.0469s/iter; left time: 622.5238s\n",
      "\titers: 400, epoch: 6 | loss: 0.0643118\n",
      "\tspeed: 0.0472s/iter; left time: 621.2413s\n",
      "\titers: 500, epoch: 6 | loss: 0.0754884\n",
      "\tspeed: 0.0489s/iter; left time: 638.4534s\n",
      "\titers: 600, epoch: 6 | loss: 0.0732567\n",
      "\tspeed: 0.0477s/iter; left time: 617.6266s\n",
      "\titers: 700, epoch: 6 | loss: 0.0647245\n",
      "\tspeed: 0.0505s/iter; left time: 649.2452s\n",
      "\titers: 800, epoch: 6 | loss: 0.0613778\n",
      "\tspeed: 0.0487s/iter; left time: 621.9970s\n",
      "\titers: 900, epoch: 6 | loss: 0.0588709\n",
      "\tspeed: 0.0485s/iter; left time: 614.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.27s\n",
      "Steps: 904 | Train Loss: 0.0696465 Vali Loss: 0.0999700 Test Loss: 0.1056041\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0637287\n",
      "\tspeed: 0.1318s/iter; left time: 1654.9452s\n",
      "\titers: 200, epoch: 7 | loss: 0.0616536\n",
      "\tspeed: 0.0504s/iter; left time: 628.2521s\n",
      "\titers: 300, epoch: 7 | loss: 0.0670370\n",
      "\tspeed: 0.0490s/iter; left time: 605.0805s\n",
      "\titers: 400, epoch: 7 | loss: 0.0667890\n",
      "\tspeed: 0.0484s/iter; left time: 593.7738s\n",
      "\titers: 500, epoch: 7 | loss: 0.0683423\n",
      "\tspeed: 0.0501s/iter; left time: 608.8140s\n",
      "\titers: 600, epoch: 7 | loss: 0.0613646\n",
      "\tspeed: 0.0517s/iter; left time: 623.3166s\n",
      "\titers: 700, epoch: 7 | loss: 0.0672958\n",
      "\tspeed: 0.0502s/iter; left time: 600.6896s\n",
      "\titers: 800, epoch: 7 | loss: 0.0559581\n",
      "\tspeed: 0.0502s/iter; left time: 595.2838s\n",
      "\titers: 900, epoch: 7 | loss: 0.0624384\n",
      "\tspeed: 0.0508s/iter; left time: 597.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 904 | Train Loss: 0.0658920 Vali Loss: 0.0985089 Test Loss: 0.1026324\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0635236\n",
      "\tspeed: 0.1302s/iter; left time: 1517.0451s\n",
      "\titers: 200, epoch: 8 | loss: 0.0639518\n",
      "\tspeed: 0.0504s/iter; left time: 582.4959s\n",
      "\titers: 300, epoch: 8 | loss: 0.0589946\n",
      "\tspeed: 0.0512s/iter; left time: 586.7656s\n",
      "\titers: 400, epoch: 8 | loss: 0.0609208\n",
      "\tspeed: 0.0494s/iter; left time: 561.3547s\n",
      "\titers: 500, epoch: 8 | loss: 0.0657021\n",
      "\tspeed: 0.0492s/iter; left time: 553.8172s\n",
      "\titers: 600, epoch: 8 | loss: 0.0638532\n",
      "\tspeed: 0.0513s/iter; left time: 572.2608s\n",
      "\titers: 700, epoch: 8 | loss: 0.0625244\n",
      "\tspeed: 0.0471s/iter; left time: 520.8477s\n",
      "\titers: 800, epoch: 8 | loss: 0.0643017\n",
      "\tspeed: 0.0471s/iter; left time: 516.0710s\n",
      "\titers: 900, epoch: 8 | loss: 0.0574698\n",
      "\tspeed: 0.0480s/iter; left time: 521.0073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 904 | Train Loss: 0.0627713 Vali Loss: 0.0998820 Test Loss: 0.1061769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0644793\n",
      "\tspeed: 0.1308s/iter; left time: 1405.8060s\n",
      "\titers: 200, epoch: 9 | loss: 0.0576581\n",
      "\tspeed: 0.0475s/iter; left time: 505.5360s\n",
      "\titers: 300, epoch: 9 | loss: 0.0671575\n",
      "\tspeed: 0.0485s/iter; left time: 511.8847s\n",
      "\titers: 400, epoch: 9 | loss: 0.0630336\n",
      "\tspeed: 0.0483s/iter; left time: 504.8561s\n",
      "\titers: 500, epoch: 9 | loss: 0.0614120\n",
      "\tspeed: 0.0480s/iter; left time: 496.5229s\n",
      "\titers: 600, epoch: 9 | loss: 0.0614003\n",
      "\tspeed: 0.0490s/iter; left time: 502.5034s\n",
      "\titers: 700, epoch: 9 | loss: 0.0554118\n",
      "\tspeed: 0.0474s/iter; left time: 480.6686s\n",
      "\titers: 800, epoch: 9 | loss: 0.0673444\n",
      "\tspeed: 0.0478s/iter; left time: 480.1690s\n",
      "\titers: 900, epoch: 9 | loss: 0.0636126\n",
      "\tspeed: 0.0495s/iter; left time: 492.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.04s\n",
      "Steps: 904 | Train Loss: 0.0598709 Vali Loss: 0.1021480 Test Loss: 0.1111396\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023365361616015434, rmse:0.15285731852054596, mae:0.10056539624929428, rse:0.5398197770118713\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:38.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2210946\n",
      "\tspeed: 0.0737s/iter; left time: 1321.9220s\n",
      "\titers: 200, epoch: 1 | loss: 0.2150234\n",
      "\tspeed: 0.0537s/iter; left time: 957.9886s\n",
      "\titers: 300, epoch: 1 | loss: 0.1989978\n",
      "\tspeed: 0.0524s/iter; left time: 930.4451s\n",
      "\titers: 400, epoch: 1 | loss: 0.1959145\n",
      "\tspeed: 0.0518s/iter; left time: 913.0236s\n",
      "\titers: 500, epoch: 1 | loss: 0.1894610\n",
      "\tspeed: 0.0551s/iter; left time: 966.1923s\n",
      "\titers: 600, epoch: 1 | loss: 0.1868032\n",
      "\tspeed: 0.0558s/iter; left time: 973.2422s\n",
      "\titers: 700, epoch: 1 | loss: 0.1755006\n",
      "\tspeed: 0.0542s/iter; left time: 939.2860s\n",
      "\titers: 800, epoch: 1 | loss: 0.1755232\n",
      "\tspeed: 0.0535s/iter; left time: 922.9635s\n",
      "\titers: 900, epoch: 1 | loss: 0.1790397\n",
      "\tspeed: 0.0544s/iter; left time: 931.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.19s\n",
      "Steps: 902 | Train Loss: 0.1968988 Vali Loss: 0.1818394 Test Loss: 0.2035483\n",
      "Validation loss decreased (inf --> 0.181839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1630306\n",
      "\tspeed: 0.1537s/iter; left time: 2618.9382s\n",
      "\titers: 200, epoch: 2 | loss: 0.1457784\n",
      "\tspeed: 0.0558s/iter; left time: 944.5413s\n",
      "\titers: 300, epoch: 2 | loss: 0.1517065\n",
      "\tspeed: 0.0542s/iter; left time: 913.1105s\n",
      "\titers: 400, epoch: 2 | loss: 0.1315056\n",
      "\tspeed: 0.0539s/iter; left time: 902.9016s\n",
      "\titers: 500, epoch: 2 | loss: 0.1377397\n",
      "\tspeed: 0.0544s/iter; left time: 904.6939s\n",
      "\titers: 600, epoch: 2 | loss: 0.1340519\n",
      "\tspeed: 0.0550s/iter; left time: 909.8625s\n",
      "\titers: 700, epoch: 2 | loss: 0.1295527\n",
      "\tspeed: 0.0518s/iter; left time: 851.9151s\n",
      "\titers: 800, epoch: 2 | loss: 0.1235380\n",
      "\tspeed: 0.0541s/iter; left time: 884.5995s\n",
      "\titers: 900, epoch: 2 | loss: 0.1223168\n",
      "\tspeed: 0.0541s/iter; left time: 878.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.31s\n",
      "Steps: 902 | Train Loss: 0.1395319 Vali Loss: 0.1480401 Test Loss: 0.1603727\n",
      "Validation loss decreased (0.181839 --> 0.148040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1297777\n",
      "\tspeed: 0.1489s/iter; left time: 2403.1501s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223811\n",
      "\tspeed: 0.0533s/iter; left time: 855.1323s\n",
      "\titers: 300, epoch: 3 | loss: 0.1176509\n",
      "\tspeed: 0.0536s/iter; left time: 853.7880s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113071\n",
      "\tspeed: 0.0511s/iter; left time: 809.5657s\n",
      "\titers: 500, epoch: 3 | loss: 0.1144058\n",
      "\tspeed: 0.0525s/iter; left time: 825.8792s\n",
      "\titers: 600, epoch: 3 | loss: 0.1042292\n",
      "\tspeed: 0.0551s/iter; left time: 861.8218s\n",
      "\titers: 700, epoch: 3 | loss: 0.1173630\n",
      "\tspeed: 0.0549s/iter; left time: 853.0265s\n",
      "\titers: 800, epoch: 3 | loss: 0.1086130\n",
      "\tspeed: 0.0550s/iter; left time: 848.5841s\n",
      "\titers: 900, epoch: 3 | loss: 0.0988219\n",
      "\tspeed: 0.0544s/iter; left time: 834.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.1134594 Vali Loss: 0.1349136 Test Loss: 0.1450328\n",
      "Validation loss decreased (0.148040 --> 0.134914).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0937771\n",
      "\tspeed: 0.1471s/iter; left time: 2241.3955s\n",
      "\titers: 200, epoch: 4 | loss: 0.1034436\n",
      "\tspeed: 0.0580s/iter; left time: 877.4435s\n",
      "\titers: 300, epoch: 4 | loss: 0.1035905\n",
      "\tspeed: 0.0565s/iter; left time: 848.7860s\n",
      "\titers: 400, epoch: 4 | loss: 0.1000669\n",
      "\tspeed: 0.0549s/iter; left time: 819.3471s\n",
      "\titers: 500, epoch: 4 | loss: 0.0924415\n",
      "\tspeed: 0.0519s/iter; left time: 769.7011s\n",
      "\titers: 600, epoch: 4 | loss: 0.0935867\n",
      "\tspeed: 0.0543s/iter; left time: 800.1798s\n",
      "\titers: 700, epoch: 4 | loss: 0.0816386\n",
      "\tspeed: 0.0566s/iter; left time: 828.8158s\n",
      "\titers: 800, epoch: 4 | loss: 0.0952003\n",
      "\tspeed: 0.0574s/iter; left time: 834.8317s\n",
      "\titers: 900, epoch: 4 | loss: 0.0908712\n",
      "\tspeed: 0.0554s/iter; left time: 799.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:50.44s\n",
      "Steps: 902 | Train Loss: 0.0983186 Vali Loss: 0.1329007 Test Loss: 0.1425156\n",
      "Validation loss decreased (0.134914 --> 0.132901).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0857247\n",
      "\tspeed: 0.1461s/iter; left time: 2094.3812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0864974\n",
      "\tspeed: 0.0521s/iter; left time: 741.1840s\n",
      "\titers: 300, epoch: 5 | loss: 0.0910721\n",
      "\tspeed: 0.0532s/iter; left time: 752.4512s\n",
      "\titers: 400, epoch: 5 | loss: 0.0882817\n",
      "\tspeed: 0.0568s/iter; left time: 796.9799s\n",
      "\titers: 500, epoch: 5 | loss: 0.0847525\n",
      "\tspeed: 0.0563s/iter; left time: 783.7958s\n",
      "\titers: 600, epoch: 5 | loss: 0.0936627\n",
      "\tspeed: 0.0559s/iter; left time: 773.3407s\n",
      "\titers: 700, epoch: 5 | loss: 0.0831097\n",
      "\tspeed: 0.0508s/iter; left time: 697.9387s\n",
      "\titers: 800, epoch: 5 | loss: 0.0785915\n",
      "\tspeed: 0.0552s/iter; left time: 752.3214s\n",
      "\titers: 900, epoch: 5 | loss: 0.0906300\n",
      "\tspeed: 0.0540s/iter; left time: 730.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.34s\n",
      "Steps: 902 | Train Loss: 0.0892973 Vali Loss: 0.1321378 Test Loss: 0.1496759\n",
      "Validation loss decreased (0.132901 --> 0.132138).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0832333\n",
      "\tspeed: 0.1459s/iter; left time: 1959.3004s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761957\n",
      "\tspeed: 0.0541s/iter; left time: 721.8474s\n",
      "\titers: 300, epoch: 6 | loss: 0.0836057\n",
      "\tspeed: 0.0541s/iter; left time: 715.7758s\n",
      "\titers: 400, epoch: 6 | loss: 0.0760027\n",
      "\tspeed: 0.0558s/iter; left time: 733.3251s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827000\n",
      "\tspeed: 0.0557s/iter; left time: 725.5069s\n",
      "\titers: 600, epoch: 6 | loss: 0.0804212\n",
      "\tspeed: 0.0546s/iter; left time: 705.9342s\n",
      "\titers: 700, epoch: 6 | loss: 0.0732568\n",
      "\tspeed: 0.0496s/iter; left time: 636.6678s\n",
      "\titers: 800, epoch: 6 | loss: 0.0830542\n",
      "\tspeed: 0.0557s/iter; left time: 708.8332s\n",
      "\titers: 900, epoch: 6 | loss: 0.0739421\n",
      "\tspeed: 0.0541s/iter; left time: 682.8341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.23s\n",
      "Steps: 902 | Train Loss: 0.0820906 Vali Loss: 0.1331190 Test Loss: 0.1502934\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0761108\n",
      "\tspeed: 0.1426s/iter; left time: 1786.6938s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811995\n",
      "\tspeed: 0.0580s/iter; left time: 720.5575s\n",
      "\titers: 300, epoch: 7 | loss: 0.0690344\n",
      "\tspeed: 0.0560s/iter; left time: 690.6803s\n",
      "\titers: 400, epoch: 7 | loss: 0.0726365\n",
      "\tspeed: 0.0558s/iter; left time: 682.7628s\n",
      "\titers: 500, epoch: 7 | loss: 0.0787980\n",
      "\tspeed: 0.0542s/iter; left time: 656.8108s\n",
      "\titers: 600, epoch: 7 | loss: 0.0778433\n",
      "\tspeed: 0.0547s/iter; left time: 658.1228s\n",
      "\titers: 700, epoch: 7 | loss: 0.0792655\n",
      "\tspeed: 0.0549s/iter; left time: 655.3470s\n",
      "\titers: 800, epoch: 7 | loss: 0.0822543\n",
      "\tspeed: 0.0550s/iter; left time: 650.1634s\n",
      "\titers: 900, epoch: 7 | loss: 0.0726486\n",
      "\tspeed: 0.0546s/iter; left time: 639.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.09s\n",
      "Steps: 902 | Train Loss: 0.0759524 Vali Loss: 0.1344025 Test Loss: 0.1518265\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0766096\n",
      "\tspeed: 0.1435s/iter; left time: 1668.6783s\n",
      "\titers: 200, epoch: 8 | loss: 0.0771285\n",
      "\tspeed: 0.0533s/iter; left time: 614.6867s\n",
      "\titers: 300, epoch: 8 | loss: 0.0707851\n",
      "\tspeed: 0.0562s/iter; left time: 642.2356s\n",
      "\titers: 400, epoch: 8 | loss: 0.0743096\n",
      "\tspeed: 0.0559s/iter; left time: 633.2961s\n",
      "\titers: 500, epoch: 8 | loss: 0.0685609\n",
      "\tspeed: 0.0542s/iter; left time: 609.0525s\n",
      "\titers: 600, epoch: 8 | loss: 0.0677029\n",
      "\tspeed: 0.0533s/iter; left time: 592.9861s\n",
      "\titers: 700, epoch: 8 | loss: 0.0747162\n",
      "\tspeed: 0.0540s/iter; left time: 595.3112s\n",
      "\titers: 800, epoch: 8 | loss: 0.0697416\n",
      "\tspeed: 0.0542s/iter; left time: 592.4504s\n",
      "\titers: 900, epoch: 8 | loss: 0.0634852\n",
      "\tspeed: 0.0549s/iter; left time: 594.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.56s\n",
      "Steps: 902 | Train Loss: 0.0710888 Vali Loss: 0.1335566 Test Loss: 0.1535211\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600012\n",
      "\tspeed: 0.1435s/iter; left time: 1538.9056s\n",
      "\titers: 200, epoch: 9 | loss: 0.0688686\n",
      "\tspeed: 0.0565s/iter; left time: 600.7901s\n",
      "\titers: 300, epoch: 9 | loss: 0.0682490\n",
      "\tspeed: 0.0562s/iter; left time: 591.2420s\n",
      "\titers: 400, epoch: 9 | loss: 0.0641419\n",
      "\tspeed: 0.0546s/iter; left time: 569.1749s\n",
      "\titers: 500, epoch: 9 | loss: 0.0618546\n",
      "\tspeed: 0.0510s/iter; left time: 527.0078s\n",
      "\titers: 600, epoch: 9 | loss: 0.0665884\n",
      "\tspeed: 0.0547s/iter; left time: 559.2908s\n",
      "\titers: 700, epoch: 9 | loss: 0.0654034\n",
      "\tspeed: 0.0550s/iter; left time: 557.2813s\n",
      "\titers: 800, epoch: 9 | loss: 0.0727210\n",
      "\tspeed: 0.0546s/iter; left time: 547.0054s\n",
      "\titers: 900, epoch: 9 | loss: 0.0543369\n",
      "\tspeed: 0.0532s/iter; left time: 528.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.52s\n",
      "Steps: 902 | Train Loss: 0.0670178 Vali Loss: 0.1351829 Test Loss: 0.1532605\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0631002\n",
      "\tspeed: 0.1396s/iter; left time: 1371.7517s\n",
      "\titers: 200, epoch: 10 | loss: 0.0637145\n",
      "\tspeed: 0.0542s/iter; left time: 526.8326s\n",
      "\titers: 300, epoch: 10 | loss: 0.0705053\n",
      "\tspeed: 0.0559s/iter; left time: 537.9831s\n",
      "\titers: 400, epoch: 10 | loss: 0.0654915\n",
      "\tspeed: 0.0560s/iter; left time: 532.8812s\n",
      "\titers: 500, epoch: 10 | loss: 0.0669276\n",
      "\tspeed: 0.0541s/iter; left time: 509.7920s\n",
      "\titers: 600, epoch: 10 | loss: 0.0660651\n",
      "\tspeed: 0.0556s/iter; left time: 518.2218s\n",
      "\titers: 700, epoch: 10 | loss: 0.0676018\n",
      "\tspeed: 0.0548s/iter; left time: 505.7728s\n",
      "\titers: 800, epoch: 10 | loss: 0.0587279\n",
      "\tspeed: 0.0554s/iter; left time: 505.4657s\n",
      "\titers: 900, epoch: 10 | loss: 0.0679491\n",
      "\tspeed: 0.0562s/iter; left time: 507.3767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:49.79s\n",
      "Steps: 902 | Train Loss: 0.0636470 Vali Loss: 0.1347284 Test Loss: 0.1531238\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04860777407884598, rmse:0.22047170996665955, mae:0.14964795112609863, rse:0.7807348966598511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2166648\n",
      "\tspeed: 0.0554s/iter; left time: 993.2199s\n",
      "\titers: 200, epoch: 1 | loss: 0.2339719\n",
      "\tspeed: 0.0559s/iter; left time: 996.5779s\n",
      "\titers: 300, epoch: 1 | loss: 0.1957048\n",
      "\tspeed: 0.0559s/iter; left time: 991.8840s\n",
      "\titers: 400, epoch: 1 | loss: 0.2040385\n",
      "\tspeed: 0.0551s/iter; left time: 971.3718s\n",
      "\titers: 500, epoch: 1 | loss: 0.2002680\n",
      "\tspeed: 0.0554s/iter; left time: 971.4095s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889003\n",
      "\tspeed: 0.0546s/iter; left time: 952.5330s\n",
      "\titers: 700, epoch: 1 | loss: 0.1814189\n",
      "\tspeed: 0.0536s/iter; left time: 930.0321s\n",
      "\titers: 800, epoch: 1 | loss: 0.1786741\n",
      "\tspeed: 0.0544s/iter; left time: 937.7319s\n",
      "\titers: 900, epoch: 1 | loss: 0.1743637\n",
      "\tspeed: 0.0552s/iter; left time: 945.7531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.71s\n",
      "Steps: 902 | Train Loss: 0.2014762 Vali Loss: 0.1856457 Test Loss: 0.2058969\n",
      "Validation loss decreased (inf --> 0.185646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1513238\n",
      "\tspeed: 0.1488s/iter; left time: 2534.6451s\n",
      "\titers: 200, epoch: 2 | loss: 0.1651270\n",
      "\tspeed: 0.0547s/iter; left time: 926.5105s\n",
      "\titers: 300, epoch: 2 | loss: 0.1447939\n",
      "\tspeed: 0.0549s/iter; left time: 924.1451s\n",
      "\titers: 400, epoch: 2 | loss: 0.1344296\n",
      "\tspeed: 0.0565s/iter; left time: 945.5339s\n",
      "\titers: 500, epoch: 2 | loss: 0.1201550\n",
      "\tspeed: 0.0556s/iter; left time: 925.3160s\n",
      "\titers: 600, epoch: 2 | loss: 0.1200757\n",
      "\tspeed: 0.0552s/iter; left time: 912.3295s\n",
      "\titers: 700, epoch: 2 | loss: 0.1214732\n",
      "\tspeed: 0.0565s/iter; left time: 929.4018s\n",
      "\titers: 800, epoch: 2 | loss: 0.1227258\n",
      "\tspeed: 0.0571s/iter; left time: 932.9366s\n",
      "\titers: 900, epoch: 2 | loss: 0.1264792\n",
      "\tspeed: 0.0565s/iter; left time: 917.1834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.71s\n",
      "Steps: 902 | Train Loss: 0.1352149 Vali Loss: 0.1446675 Test Loss: 0.1552496\n",
      "Validation loss decreased (0.185646 --> 0.144668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1231802\n",
      "\tspeed: 0.1442s/iter; left time: 2327.6570s\n",
      "\titers: 200, epoch: 3 | loss: 0.1211802\n",
      "\tspeed: 0.0531s/iter; left time: 852.3130s\n",
      "\titers: 300, epoch: 3 | loss: 0.1161199\n",
      "\tspeed: 0.0542s/iter; left time: 863.5520s\n",
      "\titers: 400, epoch: 3 | loss: 0.1170820\n",
      "\tspeed: 0.0552s/iter; left time: 873.7834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1145817\n",
      "\tspeed: 0.0540s/iter; left time: 849.1462s\n",
      "\titers: 600, epoch: 3 | loss: 0.1092131\n",
      "\tspeed: 0.0545s/iter; left time: 851.8837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1058997\n",
      "\tspeed: 0.0556s/iter; left time: 863.0891s\n",
      "\titers: 800, epoch: 3 | loss: 0.1128537\n",
      "\tspeed: 0.0537s/iter; left time: 829.0905s\n",
      "\titers: 900, epoch: 3 | loss: 0.1138040\n",
      "\tspeed: 0.0537s/iter; left time: 822.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.07s\n",
      "Steps: 902 | Train Loss: 0.1129741 Vali Loss: 0.1411677 Test Loss: 0.1493387\n",
      "Validation loss decreased (0.144668 --> 0.141168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1098315\n",
      "\tspeed: 0.1459s/iter; left time: 2223.0414s\n",
      "\titers: 200, epoch: 4 | loss: 0.0989944\n",
      "\tspeed: 0.0524s/iter; left time: 792.6422s\n",
      "\titers: 300, epoch: 4 | loss: 0.0931744\n",
      "\tspeed: 0.0528s/iter; left time: 794.5813s\n",
      "\titers: 400, epoch: 4 | loss: 0.1045861\n",
      "\tspeed: 0.0528s/iter; left time: 789.2234s\n",
      "\titers: 500, epoch: 4 | loss: 0.0985468\n",
      "\tspeed: 0.0535s/iter; left time: 793.0004s\n",
      "\titers: 600, epoch: 4 | loss: 0.0980808\n",
      "\tspeed: 0.0530s/iter; left time: 780.5440s\n",
      "\titers: 700, epoch: 4 | loss: 0.0996419\n",
      "\tspeed: 0.0555s/iter; left time: 812.7781s\n",
      "\titers: 800, epoch: 4 | loss: 0.0973174\n",
      "\tspeed: 0.0544s/iter; left time: 791.3626s\n",
      "\titers: 900, epoch: 4 | loss: 0.0998519\n",
      "\tspeed: 0.0546s/iter; left time: 788.7795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0997887 Vali Loss: 0.1349090 Test Loss: 0.1402879\n",
      "Validation loss decreased (0.141168 --> 0.134909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0962537\n",
      "\tspeed: 0.1450s/iter; left time: 2077.9396s\n",
      "\titers: 200, epoch: 5 | loss: 0.0850556\n",
      "\tspeed: 0.0540s/iter; left time: 768.6023s\n",
      "\titers: 300, epoch: 5 | loss: 0.0969836\n",
      "\tspeed: 0.0545s/iter; left time: 770.2193s\n",
      "\titers: 400, epoch: 5 | loss: 0.0904408\n",
      "\tspeed: 0.0535s/iter; left time: 751.2738s\n",
      "\titers: 500, epoch: 5 | loss: 0.0818125\n",
      "\tspeed: 0.0541s/iter; left time: 753.1949s\n",
      "\titers: 600, epoch: 5 | loss: 0.0862314\n",
      "\tspeed: 0.0537s/iter; left time: 742.1454s\n",
      "\titers: 700, epoch: 5 | loss: 0.0914021\n",
      "\tspeed: 0.0541s/iter; left time: 742.4055s\n",
      "\titers: 800, epoch: 5 | loss: 0.0877456\n",
      "\tspeed: 0.0556s/iter; left time: 758.1500s\n",
      "\titers: 900, epoch: 5 | loss: 0.0803248\n",
      "\tspeed: 0.0550s/iter; left time: 744.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.11s\n",
      "Steps: 902 | Train Loss: 0.0888418 Vali Loss: 0.1326374 Test Loss: 0.1455614\n",
      "Validation loss decreased (0.134909 --> 0.132637).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753815\n",
      "\tspeed: 0.1437s/iter; left time: 1930.0622s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821310\n",
      "\tspeed: 0.0540s/iter; left time: 720.2010s\n",
      "\titers: 300, epoch: 6 | loss: 0.0804153\n",
      "\tspeed: 0.0547s/iter; left time: 723.5463s\n",
      "\titers: 400, epoch: 6 | loss: 0.0754262\n",
      "\tspeed: 0.0562s/iter; left time: 737.6059s\n",
      "\titers: 500, epoch: 6 | loss: 0.0827585\n",
      "\tspeed: 0.0553s/iter; left time: 720.3609s\n",
      "\titers: 600, epoch: 6 | loss: 0.0791121\n",
      "\tspeed: 0.0545s/iter; left time: 704.4874s\n",
      "\titers: 700, epoch: 6 | loss: 0.0767256\n",
      "\tspeed: 0.0548s/iter; left time: 702.7476s\n",
      "\titers: 800, epoch: 6 | loss: 0.0820251\n",
      "\tspeed: 0.0555s/iter; left time: 706.5594s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813207\n",
      "\tspeed: 0.0555s/iter; left time: 701.4587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.73s\n",
      "Steps: 902 | Train Loss: 0.0820176 Vali Loss: 0.1316701 Test Loss: 0.1487080\n",
      "Validation loss decreased (0.132637 --> 0.131670).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0844795\n",
      "\tspeed: 0.1504s/iter; left time: 1883.9751s\n",
      "\titers: 200, epoch: 7 | loss: 0.0732383\n",
      "\tspeed: 0.0550s/iter; left time: 683.4636s\n",
      "\titers: 300, epoch: 7 | loss: 0.0735087\n",
      "\tspeed: 0.0570s/iter; left time: 702.8154s\n",
      "\titers: 400, epoch: 7 | loss: 0.0727343\n",
      "\tspeed: 0.0547s/iter; left time: 669.1774s\n",
      "\titers: 500, epoch: 7 | loss: 0.0786671\n",
      "\tspeed: 0.0543s/iter; left time: 658.4556s\n",
      "\titers: 600, epoch: 7 | loss: 0.0774322\n",
      "\tspeed: 0.0535s/iter; left time: 643.7039s\n",
      "\titers: 700, epoch: 7 | loss: 0.0725848\n",
      "\tspeed: 0.0539s/iter; left time: 643.4708s\n",
      "\titers: 800, epoch: 7 | loss: 0.0754771\n",
      "\tspeed: 0.0541s/iter; left time: 639.7274s\n",
      "\titers: 900, epoch: 7 | loss: 0.0715582\n",
      "\tspeed: 0.0526s/iter; left time: 617.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.59s\n",
      "Steps: 902 | Train Loss: 0.0761460 Vali Loss: 0.1307337 Test Loss: 0.1532621\n",
      "Validation loss decreased (0.131670 --> 0.130734).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0720317\n",
      "\tspeed: 0.1481s/iter; left time: 1721.4622s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759159\n",
      "\tspeed: 0.0535s/iter; left time: 616.7654s\n",
      "\titers: 300, epoch: 8 | loss: 0.0758032\n",
      "\tspeed: 0.0541s/iter; left time: 618.6473s\n",
      "\titers: 400, epoch: 8 | loss: 0.0643102\n",
      "\tspeed: 0.0536s/iter; left time: 606.7851s\n",
      "\titers: 500, epoch: 8 | loss: 0.0736005\n",
      "\tspeed: 0.0525s/iter; left time: 589.8069s\n",
      "\titers: 600, epoch: 8 | loss: 0.0730090\n",
      "\tspeed: 0.0546s/iter; left time: 607.2732s\n",
      "\titers: 700, epoch: 8 | loss: 0.0677292\n",
      "\tspeed: 0.0550s/iter; left time: 606.6055s\n",
      "\titers: 800, epoch: 8 | loss: 0.0671378\n",
      "\tspeed: 0.0536s/iter; left time: 585.3340s\n",
      "\titers: 900, epoch: 8 | loss: 0.0752704\n",
      "\tspeed: 0.0539s/iter; left time: 583.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.01s\n",
      "Steps: 902 | Train Loss: 0.0717079 Vali Loss: 0.1331291 Test Loss: 0.1536749\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663015\n",
      "\tspeed: 0.1471s/iter; left time: 1578.0465s\n",
      "\titers: 200, epoch: 9 | loss: 0.0689845\n",
      "\tspeed: 0.0563s/iter; left time: 598.4367s\n",
      "\titers: 300, epoch: 9 | loss: 0.0625833\n",
      "\tspeed: 0.0566s/iter; left time: 595.2939s\n",
      "\titers: 400, epoch: 9 | loss: 0.0733893\n",
      "\tspeed: 0.0564s/iter; left time: 588.3812s\n",
      "\titers: 500, epoch: 9 | loss: 0.0664784\n",
      "\tspeed: 0.0567s/iter; left time: 585.2451s\n",
      "\titers: 600, epoch: 9 | loss: 0.0691523\n",
      "\tspeed: 0.0571s/iter; left time: 583.3555s\n",
      "\titers: 700, epoch: 9 | loss: 0.0655821\n",
      "\tspeed: 0.0568s/iter; left time: 574.8697s\n",
      "\titers: 800, epoch: 9 | loss: 0.0681527\n",
      "\tspeed: 0.0565s/iter; left time: 566.6163s\n",
      "\titers: 900, epoch: 9 | loss: 0.0644751\n",
      "\tspeed: 0.0565s/iter; left time: 560.6616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:51.32s\n",
      "Steps: 902 | Train Loss: 0.0677233 Vali Loss: 0.1333571 Test Loss: 0.1529357\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0697708\n",
      "\tspeed: 0.1449s/iter; left time: 1422.9068s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602648\n",
      "\tspeed: 0.0572s/iter; left time: 556.2243s\n",
      "\titers: 300, epoch: 10 | loss: 0.0635448\n",
      "\tspeed: 0.0561s/iter; left time: 539.9068s\n",
      "\titers: 400, epoch: 10 | loss: 0.0652439\n",
      "\tspeed: 0.0557s/iter; left time: 530.2797s\n",
      "\titers: 500, epoch: 10 | loss: 0.0693869\n",
      "\tspeed: 0.0568s/iter; left time: 534.9445s\n",
      "\titers: 600, epoch: 10 | loss: 0.0664863\n",
      "\tspeed: 0.0570s/iter; left time: 531.7504s\n",
      "\titers: 700, epoch: 10 | loss: 0.0614513\n",
      "\tspeed: 0.0575s/iter; left time: 529.8916s\n",
      "\titers: 800, epoch: 10 | loss: 0.0657531\n",
      "\tspeed: 0.0578s/iter; left time: 527.7190s\n",
      "\titers: 900, epoch: 10 | loss: 0.0596822\n",
      "\tspeed: 0.0567s/iter; left time: 512.0498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:51.50s\n",
      "Steps: 902 | Train Loss: 0.0646153 Vali Loss: 0.1345794 Test Loss: 0.1547212\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0602282\n",
      "\tspeed: 0.1494s/iter; left time: 1332.8135s\n",
      "\titers: 200, epoch: 11 | loss: 0.0645946\n",
      "\tspeed: 0.0561s/iter; left time: 494.6909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0602183\n",
      "\tspeed: 0.0573s/iter; left time: 499.3291s\n",
      "\titers: 400, epoch: 11 | loss: 0.0670201\n",
      "\tspeed: 0.0544s/iter; left time: 468.9197s\n",
      "\titers: 500, epoch: 11 | loss: 0.0585562\n",
      "\tspeed: 0.0515s/iter; left time: 439.1460s\n",
      "\titers: 600, epoch: 11 | loss: 0.0571289\n",
      "\tspeed: 0.0562s/iter; left time: 473.4325s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642326\n",
      "\tspeed: 0.0557s/iter; left time: 463.5211s\n",
      "\titers: 800, epoch: 11 | loss: 0.0629266\n",
      "\tspeed: 0.0560s/iter; left time: 460.7442s\n",
      "\titers: 900, epoch: 11 | loss: 0.0617978\n",
      "\tspeed: 0.0568s/iter; left time: 460.9679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.77s\n",
      "Steps: 902 | Train Loss: 0.0617534 Vali Loss: 0.1359950 Test Loss: 0.1552686\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0619937\n",
      "\tspeed: 0.1429s/iter; left time: 1145.5703s\n",
      "\titers: 200, epoch: 12 | loss: 0.0652497\n",
      "\tspeed: 0.0544s/iter; left time: 430.4662s\n",
      "\titers: 300, epoch: 12 | loss: 0.0630665\n",
      "\tspeed: 0.0574s/iter; left time: 448.7369s\n",
      "\titers: 400, epoch: 12 | loss: 0.0613793\n",
      "\tspeed: 0.0567s/iter; left time: 437.5573s\n",
      "\titers: 500, epoch: 12 | loss: 0.0633681\n",
      "\tspeed: 0.0557s/iter; left time: 424.1126s\n",
      "\titers: 600, epoch: 12 | loss: 0.0587391\n",
      "\tspeed: 0.0562s/iter; left time: 422.6851s\n",
      "\titers: 700, epoch: 12 | loss: 0.0555099\n",
      "\tspeed: 0.0529s/iter; left time: 392.6429s\n",
      "\titers: 800, epoch: 12 | loss: 0.0544283\n",
      "\tspeed: 0.0514s/iter; left time: 376.5275s\n",
      "\titers: 900, epoch: 12 | loss: 0.0573106\n",
      "\tspeed: 0.0571s/iter; left time: 412.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:49.92s\n",
      "Steps: 902 | Train Loss: 0.0593499 Vali Loss: 0.1346128 Test Loss: 0.1541362\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05066155269742012, rmse:0.22508122026920319, mae:0.1532352715730667, rse:0.79705810546875\n",
      "Intermediate time for DE and pred_len 96: 00h:21m:44.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2255170\n",
      "\tspeed: 0.0896s/iter; left time: 1603.4448s\n",
      "\titers: 200, epoch: 1 | loss: 0.2059096\n",
      "\tspeed: 0.0642s/iter; left time: 1141.9491s\n",
      "\titers: 300, epoch: 1 | loss: 0.1958352\n",
      "\tspeed: 0.0632s/iter; left time: 1118.2205s\n",
      "\titers: 400, epoch: 1 | loss: 0.1891863\n",
      "\tspeed: 0.0642s/iter; left time: 1130.3772s\n",
      "\titers: 500, epoch: 1 | loss: 0.1818429\n",
      "\tspeed: 0.0643s/iter; left time: 1124.4844s\n",
      "\titers: 600, epoch: 1 | loss: 0.1825969\n",
      "\tspeed: 0.0651s/iter; left time: 1132.1681s\n",
      "\titers: 700, epoch: 1 | loss: 0.1811278\n",
      "\tspeed: 0.0650s/iter; left time: 1124.0621s\n",
      "\titers: 800, epoch: 1 | loss: 0.1870752\n",
      "\tspeed: 0.0651s/iter; left time: 1119.9352s\n",
      "\titers: 900, epoch: 1 | loss: 0.1748883\n",
      "\tspeed: 0.0660s/iter; left time: 1129.2248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:58.82s\n",
      "Steps: 900 | Train Loss: 0.1976630 Vali Loss: 0.1813300 Test Loss: 0.2045474\n",
      "Validation loss decreased (inf --> 0.181330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1563487\n",
      "\tspeed: 0.1864s/iter; left time: 3169.2338s\n",
      "\titers: 200, epoch: 2 | loss: 0.1411136\n",
      "\tspeed: 0.0644s/iter; left time: 1087.7874s\n",
      "\titers: 300, epoch: 2 | loss: 0.1527991\n",
      "\tspeed: 0.0662s/iter; left time: 1112.7419s\n",
      "\titers: 400, epoch: 2 | loss: 0.1438824\n",
      "\tspeed: 0.0651s/iter; left time: 1086.8012s\n",
      "\titers: 500, epoch: 2 | loss: 0.1451540\n",
      "\tspeed: 0.0658s/iter; left time: 1092.7563s\n",
      "\titers: 600, epoch: 2 | loss: 0.1340269\n",
      "\tspeed: 0.0658s/iter; left time: 1085.0708s\n",
      "\titers: 700, epoch: 2 | loss: 0.1359645\n",
      "\tspeed: 0.0656s/iter; left time: 1075.3427s\n",
      "\titers: 800, epoch: 2 | loss: 0.1341632\n",
      "\tspeed: 0.0654s/iter; left time: 1066.3429s\n",
      "\titers: 900, epoch: 2 | loss: 0.1322074\n",
      "\tspeed: 0.0652s/iter; left time: 1056.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.05s\n",
      "Steps: 900 | Train Loss: 0.1469673 Vali Loss: 0.1628606 Test Loss: 0.1807185\n",
      "Validation loss decreased (0.181330 --> 0.162861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1221905\n",
      "\tspeed: 0.1843s/iter; left time: 2967.9751s\n",
      "\titers: 200, epoch: 3 | loss: 0.1322021\n",
      "\tspeed: 0.0636s/iter; left time: 1017.2737s\n",
      "\titers: 300, epoch: 3 | loss: 0.1298812\n",
      "\tspeed: 0.0627s/iter; left time: 996.2012s\n",
      "\titers: 400, epoch: 3 | loss: 0.1174322\n",
      "\tspeed: 0.0657s/iter; left time: 1037.8492s\n",
      "\titers: 500, epoch: 3 | loss: 0.1210935\n",
      "\tspeed: 0.0635s/iter; left time: 996.5367s\n",
      "\titers: 600, epoch: 3 | loss: 0.1236893\n",
      "\tspeed: 0.0657s/iter; left time: 1024.9459s\n",
      "\titers: 700, epoch: 3 | loss: 0.1175467\n",
      "\tspeed: 0.0651s/iter; left time: 1008.5685s\n",
      "\titers: 800, epoch: 3 | loss: 0.1138206\n",
      "\tspeed: 0.0660s/iter; left time: 1017.1954s\n",
      "\titers: 900, epoch: 3 | loss: 0.1131205\n",
      "\tspeed: 0.0664s/iter; left time: 1016.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:58.37s\n",
      "Steps: 900 | Train Loss: 0.1268601 Vali Loss: 0.1577150 Test Loss: 0.1744126\n",
      "Validation loss decreased (0.162861 --> 0.157715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1136265\n",
      "\tspeed: 0.1823s/iter; left time: 2771.5009s\n",
      "\titers: 200, epoch: 4 | loss: 0.1177413\n",
      "\tspeed: 0.0643s/iter; left time: 971.6486s\n",
      "\titers: 300, epoch: 4 | loss: 0.1124447\n",
      "\tspeed: 0.0648s/iter; left time: 971.4177s\n",
      "\titers: 400, epoch: 4 | loss: 0.1085952\n",
      "\tspeed: 0.0652s/iter; left time: 971.8701s\n",
      "\titers: 500, epoch: 4 | loss: 0.1118137\n",
      "\tspeed: 0.0651s/iter; left time: 963.5887s\n",
      "\titers: 600, epoch: 4 | loss: 0.1055949\n",
      "\tspeed: 0.0640s/iter; left time: 940.8298s\n",
      "\titers: 700, epoch: 4 | loss: 0.1053388\n",
      "\tspeed: 0.0664s/iter; left time: 969.6390s\n",
      "\titers: 800, epoch: 4 | loss: 0.1030196\n",
      "\tspeed: 0.0637s/iter; left time: 923.7077s\n",
      "\titers: 900, epoch: 4 | loss: 0.0913839\n",
      "\tspeed: 0.0647s/iter; left time: 931.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:58.55s\n",
      "Steps: 900 | Train Loss: 0.1093702 Vali Loss: 0.1400090 Test Loss: 0.1518710\n",
      "Validation loss decreased (0.157715 --> 0.140009).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0927284\n",
      "\tspeed: 0.1806s/iter; left time: 2582.4519s\n",
      "\titers: 200, epoch: 5 | loss: 0.0969267\n",
      "\tspeed: 0.0634s/iter; left time: 900.3348s\n",
      "\titers: 300, epoch: 5 | loss: 0.0976806\n",
      "\tspeed: 0.0653s/iter; left time: 921.1413s\n",
      "\titers: 400, epoch: 5 | loss: 0.0988316\n",
      "\tspeed: 0.0653s/iter; left time: 914.8898s\n",
      "\titers: 500, epoch: 5 | loss: 0.0891098\n",
      "\tspeed: 0.0644s/iter; left time: 895.5265s\n",
      "\titers: 600, epoch: 5 | loss: 0.0892049\n",
      "\tspeed: 0.0633s/iter; left time: 873.9840s\n",
      "\titers: 700, epoch: 5 | loss: 0.0920647\n",
      "\tspeed: 0.0637s/iter; left time: 872.5018s\n",
      "\titers: 800, epoch: 5 | loss: 0.0923700\n",
      "\tspeed: 0.0657s/iter; left time: 894.1905s\n",
      "\titers: 900, epoch: 5 | loss: 0.0862480\n",
      "\tspeed: 0.0643s/iter; left time: 867.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:58.31s\n",
      "Steps: 900 | Train Loss: 0.0936963 Vali Loss: 0.1457023 Test Loss: 0.1593460\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863292\n",
      "\tspeed: 0.1681s/iter; left time: 2252.7256s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899479\n",
      "\tspeed: 0.0665s/iter; left time: 884.1411s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834917\n",
      "\tspeed: 0.0655s/iter; left time: 864.5882s\n",
      "\titers: 400, epoch: 6 | loss: 0.0860795\n",
      "\tspeed: 0.0665s/iter; left time: 871.4637s\n",
      "\titers: 500, epoch: 6 | loss: 0.0879506\n",
      "\tspeed: 0.0668s/iter; left time: 868.1656s\n",
      "\titers: 600, epoch: 6 | loss: 0.0915340\n",
      "\tspeed: 0.0646s/iter; left time: 833.8766s\n",
      "\titers: 700, epoch: 6 | loss: 0.0901183\n",
      "\tspeed: 0.0661s/iter; left time: 846.6321s\n",
      "\titers: 800, epoch: 6 | loss: 0.0807287\n",
      "\tspeed: 0.0649s/iter; left time: 824.9176s\n",
      "\titers: 900, epoch: 6 | loss: 0.0855452\n",
      "\tspeed: 0.0638s/iter; left time: 804.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.17s\n",
      "Steps: 900 | Train Loss: 0.0861249 Vali Loss: 0.1411349 Test Loss: 0.1582988\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811576\n",
      "\tspeed: 0.1813s/iter; left time: 2266.1928s\n",
      "\titers: 200, epoch: 7 | loss: 0.0792983\n",
      "\tspeed: 0.0668s/iter; left time: 828.5655s\n",
      "\titers: 300, epoch: 7 | loss: 0.0849173\n",
      "\tspeed: 0.0664s/iter; left time: 817.1776s\n",
      "\titers: 400, epoch: 7 | loss: 0.0871877\n",
      "\tspeed: 0.0657s/iter; left time: 801.2313s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828704\n",
      "\tspeed: 0.0665s/iter; left time: 804.1191s\n",
      "\titers: 600, epoch: 7 | loss: 0.0800992\n",
      "\tspeed: 0.0660s/iter; left time: 792.0529s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772918\n",
      "\tspeed: 0.0665s/iter; left time: 791.2739s\n",
      "\titers: 800, epoch: 7 | loss: 0.0775815\n",
      "\tspeed: 0.0652s/iter; left time: 769.6862s\n",
      "\titers: 900, epoch: 7 | loss: 0.0819519\n",
      "\tspeed: 0.0633s/iter; left time: 740.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:59.49s\n",
      "Steps: 900 | Train Loss: 0.0804645 Vali Loss: 0.1403205 Test Loss: 0.1570558\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0819610\n",
      "\tspeed: 0.1822s/iter; left time: 2113.6654s\n",
      "\titers: 200, epoch: 8 | loss: 0.0769638\n",
      "\tspeed: 0.0659s/iter; left time: 757.7242s\n",
      "\titers: 300, epoch: 8 | loss: 0.0721022\n",
      "\tspeed: 0.0664s/iter; left time: 757.4723s\n",
      "\titers: 400, epoch: 8 | loss: 0.0750791\n",
      "\tspeed: 0.0647s/iter; left time: 730.6567s\n",
      "\titers: 500, epoch: 8 | loss: 0.0703196\n",
      "\tspeed: 0.0658s/iter; left time: 737.1624s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739911\n",
      "\tspeed: 0.0650s/iter; left time: 721.9799s\n",
      "\titers: 700, epoch: 8 | loss: 0.0764393\n",
      "\tspeed: 0.0658s/iter; left time: 723.7267s\n",
      "\titers: 800, epoch: 8 | loss: 0.0729751\n",
      "\tspeed: 0.0669s/iter; left time: 728.8318s\n",
      "\titers: 900, epoch: 8 | loss: 0.0688019\n",
      "\tspeed: 0.0657s/iter; left time: 709.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:59.62s\n",
      "Steps: 900 | Train Loss: 0.0756521 Vali Loss: 0.1396848 Test Loss: 0.1587400\n",
      "Validation loss decreased (0.140009 --> 0.139685).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726451\n",
      "\tspeed: 0.1854s/iter; left time: 1983.9818s\n",
      "\titers: 200, epoch: 9 | loss: 0.0752377\n",
      "\tspeed: 0.0651s/iter; left time: 689.9870s\n",
      "\titers: 300, epoch: 9 | loss: 0.0693751\n",
      "\tspeed: 0.0646s/iter; left time: 678.7915s\n",
      "\titers: 400, epoch: 9 | loss: 0.0690043\n",
      "\tspeed: 0.0659s/iter; left time: 685.0982s\n",
      "\titers: 500, epoch: 9 | loss: 0.0743333\n",
      "\tspeed: 0.0653s/iter; left time: 673.0330s\n",
      "\titers: 600, epoch: 9 | loss: 0.0679046\n",
      "\tspeed: 0.0648s/iter; left time: 661.0085s\n",
      "\titers: 700, epoch: 9 | loss: 0.0715082\n",
      "\tspeed: 0.0658s/iter; left time: 664.2687s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671733\n",
      "\tspeed: 0.0660s/iter; left time: 660.2419s\n",
      "\titers: 900, epoch: 9 | loss: 0.0711839\n",
      "\tspeed: 0.0658s/iter; left time: 651.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:58.83s\n",
      "Steps: 900 | Train Loss: 0.0714859 Vali Loss: 0.1447973 Test Loss: 0.1617423\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666629\n",
      "\tspeed: 0.1790s/iter; left time: 1754.3596s\n",
      "\titers: 200, epoch: 10 | loss: 0.0707817\n",
      "\tspeed: 0.0663s/iter; left time: 642.9940s\n",
      "\titers: 300, epoch: 10 | loss: 0.0662896\n",
      "\tspeed: 0.0666s/iter; left time: 639.4648s\n",
      "\titers: 400, epoch: 10 | loss: 0.0708178\n",
      "\tspeed: 0.0654s/iter; left time: 621.1732s\n",
      "\titers: 500, epoch: 10 | loss: 0.0664254\n",
      "\tspeed: 0.0648s/iter; left time: 609.5654s\n",
      "\titers: 600, epoch: 10 | loss: 0.0673639\n",
      "\tspeed: 0.0654s/iter; left time: 608.4276s\n",
      "\titers: 700, epoch: 10 | loss: 0.0692174\n",
      "\tspeed: 0.0653s/iter; left time: 600.6494s\n",
      "\titers: 800, epoch: 10 | loss: 0.0652858\n",
      "\tspeed: 0.0652s/iter; left time: 593.5573s\n",
      "\titers: 900, epoch: 10 | loss: 0.0705820\n",
      "\tspeed: 0.0653s/iter; left time: 588.1298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:59.40s\n",
      "Steps: 900 | Train Loss: 0.0679956 Vali Loss: 0.1421618 Test Loss: 0.1608536\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0638020\n",
      "\tspeed: 0.1815s/iter; left time: 1615.7745s\n",
      "\titers: 200, epoch: 11 | loss: 0.0624168\n",
      "\tspeed: 0.0650s/iter; left time: 572.1573s\n",
      "\titers: 300, epoch: 11 | loss: 0.0654209\n",
      "\tspeed: 0.0669s/iter; left time: 581.7310s\n",
      "\titers: 400, epoch: 11 | loss: 0.0631085\n",
      "\tspeed: 0.0651s/iter; left time: 560.2017s\n",
      "\titers: 500, epoch: 11 | loss: 0.0632962\n",
      "\tspeed: 0.0666s/iter; left time: 566.0914s\n",
      "\titers: 600, epoch: 11 | loss: 0.0682882\n",
      "\tspeed: 0.0663s/iter; left time: 556.5718s\n",
      "\titers: 700, epoch: 11 | loss: 0.0688747\n",
      "\tspeed: 0.0667s/iter; left time: 553.3496s\n",
      "\titers: 800, epoch: 11 | loss: 0.0653549\n",
      "\tspeed: 0.0644s/iter; left time: 527.8551s\n",
      "\titers: 900, epoch: 11 | loss: 0.0651225\n",
      "\tspeed: 0.0628s/iter; left time: 508.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:59.31s\n",
      "Steps: 900 | Train Loss: 0.0653641 Vali Loss: 0.1439455 Test Loss: 0.1629165\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0648170\n",
      "\tspeed: 0.1800s/iter; left time: 1440.1215s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628268\n",
      "\tspeed: 0.0657s/iter; left time: 519.0961s\n",
      "\titers: 300, epoch: 12 | loss: 0.0675197\n",
      "\tspeed: 0.0648s/iter; left time: 505.3221s\n",
      "\titers: 400, epoch: 12 | loss: 0.0623434\n",
      "\tspeed: 0.0650s/iter; left time: 500.5878s\n",
      "\titers: 500, epoch: 12 | loss: 0.0669292\n",
      "\tspeed: 0.0639s/iter; left time: 485.6707s\n",
      "\titers: 600, epoch: 12 | loss: 0.0625783\n",
      "\tspeed: 0.0652s/iter; left time: 489.2274s\n",
      "\titers: 700, epoch: 12 | loss: 0.0630603\n",
      "\tspeed: 0.0644s/iter; left time: 476.8697s\n",
      "\titers: 800, epoch: 12 | loss: 0.0641293\n",
      "\tspeed: 0.0654s/iter; left time: 477.6327s\n",
      "\titers: 900, epoch: 12 | loss: 0.0577660\n",
      "\tspeed: 0.0646s/iter; left time: 465.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:58.88s\n",
      "Steps: 900 | Train Loss: 0.0629123 Vali Loss: 0.1438857 Test Loss: 0.1632325\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0588770\n",
      "\tspeed: 0.1781s/iter; left time: 1264.3433s\n",
      "\titers: 200, epoch: 13 | loss: 0.0601917\n",
      "\tspeed: 0.0656s/iter; left time: 459.4123s\n",
      "\titers: 300, epoch: 13 | loss: 0.0629294\n",
      "\tspeed: 0.0645s/iter; left time: 445.3698s\n",
      "\titers: 400, epoch: 13 | loss: 0.0605012\n",
      "\tspeed: 0.0633s/iter; left time: 430.6886s\n",
      "\titers: 500, epoch: 13 | loss: 0.0602354\n",
      "\tspeed: 0.0640s/iter; left time: 429.1620s\n",
      "\titers: 600, epoch: 13 | loss: 0.0605153\n",
      "\tspeed: 0.0638s/iter; left time: 420.9005s\n",
      "\titers: 700, epoch: 13 | loss: 0.0622508\n",
      "\tspeed: 0.0652s/iter; left time: 423.8229s\n",
      "\titers: 800, epoch: 13 | loss: 0.0612226\n",
      "\tspeed: 0.0639s/iter; left time: 408.8887s\n",
      "\titers: 900, epoch: 13 | loss: 0.0623229\n",
      "\tspeed: 0.0645s/iter; left time: 406.3166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:58.14s\n",
      "Steps: 900 | Train Loss: 0.0608280 Vali Loss: 0.1441038 Test Loss: 0.1619980\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.054843734949827194, rmse:0.23418739438056946, mae:0.15871629118919373, rse:0.8296554088592529\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2144062\n",
      "\tspeed: 0.0658s/iter; left time: 1178.7803s\n",
      "\titers: 200, epoch: 1 | loss: 0.2138640\n",
      "\tspeed: 0.0651s/iter; left time: 1158.8635s\n",
      "\titers: 300, epoch: 1 | loss: 0.2094172\n",
      "\tspeed: 0.0640s/iter; left time: 1132.2335s\n",
      "\titers: 400, epoch: 1 | loss: 0.1991727\n",
      "\tspeed: 0.0661s/iter; left time: 1163.8520s\n",
      "\titers: 500, epoch: 1 | loss: 0.1829026\n",
      "\tspeed: 0.0647s/iter; left time: 1131.8165s\n",
      "\titers: 600, epoch: 1 | loss: 0.1889913\n",
      "\tspeed: 0.0668s/iter; left time: 1163.1990s\n",
      "\titers: 700, epoch: 1 | loss: 0.1858875\n",
      "\tspeed: 0.0645s/iter; left time: 1115.5501s\n",
      "\titers: 800, epoch: 1 | loss: 0.1800248\n",
      "\tspeed: 0.0646s/iter; left time: 1110.5193s\n",
      "\titers: 900, epoch: 1 | loss: 0.1890033\n",
      "\tspeed: 0.0642s/iter; left time: 1097.5743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:58.66s\n",
      "Steps: 900 | Train Loss: 0.1983928 Vali Loss: 0.1816392 Test Loss: 0.2058317\n",
      "Validation loss decreased (inf --> 0.181639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652600\n",
      "\tspeed: 0.1787s/iter; left time: 3038.1906s\n",
      "\titers: 200, epoch: 2 | loss: 0.1524051\n",
      "\tspeed: 0.0656s/iter; left time: 1107.8872s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521987\n",
      "\tspeed: 0.0656s/iter; left time: 1102.0596s\n",
      "\titers: 400, epoch: 2 | loss: 0.1480678\n",
      "\tspeed: 0.0664s/iter; left time: 1109.6047s\n",
      "\titers: 500, epoch: 2 | loss: 0.1459770\n",
      "\tspeed: 0.0661s/iter; left time: 1097.3832s\n",
      "\titers: 600, epoch: 2 | loss: 0.1458276\n",
      "\tspeed: 0.0646s/iter; left time: 1066.3664s\n",
      "\titers: 700, epoch: 2 | loss: 0.1443732\n",
      "\tspeed: 0.0635s/iter; left time: 1041.4372s\n",
      "\titers: 800, epoch: 2 | loss: 0.1381532\n",
      "\tspeed: 0.0661s/iter; left time: 1078.1236s\n",
      "\titers: 900, epoch: 2 | loss: 0.1384155\n",
      "\tspeed: 0.0654s/iter; left time: 1058.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.12s\n",
      "Steps: 900 | Train Loss: 0.1486239 Vali Loss: 0.1700586 Test Loss: 0.1860849\n",
      "Validation loss decreased (0.181639 --> 0.170059).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1394230\n",
      "\tspeed: 0.1814s/iter; left time: 2920.1307s\n",
      "\titers: 200, epoch: 3 | loss: 0.1385765\n",
      "\tspeed: 0.0640s/iter; left time: 1024.1047s\n",
      "\titers: 300, epoch: 3 | loss: 0.1406029\n",
      "\tspeed: 0.0657s/iter; left time: 1044.4672s\n",
      "\titers: 400, epoch: 3 | loss: 0.1218038\n",
      "\tspeed: 0.0663s/iter; left time: 1048.2092s\n",
      "\titers: 500, epoch: 3 | loss: 0.1222646\n",
      "\tspeed: 0.0664s/iter; left time: 1042.0560s\n",
      "\titers: 600, epoch: 3 | loss: 0.1321568\n",
      "\tspeed: 0.0653s/iter; left time: 1018.9944s\n",
      "\titers: 700, epoch: 3 | loss: 0.1224354\n",
      "\tspeed: 0.0645s/iter; left time: 999.5177s\n",
      "\titers: 800, epoch: 3 | loss: 0.1376793\n",
      "\tspeed: 0.0653s/iter; left time: 1006.2392s\n",
      "\titers: 900, epoch: 3 | loss: 0.1324727\n",
      "\tspeed: 0.0653s/iter; left time: 998.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:59.00s\n",
      "Steps: 900 | Train Loss: 0.1306322 Vali Loss: 0.1650465 Test Loss: 0.1808047\n",
      "Validation loss decreased (0.170059 --> 0.165046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1327639\n",
      "\tspeed: 0.1822s/iter; left time: 2769.8117s\n",
      "\titers: 200, epoch: 4 | loss: 0.1123419\n",
      "\tspeed: 0.0655s/iter; left time: 988.8483s\n",
      "\titers: 300, epoch: 4 | loss: 0.1146452\n",
      "\tspeed: 0.0655s/iter; left time: 982.3768s\n",
      "\titers: 400, epoch: 4 | loss: 0.1171540\n",
      "\tspeed: 0.0653s/iter; left time: 973.1447s\n",
      "\titers: 500, epoch: 4 | loss: 0.1049273\n",
      "\tspeed: 0.0644s/iter; left time: 953.8194s\n",
      "\titers: 600, epoch: 4 | loss: 0.0954302\n",
      "\tspeed: 0.0633s/iter; left time: 930.9059s\n",
      "\titers: 700, epoch: 4 | loss: 0.0977083\n",
      "\tspeed: 0.0664s/iter; left time: 969.6277s\n",
      "\titers: 800, epoch: 4 | loss: 0.0976162\n",
      "\tspeed: 0.0656s/iter; left time: 951.6502s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973527\n",
      "\tspeed: 0.0653s/iter; left time: 940.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:58.97s\n",
      "Steps: 900 | Train Loss: 0.1100896 Vali Loss: 0.1459516 Test Loss: 0.1601590\n",
      "Validation loss decreased (0.165046 --> 0.145952).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0945781\n",
      "\tspeed: 0.1819s/iter; left time: 2601.4321s\n",
      "\titers: 200, epoch: 5 | loss: 0.0911780\n",
      "\tspeed: 0.0653s/iter; left time: 927.3713s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986132\n",
      "\tspeed: 0.0645s/iter; left time: 909.4385s\n",
      "\titers: 400, epoch: 5 | loss: 0.0943438\n",
      "\tspeed: 0.0646s/iter; left time: 904.2992s\n",
      "\titers: 500, epoch: 5 | loss: 0.0924283\n",
      "\tspeed: 0.0643s/iter; left time: 893.2806s\n",
      "\titers: 600, epoch: 5 | loss: 0.0997703\n",
      "\tspeed: 0.0664s/iter; left time: 916.1731s\n",
      "\titers: 700, epoch: 5 | loss: 0.0857699\n",
      "\tspeed: 0.0654s/iter; left time: 896.4792s\n",
      "\titers: 800, epoch: 5 | loss: 0.0972013\n",
      "\tspeed: 0.0642s/iter; left time: 873.6662s\n",
      "\titers: 900, epoch: 5 | loss: 0.0912874\n",
      "\tspeed: 0.0647s/iter; left time: 873.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:58.71s\n",
      "Steps: 900 | Train Loss: 0.0931103 Vali Loss: 0.1427651 Test Loss: 0.1565604\n",
      "Validation loss decreased (0.145952 --> 0.142765).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0881764\n",
      "\tspeed: 0.1795s/iter; left time: 2405.6096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0916909\n",
      "\tspeed: 0.0655s/iter; left time: 871.2435s\n",
      "\titers: 300, epoch: 6 | loss: 0.0830245\n",
      "\tspeed: 0.0646s/iter; left time: 853.2066s\n",
      "\titers: 400, epoch: 6 | loss: 0.0873382\n",
      "\tspeed: 0.0645s/iter; left time: 845.5424s\n",
      "\titers: 500, epoch: 6 | loss: 0.0815635\n",
      "\tspeed: 0.0638s/iter; left time: 829.1465s\n",
      "\titers: 600, epoch: 6 | loss: 0.0847429\n",
      "\tspeed: 0.0645s/iter; left time: 831.9752s\n",
      "\titers: 700, epoch: 6 | loss: 0.0881425\n",
      "\tspeed: 0.0642s/iter; left time: 821.4207s\n",
      "\titers: 800, epoch: 6 | loss: 0.0814757\n",
      "\tspeed: 0.0656s/iter; left time: 833.7478s\n",
      "\titers: 900, epoch: 6 | loss: 0.0811814\n",
      "\tspeed: 0.0650s/iter; left time: 818.5496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:58.52s\n",
      "Steps: 900 | Train Loss: 0.0853527 Vali Loss: 0.1464835 Test Loss: 0.1625535\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0820318\n",
      "\tspeed: 0.1816s/iter; left time: 2270.1224s\n",
      "\titers: 200, epoch: 7 | loss: 0.0842571\n",
      "\tspeed: 0.0659s/iter; left time: 817.6013s\n",
      "\titers: 300, epoch: 7 | loss: 0.0835595\n",
      "\tspeed: 0.0646s/iter; left time: 794.5930s\n",
      "\titers: 400, epoch: 7 | loss: 0.0795505\n",
      "\tspeed: 0.0641s/iter; left time: 782.6754s\n",
      "\titers: 500, epoch: 7 | loss: 0.0834926\n",
      "\tspeed: 0.0651s/iter; left time: 787.2999s\n",
      "\titers: 600, epoch: 7 | loss: 0.0798074\n",
      "\tspeed: 0.0650s/iter; left time: 780.3102s\n",
      "\titers: 700, epoch: 7 | loss: 0.0768181\n",
      "\tspeed: 0.0639s/iter; left time: 760.6275s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783471\n",
      "\tspeed: 0.0649s/iter; left time: 766.2951s\n",
      "\titers: 900, epoch: 7 | loss: 0.0747181\n",
      "\tspeed: 0.0651s/iter; left time: 762.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:58.85s\n",
      "Steps: 900 | Train Loss: 0.0797811 Vali Loss: 0.1463099 Test Loss: 0.1653899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0762795\n",
      "\tspeed: 0.1707s/iter; left time: 1979.8413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747696\n",
      "\tspeed: 0.0648s/iter; left time: 745.3735s\n",
      "\titers: 300, epoch: 8 | loss: 0.0726468\n",
      "\tspeed: 0.0652s/iter; left time: 742.8927s\n",
      "\titers: 400, epoch: 8 | loss: 0.0755420\n",
      "\tspeed: 0.0647s/iter; left time: 731.3962s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767261\n",
      "\tspeed: 0.0648s/iter; left time: 726.3538s\n",
      "\titers: 600, epoch: 8 | loss: 0.0754001\n",
      "\tspeed: 0.0636s/iter; left time: 706.1323s\n",
      "\titers: 700, epoch: 8 | loss: 0.0770668\n",
      "\tspeed: 0.0650s/iter; left time: 715.4267s\n",
      "\titers: 800, epoch: 8 | loss: 0.0737558\n",
      "\tspeed: 0.0643s/iter; left time: 700.9949s\n",
      "\titers: 900, epoch: 8 | loss: 0.0759718\n",
      "\tspeed: 0.0644s/iter; left time: 695.0622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:58.43s\n",
      "Steps: 900 | Train Loss: 0.0747951 Vali Loss: 0.1475625 Test Loss: 0.1637713\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685221\n",
      "\tspeed: 0.1787s/iter; left time: 1912.2224s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757452\n",
      "\tspeed: 0.0635s/iter; left time: 672.8322s\n",
      "\titers: 300, epoch: 9 | loss: 0.0725937\n",
      "\tspeed: 0.0648s/iter; left time: 680.4624s\n",
      "\titers: 400, epoch: 9 | loss: 0.0698028\n",
      "\tspeed: 0.0651s/iter; left time: 676.7747s\n",
      "\titers: 500, epoch: 9 | loss: 0.0758598\n",
      "\tspeed: 0.0646s/iter; left time: 664.9619s\n",
      "\titers: 600, epoch: 9 | loss: 0.0697028\n",
      "\tspeed: 0.0655s/iter; left time: 668.5146s\n",
      "\titers: 700, epoch: 9 | loss: 0.0734540\n",
      "\tspeed: 0.0653s/iter; left time: 659.6233s\n",
      "\titers: 800, epoch: 9 | loss: 0.0730666\n",
      "\tspeed: 0.0644s/iter; left time: 644.4919s\n",
      "\titers: 900, epoch: 9 | loss: 0.0664153\n",
      "\tspeed: 0.0638s/iter; left time: 631.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:58.54s\n",
      "Steps: 900 | Train Loss: 0.0702578 Vali Loss: 0.1483249 Test Loss: 0.1638586\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0705698\n",
      "\tspeed: 0.1769s/iter; left time: 1734.1457s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685203\n",
      "\tspeed: 0.0657s/iter; left time: 637.4885s\n",
      "\titers: 300, epoch: 10 | loss: 0.0691121\n",
      "\tspeed: 0.0658s/iter; left time: 631.3954s\n",
      "\titers: 400, epoch: 10 | loss: 0.0646251\n",
      "\tspeed: 0.0642s/iter; left time: 610.2727s\n",
      "\titers: 500, epoch: 10 | loss: 0.0663128\n",
      "\tspeed: 0.0643s/iter; left time: 604.3569s\n",
      "\titers: 600, epoch: 10 | loss: 0.0617870\n",
      "\tspeed: 0.0642s/iter; left time: 597.4891s\n",
      "\titers: 700, epoch: 10 | loss: 0.0623595\n",
      "\tspeed: 0.0648s/iter; left time: 595.8509s\n",
      "\titers: 800, epoch: 10 | loss: 0.0649806\n",
      "\tspeed: 0.0635s/iter; left time: 578.2118s\n",
      "\titers: 900, epoch: 10 | loss: 0.0664130\n",
      "\tspeed: 0.0647s/iter; left time: 582.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:58.42s\n",
      "Steps: 900 | Train Loss: 0.0667501 Vali Loss: 0.1465896 Test Loss: 0.1636302\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05288044735789299, rmse:0.2299574911594391, mae:0.15663425624370575, rse:0.814670205116272\n",
      "Intermediate time for DE and pred_len 168: 00h:27m:16.35s\n",
      "Intermediate time for DE: 01h:06m:38.83s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2326199\n",
      "\tspeed: 0.0732s/iter; left time: 1315.8850s\n",
      "\titers: 200, epoch: 1 | loss: 0.1824483\n",
      "\tspeed: 0.0498s/iter; left time: 889.9872s\n",
      "\titers: 300, epoch: 1 | loss: 0.1948155\n",
      "\tspeed: 0.0516s/iter; left time: 918.3067s\n",
      "\titers: 400, epoch: 1 | loss: 0.1782602\n",
      "\tspeed: 0.0506s/iter; left time: 893.9125s\n",
      "\titers: 500, epoch: 1 | loss: 0.1681294\n",
      "\tspeed: 0.0488s/iter; left time: 857.8395s\n",
      "\titers: 600, epoch: 1 | loss: 0.1680969\n",
      "\tspeed: 0.0484s/iter; left time: 846.5905s\n",
      "\titers: 700, epoch: 1 | loss: 0.1612779\n",
      "\tspeed: 0.0496s/iter; left time: 862.0048s\n",
      "\titers: 800, epoch: 1 | loss: 0.1540695\n",
      "\tspeed: 0.0481s/iter; left time: 830.4096s\n",
      "\titers: 900, epoch: 1 | loss: 0.1490149\n",
      "\tspeed: 0.0492s/iter; left time: 845.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.41s\n",
      "Steps: 904 | Train Loss: 0.1838433 Vali Loss: 0.1515446 Test Loss: 0.1820621\n",
      "Validation loss decreased (inf --> 0.151545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349918\n",
      "\tspeed: 0.1331s/iter; left time: 2272.9697s\n",
      "\titers: 200, epoch: 2 | loss: 0.1197643\n",
      "\tspeed: 0.0485s/iter; left time: 824.0008s\n",
      "\titers: 300, epoch: 2 | loss: 0.1094916\n",
      "\tspeed: 0.0492s/iter; left time: 831.1291s\n",
      "\titers: 400, epoch: 2 | loss: 0.1316161\n",
      "\tspeed: 0.0496s/iter; left time: 831.4760s\n",
      "\titers: 500, epoch: 2 | loss: 0.1007180\n",
      "\tspeed: 0.0474s/iter; left time: 790.7504s\n",
      "\titers: 600, epoch: 2 | loss: 0.1117829\n",
      "\tspeed: 0.0498s/iter; left time: 824.9514s\n",
      "\titers: 700, epoch: 2 | loss: 0.1025623\n",
      "\tspeed: 0.0496s/iter; left time: 817.2147s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075049\n",
      "\tspeed: 0.0483s/iter; left time: 790.3254s\n",
      "\titers: 900, epoch: 2 | loss: 0.1004276\n",
      "\tspeed: 0.0498s/iter; left time: 811.2711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.56s\n",
      "Steps: 904 | Train Loss: 0.1135365 Vali Loss: 0.1241810 Test Loss: 0.1506613\n",
      "Validation loss decreased (0.151545 --> 0.124181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1125885\n",
      "\tspeed: 0.1334s/iter; left time: 2156.8812s\n",
      "\titers: 200, epoch: 3 | loss: 0.1124380\n",
      "\tspeed: 0.0512s/iter; left time: 823.3623s\n",
      "\titers: 300, epoch: 3 | loss: 0.1164487\n",
      "\tspeed: 0.0503s/iter; left time: 803.9956s\n",
      "\titers: 400, epoch: 3 | loss: 0.0961406\n",
      "\tspeed: 0.0486s/iter; left time: 771.8406s\n",
      "\titers: 500, epoch: 3 | loss: 0.1025523\n",
      "\tspeed: 0.0486s/iter; left time: 766.9952s\n",
      "\titers: 600, epoch: 3 | loss: 0.1087661\n",
      "\tspeed: 0.0475s/iter; left time: 743.8362s\n",
      "\titers: 700, epoch: 3 | loss: 0.0990965\n",
      "\tspeed: 0.0490s/iter; left time: 762.7502s\n",
      "\titers: 800, epoch: 3 | loss: 0.0940358\n",
      "\tspeed: 0.0504s/iter; left time: 780.0334s\n",
      "\titers: 900, epoch: 3 | loss: 0.0863000\n",
      "\tspeed: 0.0495s/iter; left time: 760.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 904 | Train Loss: 0.0995454 Vali Loss: 0.1162291 Test Loss: 0.1405950\n",
      "Validation loss decreased (0.124181 --> 0.116229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1042208\n",
      "\tspeed: 0.1326s/iter; left time: 2024.9239s\n",
      "\titers: 200, epoch: 4 | loss: 0.1010323\n",
      "\tspeed: 0.0491s/iter; left time: 745.0229s\n",
      "\titers: 300, epoch: 4 | loss: 0.0986466\n",
      "\tspeed: 0.0495s/iter; left time: 745.7824s\n",
      "\titers: 400, epoch: 4 | loss: 0.0902724\n",
      "\tspeed: 0.0492s/iter; left time: 736.2962s\n",
      "\titers: 500, epoch: 4 | loss: 0.0998493\n",
      "\tspeed: 0.0485s/iter; left time: 720.9186s\n",
      "\titers: 600, epoch: 4 | loss: 0.0990290\n",
      "\tspeed: 0.0482s/iter; left time: 712.2551s\n",
      "\titers: 700, epoch: 4 | loss: 0.0914141\n",
      "\tspeed: 0.0440s/iter; left time: 644.7378s\n",
      "\titers: 800, epoch: 4 | loss: 0.0976941\n",
      "\tspeed: 0.0477s/iter; left time: 694.3362s\n",
      "\titers: 900, epoch: 4 | loss: 0.0985657\n",
      "\tspeed: 0.0491s/iter; left time: 711.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.85s\n",
      "Steps: 904 | Train Loss: 0.0960429 Vali Loss: 0.1142044 Test Loss: 0.1405463\n",
      "Validation loss decreased (0.116229 --> 0.114204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0962479\n",
      "\tspeed: 0.1293s/iter; left time: 1857.9960s\n",
      "\titers: 200, epoch: 5 | loss: 0.0932488\n",
      "\tspeed: 0.0512s/iter; left time: 730.1141s\n",
      "\titers: 300, epoch: 5 | loss: 0.0906189\n",
      "\tspeed: 0.0507s/iter; left time: 717.7998s\n",
      "\titers: 400, epoch: 5 | loss: 0.0959581\n",
      "\tspeed: 0.0491s/iter; left time: 690.8429s\n",
      "\titers: 500, epoch: 5 | loss: 0.0899868\n",
      "\tspeed: 0.0497s/iter; left time: 694.6703s\n",
      "\titers: 600, epoch: 5 | loss: 0.0778124\n",
      "\tspeed: 0.0489s/iter; left time: 678.2247s\n",
      "\titers: 700, epoch: 5 | loss: 0.0956461\n",
      "\tspeed: 0.0497s/iter; left time: 684.6932s\n",
      "\titers: 800, epoch: 5 | loss: 0.1007049\n",
      "\tspeed: 0.0519s/iter; left time: 709.8452s\n",
      "\titers: 900, epoch: 5 | loss: 0.0921056\n",
      "\tspeed: 0.0516s/iter; left time: 699.4275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.51s\n",
      "Steps: 904 | Train Loss: 0.0930086 Vali Loss: 0.1180095 Test Loss: 0.1431410\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0939353\n",
      "\tspeed: 0.1272s/iter; left time: 1711.8678s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879850\n",
      "\tspeed: 0.0509s/iter; left time: 680.4062s\n",
      "\titers: 300, epoch: 6 | loss: 0.0849343\n",
      "\tspeed: 0.0507s/iter; left time: 672.3264s\n",
      "\titers: 400, epoch: 6 | loss: 0.0910670\n",
      "\tspeed: 0.0490s/iter; left time: 644.4384s\n",
      "\titers: 500, epoch: 6 | loss: 0.0901161\n",
      "\tspeed: 0.0491s/iter; left time: 641.7438s\n",
      "\titers: 600, epoch: 6 | loss: 0.0928531\n",
      "\tspeed: 0.0484s/iter; left time: 626.7383s\n",
      "\titers: 700, epoch: 6 | loss: 0.0855069\n",
      "\tspeed: 0.0496s/iter; left time: 638.2925s\n",
      "\titers: 800, epoch: 6 | loss: 0.0857193\n",
      "\tspeed: 0.0440s/iter; left time: 561.4538s\n",
      "\titers: 900, epoch: 6 | loss: 0.0880621\n",
      "\tspeed: 0.0465s/iter; left time: 588.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.06s\n",
      "Steps: 904 | Train Loss: 0.0900311 Vali Loss: 0.1177180 Test Loss: 0.1446792\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0913210\n",
      "\tspeed: 0.1306s/iter; left time: 1640.5627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0796605\n",
      "\tspeed: 0.0490s/iter; left time: 610.6913s\n",
      "\titers: 300, epoch: 7 | loss: 0.0845419\n",
      "\tspeed: 0.0500s/iter; left time: 617.3080s\n",
      "\titers: 400, epoch: 7 | loss: 0.0856325\n",
      "\tspeed: 0.0494s/iter; left time: 605.3607s\n",
      "\titers: 500, epoch: 7 | loss: 0.0841595\n",
      "\tspeed: 0.0508s/iter; left time: 618.1280s\n",
      "\titers: 600, epoch: 7 | loss: 0.0821881\n",
      "\tspeed: 0.0493s/iter; left time: 594.1819s\n",
      "\titers: 700, epoch: 7 | loss: 0.0873339\n",
      "\tspeed: 0.0500s/iter; left time: 597.3967s\n",
      "\titers: 800, epoch: 7 | loss: 0.0816296\n",
      "\tspeed: 0.0492s/iter; left time: 583.4803s\n",
      "\titers: 900, epoch: 7 | loss: 0.0909199\n",
      "\tspeed: 0.0495s/iter; left time: 582.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.25s\n",
      "Steps: 904 | Train Loss: 0.0869063 Vali Loss: 0.1167884 Test Loss: 0.1418039\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832956\n",
      "\tspeed: 0.1291s/iter; left time: 1504.6611s\n",
      "\titers: 200, epoch: 8 | loss: 0.0890680\n",
      "\tspeed: 0.0496s/iter; left time: 573.4317s\n",
      "\titers: 300, epoch: 8 | loss: 0.0840142\n",
      "\tspeed: 0.0491s/iter; left time: 562.1707s\n",
      "\titers: 400, epoch: 8 | loss: 0.0769679\n",
      "\tspeed: 0.0476s/iter; left time: 540.2970s\n",
      "\titers: 500, epoch: 8 | loss: 0.0880028\n",
      "\tspeed: 0.0462s/iter; left time: 520.1020s\n",
      "\titers: 600, epoch: 8 | loss: 0.0843191\n",
      "\tspeed: 0.0510s/iter; left time: 568.8843s\n",
      "\titers: 700, epoch: 8 | loss: 0.0899688\n",
      "\tspeed: 0.0492s/iter; left time: 544.0054s\n",
      "\titers: 800, epoch: 8 | loss: 0.0839447\n",
      "\tspeed: 0.0495s/iter; left time: 542.4988s\n",
      "\titers: 900, epoch: 8 | loss: 0.0830101\n",
      "\tspeed: 0.0497s/iter; left time: 539.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.56s\n",
      "Steps: 904 | Train Loss: 0.0841543 Vali Loss: 0.1201528 Test Loss: 0.1467488\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763079\n",
      "\tspeed: 0.1302s/iter; left time: 1399.3314s\n",
      "\titers: 200, epoch: 9 | loss: 0.0748629\n",
      "\tspeed: 0.0495s/iter; left time: 526.9010s\n",
      "\titers: 300, epoch: 9 | loss: 0.0836891\n",
      "\tspeed: 0.0498s/iter; left time: 525.0876s\n",
      "\titers: 400, epoch: 9 | loss: 0.0804295\n",
      "\tspeed: 0.0484s/iter; left time: 505.5799s\n",
      "\titers: 500, epoch: 9 | loss: 0.0782300\n",
      "\tspeed: 0.0502s/iter; left time: 519.6233s\n",
      "\titers: 600, epoch: 9 | loss: 0.0839520\n",
      "\tspeed: 0.0498s/iter; left time: 510.2490s\n",
      "\titers: 700, epoch: 9 | loss: 0.0797323\n",
      "\tspeed: 0.0499s/iter; left time: 506.1515s\n",
      "\titers: 800, epoch: 9 | loss: 0.0904931\n",
      "\tspeed: 0.0517s/iter; left time: 519.4901s\n",
      "\titers: 900, epoch: 9 | loss: 0.0852508\n",
      "\tspeed: 0.0488s/iter; left time: 485.5998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.26s\n",
      "Steps: 904 | Train Loss: 0.0813225 Vali Loss: 0.1199956 Test Loss: 0.1488492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.046120475977659225, rmse:0.2147567868232727, mae:0.1404818892478943, rse:0.7404764294624329\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2084366\n",
      "\tspeed: 0.0523s/iter; left time: 940.5025s\n",
      "\titers: 200, epoch: 1 | loss: 0.1973465\n",
      "\tspeed: 0.0493s/iter; left time: 881.9228s\n",
      "\titers: 300, epoch: 1 | loss: 0.1771671\n",
      "\tspeed: 0.0503s/iter; left time: 893.5223s\n",
      "\titers: 400, epoch: 1 | loss: 0.1781648\n",
      "\tspeed: 0.0484s/iter; left time: 856.2364s\n",
      "\titers: 500, epoch: 1 | loss: 0.1724314\n",
      "\tspeed: 0.0494s/iter; left time: 868.5127s\n",
      "\titers: 600, epoch: 1 | loss: 0.1672256\n",
      "\tspeed: 0.0488s/iter; left time: 853.7973s\n",
      "\titers: 700, epoch: 1 | loss: 0.1611701\n",
      "\tspeed: 0.0494s/iter; left time: 858.2774s\n",
      "\titers: 800, epoch: 1 | loss: 0.1689532\n",
      "\tspeed: 0.0495s/iter; left time: 855.6020s\n",
      "\titers: 900, epoch: 1 | loss: 0.1516010\n",
      "\tspeed: 0.0490s/iter; left time: 842.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.89s\n",
      "Steps: 904 | Train Loss: 0.1840924 Vali Loss: 0.1484874 Test Loss: 0.1750864\n",
      "Validation loss decreased (inf --> 0.148487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1270520\n",
      "\tspeed: 0.1346s/iter; left time: 2298.2200s\n",
      "\titers: 200, epoch: 2 | loss: 0.1235949\n",
      "\tspeed: 0.0487s/iter; left time: 827.0102s\n",
      "\titers: 300, epoch: 2 | loss: 0.1177894\n",
      "\tspeed: 0.0483s/iter; left time: 815.3851s\n",
      "\titers: 400, epoch: 2 | loss: 0.1089158\n",
      "\tspeed: 0.0489s/iter; left time: 820.6155s\n",
      "\titers: 500, epoch: 2 | loss: 0.1065722\n",
      "\tspeed: 0.0465s/iter; left time: 774.7124s\n",
      "\titers: 600, epoch: 2 | loss: 0.1032768\n",
      "\tspeed: 0.0493s/iter; left time: 817.1283s\n",
      "\titers: 700, epoch: 2 | loss: 0.0999453\n",
      "\tspeed: 0.0489s/iter; left time: 806.1587s\n",
      "\titers: 800, epoch: 2 | loss: 0.1127204\n",
      "\tspeed: 0.0497s/iter; left time: 814.7517s\n",
      "\titers: 900, epoch: 2 | loss: 0.1021534\n",
      "\tspeed: 0.0489s/iter; left time: 795.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.43s\n",
      "Steps: 904 | Train Loss: 0.1159495 Vali Loss: 0.1167780 Test Loss: 0.1407157\n",
      "Validation loss decreased (0.148487 --> 0.116778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1072488\n",
      "\tspeed: 0.1321s/iter; left time: 2135.8697s\n",
      "\titers: 200, epoch: 3 | loss: 0.0889950\n",
      "\tspeed: 0.0484s/iter; left time: 777.7795s\n",
      "\titers: 300, epoch: 3 | loss: 0.0975622\n",
      "\tspeed: 0.0489s/iter; left time: 780.3572s\n",
      "\titers: 400, epoch: 3 | loss: 0.1020696\n",
      "\tspeed: 0.0499s/iter; left time: 791.7735s\n",
      "\titers: 500, epoch: 3 | loss: 0.0991767\n",
      "\tspeed: 0.0485s/iter; left time: 765.1159s\n",
      "\titers: 600, epoch: 3 | loss: 0.1069511\n",
      "\tspeed: 0.0520s/iter; left time: 814.5046s\n",
      "\titers: 700, epoch: 3 | loss: 0.0978666\n",
      "\tspeed: 0.0525s/iter; left time: 816.8485s\n",
      "\titers: 800, epoch: 3 | loss: 0.0862727\n",
      "\tspeed: 0.0516s/iter; left time: 797.9835s\n",
      "\titers: 900, epoch: 3 | loss: 0.0985514\n",
      "\tspeed: 0.0524s/iter; left time: 806.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 904 | Train Loss: 0.0997150 Vali Loss: 0.1117379 Test Loss: 0.1384910\n",
      "Validation loss decreased (0.116778 --> 0.111738).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1036827\n",
      "\tspeed: 0.1346s/iter; left time: 2055.3106s\n",
      "\titers: 200, epoch: 4 | loss: 0.0918781\n",
      "\tspeed: 0.0508s/iter; left time: 769.9296s\n",
      "\titers: 300, epoch: 4 | loss: 0.0877127\n",
      "\tspeed: 0.0491s/iter; left time: 739.7219s\n",
      "\titers: 400, epoch: 4 | loss: 0.0896820\n",
      "\tspeed: 0.0499s/iter; left time: 747.6080s\n",
      "\titers: 500, epoch: 4 | loss: 0.0934892\n",
      "\tspeed: 0.0492s/iter; left time: 731.6879s\n",
      "\titers: 600, epoch: 4 | loss: 0.0822336\n",
      "\tspeed: 0.0486s/iter; left time: 717.3988s\n",
      "\titers: 700, epoch: 4 | loss: 0.0894030\n",
      "\tspeed: 0.0514s/iter; left time: 753.3815s\n",
      "\titers: 800, epoch: 4 | loss: 0.0907775\n",
      "\tspeed: 0.0496s/iter; left time: 722.2880s\n",
      "\titers: 900, epoch: 4 | loss: 0.0857407\n",
      "\tspeed: 0.0455s/iter; left time: 659.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.95s\n",
      "Steps: 904 | Train Loss: 0.0917967 Vali Loss: 0.1078700 Test Loss: 0.1324418\n",
      "Validation loss decreased (0.111738 --> 0.107870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0891149\n",
      "\tspeed: 0.1359s/iter; left time: 1952.2373s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836575\n",
      "\tspeed: 0.0522s/iter; left time: 743.9825s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873000\n",
      "\tspeed: 0.0508s/iter; left time: 719.9801s\n",
      "\titers: 400, epoch: 5 | loss: 0.0827118\n",
      "\tspeed: 0.0499s/iter; left time: 701.6611s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912801\n",
      "\tspeed: 0.0503s/iter; left time: 702.3088s\n",
      "\titers: 600, epoch: 5 | loss: 0.0844417\n",
      "\tspeed: 0.0483s/iter; left time: 669.3118s\n",
      "\titers: 700, epoch: 5 | loss: 0.0892159\n",
      "\tspeed: 0.0491s/iter; left time: 676.2366s\n",
      "\titers: 800, epoch: 5 | loss: 0.0818022\n",
      "\tspeed: 0.0518s/iter; left time: 707.3959s\n",
      "\titers: 900, epoch: 5 | loss: 0.0900072\n",
      "\tspeed: 0.0491s/iter; left time: 666.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.80s\n",
      "Steps: 904 | Train Loss: 0.0881307 Vali Loss: 0.1082674 Test Loss: 0.1342080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0786097\n",
      "\tspeed: 0.1320s/iter; left time: 1777.0030s\n",
      "\titers: 200, epoch: 6 | loss: 0.0866159\n",
      "\tspeed: 0.0487s/iter; left time: 650.7287s\n",
      "\titers: 300, epoch: 6 | loss: 0.0684536\n",
      "\tspeed: 0.0500s/iter; left time: 663.5845s\n",
      "\titers: 400, epoch: 6 | loss: 0.0808354\n",
      "\tspeed: 0.0492s/iter; left time: 647.9619s\n",
      "\titers: 500, epoch: 6 | loss: 0.0936274\n",
      "\tspeed: 0.0511s/iter; left time: 667.2236s\n",
      "\titers: 600, epoch: 6 | loss: 0.0904537\n",
      "\tspeed: 0.0517s/iter; left time: 670.4878s\n",
      "\titers: 700, epoch: 6 | loss: 0.0860979\n",
      "\tspeed: 0.0503s/iter; left time: 646.4719s\n",
      "\titers: 800, epoch: 6 | loss: 0.0859296\n",
      "\tspeed: 0.0489s/iter; left time: 623.7275s\n",
      "\titers: 900, epoch: 6 | loss: 0.0792522\n",
      "\tspeed: 0.0452s/iter; left time: 571.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 904 | Train Loss: 0.0849481 Vali Loss: 0.1116445 Test Loss: 0.1347608\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769096\n",
      "\tspeed: 0.1324s/iter; left time: 1662.5354s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822701\n",
      "\tspeed: 0.0532s/iter; left time: 663.0009s\n",
      "\titers: 300, epoch: 7 | loss: 0.0850004\n",
      "\tspeed: 0.0509s/iter; left time: 629.4580s\n",
      "\titers: 400, epoch: 7 | loss: 0.0914967\n",
      "\tspeed: 0.0502s/iter; left time: 615.4169s\n",
      "\titers: 500, epoch: 7 | loss: 0.0801068\n",
      "\tspeed: 0.0484s/iter; left time: 588.7807s\n",
      "\titers: 600, epoch: 7 | loss: 0.0838383\n",
      "\tspeed: 0.0480s/iter; left time: 578.5190s\n",
      "\titers: 700, epoch: 7 | loss: 0.0744772\n",
      "\tspeed: 0.0477s/iter; left time: 570.1112s\n",
      "\titers: 800, epoch: 7 | loss: 0.0728408\n",
      "\tspeed: 0.0502s/iter; left time: 594.6858s\n",
      "\titers: 900, epoch: 7 | loss: 0.0841569\n",
      "\tspeed: 0.0498s/iter; left time: 585.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.53s\n",
      "Steps: 904 | Train Loss: 0.0818022 Vali Loss: 0.1156345 Test Loss: 0.1431344\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0782995\n",
      "\tspeed: 0.1292s/iter; left time: 1505.0576s\n",
      "\titers: 200, epoch: 8 | loss: 0.0791428\n",
      "\tspeed: 0.0483s/iter; left time: 557.7582s\n",
      "\titers: 300, epoch: 8 | loss: 0.0761797\n",
      "\tspeed: 0.0476s/iter; left time: 545.3563s\n",
      "\titers: 400, epoch: 8 | loss: 0.0745559\n",
      "\tspeed: 0.0499s/iter; left time: 566.5214s\n",
      "\titers: 500, epoch: 8 | loss: 0.0801976\n",
      "\tspeed: 0.0502s/iter; left time: 564.5543s\n",
      "\titers: 600, epoch: 8 | loss: 0.0776090\n",
      "\tspeed: 0.0498s/iter; left time: 555.6062s\n",
      "\titers: 700, epoch: 8 | loss: 0.0738001\n",
      "\tspeed: 0.0463s/iter; left time: 511.3179s\n",
      "\titers: 800, epoch: 8 | loss: 0.0697556\n",
      "\tspeed: 0.0494s/iter; left time: 541.2919s\n",
      "\titers: 900, epoch: 8 | loss: 0.0736035\n",
      "\tspeed: 0.0488s/iter; left time: 529.1799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.35s\n",
      "Steps: 904 | Train Loss: 0.0788905 Vali Loss: 0.1117111 Test Loss: 0.1392122\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0829183\n",
      "\tspeed: 0.1287s/iter; left time: 1383.6543s\n",
      "\titers: 200, epoch: 9 | loss: 0.0747281\n",
      "\tspeed: 0.0495s/iter; left time: 526.7609s\n",
      "\titers: 300, epoch: 9 | loss: 0.0812659\n",
      "\tspeed: 0.0502s/iter; left time: 529.4239s\n",
      "\titers: 400, epoch: 9 | loss: 0.0686350\n",
      "\tspeed: 0.0492s/iter; left time: 513.9288s\n",
      "\titers: 500, epoch: 9 | loss: 0.0789720\n",
      "\tspeed: 0.0500s/iter; left time: 517.4656s\n",
      "\titers: 600, epoch: 9 | loss: 0.0797494\n",
      "\tspeed: 0.0509s/iter; left time: 521.7747s\n",
      "\titers: 700, epoch: 9 | loss: 0.0849166\n",
      "\tspeed: 0.0509s/iter; left time: 516.0873s\n",
      "\titers: 800, epoch: 9 | loss: 0.0690585\n",
      "\tspeed: 0.0499s/iter; left time: 501.5993s\n",
      "\titers: 900, epoch: 9 | loss: 0.0800689\n",
      "\tspeed: 0.0451s/iter; left time: 448.5441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:44.86s\n",
      "Steps: 904 | Train Loss: 0.0759963 Vali Loss: 0.1127594 Test Loss: 0.1445938\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.039505913853645325, rmse:0.19876094162464142, mae:0.13264088332653046, rse:0.6853231191635132\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:07.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2173134\n",
      "\tspeed: 0.0809s/iter; left time: 1451.0316s\n",
      "\titers: 200, epoch: 1 | loss: 0.2006694\n",
      "\tspeed: 0.0566s/iter; left time: 1009.7556s\n",
      "\titers: 300, epoch: 1 | loss: 0.1807969\n",
      "\tspeed: 0.0530s/iter; left time: 939.8896s\n",
      "\titers: 400, epoch: 1 | loss: 0.1787154\n",
      "\tspeed: 0.0541s/iter; left time: 954.8647s\n",
      "\titers: 500, epoch: 1 | loss: 0.1915860\n",
      "\tspeed: 0.0557s/iter; left time: 977.6983s\n",
      "\titers: 600, epoch: 1 | loss: 0.1715197\n",
      "\tspeed: 0.0556s/iter; left time: 970.2119s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688506\n",
      "\tspeed: 0.0549s/iter; left time: 951.9629s\n",
      "\titers: 800, epoch: 1 | loss: 0.1658185\n",
      "\tspeed: 0.0559s/iter; left time: 963.9647s\n",
      "\titers: 900, epoch: 1 | loss: 0.1647618\n",
      "\tspeed: 0.0552s/iter; left time: 946.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.45s\n",
      "Steps: 902 | Train Loss: 0.1905512 Vali Loss: 0.1749492 Test Loss: 0.2097985\n",
      "Validation loss decreased (inf --> 0.174949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1542222\n",
      "\tspeed: 0.1478s/iter; left time: 2518.4688s\n",
      "\titers: 200, epoch: 2 | loss: 0.1374695\n",
      "\tspeed: 0.0541s/iter; left time: 915.8451s\n",
      "\titers: 300, epoch: 2 | loss: 0.1425101\n",
      "\tspeed: 0.0543s/iter; left time: 913.6002s\n",
      "\titers: 400, epoch: 2 | loss: 0.1289964\n",
      "\tspeed: 0.0541s/iter; left time: 905.4369s\n",
      "\titers: 500, epoch: 2 | loss: 0.1389110\n",
      "\tspeed: 0.0537s/iter; left time: 893.2155s\n",
      "\titers: 600, epoch: 2 | loss: 0.1347203\n",
      "\tspeed: 0.0549s/iter; left time: 908.2740s\n",
      "\titers: 700, epoch: 2 | loss: 0.1290513\n",
      "\tspeed: 0.0536s/iter; left time: 881.5041s\n",
      "\titers: 800, epoch: 2 | loss: 0.1184421\n",
      "\tspeed: 0.0533s/iter; left time: 871.5631s\n",
      "\titers: 900, epoch: 2 | loss: 0.1389074\n",
      "\tspeed: 0.0541s/iter; left time: 878.9185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.09s\n",
      "Steps: 902 | Train Loss: 0.1365861 Vali Loss: 0.1495955 Test Loss: 0.1798667\n",
      "Validation loss decreased (0.174949 --> 0.149596).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1288296\n",
      "\tspeed: 0.1475s/iter; left time: 2379.5842s\n",
      "\titers: 200, epoch: 3 | loss: 0.1312672\n",
      "\tspeed: 0.0540s/iter; left time: 865.3801s\n",
      "\titers: 300, epoch: 3 | loss: 0.1290906\n",
      "\tspeed: 0.0548s/iter; left time: 872.7805s\n",
      "\titers: 400, epoch: 3 | loss: 0.1215173\n",
      "\tspeed: 0.0549s/iter; left time: 869.8296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1148364\n",
      "\tspeed: 0.0537s/iter; left time: 845.2364s\n",
      "\titers: 600, epoch: 3 | loss: 0.1172931\n",
      "\tspeed: 0.0556s/iter; left time: 869.7132s\n",
      "\titers: 700, epoch: 3 | loss: 0.1344398\n",
      "\tspeed: 0.0543s/iter; left time: 843.2896s\n",
      "\titers: 800, epoch: 3 | loss: 0.1181802\n",
      "\tspeed: 0.0534s/iter; left time: 823.5853s\n",
      "\titers: 900, epoch: 3 | loss: 0.1110427\n",
      "\tspeed: 0.0548s/iter; left time: 840.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 902 | Train Loss: 0.1232634 Vali Loss: 0.1442335 Test Loss: 0.1826095\n",
      "Validation loss decreased (0.149596 --> 0.144233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1079351\n",
      "\tspeed: 0.1484s/iter; left time: 2260.6234s\n",
      "\titers: 200, epoch: 4 | loss: 0.1001913\n",
      "\tspeed: 0.0548s/iter; left time: 828.9402s\n",
      "\titers: 300, epoch: 4 | loss: 0.1146982\n",
      "\tspeed: 0.0536s/iter; left time: 805.4726s\n",
      "\titers: 400, epoch: 4 | loss: 0.1023415\n",
      "\tspeed: 0.0532s/iter; left time: 795.2183s\n",
      "\titers: 500, epoch: 4 | loss: 0.0966638\n",
      "\tspeed: 0.0533s/iter; left time: 790.5097s\n",
      "\titers: 600, epoch: 4 | loss: 0.1051467\n",
      "\tspeed: 0.0528s/iter; left time: 777.3143s\n",
      "\titers: 700, epoch: 4 | loss: 0.0913816\n",
      "\tspeed: 0.0525s/iter; left time: 768.2777s\n",
      "\titers: 800, epoch: 4 | loss: 0.1025503\n",
      "\tspeed: 0.0526s/iter; left time: 764.5024s\n",
      "\titers: 900, epoch: 4 | loss: 0.0988792\n",
      "\tspeed: 0.0525s/iter; left time: 757.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.33s\n",
      "Steps: 902 | Train Loss: 0.1019167 Vali Loss: 0.1316333 Test Loss: 0.1627262\n",
      "Validation loss decreased (0.144233 --> 0.131633).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0954319\n",
      "\tspeed: 0.1434s/iter; left time: 2054.7708s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865117\n",
      "\tspeed: 0.0532s/iter; left time: 757.8888s\n",
      "\titers: 300, epoch: 5 | loss: 0.0920610\n",
      "\tspeed: 0.0544s/iter; left time: 768.8200s\n",
      "\titers: 400, epoch: 5 | loss: 0.0996443\n",
      "\tspeed: 0.0550s/iter; left time: 771.5030s\n",
      "\titers: 500, epoch: 5 | loss: 0.0886308\n",
      "\tspeed: 0.0539s/iter; left time: 751.5985s\n",
      "\titers: 600, epoch: 5 | loss: 0.0977751\n",
      "\tspeed: 0.0529s/iter; left time: 731.7649s\n",
      "\titers: 700, epoch: 5 | loss: 0.0942344\n",
      "\tspeed: 0.0531s/iter; left time: 729.7966s\n",
      "\titers: 800, epoch: 5 | loss: 0.0893522\n",
      "\tspeed: 0.0542s/iter; left time: 739.5824s\n",
      "\titers: 900, epoch: 5 | loss: 0.0918429\n",
      "\tspeed: 0.0525s/iter; left time: 710.9011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.0914504 Vali Loss: 0.1317578 Test Loss: 0.1631977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0857377\n",
      "\tspeed: 0.1424s/iter; left time: 1913.0506s\n",
      "\titers: 200, epoch: 6 | loss: 0.0768838\n",
      "\tspeed: 0.0548s/iter; left time: 730.0486s\n",
      "\titers: 300, epoch: 6 | loss: 0.0748909\n",
      "\tspeed: 0.0546s/iter; left time: 721.8752s\n",
      "\titers: 400, epoch: 6 | loss: 0.0812502\n",
      "\tspeed: 0.0528s/iter; left time: 693.0766s\n",
      "\titers: 500, epoch: 6 | loss: 0.0851492\n",
      "\tspeed: 0.0546s/iter; left time: 711.2046s\n",
      "\titers: 600, epoch: 6 | loss: 0.0861262\n",
      "\tspeed: 0.0546s/iter; left time: 706.1619s\n",
      "\titers: 700, epoch: 6 | loss: 0.0764411\n",
      "\tspeed: 0.0544s/iter; left time: 698.2026s\n",
      "\titers: 800, epoch: 6 | loss: 0.0750036\n",
      "\tspeed: 0.0538s/iter; left time: 684.4980s\n",
      "\titers: 900, epoch: 6 | loss: 0.0747939\n",
      "\tspeed: 0.0547s/iter; left time: 691.1862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.11s\n",
      "Steps: 902 | Train Loss: 0.0841192 Vali Loss: 0.1290136 Test Loss: 0.1646815\n",
      "Validation loss decreased (0.131633 --> 0.129014).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0804305\n",
      "\tspeed: 0.1471s/iter; left time: 1842.9525s\n",
      "\titers: 200, epoch: 7 | loss: 0.0889668\n",
      "\tspeed: 0.0551s/iter; left time: 684.6484s\n",
      "\titers: 300, epoch: 7 | loss: 0.0782861\n",
      "\tspeed: 0.0546s/iter; left time: 673.0474s\n",
      "\titers: 400, epoch: 7 | loss: 0.0837841\n",
      "\tspeed: 0.0540s/iter; left time: 660.1399s\n",
      "\titers: 500, epoch: 7 | loss: 0.0765825\n",
      "\tspeed: 0.0523s/iter; left time: 634.7982s\n",
      "\titers: 600, epoch: 7 | loss: 0.0802874\n",
      "\tspeed: 0.0557s/iter; left time: 669.6550s\n",
      "\titers: 700, epoch: 7 | loss: 0.0784528\n",
      "\tspeed: 0.0554s/iter; left time: 660.6061s\n",
      "\titers: 800, epoch: 7 | loss: 0.0808621\n",
      "\tspeed: 0.0557s/iter; left time: 658.7051s\n",
      "\titers: 900, epoch: 7 | loss: 0.0707021\n",
      "\tspeed: 0.0534s/iter; left time: 626.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.46s\n",
      "Steps: 902 | Train Loss: 0.0777514 Vali Loss: 0.1332384 Test Loss: 0.1687949\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0747336\n",
      "\tspeed: 0.1437s/iter; left time: 1670.3555s\n",
      "\titers: 200, epoch: 8 | loss: 0.0781834\n",
      "\tspeed: 0.0553s/iter; left time: 637.4530s\n",
      "\titers: 300, epoch: 8 | loss: 0.0783325\n",
      "\tspeed: 0.0503s/iter; left time: 575.1779s\n",
      "\titers: 400, epoch: 8 | loss: 0.0749291\n",
      "\tspeed: 0.0542s/iter; left time: 614.1305s\n",
      "\titers: 500, epoch: 8 | loss: 0.0741506\n",
      "\tspeed: 0.0517s/iter; left time: 580.7168s\n",
      "\titers: 600, epoch: 8 | loss: 0.0699665\n",
      "\tspeed: 0.0526s/iter; left time: 584.8513s\n",
      "\titers: 700, epoch: 8 | loss: 0.0746879\n",
      "\tspeed: 0.0502s/iter; left time: 553.1902s\n",
      "\titers: 800, epoch: 8 | loss: 0.0683073\n",
      "\tspeed: 0.0538s/iter; left time: 588.1964s\n",
      "\titers: 900, epoch: 8 | loss: 0.0689467\n",
      "\tspeed: 0.0552s/iter; left time: 597.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.13s\n",
      "Steps: 902 | Train Loss: 0.0727507 Vali Loss: 0.1324355 Test Loss: 0.1687129\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681406\n",
      "\tspeed: 0.1433s/iter; left time: 1536.9297s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668841\n",
      "\tspeed: 0.0561s/iter; left time: 595.7280s\n",
      "\titers: 300, epoch: 9 | loss: 0.0648726\n",
      "\tspeed: 0.0542s/iter; left time: 570.7956s\n",
      "\titers: 400, epoch: 9 | loss: 0.0664961\n",
      "\tspeed: 0.0525s/iter; left time: 547.3989s\n",
      "\titers: 500, epoch: 9 | loss: 0.0645324\n",
      "\tspeed: 0.0531s/iter; left time: 548.1412s\n",
      "\titers: 600, epoch: 9 | loss: 0.0671032\n",
      "\tspeed: 0.0532s/iter; left time: 543.6181s\n",
      "\titers: 700, epoch: 9 | loss: 0.0634576\n",
      "\tspeed: 0.0558s/iter; left time: 565.4186s\n",
      "\titers: 800, epoch: 9 | loss: 0.0704599\n",
      "\tspeed: 0.0529s/iter; left time: 529.9855s\n",
      "\titers: 900, epoch: 9 | loss: 0.0613546\n",
      "\tspeed: 0.0529s/iter; left time: 524.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 902 | Train Loss: 0.0684061 Vali Loss: 0.1340248 Test Loss: 0.1675996\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0640621\n",
      "\tspeed: 0.1447s/iter; left time: 1421.0523s\n",
      "\titers: 200, epoch: 10 | loss: 0.0641608\n",
      "\tspeed: 0.0533s/iter; left time: 518.3498s\n",
      "\titers: 300, epoch: 10 | loss: 0.0721797\n",
      "\tspeed: 0.0537s/iter; left time: 516.2815s\n",
      "\titers: 400, epoch: 10 | loss: 0.0643042\n",
      "\tspeed: 0.0533s/iter; left time: 508.0101s\n",
      "\titers: 500, epoch: 10 | loss: 0.0668774\n",
      "\tspeed: 0.0504s/iter; left time: 475.0640s\n",
      "\titers: 600, epoch: 10 | loss: 0.0673209\n",
      "\tspeed: 0.0541s/iter; left time: 504.6665s\n",
      "\titers: 700, epoch: 10 | loss: 0.0667415\n",
      "\tspeed: 0.0535s/iter; left time: 493.6182s\n",
      "\titers: 800, epoch: 10 | loss: 0.0608907\n",
      "\tspeed: 0.0522s/iter; left time: 476.3807s\n",
      "\titers: 900, epoch: 10 | loss: 0.0672894\n",
      "\tspeed: 0.0533s/iter; left time: 480.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.26s\n",
      "Steps: 902 | Train Loss: 0.0650008 Vali Loss: 0.1336217 Test Loss: 0.1700243\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0605227\n",
      "\tspeed: 0.1433s/iter; left time: 1278.0655s\n",
      "\titers: 200, epoch: 11 | loss: 0.0686492\n",
      "\tspeed: 0.0524s/iter; left time: 462.3336s\n",
      "\titers: 300, epoch: 11 | loss: 0.0598812\n",
      "\tspeed: 0.0527s/iter; left time: 459.4880s\n",
      "\titers: 400, epoch: 11 | loss: 0.0594393\n",
      "\tspeed: 0.0529s/iter; left time: 456.1086s\n",
      "\titers: 500, epoch: 11 | loss: 0.0610512\n",
      "\tspeed: 0.0532s/iter; left time: 453.0317s\n",
      "\titers: 600, epoch: 11 | loss: 0.0628583\n",
      "\tspeed: 0.0523s/iter; left time: 440.6517s\n",
      "\titers: 700, epoch: 11 | loss: 0.0588660\n",
      "\tspeed: 0.0538s/iter; left time: 447.8084s\n",
      "\titers: 800, epoch: 11 | loss: 0.0565516\n",
      "\tspeed: 0.0523s/iter; left time: 429.7595s\n",
      "\titers: 900, epoch: 11 | loss: 0.0636139\n",
      "\tspeed: 0.0527s/iter; left time: 428.0579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.00s\n",
      "Steps: 902 | Train Loss: 0.0619761 Vali Loss: 0.1325506 Test Loss: 0.1673481\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05855736881494522, rmse:0.24198630452156067, mae:0.16477428376674652, rse:0.8368223309516907\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2197319\n",
      "\tspeed: 0.0536s/iter; left time: 962.3869s\n",
      "\titers: 200, epoch: 1 | loss: 0.2019864\n",
      "\tspeed: 0.0520s/iter; left time: 927.8291s\n",
      "\titers: 300, epoch: 1 | loss: 0.1916104\n",
      "\tspeed: 0.0535s/iter; left time: 948.8874s\n",
      "\titers: 400, epoch: 1 | loss: 0.1849532\n",
      "\tspeed: 0.0537s/iter; left time: 948.0377s\n",
      "\titers: 500, epoch: 1 | loss: 0.1811846\n",
      "\tspeed: 0.0541s/iter; left time: 948.6824s\n",
      "\titers: 600, epoch: 1 | loss: 0.1797911\n",
      "\tspeed: 0.0549s/iter; left time: 956.7604s\n",
      "\titers: 700, epoch: 1 | loss: 0.1670418\n",
      "\tspeed: 0.0536s/iter; left time: 930.2937s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744785\n",
      "\tspeed: 0.0534s/iter; left time: 920.4115s\n",
      "\titers: 900, epoch: 1 | loss: 0.1665413\n",
      "\tspeed: 0.0536s/iter; left time: 918.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.1904041 Vali Loss: 0.1701483 Test Loss: 0.2054472\n",
      "Validation loss decreased (inf --> 0.170148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1553813\n",
      "\tspeed: 0.1469s/iter; left time: 2502.5111s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355720\n",
      "\tspeed: 0.0533s/iter; left time: 902.0129s\n",
      "\titers: 300, epoch: 2 | loss: 0.1355396\n",
      "\tspeed: 0.0541s/iter; left time: 911.7923s\n",
      "\titers: 400, epoch: 2 | loss: 0.1343906\n",
      "\tspeed: 0.0539s/iter; left time: 902.4198s\n",
      "\titers: 500, epoch: 2 | loss: 0.1272524\n",
      "\tspeed: 0.0532s/iter; left time: 884.9310s\n",
      "\titers: 600, epoch: 2 | loss: 0.1363325\n",
      "\tspeed: 0.0524s/iter; left time: 866.4371s\n",
      "\titers: 700, epoch: 2 | loss: 0.1184589\n",
      "\tspeed: 0.0530s/iter; left time: 871.1461s\n",
      "\titers: 800, epoch: 2 | loss: 0.1223198\n",
      "\tspeed: 0.0529s/iter; left time: 864.5282s\n",
      "\titers: 900, epoch: 2 | loss: 0.1222945\n",
      "\tspeed: 0.0539s/iter; left time: 875.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.1337961 Vali Loss: 0.1352970 Test Loss: 0.1636964\n",
      "Validation loss decreased (0.170148 --> 0.135297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1167755\n",
      "\tspeed: 0.1499s/iter; left time: 2418.5958s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061238\n",
      "\tspeed: 0.0525s/iter; left time: 841.2233s\n",
      "\titers: 300, epoch: 3 | loss: 0.1172599\n",
      "\tspeed: 0.0538s/iter; left time: 857.5424s\n",
      "\titers: 400, epoch: 3 | loss: 0.1026015\n",
      "\tspeed: 0.0528s/iter; left time: 835.5637s\n",
      "\titers: 500, epoch: 3 | loss: 0.1124251\n",
      "\tspeed: 0.0532s/iter; left time: 836.9429s\n",
      "\titers: 600, epoch: 3 | loss: 0.1092865\n",
      "\tspeed: 0.0555s/iter; left time: 867.7988s\n",
      "\titers: 700, epoch: 3 | loss: 0.1106054\n",
      "\tspeed: 0.0524s/iter; left time: 814.0789s\n",
      "\titers: 800, epoch: 3 | loss: 0.1045244\n",
      "\tspeed: 0.0528s/iter; left time: 815.3648s\n",
      "\titers: 900, epoch: 3 | loss: 0.1167721\n",
      "\tspeed: 0.0532s/iter; left time: 815.3050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.1120902 Vali Loss: 0.1357784 Test Loss: 0.1689398\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1046662\n",
      "\tspeed: 0.1436s/iter; left time: 2187.3008s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910340\n",
      "\tspeed: 0.0531s/iter; left time: 804.1547s\n",
      "\titers: 300, epoch: 4 | loss: 0.0983561\n",
      "\tspeed: 0.0542s/iter; left time: 815.2486s\n",
      "\titers: 400, epoch: 4 | loss: 0.1010134\n",
      "\tspeed: 0.0537s/iter; left time: 802.2979s\n",
      "\titers: 500, epoch: 4 | loss: 0.0972668\n",
      "\tspeed: 0.0536s/iter; left time: 795.7238s\n",
      "\titers: 600, epoch: 4 | loss: 0.0952515\n",
      "\tspeed: 0.0552s/iter; left time: 813.1461s\n",
      "\titers: 700, epoch: 4 | loss: 0.0911709\n",
      "\tspeed: 0.0536s/iter; left time: 784.8618s\n",
      "\titers: 800, epoch: 4 | loss: 0.1083035\n",
      "\tspeed: 0.0539s/iter; left time: 783.9659s\n",
      "\titers: 900, epoch: 4 | loss: 0.1000835\n",
      "\tspeed: 0.0538s/iter; left time: 777.0636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.87s\n",
      "Steps: 902 | Train Loss: 0.1009320 Vali Loss: 0.1311057 Test Loss: 0.1627600\n",
      "Validation loss decreased (0.135297 --> 0.131106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0972180\n",
      "\tspeed: 0.1494s/iter; left time: 2141.5015s\n",
      "\titers: 200, epoch: 5 | loss: 0.0922289\n",
      "\tspeed: 0.0562s/iter; left time: 799.5870s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933775\n",
      "\tspeed: 0.0556s/iter; left time: 785.5053s\n",
      "\titers: 400, epoch: 5 | loss: 0.0904759\n",
      "\tspeed: 0.0525s/iter; left time: 736.5227s\n",
      "\titers: 500, epoch: 5 | loss: 0.0910248\n",
      "\tspeed: 0.0526s/iter; left time: 732.6965s\n",
      "\titers: 600, epoch: 5 | loss: 0.0861282\n",
      "\tspeed: 0.0525s/iter; left time: 726.2965s\n",
      "\titers: 700, epoch: 5 | loss: 0.0842939\n",
      "\tspeed: 0.0536s/iter; left time: 736.1430s\n",
      "\titers: 800, epoch: 5 | loss: 0.0798366\n",
      "\tspeed: 0.0534s/iter; left time: 727.5860s\n",
      "\titers: 900, epoch: 5 | loss: 0.0786860\n",
      "\tspeed: 0.0515s/iter; left time: 697.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.0921604 Vali Loss: 0.1291835 Test Loss: 0.1645053\n",
      "Validation loss decreased (0.131106 --> 0.129184).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0892210\n",
      "\tspeed: 0.1488s/iter; left time: 1998.1485s\n",
      "\titers: 200, epoch: 6 | loss: 0.0804416\n",
      "\tspeed: 0.0555s/iter; left time: 740.4457s\n",
      "\titers: 300, epoch: 6 | loss: 0.0868079\n",
      "\tspeed: 0.0511s/iter; left time: 675.9013s\n",
      "\titers: 400, epoch: 6 | loss: 0.0876180\n",
      "\tspeed: 0.0531s/iter; left time: 697.6814s\n",
      "\titers: 500, epoch: 6 | loss: 0.0824391\n",
      "\tspeed: 0.0526s/iter; left time: 686.0804s\n",
      "\titers: 600, epoch: 6 | loss: 0.0907563\n",
      "\tspeed: 0.0536s/iter; left time: 692.5630s\n",
      "\titers: 700, epoch: 6 | loss: 0.0806358\n",
      "\tspeed: 0.0528s/iter; left time: 678.0038s\n",
      "\titers: 800, epoch: 6 | loss: 0.0867172\n",
      "\tspeed: 0.0529s/iter; left time: 674.0104s\n",
      "\titers: 900, epoch: 6 | loss: 0.0835542\n",
      "\tspeed: 0.0535s/iter; left time: 676.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.51s\n",
      "Steps: 902 | Train Loss: 0.0852456 Vali Loss: 0.1279804 Test Loss: 0.1632508\n",
      "Validation loss decreased (0.129184 --> 0.127980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812335\n",
      "\tspeed: 0.1481s/iter; left time: 1855.6117s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835768\n",
      "\tspeed: 0.0539s/iter; left time: 669.7715s\n",
      "\titers: 300, epoch: 7 | loss: 0.0831627\n",
      "\tspeed: 0.0526s/iter; left time: 647.9157s\n",
      "\titers: 400, epoch: 7 | loss: 0.0695377\n",
      "\tspeed: 0.0534s/iter; left time: 653.2420s\n",
      "\titers: 500, epoch: 7 | loss: 0.0814318\n",
      "\tspeed: 0.0539s/iter; left time: 653.8625s\n",
      "\titers: 600, epoch: 7 | loss: 0.0839019\n",
      "\tspeed: 0.0524s/iter; left time: 630.8212s\n",
      "\titers: 700, epoch: 7 | loss: 0.0787681\n",
      "\tspeed: 0.0526s/iter; left time: 627.7905s\n",
      "\titers: 800, epoch: 7 | loss: 0.0774530\n",
      "\tspeed: 0.0522s/iter; left time: 617.3257s\n",
      "\titers: 900, epoch: 7 | loss: 0.0814302\n",
      "\tspeed: 0.0550s/iter; left time: 645.2173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.0795353 Vali Loss: 0.1293697 Test Loss: 0.1650295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0730272\n",
      "\tspeed: 0.1416s/iter; left time: 1646.7834s\n",
      "\titers: 200, epoch: 8 | loss: 0.0776893\n",
      "\tspeed: 0.0525s/iter; left time: 605.2979s\n",
      "\titers: 300, epoch: 8 | loss: 0.0712130\n",
      "\tspeed: 0.0530s/iter; left time: 605.3819s\n",
      "\titers: 400, epoch: 8 | loss: 0.0742463\n",
      "\tspeed: 0.0535s/iter; left time: 605.5181s\n",
      "\titers: 500, epoch: 8 | loss: 0.0733726\n",
      "\tspeed: 0.0531s/iter; left time: 596.4857s\n",
      "\titers: 600, epoch: 8 | loss: 0.0715010\n",
      "\tspeed: 0.0532s/iter; left time: 592.1137s\n",
      "\titers: 700, epoch: 8 | loss: 0.0808716\n",
      "\tspeed: 0.0520s/iter; left time: 573.3019s\n",
      "\titers: 800, epoch: 8 | loss: 0.0736129\n",
      "\tspeed: 0.0549s/iter; left time: 599.4630s\n",
      "\titers: 900, epoch: 8 | loss: 0.0746227\n",
      "\tspeed: 0.0534s/iter; left time: 578.2475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.0744848 Vali Loss: 0.1328462 Test Loss: 0.1670277\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771855\n",
      "\tspeed: 0.1423s/iter; left time: 1525.6478s\n",
      "\titers: 200, epoch: 9 | loss: 0.0663497\n",
      "\tspeed: 0.0529s/iter; left time: 561.9371s\n",
      "\titers: 300, epoch: 9 | loss: 0.0650168\n",
      "\tspeed: 0.0535s/iter; left time: 562.5988s\n",
      "\titers: 400, epoch: 9 | loss: 0.0684309\n",
      "\tspeed: 0.0507s/iter; left time: 528.0629s\n",
      "\titers: 500, epoch: 9 | loss: 0.0687707\n",
      "\tspeed: 0.0522s/iter; left time: 539.3532s\n",
      "\titers: 600, epoch: 9 | loss: 0.0762557\n",
      "\tspeed: 0.0534s/iter; left time: 545.7914s\n",
      "\titers: 700, epoch: 9 | loss: 0.0672291\n",
      "\tspeed: 0.0531s/iter; left time: 537.7885s\n",
      "\titers: 800, epoch: 9 | loss: 0.0778250\n",
      "\tspeed: 0.0523s/iter; left time: 524.1709s\n",
      "\titers: 900, epoch: 9 | loss: 0.0701323\n",
      "\tspeed: 0.0534s/iter; left time: 530.0169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.80s\n",
      "Steps: 902 | Train Loss: 0.0702824 Vali Loss: 0.1345720 Test Loss: 0.1705145\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670741\n",
      "\tspeed: 0.1431s/iter; left time: 1405.3969s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688589\n",
      "\tspeed: 0.0540s/iter; left time: 524.9919s\n",
      "\titers: 300, epoch: 10 | loss: 0.0672262\n",
      "\tspeed: 0.0520s/iter; left time: 500.8527s\n",
      "\titers: 400, epoch: 10 | loss: 0.0666856\n",
      "\tspeed: 0.0523s/iter; left time: 497.8768s\n",
      "\titers: 500, epoch: 10 | loss: 0.0654557\n",
      "\tspeed: 0.0531s/iter; left time: 500.0569s\n",
      "\titers: 600, epoch: 10 | loss: 0.0625438\n",
      "\tspeed: 0.0531s/iter; left time: 494.5906s\n",
      "\titers: 700, epoch: 10 | loss: 0.0618264\n",
      "\tspeed: 0.0530s/iter; left time: 488.7525s\n",
      "\titers: 800, epoch: 10 | loss: 0.0696221\n",
      "\tspeed: 0.0536s/iter; left time: 488.9662s\n",
      "\titers: 900, epoch: 10 | loss: 0.0680939\n",
      "\tspeed: 0.0546s/iter; left time: 492.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.18s\n",
      "Steps: 902 | Train Loss: 0.0668899 Vali Loss: 0.1358712 Test Loss: 0.1711972\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0675534\n",
      "\tspeed: 0.1448s/iter; left time: 1291.8552s\n",
      "\titers: 200, epoch: 11 | loss: 0.0674160\n",
      "\tspeed: 0.0532s/iter; left time: 469.0043s\n",
      "\titers: 300, epoch: 11 | loss: 0.0651650\n",
      "\tspeed: 0.0532s/iter; left time: 463.8096s\n",
      "\titers: 400, epoch: 11 | loss: 0.0651039\n",
      "\tspeed: 0.0538s/iter; left time: 464.1147s\n",
      "\titers: 500, epoch: 11 | loss: 0.0691317\n",
      "\tspeed: 0.0536s/iter; left time: 456.6755s\n",
      "\titers: 600, epoch: 11 | loss: 0.0626214\n",
      "\tspeed: 0.0531s/iter; left time: 447.4068s\n",
      "\titers: 700, epoch: 11 | loss: 0.0643376\n",
      "\tspeed: 0.0527s/iter; left time: 438.6501s\n",
      "\titers: 800, epoch: 11 | loss: 0.0644723\n",
      "\tspeed: 0.0562s/iter; left time: 462.1168s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628455\n",
      "\tspeed: 0.0554s/iter; left time: 449.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.0638726 Vali Loss: 0.1360918 Test Loss: 0.1696518\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05540859326720238, rmse:0.235390305519104, mae:0.16324692964553833, rse:0.8140124678611755\n",
      "Intermediate time for GB and pred_len 96: 00h:21m:24.31s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2225497\n",
      "\tspeed: 0.0831s/iter; left time: 1487.4495s\n",
      "\titers: 200, epoch: 1 | loss: 0.2013052\n",
      "\tspeed: 0.0647s/iter; left time: 1151.4249s\n",
      "\titers: 300, epoch: 1 | loss: 0.1917021\n",
      "\tspeed: 0.0667s/iter; left time: 1181.1207s\n",
      "\titers: 400, epoch: 1 | loss: 0.1818679\n",
      "\tspeed: 0.0688s/iter; left time: 1211.6169s\n",
      "\titers: 500, epoch: 1 | loss: 0.1763812\n",
      "\tspeed: 0.0683s/iter; left time: 1195.6725s\n",
      "\titers: 600, epoch: 1 | loss: 0.1750793\n",
      "\tspeed: 0.0697s/iter; left time: 1213.4408s\n",
      "\titers: 700, epoch: 1 | loss: 0.1693778\n",
      "\tspeed: 0.0674s/iter; left time: 1166.3534s\n",
      "\titers: 800, epoch: 1 | loss: 0.1739509\n",
      "\tspeed: 0.0693s/iter; left time: 1191.9882s\n",
      "\titers: 900, epoch: 1 | loss: 0.1621293\n",
      "\tspeed: 0.0685s/iter; left time: 1172.2630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:01.41s\n",
      "Steps: 900 | Train Loss: 0.1906122 Vali Loss: 0.1736810 Test Loss: 0.2083679\n",
      "Validation loss decreased (inf --> 0.173681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1500118\n",
      "\tspeed: 0.1981s/iter; left time: 3368.2710s\n",
      "\titers: 200, epoch: 2 | loss: 0.1424053\n",
      "\tspeed: 0.0684s/iter; left time: 1155.5695s\n",
      "\titers: 300, epoch: 2 | loss: 0.1532765\n",
      "\tspeed: 0.0726s/iter; left time: 1219.5615s\n",
      "\titers: 400, epoch: 2 | loss: 0.1376351\n",
      "\tspeed: 0.0692s/iter; left time: 1155.0297s\n",
      "\titers: 500, epoch: 2 | loss: 0.1325575\n",
      "\tspeed: 0.0674s/iter; left time: 1119.5011s\n",
      "\titers: 600, epoch: 2 | loss: 0.1303877\n",
      "\tspeed: 0.0687s/iter; left time: 1133.3576s\n",
      "\titers: 700, epoch: 2 | loss: 0.1300402\n",
      "\tspeed: 0.0680s/iter; left time: 1116.0552s\n",
      "\titers: 800, epoch: 2 | loss: 0.1307981\n",
      "\tspeed: 0.0688s/iter; left time: 1120.7381s\n",
      "\titers: 900, epoch: 2 | loss: 0.1267860\n",
      "\tspeed: 0.0702s/iter; left time: 1137.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.44s\n",
      "Steps: 900 | Train Loss: 0.1408517 Vali Loss: 0.1658910 Test Loss: 0.1921326\n",
      "Validation loss decreased (0.173681 --> 0.165891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1326416\n",
      "\tspeed: 0.1933s/iter; left time: 3113.0817s\n",
      "\titers: 200, epoch: 3 | loss: 0.1315781\n",
      "\tspeed: 0.0678s/iter; left time: 1085.2540s\n",
      "\titers: 300, epoch: 3 | loss: 0.1253469\n",
      "\tspeed: 0.0679s/iter; left time: 1079.0576s\n",
      "\titers: 400, epoch: 3 | loss: 0.1312651\n",
      "\tspeed: 0.0663s/iter; left time: 1047.5309s\n",
      "\titers: 500, epoch: 3 | loss: 0.1303569\n",
      "\tspeed: 0.0670s/iter; left time: 1051.5647s\n",
      "\titers: 600, epoch: 3 | loss: 0.1203315\n",
      "\tspeed: 0.0677s/iter; left time: 1056.1294s\n",
      "\titers: 700, epoch: 3 | loss: 0.1259959\n",
      "\tspeed: 0.0703s/iter; left time: 1090.0446s\n",
      "\titers: 800, epoch: 3 | loss: 0.1252832\n",
      "\tspeed: 0.0680s/iter; left time: 1047.8582s\n",
      "\titers: 900, epoch: 3 | loss: 0.1110747\n",
      "\tspeed: 0.0659s/iter; left time: 1007.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:01.23s\n",
      "Steps: 900 | Train Loss: 0.1279732 Vali Loss: 0.1500364 Test Loss: 0.1833614\n",
      "Validation loss decreased (0.165891 --> 0.150036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1210924\n",
      "\tspeed: 0.1912s/iter; left time: 2906.9046s\n",
      "\titers: 200, epoch: 4 | loss: 0.1149703\n",
      "\tspeed: 0.0685s/iter; left time: 1034.9464s\n",
      "\titers: 300, epoch: 4 | loss: 0.1128671\n",
      "\tspeed: 0.0676s/iter; left time: 1014.1223s\n",
      "\titers: 400, epoch: 4 | loss: 0.1191279\n",
      "\tspeed: 0.0664s/iter; left time: 989.6865s\n",
      "\titers: 500, epoch: 4 | loss: 0.1118654\n",
      "\tspeed: 0.0673s/iter; left time: 995.4262s\n",
      "\titers: 600, epoch: 4 | loss: 0.1075311\n",
      "\tspeed: 0.0687s/iter; left time: 1009.4595s\n",
      "\titers: 700, epoch: 4 | loss: 0.1089362\n",
      "\tspeed: 0.0672s/iter; left time: 981.2101s\n",
      "\titers: 800, epoch: 4 | loss: 0.1108903\n",
      "\tspeed: 0.0665s/iter; left time: 964.6115s\n",
      "\titers: 900, epoch: 4 | loss: 0.1048714\n",
      "\tspeed: 0.0689s/iter; left time: 991.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:01.10s\n",
      "Steps: 900 | Train Loss: 0.1127066 Vali Loss: 0.1462878 Test Loss: 0.1805487\n",
      "Validation loss decreased (0.150036 --> 0.146288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029597\n",
      "\tspeed: 0.1816s/iter; left time: 2597.4668s\n",
      "\titers: 200, epoch: 5 | loss: 0.1061077\n",
      "\tspeed: 0.0640s/iter; left time: 909.2605s\n",
      "\titers: 300, epoch: 5 | loss: 0.1030705\n",
      "\tspeed: 0.0648s/iter; left time: 913.6200s\n",
      "\titers: 400, epoch: 5 | loss: 0.1064527\n",
      "\tspeed: 0.0677s/iter; left time: 947.6802s\n",
      "\titers: 500, epoch: 5 | loss: 0.0943053\n",
      "\tspeed: 0.0690s/iter; left time: 959.5052s\n",
      "\titers: 600, epoch: 5 | loss: 0.0918113\n",
      "\tspeed: 0.0669s/iter; left time: 923.4944s\n",
      "\titers: 700, epoch: 5 | loss: 0.0971458\n",
      "\tspeed: 0.0666s/iter; left time: 912.6662s\n",
      "\titers: 800, epoch: 5 | loss: 0.0970278\n",
      "\tspeed: 0.0677s/iter; left time: 920.3829s\n",
      "\titers: 900, epoch: 5 | loss: 0.0888742\n",
      "\tspeed: 0.0676s/iter; left time: 912.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.09s\n",
      "Steps: 900 | Train Loss: 0.0997664 Vali Loss: 0.1400724 Test Loss: 0.1754277\n",
      "Validation loss decreased (0.146288 --> 0.140072).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916264\n",
      "\tspeed: 0.1934s/iter; left time: 2591.2297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0882131\n",
      "\tspeed: 0.0681s/iter; left time: 905.5381s\n",
      "\titers: 300, epoch: 6 | loss: 0.0918872\n",
      "\tspeed: 0.0687s/iter; left time: 906.5037s\n",
      "\titers: 400, epoch: 6 | loss: 0.0859831\n",
      "\tspeed: 0.0681s/iter; left time: 892.5587s\n",
      "\titers: 500, epoch: 6 | loss: 0.0882370\n",
      "\tspeed: 0.0678s/iter; left time: 881.9476s\n",
      "\titers: 600, epoch: 6 | loss: 0.0913180\n",
      "\tspeed: 0.0712s/iter; left time: 918.0716s\n",
      "\titers: 700, epoch: 6 | loss: 0.0843049\n",
      "\tspeed: 0.0705s/iter; left time: 902.8936s\n",
      "\titers: 800, epoch: 6 | loss: 0.0857140\n",
      "\tspeed: 0.0694s/iter; left time: 881.0738s\n",
      "\titers: 900, epoch: 6 | loss: 0.0819938\n",
      "\tspeed: 0.0674s/iter; left time: 849.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:02.28s\n",
      "Steps: 900 | Train Loss: 0.0870982 Vali Loss: 0.1362018 Test Loss: 0.1694082\n",
      "Validation loss decreased (0.140072 --> 0.136202).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0813140\n",
      "\tspeed: 0.2018s/iter; left time: 2523.2463s\n",
      "\titers: 200, epoch: 7 | loss: 0.0821142\n",
      "\tspeed: 0.0701s/iter; left time: 869.2863s\n",
      "\titers: 300, epoch: 7 | loss: 0.0851680\n",
      "\tspeed: 0.0684s/iter; left time: 841.7835s\n",
      "\titers: 400, epoch: 7 | loss: 0.0894461\n",
      "\tspeed: 0.0699s/iter; left time: 853.1701s\n",
      "\titers: 500, epoch: 7 | loss: 0.0841470\n",
      "\tspeed: 0.0681s/iter; left time: 823.5668s\n",
      "\titers: 600, epoch: 7 | loss: 0.0791634\n",
      "\tspeed: 0.0690s/iter; left time: 828.5647s\n",
      "\titers: 700, epoch: 7 | loss: 0.0766609\n",
      "\tspeed: 0.0701s/iter; left time: 833.8202s\n",
      "\titers: 800, epoch: 7 | loss: 0.0779586\n",
      "\tspeed: 0.0677s/iter; left time: 799.3404s\n",
      "\titers: 900, epoch: 7 | loss: 0.0804471\n",
      "\tspeed: 0.0653s/iter; left time: 764.5181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:02.25s\n",
      "Steps: 900 | Train Loss: 0.0806170 Vali Loss: 0.1361363 Test Loss: 0.1707287\n",
      "Validation loss decreased (0.136202 --> 0.136136).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800280\n",
      "\tspeed: 0.1660s/iter; left time: 1925.6309s\n",
      "\titers: 200, epoch: 8 | loss: 0.0732196\n",
      "\tspeed: 0.0629s/iter; left time: 722.8691s\n",
      "\titers: 300, epoch: 8 | loss: 0.0733048\n",
      "\tspeed: 0.0656s/iter; left time: 747.4585s\n",
      "\titers: 400, epoch: 8 | loss: 0.0780477\n",
      "\tspeed: 0.0648s/iter; left time: 732.0357s\n",
      "\titers: 500, epoch: 8 | loss: 0.0729531\n",
      "\tspeed: 0.0637s/iter; left time: 713.1714s\n",
      "\titers: 600, epoch: 8 | loss: 0.0768064\n",
      "\tspeed: 0.0634s/iter; left time: 704.2809s\n",
      "\titers: 700, epoch: 8 | loss: 0.0726582\n",
      "\tspeed: 0.0632s/iter; left time: 694.8295s\n",
      "\titers: 800, epoch: 8 | loss: 0.0754959\n",
      "\tspeed: 0.0644s/iter; left time: 702.3372s\n",
      "\titers: 900, epoch: 8 | loss: 0.0710486\n",
      "\tspeed: 0.0644s/iter; left time: 695.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:57.64s\n",
      "Steps: 900 | Train Loss: 0.0762416 Vali Loss: 0.1396767 Test Loss: 0.1713988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0737892\n",
      "\tspeed: 0.1653s/iter; left time: 1768.5383s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780689\n",
      "\tspeed: 0.0629s/iter; left time: 666.7809s\n",
      "\titers: 300, epoch: 9 | loss: 0.0721863\n",
      "\tspeed: 0.0630s/iter; left time: 661.1691s\n",
      "\titers: 400, epoch: 9 | loss: 0.0710263\n",
      "\tspeed: 0.0628s/iter; left time: 653.1758s\n",
      "\titers: 500, epoch: 9 | loss: 0.0740344\n",
      "\tspeed: 0.0619s/iter; left time: 638.1091s\n",
      "\titers: 600, epoch: 9 | loss: 0.0686198\n",
      "\tspeed: 0.0612s/iter; left time: 624.2948s\n",
      "\titers: 700, epoch: 9 | loss: 0.0770345\n",
      "\tspeed: 0.0608s/iter; left time: 613.9396s\n",
      "\titers: 800, epoch: 9 | loss: 0.0719175\n",
      "\tspeed: 0.0608s/iter; left time: 608.4426s\n",
      "\titers: 900, epoch: 9 | loss: 0.0735625\n",
      "\tspeed: 0.0610s/iter; left time: 603.8076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:56.20s\n",
      "Steps: 900 | Train Loss: 0.0726711 Vali Loss: 0.1388696 Test Loss: 0.1723199\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0683234\n",
      "\tspeed: 0.1625s/iter; left time: 1592.8920s\n",
      "\titers: 200, epoch: 10 | loss: 0.0715558\n",
      "\tspeed: 0.0610s/iter; left time: 591.5050s\n",
      "\titers: 300, epoch: 10 | loss: 0.0701727\n",
      "\tspeed: 0.0613s/iter; left time: 588.4121s\n",
      "\titers: 400, epoch: 10 | loss: 0.0694180\n",
      "\tspeed: 0.0609s/iter; left time: 578.6562s\n",
      "\titers: 500, epoch: 10 | loss: 0.0700559\n",
      "\tspeed: 0.0614s/iter; left time: 577.5493s\n",
      "\titers: 600, epoch: 10 | loss: 0.0650823\n",
      "\tspeed: 0.0611s/iter; left time: 568.4226s\n",
      "\titers: 700, epoch: 10 | loss: 0.0677874\n",
      "\tspeed: 0.0607s/iter; left time: 558.1670s\n",
      "\titers: 800, epoch: 10 | loss: 0.0689620\n",
      "\tspeed: 0.0614s/iter; left time: 558.7582s\n",
      "\titers: 900, epoch: 10 | loss: 0.0707595\n",
      "\tspeed: 0.0618s/iter; left time: 556.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:55.39s\n",
      "Steps: 900 | Train Loss: 0.0693872 Vali Loss: 0.1394778 Test Loss: 0.1764171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0618437\n",
      "\tspeed: 0.1623s/iter; left time: 1444.3067s\n",
      "\titers: 200, epoch: 11 | loss: 0.0661122\n",
      "\tspeed: 0.0624s/iter; left time: 548.8477s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647888\n",
      "\tspeed: 0.0609s/iter; left time: 530.1527s\n",
      "\titers: 400, epoch: 11 | loss: 0.0630879\n",
      "\tspeed: 0.0614s/iter; left time: 528.1910s\n",
      "\titers: 500, epoch: 11 | loss: 0.0643404\n",
      "\tspeed: 0.0607s/iter; left time: 515.7366s\n",
      "\titers: 600, epoch: 11 | loss: 0.0694348\n",
      "\tspeed: 0.0625s/iter; left time: 524.8684s\n",
      "\titers: 700, epoch: 11 | loss: 0.0688733\n",
      "\tspeed: 0.0624s/iter; left time: 518.0987s\n",
      "\titers: 800, epoch: 11 | loss: 0.0633101\n",
      "\tspeed: 0.0625s/iter; left time: 512.9497s\n",
      "\titers: 900, epoch: 11 | loss: 0.0695966\n",
      "\tspeed: 0.0629s/iter; left time: 509.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:56.03s\n",
      "Steps: 900 | Train Loss: 0.0664819 Vali Loss: 0.1400574 Test Loss: 0.1746322\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0619930\n",
      "\tspeed: 0.1620s/iter; left time: 1295.9092s\n",
      "\titers: 200, epoch: 12 | loss: 0.0680163\n",
      "\tspeed: 0.0626s/iter; left time: 494.7730s\n",
      "\titers: 300, epoch: 12 | loss: 0.0657991\n",
      "\tspeed: 0.0615s/iter; left time: 479.7753s\n",
      "\titers: 400, epoch: 12 | loss: 0.0614273\n",
      "\tspeed: 0.0610s/iter; left time: 469.9485s\n",
      "\titers: 500, epoch: 12 | loss: 0.0699258\n",
      "\tspeed: 0.0614s/iter; left time: 466.4569s\n",
      "\titers: 600, epoch: 12 | loss: 0.0625969\n",
      "\tspeed: 0.0607s/iter; left time: 455.0736s\n",
      "\titers: 700, epoch: 12 | loss: 0.0621551\n",
      "\tspeed: 0.0612s/iter; left time: 452.8217s\n",
      "\titers: 800, epoch: 12 | loss: 0.0660917\n",
      "\tspeed: 0.0609s/iter; left time: 444.7735s\n",
      "\titers: 900, epoch: 12 | loss: 0.0594676\n",
      "\tspeed: 0.0612s/iter; left time: 440.9984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:55.54s\n",
      "Steps: 900 | Train Loss: 0.0640202 Vali Loss: 0.1381647 Test Loss: 0.1732498\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06292843818664551, rmse:0.250855416059494, mae:0.17068493366241455, rse:0.8696832656860352\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2293560\n",
      "\tspeed: 0.0635s/iter; left time: 1137.5763s\n",
      "\titers: 200, epoch: 1 | loss: 0.2054293\n",
      "\tspeed: 0.0621s/iter; left time: 1106.2211s\n",
      "\titers: 300, epoch: 1 | loss: 0.1900173\n",
      "\tspeed: 0.0619s/iter; left time: 1095.5775s\n",
      "\titers: 400, epoch: 1 | loss: 0.1786476\n",
      "\tspeed: 0.0614s/iter; left time: 1081.1478s\n",
      "\titers: 500, epoch: 1 | loss: 0.1853510\n",
      "\tspeed: 0.0619s/iter; left time: 1083.0858s\n",
      "\titers: 600, epoch: 1 | loss: 0.1723691\n",
      "\tspeed: 0.0617s/iter; left time: 1073.5466s\n",
      "\titers: 700, epoch: 1 | loss: 0.1693832\n",
      "\tspeed: 0.0595s/iter; left time: 1028.7089s\n",
      "\titers: 800, epoch: 1 | loss: 0.1639853\n",
      "\tspeed: 0.0621s/iter; left time: 1068.2959s\n",
      "\titers: 900, epoch: 1 | loss: 0.1605734\n",
      "\tspeed: 0.0620s/iter; left time: 1059.5867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.69s\n",
      "Steps: 900 | Train Loss: 0.1908266 Vali Loss: 0.1790047 Test Loss: 0.2145092\n",
      "Validation loss decreased (inf --> 0.179005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1421391\n",
      "\tspeed: 0.1673s/iter; left time: 2844.1823s\n",
      "\titers: 200, epoch: 2 | loss: 0.1388582\n",
      "\tspeed: 0.0633s/iter; left time: 1069.8137s\n",
      "\titers: 300, epoch: 2 | loss: 0.1389616\n",
      "\tspeed: 0.0638s/iter; left time: 1072.5030s\n",
      "\titers: 400, epoch: 2 | loss: 0.1374534\n",
      "\tspeed: 0.0618s/iter; left time: 1032.8209s\n",
      "\titers: 500, epoch: 2 | loss: 0.1329038\n",
      "\tspeed: 0.0614s/iter; left time: 1018.7696s\n",
      "\titers: 600, epoch: 2 | loss: 0.1351897\n",
      "\tspeed: 0.0608s/iter; left time: 1003.2362s\n",
      "\titers: 700, epoch: 2 | loss: 0.1323122\n",
      "\tspeed: 0.0614s/iter; left time: 1006.9428s\n",
      "\titers: 800, epoch: 2 | loss: 0.1286181\n",
      "\tspeed: 0.0607s/iter; left time: 990.2351s\n",
      "\titers: 900, epoch: 2 | loss: 0.1308096\n",
      "\tspeed: 0.0608s/iter; left time: 984.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.99s\n",
      "Steps: 900 | Train Loss: 0.1377203 Vali Loss: 0.1582811 Test Loss: 0.1916950\n",
      "Validation loss decreased (0.179005 --> 0.158281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1270013\n",
      "\tspeed: 0.1666s/iter; left time: 2681.6589s\n",
      "\titers: 200, epoch: 3 | loss: 0.1191770\n",
      "\tspeed: 0.0612s/iter; left time: 979.9327s\n",
      "\titers: 300, epoch: 3 | loss: 0.1196750\n",
      "\tspeed: 0.0610s/iter; left time: 969.3973s\n",
      "\titers: 400, epoch: 3 | loss: 0.1224972\n",
      "\tspeed: 0.0603s/iter; left time: 953.5062s\n",
      "\titers: 500, epoch: 3 | loss: 0.1120898\n",
      "\tspeed: 0.0592s/iter; left time: 928.8554s\n",
      "\titers: 600, epoch: 3 | loss: 0.1202096\n",
      "\tspeed: 0.0580s/iter; left time: 904.7741s\n",
      "\titers: 700, epoch: 3 | loss: 0.1147640\n",
      "\tspeed: 0.0568s/iter; left time: 880.0697s\n",
      "\titers: 800, epoch: 3 | loss: 0.1130330\n",
      "\tspeed: 0.0594s/iter; left time: 915.2640s\n",
      "\titers: 900, epoch: 3 | loss: 0.1170418\n",
      "\tspeed: 0.0583s/iter; left time: 891.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.93s\n",
      "Steps: 900 | Train Loss: 0.1187953 Vali Loss: 0.1517055 Test Loss: 0.1779766\n",
      "Validation loss decreased (0.158281 --> 0.151705).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1171589\n",
      "\tspeed: 0.1672s/iter; left time: 2541.3311s\n",
      "\titers: 200, epoch: 4 | loss: 0.1145005\n",
      "\tspeed: 0.0627s/iter; left time: 946.8902s\n",
      "\titers: 300, epoch: 4 | loss: 0.1137957\n",
      "\tspeed: 0.0617s/iter; left time: 925.2244s\n",
      "\titers: 400, epoch: 4 | loss: 0.1075047\n",
      "\tspeed: 0.0615s/iter; left time: 916.1545s\n",
      "\titers: 500, epoch: 4 | loss: 0.1052206\n",
      "\tspeed: 0.0610s/iter; left time: 902.6922s\n",
      "\titers: 600, epoch: 4 | loss: 0.1100180\n",
      "\tspeed: 0.0611s/iter; left time: 898.0903s\n",
      "\titers: 700, epoch: 4 | loss: 0.1040445\n",
      "\tspeed: 0.0620s/iter; left time: 904.9112s\n",
      "\titers: 800, epoch: 4 | loss: 0.1112751\n",
      "\tspeed: 0.0612s/iter; left time: 887.4077s\n",
      "\titers: 900, epoch: 4 | loss: 0.1122736\n",
      "\tspeed: 0.0621s/iter; left time: 893.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:55.84s\n",
      "Steps: 900 | Train Loss: 0.1092714 Vali Loss: 0.1493892 Test Loss: 0.1774123\n",
      "Validation loss decreased (0.151705 --> 0.149389).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1104288\n",
      "\tspeed: 0.1692s/iter; left time: 2420.4387s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012773\n",
      "\tspeed: 0.0628s/iter; left time: 891.9042s\n",
      "\titers: 300, epoch: 5 | loss: 0.1041354\n",
      "\tspeed: 0.0616s/iter; left time: 868.6511s\n",
      "\titers: 400, epoch: 5 | loss: 0.1029279\n",
      "\tspeed: 0.0617s/iter; left time: 864.3228s\n",
      "\titers: 500, epoch: 5 | loss: 0.0971832\n",
      "\tspeed: 0.0617s/iter; left time: 858.1361s\n",
      "\titers: 600, epoch: 5 | loss: 0.0934589\n",
      "\tspeed: 0.0629s/iter; left time: 867.5552s\n",
      "\titers: 700, epoch: 5 | loss: 0.0975845\n",
      "\tspeed: 0.0613s/iter; left time: 839.6063s\n",
      "\titers: 800, epoch: 5 | loss: 0.0985008\n",
      "\tspeed: 0.0618s/iter; left time: 840.4489s\n",
      "\titers: 900, epoch: 5 | loss: 0.1022269\n",
      "\tspeed: 0.0619s/iter; left time: 835.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.13s\n",
      "Steps: 900 | Train Loss: 0.1004431 Vali Loss: 0.1532303 Test Loss: 0.1851922\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0964485\n",
      "\tspeed: 0.1621s/iter; left time: 2172.5155s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926135\n",
      "\tspeed: 0.0610s/iter; left time: 810.7253s\n",
      "\titers: 300, epoch: 6 | loss: 0.0944415\n",
      "\tspeed: 0.0614s/iter; left time: 810.2543s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901237\n",
      "\tspeed: 0.0610s/iter; left time: 798.5939s\n",
      "\titers: 500, epoch: 6 | loss: 0.0950689\n",
      "\tspeed: 0.0608s/iter; left time: 790.2973s\n",
      "\titers: 600, epoch: 6 | loss: 0.0899204\n",
      "\tspeed: 0.0611s/iter; left time: 787.8754s\n",
      "\titers: 700, epoch: 6 | loss: 0.0871553\n",
      "\tspeed: 0.0616s/iter; left time: 788.2439s\n",
      "\titers: 800, epoch: 6 | loss: 0.0903655\n",
      "\tspeed: 0.0608s/iter; left time: 771.9065s\n",
      "\titers: 900, epoch: 6 | loss: 0.0886016\n",
      "\tspeed: 0.0610s/iter; left time: 768.4844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.21s\n",
      "Steps: 900 | Train Loss: 0.0916229 Vali Loss: 0.1476179 Test Loss: 0.1798929\n",
      "Validation loss decreased (0.149389 --> 0.147618).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0900446\n",
      "\tspeed: 0.1665s/iter; left time: 2081.3200s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836732\n",
      "\tspeed: 0.0608s/iter; left time: 753.7818s\n",
      "\titers: 300, epoch: 7 | loss: 0.0800997\n",
      "\tspeed: 0.0618s/iter; left time: 760.4998s\n",
      "\titers: 400, epoch: 7 | loss: 0.0816429\n",
      "\tspeed: 0.0588s/iter; left time: 717.0577s\n",
      "\titers: 500, epoch: 7 | loss: 0.0807029\n",
      "\tspeed: 0.0590s/iter; left time: 713.8159s\n",
      "\titers: 600, epoch: 7 | loss: 0.0882307\n",
      "\tspeed: 0.0614s/iter; left time: 736.6612s\n",
      "\titers: 700, epoch: 7 | loss: 0.0856625\n",
      "\tspeed: 0.0624s/iter; left time: 742.5864s\n",
      "\titers: 800, epoch: 7 | loss: 0.0745999\n",
      "\tspeed: 0.0615s/iter; left time: 725.7873s\n",
      "\titers: 900, epoch: 7 | loss: 0.0803876\n",
      "\tspeed: 0.0623s/iter; left time: 729.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.24s\n",
      "Steps: 900 | Train Loss: 0.0816760 Vali Loss: 0.1417849 Test Loss: 0.1741753\n",
      "Validation loss decreased (0.147618 --> 0.141785).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0731656\n",
      "\tspeed: 0.1669s/iter; left time: 1936.5244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0744070\n",
      "\tspeed: 0.0594s/iter; left time: 683.2288s\n",
      "\titers: 300, epoch: 8 | loss: 0.0783141\n",
      "\tspeed: 0.0569s/iter; left time: 648.3757s\n",
      "\titers: 400, epoch: 8 | loss: 0.0721648\n",
      "\tspeed: 0.0569s/iter; left time: 642.5976s\n",
      "\titers: 500, epoch: 8 | loss: 0.0788492\n",
      "\tspeed: 0.0579s/iter; left time: 649.0029s\n",
      "\titers: 600, epoch: 8 | loss: 0.0779122\n",
      "\tspeed: 0.0569s/iter; left time: 631.2206s\n",
      "\titers: 700, epoch: 8 | loss: 0.0726748\n",
      "\tspeed: 0.0570s/iter; left time: 627.0957s\n",
      "\titers: 800, epoch: 8 | loss: 0.0772945\n",
      "\tspeed: 0.0570s/iter; left time: 621.3957s\n",
      "\titers: 900, epoch: 8 | loss: 0.0755315\n",
      "\tspeed: 0.0570s/iter; left time: 615.9185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.46s\n",
      "Steps: 900 | Train Loss: 0.0759615 Vali Loss: 0.1407801 Test Loss: 0.1750955\n",
      "Validation loss decreased (0.141785 --> 0.140780).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0752748\n",
      "\tspeed: 0.1677s/iter; left time: 1794.7539s\n",
      "\titers: 200, epoch: 9 | loss: 0.0721781\n",
      "\tspeed: 0.0621s/iter; left time: 657.9033s\n",
      "\titers: 300, epoch: 9 | loss: 0.0690940\n",
      "\tspeed: 0.0622s/iter; left time: 652.7773s\n",
      "\titers: 400, epoch: 9 | loss: 0.0680573\n",
      "\tspeed: 0.0620s/iter; left time: 645.1686s\n",
      "\titers: 500, epoch: 9 | loss: 0.0749249\n",
      "\tspeed: 0.0616s/iter; left time: 635.0326s\n",
      "\titers: 600, epoch: 9 | loss: 0.0743074\n",
      "\tspeed: 0.0611s/iter; left time: 623.2434s\n",
      "\titers: 700, epoch: 9 | loss: 0.0716757\n",
      "\tspeed: 0.0608s/iter; left time: 614.1609s\n",
      "\titers: 800, epoch: 9 | loss: 0.0705896\n",
      "\tspeed: 0.0607s/iter; left time: 607.2194s\n",
      "\titers: 900, epoch: 9 | loss: 0.0748434\n",
      "\tspeed: 0.0608s/iter; left time: 601.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:55.60s\n",
      "Steps: 900 | Train Loss: 0.0723382 Vali Loss: 0.1429294 Test Loss: 0.1776589\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0703364\n",
      "\tspeed: 0.1630s/iter; left time: 1597.2314s\n",
      "\titers: 200, epoch: 10 | loss: 0.0763479\n",
      "\tspeed: 0.0609s/iter; left time: 591.0530s\n",
      "\titers: 300, epoch: 10 | loss: 0.0694418\n",
      "\tspeed: 0.0616s/iter; left time: 591.5222s\n",
      "\titers: 400, epoch: 10 | loss: 0.0685934\n",
      "\tspeed: 0.0613s/iter; left time: 582.3154s\n",
      "\titers: 500, epoch: 10 | loss: 0.0679210\n",
      "\tspeed: 0.0619s/iter; left time: 581.7947s\n",
      "\titers: 600, epoch: 10 | loss: 0.0683651\n",
      "\tspeed: 0.0615s/iter; left time: 571.5666s\n",
      "\titers: 700, epoch: 10 | loss: 0.0723628\n",
      "\tspeed: 0.0613s/iter; left time: 564.4285s\n",
      "\titers: 800, epoch: 10 | loss: 0.0699840\n",
      "\tspeed: 0.0610s/iter; left time: 554.8672s\n",
      "\titers: 900, epoch: 10 | loss: 0.0660674\n",
      "\tspeed: 0.0611s/iter; left time: 549.5669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:55.45s\n",
      "Steps: 900 | Train Loss: 0.0689834 Vali Loss: 0.1402610 Test Loss: 0.1771575\n",
      "Validation loss decreased (0.140780 --> 0.140261).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0645286\n",
      "\tspeed: 0.1620s/iter; left time: 1442.3933s\n",
      "\titers: 200, epoch: 11 | loss: 0.0668607\n",
      "\tspeed: 0.0568s/iter; left time: 500.3107s\n",
      "\titers: 300, epoch: 11 | loss: 0.0717360\n",
      "\tspeed: 0.0603s/iter; left time: 524.9807s\n",
      "\titers: 400, epoch: 11 | loss: 0.0661930\n",
      "\tspeed: 0.0607s/iter; left time: 522.0799s\n",
      "\titers: 500, epoch: 11 | loss: 0.0673763\n",
      "\tspeed: 0.0611s/iter; left time: 519.1338s\n",
      "\titers: 600, epoch: 11 | loss: 0.0635791\n",
      "\tspeed: 0.0611s/iter; left time: 513.1462s\n",
      "\titers: 700, epoch: 11 | loss: 0.0669262\n",
      "\tspeed: 0.0616s/iter; left time: 511.0740s\n",
      "\titers: 800, epoch: 11 | loss: 0.0649403\n",
      "\tspeed: 0.0607s/iter; left time: 497.8355s\n",
      "\titers: 900, epoch: 11 | loss: 0.0653125\n",
      "\tspeed: 0.0612s/iter; left time: 495.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:54.32s\n",
      "Steps: 900 | Train Loss: 0.0661126 Vali Loss: 0.1431191 Test Loss: 0.1781114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0619500\n",
      "\tspeed: 0.1629s/iter; left time: 1302.9706s\n",
      "\titers: 200, epoch: 12 | loss: 0.0632207\n",
      "\tspeed: 0.0611s/iter; left time: 482.7565s\n",
      "\titers: 300, epoch: 12 | loss: 0.0650798\n",
      "\tspeed: 0.0607s/iter; left time: 473.5330s\n",
      "\titers: 400, epoch: 12 | loss: 0.0645208\n",
      "\tspeed: 0.0607s/iter; left time: 467.1549s\n",
      "\titers: 500, epoch: 12 | loss: 0.0592807\n",
      "\tspeed: 0.0607s/iter; left time: 461.0065s\n",
      "\titers: 600, epoch: 12 | loss: 0.0672561\n",
      "\tspeed: 0.0608s/iter; left time: 455.9847s\n",
      "\titers: 700, epoch: 12 | loss: 0.0663752\n",
      "\tspeed: 0.0610s/iter; left time: 451.2965s\n",
      "\titers: 800, epoch: 12 | loss: 0.0648330\n",
      "\tspeed: 0.0615s/iter; left time: 448.7159s\n",
      "\titers: 900, epoch: 12 | loss: 0.0639067\n",
      "\tspeed: 0.0611s/iter; left time: 440.2293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:55.15s\n",
      "Steps: 900 | Train Loss: 0.0636617 Vali Loss: 0.1431491 Test Loss: 0.1805828\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0619058\n",
      "\tspeed: 0.1630s/iter; left time: 1157.1779s\n",
      "\titers: 200, epoch: 13 | loss: 0.0668784\n",
      "\tspeed: 0.0611s/iter; left time: 427.7850s\n",
      "\titers: 300, epoch: 13 | loss: 0.0562981\n",
      "\tspeed: 0.0610s/iter; left time: 420.9137s\n",
      "\titers: 400, epoch: 13 | loss: 0.0603311\n",
      "\tspeed: 0.0616s/iter; left time: 418.8965s\n",
      "\titers: 500, epoch: 13 | loss: 0.0595990\n",
      "\tspeed: 0.0613s/iter; left time: 410.7057s\n",
      "\titers: 600, epoch: 13 | loss: 0.0613854\n",
      "\tspeed: 0.0612s/iter; left time: 403.9660s\n",
      "\titers: 700, epoch: 13 | loss: 0.0599398\n",
      "\tspeed: 0.0610s/iter; left time: 396.6076s\n",
      "\titers: 800, epoch: 13 | loss: 0.0644775\n",
      "\tspeed: 0.0614s/iter; left time: 393.1367s\n",
      "\titers: 900, epoch: 13 | loss: 0.0595841\n",
      "\tspeed: 0.0612s/iter; left time: 385.7796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:55.45s\n",
      "Steps: 900 | Train Loss: 0.0616466 Vali Loss: 0.1409219 Test Loss: 0.1775428\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0612245\n",
      "\tspeed: 0.1623s/iter; left time: 1006.5356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0609868\n",
      "\tspeed: 0.0615s/iter; left time: 375.1730s\n",
      "\titers: 300, epoch: 14 | loss: 0.0560883\n",
      "\tspeed: 0.0615s/iter; left time: 368.8026s\n",
      "\titers: 400, epoch: 14 | loss: 0.0606557\n",
      "\tspeed: 0.0581s/iter; left time: 342.6225s\n",
      "\titers: 500, epoch: 14 | loss: 0.0598517\n",
      "\tspeed: 0.0568s/iter; left time: 329.3529s\n",
      "\titers: 600, epoch: 14 | loss: 0.0628005\n",
      "\tspeed: 0.0615s/iter; left time: 350.8458s\n",
      "\titers: 700, epoch: 14 | loss: 0.0563993\n",
      "\tspeed: 0.0620s/iter; left time: 347.2985s\n",
      "\titers: 800, epoch: 14 | loss: 0.0592281\n",
      "\tspeed: 0.0584s/iter; left time: 321.0094s\n",
      "\titers: 900, epoch: 14 | loss: 0.0641531\n",
      "\tspeed: 0.0567s/iter; left time: 306.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:54.00s\n",
      "Steps: 900 | Train Loss: 0.0600984 Vali Loss: 0.1411320 Test Loss: 0.1790199\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0591424\n",
      "\tspeed: 0.1630s/iter; left time: 863.8810s\n",
      "\titers: 200, epoch: 15 | loss: 0.0577055\n",
      "\tspeed: 0.0612s/iter; left time: 318.1128s\n",
      "\titers: 300, epoch: 15 | loss: 0.0597280\n",
      "\tspeed: 0.0608s/iter; left time: 309.9782s\n",
      "\titers: 400, epoch: 15 | loss: 0.0603560\n",
      "\tspeed: 0.0608s/iter; left time: 303.9250s\n",
      "\titers: 500, epoch: 15 | loss: 0.0598284\n",
      "\tspeed: 0.0614s/iter; left time: 300.8383s\n",
      "\titers: 600, epoch: 15 | loss: 0.0613034\n",
      "\tspeed: 0.0609s/iter; left time: 292.1959s\n",
      "\titers: 700, epoch: 15 | loss: 0.0607626\n",
      "\tspeed: 0.0607s/iter; left time: 285.3522s\n",
      "\titers: 800, epoch: 15 | loss: 0.0551255\n",
      "\tspeed: 0.0607s/iter; left time: 279.4652s\n",
      "\titers: 900, epoch: 15 | loss: 0.0577309\n",
      "\tspeed: 0.0609s/iter; left time: 274.1946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:55.14s\n",
      "Steps: 900 | Train Loss: 0.0587085 Vali Loss: 0.1405999 Test Loss: 0.1795350\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06641010195016861, rmse:0.257701575756073, mae:0.177326962351799, rse:0.8934180736541748\n",
      "Intermediate time for GB and pred_len 168: 00h:30m:40.89s\n",
      "Intermediate time for GB: 01h:08m:12.79s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2255589\n",
      "\tspeed: 0.0799s/iter; left time: 1436.6814s\n",
      "\titers: 200, epoch: 1 | loss: 0.2096690\n",
      "\tspeed: 0.0522s/iter; left time: 933.0989s\n",
      "\titers: 300, epoch: 1 | loss: 0.2151971\n",
      "\tspeed: 0.0522s/iter; left time: 928.4607s\n",
      "\titers: 400, epoch: 1 | loss: 0.1993971\n",
      "\tspeed: 0.0520s/iter; left time: 920.0319s\n",
      "\titers: 500, epoch: 1 | loss: 0.1838684\n",
      "\tspeed: 0.0525s/iter; left time: 922.9028s\n",
      "\titers: 600, epoch: 1 | loss: 0.1644840\n",
      "\tspeed: 0.0527s/iter; left time: 921.6293s\n",
      "\titers: 700, epoch: 1 | loss: 0.1627082\n",
      "\tspeed: 0.0512s/iter; left time: 889.7071s\n",
      "\titers: 800, epoch: 1 | loss: 0.1487862\n",
      "\tspeed: 0.0505s/iter; left time: 873.4467s\n",
      "\titers: 900, epoch: 1 | loss: 0.1414283\n",
      "\tspeed: 0.0505s/iter; left time: 867.8196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.61s\n",
      "Steps: 904 | Train Loss: 0.1905402 Vali Loss: 0.1208565 Test Loss: 0.1507125\n",
      "Validation loss decreased (inf --> 0.120857).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1248358\n",
      "\tspeed: 0.1315s/iter; left time: 2245.2473s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042962\n",
      "\tspeed: 0.0505s/iter; left time: 857.5349s\n",
      "\titers: 300, epoch: 2 | loss: 0.0981534\n",
      "\tspeed: 0.0506s/iter; left time: 853.6691s\n",
      "\titers: 400, epoch: 2 | loss: 0.0862036\n",
      "\tspeed: 0.0502s/iter; left time: 842.8193s\n",
      "\titers: 500, epoch: 2 | loss: 0.0791885\n",
      "\tspeed: 0.0507s/iter; left time: 845.6423s\n",
      "\titers: 600, epoch: 2 | loss: 0.0769233\n",
      "\tspeed: 0.0505s/iter; left time: 836.9622s\n",
      "\titers: 700, epoch: 2 | loss: 0.0829349\n",
      "\tspeed: 0.0506s/iter; left time: 832.9988s\n",
      "\titers: 800, epoch: 2 | loss: 0.0753934\n",
      "\tspeed: 0.0505s/iter; left time: 827.2189s\n",
      "\titers: 900, epoch: 2 | loss: 0.0798330\n",
      "\tspeed: 0.0507s/iter; left time: 824.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0920257 Vali Loss: 0.0736900 Test Loss: 0.0993799\n",
      "Validation loss decreased (0.120857 --> 0.073690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0760882\n",
      "\tspeed: 0.1330s/iter; left time: 2151.3891s\n",
      "\titers: 200, epoch: 3 | loss: 0.0762329\n",
      "\tspeed: 0.0505s/iter; left time: 812.1978s\n",
      "\titers: 300, epoch: 3 | loss: 0.0723280\n",
      "\tspeed: 0.0507s/iter; left time: 809.1450s\n",
      "\titers: 400, epoch: 3 | loss: 0.0680232\n",
      "\tspeed: 0.0506s/iter; left time: 802.8789s\n",
      "\titers: 500, epoch: 3 | loss: 0.0684247\n",
      "\tspeed: 0.0507s/iter; left time: 799.2990s\n",
      "\titers: 600, epoch: 3 | loss: 0.0751826\n",
      "\tspeed: 0.0506s/iter; left time: 793.7022s\n",
      "\titers: 700, epoch: 3 | loss: 0.0648076\n",
      "\tspeed: 0.0506s/iter; left time: 787.2645s\n",
      "\titers: 800, epoch: 3 | loss: 0.0683167\n",
      "\tspeed: 0.0507s/iter; left time: 784.0252s\n",
      "\titers: 900, epoch: 3 | loss: 0.0645895\n",
      "\tspeed: 0.0503s/iter; left time: 773.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0701676 Vali Loss: 0.0687564 Test Loss: 0.0979586\n",
      "Validation loss decreased (0.073690 --> 0.068756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0670081\n",
      "\tspeed: 0.1320s/iter; left time: 2016.1511s\n",
      "\titers: 200, epoch: 4 | loss: 0.0640812\n",
      "\tspeed: 0.0505s/iter; left time: 766.4187s\n",
      "\titers: 300, epoch: 4 | loss: 0.0626987\n",
      "\tspeed: 0.0505s/iter; left time: 761.4777s\n",
      "\titers: 400, epoch: 4 | loss: 0.0576538\n",
      "\tspeed: 0.0506s/iter; left time: 757.1461s\n",
      "\titers: 500, epoch: 4 | loss: 0.0622666\n",
      "\tspeed: 0.0506s/iter; left time: 752.5136s\n",
      "\titers: 600, epoch: 4 | loss: 0.0615554\n",
      "\tspeed: 0.0506s/iter; left time: 746.9490s\n",
      "\titers: 700, epoch: 4 | loss: 0.0674005\n",
      "\tspeed: 0.0507s/iter; left time: 743.8683s\n",
      "\titers: 800, epoch: 4 | loss: 0.0543134\n",
      "\tspeed: 0.0506s/iter; left time: 737.0125s\n",
      "\titers: 900, epoch: 4 | loss: 0.0676562\n",
      "\tspeed: 0.0507s/iter; left time: 733.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0645391 Vali Loss: 0.0705969 Test Loss: 0.1026542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629703\n",
      "\tspeed: 0.1287s/iter; left time: 1848.3832s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646909\n",
      "\tspeed: 0.0506s/iter; left time: 721.4314s\n",
      "\titers: 300, epoch: 5 | loss: 0.0645909\n",
      "\tspeed: 0.0506s/iter; left time: 716.3053s\n",
      "\titers: 400, epoch: 5 | loss: 0.0606854\n",
      "\tspeed: 0.0506s/iter; left time: 712.3106s\n",
      "\titers: 500, epoch: 5 | loss: 0.0595598\n",
      "\tspeed: 0.0506s/iter; left time: 706.5908s\n",
      "\titers: 600, epoch: 5 | loss: 0.0635789\n",
      "\tspeed: 0.0508s/iter; left time: 703.9662s\n",
      "\titers: 700, epoch: 5 | loss: 0.0613890\n",
      "\tspeed: 0.0505s/iter; left time: 695.5627s\n",
      "\titers: 800, epoch: 5 | loss: 0.0557902\n",
      "\tspeed: 0.0505s/iter; left time: 690.5804s\n",
      "\titers: 900, epoch: 5 | loss: 0.0535867\n",
      "\tspeed: 0.0505s/iter; left time: 685.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0612746 Vali Loss: 0.0691765 Test Loss: 0.0996833\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0634675\n",
      "\tspeed: 0.1292s/iter; left time: 1739.1818s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587117\n",
      "\tspeed: 0.0506s/iter; left time: 676.0141s\n",
      "\titers: 300, epoch: 6 | loss: 0.0583182\n",
      "\tspeed: 0.0508s/iter; left time: 673.2300s\n",
      "\titers: 400, epoch: 6 | loss: 0.0597041\n",
      "\tspeed: 0.0506s/iter; left time: 665.9950s\n",
      "\titers: 500, epoch: 6 | loss: 0.0507859\n",
      "\tspeed: 0.0505s/iter; left time: 660.0976s\n",
      "\titers: 600, epoch: 6 | loss: 0.0589903\n",
      "\tspeed: 0.0506s/iter; left time: 655.9136s\n",
      "\titers: 700, epoch: 6 | loss: 0.0564516\n",
      "\tspeed: 0.0505s/iter; left time: 649.9645s\n",
      "\titers: 800, epoch: 6 | loss: 0.0564816\n",
      "\tspeed: 0.0506s/iter; left time: 645.2422s\n",
      "\titers: 900, epoch: 6 | loss: 0.0538923\n",
      "\tspeed: 0.0506s/iter; left time: 640.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.0582138 Vali Loss: 0.0629753 Test Loss: 0.0963199\n",
      "Validation loss decreased (0.068756 --> 0.062975).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0518016\n",
      "\tspeed: 0.1326s/iter; left time: 1664.8971s\n",
      "\titers: 200, epoch: 7 | loss: 0.0589721\n",
      "\tspeed: 0.0505s/iter; left time: 629.1858s\n",
      "\titers: 300, epoch: 7 | loss: 0.0539779\n",
      "\tspeed: 0.0505s/iter; left time: 624.1260s\n",
      "\titers: 400, epoch: 7 | loss: 0.0630000\n",
      "\tspeed: 0.0506s/iter; left time: 619.7318s\n",
      "\titers: 500, epoch: 7 | loss: 0.0628908\n",
      "\tspeed: 0.0506s/iter; left time: 615.2462s\n",
      "\titers: 600, epoch: 7 | loss: 0.0558628\n",
      "\tspeed: 0.0506s/iter; left time: 609.6041s\n",
      "\titers: 700, epoch: 7 | loss: 0.0548050\n",
      "\tspeed: 0.0505s/iter; left time: 604.3245s\n",
      "\titers: 800, epoch: 7 | loss: 0.0579669\n",
      "\tspeed: 0.0506s/iter; left time: 599.6249s\n",
      "\titers: 900, epoch: 7 | loss: 0.0549988\n",
      "\tspeed: 0.0506s/iter; left time: 594.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0559897 Vali Loss: 0.0607082 Test Loss: 0.0927652\n",
      "Validation loss decreased (0.062975 --> 0.060708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0651012\n",
      "\tspeed: 0.1339s/iter; left time: 1560.3962s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554125\n",
      "\tspeed: 0.0504s/iter; left time: 581.9090s\n",
      "\titers: 300, epoch: 8 | loss: 0.0532947\n",
      "\tspeed: 0.0509s/iter; left time: 582.8445s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521505\n",
      "\tspeed: 0.0506s/iter; left time: 573.8956s\n",
      "\titers: 500, epoch: 8 | loss: 0.0549209\n",
      "\tspeed: 0.0505s/iter; left time: 568.2313s\n",
      "\titers: 600, epoch: 8 | loss: 0.0590593\n",
      "\tspeed: 0.0505s/iter; left time: 563.4446s\n",
      "\titers: 700, epoch: 8 | loss: 0.0568598\n",
      "\tspeed: 0.0504s/iter; left time: 557.5656s\n",
      "\titers: 800, epoch: 8 | loss: 0.0552392\n",
      "\tspeed: 0.0505s/iter; left time: 553.5393s\n",
      "\titers: 900, epoch: 8 | loss: 0.0526357\n",
      "\tspeed: 0.0507s/iter; left time: 549.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.0543089 Vali Loss: 0.0604855 Test Loss: 0.1008310\n",
      "Validation loss decreased (0.060708 --> 0.060485).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0584237\n",
      "\tspeed: 0.1340s/iter; left time: 1440.6027s\n",
      "\titers: 200, epoch: 9 | loss: 0.0471470\n",
      "\tspeed: 0.0506s/iter; left time: 538.3108s\n",
      "\titers: 300, epoch: 9 | loss: 0.0512029\n",
      "\tspeed: 0.0506s/iter; left time: 534.1522s\n",
      "\titers: 400, epoch: 9 | loss: 0.0474284\n",
      "\tspeed: 0.0505s/iter; left time: 527.5003s\n",
      "\titers: 500, epoch: 9 | loss: 0.0563559\n",
      "\tspeed: 0.0505s/iter; left time: 522.8805s\n",
      "\titers: 600, epoch: 9 | loss: 0.0506028\n",
      "\tspeed: 0.0507s/iter; left time: 519.4257s\n",
      "\titers: 700, epoch: 9 | loss: 0.0487366\n",
      "\tspeed: 0.0507s/iter; left time: 514.4497s\n",
      "\titers: 800, epoch: 9 | loss: 0.0574212\n",
      "\tspeed: 0.0504s/iter; left time: 506.5088s\n",
      "\titers: 900, epoch: 9 | loss: 0.0500641\n",
      "\tspeed: 0.0506s/iter; left time: 503.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0523846 Vali Loss: 0.0602276 Test Loss: 0.1024996\n",
      "Validation loss decreased (0.060485 --> 0.060228).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0464661\n",
      "\tspeed: 0.1333s/iter; left time: 1312.7259s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559821\n",
      "\tspeed: 0.0507s/iter; left time: 493.8232s\n",
      "\titers: 300, epoch: 10 | loss: 0.0458407\n",
      "\tspeed: 0.0506s/iter; left time: 488.3920s\n",
      "\titers: 400, epoch: 10 | loss: 0.0478090\n",
      "\tspeed: 0.0505s/iter; left time: 481.9497s\n",
      "\titers: 500, epoch: 10 | loss: 0.0521144\n",
      "\tspeed: 0.0506s/iter; left time: 477.7257s\n",
      "\titers: 600, epoch: 10 | loss: 0.0421316\n",
      "\tspeed: 0.0507s/iter; left time: 473.9312s\n",
      "\titers: 700, epoch: 10 | loss: 0.0445513\n",
      "\tspeed: 0.0505s/iter; left time: 466.7136s\n",
      "\titers: 800, epoch: 10 | loss: 0.0461014\n",
      "\tspeed: 0.0506s/iter; left time: 462.9759s\n",
      "\titers: 900, epoch: 10 | loss: 0.0444714\n",
      "\tspeed: 0.0507s/iter; left time: 458.5749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0510334 Vali Loss: 0.0601239 Test Loss: 0.0962381\n",
      "Validation loss decreased (0.060228 --> 0.060124).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0554868\n",
      "\tspeed: 0.1356s/iter; left time: 1212.0464s\n",
      "\titers: 200, epoch: 11 | loss: 0.0466775\n",
      "\tspeed: 0.0505s/iter; left time: 446.6774s\n",
      "\titers: 300, epoch: 11 | loss: 0.0512582\n",
      "\tspeed: 0.0507s/iter; left time: 443.3979s\n",
      "\titers: 400, epoch: 11 | loss: 0.0527383\n",
      "\tspeed: 0.0502s/iter; left time: 434.0244s\n",
      "\titers: 500, epoch: 11 | loss: 0.0537029\n",
      "\tspeed: 0.0506s/iter; left time: 432.0637s\n",
      "\titers: 600, epoch: 11 | loss: 0.0456979\n",
      "\tspeed: 0.0505s/iter; left time: 426.4219s\n",
      "\titers: 700, epoch: 11 | loss: 0.0510997\n",
      "\tspeed: 0.0506s/iter; left time: 421.6529s\n",
      "\titers: 800, epoch: 11 | loss: 0.0532567\n",
      "\tspeed: 0.0508s/iter; left time: 418.4195s\n",
      "\titers: 900, epoch: 11 | loss: 0.0524254\n",
      "\tspeed: 0.0505s/iter; left time: 411.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0498102 Vali Loss: 0.0613486 Test Loss: 0.1038591\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0443499\n",
      "\tspeed: 0.1289s/iter; left time: 1035.6579s\n",
      "\titers: 200, epoch: 12 | loss: 0.0506378\n",
      "\tspeed: 0.0506s/iter; left time: 401.2978s\n",
      "\titers: 300, epoch: 12 | loss: 0.0504264\n",
      "\tspeed: 0.0506s/iter; left time: 396.2326s\n",
      "\titers: 400, epoch: 12 | loss: 0.0502436\n",
      "\tspeed: 0.0505s/iter; left time: 390.9497s\n",
      "\titers: 500, epoch: 12 | loss: 0.0447131\n",
      "\tspeed: 0.0505s/iter; left time: 385.9833s\n",
      "\titers: 600, epoch: 12 | loss: 0.0464692\n",
      "\tspeed: 0.0506s/iter; left time: 381.1091s\n",
      "\titers: 700, epoch: 12 | loss: 0.0476393\n",
      "\tspeed: 0.0506s/iter; left time: 376.1023s\n",
      "\titers: 800, epoch: 12 | loss: 0.0441652\n",
      "\tspeed: 0.0505s/iter; left time: 370.8168s\n",
      "\titers: 900, epoch: 12 | loss: 0.0505162\n",
      "\tspeed: 0.0506s/iter; left time: 365.8337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0483057 Vali Loss: 0.0598347 Test Loss: 0.1017781\n",
      "Validation loss decreased (0.060124 --> 0.059835).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0479011\n",
      "\tspeed: 0.1366s/iter; left time: 974.5242s\n",
      "\titers: 200, epoch: 13 | loss: 0.0396949\n",
      "\tspeed: 0.0505s/iter; left time: 355.3120s\n",
      "\titers: 300, epoch: 13 | loss: 0.0365029\n",
      "\tspeed: 0.0505s/iter; left time: 350.4550s\n",
      "\titers: 400, epoch: 13 | loss: 0.0473218\n",
      "\tspeed: 0.0506s/iter; left time: 345.4198s\n",
      "\titers: 500, epoch: 13 | loss: 0.0429502\n",
      "\tspeed: 0.0506s/iter; left time: 340.3679s\n",
      "\titers: 600, epoch: 13 | loss: 0.0412170\n",
      "\tspeed: 0.0506s/iter; left time: 335.3582s\n",
      "\titers: 700, epoch: 13 | loss: 0.0520747\n",
      "\tspeed: 0.0506s/iter; left time: 330.3996s\n",
      "\titers: 800, epoch: 13 | loss: 0.0440386\n",
      "\tspeed: 0.0505s/iter; left time: 324.7206s\n",
      "\titers: 900, epoch: 13 | loss: 0.0506571\n",
      "\tspeed: 0.0508s/iter; left time: 321.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0471684 Vali Loss: 0.0624153 Test Loss: 0.1060174\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0528012\n",
      "\tspeed: 0.1291s/iter; left time: 804.1662s\n",
      "\titers: 200, epoch: 14 | loss: 0.0456710\n",
      "\tspeed: 0.0505s/iter; left time: 309.7841s\n",
      "\titers: 300, epoch: 14 | loss: 0.0462232\n",
      "\tspeed: 0.0505s/iter; left time: 304.7416s\n",
      "\titers: 400, epoch: 14 | loss: 0.0453537\n",
      "\tspeed: 0.0507s/iter; left time: 300.4686s\n",
      "\titers: 500, epoch: 14 | loss: 0.0441317\n",
      "\tspeed: 0.0505s/iter; left time: 294.5568s\n",
      "\titers: 600, epoch: 14 | loss: 0.0459225\n",
      "\tspeed: 0.0506s/iter; left time: 289.7491s\n",
      "\titers: 700, epoch: 14 | loss: 0.0436164\n",
      "\tspeed: 0.0506s/iter; left time: 284.6329s\n",
      "\titers: 800, epoch: 14 | loss: 0.0485557\n",
      "\tspeed: 0.0502s/iter; left time: 277.7065s\n",
      "\titers: 900, epoch: 14 | loss: 0.0433136\n",
      "\tspeed: 0.0506s/iter; left time: 274.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0460061 Vali Loss: 0.0615493 Test Loss: 0.1156078\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453874\n",
      "\tspeed: 0.1285s/iter; left time: 684.1160s\n",
      "\titers: 200, epoch: 15 | loss: 0.0497002\n",
      "\tspeed: 0.0504s/iter; left time: 263.3419s\n",
      "\titers: 300, epoch: 15 | loss: 0.0439731\n",
      "\tspeed: 0.0507s/iter; left time: 260.0254s\n",
      "\titers: 400, epoch: 15 | loss: 0.0496509\n",
      "\tspeed: 0.0505s/iter; left time: 253.9912s\n",
      "\titers: 500, epoch: 15 | loss: 0.0415987\n",
      "\tspeed: 0.0505s/iter; left time: 248.9451s\n",
      "\titers: 600, epoch: 15 | loss: 0.0430271\n",
      "\tspeed: 0.0506s/iter; left time: 244.3608s\n",
      "\titers: 700, epoch: 15 | loss: 0.0500451\n",
      "\tspeed: 0.0505s/iter; left time: 238.8428s\n",
      "\titers: 800, epoch: 15 | loss: 0.0517267\n",
      "\tspeed: 0.0506s/iter; left time: 233.8933s\n",
      "\titers: 900, epoch: 15 | loss: 0.0454376\n",
      "\tspeed: 0.0507s/iter; left time: 229.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0449720 Vali Loss: 0.0625263 Test Loss: 0.1118376\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0471281\n",
      "\tspeed: 0.1286s/iter; left time: 568.5146s\n",
      "\titers: 200, epoch: 16 | loss: 0.0419302\n",
      "\tspeed: 0.0505s/iter; left time: 218.2935s\n",
      "\titers: 300, epoch: 16 | loss: 0.0484602\n",
      "\tspeed: 0.0505s/iter; left time: 213.0145s\n",
      "\titers: 400, epoch: 16 | loss: 0.0428221\n",
      "\tspeed: 0.0506s/iter; left time: 208.3597s\n",
      "\titers: 500, epoch: 16 | loss: 0.0434117\n",
      "\tspeed: 0.0506s/iter; left time: 203.3153s\n",
      "\titers: 600, epoch: 16 | loss: 0.0452284\n",
      "\tspeed: 0.0506s/iter; left time: 198.2327s\n",
      "\titers: 700, epoch: 16 | loss: 0.0397415\n",
      "\tspeed: 0.0506s/iter; left time: 193.2247s\n",
      "\titers: 800, epoch: 16 | loss: 0.0431758\n",
      "\tspeed: 0.0506s/iter; left time: 188.2467s\n",
      "\titers: 900, epoch: 16 | loss: 0.0453944\n",
      "\tspeed: 0.0506s/iter; left time: 183.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0439962 Vali Loss: 0.0619818 Test Loss: 0.1135092\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0441060\n",
      "\tspeed: 0.1289s/iter; left time: 453.2897s\n",
      "\titers: 200, epoch: 17 | loss: 0.0416578\n",
      "\tspeed: 0.0506s/iter; left time: 173.0650s\n",
      "\titers: 300, epoch: 17 | loss: 0.0367482\n",
      "\tspeed: 0.0505s/iter; left time: 167.5137s\n",
      "\titers: 400, epoch: 17 | loss: 0.0396505\n",
      "\tspeed: 0.0506s/iter; left time: 162.7016s\n",
      "\titers: 500, epoch: 17 | loss: 0.0458141\n",
      "\tspeed: 0.0505s/iter; left time: 157.5453s\n",
      "\titers: 600, epoch: 17 | loss: 0.0412807\n",
      "\tspeed: 0.0503s/iter; left time: 151.8977s\n",
      "\titers: 700, epoch: 17 | loss: 0.0390849\n",
      "\tspeed: 0.0506s/iter; left time: 147.4625s\n",
      "\titers: 800, epoch: 17 | loss: 0.0452962\n",
      "\tspeed: 0.0505s/iter; left time: 142.1409s\n",
      "\titers: 900, epoch: 17 | loss: 0.0427713\n",
      "\tspeed: 0.0506s/iter; left time: 137.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0430648 Vali Loss: 0.0616069 Test Loss: 0.1124473\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027730144560337067, rmse:0.16652370989322662, mae:0.10189637541770935, rse:0.4892970025539398\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2397650\n",
      "\tspeed: 0.0526s/iter; left time: 946.0843s\n",
      "\titers: 200, epoch: 1 | loss: 0.2188361\n",
      "\tspeed: 0.0505s/iter; left time: 903.5753s\n",
      "\titers: 300, epoch: 1 | loss: 0.2117505\n",
      "\tspeed: 0.0504s/iter; left time: 896.9429s\n",
      "\titers: 400, epoch: 1 | loss: 0.2108439\n",
      "\tspeed: 0.0505s/iter; left time: 893.0361s\n",
      "\titers: 500, epoch: 1 | loss: 0.1835208\n",
      "\tspeed: 0.0505s/iter; left time: 887.4819s\n",
      "\titers: 600, epoch: 1 | loss: 0.1797962\n",
      "\tspeed: 0.0505s/iter; left time: 883.1407s\n",
      "\titers: 700, epoch: 1 | loss: 0.1692721\n",
      "\tspeed: 0.0506s/iter; left time: 878.7652s\n",
      "\titers: 800, epoch: 1 | loss: 0.1663436\n",
      "\tspeed: 0.0507s/iter; left time: 875.3031s\n",
      "\titers: 900, epoch: 1 | loss: 0.1532150\n",
      "\tspeed: 0.0507s/iter; left time: 871.8117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.2019445 Vali Loss: 0.1334897 Test Loss: 0.1648259\n",
      "Validation loss decreased (inf --> 0.133490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1116688\n",
      "\tspeed: 0.1332s/iter; left time: 2274.2624s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985892\n",
      "\tspeed: 0.0505s/iter; left time: 857.5461s\n",
      "\titers: 300, epoch: 2 | loss: 0.0984648\n",
      "\tspeed: 0.0505s/iter; left time: 852.7499s\n",
      "\titers: 400, epoch: 2 | loss: 0.0817523\n",
      "\tspeed: 0.0505s/iter; left time: 847.3501s\n",
      "\titers: 500, epoch: 2 | loss: 0.0821061\n",
      "\tspeed: 0.0506s/iter; left time: 844.4005s\n",
      "\titers: 600, epoch: 2 | loss: 0.0829242\n",
      "\tspeed: 0.0506s/iter; left time: 839.0886s\n",
      "\titers: 700, epoch: 2 | loss: 0.0850477\n",
      "\tspeed: 0.0505s/iter; left time: 832.8836s\n",
      "\titers: 800, epoch: 2 | loss: 0.0707683\n",
      "\tspeed: 0.0505s/iter; left time: 826.8802s\n",
      "\titers: 900, epoch: 2 | loss: 0.0756843\n",
      "\tspeed: 0.0505s/iter; left time: 822.4840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0936588 Vali Loss: 0.0768641 Test Loss: 0.0958987\n",
      "Validation loss decreased (0.133490 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0709860\n",
      "\tspeed: 0.1320s/iter; left time: 2134.2438s\n",
      "\titers: 200, epoch: 3 | loss: 0.0768529\n",
      "\tspeed: 0.0505s/iter; left time: 811.7992s\n",
      "\titers: 300, epoch: 3 | loss: 0.0713860\n",
      "\tspeed: 0.0506s/iter; left time: 808.5955s\n",
      "\titers: 400, epoch: 3 | loss: 0.0770326\n",
      "\tspeed: 0.0505s/iter; left time: 801.3211s\n",
      "\titers: 500, epoch: 3 | loss: 0.0764398\n",
      "\tspeed: 0.0507s/iter; left time: 799.1539s\n",
      "\titers: 600, epoch: 3 | loss: 0.0730157\n",
      "\tspeed: 0.0505s/iter; left time: 792.0672s\n",
      "\titers: 700, epoch: 3 | loss: 0.0724796\n",
      "\tspeed: 0.0505s/iter; left time: 786.0616s\n",
      "\titers: 800, epoch: 3 | loss: 0.0702410\n",
      "\tspeed: 0.0505s/iter; left time: 782.1411s\n",
      "\titers: 900, epoch: 3 | loss: 0.0714099\n",
      "\tspeed: 0.0506s/iter; left time: 777.1526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0722953 Vali Loss: 0.0689476 Test Loss: 0.0962248\n",
      "Validation loss decreased (0.076864 --> 0.068948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729760\n",
      "\tspeed: 0.1315s/iter; left time: 2008.5778s\n",
      "\titers: 200, epoch: 4 | loss: 0.0705238\n",
      "\tspeed: 0.0505s/iter; left time: 766.6063s\n",
      "\titers: 300, epoch: 4 | loss: 0.0747623\n",
      "\tspeed: 0.0506s/iter; left time: 762.9750s\n",
      "\titers: 400, epoch: 4 | loss: 0.0651293\n",
      "\tspeed: 0.0505s/iter; left time: 756.3008s\n",
      "\titers: 500, epoch: 4 | loss: 0.0643593\n",
      "\tspeed: 0.0505s/iter; left time: 751.6170s\n",
      "\titers: 600, epoch: 4 | loss: 0.0608370\n",
      "\tspeed: 0.0506s/iter; left time: 746.7983s\n",
      "\titers: 700, epoch: 4 | loss: 0.0733763\n",
      "\tspeed: 0.0507s/iter; left time: 744.3518s\n",
      "\titers: 800, epoch: 4 | loss: 0.0617674\n",
      "\tspeed: 0.0505s/iter; left time: 735.3938s\n",
      "\titers: 900, epoch: 4 | loss: 0.0638069\n",
      "\tspeed: 0.0506s/iter; left time: 731.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0665660 Vali Loss: 0.0646527 Test Loss: 0.0950652\n",
      "Validation loss decreased (0.068948 --> 0.064653).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0578355\n",
      "\tspeed: 0.1317s/iter; left time: 1891.9249s\n",
      "\titers: 200, epoch: 5 | loss: 0.0706750\n",
      "\tspeed: 0.0506s/iter; left time: 721.1452s\n",
      "\titers: 300, epoch: 5 | loss: 0.0579103\n",
      "\tspeed: 0.0505s/iter; left time: 715.8998s\n",
      "\titers: 400, epoch: 5 | loss: 0.0679884\n",
      "\tspeed: 0.0505s/iter; left time: 710.9024s\n",
      "\titers: 500, epoch: 5 | loss: 0.0644703\n",
      "\tspeed: 0.0505s/iter; left time: 704.5819s\n",
      "\titers: 600, epoch: 5 | loss: 0.0631064\n",
      "\tspeed: 0.0505s/iter; left time: 700.7353s\n",
      "\titers: 700, epoch: 5 | loss: 0.0676001\n",
      "\tspeed: 0.0505s/iter; left time: 695.5631s\n",
      "\titers: 800, epoch: 5 | loss: 0.0594106\n",
      "\tspeed: 0.0506s/iter; left time: 691.1378s\n",
      "\titers: 900, epoch: 5 | loss: 0.0567659\n",
      "\tspeed: 0.0505s/iter; left time: 685.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0622048 Vali Loss: 0.0649141 Test Loss: 0.0969854\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0678386\n",
      "\tspeed: 0.1284s/iter; left time: 1727.7990s\n",
      "\titers: 200, epoch: 6 | loss: 0.0630894\n",
      "\tspeed: 0.0506s/iter; left time: 675.5281s\n",
      "\titers: 300, epoch: 6 | loss: 0.0616045\n",
      "\tspeed: 0.0505s/iter; left time: 670.0508s\n",
      "\titers: 400, epoch: 6 | loss: 0.0657600\n",
      "\tspeed: 0.0506s/iter; left time: 666.4788s\n",
      "\titers: 500, epoch: 6 | loss: 0.0536100\n",
      "\tspeed: 0.0506s/iter; left time: 660.4727s\n",
      "\titers: 600, epoch: 6 | loss: 0.0629427\n",
      "\tspeed: 0.0506s/iter; left time: 655.5979s\n",
      "\titers: 700, epoch: 6 | loss: 0.0577870\n",
      "\tspeed: 0.0506s/iter; left time: 650.3882s\n",
      "\titers: 800, epoch: 6 | loss: 0.0533737\n",
      "\tspeed: 0.0505s/iter; left time: 644.8720s\n",
      "\titers: 900, epoch: 6 | loss: 0.0513395\n",
      "\tspeed: 0.0508s/iter; left time: 642.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0592599 Vali Loss: 0.0636146 Test Loss: 0.0932811\n",
      "Validation loss decreased (0.064653 --> 0.063615).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570538\n",
      "\tspeed: 0.1317s/iter; left time: 1654.3088s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547817\n",
      "\tspeed: 0.0506s/iter; left time: 630.0753s\n",
      "\titers: 300, epoch: 7 | loss: 0.0550904\n",
      "\tspeed: 0.0505s/iter; left time: 623.8951s\n",
      "\titers: 400, epoch: 7 | loss: 0.0568759\n",
      "\tspeed: 0.0506s/iter; left time: 620.5523s\n",
      "\titers: 500, epoch: 7 | loss: 0.0640158\n",
      "\tspeed: 0.0507s/iter; left time: 615.8695s\n",
      "\titers: 600, epoch: 7 | loss: 0.0585768\n",
      "\tspeed: 0.0506s/iter; left time: 609.8180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0602715\n",
      "\tspeed: 0.0505s/iter; left time: 604.3150s\n",
      "\titers: 800, epoch: 7 | loss: 0.0568392\n",
      "\tspeed: 0.0504s/iter; left time: 597.4578s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559254\n",
      "\tspeed: 0.0507s/iter; left time: 595.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0573138 Vali Loss: 0.0625001 Test Loss: 0.0926404\n",
      "Validation loss decreased (0.063615 --> 0.062500).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576004\n",
      "\tspeed: 0.1324s/iter; left time: 1542.9659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545701\n",
      "\tspeed: 0.0506s/iter; left time: 584.0670s\n",
      "\titers: 300, epoch: 8 | loss: 0.0560224\n",
      "\tspeed: 0.0506s/iter; left time: 579.0259s\n",
      "\titers: 400, epoch: 8 | loss: 0.0592838\n",
      "\tspeed: 0.0506s/iter; left time: 574.9850s\n",
      "\titers: 500, epoch: 8 | loss: 0.0513735\n",
      "\tspeed: 0.0505s/iter; left time: 568.7521s\n",
      "\titers: 600, epoch: 8 | loss: 0.0510742\n",
      "\tspeed: 0.0506s/iter; left time: 564.4928s\n",
      "\titers: 700, epoch: 8 | loss: 0.0574641\n",
      "\tspeed: 0.0505s/iter; left time: 557.6411s\n",
      "\titers: 800, epoch: 8 | loss: 0.0584299\n",
      "\tspeed: 0.0506s/iter; left time: 553.6894s\n",
      "\titers: 900, epoch: 8 | loss: 0.0534401\n",
      "\tspeed: 0.0506s/iter; left time: 548.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0554033 Vali Loss: 0.0620255 Test Loss: 0.0968116\n",
      "Validation loss decreased (0.062500 --> 0.062026).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0565304\n",
      "\tspeed: 0.1314s/iter; left time: 1412.1665s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577607\n",
      "\tspeed: 0.0505s/iter; left time: 537.9329s\n",
      "\titers: 300, epoch: 9 | loss: 0.0509865\n",
      "\tspeed: 0.0506s/iter; left time: 533.3743s\n",
      "\titers: 400, epoch: 9 | loss: 0.0528701\n",
      "\tspeed: 0.0505s/iter; left time: 527.9821s\n",
      "\titers: 500, epoch: 9 | loss: 0.0490458\n",
      "\tspeed: 0.0505s/iter; left time: 522.9016s\n",
      "\titers: 600, epoch: 9 | loss: 0.0565781\n",
      "\tspeed: 0.0506s/iter; left time: 518.0877s\n",
      "\titers: 700, epoch: 9 | loss: 0.0589701\n",
      "\tspeed: 0.0505s/iter; left time: 513.0011s\n",
      "\titers: 800, epoch: 9 | loss: 0.0536784\n",
      "\tspeed: 0.0505s/iter; left time: 507.8069s\n",
      "\titers: 900, epoch: 9 | loss: 0.0513182\n",
      "\tspeed: 0.0505s/iter; left time: 502.8169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0535280 Vali Loss: 0.0610963 Test Loss: 0.0929283\n",
      "Validation loss decreased (0.062026 --> 0.061096).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0507839\n",
      "\tspeed: 0.1324s/iter; left time: 1303.5067s\n",
      "\titers: 200, epoch: 10 | loss: 0.0507232\n",
      "\tspeed: 0.0503s/iter; left time: 489.6905s\n",
      "\titers: 300, epoch: 10 | loss: 0.0510521\n",
      "\tspeed: 0.0505s/iter; left time: 487.3574s\n",
      "\titers: 400, epoch: 10 | loss: 0.0509072\n",
      "\tspeed: 0.0504s/iter; left time: 481.0999s\n",
      "\titers: 500, epoch: 10 | loss: 0.0506622\n",
      "\tspeed: 0.0505s/iter; left time: 477.3438s\n",
      "\titers: 600, epoch: 10 | loss: 0.0542776\n",
      "\tspeed: 0.0506s/iter; left time: 472.5890s\n",
      "\titers: 700, epoch: 10 | loss: 0.0532949\n",
      "\tspeed: 0.0505s/iter; left time: 466.4754s\n",
      "\titers: 800, epoch: 10 | loss: 0.0542489\n",
      "\tspeed: 0.0505s/iter; left time: 462.2781s\n",
      "\titers: 900, epoch: 10 | loss: 0.0512030\n",
      "\tspeed: 0.0506s/iter; left time: 457.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0522358 Vali Loss: 0.0604504 Test Loss: 0.0994076\n",
      "Validation loss decreased (0.061096 --> 0.060450).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0497875\n",
      "\tspeed: 0.1316s/iter; left time: 1176.7491s\n",
      "\titers: 200, epoch: 11 | loss: 0.0497646\n",
      "\tspeed: 0.0506s/iter; left time: 447.0452s\n",
      "\titers: 300, epoch: 11 | loss: 0.0541379\n",
      "\tspeed: 0.0506s/iter; left time: 441.9799s\n",
      "\titers: 400, epoch: 11 | loss: 0.0458908\n",
      "\tspeed: 0.0505s/iter; left time: 435.9920s\n",
      "\titers: 500, epoch: 11 | loss: 0.0448408\n",
      "\tspeed: 0.0504s/iter; left time: 430.7369s\n",
      "\titers: 600, epoch: 11 | loss: 0.0520327\n",
      "\tspeed: 0.0506s/iter; left time: 427.5146s\n",
      "\titers: 700, epoch: 11 | loss: 0.0512611\n",
      "\tspeed: 0.0505s/iter; left time: 421.4885s\n",
      "\titers: 800, epoch: 11 | loss: 0.0578220\n",
      "\tspeed: 0.0506s/iter; left time: 416.6442s\n",
      "\titers: 900, epoch: 11 | loss: 0.0543108\n",
      "\tspeed: 0.0506s/iter; left time: 411.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0506735 Vali Loss: 0.0603218 Test Loss: 0.1022782\n",
      "Validation loss decreased (0.060450 --> 0.060322).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0481575\n",
      "\tspeed: 0.1320s/iter; left time: 1061.2731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0498887\n",
      "\tspeed: 0.0507s/iter; left time: 402.1851s\n",
      "\titers: 300, epoch: 12 | loss: 0.0462476\n",
      "\tspeed: 0.0506s/iter; left time: 396.2046s\n",
      "\titers: 400, epoch: 12 | loss: 0.0538952\n",
      "\tspeed: 0.0506s/iter; left time: 391.2727s\n",
      "\titers: 500, epoch: 12 | loss: 0.0504462\n",
      "\tspeed: 0.0505s/iter; left time: 385.8175s\n",
      "\titers: 600, epoch: 12 | loss: 0.0539619\n",
      "\tspeed: 0.0506s/iter; left time: 381.0969s\n",
      "\titers: 700, epoch: 12 | loss: 0.0517441\n",
      "\tspeed: 0.0504s/iter; left time: 374.7800s\n",
      "\titers: 800, epoch: 12 | loss: 0.0471546\n",
      "\tspeed: 0.0506s/iter; left time: 370.9815s\n",
      "\titers: 900, epoch: 12 | loss: 0.0423225\n",
      "\tspeed: 0.0506s/iter; left time: 366.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0496949 Vali Loss: 0.0595870 Test Loss: 0.1036159\n",
      "Validation loss decreased (0.060322 --> 0.059587).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0490044\n",
      "\tspeed: 0.1320s/iter; left time: 941.7684s\n",
      "\titers: 200, epoch: 13 | loss: 0.0507402\n",
      "\tspeed: 0.0507s/iter; left time: 356.2443s\n",
      "\titers: 300, epoch: 13 | loss: 0.0454048\n",
      "\tspeed: 0.0505s/iter; left time: 350.0200s\n",
      "\titers: 400, epoch: 13 | loss: 0.0463328\n",
      "\tspeed: 0.0506s/iter; left time: 345.4185s\n",
      "\titers: 500, epoch: 13 | loss: 0.0430218\n",
      "\tspeed: 0.0505s/iter; left time: 340.3348s\n",
      "\titers: 600, epoch: 13 | loss: 0.0468026\n",
      "\tspeed: 0.0503s/iter; left time: 333.9683s\n",
      "\titers: 700, epoch: 13 | loss: 0.0548753\n",
      "\tspeed: 0.0506s/iter; left time: 330.4087s\n",
      "\titers: 800, epoch: 13 | loss: 0.0410608\n",
      "\tspeed: 0.0505s/iter; left time: 324.7343s\n",
      "\titers: 900, epoch: 13 | loss: 0.0434689\n",
      "\tspeed: 0.0506s/iter; left time: 320.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0483636 Vali Loss: 0.0609071 Test Loss: 0.1049401\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0462609\n",
      "\tspeed: 0.1283s/iter; left time: 799.2238s\n",
      "\titers: 200, epoch: 14 | loss: 0.0469013\n",
      "\tspeed: 0.0505s/iter; left time: 309.7903s\n",
      "\titers: 300, epoch: 14 | loss: 0.0430094\n",
      "\tspeed: 0.0506s/iter; left time: 304.8550s\n",
      "\titers: 400, epoch: 14 | loss: 0.0456423\n",
      "\tspeed: 0.0506s/iter; left time: 299.7361s\n",
      "\titers: 500, epoch: 14 | loss: 0.0489431\n",
      "\tspeed: 0.0506s/iter; left time: 294.6799s\n",
      "\titers: 600, epoch: 14 | loss: 0.0474015\n",
      "\tspeed: 0.0505s/iter; left time: 289.5780s\n",
      "\titers: 700, epoch: 14 | loss: 0.0502858\n",
      "\tspeed: 0.0506s/iter; left time: 284.6224s\n",
      "\titers: 800, epoch: 14 | loss: 0.0469590\n",
      "\tspeed: 0.0507s/iter; left time: 280.2071s\n",
      "\titers: 900, epoch: 14 | loss: 0.0528418\n",
      "\tspeed: 0.0506s/iter; left time: 274.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0474113 Vali Loss: 0.0604195 Test Loss: 0.1088855\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0475536\n",
      "\tspeed: 0.1284s/iter; left time: 683.7473s\n",
      "\titers: 200, epoch: 15 | loss: 0.0454886\n",
      "\tspeed: 0.0506s/iter; left time: 264.5947s\n",
      "\titers: 300, epoch: 15 | loss: 0.0436437\n",
      "\tspeed: 0.0506s/iter; left time: 259.1946s\n",
      "\titers: 400, epoch: 15 | loss: 0.0457855\n",
      "\tspeed: 0.0504s/iter; left time: 253.4951s\n",
      "\titers: 500, epoch: 15 | loss: 0.0483506\n",
      "\tspeed: 0.0504s/iter; left time: 248.4643s\n",
      "\titers: 600, epoch: 15 | loss: 0.0447313\n",
      "\tspeed: 0.0503s/iter; left time: 242.5699s\n",
      "\titers: 700, epoch: 15 | loss: 0.0479028\n",
      "\tspeed: 0.0501s/iter; left time: 236.7363s\n",
      "\titers: 800, epoch: 15 | loss: 0.0485581\n",
      "\tspeed: 0.0501s/iter; left time: 231.7718s\n",
      "\titers: 900, epoch: 15 | loss: 0.0459575\n",
      "\tspeed: 0.0499s/iter; left time: 225.9184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 904 | Train Loss: 0.0464909 Vali Loss: 0.0601524 Test Loss: 0.1096843\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0416123\n",
      "\tspeed: 0.1289s/iter; left time: 569.7362s\n",
      "\titers: 200, epoch: 16 | loss: 0.0462603\n",
      "\tspeed: 0.0506s/iter; left time: 218.4630s\n",
      "\titers: 300, epoch: 16 | loss: 0.0441902\n",
      "\tspeed: 0.0505s/iter; left time: 213.0309s\n",
      "\titers: 400, epoch: 16 | loss: 0.0432069\n",
      "\tspeed: 0.0504s/iter; left time: 207.8816s\n",
      "\titers: 500, epoch: 16 | loss: 0.0434174\n",
      "\tspeed: 0.0505s/iter; left time: 203.2070s\n",
      "\titers: 600, epoch: 16 | loss: 0.0469179\n",
      "\tspeed: 0.0506s/iter; left time: 198.2365s\n",
      "\titers: 700, epoch: 16 | loss: 0.0416427\n",
      "\tspeed: 0.0505s/iter; left time: 193.1354s\n",
      "\titers: 800, epoch: 16 | loss: 0.0482107\n",
      "\tspeed: 0.0511s/iter; left time: 190.0225s\n",
      "\titers: 900, epoch: 16 | loss: 0.0492340\n",
      "\tspeed: 0.0507s/iter; left time: 183.4238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0456746 Vali Loss: 0.0615783 Test Loss: 0.1173730\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0478281\n",
      "\tspeed: 0.1294s/iter; left time: 455.0936s\n",
      "\titers: 200, epoch: 17 | loss: 0.0439868\n",
      "\tspeed: 0.0506s/iter; left time: 172.7438s\n",
      "\titers: 300, epoch: 17 | loss: 0.0497381\n",
      "\tspeed: 0.0506s/iter; left time: 167.7376s\n",
      "\titers: 400, epoch: 17 | loss: 0.0459545\n",
      "\tspeed: 0.0506s/iter; left time: 162.6598s\n",
      "\titers: 500, epoch: 17 | loss: 0.0448027\n",
      "\tspeed: 0.0505s/iter; left time: 157.4446s\n",
      "\titers: 600, epoch: 17 | loss: 0.0502112\n",
      "\tspeed: 0.0506s/iter; left time: 152.7757s\n",
      "\titers: 700, epoch: 17 | loss: 0.0474764\n",
      "\tspeed: 0.0506s/iter; left time: 147.4861s\n",
      "\titers: 800, epoch: 17 | loss: 0.0446103\n",
      "\tspeed: 0.0506s/iter; left time: 142.5016s\n",
      "\titers: 900, epoch: 17 | loss: 0.0471329\n",
      "\tspeed: 0.0507s/iter; left time: 137.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0448907 Vali Loss: 0.0607954 Test Loss: 0.1161333\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03074352815747261, rmse:0.17533832788467407, mae:0.10366739332675934, rse:0.5151970386505127\n",
      "Intermediate time for ES and pred_len 24: 00h:30m:41.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2469863\n",
      "\tspeed: 0.0829s/iter; left time: 1487.1780s\n",
      "\titers: 200, epoch: 1 | loss: 0.2149057\n",
      "\tspeed: 0.0563s/iter; left time: 1005.2869s\n",
      "\titers: 300, epoch: 1 | loss: 0.2176140\n",
      "\tspeed: 0.0562s/iter; left time: 997.2651s\n",
      "\titers: 400, epoch: 1 | loss: 0.2101680\n",
      "\tspeed: 0.0563s/iter; left time: 993.6465s\n",
      "\titers: 500, epoch: 1 | loss: 0.1979478\n",
      "\tspeed: 0.0564s/iter; left time: 990.0891s\n",
      "\titers: 600, epoch: 1 | loss: 0.1946315\n",
      "\tspeed: 0.0559s/iter; left time: 974.6696s\n",
      "\titers: 700, epoch: 1 | loss: 0.1903439\n",
      "\tspeed: 0.0561s/iter; left time: 972.6134s\n",
      "\titers: 800, epoch: 1 | loss: 0.1860500\n",
      "\tspeed: 0.0562s/iter; left time: 968.2915s\n",
      "\titers: 900, epoch: 1 | loss: 0.1832966\n",
      "\tspeed: 0.0561s/iter; left time: 961.1580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.43s\n",
      "Steps: 902 | Train Loss: 0.2074611 Vali Loss: 0.1734132 Test Loss: 0.2133944\n",
      "Validation loss decreased (inf --> 0.173413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1505480\n",
      "\tspeed: 0.1465s/iter; left time: 2496.8924s\n",
      "\titers: 200, epoch: 2 | loss: 0.1357571\n",
      "\tspeed: 0.0561s/iter; left time: 950.0217s\n",
      "\titers: 300, epoch: 2 | loss: 0.1343678\n",
      "\tspeed: 0.0562s/iter; left time: 945.8922s\n",
      "\titers: 400, epoch: 2 | loss: 0.1273570\n",
      "\tspeed: 0.0563s/iter; left time: 942.3146s\n",
      "\titers: 500, epoch: 2 | loss: 0.1072364\n",
      "\tspeed: 0.0561s/iter; left time: 932.7962s\n",
      "\titers: 600, epoch: 2 | loss: 0.1081586\n",
      "\tspeed: 0.0562s/iter; left time: 930.0066s\n",
      "\titers: 700, epoch: 2 | loss: 0.0995950\n",
      "\tspeed: 0.0561s/iter; left time: 922.3469s\n",
      "\titers: 800, epoch: 2 | loss: 0.0981825\n",
      "\tspeed: 0.0560s/iter; left time: 915.7355s\n",
      "\titers: 900, epoch: 2 | loss: 0.0874286\n",
      "\tspeed: 0.0562s/iter; left time: 912.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.89s\n",
      "Steps: 902 | Train Loss: 0.1198459 Vali Loss: 0.1001235 Test Loss: 0.1382986\n",
      "Validation loss decreased (0.173413 --> 0.100123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924610\n",
      "\tspeed: 0.1496s/iter; left time: 2414.1895s\n",
      "\titers: 200, epoch: 3 | loss: 0.0927082\n",
      "\tspeed: 0.0562s/iter; left time: 901.7826s\n",
      "\titers: 300, epoch: 3 | loss: 0.0913245\n",
      "\tspeed: 0.0561s/iter; left time: 894.7480s\n",
      "\titers: 400, epoch: 3 | loss: 0.0881406\n",
      "\tspeed: 0.0561s/iter; left time: 888.9908s\n",
      "\titers: 500, epoch: 3 | loss: 0.0882461\n",
      "\tspeed: 0.0563s/iter; left time: 885.7319s\n",
      "\titers: 600, epoch: 3 | loss: 0.0955994\n",
      "\tspeed: 0.0563s/iter; left time: 880.5395s\n",
      "\titers: 700, epoch: 3 | loss: 0.0846845\n",
      "\tspeed: 0.0561s/iter; left time: 872.3804s\n",
      "\titers: 800, epoch: 3 | loss: 0.0834005\n",
      "\tspeed: 0.0564s/iter; left time: 871.1137s\n",
      "\titers: 900, epoch: 3 | loss: 0.0904592\n",
      "\tspeed: 0.0563s/iter; left time: 863.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:50.96s\n",
      "Steps: 902 | Train Loss: 0.0907699 Vali Loss: 0.0934744 Test Loss: 0.1358368\n",
      "Validation loss decreased (0.100123 --> 0.093474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0926084\n",
      "\tspeed: 0.1465s/iter; left time: 2232.2260s\n",
      "\titers: 200, epoch: 4 | loss: 0.0871784\n",
      "\tspeed: 0.0562s/iter; left time: 850.4937s\n",
      "\titers: 300, epoch: 4 | loss: 0.0845065\n",
      "\tspeed: 0.0563s/iter; left time: 846.4607s\n",
      "\titers: 400, epoch: 4 | loss: 0.0891221\n",
      "\tspeed: 0.0563s/iter; left time: 840.6119s\n",
      "\titers: 500, epoch: 4 | loss: 0.0808985\n",
      "\tspeed: 0.0562s/iter; left time: 834.1355s\n",
      "\titers: 600, epoch: 4 | loss: 0.0863847\n",
      "\tspeed: 0.0562s/iter; left time: 828.7826s\n",
      "\titers: 700, epoch: 4 | loss: 0.0806940\n",
      "\tspeed: 0.0563s/iter; left time: 824.1853s\n",
      "\titers: 800, epoch: 4 | loss: 0.0840356\n",
      "\tspeed: 0.0563s/iter; left time: 818.1876s\n",
      "\titers: 900, epoch: 4 | loss: 0.0939959\n",
      "\tspeed: 0.0563s/iter; left time: 812.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.00s\n",
      "Steps: 902 | Train Loss: 0.0842532 Vali Loss: 0.0889278 Test Loss: 0.1366561\n",
      "Validation loss decreased (0.093474 --> 0.088928).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825766\n",
      "\tspeed: 0.1464s/iter; left time: 2097.7886s\n",
      "\titers: 200, epoch: 5 | loss: 0.0746555\n",
      "\tspeed: 0.0562s/iter; left time: 800.0161s\n",
      "\titers: 300, epoch: 5 | loss: 0.0716366\n",
      "\tspeed: 0.0561s/iter; left time: 793.1819s\n",
      "\titers: 400, epoch: 5 | loss: 0.0804338\n",
      "\tspeed: 0.0561s/iter; left time: 787.5468s\n",
      "\titers: 500, epoch: 5 | loss: 0.0769216\n",
      "\tspeed: 0.0563s/iter; left time: 784.1376s\n",
      "\titers: 600, epoch: 5 | loss: 0.0801143\n",
      "\tspeed: 0.0562s/iter; left time: 777.0860s\n",
      "\titers: 700, epoch: 5 | loss: 0.0759158\n",
      "\tspeed: 0.0560s/iter; left time: 769.1885s\n",
      "\titers: 800, epoch: 5 | loss: 0.0747323\n",
      "\tspeed: 0.0561s/iter; left time: 764.4005s\n",
      "\titers: 900, epoch: 5 | loss: 0.0714179\n",
      "\tspeed: 0.0561s/iter; left time: 758.9176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.88s\n",
      "Steps: 902 | Train Loss: 0.0787907 Vali Loss: 0.0923521 Test Loss: 0.1462155\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734378\n",
      "\tspeed: 0.1437s/iter; left time: 1930.6729s\n",
      "\titers: 200, epoch: 6 | loss: 0.0777358\n",
      "\tspeed: 0.0560s/iter; left time: 747.1115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0738407\n",
      "\tspeed: 0.0561s/iter; left time: 742.8626s\n",
      "\titers: 400, epoch: 6 | loss: 0.0752138\n",
      "\tspeed: 0.0561s/iter; left time: 736.7580s\n",
      "\titers: 500, epoch: 6 | loss: 0.0712862\n",
      "\tspeed: 0.0562s/iter; left time: 732.7923s\n",
      "\titers: 600, epoch: 6 | loss: 0.0764351\n",
      "\tspeed: 0.0562s/iter; left time: 726.8472s\n",
      "\titers: 700, epoch: 6 | loss: 0.0734742\n",
      "\tspeed: 0.0564s/iter; left time: 723.5492s\n",
      "\titers: 800, epoch: 6 | loss: 0.0796886\n",
      "\tspeed: 0.0566s/iter; left time: 720.0222s\n",
      "\titers: 900, epoch: 6 | loss: 0.0710142\n",
      "\tspeed: 0.0564s/iter; left time: 712.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:51.00s\n",
      "Steps: 902 | Train Loss: 0.0743199 Vali Loss: 0.0908994 Test Loss: 0.1528870\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700343\n",
      "\tspeed: 0.1431s/iter; left time: 1793.5095s\n",
      "\titers: 200, epoch: 7 | loss: 0.0703626\n",
      "\tspeed: 0.0561s/iter; left time: 697.0811s\n",
      "\titers: 300, epoch: 7 | loss: 0.0654275\n",
      "\tspeed: 0.0560s/iter; left time: 690.6959s\n",
      "\titers: 400, epoch: 7 | loss: 0.0709134\n",
      "\tspeed: 0.0561s/iter; left time: 685.5287s\n",
      "\titers: 500, epoch: 7 | loss: 0.0670991\n",
      "\tspeed: 0.0559s/iter; left time: 677.8673s\n",
      "\titers: 600, epoch: 7 | loss: 0.0734681\n",
      "\tspeed: 0.0560s/iter; left time: 673.8433s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732043\n",
      "\tspeed: 0.0558s/iter; left time: 666.1297s\n",
      "\titers: 800, epoch: 7 | loss: 0.0688264\n",
      "\tspeed: 0.0559s/iter; left time: 660.6738s\n",
      "\titers: 900, epoch: 7 | loss: 0.0666078\n",
      "\tspeed: 0.0560s/iter; left time: 656.3022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.69s\n",
      "Steps: 902 | Train Loss: 0.0703692 Vali Loss: 0.0913277 Test Loss: 0.1578007\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0670952\n",
      "\tspeed: 0.1438s/iter; left time: 1671.7136s\n",
      "\titers: 200, epoch: 8 | loss: 0.0666659\n",
      "\tspeed: 0.0561s/iter; left time: 646.9821s\n",
      "\titers: 300, epoch: 8 | loss: 0.0784774\n",
      "\tspeed: 0.0563s/iter; left time: 643.8910s\n",
      "\titers: 400, epoch: 8 | loss: 0.0634514\n",
      "\tspeed: 0.0562s/iter; left time: 636.3661s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704025\n",
      "\tspeed: 0.0567s/iter; left time: 636.7802s\n",
      "\titers: 600, epoch: 8 | loss: 0.0663031\n",
      "\tspeed: 0.0564s/iter; left time: 627.6331s\n",
      "\titers: 700, epoch: 8 | loss: 0.0634680\n",
      "\tspeed: 0.0563s/iter; left time: 620.9374s\n",
      "\titers: 800, epoch: 8 | loss: 0.0678316\n",
      "\tspeed: 0.0564s/iter; left time: 616.5645s\n",
      "\titers: 900, epoch: 8 | loss: 0.0686408\n",
      "\tspeed: 0.0564s/iter; left time: 610.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.12s\n",
      "Steps: 902 | Train Loss: 0.0672424 Vali Loss: 0.0920353 Test Loss: 0.1556564\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0636137\n",
      "\tspeed: 0.1441s/iter; left time: 1545.5326s\n",
      "\titers: 200, epoch: 9 | loss: 0.0621508\n",
      "\tspeed: 0.0562s/iter; left time: 597.6302s\n",
      "\titers: 300, epoch: 9 | loss: 0.0680040\n",
      "\tspeed: 0.0563s/iter; left time: 592.3896s\n",
      "\titers: 400, epoch: 9 | loss: 0.0617895\n",
      "\tspeed: 0.0561s/iter; left time: 585.0657s\n",
      "\titers: 500, epoch: 9 | loss: 0.0655872\n",
      "\tspeed: 0.0560s/iter; left time: 578.4973s\n",
      "\titers: 600, epoch: 9 | loss: 0.0632751\n",
      "\tspeed: 0.0562s/iter; left time: 574.7558s\n",
      "\titers: 700, epoch: 9 | loss: 0.0658284\n",
      "\tspeed: 0.0561s/iter; left time: 568.3526s\n",
      "\titers: 800, epoch: 9 | loss: 0.0644073\n",
      "\tspeed: 0.0564s/iter; left time: 565.3720s\n",
      "\titers: 900, epoch: 9 | loss: 0.0623048\n",
      "\tspeed: 0.0563s/iter; left time: 559.2044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.94s\n",
      "Steps: 902 | Train Loss: 0.0642583 Vali Loss: 0.0935230 Test Loss: 0.1664874\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.048280902206897736, rmse:0.21972915530204773, mae:0.13662198185920715, rse:0.6454980969429016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2463532\n",
      "\tspeed: 0.0581s/iter; left time: 1042.7467s\n",
      "\titers: 200, epoch: 1 | loss: 0.2215522\n",
      "\tspeed: 0.0563s/iter; left time: 1004.6287s\n",
      "\titers: 300, epoch: 1 | loss: 0.2141467\n",
      "\tspeed: 0.0561s/iter; left time: 996.0868s\n",
      "\titers: 400, epoch: 1 | loss: 0.2012762\n",
      "\tspeed: 0.0565s/iter; left time: 995.9400s\n",
      "\titers: 500, epoch: 1 | loss: 0.1932724\n",
      "\tspeed: 0.0568s/iter; left time: 996.7955s\n",
      "\titers: 600, epoch: 1 | loss: 0.1960959\n",
      "\tspeed: 0.0566s/iter; left time: 986.8730s\n",
      "\titers: 700, epoch: 1 | loss: 0.1835060\n",
      "\tspeed: 0.0568s/iter; left time: 985.7081s\n",
      "\titers: 800, epoch: 1 | loss: 0.1728040\n",
      "\tspeed: 0.0564s/iter; left time: 971.8079s\n",
      "\titers: 900, epoch: 1 | loss: 0.1784550\n",
      "\tspeed: 0.0566s/iter; left time: 970.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.21s\n",
      "Steps: 902 | Train Loss: 0.2069342 Vali Loss: 0.1652073 Test Loss: 0.2061774\n",
      "Validation loss decreased (inf --> 0.165207).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1514560\n",
      "\tspeed: 0.1478s/iter; left time: 2518.1978s\n",
      "\titers: 200, epoch: 2 | loss: 0.1389660\n",
      "\tspeed: 0.0562s/iter; left time: 952.1481s\n",
      "\titers: 300, epoch: 2 | loss: 0.1304136\n",
      "\tspeed: 0.0562s/iter; left time: 946.1849s\n",
      "\titers: 400, epoch: 2 | loss: 0.1160349\n",
      "\tspeed: 0.0563s/iter; left time: 941.9140s\n",
      "\titers: 500, epoch: 2 | loss: 0.1167205\n",
      "\tspeed: 0.0561s/iter; left time: 933.6334s\n",
      "\titers: 600, epoch: 2 | loss: 0.1076152\n",
      "\tspeed: 0.0562s/iter; left time: 928.9123s\n",
      "\titers: 700, epoch: 2 | loss: 0.1034168\n",
      "\tspeed: 0.0561s/iter; left time: 921.5623s\n",
      "\titers: 800, epoch: 2 | loss: 0.0971767\n",
      "\tspeed: 0.0559s/iter; left time: 914.1000s\n",
      "\titers: 900, epoch: 2 | loss: 0.0993897\n",
      "\tspeed: 0.0564s/iter; left time: 915.3622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.93s\n",
      "Steps: 902 | Train Loss: 0.1191747 Vali Loss: 0.0973347 Test Loss: 0.1329575\n",
      "Validation loss decreased (0.165207 --> 0.097335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019672\n",
      "\tspeed: 0.1521s/iter; left time: 2453.8623s\n",
      "\titers: 200, epoch: 3 | loss: 0.0930330\n",
      "\tspeed: 0.0561s/iter; left time: 900.0000s\n",
      "\titers: 300, epoch: 3 | loss: 0.0918107\n",
      "\tspeed: 0.0561s/iter; left time: 893.4415s\n",
      "\titers: 400, epoch: 3 | loss: 0.0955074\n",
      "\tspeed: 0.0564s/iter; left time: 892.8404s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878140\n",
      "\tspeed: 0.0562s/iter; left time: 884.4940s\n",
      "\titers: 600, epoch: 3 | loss: 0.0883810\n",
      "\tspeed: 0.0562s/iter; left time: 878.1997s\n",
      "\titers: 700, epoch: 3 | loss: 0.0860955\n",
      "\tspeed: 0.0566s/iter; left time: 878.9556s\n",
      "\titers: 800, epoch: 3 | loss: 0.0864354\n",
      "\tspeed: 0.0568s/iter; left time: 876.7211s\n",
      "\titers: 900, epoch: 3 | loss: 0.0887409\n",
      "\tspeed: 0.0564s/iter; left time: 864.3201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.06s\n",
      "Steps: 902 | Train Loss: 0.0904003 Vali Loss: 0.0926813 Test Loss: 0.1307571\n",
      "Validation loss decreased (0.097335 --> 0.092681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801100\n",
      "\tspeed: 0.1408s/iter; left time: 2145.0746s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848558\n",
      "\tspeed: 0.0545s/iter; left time: 825.3763s\n",
      "\titers: 300, epoch: 4 | loss: 0.0833696\n",
      "\tspeed: 0.0561s/iter; left time: 843.5938s\n",
      "\titers: 400, epoch: 4 | loss: 0.0775898\n",
      "\tspeed: 0.0560s/iter; left time: 836.9000s\n",
      "\titers: 500, epoch: 4 | loss: 0.0802015\n",
      "\tspeed: 0.0562s/iter; left time: 833.3162s\n",
      "\titers: 600, epoch: 4 | loss: 0.0807514\n",
      "\tspeed: 0.0563s/iter; left time: 829.0238s\n",
      "\titers: 700, epoch: 4 | loss: 0.0848260\n",
      "\tspeed: 0.0561s/iter; left time: 821.5734s\n",
      "\titers: 800, epoch: 4 | loss: 0.0774291\n",
      "\tspeed: 0.0560s/iter; left time: 814.3192s\n",
      "\titers: 900, epoch: 4 | loss: 0.0848402\n",
      "\tspeed: 0.0533s/iter; left time: 769.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.75s\n",
      "Steps: 902 | Train Loss: 0.0831460 Vali Loss: 0.0918923 Test Loss: 0.1462924\n",
      "Validation loss decreased (0.092681 --> 0.091892).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836684\n",
      "\tspeed: 0.1484s/iter; left time: 2126.5193s\n",
      "\titers: 200, epoch: 5 | loss: 0.0799095\n",
      "\tspeed: 0.0562s/iter; left time: 799.7306s\n",
      "\titers: 300, epoch: 5 | loss: 0.0778950\n",
      "\tspeed: 0.0561s/iter; left time: 792.6264s\n",
      "\titers: 400, epoch: 5 | loss: 0.0817425\n",
      "\tspeed: 0.0563s/iter; left time: 790.3448s\n",
      "\titers: 500, epoch: 5 | loss: 0.0765830\n",
      "\tspeed: 0.0560s/iter; left time: 780.6859s\n",
      "\titers: 600, epoch: 5 | loss: 0.0812883\n",
      "\tspeed: 0.0562s/iter; left time: 778.0716s\n",
      "\titers: 700, epoch: 5 | loss: 0.0696413\n",
      "\tspeed: 0.0565s/iter; left time: 775.8640s\n",
      "\titers: 800, epoch: 5 | loss: 0.0719474\n",
      "\tspeed: 0.0565s/iter; left time: 770.1108s\n",
      "\titers: 900, epoch: 5 | loss: 0.0781624\n",
      "\tspeed: 0.0562s/iter; left time: 760.7328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.02s\n",
      "Steps: 902 | Train Loss: 0.0771828 Vali Loss: 0.0894527 Test Loss: 0.1502485\n",
      "Validation loss decreased (0.091892 --> 0.089453).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0721062\n",
      "\tspeed: 0.1473s/iter; left time: 1978.5165s\n",
      "\titers: 200, epoch: 6 | loss: 0.0693633\n",
      "\tspeed: 0.0565s/iter; left time: 753.5724s\n",
      "\titers: 300, epoch: 6 | loss: 0.0794636\n",
      "\tspeed: 0.0562s/iter; left time: 743.3447s\n",
      "\titers: 400, epoch: 6 | loss: 0.0710191\n",
      "\tspeed: 0.0563s/iter; left time: 739.1275s\n",
      "\titers: 500, epoch: 6 | loss: 0.0783766\n",
      "\tspeed: 0.0560s/iter; left time: 729.9291s\n",
      "\titers: 600, epoch: 6 | loss: 0.0722545\n",
      "\tspeed: 0.0563s/iter; left time: 727.4850s\n",
      "\titers: 700, epoch: 6 | loss: 0.0669375\n",
      "\tspeed: 0.0560s/iter; left time: 718.8810s\n",
      "\titers: 800, epoch: 6 | loss: 0.0695172\n",
      "\tspeed: 0.0559s/iter; left time: 712.1731s\n",
      "\titers: 900, epoch: 6 | loss: 0.0682838\n",
      "\tspeed: 0.0561s/iter; left time: 708.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.96s\n",
      "Steps: 902 | Train Loss: 0.0725950 Vali Loss: 0.0909504 Test Loss: 0.1606027\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0697130\n",
      "\tspeed: 0.1441s/iter; left time: 1805.0756s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699147\n",
      "\tspeed: 0.0562s/iter; left time: 698.5970s\n",
      "\titers: 300, epoch: 7 | loss: 0.0715107\n",
      "\tspeed: 0.0561s/iter; left time: 691.7579s\n",
      "\titers: 400, epoch: 7 | loss: 0.0746869\n",
      "\tspeed: 0.0562s/iter; left time: 687.1756s\n",
      "\titers: 500, epoch: 7 | loss: 0.0681918\n",
      "\tspeed: 0.0560s/iter; left time: 679.6655s\n",
      "\titers: 600, epoch: 7 | loss: 0.0721015\n",
      "\tspeed: 0.0561s/iter; left time: 674.6687s\n",
      "\titers: 700, epoch: 7 | loss: 0.0698742\n",
      "\tspeed: 0.0559s/iter; left time: 666.7690s\n",
      "\titers: 800, epoch: 7 | loss: 0.0641714\n",
      "\tspeed: 0.0563s/iter; left time: 666.4121s\n",
      "\titers: 900, epoch: 7 | loss: 0.0701178\n",
      "\tspeed: 0.0563s/iter; left time: 660.8995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.90s\n",
      "Steps: 902 | Train Loss: 0.0686389 Vali Loss: 0.0936627 Test Loss: 0.1661786\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0622742\n",
      "\tspeed: 0.1437s/iter; left time: 1670.5453s\n",
      "\titers: 200, epoch: 8 | loss: 0.0645106\n",
      "\tspeed: 0.0563s/iter; left time: 648.4722s\n",
      "\titers: 300, epoch: 8 | loss: 0.0619189\n",
      "\tspeed: 0.0562s/iter; left time: 642.0796s\n",
      "\titers: 400, epoch: 8 | loss: 0.0622289\n",
      "\tspeed: 0.0565s/iter; left time: 639.6793s\n",
      "\titers: 500, epoch: 8 | loss: 0.0663624\n",
      "\tspeed: 0.0563s/iter; left time: 632.1809s\n",
      "\titers: 600, epoch: 8 | loss: 0.0631392\n",
      "\tspeed: 0.0562s/iter; left time: 625.0926s\n",
      "\titers: 700, epoch: 8 | loss: 0.0668664\n",
      "\tspeed: 0.0562s/iter; left time: 620.2391s\n",
      "\titers: 800, epoch: 8 | loss: 0.0607819\n",
      "\tspeed: 0.0561s/iter; left time: 612.7887s\n",
      "\titers: 900, epoch: 8 | loss: 0.0643531\n",
      "\tspeed: 0.0563s/iter; left time: 609.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.98s\n",
      "Steps: 902 | Train Loss: 0.0649358 Vali Loss: 0.0915879 Test Loss: 0.1647141\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0590300\n",
      "\tspeed: 0.1436s/iter; left time: 1539.9229s\n",
      "\titers: 200, epoch: 9 | loss: 0.0664502\n",
      "\tspeed: 0.0559s/iter; left time: 594.0967s\n",
      "\titers: 300, epoch: 9 | loss: 0.0614165\n",
      "\tspeed: 0.0560s/iter; left time: 589.4057s\n",
      "\titers: 400, epoch: 9 | loss: 0.0631030\n",
      "\tspeed: 0.0558s/iter; left time: 581.9915s\n",
      "\titers: 500, epoch: 9 | loss: 0.0612004\n",
      "\tspeed: 0.0560s/iter; left time: 578.4004s\n",
      "\titers: 600, epoch: 9 | loss: 0.0602919\n",
      "\tspeed: 0.0558s/iter; left time: 570.5751s\n",
      "\titers: 700, epoch: 9 | loss: 0.0616944\n",
      "\tspeed: 0.0559s/iter; left time: 565.7162s\n",
      "\titers: 800, epoch: 9 | loss: 0.0565386\n",
      "\tspeed: 0.0557s/iter; left time: 558.2135s\n",
      "\titers: 900, epoch: 9 | loss: 0.0604552\n",
      "\tspeed: 0.0559s/iter; left time: 555.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.66s\n",
      "Steps: 902 | Train Loss: 0.0617440 Vali Loss: 0.0934446 Test Loss: 0.1651241\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633396\n",
      "\tspeed: 0.1437s/iter; left time: 1411.7891s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605258\n",
      "\tspeed: 0.0558s/iter; left time: 542.7811s\n",
      "\titers: 300, epoch: 10 | loss: 0.0574003\n",
      "\tspeed: 0.0563s/iter; left time: 541.5636s\n",
      "\titers: 400, epoch: 10 | loss: 0.0608039\n",
      "\tspeed: 0.0562s/iter; left time: 535.1822s\n",
      "\titers: 500, epoch: 10 | loss: 0.0606337\n",
      "\tspeed: 0.0564s/iter; left time: 531.2088s\n",
      "\titers: 600, epoch: 10 | loss: 0.0580432\n",
      "\tspeed: 0.0561s/iter; left time: 523.2630s\n",
      "\titers: 700, epoch: 10 | loss: 0.0573463\n",
      "\tspeed: 0.0518s/iter; left time: 477.3276s\n",
      "\titers: 800, epoch: 10 | loss: 0.0591562\n",
      "\tspeed: 0.0491s/iter; left time: 448.2887s\n",
      "\titers: 900, epoch: 10 | loss: 0.0593557\n",
      "\tspeed: 0.0512s/iter; left time: 461.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:49.25s\n",
      "Steps: 902 | Train Loss: 0.0591727 Vali Loss: 0.0910136 Test Loss: 0.1683331\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05975188687443733, rmse:0.24444198608398438, mae:0.1502540409564972, rse:0.7180969715118408\n",
      "Intermediate time for ES and pred_len 96: 00h:19m:08.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2446537\n",
      "\tspeed: 0.0883s/iter; left time: 1580.0079s\n",
      "\titers: 200, epoch: 1 | loss: 0.2167644\n",
      "\tspeed: 0.0595s/iter; left time: 1058.7267s\n",
      "\titers: 300, epoch: 1 | loss: 0.2115878\n",
      "\tspeed: 0.0586s/iter; left time: 1037.8224s\n",
      "\titers: 400, epoch: 1 | loss: 0.2099494\n",
      "\tspeed: 0.0605s/iter; left time: 1064.7440s\n",
      "\titers: 500, epoch: 1 | loss: 0.2013291\n",
      "\tspeed: 0.0609s/iter; left time: 1066.3213s\n",
      "\titers: 600, epoch: 1 | loss: 0.1906402\n",
      "\tspeed: 0.0609s/iter; left time: 1059.4989s\n",
      "\titers: 700, epoch: 1 | loss: 0.1922252\n",
      "\tspeed: 0.0607s/iter; left time: 1050.6307s\n",
      "\titers: 800, epoch: 1 | loss: 0.1903251\n",
      "\tspeed: 0.0575s/iter; left time: 989.1243s\n",
      "\titers: 900, epoch: 1 | loss: 0.1842010\n",
      "\tspeed: 0.0613s/iter; left time: 1048.0348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.81s\n",
      "Steps: 900 | Train Loss: 0.2100938 Vali Loss: 0.1829312 Test Loss: 0.2245326\n",
      "Validation loss decreased (inf --> 0.182931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1685560\n",
      "\tspeed: 0.1665s/iter; left time: 2830.8799s\n",
      "\titers: 200, epoch: 2 | loss: 0.1544590\n",
      "\tspeed: 0.0613s/iter; left time: 1036.2153s\n",
      "\titers: 300, epoch: 2 | loss: 0.1477959\n",
      "\tspeed: 0.0611s/iter; left time: 1027.2385s\n",
      "\titers: 400, epoch: 2 | loss: 0.1323592\n",
      "\tspeed: 0.0620s/iter; left time: 1035.7838s\n",
      "\titers: 500, epoch: 2 | loss: 0.1349913\n",
      "\tspeed: 0.0611s/iter; left time: 1013.5691s\n",
      "\titers: 600, epoch: 2 | loss: 0.1257071\n",
      "\tspeed: 0.0608s/iter; left time: 1002.8606s\n",
      "\titers: 700, epoch: 2 | loss: 0.1232229\n",
      "\tspeed: 0.0607s/iter; left time: 994.8046s\n",
      "\titers: 800, epoch: 2 | loss: 0.1067745\n",
      "\tspeed: 0.0618s/iter; left time: 1007.4753s\n",
      "\titers: 900, epoch: 2 | loss: 0.1061656\n",
      "\tspeed: 0.0616s/iter; left time: 998.6987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.42s\n",
      "Steps: 900 | Train Loss: 0.1381630 Vali Loss: 0.1071996 Test Loss: 0.1560594\n",
      "Validation loss decreased (0.182931 --> 0.107200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0955515\n",
      "\tspeed: 0.1647s/iter; left time: 2652.3975s\n",
      "\titers: 200, epoch: 3 | loss: 0.0972864\n",
      "\tspeed: 0.0569s/iter; left time: 910.8407s\n",
      "\titers: 300, epoch: 3 | loss: 0.1058855\n",
      "\tspeed: 0.0580s/iter; left time: 922.0486s\n",
      "\titers: 400, epoch: 3 | loss: 0.1047665\n",
      "\tspeed: 0.0611s/iter; left time: 965.6897s\n",
      "\titers: 500, epoch: 3 | loss: 0.0897424\n",
      "\tspeed: 0.0607s/iter; left time: 952.4395s\n",
      "\titers: 600, epoch: 3 | loss: 0.0921613\n",
      "\tspeed: 0.0607s/iter; left time: 946.4689s\n",
      "\titers: 700, epoch: 3 | loss: 0.0987247\n",
      "\tspeed: 0.0611s/iter; left time: 947.0163s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945738\n",
      "\tspeed: 0.0595s/iter; left time: 916.9434s\n",
      "\titers: 900, epoch: 3 | loss: 0.0920114\n",
      "\tspeed: 0.0567s/iter; left time: 867.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.61s\n",
      "Steps: 900 | Train Loss: 0.0968913 Vali Loss: 0.1007339 Test Loss: 0.1493993\n",
      "Validation loss decreased (0.107200 --> 0.100734).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0867963\n",
      "\tspeed: 0.1639s/iter; left time: 2491.7117s\n",
      "\titers: 200, epoch: 4 | loss: 0.0872603\n",
      "\tspeed: 0.0606s/iter; left time: 915.8373s\n",
      "\titers: 300, epoch: 4 | loss: 0.0949552\n",
      "\tspeed: 0.0608s/iter; left time: 911.4469s\n",
      "\titers: 400, epoch: 4 | loss: 0.0901616\n",
      "\tspeed: 0.0606s/iter; left time: 902.6156s\n",
      "\titers: 500, epoch: 4 | loss: 0.0886320\n",
      "\tspeed: 0.0611s/iter; left time: 903.9046s\n",
      "\titers: 600, epoch: 4 | loss: 0.0898427\n",
      "\tspeed: 0.0611s/iter; left time: 898.2888s\n",
      "\titers: 700, epoch: 4 | loss: 0.0885059\n",
      "\tspeed: 0.0617s/iter; left time: 901.3805s\n",
      "\titers: 800, epoch: 4 | loss: 0.0823737\n",
      "\tspeed: 0.0614s/iter; left time: 890.0877s\n",
      "\titers: 900, epoch: 4 | loss: 0.0858601\n",
      "\tspeed: 0.0610s/iter; left time: 877.7716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:55.13s\n",
      "Steps: 900 | Train Loss: 0.0890365 Vali Loss: 0.0990229 Test Loss: 0.1549235\n",
      "Validation loss decreased (0.100734 --> 0.099023).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888645\n",
      "\tspeed: 0.1635s/iter; left time: 2337.6800s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828766\n",
      "\tspeed: 0.0614s/iter; left time: 871.4224s\n",
      "\titers: 300, epoch: 5 | loss: 0.0841918\n",
      "\tspeed: 0.0609s/iter; left time: 858.5820s\n",
      "\titers: 400, epoch: 5 | loss: 0.0810863\n",
      "\tspeed: 0.0606s/iter; left time: 849.1553s\n",
      "\titers: 500, epoch: 5 | loss: 0.0835612\n",
      "\tspeed: 0.0616s/iter; left time: 856.0375s\n",
      "\titers: 600, epoch: 5 | loss: 0.0800412\n",
      "\tspeed: 0.0613s/iter; left time: 845.5785s\n",
      "\titers: 700, epoch: 5 | loss: 0.0796864\n",
      "\tspeed: 0.0610s/iter; left time: 835.5033s\n",
      "\titers: 800, epoch: 5 | loss: 0.0781346\n",
      "\tspeed: 0.0609s/iter; left time: 827.8052s\n",
      "\titers: 900, epoch: 5 | loss: 0.0762553\n",
      "\tspeed: 0.0609s/iter; left time: 821.5943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.17s\n",
      "Steps: 900 | Train Loss: 0.0830050 Vali Loss: 0.0968481 Test Loss: 0.1745379\n",
      "Validation loss decreased (0.099023 --> 0.096848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0784856\n",
      "\tspeed: 0.1648s/iter; left time: 2208.6442s\n",
      "\titers: 200, epoch: 6 | loss: 0.0833078\n",
      "\tspeed: 0.0606s/iter; left time: 806.7040s\n",
      "\titers: 300, epoch: 6 | loss: 0.0762790\n",
      "\tspeed: 0.0608s/iter; left time: 802.4949s\n",
      "\titers: 400, epoch: 6 | loss: 0.0757325\n",
      "\tspeed: 0.0609s/iter; left time: 798.4218s\n",
      "\titers: 500, epoch: 6 | loss: 0.0793817\n",
      "\tspeed: 0.0607s/iter; left time: 788.5107s\n",
      "\titers: 600, epoch: 6 | loss: 0.0730279\n",
      "\tspeed: 0.0607s/iter; left time: 782.6143s\n",
      "\titers: 700, epoch: 6 | loss: 0.0776703\n",
      "\tspeed: 0.0609s/iter; left time: 780.2010s\n",
      "\titers: 800, epoch: 6 | loss: 0.0786360\n",
      "\tspeed: 0.0613s/iter; left time: 779.0992s\n",
      "\titers: 900, epoch: 6 | loss: 0.0728884\n",
      "\tspeed: 0.0613s/iter; left time: 773.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.08s\n",
      "Steps: 900 | Train Loss: 0.0778119 Vali Loss: 0.0960560 Test Loss: 0.1783159\n",
      "Validation loss decreased (0.096848 --> 0.096056).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732756\n",
      "\tspeed: 0.1597s/iter; left time: 1996.9434s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759657\n",
      "\tspeed: 0.0589s/iter; left time: 730.8018s\n",
      "\titers: 300, epoch: 7 | loss: 0.0724029\n",
      "\tspeed: 0.0567s/iter; left time: 697.6409s\n",
      "\titers: 400, epoch: 7 | loss: 0.0777792\n",
      "\tspeed: 0.0604s/iter; left time: 736.6097s\n",
      "\titers: 500, epoch: 7 | loss: 0.0738658\n",
      "\tspeed: 0.0607s/iter; left time: 734.4563s\n",
      "\titers: 600, epoch: 7 | loss: 0.0738014\n",
      "\tspeed: 0.0608s/iter; left time: 729.5180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0722032\n",
      "\tspeed: 0.0607s/iter; left time: 722.1950s\n",
      "\titers: 800, epoch: 7 | loss: 0.0726668\n",
      "\tspeed: 0.0607s/iter; left time: 716.6041s\n",
      "\titers: 900, epoch: 7 | loss: 0.0735365\n",
      "\tspeed: 0.0583s/iter; left time: 681.9504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:53.64s\n",
      "Steps: 900 | Train Loss: 0.0735391 Vali Loss: 0.0963464 Test Loss: 0.1909108\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0691501\n",
      "\tspeed: 0.1614s/iter; left time: 1872.2367s\n",
      "\titers: 200, epoch: 8 | loss: 0.0684391\n",
      "\tspeed: 0.0615s/iter; left time: 707.2159s\n",
      "\titers: 300, epoch: 8 | loss: 0.0694468\n",
      "\tspeed: 0.0605s/iter; left time: 690.3216s\n",
      "\titers: 400, epoch: 8 | loss: 0.0707583\n",
      "\tspeed: 0.0607s/iter; left time: 686.1447s\n",
      "\titers: 500, epoch: 8 | loss: 0.0692568\n",
      "\tspeed: 0.0607s/iter; left time: 679.5436s\n",
      "\titers: 600, epoch: 8 | loss: 0.0715037\n",
      "\tspeed: 0.0607s/iter; left time: 673.7215s\n",
      "\titers: 700, epoch: 8 | loss: 0.0713776\n",
      "\tspeed: 0.0607s/iter; left time: 667.3845s\n",
      "\titers: 800, epoch: 8 | loss: 0.0685141\n",
      "\tspeed: 0.0607s/iter; left time: 661.4051s\n",
      "\titers: 900, epoch: 8 | loss: 0.0663676\n",
      "\tspeed: 0.0608s/iter; left time: 656.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.94s\n",
      "Steps: 900 | Train Loss: 0.0693709 Vali Loss: 0.0969994 Test Loss: 0.2027883\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0632454\n",
      "\tspeed: 0.1611s/iter; left time: 1724.1316s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675151\n",
      "\tspeed: 0.0601s/iter; left time: 636.9382s\n",
      "\titers: 300, epoch: 9 | loss: 0.0668501\n",
      "\tspeed: 0.0596s/iter; left time: 625.8029s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665974\n",
      "\tspeed: 0.0614s/iter; left time: 638.1378s\n",
      "\titers: 500, epoch: 9 | loss: 0.0694908\n",
      "\tspeed: 0.0609s/iter; left time: 627.6781s\n",
      "\titers: 600, epoch: 9 | loss: 0.0620214\n",
      "\tspeed: 0.0607s/iter; left time: 618.7207s\n",
      "\titers: 700, epoch: 9 | loss: 0.0636078\n",
      "\tspeed: 0.0614s/iter; left time: 619.8608s\n",
      "\titers: 800, epoch: 9 | loss: 0.0605845\n",
      "\tspeed: 0.0607s/iter; left time: 606.6180s\n",
      "\titers: 900, epoch: 9 | loss: 0.0619091\n",
      "\tspeed: 0.0611s/iter; left time: 604.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:54.90s\n",
      "Steps: 900 | Train Loss: 0.0661374 Vali Loss: 0.0963608 Test Loss: 0.1891286\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0653491\n",
      "\tspeed: 0.1621s/iter; left time: 1588.7180s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624712\n",
      "\tspeed: 0.0608s/iter; left time: 589.9725s\n",
      "\titers: 300, epoch: 10 | loss: 0.0637137\n",
      "\tspeed: 0.0606s/iter; left time: 582.0378s\n",
      "\titers: 400, epoch: 10 | loss: 0.0596867\n",
      "\tspeed: 0.0607s/iter; left time: 576.6537s\n",
      "\titers: 500, epoch: 10 | loss: 0.0653105\n",
      "\tspeed: 0.0606s/iter; left time: 570.1115s\n",
      "\titers: 600, epoch: 10 | loss: 0.0641338\n",
      "\tspeed: 0.0607s/iter; left time: 564.5568s\n",
      "\titers: 700, epoch: 10 | loss: 0.0604017\n",
      "\tspeed: 0.0607s/iter; left time: 558.3886s\n",
      "\titers: 800, epoch: 10 | loss: 0.0622473\n",
      "\tspeed: 0.0606s/iter; left time: 551.8927s\n",
      "\titers: 900, epoch: 10 | loss: 0.0588541\n",
      "\tspeed: 0.0610s/iter; left time: 548.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:54.98s\n",
      "Steps: 900 | Train Loss: 0.0629147 Vali Loss: 0.0967176 Test Loss: 0.1910357\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0599292\n",
      "\tspeed: 0.1619s/iter; left time: 1441.4190s\n",
      "\titers: 200, epoch: 11 | loss: 0.0605542\n",
      "\tspeed: 0.0607s/iter; left time: 534.1329s\n",
      "\titers: 300, epoch: 11 | loss: 0.0596795\n",
      "\tspeed: 0.0607s/iter; left time: 528.1254s\n",
      "\titers: 400, epoch: 11 | loss: 0.0620861\n",
      "\tspeed: 0.0607s/iter; left time: 521.9819s\n",
      "\titers: 500, epoch: 11 | loss: 0.0582006\n",
      "\tspeed: 0.0608s/iter; left time: 516.6191s\n",
      "\titers: 600, epoch: 11 | loss: 0.0576055\n",
      "\tspeed: 0.0612s/iter; left time: 514.0212s\n",
      "\titers: 700, epoch: 11 | loss: 0.0617144\n",
      "\tspeed: 0.0606s/iter; left time: 503.0030s\n",
      "\titers: 800, epoch: 11 | loss: 0.0611123\n",
      "\tspeed: 0.0608s/iter; left time: 498.3522s\n",
      "\titers: 900, epoch: 11 | loss: 0.0598379\n",
      "\tspeed: 0.0607s/iter; left time: 491.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:54.99s\n",
      "Steps: 900 | Train Loss: 0.0603561 Vali Loss: 0.0965993 Test Loss: 0.1903491\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07949484884738922, rmse:0.2819482982158661, mae:0.1783347725868225, rse:0.828172504901886\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2400369\n",
      "\tspeed: 0.0588s/iter; left time: 1053.0766s\n",
      "\titers: 200, epoch: 1 | loss: 0.2189369\n",
      "\tspeed: 0.0567s/iter; left time: 1009.9601s\n",
      "\titers: 300, epoch: 1 | loss: 0.2109801\n",
      "\tspeed: 0.0567s/iter; left time: 1004.5002s\n",
      "\titers: 400, epoch: 1 | loss: 0.2210578\n",
      "\tspeed: 0.0567s/iter; left time: 998.8231s\n",
      "\titers: 500, epoch: 1 | loss: 0.2022315\n",
      "\tspeed: 0.0567s/iter; left time: 993.1721s\n",
      "\titers: 600, epoch: 1 | loss: 0.2054794\n",
      "\tspeed: 0.0572s/iter; left time: 994.6643s\n",
      "\titers: 700, epoch: 1 | loss: 0.1916654\n",
      "\tspeed: 0.0589s/iter; left time: 1018.1871s\n",
      "\titers: 800, epoch: 1 | loss: 0.1877590\n",
      "\tspeed: 0.0569s/iter; left time: 979.1948s\n",
      "\titers: 900, epoch: 1 | loss: 0.1841711\n",
      "\tspeed: 0.0568s/iter; left time: 971.5964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.63s\n",
      "Steps: 900 | Train Loss: 0.2119864 Vali Loss: 0.1902906 Test Loss: 0.2336639\n",
      "Validation loss decreased (inf --> 0.190291).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1677065\n",
      "\tspeed: 0.1664s/iter; left time: 2828.2930s\n",
      "\titers: 200, epoch: 2 | loss: 0.1482060\n",
      "\tspeed: 0.0609s/iter; left time: 1028.7640s\n",
      "\titers: 300, epoch: 2 | loss: 0.1439606\n",
      "\tspeed: 0.0608s/iter; left time: 1021.8103s\n",
      "\titers: 400, epoch: 2 | loss: 0.1452305\n",
      "\tspeed: 0.0611s/iter; left time: 1019.7869s\n",
      "\titers: 500, epoch: 2 | loss: 0.1407253\n",
      "\tspeed: 0.0609s/iter; left time: 1011.5096s\n",
      "\titers: 600, epoch: 2 | loss: 0.1230865\n",
      "\tspeed: 0.0610s/iter; left time: 1005.9831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1124434\n",
      "\tspeed: 0.0609s/iter; left time: 998.0920s\n",
      "\titers: 800, epoch: 2 | loss: 0.1023243\n",
      "\tspeed: 0.0608s/iter; left time: 990.7852s\n",
      "\titers: 900, epoch: 2 | loss: 0.1061958\n",
      "\tspeed: 0.0608s/iter; left time: 985.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.15s\n",
      "Steps: 900 | Train Loss: 0.1367469 Vali Loss: 0.1051926 Test Loss: 0.1516795\n",
      "Validation loss decreased (0.190291 --> 0.105193).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0946447\n",
      "\tspeed: 0.1645s/iter; left time: 2649.2759s\n",
      "\titers: 200, epoch: 3 | loss: 0.0989938\n",
      "\tspeed: 0.0607s/iter; left time: 970.6198s\n",
      "\titers: 300, epoch: 3 | loss: 0.1022622\n",
      "\tspeed: 0.0606s/iter; left time: 964.0113s\n",
      "\titers: 400, epoch: 3 | loss: 0.0942882\n",
      "\tspeed: 0.0606s/iter; left time: 957.7141s\n",
      "\titers: 500, epoch: 3 | loss: 0.0935878\n",
      "\tspeed: 0.0610s/iter; left time: 957.0726s\n",
      "\titers: 600, epoch: 3 | loss: 0.0948615\n",
      "\tspeed: 0.0584s/iter; left time: 911.5169s\n",
      "\titers: 700, epoch: 3 | loss: 0.0939483\n",
      "\tspeed: 0.0595s/iter; left time: 922.3862s\n",
      "\titers: 800, epoch: 3 | loss: 0.0913653\n",
      "\tspeed: 0.0606s/iter; left time: 933.7754s\n",
      "\titers: 900, epoch: 3 | loss: 0.0951659\n",
      "\tspeed: 0.0608s/iter; left time: 929.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.63s\n",
      "Steps: 900 | Train Loss: 0.0967303 Vali Loss: 0.1045170 Test Loss: 0.1540971\n",
      "Validation loss decreased (0.105193 --> 0.104517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944142\n",
      "\tspeed: 0.1637s/iter; left time: 2488.6754s\n",
      "\titers: 200, epoch: 4 | loss: 0.0948463\n",
      "\tspeed: 0.0608s/iter; left time: 917.6564s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868002\n",
      "\tspeed: 0.0608s/iter; left time: 911.7139s\n",
      "\titers: 400, epoch: 4 | loss: 0.0878502\n",
      "\tspeed: 0.0607s/iter; left time: 903.8282s\n",
      "\titers: 500, epoch: 4 | loss: 0.0893905\n",
      "\tspeed: 0.0621s/iter; left time: 918.6218s\n",
      "\titers: 600, epoch: 4 | loss: 0.0862867\n",
      "\tspeed: 0.0613s/iter; left time: 901.7073s\n",
      "\titers: 700, epoch: 4 | loss: 0.0879168\n",
      "\tspeed: 0.0607s/iter; left time: 885.5846s\n",
      "\titers: 800, epoch: 4 | loss: 0.0880771\n",
      "\tspeed: 0.0615s/iter; left time: 891.4414s\n",
      "\titers: 900, epoch: 4 | loss: 0.0853883\n",
      "\tspeed: 0.0607s/iter; left time: 873.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:55.18s\n",
      "Steps: 900 | Train Loss: 0.0891356 Vali Loss: 0.0999913 Test Loss: 0.1594306\n",
      "Validation loss decreased (0.104517 --> 0.099991).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788516\n",
      "\tspeed: 0.1659s/iter; left time: 2372.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0849342\n",
      "\tspeed: 0.0613s/iter; left time: 870.0193s\n",
      "\titers: 300, epoch: 5 | loss: 0.0801767\n",
      "\tspeed: 0.0610s/iter; left time: 860.3045s\n",
      "\titers: 400, epoch: 5 | loss: 0.0843323\n",
      "\tspeed: 0.0612s/iter; left time: 856.5201s\n",
      "\titers: 500, epoch: 5 | loss: 0.0887556\n",
      "\tspeed: 0.0613s/iter; left time: 851.5890s\n",
      "\titers: 600, epoch: 5 | loss: 0.0839269\n",
      "\tspeed: 0.0610s/iter; left time: 842.1288s\n",
      "\titers: 700, epoch: 5 | loss: 0.0815907\n",
      "\tspeed: 0.0609s/iter; left time: 833.9476s\n",
      "\titers: 800, epoch: 5 | loss: 0.0796843\n",
      "\tspeed: 0.0607s/iter; left time: 825.0277s\n",
      "\titers: 900, epoch: 5 | loss: 0.0784328\n",
      "\tspeed: 0.0608s/iter; left time: 820.1956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.17s\n",
      "Steps: 900 | Train Loss: 0.0834460 Vali Loss: 0.1012241 Test Loss: 0.1677511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0812027\n",
      "\tspeed: 0.1635s/iter; left time: 2190.6761s\n",
      "\titers: 200, epoch: 6 | loss: 0.0815519\n",
      "\tspeed: 0.0623s/iter; left time: 829.0554s\n",
      "\titers: 300, epoch: 6 | loss: 0.0812154\n",
      "\tspeed: 0.0612s/iter; left time: 807.7589s\n",
      "\titers: 400, epoch: 6 | loss: 0.0783648\n",
      "\tspeed: 0.0609s/iter; left time: 797.1971s\n",
      "\titers: 500, epoch: 6 | loss: 0.0746267\n",
      "\tspeed: 0.0607s/iter; left time: 788.9782s\n",
      "\titers: 600, epoch: 6 | loss: 0.0772439\n",
      "\tspeed: 0.0616s/iter; left time: 794.3095s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804191\n",
      "\tspeed: 0.0621s/iter; left time: 795.2678s\n",
      "\titers: 800, epoch: 6 | loss: 0.0766137\n",
      "\tspeed: 0.0615s/iter; left time: 780.6798s\n",
      "\titers: 900, epoch: 6 | loss: 0.0814934\n",
      "\tspeed: 0.0616s/iter; left time: 775.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.72s\n",
      "Steps: 900 | Train Loss: 0.0787661 Vali Loss: 0.0987644 Test Loss: 0.1865823\n",
      "Validation loss decreased (0.099991 --> 0.098764).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763484\n",
      "\tspeed: 0.1766s/iter; left time: 2208.0628s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769554\n",
      "\tspeed: 0.0610s/iter; left time: 756.7848s\n",
      "\titers: 300, epoch: 7 | loss: 0.0746029\n",
      "\tspeed: 0.0592s/iter; left time: 728.0778s\n",
      "\titers: 400, epoch: 7 | loss: 0.0770493\n",
      "\tspeed: 0.0597s/iter; left time: 728.6116s\n",
      "\titers: 500, epoch: 7 | loss: 0.0715555\n",
      "\tspeed: 0.0583s/iter; left time: 705.7392s\n",
      "\titers: 600, epoch: 7 | loss: 0.0719796\n",
      "\tspeed: 0.0607s/iter; left time: 728.5339s\n",
      "\titers: 700, epoch: 7 | loss: 0.0676820\n",
      "\tspeed: 0.0611s/iter; left time: 727.3604s\n",
      "\titers: 800, epoch: 7 | loss: 0.0737455\n",
      "\tspeed: 0.0610s/iter; left time: 719.6509s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734292\n",
      "\tspeed: 0.0614s/iter; left time: 718.1919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:54.61s\n",
      "Steps: 900 | Train Loss: 0.0745289 Vali Loss: 0.0957008 Test Loss: 0.1824480\n",
      "Validation loss decreased (0.098764 --> 0.095701).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0704204\n",
      "\tspeed: 0.1653s/iter; left time: 1918.1978s\n",
      "\titers: 200, epoch: 8 | loss: 0.0731290\n",
      "\tspeed: 0.0617s/iter; left time: 709.8168s\n",
      "\titers: 300, epoch: 8 | loss: 0.0713908\n",
      "\tspeed: 0.0568s/iter; left time: 647.2799s\n",
      "\titers: 400, epoch: 8 | loss: 0.0744301\n",
      "\tspeed: 0.0568s/iter; left time: 641.9281s\n",
      "\titers: 500, epoch: 8 | loss: 0.0671376\n",
      "\tspeed: 0.0620s/iter; left time: 694.9570s\n",
      "\titers: 600, epoch: 8 | loss: 0.0676590\n",
      "\tspeed: 0.0621s/iter; left time: 689.1262s\n",
      "\titers: 700, epoch: 8 | loss: 0.0692136\n",
      "\tspeed: 0.0617s/iter; left time: 678.8408s\n",
      "\titers: 800, epoch: 8 | loss: 0.0698851\n",
      "\tspeed: 0.0615s/iter; left time: 670.8197s\n",
      "\titers: 900, epoch: 8 | loss: 0.0714025\n",
      "\tspeed: 0.0609s/iter; left time: 657.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.76s\n",
      "Steps: 900 | Train Loss: 0.0708033 Vali Loss: 0.0972361 Test Loss: 0.2065773\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0710427\n",
      "\tspeed: 0.1575s/iter; left time: 1685.5636s\n",
      "\titers: 200, epoch: 9 | loss: 0.0686311\n",
      "\tspeed: 0.0567s/iter; left time: 601.5713s\n",
      "\titers: 300, epoch: 9 | loss: 0.0704321\n",
      "\tspeed: 0.0573s/iter; left time: 601.2382s\n",
      "\titers: 400, epoch: 9 | loss: 0.0668777\n",
      "\tspeed: 0.0609s/iter; left time: 633.7666s\n",
      "\titers: 500, epoch: 9 | loss: 0.0688231\n",
      "\tspeed: 0.0606s/iter; left time: 624.3797s\n",
      "\titers: 600, epoch: 9 | loss: 0.0656196\n",
      "\tspeed: 0.0608s/iter; left time: 620.3743s\n",
      "\titers: 700, epoch: 9 | loss: 0.0667692\n",
      "\tspeed: 0.0608s/iter; left time: 613.7105s\n",
      "\titers: 800, epoch: 9 | loss: 0.0652089\n",
      "\tspeed: 0.0582s/iter; left time: 581.6537s\n",
      "\titers: 900, epoch: 9 | loss: 0.0679395\n",
      "\tspeed: 0.0567s/iter; left time: 561.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:53.15s\n",
      "Steps: 900 | Train Loss: 0.0674482 Vali Loss: 0.0973093 Test Loss: 0.2006649\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0644264\n",
      "\tspeed: 0.1619s/iter; left time: 1586.6514s\n",
      "\titers: 200, epoch: 10 | loss: 0.0635459\n",
      "\tspeed: 0.0608s/iter; left time: 590.1823s\n",
      "\titers: 300, epoch: 10 | loss: 0.0618790\n",
      "\tspeed: 0.0608s/iter; left time: 584.1480s\n",
      "\titers: 400, epoch: 10 | loss: 0.0672592\n",
      "\tspeed: 0.0584s/iter; left time: 554.8376s\n",
      "\titers: 500, epoch: 10 | loss: 0.0686518\n",
      "\tspeed: 0.0567s/iter; left time: 533.1664s\n",
      "\titers: 600, epoch: 10 | loss: 0.0617627\n",
      "\tspeed: 0.0567s/iter; left time: 527.6082s\n",
      "\titers: 700, epoch: 10 | loss: 0.0657413\n",
      "\tspeed: 0.0568s/iter; left time: 522.2055s\n",
      "\titers: 800, epoch: 10 | loss: 0.0633736\n",
      "\tspeed: 0.0567s/iter; left time: 516.3935s\n",
      "\titers: 900, epoch: 10 | loss: 0.0592178\n",
      "\tspeed: 0.0607s/iter; left time: 546.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:53.16s\n",
      "Steps: 900 | Train Loss: 0.0642967 Vali Loss: 0.0981166 Test Loss: 0.2008145\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0613230\n",
      "\tspeed: 0.1615s/iter; left time: 1437.1526s\n",
      "\titers: 200, epoch: 11 | loss: 0.0626560\n",
      "\tspeed: 0.0567s/iter; left time: 499.4131s\n",
      "\titers: 300, epoch: 11 | loss: 0.0591504\n",
      "\tspeed: 0.0594s/iter; left time: 516.5538s\n",
      "\titers: 400, epoch: 11 | loss: 0.0632064\n",
      "\tspeed: 0.0620s/iter; left time: 533.6852s\n",
      "\titers: 500, epoch: 11 | loss: 0.0623178\n",
      "\tspeed: 0.0609s/iter; left time: 518.0614s\n",
      "\titers: 600, epoch: 11 | loss: 0.0608381\n",
      "\tspeed: 0.0607s/iter; left time: 509.7902s\n",
      "\titers: 700, epoch: 11 | loss: 0.0666960\n",
      "\tspeed: 0.0608s/iter; left time: 504.4249s\n",
      "\titers: 800, epoch: 11 | loss: 0.0632513\n",
      "\tspeed: 0.0608s/iter; left time: 498.2250s\n",
      "\titers: 900, epoch: 11 | loss: 0.0584000\n",
      "\tspeed: 0.0608s/iter; left time: 492.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:54.56s\n",
      "Steps: 900 | Train Loss: 0.0618676 Vali Loss: 0.0971447 Test Loss: 0.1886522\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608376\n",
      "\tspeed: 0.1611s/iter; left time: 1288.8354s\n",
      "\titers: 200, epoch: 12 | loss: 0.0564305\n",
      "\tspeed: 0.0612s/iter; left time: 483.7130s\n",
      "\titers: 300, epoch: 12 | loss: 0.0570544\n",
      "\tspeed: 0.0607s/iter; left time: 473.2592s\n",
      "\titers: 400, epoch: 12 | loss: 0.0582780\n",
      "\tspeed: 0.0615s/iter; left time: 473.6523s\n",
      "\titers: 500, epoch: 12 | loss: 0.0598973\n",
      "\tspeed: 0.0621s/iter; left time: 471.7109s\n",
      "\titers: 600, epoch: 12 | loss: 0.0550026\n",
      "\tspeed: 0.0621s/iter; left time: 465.5874s\n",
      "\titers: 700, epoch: 12 | loss: 0.0564161\n",
      "\tspeed: 0.0610s/iter; left time: 451.8012s\n",
      "\titers: 800, epoch: 12 | loss: 0.0571159\n",
      "\tspeed: 0.0598s/iter; left time: 436.7538s\n",
      "\titers: 900, epoch: 12 | loss: 0.0591275\n",
      "\tspeed: 0.0596s/iter; left time: 429.2387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:55.12s\n",
      "Steps: 900 | Train Loss: 0.0595349 Vali Loss: 0.0978677 Test Loss: 0.1947020\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0831800326704979, rmse:0.2884095013141632, mae:0.18242256343364716, rse:0.8471510410308838\n",
      "Intermediate time for ES and pred_len 168: 00h:25m:08.57s\n",
      "Intermediate time for ES: 01h:14m:59.24s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1765880\n",
      "\tspeed: 0.0779s/iter; left time: 1400.8792s\n",
      "\titers: 200, epoch: 1 | loss: 0.1542308\n",
      "\tspeed: 0.0505s/iter; left time: 903.8014s\n",
      "\titers: 300, epoch: 1 | loss: 0.1662518\n",
      "\tspeed: 0.0505s/iter; left time: 898.5329s\n",
      "\titers: 400, epoch: 1 | loss: 0.1567519\n",
      "\tspeed: 0.0504s/iter; left time: 891.5171s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509907\n",
      "\tspeed: 0.0506s/iter; left time: 888.7614s\n",
      "\titers: 600, epoch: 1 | loss: 0.1506185\n",
      "\tspeed: 0.0506s/iter; left time: 883.8517s\n",
      "\titers: 700, epoch: 1 | loss: 0.1570569\n",
      "\tspeed: 0.0506s/iter; left time: 878.8649s\n",
      "\titers: 800, epoch: 1 | loss: 0.1431779\n",
      "\tspeed: 0.0506s/iter; left time: 873.8597s\n",
      "\titers: 900, epoch: 1 | loss: 0.1424787\n",
      "\tspeed: 0.0506s/iter; left time: 868.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.42s\n",
      "Steps: 904 | Train Loss: 0.1585275 Vali Loss: 0.1496957 Test Loss: 0.1732779\n",
      "Validation loss decreased (inf --> 0.149696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1232590\n",
      "\tspeed: 0.1327s/iter; left time: 2266.9298s\n",
      "\titers: 200, epoch: 2 | loss: 0.0973932\n",
      "\tspeed: 0.0506s/iter; left time: 859.8388s\n",
      "\titers: 300, epoch: 2 | loss: 0.0738992\n",
      "\tspeed: 0.0506s/iter; left time: 854.6308s\n",
      "\titers: 400, epoch: 2 | loss: 0.0604152\n",
      "\tspeed: 0.0505s/iter; left time: 847.5144s\n",
      "\titers: 500, epoch: 2 | loss: 0.0645089\n",
      "\tspeed: 0.0505s/iter; left time: 842.7496s\n",
      "\titers: 600, epoch: 2 | loss: 0.0495734\n",
      "\tspeed: 0.0507s/iter; left time: 839.6700s\n",
      "\titers: 700, epoch: 2 | loss: 0.0631037\n",
      "\tspeed: 0.0505s/iter; left time: 831.3003s\n",
      "\titers: 800, epoch: 2 | loss: 0.0648103\n",
      "\tspeed: 0.0505s/iter; left time: 827.7246s\n",
      "\titers: 900, epoch: 2 | loss: 0.0554054\n",
      "\tspeed: 0.0507s/iter; left time: 824.8684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0795072 Vali Loss: 0.0686594 Test Loss: 0.0759086\n",
      "Validation loss decreased (0.149696 --> 0.068659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0616508\n",
      "\tspeed: 0.1436s/iter; left time: 2322.3565s\n",
      "\titers: 200, epoch: 3 | loss: 0.0576355\n",
      "\tspeed: 0.0505s/iter; left time: 812.4306s\n",
      "\titers: 300, epoch: 3 | loss: 0.0677154\n",
      "\tspeed: 0.0506s/iter; left time: 808.3207s\n",
      "\titers: 400, epoch: 3 | loss: 0.0584154\n",
      "\tspeed: 0.0505s/iter; left time: 802.1732s\n",
      "\titers: 500, epoch: 3 | loss: 0.0532029\n",
      "\tspeed: 0.0505s/iter; left time: 797.0085s\n",
      "\titers: 600, epoch: 3 | loss: 0.0529178\n",
      "\tspeed: 0.0506s/iter; left time: 792.4335s\n",
      "\titers: 700, epoch: 3 | loss: 0.0514033\n",
      "\tspeed: 0.0506s/iter; left time: 787.3330s\n",
      "\titers: 800, epoch: 3 | loss: 0.0564296\n",
      "\tspeed: 0.0505s/iter; left time: 782.0161s\n",
      "\titers: 900, epoch: 3 | loss: 0.0561410\n",
      "\tspeed: 0.0507s/iter; left time: 780.0209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0549776 Vali Loss: 0.0627655 Test Loss: 0.0699775\n",
      "Validation loss decreased (0.068659 --> 0.062765).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0507133\n",
      "\tspeed: 0.1310s/iter; left time: 2000.5456s\n",
      "\titers: 200, epoch: 4 | loss: 0.0505312\n",
      "\tspeed: 0.0504s/iter; left time: 764.8778s\n",
      "\titers: 300, epoch: 4 | loss: 0.0494273\n",
      "\tspeed: 0.0505s/iter; left time: 760.3095s\n",
      "\titers: 400, epoch: 4 | loss: 0.0538551\n",
      "\tspeed: 0.0504s/iter; left time: 753.8182s\n",
      "\titers: 500, epoch: 4 | loss: 0.0489377\n",
      "\tspeed: 0.0506s/iter; left time: 751.8735s\n",
      "\titers: 600, epoch: 4 | loss: 0.0499998\n",
      "\tspeed: 0.0505s/iter; left time: 745.3499s\n",
      "\titers: 700, epoch: 4 | loss: 0.0514977\n",
      "\tspeed: 0.0505s/iter; left time: 740.1430s\n",
      "\titers: 800, epoch: 4 | loss: 0.0457442\n",
      "\tspeed: 0.0507s/iter; left time: 737.9915s\n",
      "\titers: 900, epoch: 4 | loss: 0.0434786\n",
      "\tspeed: 0.0505s/iter; left time: 730.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 904 | Train Loss: 0.0509406 Vali Loss: 0.0603722 Test Loss: 0.0698583\n",
      "Validation loss decreased (0.062765 --> 0.060372).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0454622\n",
      "\tspeed: 0.1326s/iter; left time: 1904.6406s\n",
      "\titers: 200, epoch: 5 | loss: 0.0504784\n",
      "\tspeed: 0.0507s/iter; left time: 722.5525s\n",
      "\titers: 300, epoch: 5 | loss: 0.0486649\n",
      "\tspeed: 0.0507s/iter; left time: 717.9162s\n",
      "\titers: 400, epoch: 5 | loss: 0.0524773\n",
      "\tspeed: 0.0506s/iter; left time: 710.9868s\n",
      "\titers: 500, epoch: 5 | loss: 0.0512302\n",
      "\tspeed: 0.0507s/iter; left time: 707.7029s\n",
      "\titers: 600, epoch: 5 | loss: 0.0428833\n",
      "\tspeed: 0.0506s/iter; left time: 701.2170s\n",
      "\titers: 700, epoch: 5 | loss: 0.0521267\n",
      "\tspeed: 0.0507s/iter; left time: 697.4112s\n",
      "\titers: 800, epoch: 5 | loss: 0.0470317\n",
      "\tspeed: 0.0506s/iter; left time: 690.8033s\n",
      "\titers: 900, epoch: 5 | loss: 0.0457500\n",
      "\tspeed: 0.0505s/iter; left time: 685.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0487176 Vali Loss: 0.0604037 Test Loss: 0.0658937\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0555150\n",
      "\tspeed: 0.1282s/iter; left time: 1725.0996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0488049\n",
      "\tspeed: 0.0505s/iter; left time: 674.9328s\n",
      "\titers: 300, epoch: 6 | loss: 0.0424043\n",
      "\tspeed: 0.0505s/iter; left time: 670.1674s\n",
      "\titers: 400, epoch: 6 | loss: 0.0446258\n",
      "\tspeed: 0.0506s/iter; left time: 665.8930s\n",
      "\titers: 500, epoch: 6 | loss: 0.0407961\n",
      "\tspeed: 0.0509s/iter; left time: 664.9777s\n",
      "\titers: 600, epoch: 6 | loss: 0.0564376\n",
      "\tspeed: 0.0507s/iter; left time: 656.5951s\n",
      "\titers: 700, epoch: 6 | loss: 0.0444908\n",
      "\tspeed: 0.0506s/iter; left time: 650.6449s\n",
      "\titers: 800, epoch: 6 | loss: 0.0489550\n",
      "\tspeed: 0.0505s/iter; left time: 644.9236s\n",
      "\titers: 900, epoch: 6 | loss: 0.0432534\n",
      "\tspeed: 0.0510s/iter; left time: 645.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.0470484 Vali Loss: 0.0607061 Test Loss: 0.0668339\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0391374\n",
      "\tspeed: 0.1275s/iter; left time: 1601.2634s\n",
      "\titers: 200, epoch: 7 | loss: 0.0412914\n",
      "\tspeed: 0.0506s/iter; left time: 630.2498s\n",
      "\titers: 300, epoch: 7 | loss: 0.0454113\n",
      "\tspeed: 0.0505s/iter; left time: 624.4601s\n",
      "\titers: 400, epoch: 7 | loss: 0.0454848\n",
      "\tspeed: 0.0506s/iter; left time: 620.7773s\n",
      "\titers: 500, epoch: 7 | loss: 0.0391963\n",
      "\tspeed: 0.0505s/iter; left time: 614.4700s\n",
      "\titers: 600, epoch: 7 | loss: 0.0515287\n",
      "\tspeed: 0.0506s/iter; left time: 609.6708s\n",
      "\titers: 700, epoch: 7 | loss: 0.0453807\n",
      "\tspeed: 0.0506s/iter; left time: 604.6375s\n",
      "\titers: 800, epoch: 7 | loss: 0.0466342\n",
      "\tspeed: 0.0505s/iter; left time: 599.1925s\n",
      "\titers: 900, epoch: 7 | loss: 0.0446688\n",
      "\tspeed: 0.0506s/iter; left time: 594.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0454673 Vali Loss: 0.0587941 Test Loss: 0.0654209\n",
      "Validation loss decreased (0.060372 --> 0.058794).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0526595\n",
      "\tspeed: 0.1307s/iter; left time: 1523.1780s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435260\n",
      "\tspeed: 0.0505s/iter; left time: 583.9887s\n",
      "\titers: 300, epoch: 8 | loss: 0.0459962\n",
      "\tspeed: 0.0507s/iter; left time: 580.8049s\n",
      "\titers: 400, epoch: 8 | loss: 0.0445714\n",
      "\tspeed: 0.0506s/iter; left time: 574.3793s\n",
      "\titers: 500, epoch: 8 | loss: 0.0469895\n",
      "\tspeed: 0.0505s/iter; left time: 568.5729s\n",
      "\titers: 600, epoch: 8 | loss: 0.0442014\n",
      "\tspeed: 0.0505s/iter; left time: 563.7361s\n",
      "\titers: 700, epoch: 8 | loss: 0.0464062\n",
      "\tspeed: 0.0510s/iter; left time: 564.0132s\n",
      "\titers: 800, epoch: 8 | loss: 0.0492792\n",
      "\tspeed: 0.0504s/iter; left time: 552.3823s\n",
      "\titers: 900, epoch: 8 | loss: 0.0430017\n",
      "\tspeed: 0.0506s/iter; left time: 548.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0442636 Vali Loss: 0.0583492 Test Loss: 0.0663781\n",
      "Validation loss decreased (0.058794 --> 0.058349).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0432738\n",
      "\tspeed: 0.1371s/iter; left time: 1473.9158s\n",
      "\titers: 200, epoch: 9 | loss: 0.0398520\n",
      "\tspeed: 0.0505s/iter; left time: 538.1589s\n",
      "\titers: 300, epoch: 9 | loss: 0.0493081\n",
      "\tspeed: 0.0506s/iter; left time: 533.5223s\n",
      "\titers: 400, epoch: 9 | loss: 0.0430568\n",
      "\tspeed: 0.0506s/iter; left time: 528.3076s\n",
      "\titers: 500, epoch: 9 | loss: 0.0452830\n",
      "\tspeed: 0.0507s/iter; left time: 525.0896s\n",
      "\titers: 600, epoch: 9 | loss: 0.0437548\n",
      "\tspeed: 0.0505s/iter; left time: 517.9376s\n",
      "\titers: 700, epoch: 9 | loss: 0.0444852\n",
      "\tspeed: 0.0505s/iter; left time: 512.9303s\n",
      "\titers: 800, epoch: 9 | loss: 0.0500806\n",
      "\tspeed: 0.0505s/iter; left time: 507.8686s\n",
      "\titers: 900, epoch: 9 | loss: 0.0393149\n",
      "\tspeed: 0.0505s/iter; left time: 501.9750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0429566 Vali Loss: 0.0602329 Test Loss: 0.0677185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0443967\n",
      "\tspeed: 0.1283s/iter; left time: 1263.3880s\n",
      "\titers: 200, epoch: 10 | loss: 0.0404682\n",
      "\tspeed: 0.0507s/iter; left time: 494.2178s\n",
      "\titers: 300, epoch: 10 | loss: 0.0334325\n",
      "\tspeed: 0.0510s/iter; left time: 491.7666s\n",
      "\titers: 400, epoch: 10 | loss: 0.0430959\n",
      "\tspeed: 0.0519s/iter; left time: 495.8014s\n",
      "\titers: 500, epoch: 10 | loss: 0.0392467\n",
      "\tspeed: 0.0505s/iter; left time: 476.5954s\n",
      "\titers: 600, epoch: 10 | loss: 0.0375074\n",
      "\tspeed: 0.0505s/iter; left time: 472.3492s\n",
      "\titers: 700, epoch: 10 | loss: 0.0444755\n",
      "\tspeed: 0.0506s/iter; left time: 467.7026s\n",
      "\titers: 800, epoch: 10 | loss: 0.0410721\n",
      "\tspeed: 0.0507s/iter; left time: 463.8208s\n",
      "\titers: 900, epoch: 10 | loss: 0.0385406\n",
      "\tspeed: 0.0508s/iter; left time: 459.3419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0417736 Vali Loss: 0.0579738 Test Loss: 0.0649158\n",
      "Validation loss decreased (0.058349 --> 0.057974).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0447565\n",
      "\tspeed: 0.1334s/iter; left time: 1192.6860s\n",
      "\titers: 200, epoch: 11 | loss: 0.0423072\n",
      "\tspeed: 0.0506s/iter; left time: 447.5223s\n",
      "\titers: 300, epoch: 11 | loss: 0.0478902\n",
      "\tspeed: 0.0506s/iter; left time: 441.9836s\n",
      "\titers: 400, epoch: 11 | loss: 0.0403916\n",
      "\tspeed: 0.0506s/iter; left time: 437.5018s\n",
      "\titers: 500, epoch: 11 | loss: 0.0389341\n",
      "\tspeed: 0.0505s/iter; left time: 431.6875s\n",
      "\titers: 600, epoch: 11 | loss: 0.0363502\n",
      "\tspeed: 0.0507s/iter; left time: 427.5480s\n",
      "\titers: 700, epoch: 11 | loss: 0.0404644\n",
      "\tspeed: 0.0507s/iter; left time: 423.0821s\n",
      "\titers: 800, epoch: 11 | loss: 0.0394054\n",
      "\tspeed: 0.0506s/iter; left time: 416.6700s\n",
      "\titers: 900, epoch: 11 | loss: 0.0445009\n",
      "\tspeed: 0.0505s/iter; left time: 411.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0406601 Vali Loss: 0.0589653 Test Loss: 0.0656324\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0416945\n",
      "\tspeed: 0.1288s/iter; left time: 1035.3037s\n",
      "\titers: 200, epoch: 12 | loss: 0.0431753\n",
      "\tspeed: 0.0508s/iter; left time: 402.8034s\n",
      "\titers: 300, epoch: 12 | loss: 0.0408017\n",
      "\tspeed: 0.0506s/iter; left time: 396.5909s\n",
      "\titers: 400, epoch: 12 | loss: 0.0414775\n",
      "\tspeed: 0.0513s/iter; left time: 397.0521s\n",
      "\titers: 500, epoch: 12 | loss: 0.0398259\n",
      "\tspeed: 0.0507s/iter; left time: 387.1595s\n",
      "\titers: 600, epoch: 12 | loss: 0.0430085\n",
      "\tspeed: 0.0507s/iter; left time: 381.7746s\n",
      "\titers: 700, epoch: 12 | loss: 0.0394019\n",
      "\tspeed: 0.0507s/iter; left time: 376.7780s\n",
      "\titers: 800, epoch: 12 | loss: 0.0382711\n",
      "\tspeed: 0.0505s/iter; left time: 370.8210s\n",
      "\titers: 900, epoch: 12 | loss: 0.0412988\n",
      "\tspeed: 0.0507s/iter; left time: 367.2354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.0396240 Vali Loss: 0.0594021 Test Loss: 0.0664077\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0350026\n",
      "\tspeed: 0.1286s/iter; left time: 917.5329s\n",
      "\titers: 200, epoch: 13 | loss: 0.0396435\n",
      "\tspeed: 0.0507s/iter; left time: 356.9064s\n",
      "\titers: 300, epoch: 13 | loss: 0.0374444\n",
      "\tspeed: 0.0504s/iter; left time: 349.6080s\n",
      "\titers: 400, epoch: 13 | loss: 0.0382873\n",
      "\tspeed: 0.0506s/iter; left time: 346.0087s\n",
      "\titers: 500, epoch: 13 | loss: 0.0433497\n",
      "\tspeed: 0.0505s/iter; left time: 340.3393s\n",
      "\titers: 600, epoch: 13 | loss: 0.0397549\n",
      "\tspeed: 0.0508s/iter; left time: 337.2867s\n",
      "\titers: 700, epoch: 13 | loss: 0.0378477\n",
      "\tspeed: 0.0505s/iter; left time: 330.1490s\n",
      "\titers: 800, epoch: 13 | loss: 0.0360005\n",
      "\tspeed: 0.0508s/iter; left time: 326.4756s\n",
      "\titers: 900, epoch: 13 | loss: 0.0428925\n",
      "\tspeed: 0.0505s/iter; left time: 319.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0386554 Vali Loss: 0.0602128 Test Loss: 0.0691037\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0409042\n",
      "\tspeed: 0.1280s/iter; left time: 797.4617s\n",
      "\titers: 200, epoch: 14 | loss: 0.0354530\n",
      "\tspeed: 0.0506s/iter; left time: 309.8736s\n",
      "\titers: 300, epoch: 14 | loss: 0.0358330\n",
      "\tspeed: 0.0505s/iter; left time: 304.2373s\n",
      "\titers: 400, epoch: 14 | loss: 0.0381372\n",
      "\tspeed: 0.0506s/iter; left time: 300.1606s\n",
      "\titers: 500, epoch: 14 | loss: 0.0364365\n",
      "\tspeed: 0.0505s/iter; left time: 294.4183s\n",
      "\titers: 600, epoch: 14 | loss: 0.0356496\n",
      "\tspeed: 0.0506s/iter; left time: 290.0059s\n",
      "\titers: 700, epoch: 14 | loss: 0.0401404\n",
      "\tspeed: 0.0506s/iter; left time: 284.6536s\n",
      "\titers: 800, epoch: 14 | loss: 0.0373028\n",
      "\tspeed: 0.0507s/iter; left time: 280.1741s\n",
      "\titers: 900, epoch: 14 | loss: 0.0380366\n",
      "\tspeed: 0.0507s/iter; left time: 275.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0375392 Vali Loss: 0.0588704 Test Loss: 0.0672328\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0386039\n",
      "\tspeed: 0.1288s/iter; left time: 685.8636s\n",
      "\titers: 200, epoch: 15 | loss: 0.0389755\n",
      "\tspeed: 0.0507s/iter; left time: 264.7609s\n",
      "\titers: 300, epoch: 15 | loss: 0.0316308\n",
      "\tspeed: 0.0506s/iter; left time: 259.5605s\n",
      "\titers: 400, epoch: 15 | loss: 0.0370416\n",
      "\tspeed: 0.0507s/iter; left time: 254.6415s\n",
      "\titers: 500, epoch: 15 | loss: 0.0341062\n",
      "\tspeed: 0.0505s/iter; left time: 248.5532s\n",
      "\titers: 600, epoch: 15 | loss: 0.0373095\n",
      "\tspeed: 0.0505s/iter; left time: 243.7577s\n",
      "\titers: 700, epoch: 15 | loss: 0.0361009\n",
      "\tspeed: 0.0505s/iter; left time: 238.4954s\n",
      "\titers: 800, epoch: 15 | loss: 0.0334881\n",
      "\tspeed: 0.0506s/iter; left time: 234.1777s\n",
      "\titers: 900, epoch: 15 | loss: 0.0389296\n",
      "\tspeed: 0.0506s/iter; left time: 229.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.0365351 Vali Loss: 0.0594991 Test Loss: 0.0683849\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012692660093307495, rmse:0.1126617044210434, mae:0.06498495489358902, rse:0.4347411096096039\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1857122\n",
      "\tspeed: 0.0527s/iter; left time: 947.4301s\n",
      "\titers: 200, epoch: 1 | loss: 0.1673031\n",
      "\tspeed: 0.0507s/iter; left time: 906.9927s\n",
      "\titers: 300, epoch: 1 | loss: 0.1726502\n",
      "\tspeed: 0.0504s/iter; left time: 896.7590s\n",
      "\titers: 400, epoch: 1 | loss: 0.1585011\n",
      "\tspeed: 0.0507s/iter; left time: 896.9088s\n",
      "\titers: 500, epoch: 1 | loss: 0.1398727\n",
      "\tspeed: 0.0506s/iter; left time: 889.7506s\n",
      "\titers: 600, epoch: 1 | loss: 0.1448003\n",
      "\tspeed: 0.0506s/iter; left time: 883.6976s\n",
      "\titers: 700, epoch: 1 | loss: 0.1510797\n",
      "\tspeed: 0.0507s/iter; left time: 881.2391s\n",
      "\titers: 800, epoch: 1 | loss: 0.1368613\n",
      "\tspeed: 0.0506s/iter; left time: 874.7979s\n",
      "\titers: 900, epoch: 1 | loss: 0.1403419\n",
      "\tspeed: 0.0507s/iter; left time: 870.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.1590328 Vali Loss: 0.1483693 Test Loss: 0.1695288\n",
      "Validation loss decreased (inf --> 0.148369).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1334286\n",
      "\tspeed: 0.1327s/iter; left time: 2265.7145s\n",
      "\titers: 200, epoch: 2 | loss: 0.1185983\n",
      "\tspeed: 0.0505s/iter; left time: 857.4777s\n",
      "\titers: 300, epoch: 2 | loss: 0.1030524\n",
      "\tspeed: 0.0506s/iter; left time: 854.2714s\n",
      "\titers: 400, epoch: 2 | loss: 0.1099682\n",
      "\tspeed: 0.0508s/iter; left time: 852.6645s\n",
      "\titers: 500, epoch: 2 | loss: 0.1082221\n",
      "\tspeed: 0.0505s/iter; left time: 842.3494s\n",
      "\titers: 600, epoch: 2 | loss: 0.0928978\n",
      "\tspeed: 0.0506s/iter; left time: 839.3842s\n",
      "\titers: 700, epoch: 2 | loss: 0.0728285\n",
      "\tspeed: 0.0506s/iter; left time: 833.7500s\n",
      "\titers: 800, epoch: 2 | loss: 0.0645128\n",
      "\tspeed: 0.0505s/iter; left time: 827.6636s\n",
      "\titers: 900, epoch: 2 | loss: 0.0673700\n",
      "\tspeed: 0.0506s/iter; left time: 824.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.1007329 Vali Loss: 0.0714553 Test Loss: 0.0807210\n",
      "Validation loss decreased (0.148369 --> 0.071455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0584821\n",
      "\tspeed: 0.1345s/iter; left time: 2175.0467s\n",
      "\titers: 200, epoch: 3 | loss: 0.0669703\n",
      "\tspeed: 0.0503s/iter; left time: 809.2139s\n",
      "\titers: 300, epoch: 3 | loss: 0.0617523\n",
      "\tspeed: 0.0507s/iter; left time: 809.1688s\n",
      "\titers: 400, epoch: 3 | loss: 0.0593314\n",
      "\tspeed: 0.0501s/iter; left time: 795.8170s\n",
      "\titers: 500, epoch: 3 | loss: 0.0576331\n",
      "\tspeed: 0.0506s/iter; left time: 797.3787s\n",
      "\titers: 600, epoch: 3 | loss: 0.0519418\n",
      "\tspeed: 0.0506s/iter; left time: 793.0085s\n",
      "\titers: 700, epoch: 3 | loss: 0.0611038\n",
      "\tspeed: 0.0506s/iter; left time: 787.3141s\n",
      "\titers: 800, epoch: 3 | loss: 0.0664050\n",
      "\tspeed: 0.0509s/iter; left time: 787.0001s\n",
      "\titers: 900, epoch: 3 | loss: 0.0587706\n",
      "\tspeed: 0.0508s/iter; left time: 781.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0575077 Vali Loss: 0.0651745 Test Loss: 0.0735307\n",
      "Validation loss decreased (0.071455 --> 0.065175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0581391\n",
      "\tspeed: 0.1323s/iter; left time: 2019.3385s\n",
      "\titers: 200, epoch: 4 | loss: 0.0578832\n",
      "\tspeed: 0.0506s/iter; left time: 766.9713s\n",
      "\titers: 300, epoch: 4 | loss: 0.0496099\n",
      "\tspeed: 0.0507s/iter; left time: 764.5889s\n",
      "\titers: 400, epoch: 4 | loss: 0.0476263\n",
      "\tspeed: 0.0505s/iter; left time: 756.6155s\n",
      "\titers: 500, epoch: 4 | loss: 0.0471702\n",
      "\tspeed: 0.0505s/iter; left time: 751.4651s\n",
      "\titers: 600, epoch: 4 | loss: 0.0493034\n",
      "\tspeed: 0.0504s/iter; left time: 744.9449s\n",
      "\titers: 700, epoch: 4 | loss: 0.0528247\n",
      "\tspeed: 0.0505s/iter; left time: 741.2136s\n",
      "\titers: 800, epoch: 4 | loss: 0.0520682\n",
      "\tspeed: 0.0506s/iter; left time: 737.3971s\n",
      "\titers: 900, epoch: 4 | loss: 0.0515066\n",
      "\tspeed: 0.0510s/iter; left time: 737.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0523280 Vali Loss: 0.0624945 Test Loss: 0.0713332\n",
      "Validation loss decreased (0.065175 --> 0.062495).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0495861\n",
      "\tspeed: 0.1357s/iter; left time: 1948.8739s\n",
      "\titers: 200, epoch: 5 | loss: 0.0519677\n",
      "\tspeed: 0.0506s/iter; left time: 721.2803s\n",
      "\titers: 300, epoch: 5 | loss: 0.0495330\n",
      "\tspeed: 0.0506s/iter; left time: 716.1342s\n",
      "\titers: 400, epoch: 5 | loss: 0.0477002\n",
      "\tspeed: 0.0506s/iter; left time: 711.0038s\n",
      "\titers: 500, epoch: 5 | loss: 0.0449600\n",
      "\tspeed: 0.0506s/iter; left time: 706.4074s\n",
      "\titers: 600, epoch: 5 | loss: 0.0537562\n",
      "\tspeed: 0.0507s/iter; left time: 703.5789s\n",
      "\titers: 700, epoch: 5 | loss: 0.0500192\n",
      "\tspeed: 0.0505s/iter; left time: 695.6781s\n",
      "\titers: 800, epoch: 5 | loss: 0.0479099\n",
      "\tspeed: 0.0505s/iter; left time: 690.4796s\n",
      "\titers: 900, epoch: 5 | loss: 0.0487291\n",
      "\tspeed: 0.0506s/iter; left time: 686.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0495370 Vali Loss: 0.0619618 Test Loss: 0.0706246\n",
      "Validation loss decreased (0.062495 --> 0.061962).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0439078\n",
      "\tspeed: 0.1366s/iter; left time: 1839.3775s\n",
      "\titers: 200, epoch: 6 | loss: 0.0507385\n",
      "\tspeed: 0.0505s/iter; left time: 675.1128s\n",
      "\titers: 300, epoch: 6 | loss: 0.0574638\n",
      "\tspeed: 0.0505s/iter; left time: 670.1210s\n",
      "\titers: 400, epoch: 6 | loss: 0.0490137\n",
      "\tspeed: 0.0505s/iter; left time: 665.0188s\n",
      "\titers: 500, epoch: 6 | loss: 0.0459828\n",
      "\tspeed: 0.0508s/iter; left time: 663.1712s\n",
      "\titers: 600, epoch: 6 | loss: 0.0431282\n",
      "\tspeed: 0.0506s/iter; left time: 655.3472s\n",
      "\titers: 700, epoch: 6 | loss: 0.0453926\n",
      "\tspeed: 0.0506s/iter; left time: 651.1640s\n",
      "\titers: 800, epoch: 6 | loss: 0.0464763\n",
      "\tspeed: 0.0506s/iter; left time: 645.2036s\n",
      "\titers: 900, epoch: 6 | loss: 0.0478225\n",
      "\tspeed: 0.0508s/iter; left time: 642.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0475689 Vali Loss: 0.0615592 Test Loss: 0.0695541\n",
      "Validation loss decreased (0.061962 --> 0.061559).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502358\n",
      "\tspeed: 0.1322s/iter; left time: 1659.4436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0506634\n",
      "\tspeed: 0.0504s/iter; left time: 628.2205s\n",
      "\titers: 300, epoch: 7 | loss: 0.0464740\n",
      "\tspeed: 0.0505s/iter; left time: 623.4366s\n",
      "\titers: 400, epoch: 7 | loss: 0.0463190\n",
      "\tspeed: 0.0506s/iter; left time: 619.8661s\n",
      "\titers: 500, epoch: 7 | loss: 0.0447579\n",
      "\tspeed: 0.0505s/iter; left time: 613.5116s\n",
      "\titers: 600, epoch: 7 | loss: 0.0476501\n",
      "\tspeed: 0.0506s/iter; left time: 610.6226s\n",
      "\titers: 700, epoch: 7 | loss: 0.0456153\n",
      "\tspeed: 0.0505s/iter; left time: 604.4048s\n",
      "\titers: 800, epoch: 7 | loss: 0.0416225\n",
      "\tspeed: 0.0509s/iter; left time: 602.9530s\n",
      "\titers: 900, epoch: 7 | loss: 0.0494760\n",
      "\tspeed: 0.0505s/iter; left time: 594.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0459601 Vali Loss: 0.0608928 Test Loss: 0.0669883\n",
      "Validation loss decreased (0.061559 --> 0.060893).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0436549\n",
      "\tspeed: 0.1357s/iter; left time: 1581.2486s\n",
      "\titers: 200, epoch: 8 | loss: 0.0437935\n",
      "\tspeed: 0.0506s/iter; left time: 585.1329s\n",
      "\titers: 300, epoch: 8 | loss: 0.0404316\n",
      "\tspeed: 0.0505s/iter; left time: 577.9412s\n",
      "\titers: 400, epoch: 8 | loss: 0.0440264\n",
      "\tspeed: 0.0506s/iter; left time: 574.8051s\n",
      "\titers: 500, epoch: 8 | loss: 0.0411384\n",
      "\tspeed: 0.0506s/iter; left time: 569.9155s\n",
      "\titers: 600, epoch: 8 | loss: 0.0496980\n",
      "\tspeed: 0.0506s/iter; left time: 563.7931s\n",
      "\titers: 700, epoch: 8 | loss: 0.0420317\n",
      "\tspeed: 0.0505s/iter; left time: 558.5649s\n",
      "\titers: 800, epoch: 8 | loss: 0.0377858\n",
      "\tspeed: 0.0505s/iter; left time: 552.7393s\n",
      "\titers: 900, epoch: 8 | loss: 0.0497697\n",
      "\tspeed: 0.0507s/iter; left time: 550.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0443618 Vali Loss: 0.0606880 Test Loss: 0.0691889\n",
      "Validation loss decreased (0.060893 --> 0.060688).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0389210\n",
      "\tspeed: 0.1430s/iter; left time: 1537.5263s\n",
      "\titers: 200, epoch: 9 | loss: 0.0421957\n",
      "\tspeed: 0.0506s/iter; left time: 538.3660s\n",
      "\titers: 300, epoch: 9 | loss: 0.0489388\n",
      "\tspeed: 0.0505s/iter; left time: 533.2256s\n",
      "\titers: 400, epoch: 9 | loss: 0.0433093\n",
      "\tspeed: 0.0505s/iter; left time: 527.2585s\n",
      "\titers: 500, epoch: 9 | loss: 0.0402692\n",
      "\tspeed: 0.0505s/iter; left time: 523.0895s\n",
      "\titers: 600, epoch: 9 | loss: 0.0433000\n",
      "\tspeed: 0.0505s/iter; left time: 517.9222s\n",
      "\titers: 700, epoch: 9 | loss: 0.0465603\n",
      "\tspeed: 0.0507s/iter; left time: 514.3503s\n",
      "\titers: 800, epoch: 9 | loss: 0.0388446\n",
      "\tspeed: 0.0506s/iter; left time: 508.3377s\n",
      "\titers: 900, epoch: 9 | loss: 0.0462066\n",
      "\tspeed: 0.0505s/iter; left time: 502.5629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0430836 Vali Loss: 0.0598840 Test Loss: 0.0688738\n",
      "Validation loss decreased (0.060688 --> 0.059884).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0426384\n",
      "\tspeed: 0.1363s/iter; left time: 1342.1219s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413563\n",
      "\tspeed: 0.0506s/iter; left time: 493.4274s\n",
      "\titers: 300, epoch: 10 | loss: 0.0478475\n",
      "\tspeed: 0.0505s/iter; left time: 487.2107s\n",
      "\titers: 400, epoch: 10 | loss: 0.0416776\n",
      "\tspeed: 0.0505s/iter; left time: 482.3533s\n",
      "\titers: 500, epoch: 10 | loss: 0.0418989\n",
      "\tspeed: 0.0504s/iter; left time: 476.4216s\n",
      "\titers: 600, epoch: 10 | loss: 0.0412408\n",
      "\tspeed: 0.0505s/iter; left time: 471.9978s\n",
      "\titers: 700, epoch: 10 | loss: 0.0433862\n",
      "\tspeed: 0.0506s/iter; left time: 467.3519s\n",
      "\titers: 800, epoch: 10 | loss: 0.0416713\n",
      "\tspeed: 0.0507s/iter; left time: 463.8700s\n",
      "\titers: 900, epoch: 10 | loss: 0.0395608\n",
      "\tspeed: 0.0505s/iter; left time: 457.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0421396 Vali Loss: 0.0599981 Test Loss: 0.0689363\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0351817\n",
      "\tspeed: 0.1292s/iter; left time: 1155.5683s\n",
      "\titers: 200, epoch: 11 | loss: 0.0439531\n",
      "\tspeed: 0.0508s/iter; left time: 449.0569s\n",
      "\titers: 300, epoch: 11 | loss: 0.0433584\n",
      "\tspeed: 0.0506s/iter; left time: 442.6196s\n",
      "\titers: 400, epoch: 11 | loss: 0.0428363\n",
      "\tspeed: 0.0507s/iter; left time: 437.8905s\n",
      "\titers: 500, epoch: 11 | loss: 0.0419130\n",
      "\tspeed: 0.0506s/iter; left time: 432.4478s\n",
      "\titers: 600, epoch: 11 | loss: 0.0433501\n",
      "\tspeed: 0.0509s/iter; left time: 429.6161s\n",
      "\titers: 700, epoch: 11 | loss: 0.0406113\n",
      "\tspeed: 0.0512s/iter; left time: 426.9398s\n",
      "\titers: 800, epoch: 11 | loss: 0.0406577\n",
      "\tspeed: 0.0508s/iter; left time: 418.2930s\n",
      "\titers: 900, epoch: 11 | loss: 0.0406176\n",
      "\tspeed: 0.0508s/iter; left time: 413.8346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.17s\n",
      "Steps: 904 | Train Loss: 0.0409204 Vali Loss: 0.0599961 Test Loss: 0.0661092\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0367112\n",
      "\tspeed: 0.1290s/iter; left time: 1036.5297s\n",
      "\titers: 200, epoch: 12 | loss: 0.0359865\n",
      "\tspeed: 0.0506s/iter; left time: 401.9718s\n",
      "\titers: 300, epoch: 12 | loss: 0.0399645\n",
      "\tspeed: 0.0506s/iter; left time: 396.3511s\n",
      "\titers: 400, epoch: 12 | loss: 0.0429483\n",
      "\tspeed: 0.0506s/iter; left time: 391.3353s\n",
      "\titers: 500, epoch: 12 | loss: 0.0355176\n",
      "\tspeed: 0.0505s/iter; left time: 386.0417s\n",
      "\titers: 600, epoch: 12 | loss: 0.0401016\n",
      "\tspeed: 0.0507s/iter; left time: 381.9342s\n",
      "\titers: 700, epoch: 12 | loss: 0.0419159\n",
      "\tspeed: 0.0507s/iter; left time: 376.7510s\n",
      "\titers: 800, epoch: 12 | loss: 0.0381808\n",
      "\tspeed: 0.0504s/iter; left time: 370.1410s\n",
      "\titers: 900, epoch: 12 | loss: 0.0390678\n",
      "\tspeed: 0.0507s/iter; left time: 366.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0400091 Vali Loss: 0.0599143 Test Loss: 0.0669005\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0380916\n",
      "\tspeed: 0.1296s/iter; left time: 924.1247s\n",
      "\titers: 200, epoch: 13 | loss: 0.0413469\n",
      "\tspeed: 0.0507s/iter; left time: 356.5461s\n",
      "\titers: 300, epoch: 13 | loss: 0.0396761\n",
      "\tspeed: 0.0509s/iter; left time: 352.6984s\n",
      "\titers: 400, epoch: 13 | loss: 0.0427574\n",
      "\tspeed: 0.0508s/iter; left time: 346.8727s\n",
      "\titers: 500, epoch: 13 | loss: 0.0355891\n",
      "\tspeed: 0.0507s/iter; left time: 341.4022s\n",
      "\titers: 600, epoch: 13 | loss: 0.0384784\n",
      "\tspeed: 0.0510s/iter; left time: 338.0665s\n",
      "\titers: 700, epoch: 13 | loss: 0.0411485\n",
      "\tspeed: 0.0508s/iter; left time: 331.5640s\n",
      "\titers: 800, epoch: 13 | loss: 0.0397760\n",
      "\tspeed: 0.0505s/iter; left time: 324.6650s\n",
      "\titers: 900, epoch: 13 | loss: 0.0412626\n",
      "\tspeed: 0.0507s/iter; left time: 321.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.19s\n",
      "Steps: 904 | Train Loss: 0.0390204 Vali Loss: 0.0605479 Test Loss: 0.0659600\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0361109\n",
      "\tspeed: 0.1291s/iter; left time: 804.2356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0380425\n",
      "\tspeed: 0.0509s/iter; left time: 311.7399s\n",
      "\titers: 300, epoch: 14 | loss: 0.0370116\n",
      "\tspeed: 0.0505s/iter; left time: 304.6845s\n",
      "\titers: 400, epoch: 14 | loss: 0.0419875\n",
      "\tspeed: 0.0503s/iter; left time: 298.4538s\n",
      "\titers: 500, epoch: 14 | loss: 0.0434591\n",
      "\tspeed: 0.0507s/iter; left time: 295.2719s\n",
      "\titers: 600, epoch: 14 | loss: 0.0394724\n",
      "\tspeed: 0.0506s/iter; left time: 289.6708s\n",
      "\titers: 700, epoch: 14 | loss: 0.0384241\n",
      "\tspeed: 0.0507s/iter; left time: 285.6600s\n",
      "\titers: 800, epoch: 14 | loss: 0.0401119\n",
      "\tspeed: 0.0506s/iter; left time: 279.9582s\n",
      "\titers: 900, epoch: 14 | loss: 0.0374314\n",
      "\tspeed: 0.0505s/iter; left time: 274.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0382940 Vali Loss: 0.0598113 Test Loss: 0.0670536\n",
      "Validation loss decreased (0.059884 --> 0.059811).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0340718\n",
      "\tspeed: 0.1359s/iter; left time: 723.5363s\n",
      "\titers: 200, epoch: 15 | loss: 0.0379687\n",
      "\tspeed: 0.0506s/iter; left time: 264.5856s\n",
      "\titers: 300, epoch: 15 | loss: 0.0400622\n",
      "\tspeed: 0.0505s/iter; left time: 258.9367s\n",
      "\titers: 400, epoch: 15 | loss: 0.0400198\n",
      "\tspeed: 0.0505s/iter; left time: 253.9997s\n",
      "\titers: 500, epoch: 15 | loss: 0.0360466\n",
      "\tspeed: 0.0504s/iter; left time: 248.4101s\n",
      "\titers: 600, epoch: 15 | loss: 0.0416714\n",
      "\tspeed: 0.0505s/iter; left time: 243.8295s\n",
      "\titers: 700, epoch: 15 | loss: 0.0397632\n",
      "\tspeed: 0.0508s/iter; left time: 239.8614s\n",
      "\titers: 800, epoch: 15 | loss: 0.0344180\n",
      "\tspeed: 0.0505s/iter; left time: 233.6124s\n",
      "\titers: 900, epoch: 15 | loss: 0.0398584\n",
      "\tspeed: 0.0506s/iter; left time: 228.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0375514 Vali Loss: 0.0600660 Test Loss: 0.0678906\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0365943\n",
      "\tspeed: 0.1289s/iter; left time: 569.9341s\n",
      "\titers: 200, epoch: 16 | loss: 0.0336623\n",
      "\tspeed: 0.0506s/iter; left time: 218.7182s\n",
      "\titers: 300, epoch: 16 | loss: 0.0358770\n",
      "\tspeed: 0.0505s/iter; left time: 213.2516s\n",
      "\titers: 400, epoch: 16 | loss: 0.0338554\n",
      "\tspeed: 0.0506s/iter; left time: 208.7124s\n",
      "\titers: 500, epoch: 16 | loss: 0.0367848\n",
      "\tspeed: 0.0508s/iter; left time: 204.1003s\n",
      "\titers: 600, epoch: 16 | loss: 0.0381058\n",
      "\tspeed: 0.0505s/iter; left time: 198.1753s\n",
      "\titers: 700, epoch: 16 | loss: 0.0398681\n",
      "\tspeed: 0.0506s/iter; left time: 193.4469s\n",
      "\titers: 800, epoch: 16 | loss: 0.0337113\n",
      "\tspeed: 0.0505s/iter; left time: 187.9388s\n",
      "\titers: 900, epoch: 16 | loss: 0.0369790\n",
      "\tspeed: 0.0506s/iter; left time: 183.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0367738 Vali Loss: 0.0603918 Test Loss: 0.0680215\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0363935\n",
      "\tspeed: 0.1294s/iter; left time: 455.1954s\n",
      "\titers: 200, epoch: 17 | loss: 0.0340806\n",
      "\tspeed: 0.0512s/iter; left time: 174.9911s\n",
      "\titers: 300, epoch: 17 | loss: 0.0387065\n",
      "\tspeed: 0.0510s/iter; left time: 169.1355s\n",
      "\titers: 400, epoch: 17 | loss: 0.0393172\n",
      "\tspeed: 0.0507s/iter; left time: 162.9790s\n",
      "\titers: 500, epoch: 17 | loss: 0.0368487\n",
      "\tspeed: 0.0506s/iter; left time: 157.6167s\n",
      "\titers: 600, epoch: 17 | loss: 0.0341469\n",
      "\tspeed: 0.0507s/iter; left time: 152.9826s\n",
      "\titers: 700, epoch: 17 | loss: 0.0382479\n",
      "\tspeed: 0.0506s/iter; left time: 147.7052s\n",
      "\titers: 800, epoch: 17 | loss: 0.0326593\n",
      "\tspeed: 0.0505s/iter; left time: 142.3546s\n",
      "\titers: 900, epoch: 17 | loss: 0.0368100\n",
      "\tspeed: 0.0507s/iter; left time: 137.6721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:46.14s\n",
      "Steps: 904 | Train Loss: 0.0360329 Vali Loss: 0.0598917 Test Loss: 0.0680495\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0326915\n",
      "\tspeed: 0.1284s/iter; left time: 335.6016s\n",
      "\titers: 200, epoch: 18 | loss: 0.0370163\n",
      "\tspeed: 0.0506s/iter; left time: 127.1107s\n",
      "\titers: 300, epoch: 18 | loss: 0.0361318\n",
      "\tspeed: 0.0506s/iter; left time: 122.0033s\n",
      "\titers: 400, epoch: 18 | loss: 0.0316258\n",
      "\tspeed: 0.0507s/iter; left time: 117.1723s\n",
      "\titers: 500, epoch: 18 | loss: 0.0333865\n",
      "\tspeed: 0.0506s/iter; left time: 111.9600s\n",
      "\titers: 600, epoch: 18 | loss: 0.0448753\n",
      "\tspeed: 0.0506s/iter; left time: 106.8574s\n",
      "\titers: 700, epoch: 18 | loss: 0.0332564\n",
      "\tspeed: 0.0507s/iter; left time: 101.9679s\n",
      "\titers: 800, epoch: 18 | loss: 0.0385765\n",
      "\tspeed: 0.0509s/iter; left time: 97.4216s\n",
      "\titers: 900, epoch: 18 | loss: 0.0356378\n",
      "\tspeed: 0.0505s/iter; left time: 91.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.0352917 Vali Loss: 0.0593663 Test Loss: 0.0668980\n",
      "Validation loss decreased (0.059811 --> 0.059366).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0368129\n",
      "\tspeed: 0.1326s/iter; left time: 226.5482s\n",
      "\titers: 200, epoch: 19 | loss: 0.0341845\n",
      "\tspeed: 0.0506s/iter; left time: 81.3802s\n",
      "\titers: 300, epoch: 19 | loss: 0.0335134\n",
      "\tspeed: 0.0506s/iter; left time: 76.3178s\n",
      "\titers: 400, epoch: 19 | loss: 0.0321926\n",
      "\tspeed: 0.0506s/iter; left time: 71.2511s\n",
      "\titers: 500, epoch: 19 | loss: 0.0329678\n",
      "\tspeed: 0.0505s/iter; left time: 66.0641s\n",
      "\titers: 600, epoch: 19 | loss: 0.0371957\n",
      "\tspeed: 0.0506s/iter; left time: 61.1455s\n",
      "\titers: 700, epoch: 19 | loss: 0.0382693\n",
      "\tspeed: 0.0506s/iter; left time: 56.0995s\n",
      "\titers: 800, epoch: 19 | loss: 0.0300906\n",
      "\tspeed: 0.0506s/iter; left time: 51.0361s\n",
      "\titers: 900, epoch: 19 | loss: 0.0350517\n",
      "\tspeed: 0.0507s/iter; left time: 46.0629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0346492 Vali Loss: 0.0594195 Test Loss: 0.0670713\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0314047\n",
      "\tspeed: 0.1289s/iter; left time: 103.7591s\n",
      "\titers: 200, epoch: 20 | loss: 0.0321222\n",
      "\tspeed: 0.0506s/iter; left time: 35.6734s\n",
      "\titers: 300, epoch: 20 | loss: 0.0334153\n",
      "\tspeed: 0.0506s/iter; left time: 30.6106s\n",
      "\titers: 400, epoch: 20 | loss: 0.0315652\n",
      "\tspeed: 0.0506s/iter; left time: 25.5415s\n",
      "\titers: 500, epoch: 20 | loss: 0.0363332\n",
      "\tspeed: 0.0506s/iter; left time: 20.4808s\n",
      "\titers: 600, epoch: 20 | loss: 0.0389709\n",
      "\tspeed: 0.0507s/iter; left time: 15.4541s\n",
      "\titers: 700, epoch: 20 | loss: 0.0319787\n",
      "\tspeed: 0.0506s/iter; left time: 10.3671s\n",
      "\titers: 800, epoch: 20 | loss: 0.0333809\n",
      "\tspeed: 0.0506s/iter; left time: 5.3167s\n",
      "\titers: 900, epoch: 20 | loss: 0.0342056\n",
      "\tspeed: 0.0506s/iter; left time: 0.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0340832 Vali Loss: 0.0603757 Test Loss: 0.0694185\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013476599007844925, rmse:0.11608875542879105, mae:0.06680411100387573, rse:0.44796544313430786\n",
      "Intermediate time for FR and pred_len 24: 00h:31m:38.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1901909\n",
      "\tspeed: 0.0835s/iter; left time: 1498.7707s\n",
      "\titers: 200, epoch: 1 | loss: 0.1680098\n",
      "\tspeed: 0.0565s/iter; left time: 1007.2515s\n",
      "\titers: 300, epoch: 1 | loss: 0.1631690\n",
      "\tspeed: 0.0561s/iter; left time: 994.8162s\n",
      "\titers: 400, epoch: 1 | loss: 0.1624803\n",
      "\tspeed: 0.0560s/iter; left time: 987.8026s\n",
      "\titers: 500, epoch: 1 | loss: 0.1601502\n",
      "\tspeed: 0.0561s/iter; left time: 983.6387s\n",
      "\titers: 600, epoch: 1 | loss: 0.1566006\n",
      "\tspeed: 0.0562s/iter; left time: 979.5000s\n",
      "\titers: 700, epoch: 1 | loss: 0.1517216\n",
      "\tspeed: 0.0562s/iter; left time: 974.4400s\n",
      "\titers: 800, epoch: 1 | loss: 0.1477126\n",
      "\tspeed: 0.0563s/iter; left time: 971.0177s\n",
      "\titers: 900, epoch: 1 | loss: 0.1487417\n",
      "\tspeed: 0.0562s/iter; left time: 963.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.45s\n",
      "Steps: 902 | Train Loss: 0.1630581 Vali Loss: 0.1559864 Test Loss: 0.1814378\n",
      "Validation loss decreased (inf --> 0.155986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1299998\n",
      "\tspeed: 0.1803s/iter; left time: 3072.5170s\n",
      "\titers: 200, epoch: 2 | loss: 0.1247027\n",
      "\tspeed: 0.0562s/iter; left time: 952.3190s\n",
      "\titers: 300, epoch: 2 | loss: 0.1130491\n",
      "\tspeed: 0.0564s/iter; left time: 949.7110s\n",
      "\titers: 400, epoch: 2 | loss: 0.1078960\n",
      "\tspeed: 0.0559s/iter; left time: 936.0571s\n",
      "\titers: 500, epoch: 2 | loss: 0.1063370\n",
      "\tspeed: 0.0562s/iter; left time: 934.4962s\n",
      "\titers: 600, epoch: 2 | loss: 0.1096868\n",
      "\tspeed: 0.0563s/iter; left time: 930.3330s\n",
      "\titers: 700, epoch: 2 | loss: 0.1074123\n",
      "\tspeed: 0.0562s/iter; left time: 923.4667s\n",
      "\titers: 800, epoch: 2 | loss: 0.0984203\n",
      "\tspeed: 0.0562s/iter; left time: 917.4907s\n",
      "\titers: 900, epoch: 2 | loss: 0.0975309\n",
      "\tspeed: 0.0560s/iter; left time: 909.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.91s\n",
      "Steps: 902 | Train Loss: 0.1122323 Vali Loss: 0.1155707 Test Loss: 0.1344364\n",
      "Validation loss decreased (0.155986 --> 0.115571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0907094\n",
      "\tspeed: 0.1541s/iter; left time: 2486.3745s\n",
      "\titers: 200, epoch: 3 | loss: 0.0871888\n",
      "\tspeed: 0.0564s/iter; left time: 904.1750s\n",
      "\titers: 300, epoch: 3 | loss: 0.0844483\n",
      "\tspeed: 0.0564s/iter; left time: 898.4510s\n",
      "\titers: 400, epoch: 3 | loss: 0.0790095\n",
      "\tspeed: 0.0564s/iter; left time: 893.3031s\n",
      "\titers: 500, epoch: 3 | loss: 0.0860384\n",
      "\tspeed: 0.0562s/iter; left time: 884.7998s\n",
      "\titers: 600, epoch: 3 | loss: 0.0846145\n",
      "\tspeed: 0.0566s/iter; left time: 884.6798s\n",
      "\titers: 700, epoch: 3 | loss: 0.0769225\n",
      "\tspeed: 0.0563s/iter; left time: 874.4659s\n",
      "\titers: 800, epoch: 3 | loss: 0.0771179\n",
      "\tspeed: 0.0567s/iter; left time: 874.7014s\n",
      "\titers: 900, epoch: 3 | loss: 0.0827530\n",
      "\tspeed: 0.0564s/iter; left time: 865.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.14s\n",
      "Steps: 902 | Train Loss: 0.0837687 Vali Loss: 0.0973055 Test Loss: 0.1127238\n",
      "Validation loss decreased (0.115571 --> 0.097306).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0792326\n",
      "\tspeed: 0.1469s/iter; left time: 2237.7505s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784529\n",
      "\tspeed: 0.0563s/iter; left time: 852.7832s\n",
      "\titers: 300, epoch: 4 | loss: 0.0750719\n",
      "\tspeed: 0.0565s/iter; left time: 850.1316s\n",
      "\titers: 400, epoch: 4 | loss: 0.0680206\n",
      "\tspeed: 0.0562s/iter; left time: 838.7534s\n",
      "\titers: 500, epoch: 4 | loss: 0.0670653\n",
      "\tspeed: 0.0564s/iter; left time: 836.5194s\n",
      "\titers: 600, epoch: 4 | loss: 0.0627730\n",
      "\tspeed: 0.0563s/iter; left time: 829.7335s\n",
      "\titers: 700, epoch: 4 | loss: 0.0694864\n",
      "\tspeed: 0.0561s/iter; left time: 821.6866s\n",
      "\titers: 800, epoch: 4 | loss: 0.0683251\n",
      "\tspeed: 0.0562s/iter; left time: 817.1004s\n",
      "\titers: 900, epoch: 4 | loss: 0.0744468\n",
      "\tspeed: 0.0560s/iter; left time: 808.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.00s\n",
      "Steps: 902 | Train Loss: 0.0697377 Vali Loss: 0.0847241 Test Loss: 0.0955022\n",
      "Validation loss decreased (0.097306 --> 0.084724).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635712\n",
      "\tspeed: 0.1627s/iter; left time: 2332.5755s\n",
      "\titers: 200, epoch: 5 | loss: 0.0632475\n",
      "\tspeed: 0.0561s/iter; left time: 798.3412s\n",
      "\titers: 300, epoch: 5 | loss: 0.0600521\n",
      "\tspeed: 0.0561s/iter; left time: 792.4484s\n",
      "\titers: 400, epoch: 5 | loss: 0.0601733\n",
      "\tspeed: 0.0561s/iter; left time: 787.5974s\n",
      "\titers: 500, epoch: 5 | loss: 0.0653609\n",
      "\tspeed: 0.0564s/iter; left time: 785.8665s\n",
      "\titers: 600, epoch: 5 | loss: 0.0546124\n",
      "\tspeed: 0.0565s/iter; left time: 781.8829s\n",
      "\titers: 700, epoch: 5 | loss: 0.0603751\n",
      "\tspeed: 0.0563s/iter; left time: 772.7371s\n",
      "\titers: 800, epoch: 5 | loss: 0.0573503\n",
      "\tspeed: 0.0562s/iter; left time: 766.0778s\n",
      "\titers: 900, epoch: 5 | loss: 0.0595636\n",
      "\tspeed: 0.0562s/iter; left time: 760.1172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.94s\n",
      "Steps: 902 | Train Loss: 0.0615506 Vali Loss: 0.0823914 Test Loss: 0.0944036\n",
      "Validation loss decreased (0.084724 --> 0.082391).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594747\n",
      "\tspeed: 0.1547s/iter; left time: 2078.1763s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599904\n",
      "\tspeed: 0.0563s/iter; left time: 750.2621s\n",
      "\titers: 300, epoch: 6 | loss: 0.0571336\n",
      "\tspeed: 0.0562s/iter; left time: 743.7092s\n",
      "\titers: 400, epoch: 6 | loss: 0.0572408\n",
      "\tspeed: 0.0565s/iter; left time: 742.5191s\n",
      "\titers: 500, epoch: 6 | loss: 0.0567322\n",
      "\tspeed: 0.0564s/iter; left time: 735.1324s\n",
      "\titers: 600, epoch: 6 | loss: 0.0579100\n",
      "\tspeed: 0.0562s/iter; left time: 726.8313s\n",
      "\titers: 700, epoch: 6 | loss: 0.0551857\n",
      "\tspeed: 0.0563s/iter; left time: 722.0361s\n",
      "\titers: 800, epoch: 6 | loss: 0.0525618\n",
      "\tspeed: 0.0563s/iter; left time: 716.5130s\n",
      "\titers: 900, epoch: 6 | loss: 0.0526607\n",
      "\tspeed: 0.0565s/iter; left time: 713.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:51.05s\n",
      "Steps: 902 | Train Loss: 0.0572583 Vali Loss: 0.0805459 Test Loss: 0.0904619\n",
      "Validation loss decreased (0.082391 --> 0.080546).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0568981\n",
      "\tspeed: 0.1473s/iter; left time: 1845.6407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571425\n",
      "\tspeed: 0.0559s/iter; left time: 695.2263s\n",
      "\titers: 300, epoch: 7 | loss: 0.0563408\n",
      "\tspeed: 0.0560s/iter; left time: 690.4935s\n",
      "\titers: 400, epoch: 7 | loss: 0.0527574\n",
      "\tspeed: 0.0564s/iter; left time: 689.1998s\n",
      "\titers: 500, epoch: 7 | loss: 0.0529065\n",
      "\tspeed: 0.0561s/iter; left time: 680.6020s\n",
      "\titers: 600, epoch: 7 | loss: 0.0570634\n",
      "\tspeed: 0.0560s/iter; left time: 674.1939s\n",
      "\titers: 700, epoch: 7 | loss: 0.0538532\n",
      "\tspeed: 0.0561s/iter; left time: 668.6822s\n",
      "\titers: 800, epoch: 7 | loss: 0.0517594\n",
      "\tspeed: 0.0559s/iter; left time: 661.7975s\n",
      "\titers: 900, epoch: 7 | loss: 0.0519833\n",
      "\tspeed: 0.0564s/iter; left time: 661.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.86s\n",
      "Steps: 902 | Train Loss: 0.0539211 Vali Loss: 0.0832832 Test Loss: 0.0925607\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0518047\n",
      "\tspeed: 0.1359s/iter; left time: 1579.5987s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489885\n",
      "\tspeed: 0.0491s/iter; left time: 565.4906s\n",
      "\titers: 300, epoch: 8 | loss: 0.0503035\n",
      "\tspeed: 0.0491s/iter; left time: 560.6996s\n",
      "\titers: 400, epoch: 8 | loss: 0.0451516\n",
      "\tspeed: 0.0510s/iter; left time: 577.8584s\n",
      "\titers: 500, epoch: 8 | loss: 0.0535778\n",
      "\tspeed: 0.0491s/iter; left time: 550.9892s\n",
      "\titers: 600, epoch: 8 | loss: 0.0485307\n",
      "\tspeed: 0.0490s/iter; left time: 545.7341s\n",
      "\titers: 700, epoch: 8 | loss: 0.0528692\n",
      "\tspeed: 0.0490s/iter; left time: 540.7359s\n",
      "\titers: 800, epoch: 8 | loss: 0.0541858\n",
      "\tspeed: 0.0491s/iter; left time: 536.4840s\n",
      "\titers: 900, epoch: 8 | loss: 0.0515157\n",
      "\tspeed: 0.0491s/iter; left time: 531.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.68s\n",
      "Steps: 902 | Train Loss: 0.0513391 Vali Loss: 0.0841195 Test Loss: 0.0945583\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546974\n",
      "\tspeed: 0.1434s/iter; left time: 1538.4292s\n",
      "\titers: 200, epoch: 9 | loss: 0.0498191\n",
      "\tspeed: 0.0566s/iter; left time: 601.7919s\n",
      "\titers: 300, epoch: 9 | loss: 0.0531545\n",
      "\tspeed: 0.0566s/iter; left time: 595.6207s\n",
      "\titers: 400, epoch: 9 | loss: 0.0454078\n",
      "\tspeed: 0.0564s/iter; left time: 587.7304s\n",
      "\titers: 500, epoch: 9 | loss: 0.0457338\n",
      "\tspeed: 0.0563s/iter; left time: 581.0686s\n",
      "\titers: 600, epoch: 9 | loss: 0.0455700\n",
      "\tspeed: 0.0560s/iter; left time: 572.7611s\n",
      "\titers: 700, epoch: 9 | loss: 0.0485520\n",
      "\tspeed: 0.0562s/iter; left time: 568.7762s\n",
      "\titers: 800, epoch: 9 | loss: 0.0482960\n",
      "\tspeed: 0.0560s/iter; left time: 561.7924s\n",
      "\titers: 900, epoch: 9 | loss: 0.0512725\n",
      "\tspeed: 0.0561s/iter; left time: 556.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.98s\n",
      "Steps: 902 | Train Loss: 0.0491131 Vali Loss: 0.0844347 Test Loss: 0.0987738\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0483889\n",
      "\tspeed: 0.1435s/iter; left time: 1409.3078s\n",
      "\titers: 200, epoch: 10 | loss: 0.0470985\n",
      "\tspeed: 0.0566s/iter; left time: 550.1528s\n",
      "\titers: 300, epoch: 10 | loss: 0.0481889\n",
      "\tspeed: 0.0563s/iter; left time: 541.5408s\n",
      "\titers: 400, epoch: 10 | loss: 0.0454675\n",
      "\tspeed: 0.0541s/iter; left time: 515.3991s\n",
      "\titers: 500, epoch: 10 | loss: 0.0495626\n",
      "\tspeed: 0.0535s/iter; left time: 504.5339s\n",
      "\titers: 600, epoch: 10 | loss: 0.0477467\n",
      "\tspeed: 0.0561s/iter; left time: 523.2268s\n",
      "\titers: 700, epoch: 10 | loss: 0.0474053\n",
      "\tspeed: 0.0560s/iter; left time: 516.3739s\n",
      "\titers: 800, epoch: 10 | loss: 0.0429104\n",
      "\tspeed: 0.0564s/iter; left time: 514.1458s\n",
      "\titers: 900, epoch: 10 | loss: 0.0470683\n",
      "\tspeed: 0.0560s/iter; left time: 505.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.48s\n",
      "Steps: 902 | Train Loss: 0.0471488 Vali Loss: 0.0842529 Test Loss: 0.0966227\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0470288\n",
      "\tspeed: 0.1432s/iter; left time: 1277.8946s\n",
      "\titers: 200, epoch: 11 | loss: 0.0455790\n",
      "\tspeed: 0.0562s/iter; left time: 495.6256s\n",
      "\titers: 300, epoch: 11 | loss: 0.0409460\n",
      "\tspeed: 0.0561s/iter; left time: 489.5924s\n",
      "\titers: 400, epoch: 11 | loss: 0.0455816\n",
      "\tspeed: 0.0560s/iter; left time: 482.7117s\n",
      "\titers: 500, epoch: 11 | loss: 0.0495339\n",
      "\tspeed: 0.0562s/iter; left time: 479.1836s\n",
      "\titers: 600, epoch: 11 | loss: 0.0410908\n",
      "\tspeed: 0.0560s/iter; left time: 471.2257s\n",
      "\titers: 700, epoch: 11 | loss: 0.0439081\n",
      "\tspeed: 0.0560s/iter; left time: 465.5969s\n",
      "\titers: 800, epoch: 11 | loss: 0.0481357\n",
      "\tspeed: 0.0559s/iter; left time: 459.4324s\n",
      "\titers: 900, epoch: 11 | loss: 0.0430440\n",
      "\tspeed: 0.0562s/iter; left time: 456.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.80s\n",
      "Steps: 902 | Train Loss: 0.0453884 Vali Loss: 0.0853837 Test Loss: 0.1002915\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022180521860718727, rmse:0.14893126487731934, mae:0.09044930338859558, rse:0.5761057138442993\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1790808\n",
      "\tspeed: 0.0511s/iter; left time: 917.2553s\n",
      "\titers: 200, epoch: 1 | loss: 0.1611746\n",
      "\tspeed: 0.0512s/iter; left time: 914.1593s\n",
      "\titers: 300, epoch: 1 | loss: 0.1588050\n",
      "\tspeed: 0.0564s/iter; left time: 1000.3984s\n",
      "\titers: 400, epoch: 1 | loss: 0.1532305\n",
      "\tspeed: 0.0540s/iter; left time: 952.8553s\n",
      "\titers: 500, epoch: 1 | loss: 0.1552794\n",
      "\tspeed: 0.0491s/iter; left time: 860.7307s\n",
      "\titers: 600, epoch: 1 | loss: 0.1484109\n",
      "\tspeed: 0.0491s/iter; left time: 855.7959s\n",
      "\titers: 700, epoch: 1 | loss: 0.1423070\n",
      "\tspeed: 0.0491s/iter; left time: 850.7185s\n",
      "\titers: 800, epoch: 1 | loss: 0.1413595\n",
      "\tspeed: 0.0490s/iter; left time: 845.5355s\n",
      "\titers: 900, epoch: 1 | loss: 0.1398742\n",
      "\tspeed: 0.0491s/iter; left time: 841.1176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.1619631 Vali Loss: 0.1557397 Test Loss: 0.1809092\n",
      "Validation loss decreased (inf --> 0.155740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1372153\n",
      "\tspeed: 0.1532s/iter; left time: 2610.7406s\n",
      "\titers: 200, epoch: 2 | loss: 0.1239819\n",
      "\tspeed: 0.0562s/iter; left time: 951.9283s\n",
      "\titers: 300, epoch: 2 | loss: 0.1235603\n",
      "\tspeed: 0.0560s/iter; left time: 942.7515s\n",
      "\titers: 400, epoch: 2 | loss: 0.1036138\n",
      "\tspeed: 0.0562s/iter; left time: 940.9169s\n",
      "\titers: 500, epoch: 2 | loss: 0.1003544\n",
      "\tspeed: 0.0561s/iter; left time: 932.7666s\n",
      "\titers: 600, epoch: 2 | loss: 0.1064072\n",
      "\tspeed: 0.0565s/iter; left time: 935.1106s\n",
      "\titers: 700, epoch: 2 | loss: 0.0990647\n",
      "\tspeed: 0.0565s/iter; left time: 928.5669s\n",
      "\titers: 800, epoch: 2 | loss: 0.0977695\n",
      "\tspeed: 0.0565s/iter; left time: 923.2082s\n",
      "\titers: 900, epoch: 2 | loss: 0.0885328\n",
      "\tspeed: 0.0565s/iter; left time: 917.2121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:51.03s\n",
      "Steps: 902 | Train Loss: 0.1091462 Vali Loss: 0.1041449 Test Loss: 0.1188011\n",
      "Validation loss decreased (0.155740 --> 0.104145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0927721\n",
      "\tspeed: 0.1544s/iter; left time: 2492.0916s\n",
      "\titers: 200, epoch: 3 | loss: 0.0987148\n",
      "\tspeed: 0.0563s/iter; left time: 903.1204s\n",
      "\titers: 300, epoch: 3 | loss: 0.0812884\n",
      "\tspeed: 0.0562s/iter; left time: 896.1746s\n",
      "\titers: 400, epoch: 3 | loss: 0.0846818\n",
      "\tspeed: 0.0565s/iter; left time: 894.3680s\n",
      "\titers: 500, epoch: 3 | loss: 0.0792303\n",
      "\tspeed: 0.0564s/iter; left time: 887.6006s\n",
      "\titers: 600, epoch: 3 | loss: 0.0746298\n",
      "\tspeed: 0.0566s/iter; left time: 885.1243s\n",
      "\titers: 700, epoch: 3 | loss: 0.0756328\n",
      "\tspeed: 0.0562s/iter; left time: 873.7425s\n",
      "\titers: 800, epoch: 3 | loss: 0.0748201\n",
      "\tspeed: 0.0563s/iter; left time: 868.7989s\n",
      "\titers: 900, epoch: 3 | loss: 0.0693392\n",
      "\tspeed: 0.0563s/iter; left time: 863.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.11s\n",
      "Steps: 902 | Train Loss: 0.0812706 Vali Loss: 0.0871454 Test Loss: 0.0999410\n",
      "Validation loss decreased (0.104145 --> 0.087145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0679448\n",
      "\tspeed: 0.1506s/iter; left time: 2294.1636s\n",
      "\titers: 200, epoch: 4 | loss: 0.0700184\n",
      "\tspeed: 0.0562s/iter; left time: 851.0931s\n",
      "\titers: 300, epoch: 4 | loss: 0.0774645\n",
      "\tspeed: 0.0561s/iter; left time: 843.5673s\n",
      "\titers: 400, epoch: 4 | loss: 0.0599886\n",
      "\tspeed: 0.0563s/iter; left time: 840.1416s\n",
      "\titers: 500, epoch: 4 | loss: 0.0677924\n",
      "\tspeed: 0.0560s/iter; left time: 830.1548s\n",
      "\titers: 600, epoch: 4 | loss: 0.0701996\n",
      "\tspeed: 0.0563s/iter; left time: 829.8286s\n",
      "\titers: 700, epoch: 4 | loss: 0.0656099\n",
      "\tspeed: 0.0564s/iter; left time: 826.0960s\n",
      "\titers: 800, epoch: 4 | loss: 0.0603179\n",
      "\tspeed: 0.0563s/iter; left time: 818.7789s\n",
      "\titers: 900, epoch: 4 | loss: 0.0632463\n",
      "\tspeed: 0.0563s/iter; left time: 812.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.00s\n",
      "Steps: 902 | Train Loss: 0.0675261 Vali Loss: 0.0836461 Test Loss: 0.0922461\n",
      "Validation loss decreased (0.087145 --> 0.083646).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0632569\n",
      "\tspeed: 0.1745s/iter; left time: 2501.2539s\n",
      "\titers: 200, epoch: 5 | loss: 0.0651309\n",
      "\tspeed: 0.0562s/iter; left time: 800.2998s\n",
      "\titers: 300, epoch: 5 | loss: 0.0667233\n",
      "\tspeed: 0.0563s/iter; left time: 795.3244s\n",
      "\titers: 400, epoch: 5 | loss: 0.0658062\n",
      "\tspeed: 0.0564s/iter; left time: 790.8666s\n",
      "\titers: 500, epoch: 5 | loss: 0.0605776\n",
      "\tspeed: 0.0565s/iter; left time: 787.7532s\n",
      "\titers: 600, epoch: 5 | loss: 0.0645031\n",
      "\tspeed: 0.0565s/iter; left time: 781.9725s\n",
      "\titers: 700, epoch: 5 | loss: 0.0628825\n",
      "\tspeed: 0.0564s/iter; left time: 774.4745s\n",
      "\titers: 800, epoch: 5 | loss: 0.0626413\n",
      "\tspeed: 0.0566s/iter; left time: 771.4026s\n",
      "\titers: 900, epoch: 5 | loss: 0.0676315\n",
      "\tspeed: 0.0562s/iter; left time: 761.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.13s\n",
      "Steps: 902 | Train Loss: 0.0613530 Vali Loss: 0.0837199 Test Loss: 0.0930600\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0606583\n",
      "\tspeed: 0.1435s/iter; left time: 1927.5444s\n",
      "\titers: 200, epoch: 6 | loss: 0.0564244\n",
      "\tspeed: 0.0562s/iter; left time: 748.9575s\n",
      "\titers: 300, epoch: 6 | loss: 0.0562437\n",
      "\tspeed: 0.0561s/iter; left time: 742.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0581502\n",
      "\tspeed: 0.0561s/iter; left time: 736.4674s\n",
      "\titers: 500, epoch: 6 | loss: 0.0555852\n",
      "\tspeed: 0.0562s/iter; left time: 732.3017s\n",
      "\titers: 600, epoch: 6 | loss: 0.0649780\n",
      "\tspeed: 0.0562s/iter; left time: 726.2474s\n",
      "\titers: 700, epoch: 6 | loss: 0.0578851\n",
      "\tspeed: 0.0563s/iter; left time: 722.6441s\n",
      "\titers: 800, epoch: 6 | loss: 0.0525493\n",
      "\tspeed: 0.0563s/iter; left time: 716.4398s\n",
      "\titers: 900, epoch: 6 | loss: 0.0554779\n",
      "\tspeed: 0.0561s/iter; left time: 708.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.92s\n",
      "Steps: 902 | Train Loss: 0.0570500 Vali Loss: 0.0807239 Test Loss: 0.0912359\n",
      "Validation loss decreased (0.083646 --> 0.080724).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0613119\n",
      "\tspeed: 0.1557s/iter; left time: 1950.8772s\n",
      "\titers: 200, epoch: 7 | loss: 0.0549274\n",
      "\tspeed: 0.0566s/iter; left time: 702.8983s\n",
      "\titers: 300, epoch: 7 | loss: 0.0539570\n",
      "\tspeed: 0.0565s/iter; left time: 696.4145s\n",
      "\titers: 400, epoch: 7 | loss: 0.0546516\n",
      "\tspeed: 0.0565s/iter; left time: 690.8015s\n",
      "\titers: 500, epoch: 7 | loss: 0.0533799\n",
      "\tspeed: 0.0564s/iter; left time: 683.4857s\n",
      "\titers: 600, epoch: 7 | loss: 0.0515554\n",
      "\tspeed: 0.0562s/iter; left time: 676.6153s\n",
      "\titers: 700, epoch: 7 | loss: 0.0501184\n",
      "\tspeed: 0.0565s/iter; left time: 674.4665s\n",
      "\titers: 800, epoch: 7 | loss: 0.0507369\n",
      "\tspeed: 0.0564s/iter; left time: 666.7949s\n",
      "\titers: 900, epoch: 7 | loss: 0.0503579\n",
      "\tspeed: 0.0564s/iter; left time: 662.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.19s\n",
      "Steps: 902 | Train Loss: 0.0540808 Vali Loss: 0.0826313 Test Loss: 0.0926620\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0517372\n",
      "\tspeed: 0.1443s/iter; left time: 1678.1138s\n",
      "\titers: 200, epoch: 8 | loss: 0.0480847\n",
      "\tspeed: 0.0567s/iter; left time: 653.3751s\n",
      "\titers: 300, epoch: 8 | loss: 0.0493044\n",
      "\tspeed: 0.0564s/iter; left time: 644.2982s\n",
      "\titers: 400, epoch: 8 | loss: 0.0552070\n",
      "\tspeed: 0.0565s/iter; left time: 640.0078s\n",
      "\titers: 500, epoch: 8 | loss: 0.0483311\n",
      "\tspeed: 0.0567s/iter; left time: 636.5734s\n",
      "\titers: 600, epoch: 8 | loss: 0.0522019\n",
      "\tspeed: 0.0565s/iter; left time: 628.4873s\n",
      "\titers: 700, epoch: 8 | loss: 0.0507056\n",
      "\tspeed: 0.0565s/iter; left time: 623.0507s\n",
      "\titers: 800, epoch: 8 | loss: 0.0556268\n",
      "\tspeed: 0.0564s/iter; left time: 615.9873s\n",
      "\titers: 900, epoch: 8 | loss: 0.0489149\n",
      "\tspeed: 0.0565s/iter; left time: 611.4156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.22s\n",
      "Steps: 902 | Train Loss: 0.0514754 Vali Loss: 0.0823658 Test Loss: 0.0909126\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0473248\n",
      "\tspeed: 0.1448s/iter; left time: 1552.5281s\n",
      "\titers: 200, epoch: 9 | loss: 0.0479156\n",
      "\tspeed: 0.0565s/iter; left time: 600.1515s\n",
      "\titers: 300, epoch: 9 | loss: 0.0546769\n",
      "\tspeed: 0.0567s/iter; left time: 596.5061s\n",
      "\titers: 400, epoch: 9 | loss: 0.0474635\n",
      "\tspeed: 0.0566s/iter; left time: 589.8451s\n",
      "\titers: 500, epoch: 9 | loss: 0.0471695\n",
      "\tspeed: 0.0564s/iter; left time: 582.2722s\n",
      "\titers: 600, epoch: 9 | loss: 0.0525833\n",
      "\tspeed: 0.0564s/iter; left time: 577.1286s\n",
      "\titers: 700, epoch: 9 | loss: 0.0498088\n",
      "\tspeed: 0.0564s/iter; left time: 571.0228s\n",
      "\titers: 800, epoch: 9 | loss: 0.0495152\n",
      "\tspeed: 0.0565s/iter; left time: 566.1874s\n",
      "\titers: 900, epoch: 9 | loss: 0.0439345\n",
      "\tspeed: 0.0565s/iter; left time: 561.0080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:51.22s\n",
      "Steps: 902 | Train Loss: 0.0493434 Vali Loss: 0.0810345 Test Loss: 0.0923958\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0466512\n",
      "\tspeed: 0.1446s/iter; left time: 1420.7595s\n",
      "\titers: 200, epoch: 10 | loss: 0.0457321\n",
      "\tspeed: 0.0566s/iter; left time: 550.7107s\n",
      "\titers: 300, epoch: 10 | loss: 0.0489774\n",
      "\tspeed: 0.0565s/iter; left time: 544.1310s\n",
      "\titers: 400, epoch: 10 | loss: 0.0458514\n",
      "\tspeed: 0.0563s/iter; left time: 536.4748s\n",
      "\titers: 500, epoch: 10 | loss: 0.0449775\n",
      "\tspeed: 0.0564s/iter; left time: 531.0897s\n",
      "\titers: 600, epoch: 10 | loss: 0.0465148\n",
      "\tspeed: 0.0566s/iter; left time: 527.5992s\n",
      "\titers: 700, epoch: 10 | loss: 0.0514344\n",
      "\tspeed: 0.0562s/iter; left time: 518.0314s\n",
      "\titers: 800, epoch: 10 | loss: 0.0502290\n",
      "\tspeed: 0.0565s/iter; left time: 515.0259s\n",
      "\titers: 900, epoch: 10 | loss: 0.0442613\n",
      "\tspeed: 0.0566s/iter; left time: 510.7654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:51.20s\n",
      "Steps: 902 | Train Loss: 0.0474037 Vali Loss: 0.0821136 Test Loss: 0.0928926\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0453564\n",
      "\tspeed: 0.1445s/iter; left time: 1289.4143s\n",
      "\titers: 200, epoch: 11 | loss: 0.0493980\n",
      "\tspeed: 0.0565s/iter; left time: 498.8123s\n",
      "\titers: 300, epoch: 11 | loss: 0.0439386\n",
      "\tspeed: 0.0561s/iter; left time: 489.5450s\n",
      "\titers: 400, epoch: 11 | loss: 0.0465282\n",
      "\tspeed: 0.0564s/iter; left time: 485.9607s\n",
      "\titers: 500, epoch: 11 | loss: 0.0456666\n",
      "\tspeed: 0.0564s/iter; left time: 480.1811s\n",
      "\titers: 600, epoch: 11 | loss: 0.0424073\n",
      "\tspeed: 0.0564s/iter; left time: 475.2238s\n",
      "\titers: 700, epoch: 11 | loss: 0.0416672\n",
      "\tspeed: 0.0565s/iter; left time: 469.9431s\n",
      "\titers: 800, epoch: 11 | loss: 0.0417371\n",
      "\tspeed: 0.0571s/iter; left time: 469.2648s\n",
      "\titers: 900, epoch: 11 | loss: 0.0450329\n",
      "\tspeed: 0.0566s/iter; left time: 459.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.20s\n",
      "Steps: 902 | Train Loss: 0.0456750 Vali Loss: 0.0845399 Test Loss: 0.0924668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02346043847501278, rmse:0.15316800773143768, mae:0.09117613732814789, rse:0.592494547367096\n",
      "Intermediate time for FR and pred_len 96: 00h:22m:12.14s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1905309\n",
      "\tspeed: 0.0875s/iter; left time: 1565.5916s\n",
      "\titers: 200, epoch: 1 | loss: 0.1722236\n",
      "\tspeed: 0.0620s/iter; left time: 1103.0474s\n",
      "\titers: 300, epoch: 1 | loss: 0.1527263\n",
      "\tspeed: 0.0626s/iter; left time: 1108.1600s\n",
      "\titers: 400, epoch: 1 | loss: 0.1594457\n",
      "\tspeed: 0.0635s/iter; left time: 1117.6350s\n",
      "\titers: 500, epoch: 1 | loss: 0.1559160\n",
      "\tspeed: 0.0632s/iter; left time: 1105.7207s\n",
      "\titers: 600, epoch: 1 | loss: 0.1478682\n",
      "\tspeed: 0.0625s/iter; left time: 1086.7839s\n",
      "\titers: 700, epoch: 1 | loss: 0.1513262\n",
      "\tspeed: 0.0619s/iter; left time: 1071.4898s\n",
      "\titers: 800, epoch: 1 | loss: 0.1511963\n",
      "\tspeed: 0.0608s/iter; left time: 1046.5890s\n",
      "\titers: 900, epoch: 1 | loss: 0.1429050\n",
      "\tspeed: 0.0610s/iter; left time: 1042.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:56.49s\n",
      "Steps: 900 | Train Loss: 0.1636509 Vali Loss: 0.1605958 Test Loss: 0.1871256\n",
      "Validation loss decreased (inf --> 0.160596).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1305541\n",
      "\tspeed: 0.1789s/iter; left time: 3040.9075s\n",
      "\titers: 200, epoch: 2 | loss: 0.1200160\n",
      "\tspeed: 0.0614s/iter; left time: 1037.1764s\n",
      "\titers: 300, epoch: 2 | loss: 0.1194597\n",
      "\tspeed: 0.0617s/iter; left time: 1035.9909s\n",
      "\titers: 400, epoch: 2 | loss: 0.1090600\n",
      "\tspeed: 0.0614s/iter; left time: 1024.8421s\n",
      "\titers: 500, epoch: 2 | loss: 0.1153508\n",
      "\tspeed: 0.0620s/iter; left time: 1029.2242s\n",
      "\titers: 600, epoch: 2 | loss: 0.1162904\n",
      "\tspeed: 0.0608s/iter; left time: 1003.9663s\n",
      "\titers: 700, epoch: 2 | loss: 0.1049840\n",
      "\tspeed: 0.0609s/iter; left time: 998.1439s\n",
      "\titers: 800, epoch: 2 | loss: 0.0946741\n",
      "\tspeed: 0.0609s/iter; left time: 991.9424s\n",
      "\titers: 900, epoch: 2 | loss: 0.1001221\n",
      "\tspeed: 0.0608s/iter; left time: 984.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.25s\n",
      "Steps: 900 | Train Loss: 0.1142217 Vali Loss: 0.1189184 Test Loss: 0.1388842\n",
      "Validation loss decreased (0.160596 --> 0.118918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0911478\n",
      "\tspeed: 0.1688s/iter; left time: 2717.7171s\n",
      "\titers: 200, epoch: 3 | loss: 0.0963047\n",
      "\tspeed: 0.0615s/iter; left time: 983.5208s\n",
      "\titers: 300, epoch: 3 | loss: 0.0961769\n",
      "\tspeed: 0.0618s/iter; left time: 983.4280s\n",
      "\titers: 400, epoch: 3 | loss: 0.0932656\n",
      "\tspeed: 0.0625s/iter; left time: 986.9039s\n",
      "\titers: 500, epoch: 3 | loss: 0.0867795\n",
      "\tspeed: 0.0616s/iter; left time: 966.7073s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911845\n",
      "\tspeed: 0.0621s/iter; left time: 969.3208s\n",
      "\titers: 700, epoch: 3 | loss: 0.0906929\n",
      "\tspeed: 0.0618s/iter; left time: 958.0383s\n",
      "\titers: 800, epoch: 3 | loss: 0.0875157\n",
      "\tspeed: 0.0613s/iter; left time: 943.5131s\n",
      "\titers: 900, epoch: 3 | loss: 0.0864288\n",
      "\tspeed: 0.0609s/iter; left time: 932.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:55.81s\n",
      "Steps: 900 | Train Loss: 0.0917518 Vali Loss: 0.1089867 Test Loss: 0.1267858\n",
      "Validation loss decreased (0.118918 --> 0.108987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839642\n",
      "\tspeed: 0.1694s/iter; left time: 2574.6375s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764733\n",
      "\tspeed: 0.0577s/iter; left time: 870.7830s\n",
      "\titers: 300, epoch: 4 | loss: 0.0757760\n",
      "\tspeed: 0.0593s/iter; left time: 889.5676s\n",
      "\titers: 400, epoch: 4 | loss: 0.0728718\n",
      "\tspeed: 0.0608s/iter; left time: 905.6586s\n",
      "\titers: 500, epoch: 4 | loss: 0.0714797\n",
      "\tspeed: 0.0607s/iter; left time: 897.7600s\n",
      "\titers: 600, epoch: 4 | loss: 0.0676372\n",
      "\tspeed: 0.0609s/iter; left time: 895.6526s\n",
      "\titers: 700, epoch: 4 | loss: 0.0717468\n",
      "\tspeed: 0.0606s/iter; left time: 885.4740s\n",
      "\titers: 800, epoch: 4 | loss: 0.0659306\n",
      "\tspeed: 0.0617s/iter; left time: 894.1903s\n",
      "\titers: 900, epoch: 4 | loss: 0.0684796\n",
      "\tspeed: 0.0611s/iter; left time: 879.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:54.66s\n",
      "Steps: 900 | Train Loss: 0.0727621 Vali Loss: 0.0852216 Test Loss: 0.1003924\n",
      "Validation loss decreased (0.108987 --> 0.085222).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0642178\n",
      "\tspeed: 0.1866s/iter; left time: 2668.1123s\n",
      "\titers: 200, epoch: 5 | loss: 0.0715093\n",
      "\tspeed: 0.0608s/iter; left time: 862.9157s\n",
      "\titers: 300, epoch: 5 | loss: 0.0702455\n",
      "\tspeed: 0.0622s/iter; left time: 876.6764s\n",
      "\titers: 400, epoch: 5 | loss: 0.0673527\n",
      "\tspeed: 0.0608s/iter; left time: 851.1847s\n",
      "\titers: 500, epoch: 5 | loss: 0.0654915\n",
      "\tspeed: 0.0611s/iter; left time: 850.0306s\n",
      "\titers: 600, epoch: 5 | loss: 0.0592241\n",
      "\tspeed: 0.0606s/iter; left time: 836.9582s\n",
      "\titers: 700, epoch: 5 | loss: 0.0607646\n",
      "\tspeed: 0.0607s/iter; left time: 831.6133s\n",
      "\titers: 800, epoch: 5 | loss: 0.0632829\n",
      "\tspeed: 0.0614s/iter; left time: 834.9954s\n",
      "\titers: 900, epoch: 5 | loss: 0.0621399\n",
      "\tspeed: 0.0614s/iter; left time: 829.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.27s\n",
      "Steps: 900 | Train Loss: 0.0646578 Vali Loss: 0.0889243 Test Loss: 0.1043458\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631251\n",
      "\tspeed: 0.1638s/iter; left time: 2195.5738s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587196\n",
      "\tspeed: 0.0621s/iter; left time: 825.7671s\n",
      "\titers: 300, epoch: 6 | loss: 0.0581117\n",
      "\tspeed: 0.0619s/iter; left time: 817.3107s\n",
      "\titers: 400, epoch: 6 | loss: 0.0612026\n",
      "\tspeed: 0.0610s/iter; left time: 799.4102s\n",
      "\titers: 500, epoch: 6 | loss: 0.0655371\n",
      "\tspeed: 0.0616s/iter; left time: 800.8598s\n",
      "\titers: 600, epoch: 6 | loss: 0.0606963\n",
      "\tspeed: 0.0620s/iter; left time: 799.8797s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555741\n",
      "\tspeed: 0.0571s/iter; left time: 730.4144s\n",
      "\titers: 800, epoch: 6 | loss: 0.0582874\n",
      "\tspeed: 0.0570s/iter; left time: 724.4136s\n",
      "\titers: 900, epoch: 6 | loss: 0.0583975\n",
      "\tspeed: 0.0604s/iter; left time: 760.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:54.89s\n",
      "Steps: 900 | Train Loss: 0.0608440 Vali Loss: 0.0876241 Test Loss: 0.1033983\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0523239\n",
      "\tspeed: 0.1620s/iter; left time: 2025.2560s\n",
      "\titers: 200, epoch: 7 | loss: 0.0610628\n",
      "\tspeed: 0.0611s/iter; left time: 757.3984s\n",
      "\titers: 300, epoch: 7 | loss: 0.0606242\n",
      "\tspeed: 0.0609s/iter; left time: 749.0656s\n",
      "\titers: 400, epoch: 7 | loss: 0.0520629\n",
      "\tspeed: 0.0607s/iter; left time: 740.1771s\n",
      "\titers: 500, epoch: 7 | loss: 0.0586128\n",
      "\tspeed: 0.0607s/iter; left time: 734.5683s\n",
      "\titers: 600, epoch: 7 | loss: 0.0547781\n",
      "\tspeed: 0.0613s/iter; left time: 735.6181s\n",
      "\titers: 700, epoch: 7 | loss: 0.0584283\n",
      "\tspeed: 0.0607s/iter; left time: 721.9925s\n",
      "\titers: 800, epoch: 7 | loss: 0.0513636\n",
      "\tspeed: 0.0611s/iter; left time: 721.1070s\n",
      "\titers: 900, epoch: 7 | loss: 0.0575447\n",
      "\tspeed: 0.0608s/iter; left time: 711.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.08s\n",
      "Steps: 900 | Train Loss: 0.0573183 Vali Loss: 0.0886686 Test Loss: 0.1042051\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0556776\n",
      "\tspeed: 0.1622s/iter; left time: 1881.5367s\n",
      "\titers: 200, epoch: 8 | loss: 0.0529455\n",
      "\tspeed: 0.0614s/iter; left time: 705.6658s\n",
      "\titers: 300, epoch: 8 | loss: 0.0533620\n",
      "\tspeed: 0.0608s/iter; left time: 693.3929s\n",
      "\titers: 400, epoch: 8 | loss: 0.0522618\n",
      "\tspeed: 0.0592s/iter; left time: 669.0864s\n",
      "\titers: 500, epoch: 8 | loss: 0.0512089\n",
      "\tspeed: 0.0599s/iter; left time: 670.3936s\n",
      "\titers: 600, epoch: 8 | loss: 0.0547004\n",
      "\tspeed: 0.0607s/iter; left time: 674.0225s\n",
      "\titers: 700, epoch: 8 | loss: 0.0507799\n",
      "\tspeed: 0.0595s/iter; left time: 654.9664s\n",
      "\titers: 800, epoch: 8 | loss: 0.0567368\n",
      "\tspeed: 0.0607s/iter; left time: 661.8120s\n",
      "\titers: 900, epoch: 8 | loss: 0.0557473\n",
      "\tspeed: 0.0608s/iter; left time: 656.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.67s\n",
      "Steps: 900 | Train Loss: 0.0542578 Vali Loss: 0.0874382 Test Loss: 0.1030658\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0532811\n",
      "\tspeed: 0.1628s/iter; left time: 1742.4543s\n",
      "\titers: 200, epoch: 9 | loss: 0.0500249\n",
      "\tspeed: 0.0606s/iter; left time: 641.9418s\n",
      "\titers: 300, epoch: 9 | loss: 0.0504256\n",
      "\tspeed: 0.0607s/iter; left time: 637.9094s\n",
      "\titers: 400, epoch: 9 | loss: 0.0559026\n",
      "\tspeed: 0.0613s/iter; left time: 637.1531s\n",
      "\titers: 500, epoch: 9 | loss: 0.0505319\n",
      "\tspeed: 0.0606s/iter; left time: 624.7441s\n",
      "\titers: 600, epoch: 9 | loss: 0.0483749\n",
      "\tspeed: 0.0609s/iter; left time: 621.6141s\n",
      "\titers: 700, epoch: 9 | loss: 0.0508512\n",
      "\tspeed: 0.0607s/iter; left time: 612.9122s\n",
      "\titers: 800, epoch: 9 | loss: 0.0491124\n",
      "\tspeed: 0.0608s/iter; left time: 607.5863s\n",
      "\titers: 900, epoch: 9 | loss: 0.0468031\n",
      "\tspeed: 0.0614s/iter; left time: 607.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:55.08s\n",
      "Steps: 900 | Train Loss: 0.0517976 Vali Loss: 0.0889412 Test Loss: 0.1033320\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.026063205674290657, rmse:0.16144102811813354, mae:0.10040990263223648, rse:0.6252502799034119\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1795773\n",
      "\tspeed: 0.0647s/iter; left time: 1158.0340s\n",
      "\titers: 200, epoch: 1 | loss: 0.1730241\n",
      "\tspeed: 0.0618s/iter; left time: 1099.2622s\n",
      "\titers: 300, epoch: 1 | loss: 0.1644816\n",
      "\tspeed: 0.0607s/iter; left time: 1073.6158s\n",
      "\titers: 400, epoch: 1 | loss: 0.1643108\n",
      "\tspeed: 0.0620s/iter; left time: 1090.9528s\n",
      "\titers: 500, epoch: 1 | loss: 0.1700299\n",
      "\tspeed: 0.0615s/iter; left time: 1076.0862s\n",
      "\titers: 600, epoch: 1 | loss: 0.1567816\n",
      "\tspeed: 0.0614s/iter; left time: 1068.4568s\n",
      "\titers: 700, epoch: 1 | loss: 0.1513420\n",
      "\tspeed: 0.0618s/iter; left time: 1069.6790s\n",
      "\titers: 800, epoch: 1 | loss: 0.1531353\n",
      "\tspeed: 0.0626s/iter; left time: 1077.4653s\n",
      "\titers: 900, epoch: 1 | loss: 0.1441477\n",
      "\tspeed: 0.0614s/iter; left time: 1050.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.87s\n",
      "Steps: 900 | Train Loss: 0.1647519 Vali Loss: 0.1609735 Test Loss: 0.1867595\n",
      "Validation loss decreased (inf --> 0.160973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330414\n",
      "\tspeed: 0.1784s/iter; left time: 3032.2465s\n",
      "\titers: 200, epoch: 2 | loss: 0.1243088\n",
      "\tspeed: 0.0645s/iter; left time: 1090.3808s\n",
      "\titers: 300, epoch: 2 | loss: 0.1168964\n",
      "\tspeed: 0.0634s/iter; left time: 1065.0230s\n",
      "\titers: 400, epoch: 2 | loss: 0.1228913\n",
      "\tspeed: 0.0637s/iter; left time: 1063.5109s\n",
      "\titers: 500, epoch: 2 | loss: 0.1132697\n",
      "\tspeed: 0.0634s/iter; left time: 1053.0674s\n",
      "\titers: 600, epoch: 2 | loss: 0.1139820\n",
      "\tspeed: 0.0623s/iter; left time: 1028.7074s\n",
      "\titers: 700, epoch: 2 | loss: 0.1086050\n",
      "\tspeed: 0.0622s/iter; left time: 1020.6541s\n",
      "\titers: 800, epoch: 2 | loss: 0.1095953\n",
      "\tspeed: 0.0628s/iter; left time: 1024.2180s\n",
      "\titers: 900, epoch: 2 | loss: 0.1088555\n",
      "\tspeed: 0.0628s/iter; left time: 1017.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:57.07s\n",
      "Steps: 900 | Train Loss: 0.1200069 Vali Loss: 0.1309630 Test Loss: 0.1514261\n",
      "Validation loss decreased (0.160973 --> 0.130963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1100596\n",
      "\tspeed: 0.1748s/iter; left time: 2814.9930s\n",
      "\titers: 200, epoch: 3 | loss: 0.1014378\n",
      "\tspeed: 0.0571s/iter; left time: 912.9240s\n",
      "\titers: 300, epoch: 3 | loss: 0.1074149\n",
      "\tspeed: 0.0570s/iter; left time: 906.1212s\n",
      "\titers: 400, epoch: 3 | loss: 0.1002956\n",
      "\tspeed: 0.0574s/iter; left time: 906.4809s\n",
      "\titers: 500, epoch: 3 | loss: 0.1035359\n",
      "\tspeed: 0.0592s/iter; left time: 929.1326s\n",
      "\titers: 600, epoch: 3 | loss: 0.1029749\n",
      "\tspeed: 0.0580s/iter; left time: 905.3268s\n",
      "\titers: 700, epoch: 3 | loss: 0.0951096\n",
      "\tspeed: 0.0624s/iter; left time: 968.0270s\n",
      "\titers: 800, epoch: 3 | loss: 0.1024739\n",
      "\tspeed: 0.0623s/iter; left time: 959.0675s\n",
      "\titers: 900, epoch: 3 | loss: 0.0932429\n",
      "\tspeed: 0.0576s/iter; left time: 881.6270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.38s\n",
      "Steps: 900 | Train Loss: 0.1010495 Vali Loss: 0.1183511 Test Loss: 0.1383147\n",
      "Validation loss decreased (0.130963 --> 0.118351).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901304\n",
      "\tspeed: 0.1702s/iter; left time: 2587.2020s\n",
      "\titers: 200, epoch: 4 | loss: 0.0917204\n",
      "\tspeed: 0.0612s/iter; left time: 924.8865s\n",
      "\titers: 300, epoch: 4 | loss: 0.0880649\n",
      "\tspeed: 0.0622s/iter; left time: 933.0673s\n",
      "\titers: 400, epoch: 4 | loss: 0.0856858\n",
      "\tspeed: 0.0617s/iter; left time: 919.7531s\n",
      "\titers: 500, epoch: 4 | loss: 0.0701363\n",
      "\tspeed: 0.0619s/iter; left time: 915.5385s\n",
      "\titers: 600, epoch: 4 | loss: 0.0721682\n",
      "\tspeed: 0.0608s/iter; left time: 893.6908s\n",
      "\titers: 700, epoch: 4 | loss: 0.0668488\n",
      "\tspeed: 0.0612s/iter; left time: 893.1956s\n",
      "\titers: 800, epoch: 4 | loss: 0.0687550\n",
      "\tspeed: 0.0614s/iter; left time: 889.7264s\n",
      "\titers: 900, epoch: 4 | loss: 0.0744210\n",
      "\tspeed: 0.0613s/iter; left time: 882.4332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:55.58s\n",
      "Steps: 900 | Train Loss: 0.0801123 Vali Loss: 0.0881483 Test Loss: 0.1017556\n",
      "Validation loss decreased (0.118351 --> 0.088148).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0618225\n",
      "\tspeed: 0.1780s/iter; left time: 2545.6779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0661132\n",
      "\tspeed: 0.0626s/iter; left time: 889.5911s\n",
      "\titers: 300, epoch: 5 | loss: 0.0634479\n",
      "\tspeed: 0.0609s/iter; left time: 858.5078s\n",
      "\titers: 400, epoch: 5 | loss: 0.0679347\n",
      "\tspeed: 0.0619s/iter; left time: 866.7707s\n",
      "\titers: 500, epoch: 5 | loss: 0.0679202\n",
      "\tspeed: 0.0604s/iter; left time: 840.0630s\n",
      "\titers: 600, epoch: 5 | loss: 0.0656634\n",
      "\tspeed: 0.0571s/iter; left time: 787.7593s\n",
      "\titers: 700, epoch: 5 | loss: 0.0617741\n",
      "\tspeed: 0.0570s/iter; left time: 780.8026s\n",
      "\titers: 800, epoch: 5 | loss: 0.0661589\n",
      "\tspeed: 0.0599s/iter; left time: 814.3301s\n",
      "\titers: 900, epoch: 5 | loss: 0.0643784\n",
      "\tspeed: 0.0620s/iter; left time: 837.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:54.68s\n",
      "Steps: 900 | Train Loss: 0.0652905 Vali Loss: 0.0878353 Test Loss: 0.1019427\n",
      "Validation loss decreased (0.088148 --> 0.087835).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646247\n",
      "\tspeed: 0.1749s/iter; left time: 2343.2717s\n",
      "\titers: 200, epoch: 6 | loss: 0.0703149\n",
      "\tspeed: 0.0627s/iter; left time: 834.1926s\n",
      "\titers: 300, epoch: 6 | loss: 0.0581783\n",
      "\tspeed: 0.0621s/iter; left time: 819.3777s\n",
      "\titers: 400, epoch: 6 | loss: 0.0596728\n",
      "\tspeed: 0.0608s/iter; left time: 795.9938s\n",
      "\titers: 500, epoch: 6 | loss: 0.0597872\n",
      "\tspeed: 0.0612s/iter; left time: 795.0939s\n",
      "\titers: 600, epoch: 6 | loss: 0.0607916\n",
      "\tspeed: 0.0608s/iter; left time: 784.0994s\n",
      "\titers: 700, epoch: 6 | loss: 0.0618102\n",
      "\tspeed: 0.0602s/iter; left time: 770.3296s\n",
      "\titers: 800, epoch: 6 | loss: 0.0596929\n",
      "\tspeed: 0.0595s/iter; left time: 755.0855s\n",
      "\titers: 900, epoch: 6 | loss: 0.0612893\n",
      "\tspeed: 0.0611s/iter; left time: 770.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.20s\n",
      "Steps: 900 | Train Loss: 0.0610688 Vali Loss: 0.0860139 Test Loss: 0.1003324\n",
      "Validation loss decreased (0.087835 --> 0.086014).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0560653\n",
      "\tspeed: 0.1782s/iter; left time: 2227.3466s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599142\n",
      "\tspeed: 0.0616s/iter; left time: 764.4248s\n",
      "\titers: 300, epoch: 7 | loss: 0.0532390\n",
      "\tspeed: 0.0611s/iter; left time: 751.8645s\n",
      "\titers: 400, epoch: 7 | loss: 0.0598865\n",
      "\tspeed: 0.0610s/iter; left time: 743.8047s\n",
      "\titers: 500, epoch: 7 | loss: 0.0624891\n",
      "\tspeed: 0.0611s/iter; left time: 738.8512s\n",
      "\titers: 600, epoch: 7 | loss: 0.0568476\n",
      "\tspeed: 0.0612s/iter; left time: 734.2682s\n",
      "\titers: 700, epoch: 7 | loss: 0.0571247\n",
      "\tspeed: 0.0611s/iter; left time: 726.8281s\n",
      "\titers: 800, epoch: 7 | loss: 0.0546276\n",
      "\tspeed: 0.0609s/iter; left time: 719.2465s\n",
      "\titers: 900, epoch: 7 | loss: 0.0586743\n",
      "\tspeed: 0.0613s/iter; left time: 717.0345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.39s\n",
      "Steps: 900 | Train Loss: 0.0578664 Vali Loss: 0.0888959 Test Loss: 0.1055537\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549196\n",
      "\tspeed: 0.1645s/iter; left time: 1907.9263s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542563\n",
      "\tspeed: 0.0628s/iter; left time: 721.8863s\n",
      "\titers: 300, epoch: 8 | loss: 0.0577009\n",
      "\tspeed: 0.0626s/iter; left time: 713.3346s\n",
      "\titers: 400, epoch: 8 | loss: 0.0554325\n",
      "\tspeed: 0.0623s/iter; left time: 704.3452s\n",
      "\titers: 500, epoch: 8 | loss: 0.0581641\n",
      "\tspeed: 0.0590s/iter; left time: 661.0210s\n",
      "\titers: 600, epoch: 8 | loss: 0.0553745\n",
      "\tspeed: 0.0571s/iter; left time: 633.6527s\n",
      "\titers: 700, epoch: 8 | loss: 0.0551889\n",
      "\tspeed: 0.0571s/iter; left time: 628.1271s\n",
      "\titers: 800, epoch: 8 | loss: 0.0566119\n",
      "\tspeed: 0.0572s/iter; left time: 623.2169s\n",
      "\titers: 900, epoch: 8 | loss: 0.0542694\n",
      "\tspeed: 0.0572s/iter; left time: 617.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.02s\n",
      "Steps: 900 | Train Loss: 0.0548240 Vali Loss: 0.0865072 Test Loss: 0.1030074\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0527814\n",
      "\tspeed: 0.1640s/iter; left time: 1754.5363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0541923\n",
      "\tspeed: 0.0631s/iter; left time: 668.4958s\n",
      "\titers: 300, epoch: 9 | loss: 0.0512143\n",
      "\tspeed: 0.0617s/iter; left time: 647.4356s\n",
      "\titers: 400, epoch: 9 | loss: 0.0565373\n",
      "\tspeed: 0.0603s/iter; left time: 626.7672s\n",
      "\titers: 500, epoch: 9 | loss: 0.0512039\n",
      "\tspeed: 0.0637s/iter; left time: 656.1775s\n",
      "\titers: 600, epoch: 9 | loss: 0.0527253\n",
      "\tspeed: 0.0653s/iter; left time: 666.3951s\n",
      "\titers: 700, epoch: 9 | loss: 0.0529688\n",
      "\tspeed: 0.0665s/iter; left time: 671.6682s\n",
      "\titers: 800, epoch: 9 | loss: 0.0506182\n",
      "\tspeed: 0.0653s/iter; left time: 653.1526s\n",
      "\titers: 900, epoch: 9 | loss: 0.0533949\n",
      "\tspeed: 0.0667s/iter; left time: 660.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:57.75s\n",
      "Steps: 900 | Train Loss: 0.0523338 Vali Loss: 0.0883631 Test Loss: 0.1072983\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0504632\n",
      "\tspeed: 0.1760s/iter; left time: 1724.9893s\n",
      "\titers: 200, epoch: 10 | loss: 0.0515774\n",
      "\tspeed: 0.0618s/iter; left time: 599.1924s\n",
      "\titers: 300, epoch: 10 | loss: 0.0474586\n",
      "\tspeed: 0.0631s/iter; left time: 606.2352s\n",
      "\titers: 400, epoch: 10 | loss: 0.0491338\n",
      "\tspeed: 0.0614s/iter; left time: 583.7179s\n",
      "\titers: 500, epoch: 10 | loss: 0.0503640\n",
      "\tspeed: 0.0614s/iter; left time: 577.1295s\n",
      "\titers: 600, epoch: 10 | loss: 0.0518047\n",
      "\tspeed: 0.0580s/iter; left time: 539.5271s\n",
      "\titers: 700, epoch: 10 | loss: 0.0532302\n",
      "\tspeed: 0.0585s/iter; left time: 537.9364s\n",
      "\titers: 800, epoch: 10 | loss: 0.0500691\n",
      "\tspeed: 0.0628s/iter; left time: 571.0991s\n",
      "\titers: 900, epoch: 10 | loss: 0.0489692\n",
      "\tspeed: 0.0622s/iter; left time: 559.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:55.75s\n",
      "Steps: 900 | Train Loss: 0.0501358 Vali Loss: 0.0887627 Test Loss: 0.1074180\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0493343\n",
      "\tspeed: 0.1640s/iter; left time: 1459.7212s\n",
      "\titers: 200, epoch: 11 | loss: 0.0470729\n",
      "\tspeed: 0.0610s/iter; left time: 537.2232s\n",
      "\titers: 300, epoch: 11 | loss: 0.0490052\n",
      "\tspeed: 0.0608s/iter; left time: 528.8833s\n",
      "\titers: 400, epoch: 11 | loss: 0.0463857\n",
      "\tspeed: 0.0609s/iter; left time: 523.8054s\n",
      "\titers: 500, epoch: 11 | loss: 0.0493127\n",
      "\tspeed: 0.0611s/iter; left time: 519.3334s\n",
      "\titers: 600, epoch: 11 | loss: 0.0466824\n",
      "\tspeed: 0.0609s/iter; left time: 511.4184s\n",
      "\titers: 700, epoch: 11 | loss: 0.0475644\n",
      "\tspeed: 0.0608s/iter; left time: 504.5625s\n",
      "\titers: 800, epoch: 11 | loss: 0.0484297\n",
      "\tspeed: 0.0609s/iter; left time: 499.7391s\n",
      "\titers: 900, epoch: 11 | loss: 0.0485982\n",
      "\tspeed: 0.0592s/iter; left time: 479.2467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:55.00s\n",
      "Steps: 900 | Train Loss: 0.0483040 Vali Loss: 0.0895669 Test Loss: 0.1098155\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.026005728170275688, rmse:0.16126291453838348, mae:0.10041678696870804, rse:0.6245604753494263\n",
      "Intermediate time for FR and pred_len 168: 00h:22m:21.11s\n",
      "Intermediate time for FR: 01h:16m:11.81s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2220169\n",
      "\tspeed: 0.0793s/iter; left time: 1425.9933s\n",
      "\titers: 200, epoch: 1 | loss: 0.2120331\n",
      "\tspeed: 0.0533s/iter; left time: 953.5388s\n",
      "\titers: 300, epoch: 1 | loss: 0.2048963\n",
      "\tspeed: 0.0528s/iter; left time: 939.3437s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935016\n",
      "\tspeed: 0.0531s/iter; left time: 938.4391s\n",
      "\titers: 500, epoch: 1 | loss: 0.1953676\n",
      "\tspeed: 0.0532s/iter; left time: 934.7636s\n",
      "\titers: 600, epoch: 1 | loss: 0.1865766\n",
      "\tspeed: 0.0528s/iter; left time: 923.8708s\n",
      "\titers: 700, epoch: 1 | loss: 0.1859924\n",
      "\tspeed: 0.0532s/iter; left time: 925.1301s\n",
      "\titers: 800, epoch: 1 | loss: 0.1667970\n",
      "\tspeed: 0.0533s/iter; left time: 920.7698s\n",
      "\titers: 900, epoch: 1 | loss: 0.1697891\n",
      "\tspeed: 0.0530s/iter; left time: 910.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 904 | Train Loss: 0.1973136 Vali Loss: 0.1561704 Test Loss: 0.1742558\n",
      "Validation loss decreased (inf --> 0.156170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1446020\n",
      "\tspeed: 0.1335s/iter; left time: 2279.0114s\n",
      "\titers: 200, epoch: 2 | loss: 0.0948414\n",
      "\tspeed: 0.0468s/iter; left time: 793.8489s\n",
      "\titers: 300, epoch: 2 | loss: 0.1013823\n",
      "\tspeed: 0.0503s/iter; left time: 849.3211s\n",
      "\titers: 400, epoch: 2 | loss: 0.0857927\n",
      "\tspeed: 0.0504s/iter; left time: 844.8549s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890769\n",
      "\tspeed: 0.0504s/iter; left time: 840.3594s\n",
      "\titers: 600, epoch: 2 | loss: 0.0718978\n",
      "\tspeed: 0.0504s/iter; left time: 835.8923s\n",
      "\titers: 700, epoch: 2 | loss: 0.0668615\n",
      "\tspeed: 0.0506s/iter; left time: 833.9159s\n",
      "\titers: 800, epoch: 2 | loss: 0.0816984\n",
      "\tspeed: 0.0507s/iter; left time: 829.6389s\n",
      "\titers: 900, epoch: 2 | loss: 0.0684009\n",
      "\tspeed: 0.0504s/iter; left time: 821.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.50s\n",
      "Steps: 904 | Train Loss: 0.0931827 Vali Loss: 0.0708772 Test Loss: 0.0736226\n",
      "Validation loss decreased (0.156170 --> 0.070877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754260\n",
      "\tspeed: 0.1228s/iter; left time: 1985.6450s\n",
      "\titers: 200, epoch: 3 | loss: 0.0700179\n",
      "\tspeed: 0.0428s/iter; left time: 688.5092s\n",
      "\titers: 300, epoch: 3 | loss: 0.0664507\n",
      "\tspeed: 0.0428s/iter; left time: 684.4023s\n",
      "\titers: 400, epoch: 3 | loss: 0.0666362\n",
      "\tspeed: 0.0428s/iter; left time: 679.3010s\n",
      "\titers: 500, epoch: 3 | loss: 0.0705645\n",
      "\tspeed: 0.0429s/iter; left time: 676.5136s\n",
      "\titers: 600, epoch: 3 | loss: 0.0659557\n",
      "\tspeed: 0.0429s/iter; left time: 672.1605s\n",
      "\titers: 700, epoch: 3 | loss: 0.0707858\n",
      "\tspeed: 0.0489s/iter; left time: 761.2560s\n",
      "\titers: 800, epoch: 3 | loss: 0.0711233\n",
      "\tspeed: 0.0505s/iter; left time: 782.0984s\n",
      "\titers: 900, epoch: 3 | loss: 0.0665924\n",
      "\tspeed: 0.0505s/iter; left time: 776.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.12s\n",
      "Steps: 904 | Train Loss: 0.0684362 Vali Loss: 0.0635895 Test Loss: 0.0674974\n",
      "Validation loss decreased (0.070877 --> 0.063590).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0528162\n",
      "\tspeed: 0.1236s/iter; left time: 1887.1835s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625218\n",
      "\tspeed: 0.0428s/iter; left time: 649.5845s\n",
      "\titers: 300, epoch: 4 | loss: 0.0560537\n",
      "\tspeed: 0.0484s/iter; left time: 729.1752s\n",
      "\titers: 400, epoch: 4 | loss: 0.0640604\n",
      "\tspeed: 0.0455s/iter; left time: 681.7456s\n",
      "\titers: 500, epoch: 4 | loss: 0.0624375\n",
      "\tspeed: 0.0431s/iter; left time: 641.3999s\n",
      "\titers: 600, epoch: 4 | loss: 0.0652846\n",
      "\tspeed: 0.0505s/iter; left time: 746.2957s\n",
      "\titers: 700, epoch: 4 | loss: 0.0652440\n",
      "\tspeed: 0.0505s/iter; left time: 741.4203s\n",
      "\titers: 800, epoch: 4 | loss: 0.0643763\n",
      "\tspeed: 0.0506s/iter; left time: 736.6790s\n",
      "\titers: 900, epoch: 4 | loss: 0.0580249\n",
      "\tspeed: 0.0435s/iter; left time: 629.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 904 | Train Loss: 0.0638465 Vali Loss: 0.0614826 Test Loss: 0.0651174\n",
      "Validation loss decreased (0.063590 --> 0.061483).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619651\n",
      "\tspeed: 0.1229s/iter; left time: 1766.1262s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664870\n",
      "\tspeed: 0.0428s/iter; left time: 610.8339s\n",
      "\titers: 300, epoch: 5 | loss: 0.0593476\n",
      "\tspeed: 0.0428s/iter; left time: 606.2598s\n",
      "\titers: 400, epoch: 5 | loss: 0.0647073\n",
      "\tspeed: 0.0429s/iter; left time: 603.7329s\n",
      "\titers: 500, epoch: 5 | loss: 0.0638863\n",
      "\tspeed: 0.0453s/iter; left time: 632.8995s\n",
      "\titers: 600, epoch: 5 | loss: 0.0583075\n",
      "\tspeed: 0.0505s/iter; left time: 700.6554s\n",
      "\titers: 700, epoch: 5 | loss: 0.0653319\n",
      "\tspeed: 0.0504s/iter; left time: 694.1581s\n",
      "\titers: 800, epoch: 5 | loss: 0.0643018\n",
      "\tspeed: 0.0506s/iter; left time: 691.1596s\n",
      "\titers: 900, epoch: 5 | loss: 0.0672476\n",
      "\tspeed: 0.0506s/iter; left time: 686.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.32s\n",
      "Steps: 904 | Train Loss: 0.0600594 Vali Loss: 0.0594004 Test Loss: 0.0651227\n",
      "Validation loss decreased (0.061483 --> 0.059400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566753\n",
      "\tspeed: 0.1324s/iter; left time: 1782.5672s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545091\n",
      "\tspeed: 0.0506s/iter; left time: 675.8428s\n",
      "\titers: 300, epoch: 6 | loss: 0.0551393\n",
      "\tspeed: 0.0509s/iter; left time: 675.4183s\n",
      "\titers: 400, epoch: 6 | loss: 0.0557831\n",
      "\tspeed: 0.0505s/iter; left time: 665.0028s\n",
      "\titers: 500, epoch: 6 | loss: 0.0537642\n",
      "\tspeed: 0.0507s/iter; left time: 661.5586s\n",
      "\titers: 600, epoch: 6 | loss: 0.0604097\n",
      "\tspeed: 0.0455s/iter; left time: 590.1037s\n",
      "\titers: 700, epoch: 6 | loss: 0.0635012\n",
      "\tspeed: 0.0428s/iter; left time: 551.0868s\n",
      "\titers: 800, epoch: 6 | loss: 0.0573393\n",
      "\tspeed: 0.0428s/iter; left time: 546.3688s\n",
      "\titers: 900, epoch: 6 | loss: 0.0486181\n",
      "\tspeed: 0.0428s/iter; left time: 542.0460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.13s\n",
      "Steps: 904 | Train Loss: 0.0573408 Vali Loss: 0.0579008 Test Loss: 0.0649538\n",
      "Validation loss decreased (0.059400 --> 0.057901).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0453931\n",
      "\tspeed: 0.1294s/iter; left time: 1625.0860s\n",
      "\titers: 200, epoch: 7 | loss: 0.0556038\n",
      "\tspeed: 0.0504s/iter; left time: 628.1565s\n",
      "\titers: 300, epoch: 7 | loss: 0.0601809\n",
      "\tspeed: 0.0503s/iter; left time: 621.9495s\n",
      "\titers: 400, epoch: 7 | loss: 0.0598272\n",
      "\tspeed: 0.0506s/iter; left time: 619.6852s\n",
      "\titers: 500, epoch: 7 | loss: 0.0556290\n",
      "\tspeed: 0.0506s/iter; left time: 614.9763s\n",
      "\titers: 600, epoch: 7 | loss: 0.0524923\n",
      "\tspeed: 0.0506s/iter; left time: 609.6025s\n",
      "\titers: 700, epoch: 7 | loss: 0.0559348\n",
      "\tspeed: 0.0505s/iter; left time: 604.2425s\n",
      "\titers: 800, epoch: 7 | loss: 0.0557461\n",
      "\tspeed: 0.0505s/iter; left time: 598.2329s\n",
      "\titers: 900, epoch: 7 | loss: 0.0576981\n",
      "\tspeed: 0.0507s/iter; left time: 595.7254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 904 | Train Loss: 0.0551872 Vali Loss: 0.0590154 Test Loss: 0.0639875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583881\n",
      "\tspeed: 0.1277s/iter; left time: 1488.5611s\n",
      "\titers: 200, epoch: 8 | loss: 0.0462665\n",
      "\tspeed: 0.0506s/iter; left time: 584.0817s\n",
      "\titers: 300, epoch: 8 | loss: 0.0562939\n",
      "\tspeed: 0.0504s/iter; left time: 577.7241s\n",
      "\titers: 400, epoch: 8 | loss: 0.0522180\n",
      "\tspeed: 0.0504s/iter; left time: 572.7225s\n",
      "\titers: 500, epoch: 8 | loss: 0.0497727\n",
      "\tspeed: 0.0504s/iter; left time: 566.8343s\n",
      "\titers: 600, epoch: 8 | loss: 0.0562443\n",
      "\tspeed: 0.0505s/iter; left time: 563.7438s\n",
      "\titers: 700, epoch: 8 | loss: 0.0515358\n",
      "\tspeed: 0.0507s/iter; left time: 560.0546s\n",
      "\titers: 800, epoch: 8 | loss: 0.0528656\n",
      "\tspeed: 0.0503s/iter; left time: 550.4548s\n",
      "\titers: 900, epoch: 8 | loss: 0.0553008\n",
      "\tspeed: 0.0507s/iter; left time: 549.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 904 | Train Loss: 0.0527507 Vali Loss: 0.0584474 Test Loss: 0.0647885\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0513375\n",
      "\tspeed: 0.1282s/iter; left time: 1377.9942s\n",
      "\titers: 200, epoch: 9 | loss: 0.0435674\n",
      "\tspeed: 0.0506s/iter; left time: 539.2930s\n",
      "\titers: 300, epoch: 9 | loss: 0.0500180\n",
      "\tspeed: 0.0505s/iter; left time: 533.1649s\n",
      "\titers: 400, epoch: 9 | loss: 0.0504728\n",
      "\tspeed: 0.0506s/iter; left time: 528.4076s\n",
      "\titers: 500, epoch: 9 | loss: 0.0543945\n",
      "\tspeed: 0.0505s/iter; left time: 523.0617s\n",
      "\titers: 600, epoch: 9 | loss: 0.0481849\n",
      "\tspeed: 0.0506s/iter; left time: 518.1461s\n",
      "\titers: 700, epoch: 9 | loss: 0.0454198\n",
      "\tspeed: 0.0506s/iter; left time: 513.3244s\n",
      "\titers: 800, epoch: 9 | loss: 0.0511766\n",
      "\tspeed: 0.0508s/iter; left time: 510.1814s\n",
      "\titers: 900, epoch: 9 | loss: 0.0444380\n",
      "\tspeed: 0.0506s/iter; left time: 503.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0508786 Vali Loss: 0.0594453 Test Loss: 0.0646579\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441492\n",
      "\tspeed: 0.1271s/iter; left time: 1251.0909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0447464\n",
      "\tspeed: 0.0507s/iter; left time: 493.8304s\n",
      "\titers: 300, epoch: 10 | loss: 0.0511464\n",
      "\tspeed: 0.0506s/iter; left time: 487.8012s\n",
      "\titers: 400, epoch: 10 | loss: 0.0487987\n",
      "\tspeed: 0.0506s/iter; left time: 482.7598s\n",
      "\titers: 500, epoch: 10 | loss: 0.0482507\n",
      "\tspeed: 0.0505s/iter; left time: 477.3900s\n",
      "\titers: 600, epoch: 10 | loss: 0.0468921\n",
      "\tspeed: 0.0506s/iter; left time: 472.4897s\n",
      "\titers: 700, epoch: 10 | loss: 0.0509095\n",
      "\tspeed: 0.0506s/iter; left time: 467.4182s\n",
      "\titers: 800, epoch: 10 | loss: 0.0420810\n",
      "\tspeed: 0.0505s/iter; left time: 462.0919s\n",
      "\titers: 900, epoch: 10 | loss: 0.0508464\n",
      "\tspeed: 0.0506s/iter; left time: 457.2268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.0492623 Vali Loss: 0.0578709 Test Loss: 0.0647259\n",
      "Validation loss decreased (0.057901 --> 0.057871).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0414025\n",
      "\tspeed: 0.1323s/iter; left time: 1182.7534s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481514\n",
      "\tspeed: 0.0505s/iter; left time: 446.1205s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2220169\n",
      "\tspeed: 0.0771s/iter; left time: 1385.5068s\n",
      "\titers: 200, epoch: 1 | loss: 0.2120331\n",
      "\tspeed: 0.0432s/iter; left time: 772.2426s\n",
      "\titers: 300, epoch: 1 | loss: 0.2048963\n",
      "\tspeed: 0.0430s/iter; left time: 764.6012s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935016\n",
      "\tspeed: 0.0507s/iter; left time: 896.5489s\n",
      "\titers: 500, epoch: 1 | loss: 0.1953676\n",
      "\tspeed: 0.0505s/iter; left time: 887.5480s\n",
      "\titers: 600, epoch: 1 | loss: 0.1865766\n",
      "\tspeed: 0.0507s/iter; left time: 885.7034s\n",
      "\titers: 700, epoch: 1 | loss: 0.1859924\n",
      "\tspeed: 0.0506s/iter; left time: 878.8865s\n",
      "\titers: 800, epoch: 1 | loss: 0.1667970\n",
      "\tspeed: 0.0505s/iter; left time: 873.4934s\n",
      "\titers: 900, epoch: 1 | loss: 0.1697891\n",
      "\tspeed: 0.0507s/iter; left time: 870.7279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.08s\n",
      "Steps: 904 | Train Loss: 0.1973136 Vali Loss: 0.1561704 Test Loss: 0.1742558\n",
      "Validation loss decreased (inf --> 0.156170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1446020\n",
      "\tspeed: 0.1317s/iter; left time: 2249.0751s\n",
      "\titers: 200, epoch: 2 | loss: 0.0948414\n",
      "\tspeed: 0.0505s/iter; left time: 857.8396s\n",
      "\titers: 300, epoch: 2 | loss: 0.1013823\n",
      "\tspeed: 0.0505s/iter; left time: 853.0766s\n",
      "\titers: 400, epoch: 2 | loss: 0.0857927\n",
      "\tspeed: 0.0506s/iter; left time: 848.5377s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890769\n",
      "\tspeed: 0.0476s/iter; left time: 793.7968s\n",
      "\titers: 600, epoch: 2 | loss: 0.0718978\n",
      "\tspeed: 0.0453s/iter; left time: 750.8917s\n",
      "\titers: 700, epoch: 2 | loss: 0.0668615\n",
      "\tspeed: 0.0458s/iter; left time: 754.7796s\n",
      "\titers: 800, epoch: 2 | loss: 0.0816984\n",
      "\tspeed: 0.0430s/iter; left time: 704.3163s\n",
      "\titers: 900, epoch: 2 | loss: 0.0684009\n",
      "\tspeed: 0.0430s/iter; left time: 700.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.0931827 Vali Loss: 0.0708772 Test Loss: 0.0736226\n",
      "Validation loss decreased (0.156170 --> 0.070877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0754260\n",
      "\tspeed: 0.1257s/iter; left time: 2032.7465s\n",
      "\titers: 200, epoch: 3 | loss: 0.0700179\n",
      "\tspeed: 0.0430s/iter; left time: 691.1250s\n",
      "\titers: 300, epoch: 3 | loss: 0.0664507\n",
      "\tspeed: 0.0430s/iter; left time: 686.7836s\n",
      "\titers: 400, epoch: 3 | loss: 0.0666362\n",
      "\tspeed: 0.0430s/iter; left time: 682.5918s\n",
      "\titers: 500, epoch: 3 | loss: 0.0705645\n",
      "\tspeed: 0.0430s/iter; left time: 678.2482s\n",
      "\titers: 600, epoch: 3 | loss: 0.0659557\n",
      "\tspeed: 0.0430s/iter; left time: 674.1685s\n",
      "\titers: 700, epoch: 3 | loss: 0.0707858\n",
      "\tspeed: 0.0430s/iter; left time: 669.5011s\n",
      "\titers: 800, epoch: 3 | loss: 0.0711233\n",
      "\tspeed: 0.0430s/iter; left time: 665.3304s\n",
      "\titers: 900, epoch: 3 | loss: 0.0665924\n",
      "\tspeed: 0.0430s/iter; left time: 661.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.18s\n",
      "Steps: 904 | Train Loss: 0.0684362 Vali Loss: 0.0635895 Test Loss: 0.0674974\n",
      "Validation loss decreased (0.070877 --> 0.063590).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0528162\n",
      "\tspeed: 0.1310s/iter; left time: 2000.1320s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625218\n",
      "\tspeed: 0.0506s/iter; left time: 766.9952s\n",
      "\titers: 300, epoch: 4 | loss: 0.0560537\n",
      "\tspeed: 0.0506s/iter; left time: 761.7380s\n",
      "\titers: 400, epoch: 4 | loss: 0.0640604\n",
      "\tspeed: 0.0506s/iter; left time: 756.8333s\n",
      "\titers: 500, epoch: 4 | loss: 0.0624375\n",
      "\tspeed: 0.0505s/iter; left time: 751.5054s\n",
      "\titers: 600, epoch: 4 | loss: 0.0652846\n",
      "\tspeed: 0.0506s/iter; left time: 747.0061s\n",
      "\titers: 700, epoch: 4 | loss: 0.0652440\n",
      "\tspeed: 0.0506s/iter; left time: 741.8233s\n",
      "\titers: 800, epoch: 4 | loss: 0.0643763\n",
      "\tspeed: 0.0506s/iter; left time: 736.7675s\n",
      "\titers: 900, epoch: 4 | loss: 0.0580249\n",
      "\tspeed: 0.0506s/iter; left time: 731.6018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0638465 Vali Loss: 0.0614826 Test Loss: 0.0651174\n",
      "Validation loss decreased (0.063590 --> 0.061483).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619651\n",
      "\tspeed: 0.1348s/iter; left time: 1935.8393s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664870\n",
      "\tspeed: 0.0506s/iter; left time: 721.3116s\n",
      "\titers: 300, epoch: 5 | loss: 0.0593476\n",
      "\tspeed: 0.0506s/iter; left time: 717.2746s\n",
      "\titers: 400, epoch: 5 | loss: 0.0647073\n",
      "\tspeed: 0.0505s/iter; left time: 710.8350s\n",
      "\titers: 500, epoch: 5 | loss: 0.0638863\n",
      "\tspeed: 0.0505s/iter; left time: 705.6928s\n",
      "\titers: 600, epoch: 5 | loss: 0.0583075\n",
      "\tspeed: 0.0504s/iter; left time: 698.1772s\n",
      "\titers: 700, epoch: 5 | loss: 0.0653319\n",
      "\tspeed: 0.0503s/iter; left time: 692.8615s\n",
      "\titers: 800, epoch: 5 | loss: 0.0643018\n",
      "\tspeed: 0.0506s/iter; left time: 691.0946s\n",
      "\titers: 900, epoch: 5 | loss: 0.0672476\n",
      "\tspeed: 0.0504s/iter; left time: 683.1159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0600594 Vali Loss: 0.0594004 Test Loss: 0.0651227\n",
      "Validation loss decreased (0.061483 --> 0.059400).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0566753\n",
      "\tspeed: 0.1308s/iter; left time: 1760.2146s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545091\n",
      "\tspeed: 0.0506s/iter; left time: 675.6200s\n",
      "\titers: 300, epoch: 6 | loss: 0.0551393\n",
      "\tspeed: 0.0506s/iter; left time: 671.1365s\n",
      "\titers: 400, epoch: 6 | loss: 0.0557831\n",
      "\tspeed: 0.0506s/iter; left time: 666.0871s\n",
      "\titers: 500, epoch: 6 | loss: 0.0537642\n",
      "\tspeed: 0.0506s/iter; left time: 660.5844s\n",
      "\titers: 600, epoch: 6 | loss: 0.0604097\n",
      "\tspeed: 0.0506s/iter; left time: 655.8728s\n",
      "\titers: 700, epoch: 6 | loss: 0.0635012\n",
      "\tspeed: 0.0506s/iter; left time: 650.1579s\n",
      "\titers: 800, epoch: 6 | loss: 0.0573393\n",
      "\tspeed: 0.0504s/iter; left time: 642.6712s\n",
      "\titers: 900, epoch: 6 | loss: 0.0486181\n",
      "\tspeed: 0.0506s/iter; left time: 640.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0573408 Vali Loss: 0.0579008 Test Loss: 0.0649538\n",
      "Validation loss decreased (0.059400 --> 0.057901).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0453931\n",
      "\tspeed: 0.1316s/iter; left time: 1652.9564s\n",
      "\titers: 200, epoch: 7 | loss: 0.0556038\n",
      "\tspeed: 0.0503s/iter; left time: 626.3154s\n",
      "\titers: 300, epoch: 7 | loss: 0.0601809\n",
      "\tspeed: 0.0506s/iter; left time: 625.6500s\n",
      "\titers: 400, epoch: 7 | loss: 0.0598272\n",
      "\tspeed: 0.0507s/iter; left time: 620.9060s\n",
      "\titers: 500, epoch: 7 | loss: 0.0556290\n",
      "\tspeed: 0.0505s/iter; left time: 614.1426s\n",
      "\titers: 600, epoch: 7 | loss: 0.0524923\n",
      "\tspeed: 0.0506s/iter; left time: 609.6485s\n",
      "\titers: 700, epoch: 7 | loss: 0.0559348\n",
      "\tspeed: 0.0507s/iter; left time: 605.6435s\n",
      "\titers: 800, epoch: 7 | loss: 0.0557461\n",
      "\tspeed: 0.0506s/iter; left time: 600.0657s\n",
      "\titers: 900, epoch: 7 | loss: 0.0576981\n",
      "\tspeed: 0.0505s/iter; left time: 594.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0551872 Vali Loss: 0.0590154 Test Loss: 0.0639875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583881\n",
      "\tspeed: 0.1286s/iter; left time: 1498.0634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0462665\n",
      "\tspeed: 0.0506s/iter; left time: 584.3229s\n",
      "\titers: 300, epoch: 8 | loss: 0.0562939\n",
      "\tspeed: 0.0506s/iter; left time: 579.3649s\n",
      "\titers: 400, epoch: 8 | loss: 0.0522180\n",
      "\tspeed: 0.0503s/iter; left time: 570.6892s\n",
      "\titers: 500, epoch: 8 | loss: 0.0497727\n",
      "\tspeed: 0.0506s/iter; left time: 569.0151s\n",
      "\titers: 600, epoch: 8 | loss: 0.0562443\n",
      "\tspeed: 0.0506s/iter; left time: 563.9174s\n",
      "\titers: 700, epoch: 8 | loss: 0.0515358\n",
      "\tspeed: 0.0506s/iter; left time: 559.0124s\n",
      "\titers: 800, epoch: 8 | loss: 0.0528656\n",
      "\tspeed: 0.0507s/iter; left time: 555.3239s\n",
      "\titers: 900, epoch: 8 | loss: 0.0553008\n",
      "\tspeed: 0.0506s/iter; left time: 548.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0527507 Vali Loss: 0.0584474 Test Loss: 0.0647885\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0513375\n",
      "\tspeed: 0.1281s/iter; left time: 1376.6316s\n",
      "\titers: 200, epoch: 9 | loss: 0.0435674\n",
      "\tspeed: 0.0506s/iter; left time: 538.5499s\n",
      "\titers: 300, epoch: 9 | loss: 0.0500180\n",
      "\tspeed: 0.0506s/iter; left time: 533.9377s\n",
      "\titers: 400, epoch: 9 | loss: 0.0504728\n",
      "\tspeed: 0.0507s/iter; left time: 529.5182s\n",
      "\titers: 500, epoch: 9 | loss: 0.0543945\n",
      "\tspeed: 0.0504s/iter; left time: 522.0193s\n",
      "\titers: 600, epoch: 9 | loss: 0.0481849\n",
      "\tspeed: 0.0505s/iter; left time: 518.0360s\n",
      "\titers: 700, epoch: 9 | loss: 0.0454198\n",
      "\tspeed: 0.0506s/iter; left time: 513.3122s\n",
      "\titers: 800, epoch: 9 | loss: 0.0511766\n",
      "\tspeed: 0.0506s/iter; left time: 508.3029s\n",
      "\titers: 900, epoch: 9 | loss: 0.0444380\n",
      "\tspeed: 0.0506s/iter; left time: 502.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.0508786 Vali Loss: 0.0594453 Test Loss: 0.0646579\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441492\n",
      "\tspeed: 0.1296s/iter; left time: 1275.9143s\n",
      "\titers: 200, epoch: 10 | loss: 0.0447464\n",
      "\tspeed: 0.0504s/iter; left time: 491.4436s\n",
      "\titers: 300, epoch: 10 | loss: 0.0511464\n",
      "\tspeed: 0.0506s/iter; left time: 488.4612s\n",
      "\titers: 400, epoch: 10 | loss: 0.0487987\n",
      "\tspeed: 0.0505s/iter; left time: 482.2010s\n",
      "\titers: 500, epoch: 10 | loss: 0.0482507\n",
      "\tspeed: 0.0507s/iter; left time: 478.7276s\n",
      "\titers: 600, epoch: 10 | loss: 0.0468921\n",
      "\tspeed: 0.0506s/iter; left time: 472.4170s\n",
      "\titers: 700, epoch: 10 | loss: 0.0509095\n",
      "\tspeed: 0.0506s/iter; left time: 467.7529s\n",
      "\titers: 800, epoch: 10 | loss: 0.0420810\n",
      "\tspeed: 0.0505s/iter; left time: 462.1686s\n",
      "\titers: 900, epoch: 10 | loss: 0.0508464\n",
      "\tspeed: 0.0506s/iter; left time: 457.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0492623 Vali Loss: 0.0578709 Test Loss: 0.0647259\n",
      "Validation loss decreased (0.057901 --> 0.057871).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0414025\n",
      "\tspeed: 0.1328s/iter; left time: 1187.3308s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481514\n",
      "\tspeed: 0.0506s/iter; left time: 447.0186s\n",
      "\titers: 300, epoch: 11 | loss: 0.0550469\n",
      "\tspeed: 0.0503s/iter; left time: 439.8100s\n",
      "\titers: 400, epoch: 11 | loss: 0.0460621\n",
      "\tspeed: 0.0503s/iter; left time: 434.6545s\n",
      "\titers: 500, epoch: 11 | loss: 0.0408177\n",
      "\tspeed: 0.0505s/iter; left time: 431.3094s\n",
      "\titers: 600, epoch: 11 | loss: 0.0417309\n",
      "\tspeed: 0.0505s/iter; left time: 425.8620s\n",
      "\titers: 700, epoch: 11 | loss: 0.0466855\n",
      "\tspeed: 0.0503s/iter; left time: 419.8147s\n",
      "\titers: 800, epoch: 11 | loss: 0.0502889\n",
      "\tspeed: 0.0506s/iter; left time: 416.7091s\n",
      "\titers: 900, epoch: 11 | loss: 0.0423117\n",
      "\tspeed: 0.0506s/iter; left time: 412.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.0477187 Vali Loss: 0.0591078 Test Loss: 0.0654574\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0444539\n",
      "\tspeed: 0.1290s/iter; left time: 1036.7030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0401970\n",
      "\tspeed: 0.0502s/iter; left time: 398.6589s\n",
      "\titers: 300, epoch: 12 | loss: 0.0446740\n",
      "\tspeed: 0.0505s/iter; left time: 395.8974s\n",
      "\titers: 400, epoch: 12 | loss: 0.0486227\n",
      "\tspeed: 0.0504s/iter; left time: 390.1416s\n",
      "\titers: 500, epoch: 12 | loss: 0.0445950\n",
      "\tspeed: 0.0506s/iter; left time: 386.6977s\n",
      "\titers: 600, epoch: 12 | loss: 0.0415440\n",
      "\tspeed: 0.0505s/iter; left time: 380.7514s\n",
      "\titers: 700, epoch: 12 | loss: 0.0545967\n",
      "\tspeed: 0.0505s/iter; left time: 375.6899s\n",
      "\titers: 800, epoch: 12 | loss: 0.0423129\n",
      "\tspeed: 0.0506s/iter; left time: 370.8877s\n",
      "\titers: 900, epoch: 12 | loss: 0.0461149\n",
      "\tspeed: 0.0507s/iter; left time: 366.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0463752 Vali Loss: 0.0581299 Test Loss: 0.0667680\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0440696\n",
      "\tspeed: 0.1282s/iter; left time: 914.6653s\n",
      "\titers: 200, epoch: 13 | loss: 0.0504113\n",
      "\tspeed: 0.0505s/iter; left time: 355.2302s\n",
      "\titers: 300, epoch: 13 | loss: 0.0489256\n",
      "\tspeed: 0.0505s/iter; left time: 350.2170s\n",
      "\titers: 400, epoch: 13 | loss: 0.0456077\n",
      "\tspeed: 0.0505s/iter; left time: 345.1329s\n",
      "\titers: 500, epoch: 13 | loss: 0.0415305\n",
      "\tspeed: 0.0505s/iter; left time: 340.1352s\n",
      "\titers: 600, epoch: 13 | loss: 0.0461197\n",
      "\tspeed: 0.0506s/iter; left time: 335.7914s\n",
      "\titers: 700, epoch: 13 | loss: 0.0454853\n",
      "\tspeed: 0.0506s/iter; left time: 330.6438s\n",
      "\titers: 800, epoch: 13 | loss: 0.0500284\n",
      "\tspeed: 0.0506s/iter; left time: 325.3556s\n",
      "\titers: 900, epoch: 13 | loss: 0.0450839\n",
      "\tspeed: 0.0512s/iter; left time: 324.5271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0450412 Vali Loss: 0.0594910 Test Loss: 0.0668693\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0528736\n",
      "\tspeed: 0.1288s/iter; left time: 802.4483s\n",
      "\titers: 200, epoch: 14 | loss: 0.0449290\n",
      "\tspeed: 0.0506s/iter; left time: 309.8592s\n",
      "\titers: 300, epoch: 14 | loss: 0.0496138\n",
      "\tspeed: 0.0504s/iter; left time: 303.8521s\n",
      "\titers: 400, epoch: 14 | loss: 0.0453742\n",
      "\tspeed: 0.0507s/iter; left time: 300.3199s\n",
      "\titers: 500, epoch: 14 | loss: 0.0430608\n",
      "\tspeed: 0.0507s/iter; left time: 295.8021s\n",
      "\titers: 600, epoch: 14 | loss: 0.0439676\n",
      "\tspeed: 0.0505s/iter; left time: 289.5047s\n",
      "\titers: 700, epoch: 14 | loss: 0.0459211\n",
      "\tspeed: 0.0507s/iter; left time: 285.3699s\n",
      "\titers: 800, epoch: 14 | loss: 0.0393922\n",
      "\tspeed: 0.0507s/iter; left time: 280.5156s\n",
      "\titers: 900, epoch: 14 | loss: 0.0398595\n",
      "\tspeed: 0.0509s/iter; left time: 276.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.0439890 Vali Loss: 0.0601915 Test Loss: 0.0676970\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0480025\n",
      "\tspeed: 0.1280s/iter; left time: 681.7222s\n",
      "\titers: 200, epoch: 15 | loss: 0.0439052\n",
      "\tspeed: 0.0452s/iter; left time: 236.0154s\n",
      "\titers: 300, epoch: 15 | loss: 0.0471081\n",
      "\tspeed: 0.0429s/iter; left time: 219.9839s\n",
      "\titers: 400, epoch: 15 | loss: 0.0440689\n",
      "\tspeed: 0.0429s/iter; left time: 215.7368s\n",
      "\titers: 500, epoch: 15 | loss: 0.0459111\n",
      "\tspeed: 0.0429s/iter; left time: 211.3059s\n",
      "\titers: 600, epoch: 15 | loss: 0.0423207\n",
      "\tspeed: 0.0429s/iter; left time: 207.0153s\n",
      "\titers: 700, epoch: 15 | loss: 0.0444271\n",
      "\tspeed: 0.0429s/iter; left time: 202.8253s\n",
      "\titers: 800, epoch: 15 | loss: 0.0447993\n",
      "\tspeed: 0.0429s/iter; left time: 198.4271s\n",
      "\titers: 900, epoch: 15 | loss: 0.0432104\n",
      "\tspeed: 0.0429s/iter; left time: 194.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.02s\n",
      "Steps: 904 | Train Loss: 0.0429984 Vali Loss: 0.0592297 Test Loss: 0.0665272\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013071063905954361, rmse:0.11432875692844391, mae:0.06469322741031647, rse:0.4320563077926636\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2236773\n",
      "\tspeed: 0.0533s/iter; left time: 958.3146s\n",
      "\titers: 200, epoch: 1 | loss: 0.2095613\n",
      "\tspeed: 0.0508s/iter; left time: 907.8310s\n",
      "\titers: 300, epoch: 1 | loss: 0.2052812\n",
      "\tspeed: 0.0507s/iter; left time: 900.9620s\n",
      "\titers: 400, epoch: 1 | loss: 0.1789763\n",
      "\tspeed: 0.0507s/iter; left time: 896.4708s\n",
      "\titers: 500, epoch: 1 | loss: 0.1799944\n",
      "\tspeed: 0.0506s/iter; left time: 889.5692s\n",
      "\titers: 600, epoch: 1 | loss: 0.1811869\n",
      "\tspeed: 0.0506s/iter; left time: 884.8349s\n",
      "\titers: 700, epoch: 1 | loss: 0.1696288\n",
      "\tspeed: 0.0506s/iter; left time: 879.6320s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744496\n",
      "\tspeed: 0.0505s/iter; left time: 873.0441s\n",
      "\titers: 900, epoch: 1 | loss: 0.1827007\n",
      "\tspeed: 0.0507s/iter; left time: 870.8612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.1967737 Vali Loss: 0.1554087 Test Loss: 0.1722448\n",
      "Validation loss decreased (inf --> 0.155409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1649986\n",
      "\tspeed: 0.1334s/iter; left time: 2278.7110s\n",
      "\titers: 200, epoch: 2 | loss: 0.1484587\n",
      "\tspeed: 0.0507s/iter; left time: 861.4207s\n",
      "\titers: 300, epoch: 2 | loss: 0.1409299\n",
      "\tspeed: 0.0505s/iter; left time: 852.1642s\n",
      "\titers: 400, epoch: 2 | loss: 0.1405094\n",
      "\tspeed: 0.0506s/iter; left time: 849.0249s\n",
      "\titers: 500, epoch: 2 | loss: 0.1254249\n",
      "\tspeed: 0.0507s/iter; left time: 844.7932s\n",
      "\titers: 600, epoch: 2 | loss: 0.1221838\n",
      "\tspeed: 0.0505s/iter; left time: 837.4248s\n",
      "\titers: 700, epoch: 2 | loss: 0.1249846\n",
      "\tspeed: 0.0506s/iter; left time: 833.0088s\n",
      "\titers: 800, epoch: 2 | loss: 0.1031985\n",
      "\tspeed: 0.0506s/iter; left time: 828.0412s\n",
      "\titers: 900, epoch: 2 | loss: 0.0842275\n",
      "\tspeed: 0.0507s/iter; left time: 825.6811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.1310445 Vali Loss: 0.0824979 Test Loss: 0.0866736\n",
      "Validation loss decreased (0.155409 --> 0.082498).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733967\n",
      "\tspeed: 0.1340s/iter; left time: 2167.4623s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920930\n",
      "\tspeed: 0.0509s/iter; left time: 818.1941s\n",
      "\titers: 300, epoch: 3 | loss: 0.0746256\n",
      "\tspeed: 0.0505s/iter; left time: 807.0518s\n",
      "\titers: 400, epoch: 3 | loss: 0.0752689\n",
      "\tspeed: 0.0506s/iter; left time: 802.3815s\n",
      "\titers: 500, epoch: 3 | loss: 0.0760059\n",
      "\tspeed: 0.0504s/iter; left time: 795.1185s\n",
      "\titers: 600, epoch: 3 | loss: 0.0693765\n",
      "\tspeed: 0.0506s/iter; left time: 792.4130s\n",
      "\titers: 700, epoch: 3 | loss: 0.0685310\n",
      "\tspeed: 0.0506s/iter; left time: 787.8891s\n",
      "\titers: 800, epoch: 3 | loss: 0.0609272\n",
      "\tspeed: 0.0506s/iter; left time: 782.8807s\n",
      "\titers: 900, epoch: 3 | loss: 0.0634150\n",
      "\tspeed: 0.0506s/iter; left time: 778.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.0740015 Vali Loss: 0.0705756 Test Loss: 0.0745420\n",
      "Validation loss decreased (0.082498 --> 0.070576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0683883\n",
      "\tspeed: 0.1325s/iter; left time: 2022.4279s\n",
      "\titers: 200, epoch: 4 | loss: 0.0786418\n",
      "\tspeed: 0.0504s/iter; left time: 764.1217s\n",
      "\titers: 300, epoch: 4 | loss: 0.0620849\n",
      "\tspeed: 0.0508s/iter; left time: 765.6061s\n",
      "\titers: 400, epoch: 4 | loss: 0.0737738\n",
      "\tspeed: 0.0505s/iter; left time: 756.4068s\n",
      "\titers: 500, epoch: 4 | loss: 0.0687538\n",
      "\tspeed: 0.0505s/iter; left time: 751.5726s\n",
      "\titers: 600, epoch: 4 | loss: 0.0694434\n",
      "\tspeed: 0.0506s/iter; left time: 746.8239s\n",
      "\titers: 700, epoch: 4 | loss: 0.0673035\n",
      "\tspeed: 0.0506s/iter; left time: 741.8735s\n",
      "\titers: 800, epoch: 4 | loss: 0.0707372\n",
      "\tspeed: 0.0506s/iter; left time: 737.1239s\n",
      "\titers: 900, epoch: 4 | loss: 0.0749091\n",
      "\tspeed: 0.0505s/iter; left time: 731.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0674589 Vali Loss: 0.0701587 Test Loss: 0.0747809\n",
      "Validation loss decreased (0.070576 --> 0.070159).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0664191\n",
      "\tspeed: 0.1333s/iter; left time: 1914.2690s\n",
      "\titers: 200, epoch: 5 | loss: 0.0678410\n",
      "\tspeed: 0.0508s/iter; left time: 724.4011s\n",
      "\titers: 300, epoch: 5 | loss: 0.0682586\n",
      "\tspeed: 0.0507s/iter; left time: 718.7713s\n",
      "\titers: 400, epoch: 5 | loss: 0.0669123\n",
      "\tspeed: 0.0503s/iter; left time: 707.9428s\n",
      "\titers: 500, epoch: 5 | loss: 0.0622833\n",
      "\tspeed: 0.0505s/iter; left time: 705.4592s\n",
      "\titers: 600, epoch: 5 | loss: 0.0671278\n",
      "\tspeed: 0.0505s/iter; left time: 700.5431s\n",
      "\titers: 700, epoch: 5 | loss: 0.0592359\n",
      "\tspeed: 0.0504s/iter; left time: 694.3355s\n",
      "\titers: 800, epoch: 5 | loss: 0.0649717\n",
      "\tspeed: 0.0506s/iter; left time: 691.9081s\n",
      "\titers: 900, epoch: 5 | loss: 0.0651509\n",
      "\tspeed: 0.0505s/iter; left time: 685.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0637990 Vali Loss: 0.0648832 Test Loss: 0.0705947\n",
      "Validation loss decreased (0.070159 --> 0.064883).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0682643\n",
      "\tspeed: 0.1261s/iter; left time: 1698.0497s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592618\n",
      "\tspeed: 0.0431s/iter; left time: 575.1956s\n",
      "\titers: 300, epoch: 6 | loss: 0.0657497\n",
      "\tspeed: 0.0430s/iter; left time: 570.8367s\n",
      "\titers: 400, epoch: 6 | loss: 0.0600487\n",
      "\tspeed: 0.0430s/iter; left time: 566.4797s\n",
      "\titers: 500, epoch: 6 | loss: 0.0563748\n",
      "\tspeed: 0.0430s/iter; left time: 561.8304s\n",
      "\titers: 600, epoch: 6 | loss: 0.0518400\n",
      "\tspeed: 0.0498s/iter; left time: 645.0719s\n",
      "\titers: 700, epoch: 6 | loss: 0.0580983\n",
      "\tspeed: 0.0506s/iter; left time: 651.0951s\n",
      "\titers: 800, epoch: 6 | loss: 0.0586267\n",
      "\tspeed: 0.0506s/iter; left time: 645.1004s\n",
      "\titers: 900, epoch: 6 | loss: 0.0590535\n",
      "\tspeed: 0.0480s/iter; left time: 607.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 904 | Train Loss: 0.0605568 Vali Loss: 0.0620652 Test Loss: 0.0686485\n",
      "Validation loss decreased (0.064883 --> 0.062065).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0544872\n",
      "\tspeed: 0.1321s/iter; left time: 1658.3108s\n",
      "\titers: 200, epoch: 7 | loss: 0.0565976\n",
      "\tspeed: 0.0506s/iter; left time: 629.8372s\n",
      "\titers: 300, epoch: 7 | loss: 0.0508717\n",
      "\tspeed: 0.0505s/iter; left time: 624.5322s\n",
      "\titers: 400, epoch: 7 | loss: 0.0534595\n",
      "\tspeed: 0.0505s/iter; left time: 619.4886s\n",
      "\titers: 500, epoch: 7 | loss: 0.0599232\n",
      "\tspeed: 0.0505s/iter; left time: 614.4011s\n",
      "\titers: 600, epoch: 7 | loss: 0.0590315\n",
      "\tspeed: 0.0505s/iter; left time: 609.3573s\n",
      "\titers: 700, epoch: 7 | loss: 0.0631343\n",
      "\tspeed: 0.0504s/iter; left time: 603.0366s\n",
      "\titers: 800, epoch: 7 | loss: 0.0585233\n",
      "\tspeed: 0.0505s/iter; left time: 599.1816s\n",
      "\titers: 900, epoch: 7 | loss: 0.0579281\n",
      "\tspeed: 0.0507s/iter; left time: 595.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.0569077 Vali Loss: 0.0586834 Test Loss: 0.0659661\n",
      "Validation loss decreased (0.062065 --> 0.058683).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591488\n",
      "\tspeed: 0.1327s/iter; left time: 1546.0922s\n",
      "\titers: 200, epoch: 8 | loss: 0.0515028\n",
      "\tspeed: 0.0505s/iter; left time: 583.7126s\n",
      "\titers: 300, epoch: 8 | loss: 0.0533282\n",
      "\tspeed: 0.0505s/iter; left time: 578.4558s\n",
      "\titers: 400, epoch: 8 | loss: 0.0539476\n",
      "\tspeed: 0.0505s/iter; left time: 573.6108s\n",
      "\titers: 500, epoch: 8 | loss: 0.0516925\n",
      "\tspeed: 0.0506s/iter; left time: 568.8513s\n",
      "\titers: 600, epoch: 8 | loss: 0.0573574\n",
      "\tspeed: 0.0505s/iter; left time: 563.7658s\n",
      "\titers: 700, epoch: 8 | loss: 0.0490831\n",
      "\tspeed: 0.0506s/iter; left time: 559.7844s\n",
      "\titers: 800, epoch: 8 | loss: 0.0548482\n",
      "\tspeed: 0.0503s/iter; left time: 551.4546s\n",
      "\titers: 900, epoch: 8 | loss: 0.0598577\n",
      "\tspeed: 0.0506s/iter; left time: 548.9132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0542265 Vali Loss: 0.0595771 Test Loss: 0.0652865\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0506239\n",
      "\tspeed: 0.1286s/iter; left time: 1382.2311s\n",
      "\titers: 200, epoch: 9 | loss: 0.0550224\n",
      "\tspeed: 0.0506s/iter; left time: 539.0660s\n",
      "\titers: 300, epoch: 9 | loss: 0.0530984\n",
      "\tspeed: 0.0504s/iter; left time: 532.1017s\n",
      "\titers: 400, epoch: 9 | loss: 0.0544165\n",
      "\tspeed: 0.0505s/iter; left time: 528.1781s\n",
      "\titers: 500, epoch: 9 | loss: 0.0538776\n",
      "\tspeed: 0.0505s/iter; left time: 523.1025s\n",
      "\titers: 600, epoch: 9 | loss: 0.0566327\n",
      "\tspeed: 0.0505s/iter; left time: 517.8202s\n",
      "\titers: 700, epoch: 9 | loss: 0.0507570\n",
      "\tspeed: 0.0506s/iter; left time: 513.2229s\n",
      "\titers: 800, epoch: 9 | loss: 0.0575952\n",
      "\tspeed: 0.0505s/iter; left time: 507.8788s\n",
      "\titers: 900, epoch: 9 | loss: 0.0533650\n",
      "\tspeed: 0.0507s/iter; left time: 504.3955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0522601 Vali Loss: 0.0590588 Test Loss: 0.0669343\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0540953\n",
      "\tspeed: 0.1289s/iter; left time: 1269.0238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0561355\n",
      "\tspeed: 0.0505s/iter; left time: 492.1501s\n",
      "\titers: 300, epoch: 10 | loss: 0.0517102\n",
      "\tspeed: 0.0505s/iter; left time: 487.0930s\n",
      "\titers: 400, epoch: 10 | loss: 0.0547010\n",
      "\tspeed: 0.0505s/iter; left time: 482.4521s\n",
      "\titers: 500, epoch: 10 | loss: 0.0485533\n",
      "\tspeed: 0.0506s/iter; left time: 477.4774s\n",
      "\titers: 600, epoch: 10 | loss: 0.0541562\n",
      "\tspeed: 0.0506s/iter; left time: 472.4937s\n",
      "\titers: 700, epoch: 10 | loss: 0.0512772\n",
      "\tspeed: 0.0508s/iter; left time: 469.9787s\n",
      "\titers: 800, epoch: 10 | loss: 0.0441590\n",
      "\tspeed: 0.0507s/iter; left time: 463.8961s\n",
      "\titers: 900, epoch: 10 | loss: 0.0533096\n",
      "\tspeed: 0.0507s/iter; left time: 458.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0505262 Vali Loss: 0.0582515 Test Loss: 0.0648123\n",
      "Validation loss decreased (0.058683 --> 0.058252).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0467435\n",
      "\tspeed: 0.1333s/iter; left time: 1191.5676s\n",
      "\titers: 200, epoch: 11 | loss: 0.0525729\n",
      "\tspeed: 0.0506s/iter; left time: 446.9810s\n",
      "\titers: 300, epoch: 11 | loss: 0.0507778\n",
      "\tspeed: 0.0505s/iter; left time: 441.6597s\n",
      "\titers: 400, epoch: 11 | loss: 0.0506937\n",
      "\tspeed: 0.0505s/iter; left time: 436.5431s\n",
      "\titers: 500, epoch: 11 | loss: 0.0479088\n",
      "\tspeed: 0.0506s/iter; left time: 431.9524s\n",
      "\titers: 600, epoch: 11 | loss: 0.0541141\n",
      "\tspeed: 0.0506s/iter; left time: 426.8009s\n",
      "\titers: 700, epoch: 11 | loss: 0.0458417\n",
      "\tspeed: 0.0506s/iter; left time: 421.9134s\n",
      "\titers: 800, epoch: 11 | loss: 0.0548990\n",
      "\tspeed: 0.0506s/iter; left time: 416.6303s\n",
      "\titers: 900, epoch: 11 | loss: 0.0484241\n",
      "\tspeed: 0.0506s/iter; left time: 412.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0492183 Vali Loss: 0.0590420 Test Loss: 0.0677270\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0444029\n",
      "\tspeed: 0.1289s/iter; left time: 1035.6088s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484444\n",
      "\tspeed: 0.0505s/iter; left time: 401.1740s\n",
      "\titers: 300, epoch: 12 | loss: 0.0507108\n",
      "\tspeed: 0.0507s/iter; left time: 397.0213s\n",
      "\titers: 400, epoch: 12 | loss: 0.0558305\n",
      "\tspeed: 0.0506s/iter; left time: 391.4070s\n",
      "\titers: 500, epoch: 12 | loss: 0.0472486\n",
      "\tspeed: 0.0506s/iter; left time: 386.1274s\n",
      "\titers: 600, epoch: 12 | loss: 0.0498849\n",
      "\tspeed: 0.0509s/iter; left time: 383.3362s\n",
      "\titers: 700, epoch: 12 | loss: 0.0514488\n",
      "\tspeed: 0.0505s/iter; left time: 375.6323s\n",
      "\titers: 800, epoch: 12 | loss: 0.0543285\n",
      "\tspeed: 0.0506s/iter; left time: 371.5812s\n",
      "\titers: 900, epoch: 12 | loss: 0.0479826\n",
      "\tspeed: 0.0505s/iter; left time: 365.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.0477154 Vali Loss: 0.0604115 Test Loss: 0.0672891\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0467444\n",
      "\tspeed: 0.1286s/iter; left time: 917.1135s\n",
      "\titers: 200, epoch: 13 | loss: 0.0523643\n",
      "\tspeed: 0.0505s/iter; left time: 355.2722s\n",
      "\titers: 300, epoch: 13 | loss: 0.0462362\n",
      "\tspeed: 0.0506s/iter; left time: 350.5029s\n",
      "\titers: 400, epoch: 13 | loss: 0.0461142\n",
      "\tspeed: 0.0505s/iter; left time: 345.3544s\n",
      "\titers: 500, epoch: 13 | loss: 0.0445445\n",
      "\tspeed: 0.0506s/iter; left time: 340.6442s\n",
      "\titers: 600, epoch: 13 | loss: 0.0410075\n",
      "\tspeed: 0.0509s/iter; left time: 337.5522s\n",
      "\titers: 700, epoch: 13 | loss: 0.0504712\n",
      "\tspeed: 0.0505s/iter; left time: 330.0203s\n",
      "\titers: 800, epoch: 13 | loss: 0.0469534\n",
      "\tspeed: 0.0505s/iter; left time: 325.0603s\n",
      "\titers: 900, epoch: 13 | loss: 0.0426516\n",
      "\tspeed: 0.0505s/iter; left time: 319.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0465518 Vali Loss: 0.0587973 Test Loss: 0.0667645\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0386960\n",
      "\tspeed: 0.1288s/iter; left time: 802.2528s\n",
      "\titers: 200, epoch: 14 | loss: 0.0442338\n",
      "\tspeed: 0.0505s/iter; left time: 309.7404s\n",
      "\titers: 300, epoch: 14 | loss: 0.0449690\n",
      "\tspeed: 0.0506s/iter; left time: 304.7822s\n",
      "\titers: 400, epoch: 14 | loss: 0.0477260\n",
      "\tspeed: 0.0505s/iter; left time: 299.1591s\n",
      "\titers: 500, epoch: 14 | loss: 0.0462314\n",
      "\tspeed: 0.0506s/iter; left time: 294.7014s\n",
      "\titers: 600, epoch: 14 | loss: 0.0431163\n",
      "\tspeed: 0.0506s/iter; left time: 289.9591s\n",
      "\titers: 700, epoch: 14 | loss: 0.0485747\n",
      "\tspeed: 0.0507s/iter; left time: 285.2512s\n",
      "\titers: 800, epoch: 14 | loss: 0.0516558\n",
      "\tspeed: 0.0505s/iter; left time: 279.3659s\n",
      "\titers: 900, epoch: 14 | loss: 0.0469844\n",
      "\tspeed: 0.0504s/iter; left time: 273.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0453831 Vali Loss: 0.0603541 Test Loss: 0.0682862\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0432168\n",
      "\tspeed: 0.1283s/iter; left time: 683.0364s\n",
      "\titers: 200, epoch: 15 | loss: 0.0409239\n",
      "\tspeed: 0.0506s/iter; left time: 264.1242s\n",
      "\titers: 300, epoch: 15 | loss: 0.0430283\n",
      "\tspeed: 0.0506s/iter; left time: 259.5583s\n",
      "\titers: 400, epoch: 15 | loss: 0.0427901\n",
      "\tspeed: 0.0506s/iter; left time: 254.1130s\n",
      "\titers: 500, epoch: 15 | loss: 0.0420214\n",
      "\tspeed: 0.0504s/iter; left time: 248.0186s\n",
      "\titers: 600, epoch: 15 | loss: 0.0472731\n",
      "\tspeed: 0.0505s/iter; left time: 243.8678s\n",
      "\titers: 700, epoch: 15 | loss: 0.0474453\n",
      "\tspeed: 0.0505s/iter; left time: 238.8058s\n",
      "\titers: 800, epoch: 15 | loss: 0.0438062\n",
      "\tspeed: 0.0505s/iter; left time: 233.6713s\n",
      "\titers: 900, epoch: 15 | loss: 0.0450126\n",
      "\tspeed: 0.0506s/iter; left time: 228.8191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.0443448 Vali Loss: 0.0607161 Test Loss: 0.0683593\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011997658759355545, rmse:0.10953382402658463, mae:0.06481219828128815, rse:0.41393598914146423\n",
      "Intermediate time for IT and pred_len 24: 00h:26m:42.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2395895\n",
      "\tspeed: 0.0821s/iter; left time: 1473.5341s\n",
      "\titers: 200, epoch: 1 | loss: 0.2040674\n",
      "\tspeed: 0.0563s/iter; left time: 1004.8300s\n",
      "\titers: 300, epoch: 1 | loss: 0.2146306\n",
      "\tspeed: 0.0563s/iter; left time: 999.0230s\n",
      "\titers: 400, epoch: 1 | loss: 0.2058711\n",
      "\tspeed: 0.0563s/iter; left time: 992.9710s\n",
      "\titers: 500, epoch: 1 | loss: 0.1992879\n",
      "\tspeed: 0.0560s/iter; left time: 982.3961s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957049\n",
      "\tspeed: 0.0559s/iter; left time: 975.4691s\n",
      "\titers: 700, epoch: 1 | loss: 0.1909404\n",
      "\tspeed: 0.0560s/iter; left time: 971.1880s\n",
      "\titers: 800, epoch: 1 | loss: 0.1934274\n",
      "\tspeed: 0.0562s/iter; left time: 969.2743s\n",
      "\titers: 900, epoch: 1 | loss: 0.1929820\n",
      "\tspeed: 0.0563s/iter; left time: 965.5803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.45s\n",
      "Steps: 902 | Train Loss: 0.2062051 Vali Loss: 0.1691831 Test Loss: 0.1862035\n",
      "Validation loss decreased (inf --> 0.169183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1676696\n",
      "\tspeed: 0.1515s/iter; left time: 2581.7157s\n",
      "\titers: 200, epoch: 2 | loss: 0.1622101\n",
      "\tspeed: 0.0566s/iter; left time: 957.9176s\n",
      "\titers: 300, epoch: 2 | loss: 0.1608057\n",
      "\tspeed: 0.0563s/iter; left time: 948.6731s\n",
      "\titers: 400, epoch: 2 | loss: 0.1567176\n",
      "\tspeed: 0.0561s/iter; left time: 939.1048s\n",
      "\titers: 500, epoch: 2 | loss: 0.1490850\n",
      "\tspeed: 0.0563s/iter; left time: 936.2148s\n",
      "\titers: 600, epoch: 2 | loss: 0.1439216\n",
      "\tspeed: 0.0564s/iter; left time: 933.6041s\n",
      "\titers: 700, epoch: 2 | loss: 0.1323436\n",
      "\tspeed: 0.0563s/iter; left time: 926.2272s\n",
      "\titers: 800, epoch: 2 | loss: 0.1077829\n",
      "\tspeed: 0.0562s/iter; left time: 917.5352s\n",
      "\titers: 900, epoch: 2 | loss: 0.1013042\n",
      "\tspeed: 0.0562s/iter; left time: 913.2332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:51.02s\n",
      "Steps: 902 | Train Loss: 0.1462276 Vali Loss: 0.1066677 Test Loss: 0.1138080\n",
      "Validation loss decreased (0.169183 --> 0.106668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0999345\n",
      "\tspeed: 0.1711s/iter; left time: 2760.7067s\n",
      "\titers: 200, epoch: 3 | loss: 0.0960833\n",
      "\tspeed: 0.0562s/iter; left time: 900.9314s\n",
      "\titers: 300, epoch: 3 | loss: 0.0911917\n",
      "\tspeed: 0.0562s/iter; left time: 895.2643s\n",
      "\titers: 400, epoch: 3 | loss: 0.0855746\n",
      "\tspeed: 0.0559s/iter; left time: 885.2769s\n",
      "\titers: 500, epoch: 3 | loss: 0.0957507\n",
      "\tspeed: 0.0560s/iter; left time: 881.1590s\n",
      "\titers: 600, epoch: 3 | loss: 0.0854103\n",
      "\tspeed: 0.0560s/iter; left time: 875.7366s\n",
      "\titers: 700, epoch: 3 | loss: 0.0909581\n",
      "\tspeed: 0.0560s/iter; left time: 870.5971s\n",
      "\titers: 800, epoch: 3 | loss: 0.0836157\n",
      "\tspeed: 0.0560s/iter; left time: 864.6979s\n",
      "\titers: 900, epoch: 3 | loss: 0.0940489\n",
      "\tspeed: 0.0559s/iter; left time: 856.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:50.75s\n",
      "Steps: 902 | Train Loss: 0.0928704 Vali Loss: 0.0859426 Test Loss: 0.0915419\n",
      "Validation loss decreased (0.106668 --> 0.085943).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0817366\n",
      "\tspeed: 0.1521s/iter; left time: 2317.2158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844458\n",
      "\tspeed: 0.0564s/iter; left time: 854.3094s\n",
      "\titers: 300, epoch: 4 | loss: 0.0871343\n",
      "\tspeed: 0.0561s/iter; left time: 843.4820s\n",
      "\titers: 400, epoch: 4 | loss: 0.0844404\n",
      "\tspeed: 0.0563s/iter; left time: 841.4332s\n",
      "\titers: 500, epoch: 4 | loss: 0.0890046\n",
      "\tspeed: 0.0563s/iter; left time: 835.1367s\n",
      "\titers: 600, epoch: 4 | loss: 0.0780615\n",
      "\tspeed: 0.0564s/iter; left time: 830.3918s\n",
      "\titers: 700, epoch: 4 | loss: 0.0855336\n",
      "\tspeed: 0.0563s/iter; left time: 824.3713s\n",
      "\titers: 800, epoch: 4 | loss: 0.0791685\n",
      "\tspeed: 0.0563s/iter; left time: 818.1634s\n",
      "\titers: 900, epoch: 4 | loss: 0.0817070\n",
      "\tspeed: 0.0564s/iter; left time: 813.7407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.03s\n",
      "Steps: 902 | Train Loss: 0.0825114 Vali Loss: 0.0833221 Test Loss: 0.0916651\n",
      "Validation loss decreased (0.085943 --> 0.083322).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764256\n",
      "\tspeed: 0.1463s/iter; left time: 2097.0479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827181\n",
      "\tspeed: 0.0561s/iter; left time: 798.3353s\n",
      "\titers: 300, epoch: 5 | loss: 0.0770537\n",
      "\tspeed: 0.0562s/iter; left time: 793.9174s\n",
      "\titers: 400, epoch: 5 | loss: 0.0778102\n",
      "\tspeed: 0.0559s/iter; left time: 784.5682s\n",
      "\titers: 500, epoch: 5 | loss: 0.0721894\n",
      "\tspeed: 0.0561s/iter; left time: 781.1088s\n",
      "\titers: 600, epoch: 5 | loss: 0.0764007\n",
      "\tspeed: 0.0560s/iter; left time: 774.4467s\n",
      "\titers: 700, epoch: 5 | loss: 0.0691320\n",
      "\tspeed: 0.0559s/iter; left time: 768.0472s\n",
      "\titers: 800, epoch: 5 | loss: 0.0760493\n",
      "\tspeed: 0.0558s/iter; left time: 761.1955s\n",
      "\titers: 900, epoch: 5 | loss: 0.0771307\n",
      "\tspeed: 0.0559s/iter; left time: 755.9139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.74s\n",
      "Steps: 902 | Train Loss: 0.0765282 Vali Loss: 0.0825140 Test Loss: 0.0960625\n",
      "Validation loss decreased (0.083322 --> 0.082514).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733467\n",
      "\tspeed: 0.1465s/iter; left time: 1968.2599s\n",
      "\titers: 200, epoch: 6 | loss: 0.0833497\n",
      "\tspeed: 0.0562s/iter; left time: 749.1821s\n",
      "\titers: 300, epoch: 6 | loss: 0.0659320\n",
      "\tspeed: 0.0563s/iter; left time: 745.2195s\n",
      "\titers: 400, epoch: 6 | loss: 0.0752067\n",
      "\tspeed: 0.0561s/iter; left time: 737.0589s\n",
      "\titers: 500, epoch: 6 | loss: 0.0670946\n",
      "\tspeed: 0.0561s/iter; left time: 730.5923s\n",
      "\titers: 600, epoch: 6 | loss: 0.0659085\n",
      "\tspeed: 0.0561s/iter; left time: 725.2654s\n",
      "\titers: 700, epoch: 6 | loss: 0.0690108\n",
      "\tspeed: 0.0560s/iter; left time: 718.3860s\n",
      "\titers: 800, epoch: 6 | loss: 0.0688048\n",
      "\tspeed: 0.0560s/iter; left time: 713.2835s\n",
      "\titers: 900, epoch: 6 | loss: 0.0649082\n",
      "\tspeed: 0.0561s/iter; left time: 709.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.88s\n",
      "Steps: 902 | Train Loss: 0.0723157 Vali Loss: 0.0812344 Test Loss: 0.0912931\n",
      "Validation loss decreased (0.082514 --> 0.081234).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0698899\n",
      "\tspeed: 0.1458s/iter; left time: 1827.2722s\n",
      "\titers: 200, epoch: 7 | loss: 0.0716284\n",
      "\tspeed: 0.0562s/iter; left time: 698.0201s\n",
      "\titers: 300, epoch: 7 | loss: 0.0637051\n",
      "\tspeed: 0.0561s/iter; left time: 691.8750s\n",
      "\titers: 400, epoch: 7 | loss: 0.0706311\n",
      "\tspeed: 0.0563s/iter; left time: 688.5692s\n",
      "\titers: 500, epoch: 7 | loss: 0.0664194\n",
      "\tspeed: 0.0561s/iter; left time: 680.8894s\n",
      "\titers: 600, epoch: 7 | loss: 0.0649761\n",
      "\tspeed: 0.0561s/iter; left time: 675.0067s\n",
      "\titers: 700, epoch: 7 | loss: 0.0629366\n",
      "\tspeed: 0.0564s/iter; left time: 672.6596s\n",
      "\titers: 800, epoch: 7 | loss: 0.0697752\n",
      "\tspeed: 0.0562s/iter; left time: 665.1676s\n",
      "\titers: 900, epoch: 7 | loss: 0.0735580\n",
      "\tspeed: 0.0561s/iter; left time: 657.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.89s\n",
      "Steps: 902 | Train Loss: 0.0686827 Vali Loss: 0.0833520 Test Loss: 0.0941525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0703419\n",
      "\tspeed: 0.1431s/iter; left time: 1663.3222s\n",
      "\titers: 200, epoch: 8 | loss: 0.0625026\n",
      "\tspeed: 0.0562s/iter; left time: 648.2392s\n",
      "\titers: 300, epoch: 8 | loss: 0.0712432\n",
      "\tspeed: 0.0562s/iter; left time: 642.2760s\n",
      "\titers: 400, epoch: 8 | loss: 0.0641110\n",
      "\tspeed: 0.0560s/iter; left time: 634.7619s\n",
      "\titers: 500, epoch: 8 | loss: 0.0694767\n",
      "\tspeed: 0.0563s/iter; left time: 631.8162s\n",
      "\titers: 600, epoch: 8 | loss: 0.0599983\n",
      "\tspeed: 0.0562s/iter; left time: 624.9191s\n",
      "\titers: 700, epoch: 8 | loss: 0.0687616\n",
      "\tspeed: 0.0565s/iter; left time: 622.7837s\n",
      "\titers: 800, epoch: 8 | loss: 0.0600453\n",
      "\tspeed: 0.0563s/iter; left time: 614.7592s\n",
      "\titers: 900, epoch: 8 | loss: 0.0677940\n",
      "\tspeed: 0.0566s/iter; left time: 613.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.98s\n",
      "Steps: 902 | Train Loss: 0.0655671 Vali Loss: 0.0839795 Test Loss: 0.0900842\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663990\n",
      "\tspeed: 0.1423s/iter; left time: 1526.2709s\n",
      "\titers: 200, epoch: 9 | loss: 0.0700266\n",
      "\tspeed: 0.0562s/iter; left time: 596.8418s\n",
      "\titers: 300, epoch: 9 | loss: 0.0685855\n",
      "\tspeed: 0.0561s/iter; left time: 590.1485s\n",
      "\titers: 400, epoch: 9 | loss: 0.0627696\n",
      "\tspeed: 0.0559s/iter; left time: 583.2508s\n",
      "\titers: 500, epoch: 9 | loss: 0.0606314\n",
      "\tspeed: 0.0562s/iter; left time: 580.5814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0609222\n",
      "\tspeed: 0.0563s/iter; left time: 575.5993s\n",
      "\titers: 700, epoch: 9 | loss: 0.0639502\n",
      "\tspeed: 0.0561s/iter; left time: 568.2043s\n",
      "\titers: 800, epoch: 9 | loss: 0.0614636\n",
      "\tspeed: 0.0560s/iter; left time: 561.1228s\n",
      "\titers: 900, epoch: 9 | loss: 0.0632209\n",
      "\tspeed: 0.0562s/iter; left time: 557.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.81s\n",
      "Steps: 902 | Train Loss: 0.0628933 Vali Loss: 0.0852688 Test Loss: 0.0914795\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632251\n",
      "\tspeed: 0.1426s/iter; left time: 1400.7899s\n",
      "\titers: 200, epoch: 10 | loss: 0.0626923\n",
      "\tspeed: 0.0564s/iter; left time: 547.9888s\n",
      "\titers: 300, epoch: 10 | loss: 0.0569981\n",
      "\tspeed: 0.0562s/iter; left time: 540.9485s\n",
      "\titers: 400, epoch: 10 | loss: 0.0590109\n",
      "\tspeed: 0.0559s/iter; left time: 532.3164s\n",
      "\titers: 500, epoch: 10 | loss: 0.0626045\n",
      "\tspeed: 0.0564s/iter; left time: 531.5922s\n",
      "\titers: 600, epoch: 10 | loss: 0.0582701\n",
      "\tspeed: 0.0563s/iter; left time: 524.6340s\n",
      "\titers: 700, epoch: 10 | loss: 0.0604766\n",
      "\tspeed: 0.0564s/iter; left time: 520.5509s\n",
      "\titers: 800, epoch: 10 | loss: 0.0553067\n",
      "\tspeed: 0.0571s/iter; left time: 520.9799s\n",
      "\titers: 900, epoch: 10 | loss: 0.0586292\n",
      "\tspeed: 0.0562s/iter; left time: 506.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:51.01s\n",
      "Steps: 902 | Train Loss: 0.0605744 Vali Loss: 0.0829987 Test Loss: 0.0921286\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603431\n",
      "\tspeed: 0.1427s/iter; left time: 1273.0521s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567945\n",
      "\tspeed: 0.0562s/iter; left time: 496.1430s\n",
      "\titers: 300, epoch: 11 | loss: 0.0575336\n",
      "\tspeed: 0.0561s/iter; left time: 489.2623s\n",
      "\titers: 400, epoch: 11 | loss: 0.0644362\n",
      "\tspeed: 0.0562s/iter; left time: 484.9027s\n",
      "\titers: 500, epoch: 11 | loss: 0.0663850\n",
      "\tspeed: 0.0564s/iter; left time: 480.8309s\n",
      "\titers: 600, epoch: 11 | loss: 0.0583964\n",
      "\tspeed: 0.0563s/iter; left time: 474.3476s\n",
      "\titers: 700, epoch: 11 | loss: 0.0622751\n",
      "\tspeed: 0.0564s/iter; left time: 469.0515s\n",
      "\titers: 800, epoch: 11 | loss: 0.0594868\n",
      "\tspeed: 0.0565s/iter; left time: 464.3133s\n",
      "\titers: 900, epoch: 11 | loss: 0.0596777\n",
      "\tspeed: 0.0563s/iter; left time: 456.9714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.00s\n",
      "Steps: 902 | Train Loss: 0.0582954 Vali Loss: 0.0849068 Test Loss: 0.0927532\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022102830931544304, rmse:0.14867021143436432, mae:0.09126447886228561, rse:0.5621380805969238\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2242611\n",
      "\tspeed: 0.0583s/iter; left time: 1046.2606s\n",
      "\titers: 200, epoch: 1 | loss: 0.2119186\n",
      "\tspeed: 0.0565s/iter; left time: 1007.2542s\n",
      "\titers: 300, epoch: 1 | loss: 0.2011974\n",
      "\tspeed: 0.0566s/iter; left time: 1004.3020s\n",
      "\titers: 400, epoch: 1 | loss: 0.2026695\n",
      "\tspeed: 0.0563s/iter; left time: 993.3728s\n",
      "\titers: 500, epoch: 1 | loss: 0.1947621\n",
      "\tspeed: 0.0561s/iter; left time: 984.7722s\n",
      "\titers: 600, epoch: 1 | loss: 0.2003413\n",
      "\tspeed: 0.0564s/iter; left time: 983.9245s\n",
      "\titers: 700, epoch: 1 | loss: 0.1878665\n",
      "\tspeed: 0.0564s/iter; left time: 977.5463s\n",
      "\titers: 800, epoch: 1 | loss: 0.1843780\n",
      "\tspeed: 0.0564s/iter; left time: 973.1621s\n",
      "\titers: 900, epoch: 1 | loss: 0.1817896\n",
      "\tspeed: 0.0563s/iter; left time: 965.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.12s\n",
      "Steps: 902 | Train Loss: 0.2044432 Vali Loss: 0.1684344 Test Loss: 0.1865782\n",
      "Validation loss decreased (inf --> 0.168434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1658706\n",
      "\tspeed: 0.1479s/iter; left time: 2519.8734s\n",
      "\titers: 200, epoch: 2 | loss: 0.1516571\n",
      "\tspeed: 0.0560s/iter; left time: 949.1051s\n",
      "\titers: 300, epoch: 2 | loss: 0.1385410\n",
      "\tspeed: 0.0563s/iter; left time: 948.7843s\n",
      "\titers: 400, epoch: 2 | loss: 0.1398681\n",
      "\tspeed: 0.0563s/iter; left time: 942.6144s\n",
      "\titers: 500, epoch: 2 | loss: 0.1415438\n",
      "\tspeed: 0.0560s/iter; left time: 932.2721s\n",
      "\titers: 600, epoch: 2 | loss: 0.1305475\n",
      "\tspeed: 0.0562s/iter; left time: 929.8528s\n",
      "\titers: 700, epoch: 2 | loss: 0.1114020\n",
      "\tspeed: 0.0561s/iter; left time: 922.8901s\n",
      "\titers: 800, epoch: 2 | loss: 0.1059992\n",
      "\tspeed: 0.0562s/iter; left time: 918.7391s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027744\n",
      "\tspeed: 0.0562s/iter; left time: 912.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.96s\n",
      "Steps: 902 | Train Loss: 0.1401448 Vali Loss: 0.1012840 Test Loss: 0.1069124\n",
      "Validation loss decreased (0.168434 --> 0.101284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930229\n",
      "\tspeed: 0.1496s/iter; left time: 2414.3117s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003591\n",
      "\tspeed: 0.0564s/iter; left time: 903.9577s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922170\n",
      "\tspeed: 0.0565s/iter; left time: 901.0922s\n",
      "\titers: 400, epoch: 3 | loss: 0.0894730\n",
      "\tspeed: 0.0565s/iter; left time: 894.5268s\n",
      "\titers: 500, epoch: 3 | loss: 0.0843980\n",
      "\tspeed: 0.0564s/iter; left time: 887.4088s\n",
      "\titers: 600, epoch: 3 | loss: 0.0861032\n",
      "\tspeed: 0.0566s/iter; left time: 884.6755s\n",
      "\titers: 700, epoch: 3 | loss: 0.0962278\n",
      "\tspeed: 0.0562s/iter; left time: 872.9713s\n",
      "\titers: 800, epoch: 3 | loss: 0.0844468\n",
      "\tspeed: 0.0562s/iter; left time: 868.0167s\n",
      "\titers: 900, epoch: 3 | loss: 0.0798998\n",
      "\tspeed: 0.0566s/iter; left time: 867.5488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.16s\n",
      "Steps: 902 | Train Loss: 0.0907258 Vali Loss: 0.0865435 Test Loss: 0.0928145\n",
      "Validation loss decreased (0.101284 --> 0.086543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826758\n",
      "\tspeed: 0.1487s/iter; left time: 2265.7305s\n",
      "\titers: 200, epoch: 4 | loss: 0.0822651\n",
      "\tspeed: 0.0564s/iter; left time: 853.4851s\n",
      "\titers: 300, epoch: 4 | loss: 0.0866301\n",
      "\tspeed: 0.0559s/iter; left time: 840.5407s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769262\n",
      "\tspeed: 0.0562s/iter; left time: 839.4976s\n",
      "\titers: 500, epoch: 4 | loss: 0.0888130\n",
      "\tspeed: 0.0564s/iter; left time: 837.2641s\n",
      "\titers: 600, epoch: 4 | loss: 0.0869355\n",
      "\tspeed: 0.0561s/iter; left time: 826.6202s\n",
      "\titers: 700, epoch: 4 | loss: 0.0818241\n",
      "\tspeed: 0.0562s/iter; left time: 822.7058s\n",
      "\titers: 800, epoch: 4 | loss: 0.0754548\n",
      "\tspeed: 0.0562s/iter; left time: 816.3180s\n",
      "\titers: 900, epoch: 4 | loss: 0.0746318\n",
      "\tspeed: 0.0561s/iter; left time: 809.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:50.92s\n",
      "Steps: 902 | Train Loss: 0.0822911 Vali Loss: 0.0834865 Test Loss: 0.0910495\n",
      "Validation loss decreased (0.086543 --> 0.083486).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0807130\n",
      "\tspeed: 0.1487s/iter; left time: 2131.6106s\n",
      "\titers: 200, epoch: 5 | loss: 0.0885034\n",
      "\tspeed: 0.0565s/iter; left time: 803.9462s\n",
      "\titers: 300, epoch: 5 | loss: 0.0832925\n",
      "\tspeed: 0.0562s/iter; left time: 794.1126s\n",
      "\titers: 400, epoch: 5 | loss: 0.0783903\n",
      "\tspeed: 0.0560s/iter; left time: 785.4224s\n",
      "\titers: 500, epoch: 5 | loss: 0.0690158\n",
      "\tspeed: 0.0562s/iter; left time: 783.1540s\n",
      "\titers: 600, epoch: 5 | loss: 0.0753161\n",
      "\tspeed: 0.0562s/iter; left time: 778.0616s\n",
      "\titers: 700, epoch: 5 | loss: 0.0729265\n",
      "\tspeed: 0.0563s/iter; left time: 772.4941s\n",
      "\titers: 800, epoch: 5 | loss: 0.0794189\n",
      "\tspeed: 0.0562s/iter; left time: 765.6419s\n",
      "\titers: 900, epoch: 5 | loss: 0.0734144\n",
      "\tspeed: 0.0562s/iter; left time: 760.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.99s\n",
      "Steps: 902 | Train Loss: 0.0760591 Vali Loss: 0.0843736 Test Loss: 0.0905285\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734898\n",
      "\tspeed: 0.1434s/iter; left time: 1926.0202s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756256\n",
      "\tspeed: 0.0561s/iter; left time: 747.5589s\n",
      "\titers: 300, epoch: 6 | loss: 0.0723495\n",
      "\tspeed: 0.0559s/iter; left time: 740.1631s\n",
      "\titers: 400, epoch: 6 | loss: 0.0718728\n",
      "\tspeed: 0.0563s/iter; left time: 739.2278s\n",
      "\titers: 500, epoch: 6 | loss: 0.0720919\n",
      "\tspeed: 0.0560s/iter; left time: 729.4004s\n",
      "\titers: 600, epoch: 6 | loss: 0.0741957\n",
      "\tspeed: 0.0563s/iter; left time: 727.9752s\n",
      "\titers: 700, epoch: 6 | loss: 0.0747015\n",
      "\tspeed: 0.0561s/iter; left time: 719.3194s\n",
      "\titers: 800, epoch: 6 | loss: 0.0694396\n",
      "\tspeed: 0.0560s/iter; left time: 713.2069s\n",
      "\titers: 900, epoch: 6 | loss: 0.0666835\n",
      "\tspeed: 0.0560s/iter; left time: 707.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:50.84s\n",
      "Steps: 902 | Train Loss: 0.0721327 Vali Loss: 0.0836030 Test Loss: 0.0920231\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695805\n",
      "\tspeed: 0.1445s/iter; left time: 1810.1191s\n",
      "\titers: 200, epoch: 7 | loss: 0.0731486\n",
      "\tspeed: 0.0561s/iter; left time: 697.0216s\n",
      "\titers: 300, epoch: 7 | loss: 0.0675649\n",
      "\tspeed: 0.0560s/iter; left time: 689.9042s\n",
      "\titers: 400, epoch: 7 | loss: 0.0659579\n",
      "\tspeed: 0.0562s/iter; left time: 687.8208s\n",
      "\titers: 500, epoch: 7 | loss: 0.0706826\n",
      "\tspeed: 0.0561s/iter; left time: 680.4963s\n",
      "\titers: 600, epoch: 7 | loss: 0.0635315\n",
      "\tspeed: 0.0562s/iter; left time: 675.6219s\n",
      "\titers: 700, epoch: 7 | loss: 0.0688694\n",
      "\tspeed: 0.0563s/iter; left time: 671.2283s\n",
      "\titers: 800, epoch: 7 | loss: 0.0599420\n",
      "\tspeed: 0.0564s/iter; left time: 666.7138s\n",
      "\titers: 900, epoch: 7 | loss: 0.0662823\n",
      "\tspeed: 0.0563s/iter; left time: 660.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.96s\n",
      "Steps: 902 | Train Loss: 0.0682621 Vali Loss: 0.0836893 Test Loss: 0.0946293\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0667579\n",
      "\tspeed: 0.1444s/iter; left time: 1678.5261s\n",
      "\titers: 200, epoch: 8 | loss: 0.0635563\n",
      "\tspeed: 0.0565s/iter; left time: 651.4258s\n",
      "\titers: 300, epoch: 8 | loss: 0.0671627\n",
      "\tspeed: 0.0564s/iter; left time: 643.9314s\n",
      "\titers: 400, epoch: 8 | loss: 0.0628446\n",
      "\tspeed: 0.0563s/iter; left time: 637.4019s\n",
      "\titers: 500, epoch: 8 | loss: 0.0688052\n",
      "\tspeed: 0.0562s/iter; left time: 631.3072s\n",
      "\titers: 600, epoch: 8 | loss: 0.0618176\n",
      "\tspeed: 0.0561s/iter; left time: 624.3212s\n",
      "\titers: 700, epoch: 8 | loss: 0.0720944\n",
      "\tspeed: 0.0561s/iter; left time: 618.6893s\n",
      "\titers: 800, epoch: 8 | loss: 0.0660118\n",
      "\tspeed: 0.0564s/iter; left time: 616.6174s\n",
      "\titers: 900, epoch: 8 | loss: 0.0657591\n",
      "\tspeed: 0.0562s/iter; left time: 608.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:51.02s\n",
      "Steps: 902 | Train Loss: 0.0653339 Vali Loss: 0.0831402 Test Loss: 0.0908945\n",
      "Validation loss decreased (0.083486 --> 0.083140).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606326\n",
      "\tspeed: 0.1464s/iter; left time: 1570.0944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0589722\n",
      "\tspeed: 0.0561s/iter; left time: 595.8757s\n",
      "\titers: 300, epoch: 9 | loss: 0.0678373\n",
      "\tspeed: 0.0562s/iter; left time: 591.4854s\n",
      "\titers: 400, epoch: 9 | loss: 0.0590255\n",
      "\tspeed: 0.0561s/iter; left time: 584.8119s\n",
      "\titers: 500, epoch: 9 | loss: 0.0596709\n",
      "\tspeed: 0.0562s/iter; left time: 580.6005s\n",
      "\titers: 600, epoch: 9 | loss: 0.0645740\n",
      "\tspeed: 0.0561s/iter; left time: 574.0632s\n",
      "\titers: 700, epoch: 9 | loss: 0.0607777\n",
      "\tspeed: 0.0563s/iter; left time: 570.2240s\n",
      "\titers: 800, epoch: 9 | loss: 0.0607566\n",
      "\tspeed: 0.0562s/iter; left time: 563.5586s\n",
      "\titers: 900, epoch: 9 | loss: 0.0590329\n",
      "\tspeed: 0.0561s/iter; left time: 556.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:50.94s\n",
      "Steps: 902 | Train Loss: 0.0625768 Vali Loss: 0.0859326 Test Loss: 0.0974187\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0551467\n",
      "\tspeed: 0.1441s/iter; left time: 1415.3412s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589132\n",
      "\tspeed: 0.0561s/iter; left time: 545.0131s\n",
      "\titers: 300, epoch: 10 | loss: 0.0641689\n",
      "\tspeed: 0.0562s/iter; left time: 541.1471s\n",
      "\titers: 400, epoch: 10 | loss: 0.0612116\n",
      "\tspeed: 0.0561s/iter; left time: 534.2106s\n",
      "\titers: 500, epoch: 10 | loss: 0.0636943\n",
      "\tspeed: 0.0562s/iter; left time: 529.3773s\n",
      "\titers: 600, epoch: 10 | loss: 0.0582099\n",
      "\tspeed: 0.0562s/iter; left time: 523.6021s\n",
      "\titers: 700, epoch: 10 | loss: 0.0593094\n",
      "\tspeed: 0.0561s/iter; left time: 517.4983s\n",
      "\titers: 800, epoch: 10 | loss: 0.0621365\n",
      "\tspeed: 0.0563s/iter; left time: 513.5478s\n",
      "\titers: 900, epoch: 10 | loss: 0.0586506\n",
      "\tspeed: 0.0559s/iter; left time: 504.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:50.85s\n",
      "Steps: 902 | Train Loss: 0.0602042 Vali Loss: 0.0842899 Test Loss: 0.0953909\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0584611\n",
      "\tspeed: 0.1441s/iter; left time: 1285.4098s\n",
      "\titers: 200, epoch: 11 | loss: 0.0607726\n",
      "\tspeed: 0.0558s/iter; left time: 492.0047s\n",
      "\titers: 300, epoch: 11 | loss: 0.0594198\n",
      "\tspeed: 0.0565s/iter; left time: 492.7672s\n",
      "\titers: 400, epoch: 11 | loss: 0.0550552\n",
      "\tspeed: 0.0563s/iter; left time: 485.3209s\n",
      "\titers: 500, epoch: 11 | loss: 0.0553763\n",
      "\tspeed: 0.0560s/iter; left time: 477.0779s\n",
      "\titers: 600, epoch: 11 | loss: 0.0570028\n",
      "\tspeed: 0.0560s/iter; left time: 471.3781s\n",
      "\titers: 700, epoch: 11 | loss: 0.0562664\n",
      "\tspeed: 0.0562s/iter; left time: 467.6395s\n",
      "\titers: 800, epoch: 11 | loss: 0.0542699\n",
      "\tspeed: 0.0562s/iter; left time: 462.2411s\n",
      "\titers: 900, epoch: 11 | loss: 0.0540128\n",
      "\tspeed: 0.0563s/iter; left time: 456.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.92s\n",
      "Steps: 902 | Train Loss: 0.0579487 Vali Loss: 0.0840031 Test Loss: 0.0952512\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0564515\n",
      "\tspeed: 0.1435s/iter; left time: 1150.7165s\n",
      "\titers: 200, epoch: 12 | loss: 0.0568600\n",
      "\tspeed: 0.0561s/iter; left time: 444.6259s\n",
      "\titers: 300, epoch: 12 | loss: 0.0515221\n",
      "\tspeed: 0.0561s/iter; left time: 438.9790s\n",
      "\titers: 400, epoch: 12 | loss: 0.0542253\n",
      "\tspeed: 0.0561s/iter; left time: 433.0143s\n",
      "\titers: 500, epoch: 12 | loss: 0.0633933\n",
      "\tspeed: 0.0561s/iter; left time: 427.2309s\n",
      "\titers: 600, epoch: 12 | loss: 0.0538624\n",
      "\tspeed: 0.0564s/iter; left time: 423.8113s\n",
      "\titers: 700, epoch: 12 | loss: 0.0549300\n",
      "\tspeed: 0.0561s/iter; left time: 416.0481s\n",
      "\titers: 800, epoch: 12 | loss: 0.0549908\n",
      "\tspeed: 0.0562s/iter; left time: 411.4904s\n",
      "\titers: 900, epoch: 12 | loss: 0.0552863\n",
      "\tspeed: 0.0562s/iter; left time: 405.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:50.89s\n",
      "Steps: 902 | Train Loss: 0.0559169 Vali Loss: 0.0848529 Test Loss: 0.0933341\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0565964\n",
      "\tspeed: 0.1435s/iter; left time: 1021.3680s\n",
      "\titers: 200, epoch: 13 | loss: 0.0560172\n",
      "\tspeed: 0.0561s/iter; left time: 393.4526s\n",
      "\titers: 300, epoch: 13 | loss: 0.0519472\n",
      "\tspeed: 0.0562s/iter; left time: 388.6143s\n",
      "\titers: 400, epoch: 13 | loss: 0.0506765\n",
      "\tspeed: 0.0563s/iter; left time: 384.0357s\n",
      "\titers: 500, epoch: 13 | loss: 0.0514573\n",
      "\tspeed: 0.0563s/iter; left time: 378.4678s\n",
      "\titers: 600, epoch: 13 | loss: 0.0547833\n",
      "\tspeed: 0.0562s/iter; left time: 372.0780s\n",
      "\titers: 700, epoch: 13 | loss: 0.0553436\n",
      "\tspeed: 0.0561s/iter; left time: 365.4666s\n",
      "\titers: 800, epoch: 13 | loss: 0.0489026\n",
      "\tspeed: 0.0563s/iter; left time: 361.0483s\n",
      "\titers: 900, epoch: 13 | loss: 0.0522416\n",
      "\tspeed: 0.0562s/iter; left time: 355.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:50.94s\n",
      "Steps: 902 | Train Loss: 0.0542790 Vali Loss: 0.0850339 Test Loss: 0.0930379\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_Informer_custom_ftM_sl168_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022342106327414513, rmse:0.14947275817394257, mae:0.0909552201628685, rse:0.5651726126670837\n",
      "Intermediate time for IT and pred_len 96: 00h:24m:12.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2354850\n",
      "\tspeed: 0.0898s/iter; left time: 1607.9484s\n",
      "\titers: 200, epoch: 1 | loss: 0.2147503\n",
      "\tspeed: 0.0598s/iter; left time: 1064.5785s\n",
      "\titers: 300, epoch: 1 | loss: 0.2008932\n",
      "\tspeed: 0.0595s/iter; left time: 1054.0454s\n",
      "\titers: 400, epoch: 1 | loss: 0.2055629\n",
      "\tspeed: 0.0580s/iter; left time: 1021.0031s\n",
      "\titers: 500, epoch: 1 | loss: 0.2015738\n",
      "\tspeed: 0.0583s/iter; left time: 1020.7411s\n",
      "\titers: 600, epoch: 1 | loss: 0.1937020\n",
      "\tspeed: 0.0584s/iter; left time: 1015.7053s\n",
      "\titers: 700, epoch: 1 | loss: 0.1945130\n",
      "\tspeed: 0.0627s/iter; left time: 1084.1573s\n",
      "\titers: 800, epoch: 1 | loss: 0.1981127\n",
      "\tspeed: 0.0640s/iter; left time: 1100.3500s\n",
      "\titers: 900, epoch: 1 | loss: 0.1916752\n",
      "\tspeed: 0.0615s/iter; left time: 1051.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.20s\n",
      "Steps: 900 | Train Loss: 0.2081726 Vali Loss: 0.1750176 Test Loss: 0.1928654\n",
      "Validation loss decreased (inf --> 0.175018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1755615\n",
      "\tspeed: 0.1670s/iter; left time: 2839.2090s\n",
      "\titers: 200, epoch: 2 | loss: 0.1610037\n",
      "\tspeed: 0.0634s/iter; left time: 1071.5445s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492868\n",
      "\tspeed: 0.0630s/iter; left time: 1058.7845s\n",
      "\titers: 400, epoch: 2 | loss: 0.1410785\n",
      "\tspeed: 0.0630s/iter; left time: 1052.9148s\n",
      "\titers: 500, epoch: 2 | loss: 0.1400093\n",
      "\tspeed: 0.0636s/iter; left time: 1056.6128s\n",
      "\titers: 600, epoch: 2 | loss: 0.1329311\n",
      "\tspeed: 0.0643s/iter; left time: 1060.9018s\n",
      "\titers: 700, epoch: 2 | loss: 0.1216747\n",
      "\tspeed: 0.0641s/iter; left time: 1051.9717s\n",
      "\titers: 800, epoch: 2 | loss: 0.1252876\n",
      "\tspeed: 0.0641s/iter; left time: 1045.6520s\n",
      "\titers: 900, epoch: 2 | loss: 0.1244262\n",
      "\tspeed: 0.0642s/iter; left time: 1039.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:57.53s\n",
      "Steps: 900 | Train Loss: 0.1464363 Vali Loss: 0.1188062 Test Loss: 0.1284537\n",
      "Validation loss decreased (0.175018 --> 0.118806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1027636\n",
      "\tspeed: 0.1670s/iter; left time: 2689.1175s\n",
      "\titers: 200, epoch: 3 | loss: 0.1025386\n",
      "\tspeed: 0.0625s/iter; left time: 1000.7876s\n",
      "\titers: 300, epoch: 3 | loss: 0.0942330\n",
      "\tspeed: 0.0631s/iter; left time: 1003.2582s\n",
      "\titers: 400, epoch: 3 | loss: 0.0954158\n",
      "\tspeed: 0.0639s/iter; left time: 1010.3892s\n",
      "\titers: 500, epoch: 3 | loss: 0.0912313\n",
      "\tspeed: 0.0631s/iter; left time: 990.1175s\n",
      "\titers: 600, epoch: 3 | loss: 0.0918813\n",
      "\tspeed: 0.0629s/iter; left time: 981.1655s\n",
      "\titers: 700, epoch: 3 | loss: 0.0892835\n",
      "\tspeed: 0.0618s/iter; left time: 958.6229s\n",
      "\titers: 800, epoch: 3 | loss: 0.0978737\n",
      "\tspeed: 0.0618s/iter; left time: 951.4752s\n",
      "\titers: 900, epoch: 3 | loss: 0.0864867\n",
      "\tspeed: 0.0644s/iter; left time: 985.2587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:56.93s\n",
      "Steps: 900 | Train Loss: 0.0981032 Vali Loss: 0.0898382 Test Loss: 0.0998314\n",
      "Validation loss decreased (0.118806 --> 0.089838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0924151\n",
      "\tspeed: 0.1666s/iter; left time: 2532.7074s\n",
      "\titers: 200, epoch: 4 | loss: 0.0849239\n",
      "\tspeed: 0.0627s/iter; left time: 947.5143s\n",
      "\titers: 300, epoch: 4 | loss: 0.0928083\n",
      "\tspeed: 0.0624s/iter; left time: 935.7710s\n",
      "\titers: 400, epoch: 4 | loss: 0.0960509\n",
      "\tspeed: 0.0638s/iter; left time: 951.0950s\n",
      "\titers: 500, epoch: 4 | loss: 0.0850107\n",
      "\tspeed: 0.0634s/iter; left time: 938.3724s\n",
      "\titers: 600, epoch: 4 | loss: 0.0838645\n",
      "\tspeed: 0.0634s/iter; left time: 932.7726s\n",
      "\titers: 700, epoch: 4 | loss: 0.0889425\n",
      "\tspeed: 0.0635s/iter; left time: 927.1905s\n",
      "\titers: 800, epoch: 4 | loss: 0.0788522\n",
      "\tspeed: 0.0632s/iter; left time: 916.4177s\n",
      "\titers: 900, epoch: 4 | loss: 0.0952446\n",
      "\tspeed: 0.0626s/iter; left time: 901.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:57.00s\n",
      "Steps: 900 | Train Loss: 0.0878329 Vali Loss: 0.0867684 Test Loss: 0.0978600\n",
      "Validation loss decreased (0.089838 --> 0.086768).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803263\n",
      "\tspeed: 0.1660s/iter; left time: 2373.6225s\n",
      "\titers: 200, epoch: 5 | loss: 0.0840225\n",
      "\tspeed: 0.0634s/iter; left time: 900.0842s\n",
      "\titers: 300, epoch: 5 | loss: 0.0835993\n",
      "\tspeed: 0.0617s/iter; left time: 869.7468s\n",
      "\titers: 400, epoch: 5 | loss: 0.0892021\n",
      "\tspeed: 0.0630s/iter; left time: 881.5119s\n",
      "\titers: 500, epoch: 5 | loss: 0.0832908\n",
      "\tspeed: 0.0625s/iter; left time: 868.5043s\n",
      "\titers: 600, epoch: 5 | loss: 0.0743278\n",
      "\tspeed: 0.0622s/iter; left time: 858.5802s\n",
      "\titers: 700, epoch: 5 | loss: 0.0753815\n",
      "\tspeed: 0.0626s/iter; left time: 857.2573s\n",
      "\titers: 800, epoch: 5 | loss: 0.0795464\n",
      "\tspeed: 0.0642s/iter; left time: 873.6234s\n",
      "\titers: 900, epoch: 5 | loss: 0.0814751\n",
      "\tspeed: 0.0640s/iter; left time: 863.5516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.82s\n",
      "Steps: 900 | Train Loss: 0.0812328 Vali Loss: 0.0880703 Test Loss: 0.0987538\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768563\n",
      "\tspeed: 0.1640s/iter; left time: 2197.1934s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821650\n",
      "\tspeed: 0.0647s/iter; left time: 861.2270s\n",
      "\titers: 300, epoch: 6 | loss: 0.0764931\n",
      "\tspeed: 0.0648s/iter; left time: 855.4489s\n",
      "\titers: 400, epoch: 6 | loss: 0.0748489\n",
      "\tspeed: 0.0642s/iter; left time: 841.4577s\n",
      "\titers: 500, epoch: 6 | loss: 0.0790392\n",
      "\tspeed: 0.0655s/iter; left time: 852.1673s\n",
      "\titers: 600, epoch: 6 | loss: 0.0751216\n",
      "\tspeed: 0.0642s/iter; left time: 828.7579s\n",
      "\titers: 700, epoch: 6 | loss: 0.0691384\n",
      "\tspeed: 0.0634s/iter; left time: 812.0639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0723839\n",
      "\tspeed: 0.0624s/iter; left time: 792.4768s\n",
      "\titers: 900, epoch: 6 | loss: 0.0733099\n",
      "\tspeed: 0.0617s/iter; left time: 777.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:57.66s\n",
      "Steps: 900 | Train Loss: 0.0761173 Vali Loss: 0.0890236 Test Loss: 0.0994114\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0740982\n",
      "\tspeed: 0.1637s/iter; left time: 2046.0806s\n",
      "\titers: 200, epoch: 7 | loss: 0.0704037\n",
      "\tspeed: 0.0628s/iter; left time: 779.1309s\n",
      "\titers: 300, epoch: 7 | loss: 0.0737133\n",
      "\tspeed: 0.0640s/iter; left time: 787.1748s\n",
      "\titers: 400, epoch: 7 | loss: 0.0725173\n",
      "\tspeed: 0.0637s/iter; left time: 777.5030s\n",
      "\titers: 500, epoch: 7 | loss: 0.0722179\n",
      "\tspeed: 0.0620s/iter; left time: 749.9948s\n",
      "\titers: 600, epoch: 7 | loss: 0.0780062\n",
      "\tspeed: 0.0620s/iter; left time: 743.7303s\n",
      "\titers: 700, epoch: 7 | loss: 0.0699945\n",
      "\tspeed: 0.0618s/iter; left time: 735.7352s\n",
      "\titers: 800, epoch: 7 | loss: 0.0675986\n",
      "\tspeed: 0.0620s/iter; left time: 731.1684s\n",
      "\titers: 900, epoch: 7 | loss: 0.0723994\n",
      "\tspeed: 0.0628s/iter; left time: 734.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:56.63s\n",
      "Steps: 900 | Train Loss: 0.0718566 Vali Loss: 0.0899155 Test Loss: 0.1002488\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0712975\n",
      "\tspeed: 0.1650s/iter; left time: 1914.2649s\n",
      "\titers: 200, epoch: 8 | loss: 0.0652685\n",
      "\tspeed: 0.0612s/iter; left time: 704.4053s\n",
      "\titers: 300, epoch: 8 | loss: 0.0679428\n",
      "\tspeed: 0.0620s/iter; left time: 706.5307s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708201\n",
      "\tspeed: 0.0619s/iter; left time: 699.1922s\n",
      "\titers: 500, epoch: 8 | loss: 0.0614072\n",
      "\tspeed: 0.0633s/iter; left time: 708.6055s\n",
      "\titers: 600, epoch: 8 | loss: 0.0678461\n",
      "\tspeed: 0.0633s/iter; left time: 702.8472s\n",
      "\titers: 700, epoch: 8 | loss: 0.0706128\n",
      "\tspeed: 0.0636s/iter; left time: 700.1819s\n",
      "\titers: 800, epoch: 8 | loss: 0.0673409\n",
      "\tspeed: 0.0626s/iter; left time: 682.4778s\n",
      "\titers: 900, epoch: 8 | loss: 0.0690730\n",
      "\tspeed: 0.0645s/iter; left time: 696.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.89s\n",
      "Steps: 900 | Train Loss: 0.0681586 Vali Loss: 0.0901233 Test Loss: 0.1005046\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0637906\n",
      "\tspeed: 0.1626s/iter; left time: 1739.8253s\n",
      "\titers: 200, epoch: 9 | loss: 0.0621240\n",
      "\tspeed: 0.0622s/iter; left time: 659.2240s\n",
      "\titers: 300, epoch: 9 | loss: 0.0660396\n",
      "\tspeed: 0.0628s/iter; left time: 659.6446s\n",
      "\titers: 400, epoch: 9 | loss: 0.0630083\n",
      "\tspeed: 0.0625s/iter; left time: 650.4191s\n",
      "\titers: 500, epoch: 9 | loss: 0.0657480\n",
      "\tspeed: 0.0635s/iter; left time: 654.4189s\n",
      "\titers: 600, epoch: 9 | loss: 0.0621996\n",
      "\tspeed: 0.0622s/iter; left time: 634.8985s\n",
      "\titers: 700, epoch: 9 | loss: 0.0644874\n",
      "\tspeed: 0.0637s/iter; left time: 643.4925s\n",
      "\titers: 800, epoch: 9 | loss: 0.0639477\n",
      "\tspeed: 0.0633s/iter; left time: 633.5119s\n",
      "\titers: 900, epoch: 9 | loss: 0.0662383\n",
      "\tspeed: 0.0624s/iter; left time: 617.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:56.79s\n",
      "Steps: 900 | Train Loss: 0.0649267 Vali Loss: 0.0911183 Test Loss: 0.1009968\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022543294355273247, rmse:0.15014424920082092, mae:0.09787493199110031, rse:0.5681037902832031\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2270696\n",
      "\tspeed: 0.0655s/iter; left time: 1172.6958s\n",
      "\titers: 200, epoch: 1 | loss: 0.2230852\n",
      "\tspeed: 0.0639s/iter; left time: 1137.7309s\n",
      "\titers: 300, epoch: 1 | loss: 0.2129304\n",
      "\tspeed: 0.0623s/iter; left time: 1102.0751s\n",
      "\titers: 400, epoch: 1 | loss: 0.2161908\n",
      "\tspeed: 0.0629s/iter; left time: 1106.7740s\n",
      "\titers: 500, epoch: 1 | loss: 0.2158946\n",
      "\tspeed: 0.0651s/iter; left time: 1139.4935s\n",
      "\titers: 600, epoch: 1 | loss: 0.2038420\n",
      "\tspeed: 0.0642s/iter; left time: 1117.4762s\n",
      "\titers: 700, epoch: 1 | loss: 0.1978863\n",
      "\tspeed: 0.0631s/iter; left time: 1092.0832s\n",
      "\titers: 800, epoch: 1 | loss: 0.1918117\n",
      "\tspeed: 0.0623s/iter; left time: 1071.2678s\n",
      "\titers: 900, epoch: 1 | loss: 0.1909406\n",
      "\tspeed: 0.0630s/iter; left time: 1077.3072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:57.31s\n",
      "Steps: 900 | Train Loss: 0.2121125 Vali Loss: 0.1788419 Test Loss: 0.1975866\n",
      "Validation loss decreased (inf --> 0.178842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1744377\n",
      "\tspeed: 0.1675s/iter; left time: 2846.9089s\n",
      "\titers: 200, epoch: 2 | loss: 0.1687494\n",
      "\tspeed: 0.0638s/iter; left time: 1078.5755s\n",
      "\titers: 300, epoch: 2 | loss: 0.1601137\n",
      "\tspeed: 0.0642s/iter; left time: 1079.0122s\n",
      "\titers: 400, epoch: 2 | loss: 0.1531834\n",
      "\tspeed: 0.0643s/iter; left time: 1073.4692s\n",
      "\titers: 500, epoch: 2 | loss: 0.1478471\n",
      "\tspeed: 0.0647s/iter; left time: 1073.6394s\n",
      "\titers: 600, epoch: 2 | loss: 0.1546510\n",
      "\tspeed: 0.0649s/iter; left time: 1070.9383s\n",
      "\titers: 700, epoch: 2 | loss: 0.1380949\n",
      "\tspeed: 0.0647s/iter; left time: 1061.7709s\n",
      "\titers: 800, epoch: 2 | loss: 0.1367598\n",
      "\tspeed: 0.0648s/iter; left time: 1056.7021s\n",
      "\titers: 900, epoch: 2 | loss: 0.1290002\n",
      "\tspeed: 0.0641s/iter; left time: 1038.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:58.17s\n",
      "Steps: 900 | Train Loss: 0.1564023 Vali Loss: 0.1311038 Test Loss: 0.1447971\n",
      "Validation loss decreased (0.178842 --> 0.131104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1290655\n",
      "\tspeed: 0.1711s/iter; left time: 2755.1409s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017660\n",
      "\tspeed: 0.0626s/iter; left time: 1001.9291s\n",
      "\titers: 300, epoch: 3 | loss: 0.1115754\n",
      "\tspeed: 0.0619s/iter; left time: 985.0202s\n",
      "\titers: 400, epoch: 3 | loss: 0.0959266\n",
      "\tspeed: 0.0622s/iter; left time: 982.9032s\n",
      "\titers: 500, epoch: 3 | loss: 0.1074370\n",
      "\tspeed: 0.0636s/iter; left time: 998.1022s\n",
      "\titers: 600, epoch: 3 | loss: 0.0959305\n",
      "\tspeed: 0.0633s/iter; left time: 986.8924s\n",
      "\titers: 700, epoch: 3 | loss: 0.0966646\n",
      "\tspeed: 0.0651s/iter; left time: 1009.8462s\n",
      "\titers: 800, epoch: 3 | loss: 0.0923713\n",
      "\tspeed: 0.0634s/iter; left time: 976.4292s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931485\n",
      "\tspeed: 0.0626s/iter; left time: 957.7714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:57.26s\n",
      "Steps: 900 | Train Loss: 0.1015458 Vali Loss: 0.0911401 Test Loss: 0.1012839\n",
      "Validation loss decreased (0.131104 --> 0.091140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0955652\n",
      "\tspeed: 0.1676s/iter; left time: 2546.9778s\n",
      "\titers: 200, epoch: 4 | loss: 0.0928969\n",
      "\tspeed: 0.0640s/iter; left time: 967.1860s\n",
      "\titers: 300, epoch: 4 | loss: 0.0864414\n",
      "\tspeed: 0.0644s/iter; left time: 965.6950s\n",
      "\titers: 400, epoch: 4 | loss: 0.0865208\n",
      "\tspeed: 0.0638s/iter; left time: 950.9662s\n",
      "\titers: 500, epoch: 4 | loss: 0.0854591\n",
      "\tspeed: 0.0623s/iter; left time: 921.9449s\n",
      "\titers: 600, epoch: 4 | loss: 0.0875213\n",
      "\tspeed: 0.0631s/iter; left time: 928.3588s\n",
      "\titers: 700, epoch: 4 | loss: 0.0879745\n",
      "\tspeed: 0.0626s/iter; left time: 913.6673s\n",
      "\titers: 800, epoch: 4 | loss: 0.0889824\n",
      "\tspeed: 0.0619s/iter; left time: 897.1050s\n",
      "\titers: 900, epoch: 4 | loss: 0.0853724\n",
      "\tspeed: 0.0624s/iter; left time: 898.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:57.01s\n",
      "Steps: 900 | Train Loss: 0.0884457 Vali Loss: 0.0890288 Test Loss: 0.1008908\n",
      "Validation loss decreased (0.091140 --> 0.089029).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0828815\n",
      "\tspeed: 0.1666s/iter; left time: 2382.6684s\n",
      "\titers: 200, epoch: 5 | loss: 0.0799549\n",
      "\tspeed: 0.0633s/iter; left time: 898.3104s\n",
      "\titers: 300, epoch: 5 | loss: 0.0809719\n",
      "\tspeed: 0.0637s/iter; left time: 897.9718s\n",
      "\titers: 400, epoch: 5 | loss: 0.0804424\n",
      "\tspeed: 0.0640s/iter; left time: 896.3662s\n",
      "\titers: 500, epoch: 5 | loss: 0.0810230\n",
      "\tspeed: 0.0627s/iter; left time: 872.0389s\n",
      "\titers: 600, epoch: 5 | loss: 0.0836331\n",
      "\tspeed: 0.0620s/iter; left time: 855.4674s\n",
      "\titers: 700, epoch: 5 | loss: 0.0832831\n",
      "\tspeed: 0.0618s/iter; left time: 847.0924s\n",
      "\titers: 800, epoch: 5 | loss: 0.0821871\n",
      "\tspeed: 0.0632s/iter; left time: 859.2167s\n",
      "\titers: 900, epoch: 5 | loss: 0.0827163\n",
      "\tspeed: 0.0635s/iter; left time: 857.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.94s\n",
      "Steps: 900 | Train Loss: 0.0822569 Vali Loss: 0.0869446 Test Loss: 0.0977937\n",
      "Validation loss decreased (0.089029 --> 0.086945).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0753034\n",
      "\tspeed: 0.1715s/iter; left time: 2298.7922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837929\n",
      "\tspeed: 0.0641s/iter; left time: 852.6062s\n",
      "\titers: 300, epoch: 6 | loss: 0.0778363\n",
      "\tspeed: 0.0635s/iter; left time: 838.0692s\n",
      "\titers: 400, epoch: 6 | loss: 0.0729796\n",
      "\tspeed: 0.0643s/iter; left time: 842.3492s\n",
      "\titers: 500, epoch: 6 | loss: 0.0760988\n",
      "\tspeed: 0.0640s/iter; left time: 832.5415s\n",
      "\titers: 600, epoch: 6 | loss: 0.0728167\n",
      "\tspeed: 0.0635s/iter; left time: 818.7797s\n",
      "\titers: 700, epoch: 6 | loss: 0.0777531\n",
      "\tspeed: 0.0634s/iter; left time: 811.1666s\n",
      "\titers: 800, epoch: 6 | loss: 0.0770301\n",
      "\tspeed: 0.0660s/iter; left time: 838.0555s\n",
      "\titers: 900, epoch: 6 | loss: 0.0749996\n",
      "\tspeed: 0.0641s/iter; left time: 807.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:58.01s\n",
      "Steps: 900 | Train Loss: 0.0771250 Vali Loss: 0.0876575 Test Loss: 0.1000345\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0733282\n",
      "\tspeed: 0.1664s/iter; left time: 2079.6701s\n",
      "\titers: 200, epoch: 7 | loss: 0.0715773\n",
      "\tspeed: 0.0637s/iter; left time: 789.7716s\n",
      "\titers: 300, epoch: 7 | loss: 0.0729310\n",
      "\tspeed: 0.0649s/iter; left time: 798.1047s\n",
      "\titers: 400, epoch: 7 | loss: 0.0691222\n",
      "\tspeed: 0.0656s/iter; left time: 800.1369s\n",
      "\titers: 500, epoch: 7 | loss: 0.0746833\n",
      "\tspeed: 0.0632s/iter; left time: 764.2230s\n",
      "\titers: 600, epoch: 7 | loss: 0.0715669\n",
      "\tspeed: 0.0644s/iter; left time: 772.3128s\n",
      "\titers: 700, epoch: 7 | loss: 0.0749784\n",
      "\tspeed: 0.0649s/iter; left time: 772.2320s\n",
      "\titers: 800, epoch: 7 | loss: 0.0667086\n",
      "\tspeed: 0.0664s/iter; left time: 784.0103s\n",
      "\titers: 900, epoch: 7 | loss: 0.0675611\n",
      "\tspeed: 0.0651s/iter; left time: 761.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:58.54s\n",
      "Steps: 900 | Train Loss: 0.0727086 Vali Loss: 0.0897830 Test Loss: 0.1026342\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0688337\n",
      "\tspeed: 0.1639s/iter; left time: 1901.6585s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691359\n",
      "\tspeed: 0.0633s/iter; left time: 728.0951s\n",
      "\titers: 300, epoch: 8 | loss: 0.0718678\n",
      "\tspeed: 0.0651s/iter; left time: 741.8215s\n",
      "\titers: 400, epoch: 8 | loss: 0.0681092\n",
      "\tspeed: 0.0652s/iter; left time: 736.3070s\n",
      "\titers: 500, epoch: 8 | loss: 0.0689357\n",
      "\tspeed: 0.0640s/iter; left time: 716.4798s\n",
      "\titers: 600, epoch: 8 | loss: 0.0686972\n",
      "\tspeed: 0.0628s/iter; left time: 697.5830s\n",
      "\titers: 700, epoch: 8 | loss: 0.0732154\n",
      "\tspeed: 0.0609s/iter; left time: 670.3373s\n",
      "\titers: 800, epoch: 8 | loss: 0.0703904\n",
      "\tspeed: 0.0609s/iter; left time: 663.4273s\n",
      "\titers: 900, epoch: 8 | loss: 0.0667317\n",
      "\tspeed: 0.0621s/iter; left time: 670.7204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.88s\n",
      "Steps: 900 | Train Loss: 0.0691280 Vali Loss: 0.0919902 Test Loss: 0.1022894\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0658195\n",
      "\tspeed: 0.1655s/iter; left time: 1771.3862s\n",
      "\titers: 200, epoch: 9 | loss: 0.0682109\n",
      "\tspeed: 0.0630s/iter; left time: 668.3786s\n",
      "\titers: 300, epoch: 9 | loss: 0.0675055\n",
      "\tspeed: 0.0639s/iter; left time: 670.6592s\n",
      "\titers: 400, epoch: 9 | loss: 0.0678290\n",
      "\tspeed: 0.0639s/iter; left time: 664.3222s\n",
      "\titers: 500, epoch: 9 | loss: 0.0640672\n",
      "\tspeed: 0.0636s/iter; left time: 655.0882s\n",
      "\titers: 600, epoch: 9 | loss: 0.0691719\n",
      "\tspeed: 0.0644s/iter; left time: 656.7573s\n",
      "\titers: 700, epoch: 9 | loss: 0.0649883\n",
      "\tspeed: 0.0666s/iter; left time: 672.7623s\n",
      "\titers: 800, epoch: 9 | loss: 0.0639870\n",
      "\tspeed: 0.0662s/iter; left time: 662.1073s\n",
      "\titers: 900, epoch: 9 | loss: 0.0635537\n",
      "\tspeed: 0.0642s/iter; left time: 635.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:58.07s\n",
      "Steps: 900 | Train Loss: 0.0659078 Vali Loss: 0.0915642 Test Loss: 0.1032215\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0611593\n",
      "\tspeed: 0.1662s/iter; left time: 1628.9686s\n",
      "\titers: 200, epoch: 10 | loss: 0.0621308\n",
      "\tspeed: 0.0650s/iter; left time: 630.1182s\n",
      "\titers: 300, epoch: 10 | loss: 0.0633088\n",
      "\tspeed: 0.0643s/iter; left time: 617.5153s\n",
      "\titers: 400, epoch: 10 | loss: 0.0589147\n",
      "\tspeed: 0.0635s/iter; left time: 603.4827s\n",
      "\titers: 500, epoch: 10 | loss: 0.0612601\n",
      "\tspeed: 0.0634s/iter; left time: 596.3464s\n",
      "\titers: 600, epoch: 10 | loss: 0.0620784\n",
      "\tspeed: 0.0633s/iter; left time: 589.1591s\n",
      "\titers: 700, epoch: 10 | loss: 0.0600841\n",
      "\tspeed: 0.0634s/iter; left time: 583.6646s\n",
      "\titers: 800, epoch: 10 | loss: 0.0589797\n",
      "\tspeed: 0.0638s/iter; left time: 580.5465s\n",
      "\titers: 900, epoch: 10 | loss: 0.0598935\n",
      "\tspeed: 0.0645s/iter; left time: 580.2135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:57.89s\n",
      "Steps: 900 | Train Loss: 0.0630859 Vali Loss: 0.0934347 Test Loss: 0.1046579\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_Informer_custom_ftM_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02358420379459858, rmse:0.1535715013742447, mae:0.0978248119354248, rse:0.5810715556144714\n",
      "Intermediate time for IT and pred_len 168: 00h:21m:40.29s\n",
      "Intermediate time for IT: 01h:12m:35.97s\n",
      "Total time: 01h:12m:35.98s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.013071063905954361,\n",
       "  'RMSE': 0.11432875692844391,\n",
       "  'MAE': 0.06469322741031647},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 24,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.011997658759355545,\n",
       "  'RMSE': 0.10953382402658463,\n",
       "  'MAE': 0.06481219828128815},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.022102830931544304,\n",
       "  'RMSE': 0.14867021143436432,\n",
       "  'MAE': 0.09126447886228561},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 96,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.022342106327414513,\n",
       "  'RMSE': 0.14947275817394257,\n",
       "  'MAE': 0.0909552201628685},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 1,\n",
       "  'MSE': 0.022543294355273247,\n",
       "  'RMSE': 0.15014424920082092,\n",
       "  'MAE': 0.09787493199110031},\n",
       " {'Country': 'IT',\n",
       "  'Pred_len': 168,\n",
       "  'Iteration': 2,\n",
       "  'MSE': 0.02358420379459858,\n",
       "  'RMSE': 0.1535715013742447,\n",
       "  'MAE': 0.0978248119354248}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= informer_results = []\n",
    "\n",
    "# DE 24\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.025699591264128685,\n",
    "    'RMSE': 0.16031092405319214,\n",
    "    'MAE': 0.10348266363143921,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.023365361616015434,\n",
    "    'RMSE': 0.15285731852054596,\n",
    "    'MAE': 0.10056539624929428,\n",
    "})\n",
    "\n",
    "# DE 96\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.04860777407884598,\n",
    "    'RMSE': 0.22047170996665955,\n",
    "    'MAE': 0.14964795112609863,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05066155269742012,\n",
    "    'RMSE': 0.22508122026920319,\n",
    "    'MAE': 0.1532352715730667,\n",
    "})\n",
    "\n",
    "# DE 168\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.054843734949827194,\n",
    "    'RMSE': 0.23418739438056946,\n",
    "    'MAE': 0.15871629118919373,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05288044735789299,\n",
    "    'RMSE': 0.2299574911594391,\n",
    "    'MAE': 0.15663425624370575,\n",
    "})\n",
    "\n",
    "# GB 24\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.046120475977659225,\n",
    "    'RMSE': 0.2147567868232727,\n",
    "    'MAE': 0.1404818892478943,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.039505913853645325,\n",
    "    'RMSE': 0.19876094162464142,\n",
    "    'MAE': 0.13264088332653046,\n",
    "})\n",
    "\n",
    "# GB 96\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.05855736881494522,\n",
    "    'RMSE': 0.24198630452156067,\n",
    "    'MAE': 0.16477428376674652,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05540859326720238,\n",
    "    'RMSE': 0.235390305519104,\n",
    "    'MAE': 0.16324692964553833,\n",
    "})\n",
    "\n",
    "# GB 168\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.06292843818664551,\n",
    "    'RMSE': 0.250855416059494,\n",
    "    'MAE': 0.17068493366241455,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.06641010195016861,\n",
    "    'RMSE': 0.257701575756073,\n",
    "    'MAE': 0.177326962351799,\n",
    "})\n",
    "\n",
    "# ES 24\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.027730144560337067,\n",
    "    'RMSE': 0.16652370989322662,\n",
    "    'MAE': 0.10189637541770935,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.03074352815747261,\n",
    "    'RMSE': 0.17533832788467407,\n",
    "    'MAE': 0.10366739332675934,\n",
    "})\n",
    "\n",
    "# ES 96\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.048280902206897736,\n",
    "    'RMSE': 0.21972915530204773,\n",
    "    'MAE': 0.13662198185920715,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05975188687443733,\n",
    "    'RMSE': 0.24444198608398438,\n",
    "    'MAE': 0.1502540409564972,\n",
    "})\n",
    "\n",
    "# ES 168\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.07949484884738922,\n",
    "    'RMSE': 0.2819482982158661,\n",
    "    'MAE': 0.1783347725868225,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.0831800326704979,\n",
    "    'RMSE': 0.2884095013141632,\n",
    "    'MAE': 0.18242256343364716,\n",
    "})\n",
    "\n",
    "# FR 24\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.012692660093307495,\n",
    "    'RMSE': 0.1126617044210434,\n",
    "    'MAE': 0.06498495489358902,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.013476599007844925,\n",
    "    'RMSE': 0.11608875542879105,\n",
    "    'MAE': 0.06680411100387573,\n",
    "})\n",
    "\n",
    "# FR 96\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.022180521860718727,\n",
    "    'RMSE': 0.14893126487731934,\n",
    "    'MAE': 0.09044930338859558,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.02346043847501278,\n",
    "    'RMSE': 0.15316800773143768,\n",
    "    'MAE': 0.09117613732814789,\n",
    "})\n",
    "\n",
    "# FR 168\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.026063205674290657,\n",
    "    'RMSE': 0.16144102811813354,\n",
    "    'MAE': 0.10040990263223648,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.026005728170275688,\n",
    "    'RMSE': 0.16126291453838348,\n",
    "    'MAE': 0.10041678696870804,\n",
    "})\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_transformers\", 'informer_npy_168')\n",
    "os.rename(\"test_results\", \"informer_pics_168\")\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer_168.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 168\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1369714\n",
      "\tspeed: 0.0541s/iter; left time: 1205.4753s\n",
      "\titers: 200, epoch: 1 | loss: 0.1247781\n",
      "\tspeed: 0.0266s/iter; left time: 591.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.1417671 Vali Loss: 0.1297606 Test Loss: 0.1347090\n",
      "Validation loss decreased (inf --> 0.129761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869461\n",
      "\tspeed: 0.0521s/iter; left time: 1150.1137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0833711\n",
      "\tspeed: 0.0267s/iter; left time: 587.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0896184 Vali Loss: 0.0936917 Test Loss: 0.0950095\n",
      "Validation loss decreased (0.129761 --> 0.093692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0781575\n",
      "\tspeed: 0.0518s/iter; left time: 1132.7286s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792153\n",
      "\tspeed: 0.0268s/iter; left time: 582.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0797606 Vali Loss: 0.0909321 Test Loss: 0.0923397\n",
      "Validation loss decreased (0.093692 --> 0.090932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807218\n",
      "\tspeed: 0.0511s/iter; left time: 1106.0893s\n",
      "\titers: 200, epoch: 4 | loss: 0.0808649\n",
      "\tspeed: 0.0267s/iter; left time: 574.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0773325 Vali Loss: 0.0890039 Test Loss: 0.0909385\n",
      "Validation loss decreased (0.090932 --> 0.089004).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773130\n",
      "\tspeed: 0.0520s/iter; left time: 1112.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0740610\n",
      "\tspeed: 0.0267s/iter; left time: 569.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0758602 Vali Loss: 0.0885584 Test Loss: 0.0901798\n",
      "Validation loss decreased (0.089004 --> 0.088558).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0830306\n",
      "\tspeed: 0.0516s/iter; left time: 1093.4893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0726725\n",
      "\tspeed: 0.0267s/iter; left time: 563.4790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0749306 Vali Loss: 0.0880955 Test Loss: 0.0901085\n",
      "Validation loss decreased (0.088558 --> 0.088095).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0732605\n",
      "\tspeed: 0.0517s/iter; left time: 1082.8480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776332\n",
      "\tspeed: 0.0267s/iter; left time: 555.8914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0740759 Vali Loss: 0.0876682 Test Loss: 0.0896309\n",
      "Validation loss decreased (0.088095 --> 0.087668).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0715202\n",
      "\tspeed: 0.0528s/iter; left time: 1093.9648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723670\n",
      "\tspeed: 0.0267s/iter; left time: 550.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0736438 Vali Loss: 0.0882936 Test Loss: 0.0894522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775626\n",
      "\tspeed: 0.0514s/iter; left time: 1054.5261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756080\n",
      "\tspeed: 0.0267s/iter; left time: 545.5887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0733198 Vali Loss: 0.0876187 Test Loss: 0.0892001\n",
      "Validation loss decreased (0.087668 --> 0.087619).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0764146\n",
      "\tspeed: 0.0525s/iter; left time: 1064.7971s\n",
      "\titers: 200, epoch: 10 | loss: 0.0708030\n",
      "\tspeed: 0.0265s/iter; left time: 535.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0727986 Vali Loss: 0.0873704 Test Loss: 0.0889288\n",
      "Validation loss decreased (0.087619 --> 0.087370).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678855\n",
      "\tspeed: 0.0522s/iter; left time: 1048.0739s\n",
      "\titers: 200, epoch: 11 | loss: 0.0720052\n",
      "\tspeed: 0.0268s/iter; left time: 534.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0725260 Vali Loss: 0.0871207 Test Loss: 0.0886076\n",
      "Validation loss decreased (0.087370 --> 0.087121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715223\n",
      "\tspeed: 0.0519s/iter; left time: 1030.5229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0742159\n",
      "\tspeed: 0.0266s/iter; left time: 524.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0722907 Vali Loss: 0.0866924 Test Loss: 0.0887910\n",
      "Validation loss decreased (0.087121 --> 0.086692).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0667619\n",
      "\tspeed: 0.0517s/iter; left time: 1013.0115s\n",
      "\titers: 200, epoch: 13 | loss: 0.0701735\n",
      "\tspeed: 0.0267s/iter; left time: 520.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0720069 Vali Loss: 0.0869621 Test Loss: 0.0883650\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0710825\n",
      "\tspeed: 0.0510s/iter; left time: 988.5146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727319\n",
      "\tspeed: 0.0266s/iter; left time: 512.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0718207 Vali Loss: 0.0862084 Test Loss: 0.0881200\n",
      "Validation loss decreased (0.086692 --> 0.086208).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0721587\n",
      "\tspeed: 0.0518s/iter; left time: 993.4135s\n",
      "\titers: 200, epoch: 15 | loss: 0.0660384\n",
      "\tspeed: 0.0267s/iter; left time: 509.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0716865 Vali Loss: 0.0862676 Test Loss: 0.0882083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0726189\n",
      "\tspeed: 0.0513s/iter; left time: 971.7333s\n",
      "\titers: 200, epoch: 16 | loss: 0.0699743\n",
      "\tspeed: 0.0266s/iter; left time: 500.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0715561 Vali Loss: 0.0862403 Test Loss: 0.0882708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734295\n",
      "\tspeed: 0.0508s/iter; left time: 950.7064s\n",
      "\titers: 200, epoch: 17 | loss: 0.0729700\n",
      "\tspeed: 0.0269s/iter; left time: 499.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0714500 Vali Loss: 0.0860131 Test Loss: 0.0878391\n",
      "Validation loss decreased (0.086208 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0720860\n",
      "\tspeed: 0.0510s/iter; left time: 943.6124s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807038\n",
      "\tspeed: 0.0285s/iter; left time: 524.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0712926 Vali Loss: 0.0858605 Test Loss: 0.0881299\n",
      "Validation loss decreased (0.086013 --> 0.085860).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0672827\n",
      "\tspeed: 0.0521s/iter; left time: 952.6361s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683527\n",
      "\tspeed: 0.0268s/iter; left time: 486.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0712880 Vali Loss: 0.0860396 Test Loss: 0.0881207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685089\n",
      "\tspeed: 0.0512s/iter; left time: 924.0535s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723603\n",
      "\tspeed: 0.0266s/iter; left time: 477.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0711309 Vali Loss: 0.0858991 Test Loss: 0.0879555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0669795\n",
      "\tspeed: 0.0510s/iter; left time: 908.4794s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729611\n",
      "\tspeed: 0.0266s/iter; left time: 471.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0710612 Vali Loss: 0.0858557 Test Loss: 0.0878603\n",
      "Validation loss decreased (0.085860 --> 0.085856).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0644646\n",
      "\tspeed: 0.0516s/iter; left time: 908.2609s\n",
      "\titers: 200, epoch: 22 | loss: 0.0674015\n",
      "\tspeed: 0.0267s/iter; left time: 466.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0709746 Vali Loss: 0.0858742 Test Loss: 0.0879468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0715065\n",
      "\tspeed: 0.0506s/iter; left time: 878.9808s\n",
      "\titers: 200, epoch: 23 | loss: 0.0664888\n",
      "\tspeed: 0.0266s/iter; left time: 459.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0708909 Vali Loss: 0.0858572 Test Loss: 0.0878468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697132\n",
      "\tspeed: 0.0514s/iter; left time: 881.7388s\n",
      "\titers: 200, epoch: 24 | loss: 0.0695731\n",
      "\tspeed: 0.0265s/iter; left time: 451.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0709061 Vali Loss: 0.0856822 Test Loss: 0.0878505\n",
      "Validation loss decreased (0.085856 --> 0.085682).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0698776\n",
      "\tspeed: 0.0509s/iter; left time: 862.2074s\n",
      "\titers: 200, epoch: 25 | loss: 0.0794153\n",
      "\tspeed: 0.0264s/iter; left time: 444.6524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0708391 Vali Loss: 0.0857899 Test Loss: 0.0877605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0693570\n",
      "\tspeed: 0.0507s/iter; left time: 847.0964s\n",
      "\titers: 200, epoch: 26 | loss: 0.0686728\n",
      "\tspeed: 0.0267s/iter; left time: 442.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708132 Vali Loss: 0.0856289 Test Loss: 0.0876225\n",
      "Validation loss decreased (0.085682 --> 0.085629).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736588\n",
      "\tspeed: 0.0522s/iter; left time: 859.5258s\n",
      "\titers: 200, epoch: 27 | loss: 0.0751999\n",
      "\tspeed: 0.0266s/iter; left time: 435.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0706946 Vali Loss: 0.0857887 Test Loss: 0.0877622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681836\n",
      "\tspeed: 0.0513s/iter; left time: 834.2176s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738424\n",
      "\tspeed: 0.0267s/iter; left time: 430.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0707199 Vali Loss: 0.0856799 Test Loss: 0.0876857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0720591\n",
      "\tspeed: 0.0512s/iter; left time: 820.0638s\n",
      "\titers: 200, epoch: 29 | loss: 0.0661264\n",
      "\tspeed: 0.0267s/iter; left time: 425.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0706302 Vali Loss: 0.0856200 Test Loss: 0.0876701\n",
      "Validation loss decreased (0.085629 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0764758\n",
      "\tspeed: 0.0525s/iter; left time: 829.9523s\n",
      "\titers: 200, epoch: 30 | loss: 0.0717371\n",
      "\tspeed: 0.0265s/iter; left time: 415.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0705703 Vali Loss: 0.0856172 Test Loss: 0.0877889\n",
      "Validation loss decreased (0.085620 --> 0.085617).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0694562\n",
      "\tspeed: 0.0528s/iter; left time: 823.0867s\n",
      "\titers: 200, epoch: 31 | loss: 0.0669540\n",
      "\tspeed: 0.0271s/iter; left time: 420.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0705669 Vali Loss: 0.0855405 Test Loss: 0.0876212\n",
      "Validation loss decreased (0.085617 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0648792\n",
      "\tspeed: 0.0519s/iter; left time: 796.4069s\n",
      "\titers: 200, epoch: 32 | loss: 0.0739037\n",
      "\tspeed: 0.0265s/iter; left time: 403.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0705570 Vali Loss: 0.0856224 Test Loss: 0.0876501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0760883\n",
      "\tspeed: 0.0509s/iter; left time: 769.5590s\n",
      "\titers: 200, epoch: 33 | loss: 0.0659316\n",
      "\tspeed: 0.0264s/iter; left time: 397.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0705282 Vali Loss: 0.0856680 Test Loss: 0.0876398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0700403\n",
      "\tspeed: 0.0509s/iter; left time: 758.6267s\n",
      "\titers: 200, epoch: 34 | loss: 0.0733599\n",
      "\tspeed: 0.0265s/iter; left time: 392.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0705505 Vali Loss: 0.0856534 Test Loss: 0.0876419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0716821\n",
      "\tspeed: 0.0509s/iter; left time: 747.2629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0660121\n",
      "\tspeed: 0.0267s/iter; left time: 389.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0704936 Vali Loss: 0.0856017 Test Loss: 0.0876743\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702281\n",
      "\tspeed: 0.0520s/iter; left time: 751.7426s\n",
      "\titers: 200, epoch: 36 | loss: 0.0758533\n",
      "\tspeed: 0.0268s/iter; left time: 385.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704848 Vali Loss: 0.0856520 Test Loss: 0.0876421\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0775575\n",
      "\tspeed: 0.0516s/iter; left time: 734.5360s\n",
      "\titers: 200, epoch: 37 | loss: 0.0730687\n",
      "\tspeed: 0.0267s/iter; left time: 377.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0705037 Vali Loss: 0.0856726 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0694183\n",
      "\tspeed: 0.0517s/iter; left time: 724.0252s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666340\n",
      "\tspeed: 0.0268s/iter; left time: 372.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704922 Vali Loss: 0.0855943 Test Loss: 0.0876738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0741279\n",
      "\tspeed: 0.0517s/iter; left time: 713.1725s\n",
      "\titers: 200, epoch: 39 | loss: 0.0680151\n",
      "\tspeed: 0.0268s/iter; left time: 366.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704478 Vali Loss: 0.0855522 Test Loss: 0.0876500\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0680514\n",
      "\tspeed: 0.0510s/iter; left time: 691.1667s\n",
      "\titers: 200, epoch: 40 | loss: 0.0764029\n",
      "\tspeed: 0.0265s/iter; left time: 356.5305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704099 Vali Loss: 0.0856432 Test Loss: 0.0876450\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0655310\n",
      "\tspeed: 0.0508s/iter; left time: 677.2596s\n",
      "\titers: 200, epoch: 41 | loss: 0.0691073\n",
      "\tspeed: 0.0268s/iter; left time: 355.4340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703985 Vali Loss: 0.0854845 Test Loss: 0.0875877\n",
      "Validation loss decreased (0.085541 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0682409\n",
      "\tspeed: 0.0513s/iter; left time: 672.5361s\n",
      "\titers: 200, epoch: 42 | loss: 0.0763331\n",
      "\tspeed: 0.0265s/iter; left time: 345.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0704444 Vali Loss: 0.0856361 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755680\n",
      "\tspeed: 0.0513s/iter; left time: 661.0572s\n",
      "\titers: 200, epoch: 43 | loss: 0.0719940\n",
      "\tspeed: 0.0265s/iter; left time: 339.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704495 Vali Loss: 0.0855508 Test Loss: 0.0876172\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644201\n",
      "\tspeed: 0.0509s/iter; left time: 645.4822s\n",
      "\titers: 200, epoch: 44 | loss: 0.0712258\n",
      "\tspeed: 0.0265s/iter; left time: 333.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0704013 Vali Loss: 0.0855588 Test Loss: 0.0876322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0704731\n",
      "\tspeed: 0.0520s/iter; left time: 647.4943s\n",
      "\titers: 200, epoch: 45 | loss: 0.0729366\n",
      "\tspeed: 0.0265s/iter; left time: 327.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703918 Vali Loss: 0.0855635 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0704228\n",
      "\tspeed: 0.0513s/iter; left time: 627.0158s\n",
      "\titers: 200, epoch: 46 | loss: 0.0755504\n",
      "\tspeed: 0.0266s/iter; left time: 323.0006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703368 Vali Loss: 0.0855913 Test Loss: 0.0876351\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0714861\n",
      "\tspeed: 0.0527s/iter; left time: 632.7437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0703084\n",
      "\tspeed: 0.0270s/iter; left time: 321.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0703858 Vali Loss: 0.0855839 Test Loss: 0.0876863\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0716547\n",
      "\tspeed: 0.0512s/iter; left time: 603.1520s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697001\n",
      "\tspeed: 0.0269s/iter; left time: 314.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703595 Vali Loss: 0.0855201 Test Loss: 0.0876336\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0721770\n",
      "\tspeed: 0.0514s/iter; left time: 593.2863s\n",
      "\titers: 200, epoch: 49 | loss: 0.0752482\n",
      "\tspeed: 0.0269s/iter; left time: 308.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703970 Vali Loss: 0.0854210 Test Loss: 0.0876339\n",
      "Validation loss decreased (0.085485 --> 0.085421).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0676463\n",
      "\tspeed: 0.0513s/iter; left time: 580.5348s\n",
      "\titers: 200, epoch: 50 | loss: 0.0677730\n",
      "\tspeed: 0.0265s/iter; left time: 297.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703362 Vali Loss: 0.0856355 Test Loss: 0.0876200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0666008\n",
      "\tspeed: 0.0516s/iter; left time: 573.0979s\n",
      "\titers: 200, epoch: 51 | loss: 0.0702993\n",
      "\tspeed: 0.0268s/iter; left time: 294.2959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0703573 Vali Loss: 0.0855665 Test Loss: 0.0876208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0723010\n",
      "\tspeed: 0.0510s/iter; left time: 555.1316s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758060\n",
      "\tspeed: 0.0265s/iter; left time: 285.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703259 Vali Loss: 0.0854868 Test Loss: 0.0876280\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0706884\n",
      "\tspeed: 0.0514s/iter; left time: 547.3564s\n",
      "\titers: 200, epoch: 53 | loss: 0.0751953\n",
      "\tspeed: 0.0265s/iter; left time: 280.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703530 Vali Loss: 0.0855637 Test Loss: 0.0876266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0702771\n",
      "\tspeed: 0.0513s/iter; left time: 535.4939s\n",
      "\titers: 200, epoch: 54 | loss: 0.0684877\n",
      "\tspeed: 0.0268s/iter; left time: 277.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0703710 Vali Loss: 0.0855449 Test Loss: 0.0876197\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0688983\n",
      "\tspeed: 0.0514s/iter; left time: 524.3484s\n",
      "\titers: 200, epoch: 55 | loss: 0.0738532\n",
      "\tspeed: 0.0269s/iter; left time: 271.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0703545 Vali Loss: 0.0854906 Test Loss: 0.0876294\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0730539\n",
      "\tspeed: 0.0526s/iter; left time: 525.1879s\n",
      "\titers: 200, epoch: 56 | loss: 0.0674224\n",
      "\tspeed: 0.0266s/iter; left time: 263.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0704173 Vali Loss: 0.0854536 Test Loss: 0.0876250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0707048\n",
      "\tspeed: 0.0513s/iter; left time: 500.7753s\n",
      "\titers: 200, epoch: 57 | loss: 0.0710349\n",
      "\tspeed: 0.0265s/iter; left time: 255.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0703584 Vali Loss: 0.0855452 Test Loss: 0.0876381\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736169\n",
      "\tspeed: 0.0504s/iter; left time: 480.1522s\n",
      "\titers: 200, epoch: 58 | loss: 0.0741034\n",
      "\tspeed: 0.0266s/iter; left time: 250.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0703132 Vali Loss: 0.0855490 Test Loss: 0.0876148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0710790\n",
      "\tspeed: 0.0514s/iter; left time: 478.3326s\n",
      "\titers: 200, epoch: 59 | loss: 0.0729701\n",
      "\tspeed: 0.0269s/iter; left time: 247.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0703250 Vali Loss: 0.0855128 Test Loss: 0.0876621\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020939357578754425, rmse:0.14470438659191132, mae:0.08763387054204941, rse:0.5106817483901978\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1389406\n",
      "\tspeed: 0.0286s/iter; left time: 637.3228s\n",
      "\titers: 200, epoch: 1 | loss: 0.1228134\n",
      "\tspeed: 0.0266s/iter; left time: 590.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1422911 Vali Loss: 0.1295809 Test Loss: 0.1351006\n",
      "Validation loss decreased (inf --> 0.129581).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877811\n",
      "\tspeed: 0.0524s/iter; left time: 1157.5606s\n",
      "\titers: 200, epoch: 2 | loss: 0.0832211\n",
      "\tspeed: 0.0267s/iter; left time: 585.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0894358 Vali Loss: 0.0936241 Test Loss: 0.0940987\n",
      "Validation loss decreased (0.129581 --> 0.093624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775893\n",
      "\tspeed: 0.0529s/iter; left time: 1155.7753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735417\n",
      "\tspeed: 0.0268s/iter; left time: 582.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0796590 Vali Loss: 0.0902558 Test Loss: 0.0915840\n",
      "Validation loss decreased (0.093624 --> 0.090256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0772389\n",
      "\tspeed: 0.0535s/iter; left time: 1157.4906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0764423\n",
      "\tspeed: 0.0267s/iter; left time: 575.2471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0774734 Vali Loss: 0.0893443 Test Loss: 0.0907840\n",
      "Validation loss decreased (0.090256 --> 0.089344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0743019\n",
      "\tspeed: 0.0524s/iter; left time: 1122.3344s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750691\n",
      "\tspeed: 0.0266s/iter; left time: 566.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0761713 Vali Loss: 0.0888839 Test Loss: 0.0900800\n",
      "Validation loss decreased (0.089344 --> 0.088884).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0693859\n",
      "\tspeed: 0.0531s/iter; left time: 1125.5393s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754470\n",
      "\tspeed: 0.0268s/iter; left time: 564.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0751449 Vali Loss: 0.0878856 Test Loss: 0.0899183\n",
      "Validation loss decreased (0.088884 --> 0.087886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723351\n",
      "\tspeed: 0.0524s/iter; left time: 1098.0215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741934\n",
      "\tspeed: 0.0266s/iter; left time: 553.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0744148 Vali Loss: 0.0882161 Test Loss: 0.0896968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0743478\n",
      "\tspeed: 0.0515s/iter; left time: 1067.8407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734460\n",
      "\tspeed: 0.0266s/iter; left time: 547.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0738465 Vali Loss: 0.0875170 Test Loss: 0.0890645\n",
      "Validation loss decreased (0.087886 --> 0.087517).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0690735\n",
      "\tspeed: 0.0529s/iter; left time: 1085.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759658\n",
      "\tspeed: 0.0267s/iter; left time: 545.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0733618 Vali Loss: 0.0870617 Test Loss: 0.0888512\n",
      "Validation loss decreased (0.087517 --> 0.087062).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0763888\n",
      "\tspeed: 0.0540s/iter; left time: 1095.9059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748855\n",
      "\tspeed: 0.0267s/iter; left time: 538.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0729996 Vali Loss: 0.0868114 Test Loss: 0.0887925\n",
      "Validation loss decreased (0.087062 --> 0.086811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753090\n",
      "\tspeed: 0.0522s/iter; left time: 1047.6334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728513\n",
      "\tspeed: 0.0265s/iter; left time: 528.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0726921 Vali Loss: 0.0872061 Test Loss: 0.0885696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0705457\n",
      "\tspeed: 0.0520s/iter; left time: 1031.3150s\n",
      "\titers: 200, epoch: 12 | loss: 0.0726305\n",
      "\tspeed: 0.0265s/iter; left time: 523.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723711 Vali Loss: 0.0864833 Test Loss: 0.0882598\n",
      "Validation loss decreased (0.086811 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0700529\n",
      "\tspeed: 0.0524s/iter; left time: 1027.1079s\n",
      "\titers: 200, epoch: 13 | loss: 0.0684496\n",
      "\tspeed: 0.0267s/iter; left time: 520.3979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0721546 Vali Loss: 0.0865951 Test Loss: 0.0883359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748019\n",
      "\tspeed: 0.0529s/iter; left time: 1024.8560s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713811\n",
      "\tspeed: 0.0270s/iter; left time: 520.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0719527 Vali Loss: 0.0866737 Test Loss: 0.0880236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0713503\n",
      "\tspeed: 0.0521s/iter; left time: 999.2792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763744\n",
      "\tspeed: 0.0266s/iter; left time: 506.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0716899 Vali Loss: 0.0864420 Test Loss: 0.0880862\n",
      "Validation loss decreased (0.086483 --> 0.086442).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746533\n",
      "\tspeed: 0.0524s/iter; left time: 992.8871s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665798\n",
      "\tspeed: 0.0265s/iter; left time: 499.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0715671 Vali Loss: 0.0860693 Test Loss: 0.0879256\n",
      "Validation loss decreased (0.086442 --> 0.086069).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704673\n",
      "\tspeed: 0.0527s/iter; left time: 987.2801s\n",
      "\titers: 200, epoch: 17 | loss: 0.0683351\n",
      "\tspeed: 0.0268s/iter; left time: 498.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0714092 Vali Loss: 0.0860398 Test Loss: 0.0881202\n",
      "Validation loss decreased (0.086069 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692278\n",
      "\tspeed: 0.0532s/iter; left time: 984.5075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706096\n",
      "\tspeed: 0.0265s/iter; left time: 487.5949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0713103 Vali Loss: 0.0860568 Test Loss: 0.0880662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711174\n",
      "\tspeed: 0.0527s/iter; left time: 963.1993s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707833\n",
      "\tspeed: 0.0265s/iter; left time: 480.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0711834 Vali Loss: 0.0858907 Test Loss: 0.0879579\n",
      "Validation loss decreased (0.086040 --> 0.085891).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700932\n",
      "\tspeed: 0.0527s/iter; left time: 951.2086s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701582\n",
      "\tspeed: 0.0268s/iter; left time: 480.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0710876 Vali Loss: 0.0862701 Test Loss: 0.0880781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699507\n",
      "\tspeed: 0.0528s/iter; left time: 940.8659s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683075\n",
      "\tspeed: 0.0267s/iter; left time: 473.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0710427 Vali Loss: 0.0861612 Test Loss: 0.0881739\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0751726\n",
      "\tspeed: 0.0519s/iter; left time: 912.4235s\n",
      "\titers: 200, epoch: 22 | loss: 0.0686039\n",
      "\tspeed: 0.0265s/iter; left time: 464.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0709314 Vali Loss: 0.0859297 Test Loss: 0.0879431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740635\n",
      "\tspeed: 0.0530s/iter; left time: 920.0264s\n",
      "\titers: 200, epoch: 23 | loss: 0.0754669\n",
      "\tspeed: 0.0267s/iter; left time: 460.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0708511 Vali Loss: 0.0858247 Test Loss: 0.0877661\n",
      "Validation loss decreased (0.085891 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0669902\n",
      "\tspeed: 0.0531s/iter; left time: 911.2386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0699968\n",
      "\tspeed: 0.0264s/iter; left time: 450.4041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0708038 Vali Loss: 0.0857948 Test Loss: 0.0880593\n",
      "Validation loss decreased (0.085825 --> 0.085795).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0710267\n",
      "\tspeed: 0.0519s/iter; left time: 878.6579s\n",
      "\titers: 200, epoch: 25 | loss: 0.0701005\n",
      "\tspeed: 0.0265s/iter; left time: 445.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0707550 Vali Loss: 0.0858620 Test Loss: 0.0879302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0675721\n",
      "\tspeed: 0.0519s/iter; left time: 866.8273s\n",
      "\titers: 200, epoch: 26 | loss: 0.0723306\n",
      "\tspeed: 0.0266s/iter; left time: 441.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0707452 Vali Loss: 0.0857506 Test Loss: 0.0878565\n",
      "Validation loss decreased (0.085795 --> 0.085751).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725780\n",
      "\tspeed: 0.0528s/iter; left time: 869.7247s\n",
      "\titers: 200, epoch: 27 | loss: 0.0715543\n",
      "\tspeed: 0.0268s/iter; left time: 438.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0706913 Vali Loss: 0.0857717 Test Loss: 0.0878863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0656819\n",
      "\tspeed: 0.0536s/iter; left time: 870.6048s\n",
      "\titers: 200, epoch: 28 | loss: 0.0728222\n",
      "\tspeed: 0.0269s/iter; left time: 434.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0706028 Vali Loss: 0.0855976 Test Loss: 0.0878353\n",
      "Validation loss decreased (0.085751 --> 0.085598).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0716999\n",
      "\tspeed: 0.0531s/iter; left time: 850.3424s\n",
      "\titers: 200, epoch: 29 | loss: 0.0711410\n",
      "\tspeed: 0.0265s/iter; left time: 422.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0705973 Vali Loss: 0.0859616 Test Loss: 0.0878585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0745615\n",
      "\tspeed: 0.0523s/iter; left time: 827.2763s\n",
      "\titers: 200, epoch: 30 | loss: 0.0758140\n",
      "\tspeed: 0.0269s/iter; left time: 422.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705595 Vali Loss: 0.0856872 Test Loss: 0.0878131\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0744614\n",
      "\tspeed: 0.0525s/iter; left time: 818.0931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0705624\n",
      "\tspeed: 0.0267s/iter; left time: 414.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0705045 Vali Loss: 0.0857018 Test Loss: 0.0878923\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0687968\n",
      "\tspeed: 0.0528s/iter; left time: 810.4927s\n",
      "\titers: 200, epoch: 32 | loss: 0.0645319\n",
      "\tspeed: 0.0267s/iter; left time: 406.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0705371 Vali Loss: 0.0856552 Test Loss: 0.0878005\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0692253\n",
      "\tspeed: 0.0522s/iter; left time: 790.4230s\n",
      "\titers: 200, epoch: 33 | loss: 0.0719842\n",
      "\tspeed: 0.0267s/iter; left time: 401.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0704541 Vali Loss: 0.0857210 Test Loss: 0.0878580\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0711537\n",
      "\tspeed: 0.0519s/iter; left time: 773.8731s\n",
      "\titers: 200, epoch: 34 | loss: 0.0700859\n",
      "\tspeed: 0.0267s/iter; left time: 395.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0704086 Vali Loss: 0.0857385 Test Loss: 0.0877898\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0727249\n",
      "\tspeed: 0.0525s/iter; left time: 771.6492s\n",
      "\titers: 200, epoch: 35 | loss: 0.0703164\n",
      "\tspeed: 0.0265s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0704289 Vali Loss: 0.0856548 Test Loss: 0.0878404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0692909\n",
      "\tspeed: 0.0518s/iter; left time: 749.3944s\n",
      "\titers: 200, epoch: 36 | loss: 0.0745890\n",
      "\tspeed: 0.0265s/iter; left time: 380.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 224 | Train Loss: 0.0704170 Vali Loss: 0.0855795 Test Loss: 0.0877761\n",
      "Validation loss decreased (0.085598 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669411\n",
      "\tspeed: 0.0523s/iter; left time: 743.9817s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717780\n",
      "\tspeed: 0.0265s/iter; left time: 374.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703451 Vali Loss: 0.0857678 Test Loss: 0.0877872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0692922\n",
      "\tspeed: 0.0523s/iter; left time: 732.2128s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706012\n",
      "\tspeed: 0.0274s/iter; left time: 381.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0703509 Vali Loss: 0.0856808 Test Loss: 0.0877914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0644956\n",
      "\tspeed: 0.0523s/iter; left time: 721.3358s\n",
      "\titers: 200, epoch: 39 | loss: 0.0683517\n",
      "\tspeed: 0.0265s/iter; left time: 362.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0703036 Vali Loss: 0.0857069 Test Loss: 0.0877940\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712174\n",
      "\tspeed: 0.0528s/iter; left time: 716.0116s\n",
      "\titers: 200, epoch: 40 | loss: 0.0717972\n",
      "\tspeed: 0.0266s/iter; left time: 357.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703386 Vali Loss: 0.0855974 Test Loss: 0.0877805\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0709783\n",
      "\tspeed: 0.0521s/iter; left time: 694.8751s\n",
      "\titers: 200, epoch: 41 | loss: 0.0727384\n",
      "\tspeed: 0.0267s/iter; left time: 353.5061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0703057 Vali Loss: 0.0855847 Test Loss: 0.0877485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0696685\n",
      "\tspeed: 0.0521s/iter; left time: 684.0514s\n",
      "\titers: 200, epoch: 42 | loss: 0.0708702\n",
      "\tspeed: 0.0266s/iter; left time: 345.9082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0702815 Vali Loss: 0.0856937 Test Loss: 0.0877606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0755521\n",
      "\tspeed: 0.0524s/iter; left time: 675.6540s\n",
      "\titers: 200, epoch: 43 | loss: 0.0711717\n",
      "\tspeed: 0.0266s/iter; left time: 340.3418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0703419 Vali Loss: 0.0854786 Test Loss: 0.0877750\n",
      "Validation loss decreased (0.085579 --> 0.085479).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0711064\n",
      "\tspeed: 0.0524s/iter; left time: 664.3796s\n",
      "\titers: 200, epoch: 44 | loss: 0.0720553\n",
      "\tspeed: 0.0267s/iter; left time: 335.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0703236 Vali Loss: 0.0856422 Test Loss: 0.0877193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0685135\n",
      "\tspeed: 0.0518s/iter; left time: 645.1912s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710313\n",
      "\tspeed: 0.0270s/iter; left time: 333.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703195 Vali Loss: 0.0855412 Test Loss: 0.0877509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0682689\n",
      "\tspeed: 0.0519s/iter; left time: 634.1017s\n",
      "\titers: 200, epoch: 46 | loss: 0.0663539\n",
      "\tspeed: 0.0265s/iter; left time: 321.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702857 Vali Loss: 0.0856832 Test Loss: 0.0877343\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0781750\n",
      "\tspeed: 0.0532s/iter; left time: 637.8936s\n",
      "\titers: 200, epoch: 47 | loss: 0.0668642\n",
      "\tspeed: 0.0267s/iter; left time: 317.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0703067 Vali Loss: 0.0856037 Test Loss: 0.0877680\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0757289\n",
      "\tspeed: 0.0527s/iter; left time: 620.0069s\n",
      "\titers: 200, epoch: 48 | loss: 0.0714607\n",
      "\tspeed: 0.0265s/iter; left time: 309.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0703030 Vali Loss: 0.0855959 Test Loss: 0.0877536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0738765\n",
      "\tspeed: 0.0524s/iter; left time: 605.3152s\n",
      "\titers: 200, epoch: 49 | loss: 0.0682928\n",
      "\tspeed: 0.0268s/iter; left time: 306.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0703193 Vali Loss: 0.0856737 Test Loss: 0.0877642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0721883\n",
      "\tspeed: 0.0523s/iter; left time: 592.4528s\n",
      "\titers: 200, epoch: 50 | loss: 0.0696596\n",
      "\tspeed: 0.0266s/iter; left time: 298.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0702247 Vali Loss: 0.0856217 Test Loss: 0.0877349\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0724216\n",
      "\tspeed: 0.0521s/iter; left time: 578.8286s\n",
      "\titers: 200, epoch: 51 | loss: 0.0683385\n",
      "\tspeed: 0.0264s/iter; left time: 290.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0702224 Vali Loss: 0.0856550 Test Loss: 0.0877666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0707191\n",
      "\tspeed: 0.0517s/iter; left time: 562.1389s\n",
      "\titers: 200, epoch: 52 | loss: 0.0697485\n",
      "\tspeed: 0.0265s/iter; left time: 285.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0702648 Vali Loss: 0.0856051 Test Loss: 0.0877736\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0723032\n",
      "\tspeed: 0.0528s/iter; left time: 562.8959s\n",
      "\titers: 200, epoch: 53 | loss: 0.0695717\n",
      "\tspeed: 0.0266s/iter; left time: 280.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0702753 Vali Loss: 0.0856733 Test Loss: 0.0877745\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020994756370782852, rmse:0.14489567279815674, mae:0.08777499943971634, rse:0.5113568902015686\n",
      "Intermediate time for DE and pred_len 24: 00h:14m:50.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1487391\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1487s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375452\n",
      "\tspeed: 0.0269s/iter; left time: 598.1186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 224 | Train Loss: 0.1484455 Vali Loss: 0.1405499 Test Loss: 0.1490060\n",
      "Validation loss decreased (inf --> 0.140550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1194897\n",
      "\tspeed: 0.0533s/iter; left time: 1176.9588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1064227\n",
      "\tspeed: 0.0268s/iter; left time: 588.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.1145359 Vali Loss: 0.1213630 Test Loss: 0.1295630\n",
      "Validation loss decreased (0.140550 --> 0.121363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036745\n",
      "\tspeed: 0.0540s/iter; left time: 1179.6751s\n",
      "\titers: 200, epoch: 3 | loss: 0.1068880\n",
      "\tspeed: 0.0268s/iter; left time: 583.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1064633 Vali Loss: 0.1195266 Test Loss: 0.1282235\n",
      "Validation loss decreased (0.121363 --> 0.119527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1044791\n",
      "\tspeed: 0.0537s/iter; left time: 1160.7622s\n",
      "\titers: 200, epoch: 4 | loss: 0.1004268\n",
      "\tspeed: 0.0269s/iter; left time: 579.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1045039 Vali Loss: 0.1190653 Test Loss: 0.1280503\n",
      "Validation loss decreased (0.119527 --> 0.119065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030031\n",
      "\tspeed: 0.0531s/iter; left time: 1137.1471s\n",
      "\titers: 200, epoch: 5 | loss: 0.0965900\n",
      "\tspeed: 0.0268s/iter; left time: 570.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1033400 Vali Loss: 0.1186632 Test Loss: 0.1276050\n",
      "Validation loss decreased (0.119065 --> 0.118663).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1102587\n",
      "\tspeed: 0.0538s/iter; left time: 1140.5733s\n",
      "\titers: 200, epoch: 6 | loss: 0.1076527\n",
      "\tspeed: 0.0269s/iter; left time: 567.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1024590 Vali Loss: 0.1179634 Test Loss: 0.1265461\n",
      "Validation loss decreased (0.118663 --> 0.117963).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1025728\n",
      "\tspeed: 0.0538s/iter; left time: 1126.7627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953970\n",
      "\tspeed: 0.0269s/iter; left time: 560.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1016823 Vali Loss: 0.1186003 Test Loss: 0.1277381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0998731\n",
      "\tspeed: 0.0539s/iter; left time: 1116.5655s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977558\n",
      "\tspeed: 0.0267s/iter; left time: 551.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1010973 Vali Loss: 0.1182861 Test Loss: 0.1272469\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0999197\n",
      "\tspeed: 0.0532s/iter; left time: 1090.9066s\n",
      "\titers: 200, epoch: 9 | loss: 0.1026386\n",
      "\tspeed: 0.0268s/iter; left time: 546.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1004929 Vali Loss: 0.1175796 Test Loss: 0.1266904\n",
      "Validation loss decreased (0.117963 --> 0.117580).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008377\n",
      "\tspeed: 0.0538s/iter; left time: 1091.6922s\n",
      "\titers: 200, epoch: 10 | loss: 0.0974689\n",
      "\tspeed: 0.0268s/iter; left time: 541.3570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1000229 Vali Loss: 0.1174014 Test Loss: 0.1273050\n",
      "Validation loss decreased (0.117580 --> 0.117401).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0975121\n",
      "\tspeed: 0.0536s/iter; left time: 1074.5040s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031677\n",
      "\tspeed: 0.0268s/iter; left time: 534.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0996410 Vali Loss: 0.1172269 Test Loss: 0.1274734\n",
      "Validation loss decreased (0.117401 --> 0.117227).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1019047\n",
      "\tspeed: 0.0535s/iter; left time: 1062.0590s\n",
      "\titers: 200, epoch: 12 | loss: 0.0963887\n",
      "\tspeed: 0.0268s/iter; left time: 528.2677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0992125 Vali Loss: 0.1170878 Test Loss: 0.1278752\n",
      "Validation loss decreased (0.117227 --> 0.117088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961119\n",
      "\tspeed: 0.0544s/iter; left time: 1066.5978s\n",
      "\titers: 200, epoch: 13 | loss: 0.0989636\n",
      "\tspeed: 0.0268s/iter; left time: 523.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0988020 Vali Loss: 0.1168609 Test Loss: 0.1279964\n",
      "Validation loss decreased (0.117088 --> 0.116861).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0999261\n",
      "\tspeed: 0.0537s/iter; left time: 1040.9073s\n",
      "\titers: 200, epoch: 14 | loss: 0.0937633\n",
      "\tspeed: 0.0269s/iter; left time: 517.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0984957 Vali Loss: 0.1170542 Test Loss: 0.1275455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0966726\n",
      "\tspeed: 0.0539s/iter; left time: 1033.5501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981507\n",
      "\tspeed: 0.0270s/iter; left time: 515.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0981710 Vali Loss: 0.1166702 Test Loss: 0.1279635\n",
      "Validation loss decreased (0.116861 --> 0.116670).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1011894\n",
      "\tspeed: 0.0547s/iter; left time: 1036.4337s\n",
      "\titers: 200, epoch: 16 | loss: 0.1026321\n",
      "\tspeed: 0.0271s/iter; left time: 510.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0978653 Vali Loss: 0.1167809 Test Loss: 0.1274564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973510\n",
      "\tspeed: 0.0535s/iter; left time: 1000.7220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0980666\n",
      "\tspeed: 0.0269s/iter; left time: 501.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0976454 Vali Loss: 0.1168894 Test Loss: 0.1274555\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0964897\n",
      "\tspeed: 0.0535s/iter; left time: 989.2355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0915851\n",
      "\tspeed: 0.0269s/iter; left time: 494.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0973645 Vali Loss: 0.1169818 Test Loss: 0.1278145\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0937841\n",
      "\tspeed: 0.0539s/iter; left time: 984.7285s\n",
      "\titers: 200, epoch: 19 | loss: 0.0945172\n",
      "\tspeed: 0.0268s/iter; left time: 486.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0971042 Vali Loss: 0.1170631 Test Loss: 0.1279219\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0976394\n",
      "\tspeed: 0.0532s/iter; left time: 959.2814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025702\n",
      "\tspeed: 0.0268s/iter; left time: 480.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0969481 Vali Loss: 0.1168795 Test Loss: 0.1282358\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0984403\n",
      "\tspeed: 0.0539s/iter; left time: 960.3656s\n",
      "\titers: 200, epoch: 21 | loss: 0.0932305\n",
      "\tspeed: 0.0269s/iter; left time: 477.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0967456 Vali Loss: 0.1170377 Test Loss: 0.1280329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0958503\n",
      "\tspeed: 0.0537s/iter; left time: 945.1394s\n",
      "\titers: 200, epoch: 22 | loss: 0.0987119\n",
      "\tspeed: 0.0269s/iter; left time: 471.5420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0965442 Vali Loss: 0.1168456 Test Loss: 0.1277162\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0967639\n",
      "\tspeed: 0.0528s/iter; left time: 917.3884s\n",
      "\titers: 200, epoch: 23 | loss: 0.1017741\n",
      "\tspeed: 0.0268s/iter; left time: 463.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0964595 Vali Loss: 0.1169775 Test Loss: 0.1280533\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1019816\n",
      "\tspeed: 0.0538s/iter; left time: 922.2519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0947855\n",
      "\tspeed: 0.0269s/iter; left time: 458.3107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0962695 Vali Loss: 0.1168131 Test Loss: 0.1279567\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0958062\n",
      "\tspeed: 0.0530s/iter; left time: 897.5916s\n",
      "\titers: 200, epoch: 25 | loss: 0.0925729\n",
      "\tspeed: 0.0269s/iter; left time: 452.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961852 Vali Loss: 0.1169263 Test Loss: 0.1279396\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03738878667354584, rmse:0.1933618038892746, mae:0.12796346843242645, rse:0.6847332715988159\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1453122\n",
      "\tspeed: 0.0287s/iter; left time: 639.1908s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341071\n",
      "\tspeed: 0.0268s/iter; left time: 594.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.1493950 Vali Loss: 0.1402512 Test Loss: 0.1483553\n",
      "Validation loss decreased (inf --> 0.140251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097633\n",
      "\tspeed: 0.0543s/iter; left time: 1198.2260s\n",
      "\titers: 200, epoch: 2 | loss: 0.1095724\n",
      "\tspeed: 0.0269s/iter; left time: 591.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1142674 Vali Loss: 0.1222842 Test Loss: 0.1300744\n",
      "Validation loss decreased (0.140251 --> 0.122284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055942\n",
      "\tspeed: 0.0555s/iter; left time: 1212.4990s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084602\n",
      "\tspeed: 0.0270s/iter; left time: 587.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.1065267 Vali Loss: 0.1205910 Test Loss: 0.1294958\n",
      "Validation loss decreased (0.122284 --> 0.120591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018099\n",
      "\tspeed: 0.0542s/iter; left time: 1171.7338s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051938\n",
      "\tspeed: 0.0269s/iter; left time: 579.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1047808 Vali Loss: 0.1190739 Test Loss: 0.1283687\n",
      "Validation loss decreased (0.120591 --> 0.119074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018800\n",
      "\tspeed: 0.0539s/iter; left time: 1153.8204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0956694\n",
      "\tspeed: 0.0267s/iter; left time: 569.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1035395 Vali Loss: 0.1188459 Test Loss: 0.1280372\n",
      "Validation loss decreased (0.119074 --> 0.118846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0991640\n",
      "\tspeed: 0.0546s/iter; left time: 1156.3359s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049700\n",
      "\tspeed: 0.0269s/iter; left time: 568.1287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1181803 Test Loss: 0.1279618\n",
      "Validation loss decreased (0.118846 --> 0.118180).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013687\n",
      "\tspeed: 0.0545s/iter; left time: 1142.8758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993038\n",
      "\tspeed: 0.0268s/iter; left time: 557.9995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1018238 Vali Loss: 0.1180655 Test Loss: 0.1277595\n",
      "Validation loss decreased (0.118180 --> 0.118066).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997346\n",
      "\tspeed: 0.0555s/iter; left time: 1150.8520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997878\n",
      "\tspeed: 0.0270s/iter; left time: 557.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1010508 Vali Loss: 0.1179035 Test Loss: 0.1281448\n",
      "Validation loss decreased (0.118066 --> 0.117903).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0988701\n",
      "\tspeed: 0.0563s/iter; left time: 1154.6799s\n",
      "\titers: 200, epoch: 9 | loss: 0.0968515\n",
      "\tspeed: 0.0271s/iter; left time: 552.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1004422 Vali Loss: 0.1178284 Test Loss: 0.1291293\n",
      "Validation loss decreased (0.117903 --> 0.117828).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008913\n",
      "\tspeed: 0.0546s/iter; left time: 1108.5587s\n",
      "\titers: 200, epoch: 10 | loss: 0.0954883\n",
      "\tspeed: 0.0267s/iter; left time: 539.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0998062 Vali Loss: 0.1179435 Test Loss: 0.1273128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1016945\n",
      "\tspeed: 0.0525s/iter; left time: 1052.5954s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974247\n",
      "\tspeed: 0.0269s/iter; left time: 536.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0992023 Vali Loss: 0.1177902 Test Loss: 0.1276344\n",
      "Validation loss decreased (0.117828 --> 0.117790).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0978504\n",
      "\tspeed: 0.0552s/iter; left time: 1094.3827s\n",
      "\titers: 200, epoch: 12 | loss: 0.1006840\n",
      "\tspeed: 0.0270s/iter; left time: 533.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0986686 Vali Loss: 0.1178868 Test Loss: 0.1283520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1029566\n",
      "\tspeed: 0.0534s/iter; left time: 1048.1343s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995638\n",
      "\tspeed: 0.0267s/iter; left time: 521.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0982064 Vali Loss: 0.1177266 Test Loss: 0.1271849\n",
      "Validation loss decreased (0.117790 --> 0.117727).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966322\n",
      "\tspeed: 0.0541s/iter; left time: 1048.6480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0939447\n",
      "\tspeed: 0.0271s/iter; left time: 521.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0977019 Vali Loss: 0.1176199 Test Loss: 0.1285766\n",
      "Validation loss decreased (0.117727 --> 0.117620).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0955380\n",
      "\tspeed: 0.0567s/iter; left time: 1086.8307s\n",
      "\titers: 200, epoch: 15 | loss: 0.0928111\n",
      "\tspeed: 0.0271s/iter; left time: 516.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0973574 Vali Loss: 0.1177496 Test Loss: 0.1279720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019763\n",
      "\tspeed: 0.0549s/iter; left time: 1039.6933s\n",
      "\titers: 200, epoch: 16 | loss: 0.1012777\n",
      "\tspeed: 0.0270s/iter; left time: 509.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0969753 Vali Loss: 0.1177540 Test Loss: 0.1296667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0968168\n",
      "\tspeed: 0.0551s/iter; left time: 1030.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0930788\n",
      "\tspeed: 0.0270s/iter; left time: 502.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0968140 Vali Loss: 0.1179194 Test Loss: 0.1291604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0877084\n",
      "\tspeed: 0.0546s/iter; left time: 1009.5318s\n",
      "\titers: 200, epoch: 18 | loss: 0.0964585\n",
      "\tspeed: 0.0271s/iter; left time: 497.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0964126 Vali Loss: 0.1179514 Test Loss: 0.1292164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0978073\n",
      "\tspeed: 0.0549s/iter; left time: 1002.6800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0927446\n",
      "\tspeed: 0.0270s/iter; left time: 491.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0961563 Vali Loss: 0.1180256 Test Loss: 0.1296065\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0997547\n",
      "\tspeed: 0.0541s/iter; left time: 976.4935s\n",
      "\titers: 200, epoch: 20 | loss: 0.0986387\n",
      "\tspeed: 0.0274s/iter; left time: 491.8739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0959443 Vali Loss: 0.1176773 Test Loss: 0.1286344\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0958655\n",
      "\tspeed: 0.0560s/iter; left time: 998.6060s\n",
      "\titers: 200, epoch: 21 | loss: 0.0964852\n",
      "\tspeed: 0.0270s/iter; left time: 478.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0957407 Vali Loss: 0.1176798 Test Loss: 0.1287229\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0942021\n",
      "\tspeed: 0.0553s/iter; left time: 972.3128s\n",
      "\titers: 200, epoch: 22 | loss: 0.0922590\n",
      "\tspeed: 0.0270s/iter; left time: 472.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0955422 Vali Loss: 0.1179530 Test Loss: 0.1288881\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0922816\n",
      "\tspeed: 0.0546s/iter; left time: 948.8017s\n",
      "\titers: 200, epoch: 23 | loss: 0.0962126\n",
      "\tspeed: 0.0273s/iter; left time: 471.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0954098 Vali Loss: 0.1179873 Test Loss: 0.1291286\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0962873\n",
      "\tspeed: 0.0545s/iter; left time: 933.8682s\n",
      "\titers: 200, epoch: 24 | loss: 0.0961054\n",
      "\tspeed: 0.0271s/iter; left time: 462.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0953075 Vali Loss: 0.1179708 Test Loss: 0.1295294\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.037975143641233444, rmse:0.19487212598323822, mae:0.1285766065120697, rse:0.6900815963745117\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:50.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1511204\n",
      "\tspeed: 0.0547s/iter; left time: 1213.9765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396091\n",
      "\tspeed: 0.0271s/iter; left time: 598.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 223 | Train Loss: 0.1507847 Vali Loss: 0.1426704 Test Loss: 0.1519556\n",
      "Validation loss decreased (inf --> 0.142670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1238355\n",
      "\tspeed: 0.0542s/iter; left time: 1191.4815s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123134\n",
      "\tspeed: 0.0274s/iter; left time: 599.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1200940 Vali Loss: 0.1261885 Test Loss: 0.1355995\n",
      "Validation loss decreased (0.142670 --> 0.126188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164904\n",
      "\tspeed: 0.0582s/iter; left time: 1265.1403s\n",
      "\titers: 200, epoch: 3 | loss: 0.1123756\n",
      "\tspeed: 0.0274s/iter; left time: 593.0027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1126304 Vali Loss: 0.1248742 Test Loss: 0.1346599\n",
      "Validation loss decreased (0.126188 --> 0.124874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090264\n",
      "\tspeed: 0.0564s/iter; left time: 1214.2777s\n",
      "\titers: 200, epoch: 4 | loss: 0.1161850\n",
      "\tspeed: 0.0277s/iter; left time: 593.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1108241 Vali Loss: 0.1231168 Test Loss: 0.1345049\n",
      "Validation loss decreased (0.124874 --> 0.123117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1067239\n",
      "\tspeed: 0.0557s/iter; left time: 1187.0533s\n",
      "\titers: 200, epoch: 5 | loss: 0.1134487\n",
      "\tspeed: 0.0273s/iter; left time: 578.5087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1096404 Vali Loss: 0.1232052 Test Loss: 0.1344802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1046681\n",
      "\tspeed: 0.0548s/iter; left time: 1154.7548s\n",
      "\titers: 200, epoch: 6 | loss: 0.1130422\n",
      "\tspeed: 0.0273s/iter; left time: 573.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1086139 Vali Loss: 0.1229566 Test Loss: 0.1347695\n",
      "Validation loss decreased (0.123117 --> 0.122957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1078895\n",
      "\tspeed: 0.0562s/iter; left time: 1172.1359s\n",
      "\titers: 200, epoch: 7 | loss: 0.1087261\n",
      "\tspeed: 0.0273s/iter; left time: 566.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1077184 Vali Loss: 0.1223245 Test Loss: 0.1334847\n",
      "Validation loss decreased (0.122957 --> 0.122324).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035181\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6720s\n",
      "\titers: 200, epoch: 8 | loss: 0.1118061\n",
      "\tspeed: 0.0274s/iter; left time: 562.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1069834 Vali Loss: 0.1218858 Test Loss: 0.1330454\n",
      "Validation loss decreased (0.122324 --> 0.121886).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1058632\n",
      "\tspeed: 0.0555s/iter; left time: 1132.6126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0987647\n",
      "\tspeed: 0.0272s/iter; left time: 553.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1062651 Vali Loss: 0.1219982 Test Loss: 0.1338042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1030127\n",
      "\tspeed: 0.0538s/iter; left time: 1086.2314s\n",
      "\titers: 200, epoch: 10 | loss: 0.1031541\n",
      "\tspeed: 0.0273s/iter; left time: 548.5068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1056596 Vali Loss: 0.1220121 Test Loss: 0.1338617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1061721\n",
      "\tspeed: 0.0545s/iter; left time: 1089.1685s\n",
      "\titers: 200, epoch: 11 | loss: 0.1000139\n",
      "\tspeed: 0.0286s/iter; left time: 568.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1051509 Vali Loss: 0.1223389 Test Loss: 0.1343730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1016918\n",
      "\tspeed: 0.0557s/iter; left time: 1099.9068s\n",
      "\titers: 200, epoch: 12 | loss: 0.1091376\n",
      "\tspeed: 0.0273s/iter; left time: 536.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.1046909 Vali Loss: 0.1220724 Test Loss: 0.1342280\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1095180\n",
      "\tspeed: 0.0545s/iter; left time: 1064.6654s\n",
      "\titers: 200, epoch: 13 | loss: 0.1059984\n",
      "\tspeed: 0.0273s/iter; left time: 529.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1042259 Vali Loss: 0.1223401 Test Loss: 0.1342049\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0977468\n",
      "\tspeed: 0.0541s/iter; left time: 1045.0044s\n",
      "\titers: 200, epoch: 14 | loss: 0.1107927\n",
      "\tspeed: 0.0270s/iter; left time: 518.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1039162 Vali Loss: 0.1222137 Test Loss: 0.1342742\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1054508\n",
      "\tspeed: 0.0546s/iter; left time: 1042.4705s\n",
      "\titers: 200, epoch: 15 | loss: 0.1117989\n",
      "\tspeed: 0.0273s/iter; left time: 517.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035189 Vali Loss: 0.1224293 Test Loss: 0.1347673\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1062974\n",
      "\tspeed: 0.0547s/iter; left time: 1030.8627s\n",
      "\titers: 200, epoch: 16 | loss: 0.1125161\n",
      "\tspeed: 0.0272s/iter; left time: 511.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1031467 Vali Loss: 0.1224126 Test Loss: 0.1339886\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1029710\n",
      "\tspeed: 0.0545s/iter; left time: 1015.8779s\n",
      "\titers: 200, epoch: 17 | loss: 0.1050183\n",
      "\tspeed: 0.0273s/iter; left time: 505.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1029577 Vali Loss: 0.1227930 Test Loss: 0.1340047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1025430\n",
      "\tspeed: 0.0542s/iter; left time: 998.1419s\n",
      "\titers: 200, epoch: 18 | loss: 0.1046702\n",
      "\tspeed: 0.0272s/iter; left time: 497.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1026303 Vali Loss: 0.1226197 Test Loss: 0.1343808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03874775022268295, rmse:0.19684448838233948, mae:0.13304544985294342, rse:0.6972389817237854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1546361\n",
      "\tspeed: 0.0298s/iter; left time: 662.3935s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357865\n",
      "\tspeed: 0.0272s/iter; left time: 600.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1520326 Vali Loss: 0.1427907 Test Loss: 0.1520844\n",
      "Validation loss decreased (inf --> 0.142791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1183958\n",
      "\tspeed: 0.0566s/iter; left time: 1243.1818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188114\n",
      "\tspeed: 0.0273s/iter; left time: 597.6013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1199734 Vali Loss: 0.1263667 Test Loss: 0.1363375\n",
      "Validation loss decreased (0.142791 --> 0.126367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1155362\n",
      "\tspeed: 0.0556s/iter; left time: 1208.6087s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098592\n",
      "\tspeed: 0.0272s/iter; left time: 588.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1126673 Vali Loss: 0.1251423 Test Loss: 0.1348121\n",
      "Validation loss decreased (0.126367 --> 0.125142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086826\n",
      "\tspeed: 0.0557s/iter; left time: 1199.5182s\n",
      "\titers: 200, epoch: 4 | loss: 0.1126055\n",
      "\tspeed: 0.0274s/iter; left time: 587.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1106587 Vali Loss: 0.1242879 Test Loss: 0.1354954\n",
      "Validation loss decreased (0.125142 --> 0.124288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1116844\n",
      "\tspeed: 0.0560s/iter; left time: 1194.1369s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103760\n",
      "\tspeed: 0.0274s/iter; left time: 580.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1092648 Vali Loss: 0.1238110 Test Loss: 0.1339414\n",
      "Validation loss decreased (0.124288 --> 0.123811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062780\n",
      "\tspeed: 0.0556s/iter; left time: 1172.0651s\n",
      "\titers: 200, epoch: 6 | loss: 0.1105472\n",
      "\tspeed: 0.0275s/iter; left time: 576.8189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1083813 Vali Loss: 0.1230377 Test Loss: 0.1344151\n",
      "Validation loss decreased (0.123811 --> 0.123038).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1100236\n",
      "\tspeed: 0.0563s/iter; left time: 1173.7410s\n",
      "\titers: 200, epoch: 7 | loss: 0.1094361\n",
      "\tspeed: 0.0271s/iter; left time: 563.2219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1075638 Vali Loss: 0.1233376 Test Loss: 0.1351425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1083931\n",
      "\tspeed: 0.0550s/iter; left time: 1135.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076261\n",
      "\tspeed: 0.0272s/iter; left time: 559.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.1067569 Vali Loss: 0.1231392 Test Loss: 0.1350849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042043\n",
      "\tspeed: 0.0562s/iter; left time: 1148.2966s\n",
      "\titers: 200, epoch: 9 | loss: 0.1087456\n",
      "\tspeed: 0.0286s/iter; left time: 580.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.1061874 Vali Loss: 0.1229115 Test Loss: 0.1347596\n",
      "Validation loss decreased (0.123038 --> 0.122912).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047019\n",
      "\tspeed: 0.0569s/iter; left time: 1149.2216s\n",
      "\titers: 200, epoch: 10 | loss: 0.1098653\n",
      "\tspeed: 0.0274s/iter; left time: 551.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1054878 Vali Loss: 0.1231185 Test Loss: 0.1345507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1028828\n",
      "\tspeed: 0.0549s/iter; left time: 1096.4879s\n",
      "\titers: 200, epoch: 11 | loss: 0.1091575\n",
      "\tspeed: 0.0277s/iter; left time: 549.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1048839 Vali Loss: 0.1236878 Test Loss: 0.1354434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1043799\n",
      "\tspeed: 0.0562s/iter; left time: 1109.6457s\n",
      "\titers: 200, epoch: 12 | loss: 0.1061269\n",
      "\tspeed: 0.0280s/iter; left time: 549.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.1043107 Vali Loss: 0.1239945 Test Loss: 0.1346901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1080359\n",
      "\tspeed: 0.0548s/iter; left time: 1070.4594s\n",
      "\titers: 200, epoch: 13 | loss: 0.1058448\n",
      "\tspeed: 0.0271s/iter; left time: 527.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1037742 Vali Loss: 0.1241476 Test Loss: 0.1351113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1032596\n",
      "\tspeed: 0.0556s/iter; left time: 1073.1232s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017853\n",
      "\tspeed: 0.0273s/iter; left time: 523.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1033254 Vali Loss: 0.1241768 Test Loss: 0.1357941\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1011182\n",
      "\tspeed: 0.0548s/iter; left time: 1044.6235s\n",
      "\titers: 200, epoch: 15 | loss: 0.1017340\n",
      "\tspeed: 0.0272s/iter; left time: 516.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.1029318 Vali Loss: 0.1242862 Test Loss: 0.1359198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1043327\n",
      "\tspeed: 0.0555s/iter; left time: 1046.7619s\n",
      "\titers: 200, epoch: 16 | loss: 0.1076296\n",
      "\tspeed: 0.0273s/iter; left time: 511.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1024750 Vali Loss: 0.1245145 Test Loss: 0.1355859\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1003824\n",
      "\tspeed: 0.0549s/iter; left time: 1023.8289s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016187\n",
      "\tspeed: 0.0274s/iter; left time: 507.3118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1022286 Vali Loss: 0.1240813 Test Loss: 0.1352433\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1041608\n",
      "\tspeed: 0.0561s/iter; left time: 1032.5608s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061510\n",
      "\tspeed: 0.0277s/iter; left time: 506.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1019955 Vali Loss: 0.1249169 Test Loss: 0.1354775\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1080255\n",
      "\tspeed: 0.0557s/iter; left time: 1013.8191s\n",
      "\titers: 200, epoch: 19 | loss: 0.0987023\n",
      "\tspeed: 0.0274s/iter; left time: 496.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1016865 Vali Loss: 0.1249771 Test Loss: 0.1352909\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03975802659988403, rmse:0.19939415156841278, mae:0.13475961983203888, rse:0.7062700986862183\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:20.07s\n",
      "Intermediate time for DE: 00h:27m:01.80s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1243801\n",
      "\tspeed: 0.0543s/iter; left time: 1211.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137652\n",
      "\tspeed: 0.0266s/iter; left time: 590.8778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 224 | Train Loss: 0.1302879 Vali Loss: 0.1216964 Test Loss: 0.1408504\n",
      "Validation loss decreased (inf --> 0.121696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0839070\n",
      "\tspeed: 0.0520s/iter; left time: 1147.3483s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818553\n",
      "\tspeed: 0.0265s/iter; left time: 583.1974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0865396 Vali Loss: 0.0920018 Test Loss: 0.1033591\n",
      "Validation loss decreased (0.121696 --> 0.092002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0733085\n",
      "\tspeed: 0.0515s/iter; left time: 1125.3848s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821068\n",
      "\tspeed: 0.0267s/iter; left time: 581.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0793856 Vali Loss: 0.0900384 Test Loss: 0.1024917\n",
      "Validation loss decreased (0.092002 --> 0.090038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0750556\n",
      "\tspeed: 0.0518s/iter; left time: 1121.1212s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780856\n",
      "\tspeed: 0.0264s/iter; left time: 568.7586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0779691 Vali Loss: 0.0899016 Test Loss: 0.1022058\n",
      "Validation loss decreased (0.090038 --> 0.089902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0758535\n",
      "\tspeed: 0.0517s/iter; left time: 1107.5445s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757776\n",
      "\tspeed: 0.0267s/iter; left time: 568.9676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0769919 Vali Loss: 0.0893033 Test Loss: 0.1019564\n",
      "Validation loss decreased (0.089902 --> 0.089303).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798705\n",
      "\tspeed: 0.0522s/iter; left time: 1104.7398s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816744\n",
      "\tspeed: 0.0267s/iter; left time: 563.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0762630 Vali Loss: 0.0887678 Test Loss: 0.1014424\n",
      "Validation loss decreased (0.089303 --> 0.088768).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754332\n",
      "\tspeed: 0.0518s/iter; left time: 1085.2478s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806607\n",
      "\tspeed: 0.0267s/iter; left time: 557.7843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0756519 Vali Loss: 0.0887744 Test Loss: 0.1014127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0728288\n",
      "\tspeed: 0.0511s/iter; left time: 1059.7034s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775176\n",
      "\tspeed: 0.0266s/iter; left time: 547.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0752004 Vali Loss: 0.0885392 Test Loss: 0.1006487\n",
      "Validation loss decreased (0.088768 --> 0.088539).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738876\n",
      "\tspeed: 0.0528s/iter; left time: 1082.2772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0792237\n",
      "\tspeed: 0.0268s/iter; left time: 546.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0748653 Vali Loss: 0.0884795 Test Loss: 0.1006068\n",
      "Validation loss decreased (0.088539 --> 0.088479).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808073\n",
      "\tspeed: 0.0520s/iter; left time: 1054.3701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0720843\n",
      "\tspeed: 0.0267s/iter; left time: 538.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0745151 Vali Loss: 0.0878042 Test Loss: 0.1009895\n",
      "Validation loss decreased (0.088479 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773240\n",
      "\tspeed: 0.0519s/iter; left time: 1041.0894s\n",
      "\titers: 200, epoch: 11 | loss: 0.0738162\n",
      "\tspeed: 0.0267s/iter; left time: 531.9959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0742512 Vali Loss: 0.0880865 Test Loss: 0.1001864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778451\n",
      "\tspeed: 0.0510s/iter; left time: 1012.4607s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704564\n",
      "\tspeed: 0.0267s/iter; left time: 527.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0739914 Vali Loss: 0.0879424 Test Loss: 0.1007774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728143\n",
      "\tspeed: 0.0519s/iter; left time: 1018.4859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0723630\n",
      "\tspeed: 0.0266s/iter; left time: 520.0003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0738506 Vali Loss: 0.0879685 Test Loss: 0.1000657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773398\n",
      "\tspeed: 0.0518s/iter; left time: 1004.9878s\n",
      "\titers: 200, epoch: 14 | loss: 0.0699778\n",
      "\tspeed: 0.0267s/iter; left time: 514.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0736961 Vali Loss: 0.0878420 Test Loss: 0.0999213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665786\n",
      "\tspeed: 0.0518s/iter; left time: 992.4915s\n",
      "\titers: 200, epoch: 15 | loss: 0.0686087\n",
      "\tspeed: 0.0266s/iter; left time: 507.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0734943 Vali Loss: 0.0880088 Test Loss: 0.1000402\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0704044\n",
      "\tspeed: 0.0525s/iter; left time: 993.4795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735029\n",
      "\tspeed: 0.0268s/iter; left time: 505.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0733230 Vali Loss: 0.0875390 Test Loss: 0.1002045\n",
      "Validation loss decreased (0.087804 --> 0.087539).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733052\n",
      "\tspeed: 0.0529s/iter; left time: 989.9356s\n",
      "\titers: 200, epoch: 17 | loss: 0.0776525\n",
      "\tspeed: 0.0267s/iter; left time: 496.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0732607 Vali Loss: 0.0874719 Test Loss: 0.0997542\n",
      "Validation loss decreased (0.087539 --> 0.087472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0733563\n",
      "\tspeed: 0.0528s/iter; left time: 976.5661s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740419\n",
      "\tspeed: 0.0269s/iter; left time: 493.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0731655 Vali Loss: 0.0875383 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0704366\n",
      "\tspeed: 0.0523s/iter; left time: 956.2087s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727878\n",
      "\tspeed: 0.0269s/iter; left time: 488.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0730607 Vali Loss: 0.0878342 Test Loss: 0.0998149\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639565\n",
      "\tspeed: 0.0523s/iter; left time: 943.3723s\n",
      "\titers: 200, epoch: 20 | loss: 0.0710644\n",
      "\tspeed: 0.0268s/iter; left time: 481.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0729284 Vali Loss: 0.0876287 Test Loss: 0.0996863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751909\n",
      "\tspeed: 0.0521s/iter; left time: 928.5994s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704616\n",
      "\tspeed: 0.0265s/iter; left time: 469.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0727867 Vali Loss: 0.0875195 Test Loss: 0.0996076\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0709846\n",
      "\tspeed: 0.0528s/iter; left time: 928.9821s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672187\n",
      "\tspeed: 0.0271s/iter; left time: 473.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0727850 Vali Loss: 0.0873734 Test Loss: 0.0995667\n",
      "Validation loss decreased (0.087472 --> 0.087373).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0724984\n",
      "\tspeed: 0.0546s/iter; left time: 947.7766s\n",
      "\titers: 200, epoch: 23 | loss: 0.0676599\n",
      "\tspeed: 0.0269s/iter; left time: 464.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0727007 Vali Loss: 0.0874452 Test Loss: 0.0995794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0710710\n",
      "\tspeed: 0.0533s/iter; left time: 914.8627s\n",
      "\titers: 200, epoch: 24 | loss: 0.0718718\n",
      "\tspeed: 0.0272s/iter; left time: 463.7653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0726696 Vali Loss: 0.0874877 Test Loss: 0.0994474\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0733318\n",
      "\tspeed: 0.0538s/iter; left time: 909.7842s\n",
      "\titers: 200, epoch: 25 | loss: 0.0770599\n",
      "\tspeed: 0.0271s/iter; left time: 456.1697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0726920 Vali Loss: 0.0873381 Test Loss: 0.0994857\n",
      "Validation loss decreased (0.087373 --> 0.087338).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0732230\n",
      "\tspeed: 0.0537s/iter; left time: 896.6000s\n",
      "\titers: 200, epoch: 26 | loss: 0.0704290\n",
      "\tspeed: 0.0268s/iter; left time: 445.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0726002 Vali Loss: 0.0874241 Test Loss: 0.0995524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722607\n",
      "\tspeed: 0.0535s/iter; left time: 881.7593s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757692\n",
      "\tspeed: 0.0273s/iter; left time: 446.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0725308 Vali Loss: 0.0873835 Test Loss: 0.0995856\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780362\n",
      "\tspeed: 0.0530s/iter; left time: 860.7019s\n",
      "\titers: 200, epoch: 28 | loss: 0.0754186\n",
      "\tspeed: 0.0269s/iter; left time: 433.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724948 Vali Loss: 0.0874800 Test Loss: 0.0996659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0755497\n",
      "\tspeed: 0.0534s/iter; left time: 856.6310s\n",
      "\titers: 200, epoch: 29 | loss: 0.0672095\n",
      "\tspeed: 0.0269s/iter; left time: 427.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724994 Vali Loss: 0.0873726 Test Loss: 0.0994512\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743681\n",
      "\tspeed: 0.0530s/iter; left time: 837.2495s\n",
      "\titers: 200, epoch: 30 | loss: 0.0714248\n",
      "\tspeed: 0.0268s/iter; left time: 421.2640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0724325 Vali Loss: 0.0874007 Test Loss: 0.0996015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670253\n",
      "\tspeed: 0.0540s/iter; left time: 840.9434s\n",
      "\titers: 200, epoch: 31 | loss: 0.0738778\n",
      "\tspeed: 0.0265s/iter; left time: 410.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0723963 Vali Loss: 0.0873461 Test Loss: 0.0995764\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0729594\n",
      "\tspeed: 0.0534s/iter; left time: 820.6041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0743888\n",
      "\tspeed: 0.0268s/iter; left time: 409.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0724081 Vali Loss: 0.0872245 Test Loss: 0.0994373\n",
      "Validation loss decreased (0.087338 --> 0.087224).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723266\n",
      "\tspeed: 0.0541s/iter; left time: 818.1361s\n",
      "\titers: 200, epoch: 33 | loss: 0.0713193\n",
      "\tspeed: 0.0269s/iter; left time: 404.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0723961 Vali Loss: 0.0874335 Test Loss: 0.0996177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0732763\n",
      "\tspeed: 0.0532s/iter; left time: 793.2879s\n",
      "\titers: 200, epoch: 34 | loss: 0.0748497\n",
      "\tspeed: 0.0268s/iter; left time: 396.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0723704 Vali Loss: 0.0873889 Test Loss: 0.0995195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0779761\n",
      "\tspeed: 0.0529s/iter; left time: 776.7366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0753652\n",
      "\tspeed: 0.0268s/iter; left time: 390.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723036 Vali Loss: 0.0872547 Test Loss: 0.0995013\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0686231\n",
      "\tspeed: 0.0528s/iter; left time: 764.0125s\n",
      "\titers: 200, epoch: 36 | loss: 0.0763031\n",
      "\tspeed: 0.0268s/iter; left time: 384.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722592 Vali Loss: 0.0874217 Test Loss: 0.0995324\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755020\n",
      "\tspeed: 0.0527s/iter; left time: 750.5292s\n",
      "\titers: 200, epoch: 37 | loss: 0.0714776\n",
      "\tspeed: 0.0268s/iter; left time: 378.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723462 Vali Loss: 0.0874196 Test Loss: 0.0995449\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0748234\n",
      "\tspeed: 0.0534s/iter; left time: 747.9698s\n",
      "\titers: 200, epoch: 38 | loss: 0.0689176\n",
      "\tspeed: 0.0268s/iter; left time: 373.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0723155 Vali Loss: 0.0872684 Test Loss: 0.0995207\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765601\n",
      "\tspeed: 0.0540s/iter; left time: 744.7602s\n",
      "\titers: 200, epoch: 39 | loss: 0.0677570\n",
      "\tspeed: 0.0268s/iter; left time: 366.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722663 Vali Loss: 0.0874316 Test Loss: 0.0995467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0654785\n",
      "\tspeed: 0.0528s/iter; left time: 716.1290s\n",
      "\titers: 200, epoch: 40 | loss: 0.0748680\n",
      "\tspeed: 0.0265s/iter; left time: 356.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0723363 Vali Loss: 0.0873764 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700707\n",
      "\tspeed: 0.0531s/iter; left time: 708.0991s\n",
      "\titers: 200, epoch: 41 | loss: 0.0708900\n",
      "\tspeed: 0.0270s/iter; left time: 356.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0722918 Vali Loss: 0.0873483 Test Loss: 0.0995223\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721399\n",
      "\tspeed: 0.0532s/iter; left time: 697.5313s\n",
      "\titers: 200, epoch: 42 | loss: 0.0775154\n",
      "\tspeed: 0.0272s/iter; left time: 353.7779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0722849 Vali Loss: 0.0872172 Test Loss: 0.0995116\n",
      "Validation loss decreased (0.087224 --> 0.087217).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0751871\n",
      "\tspeed: 0.0535s/iter; left time: 689.5227s\n",
      "\titers: 200, epoch: 43 | loss: 0.0700004\n",
      "\tspeed: 0.0269s/iter; left time: 343.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722874 Vali Loss: 0.0872460 Test Loss: 0.0994964\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0771745\n",
      "\tspeed: 0.0536s/iter; left time: 678.9808s\n",
      "\titers: 200, epoch: 44 | loss: 0.0732692\n",
      "\tspeed: 0.0268s/iter; left time: 336.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722729 Vali Loss: 0.0872457 Test Loss: 0.0994803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0702146\n",
      "\tspeed: 0.0527s/iter; left time: 656.2688s\n",
      "\titers: 200, epoch: 45 | loss: 0.0754088\n",
      "\tspeed: 0.0268s/iter; left time: 330.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722204 Vali Loss: 0.0872447 Test Loss: 0.0994848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0695563\n",
      "\tspeed: 0.0525s/iter; left time: 641.3707s\n",
      "\titers: 200, epoch: 46 | loss: 0.0708172\n",
      "\tspeed: 0.0269s/iter; left time: 325.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722368 Vali Loss: 0.0872585 Test Loss: 0.0994719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0748870\n",
      "\tspeed: 0.0531s/iter; left time: 636.6953s\n",
      "\titers: 200, epoch: 47 | loss: 0.0730831\n",
      "\tspeed: 0.0269s/iter; left time: 319.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722215 Vali Loss: 0.0873487 Test Loss: 0.0995225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0761661\n",
      "\tspeed: 0.0530s/iter; left time: 624.1234s\n",
      "\titers: 200, epoch: 48 | loss: 0.0745982\n",
      "\tspeed: 0.0268s/iter; left time: 312.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721901 Vali Loss: 0.0873764 Test Loss: 0.0994837\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0708556\n",
      "\tspeed: 0.0533s/iter; left time: 615.7655s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708657\n",
      "\tspeed: 0.0268s/iter; left time: 307.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0722119 Vali Loss: 0.0872935 Test Loss: 0.0994825\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738270\n",
      "\tspeed: 0.0525s/iter; left time: 594.2805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0708394\n",
      "\tspeed: 0.0269s/iter; left time: 301.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721791 Vali Loss: 0.0872133 Test Loss: 0.0994824\n",
      "Validation loss decreased (0.087217 --> 0.087213).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0729056\n",
      "\tspeed: 0.0537s/iter; left time: 596.5067s\n",
      "\titers: 200, epoch: 51 | loss: 0.0680218\n",
      "\tspeed: 0.0268s/iter; left time: 294.5880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0721853 Vali Loss: 0.0873186 Test Loss: 0.0994690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0694491\n",
      "\tspeed: 0.0528s/iter; left time: 574.4605s\n",
      "\titers: 200, epoch: 52 | loss: 0.0776386\n",
      "\tspeed: 0.0269s/iter; left time: 289.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0722179 Vali Loss: 0.0873789 Test Loss: 0.0994850\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0731650\n",
      "\tspeed: 0.0526s/iter; left time: 559.9777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0769954\n",
      "\tspeed: 0.0268s/iter; left time: 283.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0721883 Vali Loss: 0.0873961 Test Loss: 0.0994792\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0745562\n",
      "\tspeed: 0.0537s/iter; left time: 559.6576s\n",
      "\titers: 200, epoch: 54 | loss: 0.0707905\n",
      "\tspeed: 0.0268s/iter; left time: 276.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0722220 Vali Loss: 0.0872954 Test Loss: 0.0995034\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0701514\n",
      "\tspeed: 0.0533s/iter; left time: 543.8353s\n",
      "\titers: 200, epoch: 55 | loss: 0.0714959\n",
      "\tspeed: 0.0271s/iter; left time: 274.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0873029 Test Loss: 0.0994843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0704450\n",
      "\tspeed: 0.0535s/iter; left time: 534.3546s\n",
      "\titers: 200, epoch: 56 | loss: 0.0675059\n",
      "\tspeed: 0.0269s/iter; left time: 266.2749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0721501 Vali Loss: 0.0873734 Test Loss: 0.0994912\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0738333\n",
      "\tspeed: 0.0537s/iter; left time: 523.7482s\n",
      "\titers: 200, epoch: 57 | loss: 0.0705020\n",
      "\tspeed: 0.0269s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0722345 Vali Loss: 0.0874336 Test Loss: 0.0994758\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0767229\n",
      "\tspeed: 0.0527s/iter; left time: 502.0444s\n",
      "\titers: 200, epoch: 58 | loss: 0.0729605\n",
      "\tspeed: 0.0268s/iter; left time: 253.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722041 Vali Loss: 0.0873020 Test Loss: 0.0994863\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0756847\n",
      "\tspeed: 0.0534s/iter; left time: 497.0981s\n",
      "\titers: 200, epoch: 59 | loss: 0.0757611\n",
      "\tspeed: 0.0268s/iter; left time: 247.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0721992 Vali Loss: 0.0872928 Test Loss: 0.0994752\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0702965\n",
      "\tspeed: 0.0524s/iter; left time: 476.4810s\n",
      "\titers: 200, epoch: 60 | loss: 0.0741313\n",
      "\tspeed: 0.0268s/iter; left time: 240.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0722097 Vali Loss: 0.0873115 Test Loss: 0.0994877\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02502487227320671, rmse:0.15819251537322998, mae:0.09948243200778961, rse:0.54571932554245\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1281256\n",
      "\tspeed: 0.0292s/iter; left time: 650.2233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1138560\n",
      "\tspeed: 0.0268s/iter; left time: 594.1969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1290584 Vali Loss: 0.1207433 Test Loss: 0.1395016\n",
      "Validation loss decreased (inf --> 0.120743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853941\n",
      "\tspeed: 0.0536s/iter; left time: 1182.5697s\n",
      "\titers: 200, epoch: 2 | loss: 0.0847853\n",
      "\tspeed: 0.0269s/iter; left time: 590.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0861361 Vali Loss: 0.0918532 Test Loss: 0.1040095\n",
      "Validation loss decreased (0.120743 --> 0.091853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0775025\n",
      "\tspeed: 0.0535s/iter; left time: 1169.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788021\n",
      "\tspeed: 0.0268s/iter; left time: 583.5978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0792676 Vali Loss: 0.0905056 Test Loss: 0.1025451\n",
      "Validation loss decreased (0.091853 --> 0.090506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744780\n",
      "\tspeed: 0.0530s/iter; left time: 1146.1907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797157\n",
      "\tspeed: 0.0268s/iter; left time: 576.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0780674 Vali Loss: 0.0906739 Test Loss: 0.1020297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770665\n",
      "\tspeed: 0.0537s/iter; left time: 1149.1107s\n",
      "\titers: 200, epoch: 5 | loss: 0.0766374\n",
      "\tspeed: 0.0268s/iter; left time: 571.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0769707 Vali Loss: 0.0894935 Test Loss: 0.1018222\n",
      "Validation loss decreased (0.090506 --> 0.089494).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0809719\n",
      "\tspeed: 0.0542s/iter; left time: 1148.6083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820128\n",
      "\tspeed: 0.0268s/iter; left time: 565.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.0762634 Vali Loss: 0.0891491 Test Loss: 0.1013036\n",
      "Validation loss decreased (0.089494 --> 0.089149).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794357\n",
      "\tspeed: 0.0534s/iter; left time: 1119.2823s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746093\n",
      "\tspeed: 0.0269s/iter; left time: 560.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0757042 Vali Loss: 0.0887241 Test Loss: 0.1007391\n",
      "Validation loss decreased (0.089149 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761330\n",
      "\tspeed: 0.0535s/iter; left time: 1109.9562s\n",
      "\titers: 200, epoch: 8 | loss: 0.0747115\n",
      "\tspeed: 0.0269s/iter; left time: 555.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0752742 Vali Loss: 0.0889610 Test Loss: 0.1005073\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797194\n",
      "\tspeed: 0.0531s/iter; left time: 1089.4519s\n",
      "\titers: 200, epoch: 9 | loss: 0.0733876\n",
      "\tspeed: 0.0269s/iter; left time: 548.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0748621 Vali Loss: 0.0881851 Test Loss: 0.1004349\n",
      "Validation loss decreased (0.088724 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0750555\n",
      "\tspeed: 0.0529s/iter; left time: 1073.6207s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730892\n",
      "\tspeed: 0.0268s/iter; left time: 540.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0745724 Vali Loss: 0.0886613 Test Loss: 0.0999387\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0729881\n",
      "\tspeed: 0.0534s/iter; left time: 1071.6187s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750049\n",
      "\tspeed: 0.0268s/iter; left time: 534.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0742235 Vali Loss: 0.0879054 Test Loss: 0.1000553\n",
      "Validation loss decreased (0.088185 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0731180\n",
      "\tspeed: 0.0537s/iter; left time: 1065.7722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704911\n",
      "\tspeed: 0.0268s/iter; left time: 529.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0739811 Vali Loss: 0.0880940 Test Loss: 0.1000203\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0734993\n",
      "\tspeed: 0.0533s/iter; left time: 1046.3170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0771078\n",
      "\tspeed: 0.0268s/iter; left time: 522.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0738054 Vali Loss: 0.0879598 Test Loss: 0.1001505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748501\n",
      "\tspeed: 0.0532s/iter; left time: 1031.9631s\n",
      "\titers: 200, epoch: 14 | loss: 0.0740310\n",
      "\tspeed: 0.0269s/iter; left time: 518.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0736476 Vali Loss: 0.0878529 Test Loss: 0.1002746\n",
      "Validation loss decreased (0.087905 --> 0.087853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738298\n",
      "\tspeed: 0.0543s/iter; left time: 1041.4646s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762812\n",
      "\tspeed: 0.0269s/iter; left time: 513.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0735278 Vali Loss: 0.0878173 Test Loss: 0.1001467\n",
      "Validation loss decreased (0.087853 --> 0.087817).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0707365\n",
      "\tspeed: 0.0534s/iter; left time: 1010.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0745331\n",
      "\tspeed: 0.0269s/iter; left time: 505.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0732803 Vali Loss: 0.0877546 Test Loss: 0.0999003\n",
      "Validation loss decreased (0.087817 --> 0.087755).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0703407\n",
      "\tspeed: 0.0537s/iter; left time: 1005.2025s\n",
      "\titers: 200, epoch: 17 | loss: 0.0806976\n",
      "\tspeed: 0.0270s/iter; left time: 501.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 224 | Train Loss: 0.0732293 Vali Loss: 0.0877284 Test Loss: 0.1001207\n",
      "Validation loss decreased (0.087755 --> 0.087728).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0721018\n",
      "\tspeed: 0.0533s/iter; left time: 985.6505s\n",
      "\titers: 200, epoch: 18 | loss: 0.0723104\n",
      "\tspeed: 0.0268s/iter; left time: 493.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0730768 Vali Loss: 0.0877988 Test Loss: 0.0999179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0745736\n",
      "\tspeed: 0.0523s/iter; left time: 954.9691s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709844\n",
      "\tspeed: 0.0268s/iter; left time: 486.2546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0729765 Vali Loss: 0.0877342 Test Loss: 0.0999373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700831\n",
      "\tspeed: 0.0528s/iter; left time: 951.9676s\n",
      "\titers: 200, epoch: 20 | loss: 0.0720744\n",
      "\tspeed: 0.0268s/iter; left time: 480.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728975 Vali Loss: 0.0876718 Test Loss: 0.0999224\n",
      "Validation loss decreased (0.087728 --> 0.087672).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748239\n",
      "\tspeed: 0.0530s/iter; left time: 943.8389s\n",
      "\titers: 200, epoch: 21 | loss: 0.0763428\n",
      "\tspeed: 0.0268s/iter; left time: 474.5804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0728158 Vali Loss: 0.0874219 Test Loss: 0.0997877\n",
      "Validation loss decreased (0.087672 --> 0.087422).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0726125\n",
      "\tspeed: 0.0535s/iter; left time: 941.3583s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784063\n",
      "\tspeed: 0.0267s/iter; left time: 467.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0727590 Vali Loss: 0.0874105 Test Loss: 0.0995382\n",
      "Validation loss decreased (0.087422 --> 0.087410).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0671866\n",
      "\tspeed: 0.0535s/iter; left time: 929.4445s\n",
      "\titers: 200, epoch: 23 | loss: 0.0725489\n",
      "\tspeed: 0.0268s/iter; left time: 462.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0726649 Vali Loss: 0.0874186 Test Loss: 0.0996998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0776832\n",
      "\tspeed: 0.0533s/iter; left time: 913.3976s\n",
      "\titers: 200, epoch: 24 | loss: 0.0751887\n",
      "\tspeed: 0.0268s/iter; left time: 456.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0726117 Vali Loss: 0.0874993 Test Loss: 0.0999176\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748994\n",
      "\tspeed: 0.0529s/iter; left time: 894.5695s\n",
      "\titers: 200, epoch: 25 | loss: 0.0756038\n",
      "\tspeed: 0.0265s/iter; left time: 446.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0725972 Vali Loss: 0.0874437 Test Loss: 0.0998308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704204\n",
      "\tspeed: 0.0528s/iter; left time: 881.4889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690703\n",
      "\tspeed: 0.0265s/iter; left time: 439.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0725073 Vali Loss: 0.0873915 Test Loss: 0.0997966\n",
      "Validation loss decreased (0.087410 --> 0.087391).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0722938\n",
      "\tspeed: 0.0550s/iter; left time: 906.8522s\n",
      "\titers: 200, epoch: 27 | loss: 0.0707320\n",
      "\tspeed: 0.0269s/iter; left time: 440.5791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0724955 Vali Loss: 0.0874042 Test Loss: 0.0997572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708005\n",
      "\tspeed: 0.0524s/iter; left time: 852.1813s\n",
      "\titers: 200, epoch: 28 | loss: 0.0706717\n",
      "\tspeed: 0.0265s/iter; left time: 427.8731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0725039 Vali Loss: 0.0873560 Test Loss: 0.0996761\n",
      "Validation loss decreased (0.087391 --> 0.087356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742883\n",
      "\tspeed: 0.0536s/iter; left time: 859.0053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742773\n",
      "\tspeed: 0.0269s/iter; left time: 427.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724317 Vali Loss: 0.0874750 Test Loss: 0.0997233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733841\n",
      "\tspeed: 0.0534s/iter; left time: 844.4930s\n",
      "\titers: 200, epoch: 30 | loss: 0.0713019\n",
      "\tspeed: 0.0268s/iter; left time: 421.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0724177 Vali Loss: 0.0873239 Test Loss: 0.0995659\n",
      "Validation loss decreased (0.087356 --> 0.087324).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0728526\n",
      "\tspeed: 0.0535s/iter; left time: 834.2808s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712871\n",
      "\tspeed: 0.0268s/iter; left time: 414.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0723862 Vali Loss: 0.0873993 Test Loss: 0.0997216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745156\n",
      "\tspeed: 0.0529s/iter; left time: 811.9430s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705794\n",
      "\tspeed: 0.0267s/iter; left time: 407.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0723662 Vali Loss: 0.0874361 Test Loss: 0.0997775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0698627\n",
      "\tspeed: 0.0531s/iter; left time: 804.2879s\n",
      "\titers: 200, epoch: 33 | loss: 0.0744560\n",
      "\tspeed: 0.0267s/iter; left time: 401.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723162 Vali Loss: 0.0872565 Test Loss: 0.0996848\n",
      "Validation loss decreased (0.087324 --> 0.087256).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720458\n",
      "\tspeed: 0.0529s/iter; left time: 789.0979s\n",
      "\titers: 200, epoch: 34 | loss: 0.0796783\n",
      "\tspeed: 0.0267s/iter; left time: 395.3279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722920 Vali Loss: 0.0873715 Test Loss: 0.0996110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0731819\n",
      "\tspeed: 0.0527s/iter; left time: 773.4842s\n",
      "\titers: 200, epoch: 35 | loss: 0.0786404\n",
      "\tspeed: 0.0267s/iter; left time: 389.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723127 Vali Loss: 0.0874032 Test Loss: 0.0996725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0717856\n",
      "\tspeed: 0.0527s/iter; left time: 761.5788s\n",
      "\titers: 200, epoch: 36 | loss: 0.0735888\n",
      "\tspeed: 0.0267s/iter; left time: 383.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0723288 Vali Loss: 0.0872270 Test Loss: 0.0996796\n",
      "Validation loss decreased (0.087256 --> 0.087227).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0752889\n",
      "\tspeed: 0.0529s/iter; left time: 753.7263s\n",
      "\titers: 200, epoch: 37 | loss: 0.0713401\n",
      "\tspeed: 0.0268s/iter; left time: 378.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0723031 Vali Loss: 0.0874127 Test Loss: 0.0996993\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0730377\n",
      "\tspeed: 0.0528s/iter; left time: 740.2937s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670286\n",
      "\tspeed: 0.0266s/iter; left time: 369.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0722490 Vali Loss: 0.0873063 Test Loss: 0.0996096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0739416\n",
      "\tspeed: 0.0528s/iter; left time: 727.5970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706054\n",
      "\tspeed: 0.0266s/iter; left time: 364.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0722615 Vali Loss: 0.0873521 Test Loss: 0.0996684\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0689131\n",
      "\tspeed: 0.0538s/iter; left time: 729.3039s\n",
      "\titers: 200, epoch: 40 | loss: 0.0731106\n",
      "\tspeed: 0.0269s/iter; left time: 362.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 224 | Train Loss: 0.0722557 Vali Loss: 0.0874369 Test Loss: 0.0997051\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0715132\n",
      "\tspeed: 0.0532s/iter; left time: 710.0583s\n",
      "\titers: 200, epoch: 41 | loss: 0.0690387\n",
      "\tspeed: 0.0267s/iter; left time: 353.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722332 Vali Loss: 0.0872902 Test Loss: 0.0996747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0766864\n",
      "\tspeed: 0.0525s/iter; left time: 688.9114s\n",
      "\titers: 200, epoch: 42 | loss: 0.0704855\n",
      "\tspeed: 0.0265s/iter; left time: 345.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 224 | Train Loss: 0.0722141 Vali Loss: 0.0873723 Test Loss: 0.0996596\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0717274\n",
      "\tspeed: 0.0530s/iter; left time: 683.2456s\n",
      "\titers: 200, epoch: 43 | loss: 0.0687616\n",
      "\tspeed: 0.0274s/iter; left time: 350.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0721847 Vali Loss: 0.0872899 Test Loss: 0.0996401\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0682925\n",
      "\tspeed: 0.0532s/iter; left time: 673.6730s\n",
      "\titers: 200, epoch: 44 | loss: 0.0717148\n",
      "\tspeed: 0.0267s/iter; left time: 336.1236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0722191 Vali Loss: 0.0873592 Test Loss: 0.0996715\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0739661\n",
      "\tspeed: 0.0526s/iter; left time: 654.3423s\n",
      "\titers: 200, epoch: 45 | loss: 0.0704421\n",
      "\tspeed: 0.0268s/iter; left time: 330.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721614 Vali Loss: 0.0873060 Test Loss: 0.0996651\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0744253\n",
      "\tspeed: 0.0525s/iter; left time: 642.1980s\n",
      "\titers: 200, epoch: 46 | loss: 0.0733730\n",
      "\tspeed: 0.0268s/iter; left time: 324.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0721902 Vali Loss: 0.0871615 Test Loss: 0.0996455\n",
      "Validation loss decreased (0.087227 --> 0.087162).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738844\n",
      "\tspeed: 0.0523s/iter; left time: 627.0182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0732504\n",
      "\tspeed: 0.0265s/iter; left time: 315.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0721966 Vali Loss: 0.0873352 Test Loss: 0.0996582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0738569\n",
      "\tspeed: 0.0522s/iter; left time: 615.0724s\n",
      "\titers: 200, epoch: 48 | loss: 0.0660235\n",
      "\tspeed: 0.0265s/iter; left time: 309.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721567 Vali Loss: 0.0874393 Test Loss: 0.0996577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0700567\n",
      "\tspeed: 0.0530s/iter; left time: 611.5923s\n",
      "\titers: 200, epoch: 49 | loss: 0.0708773\n",
      "\tspeed: 0.0268s/iter; left time: 306.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0721437 Vali Loss: 0.0873161 Test Loss: 0.0996556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0701776\n",
      "\tspeed: 0.0522s/iter; left time: 590.7105s\n",
      "\titers: 200, epoch: 50 | loss: 0.0751142\n",
      "\tspeed: 0.0267s/iter; left time: 299.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0721538 Vali Loss: 0.0873739 Test Loss: 0.0996439\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0683126\n",
      "\tspeed: 0.0519s/iter; left time: 576.3710s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737489\n",
      "\tspeed: 0.0270s/iter; left time: 297.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0721442 Vali Loss: 0.0874031 Test Loss: 0.0996389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0686506\n",
      "\tspeed: 0.0521s/iter; left time: 566.9737s\n",
      "\titers: 200, epoch: 52 | loss: 0.0714018\n",
      "\tspeed: 0.0266s/iter; left time: 286.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0721793 Vali Loss: 0.0872806 Test Loss: 0.0996446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0680443\n",
      "\tspeed: 0.0520s/iter; left time: 553.8117s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746092\n",
      "\tspeed: 0.0268s/iter; left time: 282.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0721653 Vali Loss: 0.0872594 Test Loss: 0.0996658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0697796\n",
      "\tspeed: 0.0522s/iter; left time: 544.4062s\n",
      "\titers: 200, epoch: 54 | loss: 0.0704911\n",
      "\tspeed: 0.0264s/iter; left time: 273.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721745 Vali Loss: 0.0874115 Test Loss: 0.0996338\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0660143\n",
      "\tspeed: 0.0517s/iter; left time: 527.2257s\n",
      "\titers: 200, epoch: 55 | loss: 0.0712318\n",
      "\tspeed: 0.0265s/iter; left time: 268.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0721330 Vali Loss: 0.0873371 Test Loss: 0.0996511\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0705199\n",
      "\tspeed: 0.0519s/iter; left time: 518.3399s\n",
      "\titers: 200, epoch: 56 | loss: 0.0784174\n",
      "\tspeed: 0.0265s/iter; left time: 262.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0721358 Vali Loss: 0.0872928 Test Loss: 0.0996450\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025020133703947067, rmse:0.15817753970623016, mae:0.09964548796415329, rse:0.5456676483154297\n",
      "Intermediate time for GB and pred_len 24: 00h:15m:37.54s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1362466\n",
      "\tspeed: 0.0553s/iter; left time: 1234.0899s\n",
      "\titers: 200, epoch: 1 | loss: 0.1315828\n",
      "\tspeed: 0.0268s/iter; left time: 594.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 224 | Train Loss: 0.1354785 Vali Loss: 0.1317148 Test Loss: 0.1549259\n",
      "Validation loss decreased (inf --> 0.131715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100148\n",
      "\tspeed: 0.0537s/iter; left time: 1185.5225s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011972\n",
      "\tspeed: 0.0269s/iter; left time: 590.6520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.1090403 Vali Loss: 0.1182589 Test Loss: 0.1401924\n",
      "Validation loss decreased (0.131715 --> 0.118259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020023\n",
      "\tspeed: 0.0538s/iter; left time: 1174.9266s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028889\n",
      "\tspeed: 0.0270s/iter; left time: 586.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.1039733 Vali Loss: 0.1175403 Test Loss: 0.1411576\n",
      "Validation loss decreased (0.118259 --> 0.117540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1018276\n",
      "\tspeed: 0.0529s/iter; left time: 1143.3982s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026525\n",
      "\tspeed: 0.0270s/iter; left time: 581.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1026064 Vali Loss: 0.1166299 Test Loss: 0.1399759\n",
      "Validation loss decreased (0.117540 --> 0.116630).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026763\n",
      "\tspeed: 0.0534s/iter; left time: 1144.0695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0943075\n",
      "\tspeed: 0.0268s/iter; left time: 570.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1015074 Vali Loss: 0.1164241 Test Loss: 0.1412032\n",
      "Validation loss decreased (0.116630 --> 0.116424).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1025002\n",
      "\tspeed: 0.0531s/iter; left time: 1123.7738s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032541\n",
      "\tspeed: 0.0271s/iter; left time: 571.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1006094 Vali Loss: 0.1160348 Test Loss: 0.1397788\n",
      "Validation loss decreased (0.116424 --> 0.116035).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038390\n",
      "\tspeed: 0.0535s/iter; left time: 1121.2498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0969341\n",
      "\tspeed: 0.0268s/iter; left time: 559.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0997999 Vali Loss: 0.1159833 Test Loss: 0.1389591\n",
      "Validation loss decreased (0.116035 --> 0.115983).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1006562\n",
      "\tspeed: 0.0540s/iter; left time: 1120.2872s\n",
      "\titers: 200, epoch: 8 | loss: 0.0981172\n",
      "\tspeed: 0.0270s/iter; left time: 557.5209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0990484 Vali Loss: 0.1169135 Test Loss: 0.1407297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0989951\n",
      "\tspeed: 0.0535s/iter; left time: 1097.1081s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990440\n",
      "\tspeed: 0.0271s/iter; left time: 553.4864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0983205 Vali Loss: 0.1171196 Test Loss: 0.1430553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1003540\n",
      "\tspeed: 0.0529s/iter; left time: 1073.5132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0943393\n",
      "\tspeed: 0.0269s/iter; left time: 543.6021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0977161 Vali Loss: 0.1167704 Test Loss: 0.1415311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969625\n",
      "\tspeed: 0.0539s/iter; left time: 1081.2312s\n",
      "\titers: 200, epoch: 11 | loss: 0.0986367\n",
      "\tspeed: 0.0268s/iter; left time: 534.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0971241 Vali Loss: 0.1168764 Test Loss: 0.1429615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1012906\n",
      "\tspeed: 0.0530s/iter; left time: 1051.5503s\n",
      "\titers: 200, epoch: 12 | loss: 0.0969430\n",
      "\tspeed: 0.0268s/iter; left time: 529.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0966664 Vali Loss: 0.1162381 Test Loss: 0.1405379\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961613\n",
      "\tspeed: 0.0536s/iter; left time: 1050.6042s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981514\n",
      "\tspeed: 0.0270s/iter; left time: 525.9338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0962394 Vali Loss: 0.1173263 Test Loss: 0.1436641\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0961513\n",
      "\tspeed: 0.0532s/iter; left time: 1031.3833s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940166\n",
      "\tspeed: 0.0269s/iter; left time: 518.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0958293 Vali Loss: 0.1172846 Test Loss: 0.1412998\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0907448\n",
      "\tspeed: 0.0530s/iter; left time: 1015.5836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0936777\n",
      "\tspeed: 0.0269s/iter; left time: 513.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0954853 Vali Loss: 0.1174681 Test Loss: 0.1431191\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0971071\n",
      "\tspeed: 0.0530s/iter; left time: 1004.5613s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991246\n",
      "\tspeed: 0.0270s/iter; left time: 508.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0951561 Vali Loss: 0.1177430 Test Loss: 0.1433660\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0933138\n",
      "\tspeed: 0.0532s/iter; left time: 996.3669s\n",
      "\titers: 200, epoch: 17 | loss: 0.0953560\n",
      "\tspeed: 0.0270s/iter; left time: 502.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0948642 Vali Loss: 0.1173937 Test Loss: 0.1422419\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04156280308961868, rmse:0.20386956632137299, mae:0.138959139585495, rse:0.705009400844574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1342963\n",
      "\tspeed: 0.0294s/iter; left time: 655.5017s\n",
      "\titers: 200, epoch: 1 | loss: 0.1212572\n",
      "\tspeed: 0.0270s/iter; left time: 598.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 224 | Train Loss: 0.1354378 Vali Loss: 0.1306439 Test Loss: 0.1532763\n",
      "Validation loss decreased (inf --> 0.130644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1063669\n",
      "\tspeed: 0.0539s/iter; left time: 1190.0957s\n",
      "\titers: 200, epoch: 2 | loss: 0.1015290\n",
      "\tspeed: 0.0268s/iter; left time: 588.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.1090908 Vali Loss: 0.1179647 Test Loss: 0.1400083\n",
      "Validation loss decreased (0.130644 --> 0.117965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034727\n",
      "\tspeed: 0.0543s/iter; left time: 1186.3327s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050127\n",
      "\tspeed: 0.0268s/iter; left time: 582.9759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1041194 Vali Loss: 0.1176144 Test Loss: 0.1397710\n",
      "Validation loss decreased (0.117965 --> 0.117614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0971245\n",
      "\tspeed: 0.0556s/iter; left time: 1202.5577s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046980\n",
      "\tspeed: 0.0271s/iter; left time: 583.1737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.1028142 Vali Loss: 0.1171384 Test Loss: 0.1404998\n",
      "Validation loss decreased (0.117614 --> 0.117138).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977949\n",
      "\tspeed: 0.0553s/iter; left time: 1182.8713s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043665\n",
      "\tspeed: 0.0268s/iter; left time: 571.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1018217 Vali Loss: 0.1171914 Test Loss: 0.1403327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947371\n",
      "\tspeed: 0.0534s/iter; left time: 1131.0207s\n",
      "\titers: 200, epoch: 6 | loss: 0.1068232\n",
      "\tspeed: 0.0268s/iter; left time: 564.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.1010497 Vali Loss: 0.1167937 Test Loss: 0.1400926\n",
      "Validation loss decreased (0.117138 --> 0.116794).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0955816\n",
      "\tspeed: 0.0545s/iter; left time: 1143.1946s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973860\n",
      "\tspeed: 0.0267s/iter; left time: 557.5776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.1002006 Vali Loss: 0.1169059 Test Loss: 0.1398973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982215\n",
      "\tspeed: 0.0550s/iter; left time: 1140.3708s\n",
      "\titers: 200, epoch: 8 | loss: 0.0986912\n",
      "\tspeed: 0.0269s/iter; left time: 555.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0995622 Vali Loss: 0.1171644 Test Loss: 0.1394792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0983291\n",
      "\tspeed: 0.0544s/iter; left time: 1115.5611s\n",
      "\titers: 200, epoch: 9 | loss: 0.1015055\n",
      "\tspeed: 0.0267s/iter; left time: 544.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0990405 Vali Loss: 0.1170354 Test Loss: 0.1404738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0966749\n",
      "\tspeed: 0.0548s/iter; left time: 1111.2377s\n",
      "\titers: 200, epoch: 10 | loss: 0.0984571\n",
      "\tspeed: 0.0271s/iter; left time: 547.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0984118 Vali Loss: 0.1174196 Test Loss: 0.1405433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945642\n",
      "\tspeed: 0.0554s/iter; left time: 1111.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0937180\n",
      "\tspeed: 0.0268s/iter; left time: 534.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0979818 Vali Loss: 0.1171703 Test Loss: 0.1407737\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0964229\n",
      "\tspeed: 0.0543s/iter; left time: 1077.2916s\n",
      "\titers: 200, epoch: 12 | loss: 0.1007808\n",
      "\tspeed: 0.0270s/iter; left time: 533.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.0975590 Vali Loss: 0.1174397 Test Loss: 0.1414426\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0947333\n",
      "\tspeed: 0.0534s/iter; left time: 1048.2167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0915383\n",
      "\tspeed: 0.0268s/iter; left time: 523.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0971209 Vali Loss: 0.1181216 Test Loss: 0.1418197\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0964207\n",
      "\tspeed: 0.0543s/iter; left time: 1053.2275s\n",
      "\titers: 200, epoch: 14 | loss: 0.0957182\n",
      "\tspeed: 0.0268s/iter; left time: 516.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 224 | Train Loss: 0.0966924 Vali Loss: 0.1173833 Test Loss: 0.1408844\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0976923\n",
      "\tspeed: 0.0538s/iter; left time: 1031.1701s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943371\n",
      "\tspeed: 0.0268s/iter; left time: 511.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0964538 Vali Loss: 0.1180992 Test Loss: 0.1427835\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0937670\n",
      "\tspeed: 0.0538s/iter; left time: 1018.7485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0968458\n",
      "\tspeed: 0.0268s/iter; left time: 505.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0961151 Vali Loss: 0.1176016 Test Loss: 0.1419638\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04211575910449028, rmse:0.2052212506532669, mae:0.1400926262140274, rse:0.7096836566925049\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:39.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354124\n",
      "\tspeed: 0.0554s/iter; left time: 1229.6732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1269919\n",
      "\tspeed: 0.0271s/iter; left time: 599.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 223 | Train Loss: 0.1370751 Vali Loss: 0.1339571 Test Loss: 0.1580050\n",
      "Validation loss decreased (inf --> 0.133957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1144067\n",
      "\tspeed: 0.0538s/iter; left time: 1181.8960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070809\n",
      "\tspeed: 0.0271s/iter; left time: 593.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.1134790 Vali Loss: 0.1227112 Test Loss: 0.1471968\n",
      "Validation loss decreased (0.133957 --> 0.122711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099978\n",
      "\tspeed: 0.0546s/iter; left time: 1186.9160s\n",
      "\titers: 200, epoch: 3 | loss: 0.1067006\n",
      "\tspeed: 0.0272s/iter; left time: 588.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.1086630 Vali Loss: 0.1216847 Test Loss: 0.1465340\n",
      "Validation loss decreased (0.122711 --> 0.121685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087929\n",
      "\tspeed: 0.0553s/iter; left time: 1189.7324s\n",
      "\titers: 200, epoch: 4 | loss: 0.1128875\n",
      "\tspeed: 0.0271s/iter; left time: 580.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1071564 Vali Loss: 0.1216329 Test Loss: 0.1464036\n",
      "Validation loss decreased (0.121685 --> 0.121633).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036660\n",
      "\tspeed: 0.0565s/iter; left time: 1204.0028s\n",
      "\titers: 200, epoch: 5 | loss: 0.1098936\n",
      "\tspeed: 0.0271s/iter; left time: 575.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.1058232 Vali Loss: 0.1211363 Test Loss: 0.1468929\n",
      "Validation loss decreased (0.121633 --> 0.121136).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1023184\n",
      "\tspeed: 0.0551s/iter; left time: 1162.4825s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047149\n",
      "\tspeed: 0.0272s/iter; left time: 570.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.1045786 Vali Loss: 0.1214660 Test Loss: 0.1477442\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1030283\n",
      "\tspeed: 0.0551s/iter; left time: 1148.7618s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983301\n",
      "\tspeed: 0.0274s/iter; left time: 568.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1035771 Vali Loss: 0.1215716 Test Loss: 0.1494350\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1021642\n",
      "\tspeed: 0.0551s/iter; left time: 1137.1951s\n",
      "\titers: 200, epoch: 8 | loss: 0.1072234\n",
      "\tspeed: 0.0274s/iter; left time: 562.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026726 Vali Loss: 0.1215428 Test Loss: 0.1478654\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027741\n",
      "\tspeed: 0.0555s/iter; left time: 1132.5589s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979295\n",
      "\tspeed: 0.0273s/iter; left time: 554.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1020552 Vali Loss: 0.1213815 Test Loss: 0.1498316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996236\n",
      "\tspeed: 0.0543s/iter; left time: 1096.0517s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013777\n",
      "\tspeed: 0.0273s/iter; left time: 548.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.1013867 Vali Loss: 0.1220490 Test Loss: 0.1514326\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994694\n",
      "\tspeed: 0.0553s/iter; left time: 1104.2498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0999421\n",
      "\tspeed: 0.0274s/iter; left time: 543.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.1007758 Vali Loss: 0.1213371 Test Loss: 0.1484833\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0966362\n",
      "\tspeed: 0.0549s/iter; left time: 1083.1968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990719\n",
      "\tspeed: 0.0273s/iter; left time: 535.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1002209 Vali Loss: 0.1218838 Test Loss: 0.1496712\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996767\n",
      "\tspeed: 0.0548s/iter; left time: 1070.0136s\n",
      "\titers: 200, epoch: 13 | loss: 0.1026959\n",
      "\tspeed: 0.0272s/iter; left time: 528.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0997564 Vali Loss: 0.1217964 Test Loss: 0.1501298\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0985504\n",
      "\tspeed: 0.0554s/iter; left time: 1068.8520s\n",
      "\titers: 200, epoch: 14 | loss: 0.0999128\n",
      "\tspeed: 0.0272s/iter; left time: 523.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0993586 Vali Loss: 0.1223004 Test Loss: 0.1509998\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1021761\n",
      "\tspeed: 0.0548s/iter; left time: 1045.3280s\n",
      "\titers: 200, epoch: 15 | loss: 0.1022515\n",
      "\tspeed: 0.0273s/iter; left time: 517.9778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0989366 Vali Loss: 0.1226592 Test Loss: 0.1515421\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459306597709656, rmse:0.21117070317268372, mae:0.14689284563064575, rse:0.7321591973304749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343334\n",
      "\tspeed: 0.0304s/iter; left time: 675.5745s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274043\n",
      "\tspeed: 0.0273s/iter; left time: 604.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.1373720 Vali Loss: 0.1342096 Test Loss: 0.1581728\n",
      "Validation loss decreased (inf --> 0.134210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1134263\n",
      "\tspeed: 0.0564s/iter; left time: 1240.0853s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105637\n",
      "\tspeed: 0.0276s/iter; left time: 603.9956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.1132997 Vali Loss: 0.1233650 Test Loss: 0.1481477\n",
      "Validation loss decreased (0.134210 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1110428\n",
      "\tspeed: 0.0561s/iter; left time: 1219.9967s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082572\n",
      "\tspeed: 0.0271s/iter; left time: 587.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1087510 Vali Loss: 0.1223908 Test Loss: 0.1466880\n",
      "Validation loss decreased (0.123365 --> 0.122391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1091575\n",
      "\tspeed: 0.0577s/iter; left time: 1241.7612s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072541\n",
      "\tspeed: 0.0274s/iter; left time: 587.3713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.1072281 Vali Loss: 0.1221424 Test Loss: 0.1471605\n",
      "Validation loss decreased (0.122391 --> 0.122142).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074684\n",
      "\tspeed: 0.0569s/iter; left time: 1212.2677s\n",
      "\titers: 200, epoch: 5 | loss: 0.1056222\n",
      "\tspeed: 0.0274s/iter; left time: 581.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.1056581 Vali Loss: 0.1219717 Test Loss: 0.1469719\n",
      "Validation loss decreased (0.122142 --> 0.121972).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063322\n",
      "\tspeed: 0.0565s/iter; left time: 1192.2183s\n",
      "\titers: 200, epoch: 6 | loss: 0.1021206\n",
      "\tspeed: 0.0273s/iter; left time: 572.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.1043592 Vali Loss: 0.1220159 Test Loss: 0.1479042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1007787\n",
      "\tspeed: 0.0559s/iter; left time: 1165.4247s\n",
      "\titers: 200, epoch: 7 | loss: 0.1071176\n",
      "\tspeed: 0.0273s/iter; left time: 565.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1034426 Vali Loss: 0.1219470 Test Loss: 0.1468008\n",
      "Validation loss decreased (0.121972 --> 0.121947).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024007\n",
      "\tspeed: 0.0562s/iter; left time: 1159.3587s\n",
      "\titers: 200, epoch: 8 | loss: 0.1011106\n",
      "\tspeed: 0.0273s/iter; left time: 560.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.1026371 Vali Loss: 0.1226881 Test Loss: 0.1485755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010926\n",
      "\tspeed: 0.0561s/iter; left time: 1146.1769s\n",
      "\titers: 200, epoch: 9 | loss: 0.1037420\n",
      "\tspeed: 0.0273s/iter; left time: 555.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.1018770 Vali Loss: 0.1230170 Test Loss: 0.1505015\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995526\n",
      "\tspeed: 0.0558s/iter; left time: 1126.7199s\n",
      "\titers: 200, epoch: 10 | loss: 0.1030146\n",
      "\tspeed: 0.0273s/iter; left time: 549.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.1011918 Vali Loss: 0.1236346 Test Loss: 0.1512475\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1019870\n",
      "\tspeed: 0.0558s/iter; left time: 1114.2898s\n",
      "\titers: 200, epoch: 11 | loss: 0.1035597\n",
      "\tspeed: 0.0274s/iter; left time: 543.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1005595 Vali Loss: 0.1228452 Test Loss: 0.1502132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1003256\n",
      "\tspeed: 0.0562s/iter; left time: 1110.7425s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002665\n",
      "\tspeed: 0.0273s/iter; left time: 537.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.1000163 Vali Loss: 0.1234094 Test Loss: 0.1494783\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1022886\n",
      "\tspeed: 0.0564s/iter; left time: 1101.7633s\n",
      "\titers: 200, epoch: 13 | loss: 0.1002941\n",
      "\tspeed: 0.0274s/iter; left time: 531.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0994505 Vali Loss: 0.1235107 Test Loss: 0.1497943\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975255\n",
      "\tspeed: 0.0559s/iter; left time: 1078.1402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0986446\n",
      "\tspeed: 0.0274s/iter; left time: 526.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0990837 Vali Loss: 0.1231035 Test Loss: 0.1512404\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982782\n",
      "\tspeed: 0.0557s/iter; left time: 1061.8515s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003537\n",
      "\tspeed: 0.0273s/iter; left time: 518.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0986666 Vali Loss: 0.1234591 Test Loss: 0.1508010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1010868\n",
      "\tspeed: 0.0562s/iter; left time: 1058.7894s\n",
      "\titers: 200, epoch: 16 | loss: 0.1004014\n",
      "\tspeed: 0.0274s/iter; left time: 513.3969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0983119 Vali Loss: 0.1234264 Test Loss: 0.1515623\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0973225\n",
      "\tspeed: 0.0560s/iter; left time: 1042.6396s\n",
      "\titers: 200, epoch: 17 | loss: 0.0972442\n",
      "\tspeed: 0.0271s/iter; left time: 502.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0979932 Vali Loss: 0.1239732 Test Loss: 0.1527091\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04486566409468651, rmse:0.21181516349315643, mae:0.14680077135562897, rse:0.7343935966491699\n",
      "Intermediate time for GB and pred_len 168: 00h:04m:39.74s\n",
      "Intermediate time for GB: 00h:24m:56.87s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1297289\n",
      "\tspeed: 0.0455s/iter; left time: 1015.3594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1126045\n",
      "\tspeed: 0.0178s/iter; left time: 395.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1356361 Vali Loss: 0.0979728 Test Loss: 0.1105253\n",
      "Validation loss decreased (inf --> 0.097973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740920\n",
      "\tspeed: 0.0365s/iter; left time: 805.5324s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695283\n",
      "\tspeed: 0.0174s/iter; left time: 382.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0769994 Vali Loss: 0.0646745 Test Loss: 0.0711548\n",
      "Validation loss decreased (0.097973 --> 0.064675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641058\n",
      "\tspeed: 0.0361s/iter; left time: 789.8069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0647144\n",
      "\tspeed: 0.0174s/iter; left time: 378.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0655269 Vali Loss: 0.0602642 Test Loss: 0.0665508\n",
      "Validation loss decreased (0.064675 --> 0.060264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620353\n",
      "\tspeed: 0.0359s/iter; left time: 777.5343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641675\n",
      "\tspeed: 0.0180s/iter; left time: 386.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0622778 Vali Loss: 0.0589169 Test Loss: 0.0652260\n",
      "Validation loss decreased (0.060264 --> 0.058917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600411\n",
      "\tspeed: 0.0386s/iter; left time: 827.2866s\n",
      "\titers: 200, epoch: 5 | loss: 0.0605951\n",
      "\tspeed: 0.0208s/iter; left time: 443.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0604136 Vali Loss: 0.0574598 Test Loss: 0.0637832\n",
      "Validation loss decreased (0.058917 --> 0.057460).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0576362\n",
      "\tspeed: 0.0362s/iter; left time: 767.1964s\n",
      "\titers: 200, epoch: 6 | loss: 0.0572372\n",
      "\tspeed: 0.0185s/iter; left time: 389.9134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0592250 Vali Loss: 0.0569232 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.057460 --> 0.056923).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0641758\n",
      "\tspeed: 0.0404s/iter; left time: 847.3156s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604304\n",
      "\tspeed: 0.0228s/iter; left time: 474.5829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0582727 Vali Loss: 0.0563158 Test Loss: 0.0624014\n",
      "Validation loss decreased (0.056923 --> 0.056316).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597004\n",
      "\tspeed: 0.0397s/iter; left time: 823.0412s\n",
      "\titers: 200, epoch: 8 | loss: 0.0545038\n",
      "\tspeed: 0.0217s/iter; left time: 448.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0575341 Vali Loss: 0.0555614 Test Loss: 0.0619747\n",
      "Validation loss decreased (0.056316 --> 0.055561).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0581241\n",
      "\tspeed: 0.0373s/iter; left time: 764.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0560733\n",
      "\tspeed: 0.0177s/iter; left time: 361.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0569077 Vali Loss: 0.0551520 Test Loss: 0.0613294\n",
      "Validation loss decreased (0.055561 --> 0.055152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600654\n",
      "\tspeed: 0.0369s/iter; left time: 748.1508s\n",
      "\titers: 200, epoch: 10 | loss: 0.0543051\n",
      "\tspeed: 0.0173s/iter; left time: 349.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0564565 Vali Loss: 0.0552002 Test Loss: 0.0615373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0573782\n",
      "\tspeed: 0.0354s/iter; left time: 710.7419s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561891\n",
      "\tspeed: 0.0173s/iter; left time: 346.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0560166 Vali Loss: 0.0547021 Test Loss: 0.0608617\n",
      "Validation loss decreased (0.055152 --> 0.054702).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549166\n",
      "\tspeed: 0.0368s/iter; left time: 730.5754s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550303\n",
      "\tspeed: 0.0175s/iter; left time: 345.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0556077 Vali Loss: 0.0544642 Test Loss: 0.0607819\n",
      "Validation loss decreased (0.054702 --> 0.054464).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0530001\n",
      "\tspeed: 0.0374s/iter; left time: 734.4276s\n",
      "\titers: 200, epoch: 13 | loss: 0.0505261\n",
      "\tspeed: 0.0172s/iter; left time: 336.1488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0553481 Vali Loss: 0.0544108 Test Loss: 0.0603867\n",
      "Validation loss decreased (0.054464 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576824\n",
      "\tspeed: 0.0382s/iter; left time: 741.3690s\n",
      "\titers: 200, epoch: 14 | loss: 0.0537340\n",
      "\tspeed: 0.0180s/iter; left time: 347.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0550210 Vali Loss: 0.0542770 Test Loss: 0.0605504\n",
      "Validation loss decreased (0.054411 --> 0.054277).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0541440\n",
      "\tspeed: 0.0374s/iter; left time: 716.8168s\n",
      "\titers: 200, epoch: 15 | loss: 0.0551845\n",
      "\tspeed: 0.0176s/iter; left time: 336.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0547780 Vali Loss: 0.0540772 Test Loss: 0.0603587\n",
      "Validation loss decreased (0.054277 --> 0.054077).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509629\n",
      "\tspeed: 0.0377s/iter; left time: 714.1568s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555559\n",
      "\tspeed: 0.0201s/iter; left time: 379.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0545937 Vali Loss: 0.0540071 Test Loss: 0.0602936\n",
      "Validation loss decreased (0.054077 --> 0.054007).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533449\n",
      "\tspeed: 0.0376s/iter; left time: 702.8441s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549480\n",
      "\tspeed: 0.0232s/iter; left time: 431.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543840 Vali Loss: 0.0535351 Test Loss: 0.0598909\n",
      "Validation loss decreased (0.054007 --> 0.053535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534377\n",
      "\tspeed: 0.0413s/iter; left time: 763.0813s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519669\n",
      "\tspeed: 0.0180s/iter; left time: 330.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0541835 Vali Loss: 0.0535182 Test Loss: 0.0599301\n",
      "Validation loss decreased (0.053535 --> 0.053518).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0546421\n",
      "\tspeed: 0.0365s/iter; left time: 666.7154s\n",
      "\titers: 200, epoch: 19 | loss: 0.0532574\n",
      "\tspeed: 0.0173s/iter; left time: 315.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0541097 Vali Loss: 0.0536294 Test Loss: 0.0598268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0540954\n",
      "\tspeed: 0.0388s/iter; left time: 699.9337s\n",
      "\titers: 200, epoch: 20 | loss: 0.0566773\n",
      "\tspeed: 0.0218s/iter; left time: 391.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0538978 Vali Loss: 0.0535801 Test Loss: 0.0599190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0543947\n",
      "\tspeed: 0.0428s/iter; left time: 762.3693s\n",
      "\titers: 200, epoch: 21 | loss: 0.0548367\n",
      "\tspeed: 0.0209s/iter; left time: 369.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0537692 Vali Loss: 0.0534152 Test Loss: 0.0598009\n",
      "Validation loss decreased (0.053518 --> 0.053415).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549492\n",
      "\tspeed: 0.0444s/iter; left time: 780.6195s\n",
      "\titers: 200, epoch: 22 | loss: 0.0514017\n",
      "\tspeed: 0.0198s/iter; left time: 346.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0537207 Vali Loss: 0.0533374 Test Loss: 0.0596908\n",
      "Validation loss decreased (0.053415 --> 0.053337).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0534591\n",
      "\tspeed: 0.0393s/iter; left time: 682.3595s\n",
      "\titers: 200, epoch: 23 | loss: 0.0526582\n",
      "\tspeed: 0.0216s/iter; left time: 372.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0536544 Vali Loss: 0.0533163 Test Loss: 0.0596185\n",
      "Validation loss decreased (0.053337 --> 0.053316).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0538955\n",
      "\tspeed: 0.0382s/iter; left time: 655.3983s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538660\n",
      "\tspeed: 0.0208s/iter; left time: 354.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0535522 Vali Loss: 0.0532527 Test Loss: 0.0594967\n",
      "Validation loss decreased (0.053316 --> 0.053253).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0573650\n",
      "\tspeed: 0.0380s/iter; left time: 643.7574s\n",
      "\titers: 200, epoch: 25 | loss: 0.0528080\n",
      "\tspeed: 0.0178s/iter; left time: 300.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0534546 Vali Loss: 0.0532459 Test Loss: 0.0595710\n",
      "Validation loss decreased (0.053253 --> 0.053246).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0537234\n",
      "\tspeed: 0.0401s/iter; left time: 669.8796s\n",
      "\titers: 200, epoch: 26 | loss: 0.0546586\n",
      "\tspeed: 0.0176s/iter; left time: 292.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0533645 Vali Loss: 0.0533376 Test Loss: 0.0595235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0516834\n",
      "\tspeed: 0.0371s/iter; left time: 610.6094s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571585\n",
      "\tspeed: 0.0177s/iter; left time: 289.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0532839 Vali Loss: 0.0533172 Test Loss: 0.0594809\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0494189\n",
      "\tspeed: 0.0375s/iter; left time: 610.2077s\n",
      "\titers: 200, epoch: 28 | loss: 0.0522387\n",
      "\tspeed: 0.0174s/iter; left time: 281.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0533023 Vali Loss: 0.0531314 Test Loss: 0.0593853\n",
      "Validation loss decreased (0.053246 --> 0.053131).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0519411\n",
      "\tspeed: 0.0371s/iter; left time: 594.9347s\n",
      "\titers: 200, epoch: 29 | loss: 0.0522147\n",
      "\tspeed: 0.0180s/iter; left time: 286.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0532008 Vali Loss: 0.0530601 Test Loss: 0.0593986\n",
      "Validation loss decreased (0.053131 --> 0.053060).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0523858\n",
      "\tspeed: 0.0420s/iter; left time: 664.5347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0539169\n",
      "\tspeed: 0.0184s/iter; left time: 288.5349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0532031 Vali Loss: 0.0530461 Test Loss: 0.0593301\n",
      "Validation loss decreased (0.053060 --> 0.053046).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0542132\n",
      "\tspeed: 0.0406s/iter; left time: 633.3297s\n",
      "\titers: 200, epoch: 31 | loss: 0.0558742\n",
      "\tspeed: 0.0176s/iter; left time: 272.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0531557 Vali Loss: 0.0529637 Test Loss: 0.0594197\n",
      "Validation loss decreased (0.053046 --> 0.052964).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531322\n",
      "\tspeed: 0.0409s/iter; left time: 627.4583s\n",
      "\titers: 200, epoch: 32 | loss: 0.0507826\n",
      "\tspeed: 0.0204s/iter; left time: 310.8573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531287 Vali Loss: 0.0530666 Test Loss: 0.0593458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0550206\n",
      "\tspeed: 0.0367s/iter; left time: 555.3600s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542851\n",
      "\tspeed: 0.0176s/iter; left time: 264.7813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0531302 Vali Loss: 0.0529413 Test Loss: 0.0592580\n",
      "Validation loss decreased (0.052964 --> 0.052941).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0553355\n",
      "\tspeed: 0.0431s/iter; left time: 642.1845s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519135\n",
      "\tspeed: 0.0197s/iter; left time: 292.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0530112 Vali Loss: 0.0529859 Test Loss: 0.0593040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0532875\n",
      "\tspeed: 0.0362s/iter; left time: 530.9979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0528023\n",
      "\tspeed: 0.0181s/iter; left time: 264.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0530626 Vali Loss: 0.0530781 Test Loss: 0.0593102\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0557845\n",
      "\tspeed: 0.0373s/iter; left time: 539.1795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0521810\n",
      "\tspeed: 0.0176s/iter; left time: 252.7647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529679 Vali Loss: 0.0529296 Test Loss: 0.0592321\n",
      "Validation loss decreased (0.052941 --> 0.052930).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0516731\n",
      "\tspeed: 0.0358s/iter; left time: 510.3623s\n",
      "\titers: 200, epoch: 37 | loss: 0.0540236\n",
      "\tspeed: 0.0172s/iter; left time: 243.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0529866 Vali Loss: 0.0529916 Test Loss: 0.0592840\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0508000\n",
      "\tspeed: 0.0362s/iter; left time: 507.2096s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547213\n",
      "\tspeed: 0.0175s/iter; left time: 244.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0529485 Vali Loss: 0.0529122 Test Loss: 0.0592196\n",
      "Validation loss decreased (0.052930 --> 0.052912).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0529043\n",
      "\tspeed: 0.0439s/iter; left time: 605.4128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0516311\n",
      "\tspeed: 0.0246s/iter; left time: 337.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0528965 Test Loss: 0.0592480\n",
      "Validation loss decreased (0.052912 --> 0.052897).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0494722\n",
      "\tspeed: 0.0396s/iter; left time: 537.3741s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527704\n",
      "\tspeed: 0.0175s/iter; left time: 235.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0528899 Vali Loss: 0.0529518 Test Loss: 0.0593059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0527010\n",
      "\tspeed: 0.0354s/iter; left time: 471.6542s\n",
      "\titers: 200, epoch: 41 | loss: 0.0523881\n",
      "\tspeed: 0.0176s/iter; left time: 232.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529096 Vali Loss: 0.0528782 Test Loss: 0.0592054\n",
      "Validation loss decreased (0.052897 --> 0.052878).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0550479\n",
      "\tspeed: 0.0420s/iter; left time: 550.5007s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528131\n",
      "\tspeed: 0.0175s/iter; left time: 227.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0529324 Vali Loss: 0.0529419 Test Loss: 0.0592431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511567\n",
      "\tspeed: 0.0449s/iter; left time: 578.9241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0510774\n",
      "\tspeed: 0.0215s/iter; left time: 275.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0528664 Vali Loss: 0.0529480 Test Loss: 0.0592471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547131\n",
      "\tspeed: 0.0377s/iter; left time: 478.0473s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535225\n",
      "\tspeed: 0.0176s/iter; left time: 220.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0529409 Vali Loss: 0.0529403 Test Loss: 0.0591982\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0499585\n",
      "\tspeed: 0.0368s/iter; left time: 458.5532s\n",
      "\titers: 200, epoch: 45 | loss: 0.0560696\n",
      "\tspeed: 0.0211s/iter; left time: 260.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0528784 Vali Loss: 0.0529030 Test Loss: 0.0592152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0512092\n",
      "\tspeed: 0.0385s/iter; left time: 470.9820s\n",
      "\titers: 200, epoch: 46 | loss: 0.0548510\n",
      "\tspeed: 0.0178s/iter; left time: 216.1218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0528416 Vali Loss: 0.0529498 Test Loss: 0.0591846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0539514\n",
      "\tspeed: 0.0358s/iter; left time: 429.2966s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507728\n",
      "\tspeed: 0.0174s/iter; left time: 207.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0528806 Vali Loss: 0.0529439 Test Loss: 0.0591778\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0547237\n",
      "\tspeed: 0.0360s/iter; left time: 423.9098s\n",
      "\titers: 200, epoch: 48 | loss: 0.0500909\n",
      "\tspeed: 0.0175s/iter; left time: 204.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0528072 Vali Loss: 0.0529146 Test Loss: 0.0592384\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0538362\n",
      "\tspeed: 0.0378s/iter; left time: 436.7830s\n",
      "\titers: 200, epoch: 49 | loss: 0.0551731\n",
      "\tspeed: 0.0176s/iter; left time: 201.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0528127 Vali Loss: 0.0528409 Test Loss: 0.0591774\n",
      "Validation loss decreased (0.052878 --> 0.052841).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547548\n",
      "\tspeed: 0.0363s/iter; left time: 410.5844s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522613\n",
      "\tspeed: 0.0175s/iter; left time: 196.0091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0528483 Vali Loss: 0.0529676 Test Loss: 0.0592235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0515651\n",
      "\tspeed: 0.0434s/iter; left time: 482.0306s\n",
      "\titers: 200, epoch: 51 | loss: 0.0519167\n",
      "\tspeed: 0.0205s/iter; left time: 225.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0528751 Vali Loss: 0.0528772 Test Loss: 0.0591687\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0547058\n",
      "\tspeed: 0.0394s/iter; left time: 428.2818s\n",
      "\titers: 200, epoch: 52 | loss: 0.0527426\n",
      "\tspeed: 0.0233s/iter; left time: 251.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0528348 Vali Loss: 0.0528290 Test Loss: 0.0591753\n",
      "Validation loss decreased (0.052841 --> 0.052829).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0529373\n",
      "\tspeed: 0.0379s/iter; left time: 404.1027s\n",
      "\titers: 200, epoch: 53 | loss: 0.0567268\n",
      "\tspeed: 0.0182s/iter; left time: 192.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0528269 Vali Loss: 0.0528880 Test Loss: 0.0591835\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0536679\n",
      "\tspeed: 0.0388s/iter; left time: 404.9540s\n",
      "\titers: 200, epoch: 54 | loss: 0.0512394\n",
      "\tspeed: 0.0189s/iter; left time: 195.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0527903 Vali Loss: 0.0528845 Test Loss: 0.0591716\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0511981\n",
      "\tspeed: 0.0394s/iter; left time: 401.7271s\n",
      "\titers: 200, epoch: 55 | loss: 0.0518198\n",
      "\tspeed: 0.0175s/iter; left time: 176.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0527804 Vali Loss: 0.0528382 Test Loss: 0.0591643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0501965\n",
      "\tspeed: 0.0377s/iter; left time: 376.6580s\n",
      "\titers: 200, epoch: 56 | loss: 0.0531978\n",
      "\tspeed: 0.0177s/iter; left time: 175.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0528132 Vali Loss: 0.0529282 Test Loss: 0.0592545\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0523530\n",
      "\tspeed: 0.0383s/iter; left time: 373.5001s\n",
      "\titers: 200, epoch: 57 | loss: 0.0532235\n",
      "\tspeed: 0.0188s/iter; left time: 181.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0528334 Vali Loss: 0.0528543 Test Loss: 0.0591806\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0517060\n",
      "\tspeed: 0.0385s/iter; left time: 367.0567s\n",
      "\titers: 200, epoch: 58 | loss: 0.0537203\n",
      "\tspeed: 0.0222s/iter; left time: 209.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0528633 Vali Loss: 0.0529062 Test Loss: 0.0591597\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0542901\n",
      "\tspeed: 0.0444s/iter; left time: 413.4854s\n",
      "\titers: 200, epoch: 59 | loss: 0.0490207\n",
      "\tspeed: 0.0196s/iter; left time: 180.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0527814 Vali Loss: 0.0528723 Test Loss: 0.0591480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0534826\n",
      "\tspeed: 0.0398s/iter; left time: 361.2870s\n",
      "\titers: 200, epoch: 60 | loss: 0.0522820\n",
      "\tspeed: 0.0175s/iter; left time: 157.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0528065 Vali Loss: 0.0528880 Test Loss: 0.0591799\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0541162\n",
      "\tspeed: 0.0382s/iter; left time: 338.2691s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526189\n",
      "\tspeed: 0.0199s/iter; left time: 174.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0528557 Vali Loss: 0.0528851 Test Loss: 0.0591978\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0529211\n",
      "\tspeed: 0.0372s/iter; left time: 321.3345s\n",
      "\titers: 200, epoch: 62 | loss: 0.0479516\n",
      "\tspeed: 0.0172s/iter; left time: 147.0690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0527867 Vali Loss: 0.0529483 Test Loss: 0.0591934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009751381352543831, rmse:0.0987490862607956, mae:0.05917529761791229, rse:0.29060661792755127\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1337921\n",
      "\tspeed: 0.0206s/iter; left time: 458.7822s\n",
      "\titers: 200, epoch: 1 | loss: 0.1069674\n",
      "\tspeed: 0.0206s/iter; left time: 458.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.1356587 Vali Loss: 0.0968538 Test Loss: 0.1094441\n",
      "Validation loss decreased (inf --> 0.096854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746105\n",
      "\tspeed: 0.0394s/iter; left time: 869.6349s\n",
      "\titers: 200, epoch: 2 | loss: 0.0701489\n",
      "\tspeed: 0.0175s/iter; left time: 385.2628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0767475 Vali Loss: 0.0639559 Test Loss: 0.0706353\n",
      "Validation loss decreased (0.096854 --> 0.063956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675678\n",
      "\tspeed: 0.0370s/iter; left time: 807.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0615702\n",
      "\tspeed: 0.0174s/iter; left time: 379.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0655629 Vali Loss: 0.0605291 Test Loss: 0.0668655\n",
      "Validation loss decreased (0.063956 --> 0.060529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0629944\n",
      "\tspeed: 0.0368s/iter; left time: 795.4977s\n",
      "\titers: 200, epoch: 4 | loss: 0.0648704\n",
      "\tspeed: 0.0183s/iter; left time: 393.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0625614 Vali Loss: 0.0589684 Test Loss: 0.0655182\n",
      "Validation loss decreased (0.060529 --> 0.058968).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588870\n",
      "\tspeed: 0.0402s/iter; left time: 860.9520s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.0176s/iter; left time: 375.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0606106 Vali Loss: 0.0578980 Test Loss: 0.0645265\n",
      "Validation loss decreased (0.058968 --> 0.057898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592575\n",
      "\tspeed: 0.0370s/iter; left time: 782.9556s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571381\n",
      "\tspeed: 0.0175s/iter; left time: 368.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593913 Vali Loss: 0.0566761 Test Loss: 0.0631738\n",
      "Validation loss decreased (0.057898 --> 0.056676).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0611145\n",
      "\tspeed: 0.0367s/iter; left time: 769.3887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605097\n",
      "\tspeed: 0.0174s/iter; left time: 362.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0583720 Vali Loss: 0.0562617 Test Loss: 0.0624770\n",
      "Validation loss decreased (0.056676 --> 0.056262).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0629369\n",
      "\tspeed: 0.0418s/iter; left time: 866.8303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618621\n",
      "\tspeed: 0.0217s/iter; left time: 447.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0576425 Vali Loss: 0.0556517 Test Loss: 0.0618897\n",
      "Validation loss decreased (0.056262 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0606712\n",
      "\tspeed: 0.0427s/iter; left time: 875.6113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0555764\n",
      "\tspeed: 0.0222s/iter; left time: 453.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0555573 Test Loss: 0.0616752\n",
      "Validation loss decreased (0.055652 --> 0.055557).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596933\n",
      "\tspeed: 0.0453s/iter; left time: 919.0482s\n",
      "\titers: 200, epoch: 10 | loss: 0.0554582\n",
      "\tspeed: 0.0227s/iter; left time: 457.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0565138 Vali Loss: 0.0551991 Test Loss: 0.0614132\n",
      "Validation loss decreased (0.055557 --> 0.055199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0616147\n",
      "\tspeed: 0.0387s/iter; left time: 776.9877s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578825\n",
      "\tspeed: 0.0174s/iter; left time: 348.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0561789 Vali Loss: 0.0549304 Test Loss: 0.0611437\n",
      "Validation loss decreased (0.055199 --> 0.054930).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0537045\n",
      "\tspeed: 0.0367s/iter; left time: 727.8192s\n",
      "\titers: 200, epoch: 12 | loss: 0.0578890\n",
      "\tspeed: 0.0176s/iter; left time: 347.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0557681 Vali Loss: 0.0547644 Test Loss: 0.0607991\n",
      "Validation loss decreased (0.054930 --> 0.054764).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0570883\n",
      "\tspeed: 0.0426s/iter; left time: 835.6845s\n",
      "\titers: 200, epoch: 13 | loss: 0.0543759\n",
      "\tspeed: 0.0178s/iter; left time: 347.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0554576 Vali Loss: 0.0546486 Test Loss: 0.0609315\n",
      "Validation loss decreased (0.054764 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0559569\n",
      "\tspeed: 0.0405s/iter; left time: 784.2899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576939\n",
      "\tspeed: 0.0206s/iter; left time: 397.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0551173 Vali Loss: 0.0543713 Test Loss: 0.0607464\n",
      "Validation loss decreased (0.054649 --> 0.054371).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574309\n",
      "\tspeed: 0.0404s/iter; left time: 773.9555s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533791\n",
      "\tspeed: 0.0193s/iter; left time: 367.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0548902 Vali Loss: 0.0541163 Test Loss: 0.0603891\n",
      "Validation loss decreased (0.054371 --> 0.054116).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0560301\n",
      "\tspeed: 0.0400s/iter; left time: 758.5325s\n",
      "\titers: 200, epoch: 16 | loss: 0.0556359\n",
      "\tspeed: 0.0215s/iter; left time: 404.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0546661 Vali Loss: 0.0540735 Test Loss: 0.0603688\n",
      "Validation loss decreased (0.054116 --> 0.054073).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567861\n",
      "\tspeed: 0.0400s/iter; left time: 749.0467s\n",
      "\titers: 200, epoch: 17 | loss: 0.0534253\n",
      "\tspeed: 0.0173s/iter; left time: 321.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0545065 Vali Loss: 0.0539584 Test Loss: 0.0603209\n",
      "Validation loss decreased (0.054073 --> 0.053958).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0544936\n",
      "\tspeed: 0.0390s/iter; left time: 721.0882s\n",
      "\titers: 200, epoch: 18 | loss: 0.0505661\n",
      "\tspeed: 0.0215s/iter; left time: 394.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0542611 Vali Loss: 0.0537714 Test Loss: 0.0600516\n",
      "Validation loss decreased (0.053958 --> 0.053771).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0572401\n",
      "\tspeed: 0.0395s/iter; left time: 720.9557s\n",
      "\titers: 200, epoch: 19 | loss: 0.0509766\n",
      "\tspeed: 0.0203s/iter; left time: 368.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541876 Vali Loss: 0.0537230 Test Loss: 0.0601269\n",
      "Validation loss decreased (0.053771 --> 0.053723).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0581672\n",
      "\tspeed: 0.0391s/iter; left time: 704.9706s\n",
      "\titers: 200, epoch: 20 | loss: 0.0560375\n",
      "\tspeed: 0.0176s/iter; left time: 316.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540584 Vali Loss: 0.0535869 Test Loss: 0.0598196\n",
      "Validation loss decreased (0.053723 --> 0.053587).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0489908\n",
      "\tspeed: 0.0382s/iter; left time: 680.8923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556523\n",
      "\tspeed: 0.0175s/iter; left time: 310.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0539873 Vali Loss: 0.0535157 Test Loss: 0.0598667\n",
      "Validation loss decreased (0.053587 --> 0.053516).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0564136\n",
      "\tspeed: 0.0368s/iter; left time: 647.5133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0507003\n",
      "\tspeed: 0.0175s/iter; left time: 305.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0538451 Vali Loss: 0.0534693 Test Loss: 0.0597156\n",
      "Validation loss decreased (0.053516 --> 0.053469).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0500772\n",
      "\tspeed: 0.0375s/iter; left time: 651.1026s\n",
      "\titers: 200, epoch: 23 | loss: 0.0531840\n",
      "\tspeed: 0.0175s/iter; left time: 301.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0537557 Vali Loss: 0.0533803 Test Loss: 0.0598192\n",
      "Validation loss decreased (0.053469 --> 0.053380).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0520380\n",
      "\tspeed: 0.0453s/iter; left time: 776.9973s\n",
      "\titers: 200, epoch: 24 | loss: 0.0564743\n",
      "\tspeed: 0.0176s/iter; left time: 300.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0536120 Vali Loss: 0.0534145 Test Loss: 0.0596311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0510081\n",
      "\tspeed: 0.0377s/iter; left time: 638.7096s\n",
      "\titers: 200, epoch: 25 | loss: 0.0502159\n",
      "\tspeed: 0.0174s/iter; left time: 293.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0535521 Vali Loss: 0.0534059 Test Loss: 0.0596591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0510387\n",
      "\tspeed: 0.0371s/iter; left time: 620.4239s\n",
      "\titers: 200, epoch: 26 | loss: 0.0527924\n",
      "\tspeed: 0.0177s/iter; left time: 293.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0534718 Vali Loss: 0.0533074 Test Loss: 0.0596614\n",
      "Validation loss decreased (0.053380 --> 0.053307).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0546484\n",
      "\tspeed: 0.0363s/iter; left time: 597.5156s\n",
      "\titers: 200, epoch: 27 | loss: 0.0502867\n",
      "\tspeed: 0.0173s/iter; left time: 283.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0534427 Vali Loss: 0.0532914 Test Loss: 0.0595673\n",
      "Validation loss decreased (0.053307 --> 0.053291).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0513472\n",
      "\tspeed: 0.0380s/iter; left time: 617.8899s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544608\n",
      "\tspeed: 0.0177s/iter; left time: 286.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0534265 Vali Loss: 0.0533097 Test Loss: 0.0595132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0543246\n",
      "\tspeed: 0.0378s/iter; left time: 606.4173s\n",
      "\titers: 200, epoch: 29 | loss: 0.0545000\n",
      "\tspeed: 0.0175s/iter; left time: 278.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0533031 Vali Loss: 0.0533129 Test Loss: 0.0596252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0578123\n",
      "\tspeed: 0.0384s/iter; left time: 606.5506s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523473\n",
      "\tspeed: 0.0175s/iter; left time: 275.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0532915 Vali Loss: 0.0531913 Test Loss: 0.0594889\n",
      "Validation loss decreased (0.053291 --> 0.053191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544150\n",
      "\tspeed: 0.0371s/iter; left time: 578.5391s\n",
      "\titers: 200, epoch: 31 | loss: 0.0515520\n",
      "\tspeed: 0.0175s/iter; left time: 270.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0532813 Vali Loss: 0.0531744 Test Loss: 0.0595354\n",
      "Validation loss decreased (0.053191 --> 0.053174).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559174\n",
      "\tspeed: 0.0378s/iter; left time: 580.8415s\n",
      "\titers: 200, epoch: 32 | loss: 0.0526729\n",
      "\tspeed: 0.0173s/iter; left time: 264.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0532091 Vali Loss: 0.0531425 Test Loss: 0.0594587\n",
      "Validation loss decreased (0.053174 --> 0.053143).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0532093\n",
      "\tspeed: 0.0366s/iter; left time: 553.8593s\n",
      "\titers: 200, epoch: 33 | loss: 0.0478663\n",
      "\tspeed: 0.0173s/iter; left time: 259.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0531877 Vali Loss: 0.0531788 Test Loss: 0.0594424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0499334\n",
      "\tspeed: 0.0370s/iter; left time: 551.6185s\n",
      "\titers: 200, epoch: 34 | loss: 0.0506587\n",
      "\tspeed: 0.0175s/iter; left time: 259.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0531430 Vali Loss: 0.0531837 Test Loss: 0.0594441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517330\n",
      "\tspeed: 0.0424s/iter; left time: 622.5793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0551342\n",
      "\tspeed: 0.0203s/iter; left time: 295.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0531663 Vali Loss: 0.0531581 Test Loss: 0.0594528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506947\n",
      "\tspeed: 0.0403s/iter; left time: 582.4848s\n",
      "\titers: 200, epoch: 36 | loss: 0.0583177\n",
      "\tspeed: 0.0203s/iter; left time: 291.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0531392 Vali Loss: 0.0531340 Test Loss: 0.0594451\n",
      "Validation loss decreased (0.053143 --> 0.053134).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542479\n",
      "\tspeed: 0.0454s/iter; left time: 646.6699s\n",
      "\titers: 200, epoch: 37 | loss: 0.0510775\n",
      "\tspeed: 0.0217s/iter; left time: 306.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0530918 Vali Loss: 0.0530867 Test Loss: 0.0593737\n",
      "Validation loss decreased (0.053134 --> 0.053087).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556557\n",
      "\tspeed: 0.0396s/iter; left time: 554.6645s\n",
      "\titers: 200, epoch: 38 | loss: 0.0513426\n",
      "\tspeed: 0.0202s/iter; left time: 281.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0530756 Vali Loss: 0.0531610 Test Loss: 0.0594667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0526359\n",
      "\tspeed: 0.0394s/iter; left time: 543.4934s\n",
      "\titers: 200, epoch: 39 | loss: 0.0522014\n",
      "\tspeed: 0.0172s/iter; left time: 235.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0530237 Vali Loss: 0.0530525 Test Loss: 0.0593700\n",
      "Validation loss decreased (0.053087 --> 0.053052).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0489786\n",
      "\tspeed: 0.0409s/iter; left time: 554.8960s\n",
      "\titers: 200, epoch: 40 | loss: 0.0538423\n",
      "\tspeed: 0.0191s/iter; left time: 257.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0530496 Vali Loss: 0.0531109 Test Loss: 0.0593490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0539034\n",
      "\tspeed: 0.0382s/iter; left time: 508.9971s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502612\n",
      "\tspeed: 0.0201s/iter; left time: 266.3523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0529953 Vali Loss: 0.0531376 Test Loss: 0.0593575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0509308\n",
      "\tspeed: 0.0407s/iter; left time: 533.3291s\n",
      "\titers: 200, epoch: 42 | loss: 0.0528011\n",
      "\tspeed: 0.0203s/iter; left time: 264.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0530408 Vali Loss: 0.0531074 Test Loss: 0.0593930\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0536508\n",
      "\tspeed: 0.0398s/iter; left time: 513.6043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0535419\n",
      "\tspeed: 0.0209s/iter; left time: 267.6998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0530064 Vali Loss: 0.0531483 Test Loss: 0.0593524\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0534231\n",
      "\tspeed: 0.0422s/iter; left time: 534.2851s\n",
      "\titers: 200, epoch: 44 | loss: 0.0485632\n",
      "\tspeed: 0.0199s/iter; left time: 250.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0529402 Vali Loss: 0.0530934 Test Loss: 0.0593843\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0504932\n",
      "\tspeed: 0.0404s/iter; left time: 502.4356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0521229\n",
      "\tspeed: 0.0174s/iter; left time: 214.9795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0530215 Vali Loss: 0.0530575 Test Loss: 0.0593451\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0538279\n",
      "\tspeed: 0.0362s/iter; left time: 442.9136s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554503\n",
      "\tspeed: 0.0174s/iter; left time: 211.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0529353 Vali Loss: 0.0530863 Test Loss: 0.0592994\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0534511\n",
      "\tspeed: 0.0370s/iter; left time: 444.1844s\n",
      "\titers: 200, epoch: 47 | loss: 0.0537172\n",
      "\tspeed: 0.0176s/iter; left time: 208.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0529956 Vali Loss: 0.0529808 Test Loss: 0.0593239\n",
      "Validation loss decreased (0.053052 --> 0.052981).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0545642\n",
      "\tspeed: 0.0414s/iter; left time: 487.0466s\n",
      "\titers: 200, epoch: 48 | loss: 0.0503907\n",
      "\tspeed: 0.0176s/iter; left time: 205.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0529698 Vali Loss: 0.0530103 Test Loss: 0.0593279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0509437\n",
      "\tspeed: 0.0385s/iter; left time: 444.9423s\n",
      "\titers: 200, epoch: 49 | loss: 0.0518087\n",
      "\tspeed: 0.0175s/iter; left time: 200.7417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0529407 Vali Loss: 0.0531188 Test Loss: 0.0594364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0541317\n",
      "\tspeed: 0.0405s/iter; left time: 458.9719s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539311\n",
      "\tspeed: 0.0204s/iter; left time: 228.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0529140 Vali Loss: 0.0530143 Test Loss: 0.0593071\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0535859\n",
      "\tspeed: 0.0379s/iter; left time: 421.0638s\n",
      "\titers: 200, epoch: 51 | loss: 0.0555147\n",
      "\tspeed: 0.0172s/iter; left time: 189.5783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0529585 Vali Loss: 0.0530431 Test Loss: 0.0593245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0542467\n",
      "\tspeed: 0.0359s/iter; left time: 390.8151s\n",
      "\titers: 200, epoch: 52 | loss: 0.0480840\n",
      "\tspeed: 0.0176s/iter; left time: 189.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0529279 Vali Loss: 0.0530876 Test Loss: 0.0593659\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0522306\n",
      "\tspeed: 0.0385s/iter; left time: 410.1747s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510478\n",
      "\tspeed: 0.0195s/iter; left time: 205.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0529877 Vali Loss: 0.0530985 Test Loss: 0.0593327\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0538847\n",
      "\tspeed: 0.0378s/iter; left time: 394.1452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0531133\n",
      "\tspeed: 0.0174s/iter; left time: 179.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0529167 Vali Loss: 0.0530712 Test Loss: 0.0593545\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0534907\n",
      "\tspeed: 0.0399s/iter; left time: 407.1084s\n",
      "\titers: 200, epoch: 55 | loss: 0.0500412\n",
      "\tspeed: 0.0200s/iter; left time: 202.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0529414 Vali Loss: 0.0530433 Test Loss: 0.0593276\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0530696\n",
      "\tspeed: 0.0400s/iter; left time: 398.8456s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546860\n",
      "\tspeed: 0.0176s/iter; left time: 173.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0529148 Vali Loss: 0.0530499 Test Loss: 0.0593268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0518850\n",
      "\tspeed: 0.0382s/iter; left time: 372.5004s\n",
      "\titers: 200, epoch: 57 | loss: 0.0534603\n",
      "\tspeed: 0.0229s/iter; left time: 221.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0529192 Vali Loss: 0.0530396 Test Loss: 0.0593469\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009775502607226372, rmse:0.0988711416721344, mae:0.05932391434907913, rse:0.29096582531929016\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:39.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1329530\n",
      "\tspeed: 0.0443s/iter; left time: 987.1059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160002\n",
      "\tspeed: 0.0176s/iter; left time: 390.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.1391902 Vali Loss: 0.1071772 Test Loss: 0.1206293\n",
      "Validation loss decreased (inf --> 0.107177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0942523\n",
      "\tspeed: 0.0385s/iter; left time: 850.8737s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861847\n",
      "\tspeed: 0.0185s/iter; left time: 406.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0945715 Vali Loss: 0.0842465 Test Loss: 0.0952013\n",
      "Validation loss decreased (0.107177 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0845243\n",
      "\tspeed: 0.0382s/iter; left time: 834.0629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815090\n",
      "\tspeed: 0.0181s/iter; left time: 393.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0852838 Vali Loss: 0.0807858 Test Loss: 0.0915264\n",
      "Validation loss decreased (0.084247 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0820356\n",
      "\tspeed: 0.0378s/iter; left time: 816.7261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805881\n",
      "\tspeed: 0.0176s/iter; left time: 378.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0823000 Vali Loss: 0.0797732 Test Loss: 0.0897798\n",
      "Validation loss decreased (0.080786 --> 0.079773).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0798331\n",
      "\tspeed: 0.0379s/iter; left time: 810.5959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755010\n",
      "\tspeed: 0.0177s/iter; left time: 376.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0804131 Vali Loss: 0.0779141 Test Loss: 0.0881555\n",
      "Validation loss decreased (0.079773 --> 0.077914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0796704\n",
      "\tspeed: 0.0375s/iter; left time: 793.5661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799784\n",
      "\tspeed: 0.0176s/iter; left time: 371.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0789057 Vali Loss: 0.0770733 Test Loss: 0.0876542\n",
      "Validation loss decreased (0.077914 --> 0.077073).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788884\n",
      "\tspeed: 0.0376s/iter; left time: 788.3541s\n",
      "\titers: 200, epoch: 7 | loss: 0.0752197\n",
      "\tspeed: 0.0177s/iter; left time: 368.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777904 Vali Loss: 0.0771061 Test Loss: 0.0872416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774317\n",
      "\tspeed: 0.0376s/iter; left time: 779.7228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751686\n",
      "\tspeed: 0.0205s/iter; left time: 423.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0770810 Vali Loss: 0.0767934 Test Loss: 0.0870996\n",
      "Validation loss decreased (0.077073 --> 0.076793).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771739\n",
      "\tspeed: 0.0401s/iter; left time: 823.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746005\n",
      "\tspeed: 0.0182s/iter; left time: 372.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0765222 Vali Loss: 0.0760892 Test Loss: 0.0869368\n",
      "Validation loss decreased (0.076793 --> 0.076089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779370\n",
      "\tspeed: 0.0435s/iter; left time: 882.3856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787978\n",
      "\tspeed: 0.0186s/iter; left time: 375.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0760347 Vali Loss: 0.0766135 Test Loss: 0.0868480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761426\n",
      "\tspeed: 0.0382s/iter; left time: 765.4540s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789521\n",
      "\tspeed: 0.0178s/iter; left time: 355.2533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0756286 Vali Loss: 0.0763626 Test Loss: 0.0866961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0761763\n",
      "\tspeed: 0.0373s/iter; left time: 740.3132s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757204\n",
      "\tspeed: 0.0178s/iter; left time: 352.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0753164 Vali Loss: 0.0763749 Test Loss: 0.0863272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718356\n",
      "\tspeed: 0.0375s/iter; left time: 735.7471s\n",
      "\titers: 200, epoch: 13 | loss: 0.0752915\n",
      "\tspeed: 0.0178s/iter; left time: 348.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0749505 Vali Loss: 0.0764924 Test Loss: 0.0864433\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712507\n",
      "\tspeed: 0.0413s/iter; left time: 800.9626s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751940\n",
      "\tspeed: 0.0204s/iter; left time: 393.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0747298 Vali Loss: 0.0763432 Test Loss: 0.0865515\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0714074\n",
      "\tspeed: 0.0389s/iter; left time: 746.0339s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769075\n",
      "\tspeed: 0.0179s/iter; left time: 340.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0744110 Vali Loss: 0.0763409 Test Loss: 0.0860551\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736857\n",
      "\tspeed: 0.0390s/iter; left time: 738.2485s\n",
      "\titers: 200, epoch: 16 | loss: 0.0758855\n",
      "\tspeed: 0.0179s/iter; left time: 336.5092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0741638 Vali Loss: 0.0763573 Test Loss: 0.0862534\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0732683\n",
      "\tspeed: 0.0372s/iter; left time: 696.4759s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766605\n",
      "\tspeed: 0.0178s/iter; left time: 332.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0739782 Vali Loss: 0.0760687 Test Loss: 0.0860618\n",
      "Validation loss decreased (0.076089 --> 0.076069).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0758949\n",
      "\tspeed: 0.0420s/iter; left time: 775.8797s\n",
      "\titers: 200, epoch: 18 | loss: 0.0741989\n",
      "\tspeed: 0.0201s/iter; left time: 369.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0738317 Vali Loss: 0.0758029 Test Loss: 0.0859767\n",
      "Validation loss decreased (0.076069 --> 0.075803).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731899\n",
      "\tspeed: 0.0400s/iter; left time: 730.6615s\n",
      "\titers: 200, epoch: 19 | loss: 0.0783558\n",
      "\tspeed: 0.0180s/iter; left time: 326.9009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0736161 Vali Loss: 0.0767120 Test Loss: 0.0861842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724703\n",
      "\tspeed: 0.0395s/iter; left time: 713.2295s\n",
      "\titers: 200, epoch: 20 | loss: 0.0739780\n",
      "\tspeed: 0.0187s/iter; left time: 335.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0735227 Vali Loss: 0.0763454 Test Loss: 0.0858723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0736979\n",
      "\tspeed: 0.0383s/iter; left time: 681.9721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0692475\n",
      "\tspeed: 0.0176s/iter; left time: 312.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0733244 Vali Loss: 0.0759520 Test Loss: 0.0858447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0742377\n",
      "\tspeed: 0.0378s/iter; left time: 664.7089s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738283\n",
      "\tspeed: 0.0177s/iter; left time: 309.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0732371 Vali Loss: 0.0761869 Test Loss: 0.0859049\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716027\n",
      "\tspeed: 0.0386s/iter; left time: 671.2958s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768406\n",
      "\tspeed: 0.0176s/iter; left time: 304.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0730942 Vali Loss: 0.0761952 Test Loss: 0.0858184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739905\n",
      "\tspeed: 0.0375s/iter; left time: 643.1647s\n",
      "\titers: 200, epoch: 24 | loss: 0.0714365\n",
      "\tspeed: 0.0177s/iter; left time: 300.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0729818 Vali Loss: 0.0762859 Test Loss: 0.0857470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0700301\n",
      "\tspeed: 0.0383s/iter; left time: 648.7693s\n",
      "\titers: 200, epoch: 25 | loss: 0.0753928\n",
      "\tspeed: 0.0181s/iter; left time: 303.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0729328 Vali Loss: 0.0763261 Test Loss: 0.0859215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696138\n",
      "\tspeed: 0.0382s/iter; left time: 637.6291s\n",
      "\titers: 200, epoch: 26 | loss: 0.0715025\n",
      "\tspeed: 0.0196s/iter; left time: 325.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0728175 Vali Loss: 0.0762029 Test Loss: 0.0858192\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0725613\n",
      "\tspeed: 0.0370s/iter; left time: 610.2925s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719680\n",
      "\tspeed: 0.0185s/iter; left time: 302.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0727753 Vali Loss: 0.0761756 Test Loss: 0.0857254\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0751431\n",
      "\tspeed: 0.0390s/iter; left time: 634.0645s\n",
      "\titers: 200, epoch: 28 | loss: 0.0738966\n",
      "\tspeed: 0.0178s/iter; left time: 287.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0727138 Vali Loss: 0.0765646 Test Loss: 0.0857118\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01854773983359337, rmse:0.13619008660316467, mae:0.08597671240568161, rse:0.4000854790210724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1367538\n",
      "\tspeed: 0.0223s/iter; left time: 496.8574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1153385\n",
      "\tspeed: 0.0233s/iter; left time: 517.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.1400050 Vali Loss: 0.1071248 Test Loss: 0.1205454\n",
      "Validation loss decreased (inf --> 0.107125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936913\n",
      "\tspeed: 0.0460s/iter; left time: 1015.9851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0879241\n",
      "\tspeed: 0.0176s/iter; left time: 387.3446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0942411 Vali Loss: 0.0843040 Test Loss: 0.0953580\n",
      "Validation loss decreased (0.107125 --> 0.084304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803946\n",
      "\tspeed: 0.0403s/iter; left time: 880.0693s\n",
      "\titers: 200, epoch: 3 | loss: 0.0812021\n",
      "\tspeed: 0.0178s/iter; left time: 386.2305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0852106 Vali Loss: 0.0801856 Test Loss: 0.0912001\n",
      "Validation loss decreased (0.084304 --> 0.080186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0788692\n",
      "\tspeed: 0.0415s/iter; left time: 898.5903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0762093\n",
      "\tspeed: 0.0216s/iter; left time: 466.0767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0821201 Vali Loss: 0.0789561 Test Loss: 0.0895967\n",
      "Validation loss decreased (0.080186 --> 0.078956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0793223\n",
      "\tspeed: 0.0421s/iter; left time: 900.2679s\n",
      "\titers: 200, epoch: 5 | loss: 0.0773962\n",
      "\tspeed: 0.0193s/iter; left time: 410.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0802467 Vali Loss: 0.0778591 Test Loss: 0.0884357\n",
      "Validation loss decreased (0.078956 --> 0.077859).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816932\n",
      "\tspeed: 0.0403s/iter; left time: 853.8364s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778644\n",
      "\tspeed: 0.0177s/iter; left time: 373.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0790325 Vali Loss: 0.0767959 Test Loss: 0.0875439\n",
      "Validation loss decreased (0.077859 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745961\n",
      "\tspeed: 0.0387s/iter; left time: 810.0707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0834768\n",
      "\tspeed: 0.0178s/iter; left time: 371.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0781038 Vali Loss: 0.0762627 Test Loss: 0.0873462\n",
      "Validation loss decreased (0.076796 --> 0.076263).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0800848\n",
      "\tspeed: 0.0400s/iter; left time: 829.6929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742644\n",
      "\tspeed: 0.0178s/iter; left time: 367.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0773239 Vali Loss: 0.0775152 Test Loss: 0.0874873\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721739\n",
      "\tspeed: 0.0381s/iter; left time: 780.9902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0794274\n",
      "\tspeed: 0.0209s/iter; left time: 426.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.0767547 Vali Loss: 0.0763608 Test Loss: 0.0870005\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758219\n",
      "\tspeed: 0.0409s/iter; left time: 828.6589s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767745\n",
      "\tspeed: 0.0189s/iter; left time: 381.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0761915 Vali Loss: 0.0771433 Test Loss: 0.0867632\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747136\n",
      "\tspeed: 0.0450s/iter; left time: 903.2435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756405\n",
      "\tspeed: 0.0197s/iter; left time: 394.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0757717 Vali Loss: 0.0765610 Test Loss: 0.0865518\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0714020\n",
      "\tspeed: 0.0425s/iter; left time: 843.1375s\n",
      "\titers: 200, epoch: 12 | loss: 0.0774138\n",
      "\tspeed: 0.0219s/iter; left time: 431.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0754335 Vali Loss: 0.0767363 Test Loss: 0.0865050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0722883\n",
      "\tspeed: 0.0396s/iter; left time: 775.7284s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759881\n",
      "\tspeed: 0.0175s/iter; left time: 341.8679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0751549 Vali Loss: 0.0761463 Test Loss: 0.0862424\n",
      "Validation loss decreased (0.076263 --> 0.076146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745482\n",
      "\tspeed: 0.0412s/iter; left time: 799.4890s\n",
      "\titers: 200, epoch: 14 | loss: 0.0744093\n",
      "\tspeed: 0.0245s/iter; left time: 471.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0747696 Vali Loss: 0.0762650 Test Loss: 0.0862187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720881\n",
      "\tspeed: 0.0400s/iter; left time: 765.8024s\n",
      "\titers: 200, epoch: 15 | loss: 0.0781316\n",
      "\tspeed: 0.0174s/iter; left time: 331.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0745868 Vali Loss: 0.0765290 Test Loss: 0.0860522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0727114\n",
      "\tspeed: 0.0412s/iter; left time: 779.4685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0736387\n",
      "\tspeed: 0.0179s/iter; left time: 337.6929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0743449 Vali Loss: 0.0765852 Test Loss: 0.0860310\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706794\n",
      "\tspeed: 0.0388s/iter; left time: 726.9777s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752406\n",
      "\tspeed: 0.0205s/iter; left time: 381.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0741923 Vali Loss: 0.0764369 Test Loss: 0.0859239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0744676\n",
      "\tspeed: 0.0419s/iter; left time: 775.4276s\n",
      "\titers: 200, epoch: 18 | loss: 0.0762818\n",
      "\tspeed: 0.0202s/iter; left time: 371.9966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0740024 Vali Loss: 0.0767829 Test Loss: 0.0857268\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720721\n",
      "\tspeed: 0.0437s/iter; left time: 797.7713s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713664\n",
      "\tspeed: 0.0189s/iter; left time: 342.6416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0738495 Vali Loss: 0.0765352 Test Loss: 0.0859384\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717330\n",
      "\tspeed: 0.0413s/iter; left time: 745.2349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0795915\n",
      "\tspeed: 0.0205s/iter; left time: 368.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0736705 Vali Loss: 0.0764407 Test Loss: 0.0857348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0724586\n",
      "\tspeed: 0.0392s/iter; left time: 697.8497s\n",
      "\titers: 200, epoch: 21 | loss: 0.0760887\n",
      "\tspeed: 0.0186s/iter; left time: 329.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0735496 Vali Loss: 0.0764364 Test Loss: 0.0857035\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0712291\n",
      "\tspeed: 0.0433s/iter; left time: 762.3607s\n",
      "\titers: 200, epoch: 22 | loss: 0.0771685\n",
      "\tspeed: 0.0197s/iter; left time: 344.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0734158 Vali Loss: 0.0766588 Test Loss: 0.0858466\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0699845\n",
      "\tspeed: 0.0433s/iter; left time: 751.8209s\n",
      "\titers: 200, epoch: 23 | loss: 0.0729147\n",
      "\tspeed: 0.0220s/iter; left time: 380.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0733128 Vali Loss: 0.0762644 Test Loss: 0.0857591\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018521282821893692, rmse:0.1360929161310196, mae:0.08624237030744553, rse:0.39980003237724304\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:11.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1373530\n",
      "\tspeed: 0.0465s/iter; left time: 1032.9857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231130\n",
      "\tspeed: 0.0178s/iter; left time: 392.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.1409036 Vali Loss: 0.1098791 Test Loss: 0.1227950\n",
      "Validation loss decreased (inf --> 0.109879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0984424\n",
      "\tspeed: 0.0383s/iter; left time: 841.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.0898476\n",
      "\tspeed: 0.0182s/iter; left time: 398.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0985992 Vali Loss: 0.0892979 Test Loss: 0.1007477\n",
      "Validation loss decreased (0.109879 --> 0.089298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924045\n",
      "\tspeed: 0.0405s/iter; left time: 880.7054s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917421\n",
      "\tspeed: 0.0180s/iter; left time: 389.3996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0898567 Vali Loss: 0.0863748 Test Loss: 0.0964161\n",
      "Validation loss decreased (0.089298 --> 0.086375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892772\n",
      "\tspeed: 0.0398s/iter; left time: 856.7383s\n",
      "\titers: 200, epoch: 4 | loss: 0.0851799\n",
      "\tspeed: 0.0179s/iter; left time: 383.3302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0869219 Vali Loss: 0.0845703 Test Loss: 0.0945225\n",
      "Validation loss decreased (0.086375 --> 0.084570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874058\n",
      "\tspeed: 0.0391s/iter; left time: 832.4707s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828013\n",
      "\tspeed: 0.0178s/iter; left time: 377.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0849152 Vali Loss: 0.0836334 Test Loss: 0.0937513\n",
      "Validation loss decreased (0.084570 --> 0.083633).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0815478\n",
      "\tspeed: 0.0387s/iter; left time: 816.1537s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822768\n",
      "\tspeed: 0.0180s/iter; left time: 377.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0835952 Vali Loss: 0.0829994 Test Loss: 0.0932573\n",
      "Validation loss decreased (0.083633 --> 0.082999).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838339\n",
      "\tspeed: 0.0395s/iter; left time: 823.9421s\n",
      "\titers: 200, epoch: 7 | loss: 0.0832751\n",
      "\tspeed: 0.0178s/iter; left time: 370.5364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0826350 Vali Loss: 0.0830178 Test Loss: 0.0929825\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780568\n",
      "\tspeed: 0.0390s/iter; left time: 803.9680s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825638\n",
      "\tspeed: 0.0203s/iter; left time: 417.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 223 | Train Loss: 0.0819650 Vali Loss: 0.0831217 Test Loss: 0.0930658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0815612\n",
      "\tspeed: 0.0383s/iter; left time: 782.0732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793496\n",
      "\tspeed: 0.0184s/iter; left time: 373.9912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0814262 Vali Loss: 0.0825041 Test Loss: 0.0924428\n",
      "Validation loss decreased (0.082999 --> 0.082504).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0814151\n",
      "\tspeed: 0.0392s/iter; left time: 790.9053s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819548\n",
      "\tspeed: 0.0179s/iter; left time: 360.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0809147 Vali Loss: 0.0830627 Test Loss: 0.0926520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0803450\n",
      "\tspeed: 0.0384s/iter; left time: 767.3787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782218\n",
      "\tspeed: 0.0181s/iter; left time: 360.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0805403 Vali Loss: 0.0824139 Test Loss: 0.0921823\n",
      "Validation loss decreased (0.082504 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0775920\n",
      "\tspeed: 0.0397s/iter; left time: 784.6760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816294\n",
      "\tspeed: 0.0182s/iter; left time: 357.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0801135 Vali Loss: 0.0824283 Test Loss: 0.0917523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782452\n",
      "\tspeed: 0.0407s/iter; left time: 794.1000s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793490\n",
      "\tspeed: 0.0190s/iter; left time: 369.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0797442 Vali Loss: 0.0824807 Test Loss: 0.0922180\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785616\n",
      "\tspeed: 0.0401s/iter; left time: 773.2075s\n",
      "\titers: 200, epoch: 14 | loss: 0.0811015\n",
      "\tspeed: 0.0178s/iter; left time: 342.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0794834 Vali Loss: 0.0825382 Test Loss: 0.0917946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793498\n",
      "\tspeed: 0.0381s/iter; left time: 726.5424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0845542\n",
      "\tspeed: 0.0178s/iter; left time: 337.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0791975 Vali Loss: 0.0827265 Test Loss: 0.0922221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800094\n",
      "\tspeed: 0.0381s/iter; left time: 719.1809s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803068\n",
      "\tspeed: 0.0181s/iter; left time: 340.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0789066 Vali Loss: 0.0829194 Test Loss: 0.0920897\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777317\n",
      "\tspeed: 0.0381s/iter; left time: 710.2658s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769415\n",
      "\tspeed: 0.0178s/iter; left time: 329.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0787117 Vali Loss: 0.0828620 Test Loss: 0.0919372\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0754707\n",
      "\tspeed: 0.0418s/iter; left time: 769.0558s\n",
      "\titers: 200, epoch: 18 | loss: 0.0807448\n",
      "\tspeed: 0.0184s/iter; left time: 336.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0784592 Vali Loss: 0.0827428 Test Loss: 0.0919137\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0788248\n",
      "\tspeed: 0.0387s/iter; left time: 703.3631s\n",
      "\titers: 200, epoch: 19 | loss: 0.0779088\n",
      "\tspeed: 0.0180s/iter; left time: 325.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0783152 Vali Loss: 0.0827719 Test Loss: 0.0921597\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0814836\n",
      "\tspeed: 0.0378s/iter; left time: 678.8644s\n",
      "\titers: 200, epoch: 20 | loss: 0.0774235\n",
      "\tspeed: 0.0178s/iter; left time: 317.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0781401 Vali Loss: 0.0830398 Test Loss: 0.0921266\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0771261\n",
      "\tspeed: 0.0382s/iter; left time: 677.8467s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789094\n",
      "\tspeed: 0.0178s/iter; left time: 314.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0780248 Vali Loss: 0.0829910 Test Loss: 0.0919375\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020852474495768547, rmse:0.1444038599729538, mae:0.09218230098485947, rse:0.42424553632736206\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1372358\n",
      "\tspeed: 0.0202s/iter; left time: 449.2328s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189031\n",
      "\tspeed: 0.0179s/iter; left time: 395.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1425659 Vali Loss: 0.1109068 Test Loss: 0.1238196\n",
      "Validation loss decreased (inf --> 0.110907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0962597\n",
      "\tspeed: 0.0425s/iter; left time: 935.0872s\n",
      "\titers: 200, epoch: 2 | loss: 0.0892632\n",
      "\tspeed: 0.0180s/iter; left time: 393.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0986520 Vali Loss: 0.0897229 Test Loss: 0.1013632\n",
      "Validation loss decreased (0.110907 --> 0.089723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0895527\n",
      "\tspeed: 0.0434s/iter; left time: 943.5019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0907336\n",
      "\tspeed: 0.0201s/iter; left time: 435.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0899338 Vali Loss: 0.0860113 Test Loss: 0.0964112\n",
      "Validation loss decreased (0.089723 --> 0.086011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0877847\n",
      "\tspeed: 0.0397s/iter; left time: 854.1758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873513\n",
      "\tspeed: 0.0179s/iter; left time: 383.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0867699 Vali Loss: 0.0845652 Test Loss: 0.0945405\n",
      "Validation loss decreased (0.086011 --> 0.084565).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860343\n",
      "\tspeed: 0.0392s/iter; left time: 834.4113s\n",
      "\titers: 200, epoch: 5 | loss: 0.0856858\n",
      "\tspeed: 0.0179s/iter; left time: 380.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0848098 Vali Loss: 0.0831996 Test Loss: 0.0935732\n",
      "Validation loss decreased (0.084565 --> 0.083200).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817515\n",
      "\tspeed: 0.0383s/iter; left time: 807.6410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0839486\n",
      "\tspeed: 0.0178s/iter; left time: 374.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0835718 Vali Loss: 0.0824345 Test Loss: 0.0923223\n",
      "Validation loss decreased (0.083200 --> 0.082434).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821306\n",
      "\tspeed: 0.0427s/iter; left time: 891.5068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0817424\n",
      "\tspeed: 0.0198s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0828282 Vali Loss: 0.0827731 Test Loss: 0.0922567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816821\n",
      "\tspeed: 0.0384s/iter; left time: 791.9485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851653\n",
      "\tspeed: 0.0178s/iter; left time: 366.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0822374 Vali Loss: 0.0825162 Test Loss: 0.0923592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792334\n",
      "\tspeed: 0.0387s/iter; left time: 789.8722s\n",
      "\titers: 200, epoch: 9 | loss: 0.0820873\n",
      "\tspeed: 0.0177s/iter; left time: 360.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0817259 Vali Loss: 0.0824933 Test Loss: 0.0925659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0831882\n",
      "\tspeed: 0.0420s/iter; left time: 848.0628s\n",
      "\titers: 200, epoch: 10 | loss: 0.0840190\n",
      "\tspeed: 0.0204s/iter; left time: 410.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0812772 Vali Loss: 0.0824480 Test Loss: 0.0920063\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844629\n",
      "\tspeed: 0.0422s/iter; left time: 842.0142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0821361\n",
      "\tspeed: 0.0217s/iter; left time: 430.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 223 | Train Loss: 0.0809295 Vali Loss: 0.0831282 Test Loss: 0.0924046\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819720\n",
      "\tspeed: 0.0393s/iter; left time: 775.8412s\n",
      "\titers: 200, epoch: 12 | loss: 0.0770248\n",
      "\tspeed: 0.0181s/iter; left time: 356.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0805377 Vali Loss: 0.0823976 Test Loss: 0.0917684\n",
      "Validation loss decreased (0.082434 --> 0.082398).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0825309\n",
      "\tspeed: 0.0393s/iter; left time: 768.1248s\n",
      "\titers: 200, epoch: 13 | loss: 0.0808482\n",
      "\tspeed: 0.0178s/iter; left time: 346.5230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0802130 Vali Loss: 0.0822795 Test Loss: 0.0915192\n",
      "Validation loss decreased (0.082398 --> 0.082279).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0787355\n",
      "\tspeed: 0.0396s/iter; left time: 764.3940s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800075\n",
      "\tspeed: 0.0178s/iter; left time: 341.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0799463 Vali Loss: 0.0827081 Test Loss: 0.0917543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0808903\n",
      "\tspeed: 0.0406s/iter; left time: 775.0545s\n",
      "\titers: 200, epoch: 15 | loss: 0.0780651\n",
      "\tspeed: 0.0209s/iter; left time: 397.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0796282 Vali Loss: 0.0825399 Test Loss: 0.0913055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0823017\n",
      "\tspeed: 0.0437s/iter; left time: 823.8916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0812932\n",
      "\tspeed: 0.0181s/iter; left time: 339.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0794008 Vali Loss: 0.0822595 Test Loss: 0.0912687\n",
      "Validation loss decreased (0.082279 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0768999\n",
      "\tspeed: 0.0397s/iter; left time: 740.5874s\n",
      "\titers: 200, epoch: 17 | loss: 0.0793285\n",
      "\tspeed: 0.0182s/iter; left time: 337.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0792046 Vali Loss: 0.0824286 Test Loss: 0.0913005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0811558\n",
      "\tspeed: 0.0422s/iter; left time: 776.8880s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767288\n",
      "\tspeed: 0.0186s/iter; left time: 341.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0790217 Vali Loss: 0.0826947 Test Loss: 0.0914750\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766188\n",
      "\tspeed: 0.0383s/iter; left time: 696.5783s\n",
      "\titers: 200, epoch: 19 | loss: 0.0823196\n",
      "\tspeed: 0.0180s/iter; left time: 325.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0788044 Vali Loss: 0.0827591 Test Loss: 0.0914700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801984\n",
      "\tspeed: 0.0382s/iter; left time: 686.2105s\n",
      "\titers: 200, epoch: 20 | loss: 0.0807184\n",
      "\tspeed: 0.0179s/iter; left time: 319.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0786730 Vali Loss: 0.0820548 Test Loss: 0.0909845\n",
      "Validation loss decreased (0.082259 --> 0.082055).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0805757\n",
      "\tspeed: 0.0410s/iter; left time: 726.6098s\n",
      "\titers: 200, epoch: 21 | loss: 0.0777372\n",
      "\tspeed: 0.0185s/iter; left time: 325.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0785318 Vali Loss: 0.0824276 Test Loss: 0.0911584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793678\n",
      "\tspeed: 0.0398s/iter; left time: 697.4270s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783650\n",
      "\tspeed: 0.0185s/iter; left time: 322.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0784128 Vali Loss: 0.0825987 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0799742\n",
      "\tspeed: 0.0389s/iter; left time: 673.1967s\n",
      "\titers: 200, epoch: 23 | loss: 0.0794193\n",
      "\tspeed: 0.0180s/iter; left time: 308.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0783116 Vali Loss: 0.0825067 Test Loss: 0.0911256\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0774844\n",
      "\tspeed: 0.0408s/iter; left time: 695.8240s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797026\n",
      "\tspeed: 0.0187s/iter; left time: 317.2155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0781464 Vali Loss: 0.0826594 Test Loss: 0.0912149\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770763\n",
      "\tspeed: 0.0453s/iter; left time: 763.6968s\n",
      "\titers: 200, epoch: 25 | loss: 0.0791379\n",
      "\tspeed: 0.0215s/iter; left time: 359.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0780359 Vali Loss: 0.0827667 Test Loss: 0.0911917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812251\n",
      "\tspeed: 0.0463s/iter; left time: 769.7062s\n",
      "\titers: 200, epoch: 26 | loss: 0.0773855\n",
      "\tspeed: 0.0217s/iter; left time: 358.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0779974 Vali Loss: 0.0827996 Test Loss: 0.0910253\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775638\n",
      "\tspeed: 0.0450s/iter; left time: 737.7617s\n",
      "\titers: 200, epoch: 27 | loss: 0.0749843\n",
      "\tspeed: 0.0213s/iter; left time: 346.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0779365 Vali Loss: 0.0824053 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0782782\n",
      "\tspeed: 0.0427s/iter; left time: 691.0858s\n",
      "\titers: 200, epoch: 28 | loss: 0.0794728\n",
      "\tspeed: 0.0213s/iter; left time: 342.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0778237 Vali Loss: 0.0824167 Test Loss: 0.0909431\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744470\n",
      "\tspeed: 0.0498s/iter; left time: 794.5243s\n",
      "\titers: 200, epoch: 29 | loss: 0.0743873\n",
      "\tspeed: 0.0229s/iter; left time: 363.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 223 | Train Loss: 0.0778208 Vali Loss: 0.0826677 Test Loss: 0.0910047\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0778956\n",
      "\tspeed: 0.0468s/iter; left time: 736.4441s\n",
      "\titers: 200, epoch: 30 | loss: 0.0735903\n",
      "\tspeed: 0.0199s/iter; left time: 311.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0777318 Vali Loss: 0.0826702 Test Loss: 0.0909662\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02058718539774418, rmse:0.14348235726356506, mae:0.09098456054925919, rse:0.42153823375701904\n",
      "Intermediate time for ES and pred_len 168: 00h:05m:15.25s\n",
      "Intermediate time for ES: 00h:22m:06.03s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0923198\n",
      "\tspeed: 0.0471s/iter; left time: 1050.7328s\n",
      "\titers: 200, epoch: 1 | loss: 0.0812700\n",
      "\tspeed: 0.0175s/iter; left time: 389.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0997137 Vali Loss: 0.0826080 Test Loss: 0.0894115\n",
      "Validation loss decreased (inf --> 0.082608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0530040\n",
      "\tspeed: 0.0374s/iter; left time: 825.2455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500890\n",
      "\tspeed: 0.0176s/iter; left time: 386.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0568332 Vali Loss: 0.0584304 Test Loss: 0.0615740\n",
      "Validation loss decreased (0.082608 --> 0.058430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0495541\n",
      "\tspeed: 0.0390s/iter; left time: 852.1089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0470994\n",
      "\tspeed: 0.0178s/iter; left time: 386.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0492891 Vali Loss: 0.0561867 Test Loss: 0.0599419\n",
      "Validation loss decreased (0.058430 --> 0.056187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472196\n",
      "\tspeed: 0.0373s/iter; left time: 805.7826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496854\n",
      "\tspeed: 0.0175s/iter; left time: 375.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0474948 Vali Loss: 0.0547214 Test Loss: 0.0583943\n",
      "Validation loss decreased (0.056187 --> 0.054721).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0445898\n",
      "\tspeed: 0.0379s/iter; left time: 811.0635s\n",
      "\titers: 200, epoch: 5 | loss: 0.0486444\n",
      "\tspeed: 0.0175s/iter; left time: 373.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0462286 Vali Loss: 0.0537535 Test Loss: 0.0576479\n",
      "Validation loss decreased (0.054721 --> 0.053753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0466075\n",
      "\tspeed: 0.0384s/iter; left time: 813.6643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0427133\n",
      "\tspeed: 0.0173s/iter; left time: 364.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0453936 Vali Loss: 0.0532484 Test Loss: 0.0574954\n",
      "Validation loss decreased (0.053753 --> 0.053248).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0491663\n",
      "\tspeed: 0.0406s/iter; left time: 851.6473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0448862\n",
      "\tspeed: 0.0174s/iter; left time: 362.2701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0447000 Vali Loss: 0.0526119 Test Loss: 0.0567984\n",
      "Validation loss decreased (0.053248 --> 0.052612).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0448391\n",
      "\tspeed: 0.0388s/iter; left time: 803.6487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0443497\n",
      "\tspeed: 0.0175s/iter; left time: 361.5817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0441658 Vali Loss: 0.0528287 Test Loss: 0.0566366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0405296\n",
      "\tspeed: 0.0380s/iter; left time: 779.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0458015\n",
      "\tspeed: 0.0173s/iter; left time: 354.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0437640 Vali Loss: 0.0521360 Test Loss: 0.0564570\n",
      "Validation loss decreased (0.052612 --> 0.052136).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441886\n",
      "\tspeed: 0.0407s/iter; left time: 826.5387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0448638\n",
      "\tspeed: 0.0206s/iter; left time: 415.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0434143 Vali Loss: 0.0517792 Test Loss: 0.0561378\n",
      "Validation loss decreased (0.052136 --> 0.051779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440236\n",
      "\tspeed: 0.0429s/iter; left time: 861.3392s\n",
      "\titers: 200, epoch: 11 | loss: 0.0420616\n",
      "\tspeed: 0.0212s/iter; left time: 423.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0431010 Vali Loss: 0.0520836 Test Loss: 0.0564000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0403346\n",
      "\tspeed: 0.0366s/iter; left time: 726.8405s\n",
      "\titers: 200, epoch: 12 | loss: 0.0413291\n",
      "\tspeed: 0.0175s/iter; left time: 345.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0428325 Vali Loss: 0.0517494 Test Loss: 0.0560631\n",
      "Validation loss decreased (0.051779 --> 0.051749).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0406433\n",
      "\tspeed: 0.0376s/iter; left time: 737.7125s\n",
      "\titers: 200, epoch: 13 | loss: 0.0392740\n",
      "\tspeed: 0.0175s/iter; left time: 342.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0425714 Vali Loss: 0.0517062 Test Loss: 0.0557897\n",
      "Validation loss decreased (0.051749 --> 0.051706).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0407032\n",
      "\tspeed: 0.0399s/iter; left time: 773.5516s\n",
      "\titers: 200, epoch: 14 | loss: 0.0415839\n",
      "\tspeed: 0.0184s/iter; left time: 355.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0424152 Vali Loss: 0.0514950 Test Loss: 0.0557442\n",
      "Validation loss decreased (0.051706 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0427796\n",
      "\tspeed: 0.0377s/iter; left time: 723.2441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0386341\n",
      "\tspeed: 0.0173s/iter; left time: 330.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0422304 Vali Loss: 0.0514152 Test Loss: 0.0555388\n",
      "Validation loss decreased (0.051495 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407047\n",
      "\tspeed: 0.0367s/iter; left time: 695.1301s\n",
      "\titers: 200, epoch: 16 | loss: 0.0395314\n",
      "\tspeed: 0.0197s/iter; left time: 370.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0421071 Vali Loss: 0.0514455 Test Loss: 0.0555331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0455639\n",
      "\tspeed: 0.0411s/iter; left time: 768.5792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0418858\n",
      "\tspeed: 0.0178s/iter; left time: 331.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0419426 Vali Loss: 0.0512198 Test Loss: 0.0553853\n",
      "Validation loss decreased (0.051415 --> 0.051220).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0401110\n",
      "\tspeed: 0.0382s/iter; left time: 706.4201s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410072\n",
      "\tspeed: 0.0177s/iter; left time: 326.4655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418059 Vali Loss: 0.0510725 Test Loss: 0.0553629\n",
      "Validation loss decreased (0.051220 --> 0.051072).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0397940\n",
      "\tspeed: 0.0400s/iter; left time: 730.7567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415944\n",
      "\tspeed: 0.0209s/iter; left time: 378.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0416938 Vali Loss: 0.0510424 Test Loss: 0.0552553\n",
      "Validation loss decreased (0.051072 --> 0.051042).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0410033\n",
      "\tspeed: 0.0427s/iter; left time: 770.8388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0419177\n",
      "\tspeed: 0.0181s/iter; left time: 324.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0416170 Vali Loss: 0.0509896 Test Loss: 0.0552562\n",
      "Validation loss decreased (0.051042 --> 0.050990).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0414350\n",
      "\tspeed: 0.0380s/iter; left time: 677.0998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0406842\n",
      "\tspeed: 0.0174s/iter; left time: 307.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0415393 Vali Loss: 0.0508995 Test Loss: 0.0550967\n",
      "Validation loss decreased (0.050990 --> 0.050899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0403014\n",
      "\tspeed: 0.0401s/iter; left time: 705.8079s\n",
      "\titers: 200, epoch: 22 | loss: 0.0367226\n",
      "\tspeed: 0.0178s/iter; left time: 310.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0414575 Vali Loss: 0.0509838 Test Loss: 0.0551132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0409429\n",
      "\tspeed: 0.0398s/iter; left time: 691.6798s\n",
      "\titers: 200, epoch: 23 | loss: 0.0429620\n",
      "\tspeed: 0.0223s/iter; left time: 385.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0413607 Vali Loss: 0.0509441 Test Loss: 0.0551800\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404058\n",
      "\tspeed: 0.0397s/iter; left time: 681.0152s\n",
      "\titers: 200, epoch: 24 | loss: 0.0405565\n",
      "\tspeed: 0.0222s/iter; left time: 378.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0413338 Vali Loss: 0.0509188 Test Loss: 0.0551000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423914\n",
      "\tspeed: 0.0407s/iter; left time: 688.4196s\n",
      "\titers: 200, epoch: 25 | loss: 0.0413437\n",
      "\tspeed: 0.0197s/iter; left time: 330.8031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0412619 Vali Loss: 0.0509029 Test Loss: 0.0551642\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0389570\n",
      "\tspeed: 0.0380s/iter; left time: 634.0786s\n",
      "\titers: 200, epoch: 26 | loss: 0.0388686\n",
      "\tspeed: 0.0176s/iter; left time: 292.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0412201 Vali Loss: 0.0509290 Test Loss: 0.0551733\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0415587\n",
      "\tspeed: 0.0369s/iter; left time: 607.7228s\n",
      "\titers: 200, epoch: 27 | loss: 0.0423500\n",
      "\tspeed: 0.0197s/iter; left time: 322.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0411406 Vali Loss: 0.0508458 Test Loss: 0.0550130\n",
      "Validation loss decreased (0.050899 --> 0.050846).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0435844\n",
      "\tspeed: 0.0411s/iter; left time: 668.6772s\n",
      "\titers: 200, epoch: 28 | loss: 0.0385247\n",
      "\tspeed: 0.0200s/iter; left time: 322.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0411405 Vali Loss: 0.0508347 Test Loss: 0.0550222\n",
      "Validation loss decreased (0.050846 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0420762\n",
      "\tspeed: 0.0368s/iter; left time: 589.5002s\n",
      "\titers: 200, epoch: 29 | loss: 0.0388678\n",
      "\tspeed: 0.0175s/iter; left time: 278.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0411094 Vali Loss: 0.0508880 Test Loss: 0.0549905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0427229\n",
      "\tspeed: 0.0421s/iter; left time: 665.9101s\n",
      "\titers: 200, epoch: 30 | loss: 0.0388344\n",
      "\tspeed: 0.0202s/iter; left time: 317.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0410763 Vali Loss: 0.0508937 Test Loss: 0.0550308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0407782\n",
      "\tspeed: 0.0365s/iter; left time: 568.3944s\n",
      "\titers: 200, epoch: 31 | loss: 0.0419291\n",
      "\tspeed: 0.0195s/iter; left time: 302.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0410766 Vali Loss: 0.0506749 Test Loss: 0.0550058\n",
      "Validation loss decreased (0.050835 --> 0.050675).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0414399\n",
      "\tspeed: 0.0382s/iter; left time: 586.8291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421118\n",
      "\tspeed: 0.0199s/iter; left time: 303.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0410319 Vali Loss: 0.0507480 Test Loss: 0.0549598\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0422271\n",
      "\tspeed: 0.0365s/iter; left time: 552.3449s\n",
      "\titers: 200, epoch: 33 | loss: 0.0414499\n",
      "\tspeed: 0.0175s/iter; left time: 263.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0409737 Vali Loss: 0.0507774 Test Loss: 0.0549851\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0413024\n",
      "\tspeed: 0.0361s/iter; left time: 538.2906s\n",
      "\titers: 200, epoch: 34 | loss: 0.0401151\n",
      "\tspeed: 0.0174s/iter; left time: 256.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0409406 Vali Loss: 0.0506703 Test Loss: 0.0549519\n",
      "Validation loss decreased (0.050675 --> 0.050670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0408263\n",
      "\tspeed: 0.0391s/iter; left time: 574.3639s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405118\n",
      "\tspeed: 0.0176s/iter; left time: 256.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0409528 Vali Loss: 0.0507586 Test Loss: 0.0549365\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0392115\n",
      "\tspeed: 0.0370s/iter; left time: 534.8904s\n",
      "\titers: 200, epoch: 36 | loss: 0.0404948\n",
      "\tspeed: 0.0175s/iter; left time: 251.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409394 Vali Loss: 0.0507388 Test Loss: 0.0549210\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0423826\n",
      "\tspeed: 0.0361s/iter; left time: 513.9982s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399949\n",
      "\tspeed: 0.0187s/iter; left time: 264.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0409280 Vali Loss: 0.0507797 Test Loss: 0.0549513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0420419\n",
      "\tspeed: 0.0364s/iter; left time: 509.5619s\n",
      "\titers: 200, epoch: 38 | loss: 0.0414468\n",
      "\tspeed: 0.0180s/iter; left time: 250.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0408825 Vali Loss: 0.0506685 Test Loss: 0.0549180\n",
      "Validation loss decreased (0.050670 --> 0.050669).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0411821\n",
      "\tspeed: 0.0397s/iter; left time: 546.7866s\n",
      "\titers: 200, epoch: 39 | loss: 0.0366663\n",
      "\tspeed: 0.0173s/iter; left time: 236.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0409059 Vali Loss: 0.0507391 Test Loss: 0.0549399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0391978\n",
      "\tspeed: 0.0413s/iter; left time: 560.1932s\n",
      "\titers: 200, epoch: 40 | loss: 0.0425756\n",
      "\tspeed: 0.0195s/iter; left time: 263.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0409207 Vali Loss: 0.0506791 Test Loss: 0.0549067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416604\n",
      "\tspeed: 0.0367s/iter; left time: 489.4409s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402725\n",
      "\tspeed: 0.0173s/iter; left time: 228.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0408218 Vali Loss: 0.0507860 Test Loss: 0.0549271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0415616\n",
      "\tspeed: 0.0356s/iter; left time: 466.7670s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426821\n",
      "\tspeed: 0.0174s/iter; left time: 226.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0408661 Vali Loss: 0.0506999 Test Loss: 0.0549061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0412373\n",
      "\tspeed: 0.0362s/iter; left time: 466.9375s\n",
      "\titers: 200, epoch: 43 | loss: 0.0388965\n",
      "\tspeed: 0.0175s/iter; left time: 224.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408737 Vali Loss: 0.0507067 Test Loss: 0.0549184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0409356\n",
      "\tspeed: 0.0366s/iter; left time: 463.4980s\n",
      "\titers: 200, epoch: 44 | loss: 0.0419919\n",
      "\tspeed: 0.0175s/iter; left time: 220.0932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0407900 Vali Loss: 0.0507195 Test Loss: 0.0548893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0395876\n",
      "\tspeed: 0.0357s/iter; left time: 444.3419s\n",
      "\titers: 200, epoch: 45 | loss: 0.0424386\n",
      "\tspeed: 0.0176s/iter; left time: 217.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408467 Vali Loss: 0.0507040 Test Loss: 0.0548965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400761\n",
      "\tspeed: 0.0384s/iter; left time: 468.8836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0398946\n",
      "\tspeed: 0.0200s/iter; left time: 242.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 224 | Train Loss: 0.0407960 Vali Loss: 0.0507497 Test Loss: 0.0548866\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393914\n",
      "\tspeed: 0.0370s/iter; left time: 443.4982s\n",
      "\titers: 200, epoch: 47 | loss: 0.0387283\n",
      "\tspeed: 0.0223s/iter; left time: 265.7545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408184 Vali Loss: 0.0507020 Test Loss: 0.0548986\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393765\n",
      "\tspeed: 0.0409s/iter; left time: 481.1759s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420225\n",
      "\tspeed: 0.0176s/iter; left time: 205.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0408080 Vali Loss: 0.0507258 Test Loss: 0.0548816\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010047451592981815, rmse:0.10023697465658188, mae:0.05491799861192703, rse:0.3867114782333374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0935595\n",
      "\tspeed: 0.0249s/iter; left time: 554.6922s\n",
      "\titers: 200, epoch: 1 | loss: 0.0815350\n",
      "\tspeed: 0.0238s/iter; left time: 529.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0985673 Vali Loss: 0.0815828 Test Loss: 0.0878835\n",
      "Validation loss decreased (inf --> 0.081583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0546182\n",
      "\tspeed: 0.0405s/iter; left time: 894.5638s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524375\n",
      "\tspeed: 0.0177s/iter; left time: 388.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0564773 Vali Loss: 0.0585265 Test Loss: 0.0620153\n",
      "Validation loss decreased (0.081583 --> 0.058526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0516169\n",
      "\tspeed: 0.0405s/iter; left time: 883.9750s\n",
      "\titers: 200, epoch: 3 | loss: 0.0538712\n",
      "\tspeed: 0.0176s/iter; left time: 383.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0494922 Vali Loss: 0.0564595 Test Loss: 0.0600532\n",
      "Validation loss decreased (0.058526 --> 0.056460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0500758\n",
      "\tspeed: 0.0409s/iter; left time: 884.1769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0470287\n",
      "\tspeed: 0.0173s/iter; left time: 372.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0476510 Vali Loss: 0.0550841 Test Loss: 0.0591046\n",
      "Validation loss decreased (0.056460 --> 0.055084).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476657\n",
      "\tspeed: 0.0393s/iter; left time: 840.3386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0453900\n",
      "\tspeed: 0.0175s/iter; left time: 372.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0462703 Vali Loss: 0.0539240 Test Loss: 0.0578887\n",
      "Validation loss decreased (0.055084 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0436470\n",
      "\tspeed: 0.0385s/iter; left time: 815.6399s\n",
      "\titers: 200, epoch: 6 | loss: 0.0469544\n",
      "\tspeed: 0.0179s/iter; left time: 377.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0453504 Vali Loss: 0.0534992 Test Loss: 0.0576763\n",
      "Validation loss decreased (0.053924 --> 0.053499).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0498019\n",
      "\tspeed: 0.0372s/iter; left time: 780.1501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0435070\n",
      "\tspeed: 0.0173s/iter; left time: 361.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0447041 Vali Loss: 0.0528023 Test Loss: 0.0570895\n",
      "Validation loss decreased (0.053499 --> 0.052802).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433632\n",
      "\tspeed: 0.0385s/iter; left time: 797.2715s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472117\n",
      "\tspeed: 0.0184s/iter; left time: 380.0873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0442430 Vali Loss: 0.0525080 Test Loss: 0.0565417\n",
      "Validation loss decreased (0.052802 --> 0.052508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0442935\n",
      "\tspeed: 0.0381s/iter; left time: 780.5073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439991\n",
      "\tspeed: 0.0181s/iter; left time: 369.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0437869 Vali Loss: 0.0521499 Test Loss: 0.0563267\n",
      "Validation loss decreased (0.052508 --> 0.052150).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457982\n",
      "\tspeed: 0.0375s/iter; left time: 761.0894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0451140\n",
      "\tspeed: 0.0175s/iter; left time: 354.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0434726 Vali Loss: 0.0523196 Test Loss: 0.0562200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0418626\n",
      "\tspeed: 0.0373s/iter; left time: 747.8968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0411332\n",
      "\tspeed: 0.0176s/iter; left time: 350.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0431422 Vali Loss: 0.0519555 Test Loss: 0.0562363\n",
      "Validation loss decreased (0.052150 --> 0.051955).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0414568\n",
      "\tspeed: 0.0397s/iter; left time: 787.3697s\n",
      "\titers: 200, epoch: 12 | loss: 0.0442729\n",
      "\tspeed: 0.0185s/iter; left time: 365.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.0429151 Vali Loss: 0.0517021 Test Loss: 0.0557212\n",
      "Validation loss decreased (0.051955 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0447191\n",
      "\tspeed: 0.0423s/iter; left time: 829.6593s\n",
      "\titers: 200, epoch: 13 | loss: 0.0452590\n",
      "\tspeed: 0.0227s/iter; left time: 443.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0426312 Vali Loss: 0.0516790 Test Loss: 0.0557699\n",
      "Validation loss decreased (0.051702 --> 0.051679).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0460300\n",
      "\tspeed: 0.0378s/iter; left time: 732.2859s\n",
      "\titers: 200, epoch: 14 | loss: 0.0424465\n",
      "\tspeed: 0.0174s/iter; left time: 335.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0424535 Vali Loss: 0.0514955 Test Loss: 0.0555738\n",
      "Validation loss decreased (0.051679 --> 0.051495).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425895\n",
      "\tspeed: 0.0379s/iter; left time: 725.9930s\n",
      "\titers: 200, epoch: 15 | loss: 0.0400014\n",
      "\tspeed: 0.0199s/iter; left time: 379.4924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0422823 Vali Loss: 0.0517129 Test Loss: 0.0555978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0436068\n",
      "\tspeed: 0.0389s/iter; left time: 736.5599s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415642\n",
      "\tspeed: 0.0175s/iter; left time: 330.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0421010 Vali Loss: 0.0514501 Test Loss: 0.0553953\n",
      "Validation loss decreased (0.051495 --> 0.051450).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0403893\n",
      "\tspeed: 0.0378s/iter; left time: 707.0198s\n",
      "\titers: 200, epoch: 17 | loss: 0.0428705\n",
      "\tspeed: 0.0175s/iter; left time: 326.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0419437 Vali Loss: 0.0512283 Test Loss: 0.0553973\n",
      "Validation loss decreased (0.051450 --> 0.051228).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435594\n",
      "\tspeed: 0.0374s/iter; left time: 691.4029s\n",
      "\titers: 200, epoch: 18 | loss: 0.0430981\n",
      "\tspeed: 0.0176s/iter; left time: 323.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0418711 Vali Loss: 0.0511208 Test Loss: 0.0552354\n",
      "Validation loss decreased (0.051228 --> 0.051121).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0425317\n",
      "\tspeed: 0.0388s/iter; left time: 708.5180s\n",
      "\titers: 200, epoch: 19 | loss: 0.0425620\n",
      "\tspeed: 0.0178s/iter; left time: 322.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0417220 Vali Loss: 0.0513766 Test Loss: 0.0552269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0389410\n",
      "\tspeed: 0.0386s/iter; left time: 696.3162s\n",
      "\titers: 200, epoch: 20 | loss: 0.0418354\n",
      "\tspeed: 0.0176s/iter; left time: 316.2799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0416325 Vali Loss: 0.0510026 Test Loss: 0.0550833\n",
      "Validation loss decreased (0.051121 --> 0.051003).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0438422\n",
      "\tspeed: 0.0370s/iter; left time: 659.7459s\n",
      "\titers: 200, epoch: 21 | loss: 0.0418498\n",
      "\tspeed: 0.0176s/iter; left time: 311.9549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0415382 Vali Loss: 0.0509244 Test Loss: 0.0550689\n",
      "Validation loss decreased (0.051003 --> 0.050924).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414739\n",
      "\tspeed: 0.0399s/iter; left time: 701.7967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0414515\n",
      "\tspeed: 0.0176s/iter; left time: 307.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0414551 Vali Loss: 0.0509189 Test Loss: 0.0550239\n",
      "Validation loss decreased (0.050924 --> 0.050919).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412667\n",
      "\tspeed: 0.0418s/iter; left time: 726.3481s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385480\n",
      "\tspeed: 0.0183s/iter; left time: 316.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 224 | Train Loss: 0.0414020 Vali Loss: 0.0509293 Test Loss: 0.0549526\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0404608\n",
      "\tspeed: 0.0433s/iter; left time: 742.8594s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383370\n",
      "\tspeed: 0.0182s/iter; left time: 310.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0413754 Vali Loss: 0.0509873 Test Loss: 0.0550544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0416779\n",
      "\tspeed: 0.0377s/iter; left time: 638.7238s\n",
      "\titers: 200, epoch: 25 | loss: 0.0415474\n",
      "\tspeed: 0.0176s/iter; left time: 295.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0412857 Vali Loss: 0.0509787 Test Loss: 0.0549485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0422339\n",
      "\tspeed: 0.0382s/iter; left time: 638.6748s\n",
      "\titers: 200, epoch: 26 | loss: 0.0430234\n",
      "\tspeed: 0.0173s/iter; left time: 287.3618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0412502 Vali Loss: 0.0510159 Test Loss: 0.0549871\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0391803\n",
      "\tspeed: 0.0425s/iter; left time: 699.8363s\n",
      "\titers: 200, epoch: 27 | loss: 0.0413634\n",
      "\tspeed: 0.0215s/iter; left time: 351.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0412082 Vali Loss: 0.0509350 Test Loss: 0.0548990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0405897\n",
      "\tspeed: 0.0418s/iter; left time: 679.4927s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397338\n",
      "\tspeed: 0.0213s/iter; left time: 344.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0411314 Vali Loss: 0.0508925 Test Loss: 0.0549294\n",
      "Validation loss decreased (0.050919 --> 0.050893).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0437130\n",
      "\tspeed: 0.0387s/iter; left time: 619.6992s\n",
      "\titers: 200, epoch: 29 | loss: 0.0453305\n",
      "\tspeed: 0.0173s/iter; left time: 276.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0410808 Vali Loss: 0.0508684 Test Loss: 0.0549480\n",
      "Validation loss decreased (0.050893 --> 0.050868).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0404034\n",
      "\tspeed: 0.0374s/iter; left time: 591.2247s\n",
      "\titers: 200, epoch: 30 | loss: 0.0408411\n",
      "\tspeed: 0.0175s/iter; left time: 274.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0410524 Vali Loss: 0.0508277 Test Loss: 0.0548504\n",
      "Validation loss decreased (0.050868 --> 0.050828).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0427010\n",
      "\tspeed: 0.0380s/iter; left time: 592.4086s\n",
      "\titers: 200, epoch: 31 | loss: 0.0425292\n",
      "\tspeed: 0.0176s/iter; left time: 271.9788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0410449 Vali Loss: 0.0508885 Test Loss: 0.0548904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0403372\n",
      "\tspeed: 0.0369s/iter; left time: 566.6934s\n",
      "\titers: 200, epoch: 32 | loss: 0.0405556\n",
      "\tspeed: 0.0175s/iter; left time: 266.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0410464 Vali Loss: 0.0508567 Test Loss: 0.0548694\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0431220\n",
      "\tspeed: 0.0385s/iter; left time: 582.1933s\n",
      "\titers: 200, epoch: 33 | loss: 0.0424416\n",
      "\tspeed: 0.0190s/iter; left time: 286.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 224 | Train Loss: 0.0410148 Vali Loss: 0.0507454 Test Loss: 0.0548886\n",
      "Validation loss decreased (0.050828 --> 0.050745).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0425253\n",
      "\tspeed: 0.0384s/iter; left time: 572.9638s\n",
      "\titers: 200, epoch: 34 | loss: 0.0445072\n",
      "\tspeed: 0.0176s/iter; left time: 260.8919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409694 Vali Loss: 0.0507921 Test Loss: 0.0548382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0386003\n",
      "\tspeed: 0.0386s/iter; left time: 567.2513s\n",
      "\titers: 200, epoch: 35 | loss: 0.0397497\n",
      "\tspeed: 0.0178s/iter; left time: 259.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0409914 Vali Loss: 0.0507661 Test Loss: 0.0548480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0463726\n",
      "\tspeed: 0.0379s/iter; left time: 547.6972s\n",
      "\titers: 200, epoch: 36 | loss: 0.0397050\n",
      "\tspeed: 0.0176s/iter; left time: 252.7580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0409164 Vali Loss: 0.0508233 Test Loss: 0.0548441\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0409133\n",
      "\tspeed: 0.0376s/iter; left time: 534.7156s\n",
      "\titers: 200, epoch: 37 | loss: 0.0423615\n",
      "\tspeed: 0.0175s/iter; left time: 247.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0409337 Vali Loss: 0.0508035 Test Loss: 0.0548229\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0406316\n",
      "\tspeed: 0.0387s/iter; left time: 542.5981s\n",
      "\titers: 200, epoch: 38 | loss: 0.0397512\n",
      "\tspeed: 0.0189s/iter; left time: 263.6104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0409042 Vali Loss: 0.0507964 Test Loss: 0.0548444\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0381033\n",
      "\tspeed: 0.0399s/iter; left time: 550.0490s\n",
      "\titers: 200, epoch: 39 | loss: 0.0382526\n",
      "\tspeed: 0.0173s/iter; left time: 236.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0409219 Vali Loss: 0.0508203 Test Loss: 0.0548079\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0409601\n",
      "\tspeed: 0.0444s/iter; left time: 602.0461s\n",
      "\titers: 200, epoch: 40 | loss: 0.0414687\n",
      "\tspeed: 0.0204s/iter; left time: 274.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0408627 Vali Loss: 0.0507907 Test Loss: 0.0547983\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0436835\n",
      "\tspeed: 0.0442s/iter; left time: 590.2730s\n",
      "\titers: 200, epoch: 41 | loss: 0.0395844\n",
      "\tspeed: 0.0205s/iter; left time: 271.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0408995 Vali Loss: 0.0507025 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050745 --> 0.050702).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0397279\n",
      "\tspeed: 0.0438s/iter; left time: 574.0071s\n",
      "\titers: 200, epoch: 42 | loss: 0.0432200\n",
      "\tspeed: 0.0203s/iter; left time: 264.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408592 Vali Loss: 0.0507363 Test Loss: 0.0547963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0390139\n",
      "\tspeed: 0.0385s/iter; left time: 496.0208s\n",
      "\titers: 200, epoch: 43 | loss: 0.0416165\n",
      "\tspeed: 0.0176s/iter; left time: 225.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0409098 Vali Loss: 0.0507644 Test Loss: 0.0547888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0394929\n",
      "\tspeed: 0.0378s/iter; left time: 478.8054s\n",
      "\titers: 200, epoch: 44 | loss: 0.0391143\n",
      "\tspeed: 0.0177s/iter; left time: 222.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0408876 Vali Loss: 0.0507556 Test Loss: 0.0547861\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0385056\n",
      "\tspeed: 0.0373s/iter; left time: 463.8164s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418280\n",
      "\tspeed: 0.0176s/iter; left time: 216.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0408062 Vali Loss: 0.0506480 Test Loss: 0.0547880\n",
      "Validation loss decreased (0.050702 --> 0.050648).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0404662\n",
      "\tspeed: 0.0407s/iter; left time: 496.9452s\n",
      "\titers: 200, epoch: 46 | loss: 0.0425981\n",
      "\tspeed: 0.0212s/iter; left time: 257.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0408597 Vali Loss: 0.0507410 Test Loss: 0.0547948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0412951\n",
      "\tspeed: 0.0371s/iter; left time: 445.5673s\n",
      "\titers: 200, epoch: 47 | loss: 0.0460205\n",
      "\tspeed: 0.0176s/iter; left time: 209.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0408051 Vali Loss: 0.0507380 Test Loss: 0.0547790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0396187\n",
      "\tspeed: 0.0385s/iter; left time: 453.1386s\n",
      "\titers: 200, epoch: 48 | loss: 0.0420261\n",
      "\tspeed: 0.0177s/iter; left time: 206.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0408679 Vali Loss: 0.0508199 Test Loss: 0.0547630\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0402250\n",
      "\tspeed: 0.0394s/iter; left time: 455.5809s\n",
      "\titers: 200, epoch: 49 | loss: 0.0436193\n",
      "\tspeed: 0.0194s/iter; left time: 222.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0408469 Vali Loss: 0.0507091 Test Loss: 0.0547697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0362207\n",
      "\tspeed: 0.0371s/iter; left time: 420.3064s\n",
      "\titers: 200, epoch: 50 | loss: 0.0385387\n",
      "\tspeed: 0.0175s/iter; left time: 196.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408548 Vali Loss: 0.0506502 Test Loss: 0.0547767\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440735\n",
      "\tspeed: 0.0385s/iter; left time: 427.6925s\n",
      "\titers: 200, epoch: 51 | loss: 0.0387501\n",
      "\tspeed: 0.0181s/iter; left time: 199.0820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0408112 Vali Loss: 0.0507077 Test Loss: 0.0547609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0404372\n",
      "\tspeed: 0.0432s/iter; left time: 470.1337s\n",
      "\titers: 200, epoch: 52 | loss: 0.0423694\n",
      "\tspeed: 0.0177s/iter; left time: 190.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408257 Vali Loss: 0.0507446 Test Loss: 0.0547665\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0421164\n",
      "\tspeed: 0.0409s/iter; left time: 435.6301s\n",
      "\titers: 200, epoch: 53 | loss: 0.0415824\n",
      "\tspeed: 0.0186s/iter; left time: 196.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0408422 Vali Loss: 0.0507633 Test Loss: 0.0547696\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0443786\n",
      "\tspeed: 0.0368s/iter; left time: 383.9620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0391313\n",
      "\tspeed: 0.0175s/iter; left time: 181.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408320 Vali Loss: 0.0507100 Test Loss: 0.0547600\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0417649\n",
      "\tspeed: 0.0400s/iter; left time: 408.2279s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409617\n",
      "\tspeed: 0.0212s/iter; left time: 214.4113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0408236 Vali Loss: 0.0506238 Test Loss: 0.0547631\n",
      "Validation loss decreased (0.050648 --> 0.050624).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0360162\n",
      "\tspeed: 0.0393s/iter; left time: 392.0179s\n",
      "\titers: 200, epoch: 56 | loss: 0.0408644\n",
      "\tspeed: 0.0177s/iter; left time: 174.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0407994 Vali Loss: 0.0507128 Test Loss: 0.0547610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0406955\n",
      "\tspeed: 0.0369s/iter; left time: 359.5597s\n",
      "\titers: 200, epoch: 57 | loss: 0.0420306\n",
      "\tspeed: 0.0176s/iter; left time: 170.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0408128 Vali Loss: 0.0507455 Test Loss: 0.0547706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0457876\n",
      "\tspeed: 0.0364s/iter; left time: 346.5785s\n",
      "\titers: 200, epoch: 58 | loss: 0.0406639\n",
      "\tspeed: 0.0176s/iter; left time: 166.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0408230 Vali Loss: 0.0506479 Test Loss: 0.0547651\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0408023\n",
      "\tspeed: 0.0401s/iter; left time: 373.1203s\n",
      "\titers: 200, epoch: 59 | loss: 0.0427719\n",
      "\tspeed: 0.0178s/iter; left time: 163.6327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0407709 Vali Loss: 0.0507367 Test Loss: 0.0547671\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0425067\n",
      "\tspeed: 0.0369s/iter; left time: 335.6411s\n",
      "\titers: 200, epoch: 60 | loss: 0.0396171\n",
      "\tspeed: 0.0190s/iter; left time: 170.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0408547 Vali Loss: 0.0507473 Test Loss: 0.0547641\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0417092\n",
      "\tspeed: 0.0435s/iter; left time: 385.4814s\n",
      "\titers: 200, epoch: 61 | loss: 0.0407552\n",
      "\tspeed: 0.0225s/iter; left time: 196.9673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0408172 Vali Loss: 0.0507417 Test Loss: 0.0547586\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394446\n",
      "\tspeed: 0.0441s/iter; left time: 380.7387s\n",
      "\titers: 200, epoch: 62 | loss: 0.0394354\n",
      "\tspeed: 0.0205s/iter; left time: 174.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0408144 Vali Loss: 0.0506968 Test Loss: 0.0547682\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0409796\n",
      "\tspeed: 0.0377s/iter; left time: 316.9350s\n",
      "\titers: 200, epoch: 63 | loss: 0.0429062\n",
      "\tspeed: 0.0180s/iter; left time: 149.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0408127 Vali Loss: 0.0507607 Test Loss: 0.0547640\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0448329\n",
      "\tspeed: 0.0409s/iter; left time: 334.5994s\n",
      "\titers: 200, epoch: 64 | loss: 0.0424715\n",
      "\tspeed: 0.0195s/iter; left time: 157.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0408103 Vali Loss: 0.0507010 Test Loss: 0.0547563\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0428965\n",
      "\tspeed: 0.0388s/iter; left time: 309.0573s\n",
      "\titers: 200, epoch: 65 | loss: 0.0406603\n",
      "\tspeed: 0.0200s/iter; left time: 156.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0407825 Vali Loss: 0.0506624 Test Loss: 0.0547556\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009938369505107403, rmse:0.09969136863946915, mae:0.05476314201951027, rse:0.3846065402030945\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:01.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0980609\n",
      "\tspeed: 0.0442s/iter; left time: 986.0843s\n",
      "\titers: 200, epoch: 1 | loss: 0.0871001\n",
      "\tspeed: 0.0176s/iter; left time: 391.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.1031007 Vali Loss: 0.0901211 Test Loss: 0.0987843\n",
      "Validation loss decreased (inf --> 0.090121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0744202\n",
      "\tspeed: 0.0399s/iter; left time: 880.2678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0627046\n",
      "\tspeed: 0.0176s/iter; left time: 387.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0707878 Vali Loss: 0.0750685 Test Loss: 0.0840957\n",
      "Validation loss decreased (0.090121 --> 0.075069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646639\n",
      "\tspeed: 0.0380s/iter; left time: 829.7925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631343\n",
      "\tspeed: 0.0185s/iter; left time: 403.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0642391 Vali Loss: 0.0723593 Test Loss: 0.0822695\n",
      "Validation loss decreased (0.075069 --> 0.072359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610678\n",
      "\tspeed: 0.0388s/iter; left time: 838.9979s\n",
      "\titers: 200, epoch: 4 | loss: 0.0642769\n",
      "\tspeed: 0.0196s/iter; left time: 421.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0623806 Vali Loss: 0.0713594 Test Loss: 0.0812874\n",
      "Validation loss decreased (0.072359 --> 0.071359).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0621786\n",
      "\tspeed: 0.0390s/iter; left time: 835.2215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588774\n",
      "\tspeed: 0.0199s/iter; left time: 424.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 224 | Train Loss: 0.0612256 Vali Loss: 0.0713809 Test Loss: 0.0812414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647122\n",
      "\tspeed: 0.0367s/iter; left time: 776.4822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587326\n",
      "\tspeed: 0.0176s/iter; left time: 371.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0604238 Vali Loss: 0.0708679 Test Loss: 0.0803343\n",
      "Validation loss decreased (0.071359 --> 0.070868).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0619604\n",
      "\tspeed: 0.0379s/iter; left time: 793.8591s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573329\n",
      "\tspeed: 0.0176s/iter; left time: 367.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0597714 Vali Loss: 0.0706334 Test Loss: 0.0803544\n",
      "Validation loss decreased (0.070868 --> 0.070633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0618974\n",
      "\tspeed: 0.0390s/iter; left time: 809.4536s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577334\n",
      "\tspeed: 0.0230s/iter; left time: 475.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0593515 Vali Loss: 0.0705784 Test Loss: 0.0799828\n",
      "Validation loss decreased (0.070633 --> 0.070578).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578773\n",
      "\tspeed: 0.0423s/iter; left time: 866.8690s\n",
      "\titers: 200, epoch: 9 | loss: 0.0587067\n",
      "\tspeed: 0.0201s/iter; left time: 411.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0589615 Vali Loss: 0.0703924 Test Loss: 0.0804243\n",
      "Validation loss decreased (0.070578 --> 0.070392).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590116\n",
      "\tspeed: 0.0401s/iter; left time: 813.8909s\n",
      "\titers: 200, epoch: 10 | loss: 0.0577656\n",
      "\tspeed: 0.0204s/iter; left time: 410.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 224 | Train Loss: 0.0585875 Vali Loss: 0.0701964 Test Loss: 0.0800692\n",
      "Validation loss decreased (0.070392 --> 0.070196).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595273\n",
      "\tspeed: 0.0388s/iter; left time: 777.9013s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568395\n",
      "\tspeed: 0.0190s/iter; left time: 379.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0582978 Vali Loss: 0.0700665 Test Loss: 0.0801848\n",
      "Validation loss decreased (0.070196 --> 0.070066).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0578398\n",
      "\tspeed: 0.0400s/iter; left time: 792.9082s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565718\n",
      "\tspeed: 0.0179s/iter; left time: 352.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0580421 Vali Loss: 0.0702680 Test Loss: 0.0803339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582126\n",
      "\tspeed: 0.0399s/iter; left time: 783.3161s\n",
      "\titers: 200, epoch: 13 | loss: 0.0575784\n",
      "\tspeed: 0.0212s/iter; left time: 414.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0577998 Vali Loss: 0.0704259 Test Loss: 0.0806946\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0567649\n",
      "\tspeed: 0.0372s/iter; left time: 721.7618s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573596\n",
      "\tspeed: 0.0178s/iter; left time: 342.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0575422 Vali Loss: 0.0701961 Test Loss: 0.0797991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537720\n",
      "\tspeed: 0.0373s/iter; left time: 714.3229s\n",
      "\titers: 200, epoch: 15 | loss: 0.0601896\n",
      "\tspeed: 0.0177s/iter; left time: 338.0865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0573678 Vali Loss: 0.0700427 Test Loss: 0.0800929\n",
      "Validation loss decreased (0.070066 --> 0.070043).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0578917\n",
      "\tspeed: 0.0399s/iter; left time: 756.3327s\n",
      "\titers: 200, epoch: 16 | loss: 0.0594120\n",
      "\tspeed: 0.0189s/iter; left time: 355.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0571036 Vali Loss: 0.0701092 Test Loss: 0.0802814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0561508\n",
      "\tspeed: 0.0362s/iter; left time: 677.5379s\n",
      "\titers: 200, epoch: 17 | loss: 0.0588087\n",
      "\tspeed: 0.0178s/iter; left time: 330.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0569985 Vali Loss: 0.0697514 Test Loss: 0.0801798\n",
      "Validation loss decreased (0.070043 --> 0.069751).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570127\n",
      "\tspeed: 0.0401s/iter; left time: 741.0149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0550547\n",
      "\tspeed: 0.0204s/iter; left time: 374.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0568377 Vali Loss: 0.0700514 Test Loss: 0.0800432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0599390\n",
      "\tspeed: 0.0424s/iter; left time: 773.9867s\n",
      "\titers: 200, epoch: 19 | loss: 0.0592506\n",
      "\tspeed: 0.0201s/iter; left time: 365.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0566340 Vali Loss: 0.0700143 Test Loss: 0.0800947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0555497\n",
      "\tspeed: 0.0402s/iter; left time: 725.6980s\n",
      "\titers: 200, epoch: 20 | loss: 0.0594845\n",
      "\tspeed: 0.0177s/iter; left time: 317.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0565479 Vali Loss: 0.0699431 Test Loss: 0.0799722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0595895\n",
      "\tspeed: 0.0426s/iter; left time: 758.6109s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514547\n",
      "\tspeed: 0.0180s/iter; left time: 319.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0564134 Vali Loss: 0.0699077 Test Loss: 0.0799024\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0577438\n",
      "\tspeed: 0.0406s/iter; left time: 713.9933s\n",
      "\titers: 200, epoch: 22 | loss: 0.0570781\n",
      "\tspeed: 0.0180s/iter; left time: 315.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0562344 Vali Loss: 0.0699412 Test Loss: 0.0799161\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0543055\n",
      "\tspeed: 0.0374s/iter; left time: 650.0469s\n",
      "\titers: 200, epoch: 23 | loss: 0.0568372\n",
      "\tspeed: 0.0178s/iter; left time: 307.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0561991 Vali Loss: 0.0698163 Test Loss: 0.0800117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0562022\n",
      "\tspeed: 0.0401s/iter; left time: 687.3905s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531656\n",
      "\tspeed: 0.0196s/iter; left time: 334.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0560687 Vali Loss: 0.0699291 Test Loss: 0.0799469\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552870\n",
      "\tspeed: 0.0384s/iter; left time: 650.0462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0552926\n",
      "\tspeed: 0.0192s/iter; left time: 322.8322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0560483 Vali Loss: 0.0698628 Test Loss: 0.0803341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0539591\n",
      "\tspeed: 0.0398s/iter; left time: 663.8899s\n",
      "\titers: 200, epoch: 26 | loss: 0.0611918\n",
      "\tspeed: 0.0195s/iter; left time: 323.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 224 | Train Loss: 0.0559247 Vali Loss: 0.0697493 Test Loss: 0.0802485\n",
      "Validation loss decreased (0.069751 --> 0.069749).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0552940\n",
      "\tspeed: 0.0390s/iter; left time: 643.2036s\n",
      "\titers: 200, epoch: 27 | loss: 0.0568207\n",
      "\tspeed: 0.0177s/iter; left time: 290.2654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0558538 Vali Loss: 0.0698645 Test Loss: 0.0802962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0553827\n",
      "\tspeed: 0.0366s/iter; left time: 595.1012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0563543\n",
      "\tspeed: 0.0176s/iter; left time: 283.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0558139 Vali Loss: 0.0699737 Test Loss: 0.0799117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0549611\n",
      "\tspeed: 0.0382s/iter; left time: 612.8983s\n",
      "\titers: 200, epoch: 29 | loss: 0.0588496\n",
      "\tspeed: 0.0220s/iter; left time: 350.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0557804 Vali Loss: 0.0698076 Test Loss: 0.0803077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0569736\n",
      "\tspeed: 0.0406s/iter; left time: 642.2532s\n",
      "\titers: 200, epoch: 30 | loss: 0.0523944\n",
      "\tspeed: 0.0191s/iter; left time: 300.5794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0556698 Vali Loss: 0.0699552 Test Loss: 0.0799103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0591903\n",
      "\tspeed: 0.0438s/iter; left time: 682.9421s\n",
      "\titers: 200, epoch: 31 | loss: 0.0563744\n",
      "\tspeed: 0.0195s/iter; left time: 302.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0557028 Vali Loss: 0.0698280 Test Loss: 0.0799427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0564075\n",
      "\tspeed: 0.0367s/iter; left time: 563.8824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564259\n",
      "\tspeed: 0.0178s/iter; left time: 271.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0556475 Vali Loss: 0.0699557 Test Loss: 0.0800001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0571123\n",
      "\tspeed: 0.0371s/iter; left time: 561.7987s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562876\n",
      "\tspeed: 0.0178s/iter; left time: 267.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0555754 Vali Loss: 0.0698408 Test Loss: 0.0799727\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0549147\n",
      "\tspeed: 0.0368s/iter; left time: 549.0334s\n",
      "\titers: 200, epoch: 34 | loss: 0.0569688\n",
      "\tspeed: 0.0176s/iter; left time: 260.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0555628 Vali Loss: 0.0698081 Test Loss: 0.0801774\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539672\n",
      "\tspeed: 0.0394s/iter; left time: 577.9793s\n",
      "\titers: 200, epoch: 35 | loss: 0.0568721\n",
      "\tspeed: 0.0178s/iter; left time: 259.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0555678 Vali Loss: 0.0698511 Test Loss: 0.0800220\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0555374\n",
      "\tspeed: 0.0413s/iter; left time: 596.6173s\n",
      "\titers: 200, epoch: 36 | loss: 0.0540787\n",
      "\tspeed: 0.0202s/iter; left time: 289.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0554807 Vali Loss: 0.0698264 Test Loss: 0.0801089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019129442051053047, rmse:0.13830922544002533, mae:0.08024851232767105, rse:0.5350168347358704\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0993653\n",
      "\tspeed: 0.0221s/iter; left time: 493.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925130\n",
      "\tspeed: 0.0200s/iter; left time: 443.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.1028261 Vali Loss: 0.0896393 Test Loss: 0.0984749\n",
      "Validation loss decreased (inf --> 0.089639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0716707\n",
      "\tspeed: 0.0402s/iter; left time: 888.0405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649474\n",
      "\tspeed: 0.0206s/iter; left time: 452.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 224 | Train Loss: 0.0706721 Vali Loss: 0.0753703 Test Loss: 0.0839644\n",
      "Validation loss decreased (0.089639 --> 0.075370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619266\n",
      "\tspeed: 0.0440s/iter; left time: 960.5970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0610446\n",
      "\tspeed: 0.0202s/iter; left time: 438.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0645758 Vali Loss: 0.0726078 Test Loss: 0.0825484\n",
      "Validation loss decreased (0.075370 --> 0.072608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0586112\n",
      "\tspeed: 0.0396s/iter; left time: 856.5662s\n",
      "\titers: 200, epoch: 4 | loss: 0.0566655\n",
      "\tspeed: 0.0199s/iter; left time: 429.0625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0626355 Vali Loss: 0.0717694 Test Loss: 0.0815929\n",
      "Validation loss decreased (0.072608 --> 0.071769).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629928\n",
      "\tspeed: 0.0434s/iter; left time: 928.5031s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631500\n",
      "\tspeed: 0.0198s/iter; left time: 421.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0614584 Vali Loss: 0.0710907 Test Loss: 0.0806131\n",
      "Validation loss decreased (0.071769 --> 0.071091).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608282\n",
      "\tspeed: 0.0438s/iter; left time: 928.3181s\n",
      "\titers: 200, epoch: 6 | loss: 0.0621219\n",
      "\tspeed: 0.0202s/iter; left time: 425.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0605699 Vali Loss: 0.0708390 Test Loss: 0.0803163\n",
      "Validation loss decreased (0.071091 --> 0.070839).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0545628\n",
      "\tspeed: 0.0392s/iter; left time: 820.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594872\n",
      "\tspeed: 0.0180s/iter; left time: 375.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0599846 Vali Loss: 0.0707349 Test Loss: 0.0810065\n",
      "Validation loss decreased (0.070839 --> 0.070735).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596696\n",
      "\tspeed: 0.0429s/iter; left time: 889.9808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551469\n",
      "\tspeed: 0.0199s/iter; left time: 409.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0594251 Vali Loss: 0.0704187 Test Loss: 0.0808286\n",
      "Validation loss decreased (0.070735 --> 0.070419).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0601396\n",
      "\tspeed: 0.0434s/iter; left time: 889.6753s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632646\n",
      "\tspeed: 0.0244s/iter; left time: 497.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 224 | Train Loss: 0.0589964 Vali Loss: 0.0704514 Test Loss: 0.0805737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0605195\n",
      "\tspeed: 0.0416s/iter; left time: 844.5786s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591787\n",
      "\tspeed: 0.0232s/iter; left time: 467.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0585768 Vali Loss: 0.0702656 Test Loss: 0.0809564\n",
      "Validation loss decreased (0.070419 --> 0.070266).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585001\n",
      "\tspeed: 0.0410s/iter; left time: 822.7208s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562668\n",
      "\tspeed: 0.0186s/iter; left time: 371.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0582614 Vali Loss: 0.0702181 Test Loss: 0.0812004\n",
      "Validation loss decreased (0.070266 --> 0.070218).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0563077\n",
      "\tspeed: 0.0414s/iter; left time: 821.1961s\n",
      "\titers: 200, epoch: 12 | loss: 0.0616315\n",
      "\tspeed: 0.0200s/iter; left time: 395.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0579842 Vali Loss: 0.0700841 Test Loss: 0.0812889\n",
      "Validation loss decreased (0.070218 --> 0.070084).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0610500\n",
      "\tspeed: 0.0430s/iter; left time: 843.5268s\n",
      "\titers: 200, epoch: 13 | loss: 0.0572273\n",
      "\tspeed: 0.0196s/iter; left time: 381.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0576614 Vali Loss: 0.0702207 Test Loss: 0.0815973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575464\n",
      "\tspeed: 0.0443s/iter; left time: 859.2950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597506\n",
      "\tspeed: 0.0186s/iter; left time: 359.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0574103 Vali Loss: 0.0701746 Test Loss: 0.0815515\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0539393\n",
      "\tspeed: 0.0410s/iter; left time: 785.1048s\n",
      "\titers: 200, epoch: 15 | loss: 0.0575244\n",
      "\tspeed: 0.0180s/iter; left time: 343.9889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0571507 Vali Loss: 0.0700377 Test Loss: 0.0809218\n",
      "Validation loss decreased (0.070084 --> 0.070038).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0552823\n",
      "\tspeed: 0.0431s/iter; left time: 816.5003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0567672\n",
      "\tspeed: 0.0242s/iter; left time: 456.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0569635 Vali Loss: 0.0699133 Test Loss: 0.0814106\n",
      "Validation loss decreased (0.070038 --> 0.069913).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0533414\n",
      "\tspeed: 0.0426s/iter; left time: 796.9191s\n",
      "\titers: 200, epoch: 17 | loss: 0.0565612\n",
      "\tspeed: 0.0203s/iter; left time: 377.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0567306 Vali Loss: 0.0700455 Test Loss: 0.0815984\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608345\n",
      "\tspeed: 0.0403s/iter; left time: 745.6117s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592519\n",
      "\tspeed: 0.0183s/iter; left time: 335.8144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0566090 Vali Loss: 0.0699562 Test Loss: 0.0814214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0590397\n",
      "\tspeed: 0.0403s/iter; left time: 735.9679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541783\n",
      "\tspeed: 0.0202s/iter; left time: 367.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0564276 Vali Loss: 0.0701004 Test Loss: 0.0813950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572432\n",
      "\tspeed: 0.0412s/iter; left time: 742.9460s\n",
      "\titers: 200, epoch: 20 | loss: 0.0551385\n",
      "\tspeed: 0.0200s/iter; left time: 358.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0562702 Vali Loss: 0.0701160 Test Loss: 0.0818849\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0536732\n",
      "\tspeed: 0.0392s/iter; left time: 698.7143s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556528\n",
      "\tspeed: 0.0213s/iter; left time: 378.0601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0561357 Vali Loss: 0.0701280 Test Loss: 0.0817430\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0569166\n",
      "\tspeed: 0.0418s/iter; left time: 734.7146s\n",
      "\titers: 200, epoch: 22 | loss: 0.0534606\n",
      "\tspeed: 0.0236s/iter; left time: 413.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0559808 Vali Loss: 0.0702114 Test Loss: 0.0819262\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0560534\n",
      "\tspeed: 0.0420s/iter; left time: 729.4056s\n",
      "\titers: 200, epoch: 23 | loss: 0.0574485\n",
      "\tspeed: 0.0224s/iter; left time: 386.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0559322 Vali Loss: 0.0700866 Test Loss: 0.0819694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0585243\n",
      "\tspeed: 0.0422s/iter; left time: 724.4744s\n",
      "\titers: 200, epoch: 24 | loss: 0.0549269\n",
      "\tspeed: 0.0235s/iter; left time: 400.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0557595 Vali Loss: 0.0701298 Test Loss: 0.0818227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0532516\n",
      "\tspeed: 0.0463s/iter; left time: 783.6475s\n",
      "\titers: 200, epoch: 25 | loss: 0.0586018\n",
      "\tspeed: 0.0249s/iter; left time: 419.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0557496 Vali Loss: 0.0702347 Test Loss: 0.0820146\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552508\n",
      "\tspeed: 0.0463s/iter; left time: 772.7935s\n",
      "\titers: 200, epoch: 26 | loss: 0.0518143\n",
      "\tspeed: 0.0206s/iter; left time: 342.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0555888 Vali Loss: 0.0702477 Test Loss: 0.0821850\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019507648423314095, rmse:0.13966979086399078, mae:0.08141053467988968, rse:0.5402798652648926\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:24.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1048215\n",
      "\tspeed: 0.0448s/iter; left time: 993.6942s\n",
      "\titers: 200, epoch: 1 | loss: 0.0905720\n",
      "\tspeed: 0.0178s/iter; left time: 393.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.1048050 Vali Loss: 0.0926501 Test Loss: 0.1004419\n",
      "Validation loss decreased (inf --> 0.092650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0787801\n",
      "\tspeed: 0.0392s/iter; left time: 860.8228s\n",
      "\titers: 200, epoch: 2 | loss: 0.0704006\n",
      "\tspeed: 0.0178s/iter; left time: 390.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0745573 Vali Loss: 0.0786099 Test Loss: 0.0878751\n",
      "Validation loss decreased (0.092650 --> 0.078610).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726460\n",
      "\tspeed: 0.0391s/iter; left time: 849.8043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645619\n",
      "\tspeed: 0.0178s/iter; left time: 386.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0679619 Vali Loss: 0.0757840 Test Loss: 0.0871083\n",
      "Validation loss decreased (0.078610 --> 0.075784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659405\n",
      "\tspeed: 0.0392s/iter; left time: 844.1832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0691877\n",
      "\tspeed: 0.0180s/iter; left time: 385.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0661932 Vali Loss: 0.0753940 Test Loss: 0.0867535\n",
      "Validation loss decreased (0.075784 --> 0.075394).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0673685\n",
      "\tspeed: 0.0386s/iter; left time: 823.0725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653306\n",
      "\tspeed: 0.0184s/iter; left time: 390.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0651771 Vali Loss: 0.0749387 Test Loss: 0.0866767\n",
      "Validation loss decreased (0.075394 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0621401\n",
      "\tspeed: 0.0391s/iter; left time: 825.2142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653071\n",
      "\tspeed: 0.0183s/iter; left time: 385.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0644035 Vali Loss: 0.0745415 Test Loss: 0.0861986\n",
      "Validation loss decreased (0.074939 --> 0.074541).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0668753\n",
      "\tspeed: 0.0396s/iter; left time: 826.2922s\n",
      "\titers: 200, epoch: 7 | loss: 0.0647811\n",
      "\tspeed: 0.0181s/iter; left time: 376.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0638201 Vali Loss: 0.0746210 Test Loss: 0.0858707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0590196\n",
      "\tspeed: 0.0405s/iter; left time: 835.0479s\n",
      "\titers: 200, epoch: 8 | loss: 0.0675284\n",
      "\tspeed: 0.0182s/iter; left time: 374.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0633939 Vali Loss: 0.0744509 Test Loss: 0.0864062\n",
      "Validation loss decreased (0.074541 --> 0.074451).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666170\n",
      "\tspeed: 0.0394s/iter; left time: 805.2458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584317\n",
      "\tspeed: 0.0178s/iter; left time: 360.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0629750 Vali Loss: 0.0741344 Test Loss: 0.0858306\n",
      "Validation loss decreased (0.074451 --> 0.074134).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615673\n",
      "\tspeed: 0.0384s/iter; left time: 775.9894s\n",
      "\titers: 200, epoch: 10 | loss: 0.0612158\n",
      "\tspeed: 0.0178s/iter; left time: 357.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.0626131 Vali Loss: 0.0743963 Test Loss: 0.0868935\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669771\n",
      "\tspeed: 0.0389s/iter; left time: 776.3254s\n",
      "\titers: 200, epoch: 11 | loss: 0.0583333\n",
      "\tspeed: 0.0182s/iter; left time: 360.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.0622680 Vali Loss: 0.0740912 Test Loss: 0.0864191\n",
      "Validation loss decreased (0.074134 --> 0.074091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0600857\n",
      "\tspeed: 0.0398s/iter; left time: 785.8133s\n",
      "\titers: 200, epoch: 12 | loss: 0.0624289\n",
      "\tspeed: 0.0182s/iter; left time: 357.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0620072 Vali Loss: 0.0738088 Test Loss: 0.0868813\n",
      "Validation loss decreased (0.074091 --> 0.073809).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0633508\n",
      "\tspeed: 0.0382s/iter; left time: 746.2036s\n",
      "\titers: 200, epoch: 13 | loss: 0.0622426\n",
      "\tspeed: 0.0177s/iter; left time: 344.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0617034 Vali Loss: 0.0738194 Test Loss: 0.0859601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0624652\n",
      "\tspeed: 0.0432s/iter; left time: 833.1308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0640134\n",
      "\tspeed: 0.0223s/iter; left time: 428.7406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0614224 Vali Loss: 0.0735637 Test Loss: 0.0866766\n",
      "Validation loss decreased (0.073809 --> 0.073564).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0592811\n",
      "\tspeed: 0.0412s/iter; left time: 786.3647s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659775\n",
      "\tspeed: 0.0198s/iter; left time: 375.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0612476 Vali Loss: 0.0735167 Test Loss: 0.0868006\n",
      "Validation loss decreased (0.073564 --> 0.073517).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0644561\n",
      "\tspeed: 0.0412s/iter; left time: 777.3279s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619274\n",
      "\tspeed: 0.0179s/iter; left time: 336.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0610197 Vali Loss: 0.0734734 Test Loss: 0.0862646\n",
      "Validation loss decreased (0.073517 --> 0.073473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604587\n",
      "\tspeed: 0.0385s/iter; left time: 717.5171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0619207\n",
      "\tspeed: 0.0182s/iter; left time: 337.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0608512 Vali Loss: 0.0734382 Test Loss: 0.0864064\n",
      "Validation loss decreased (0.073473 --> 0.073438).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621410\n",
      "\tspeed: 0.0444s/iter; left time: 816.7679s\n",
      "\titers: 200, epoch: 18 | loss: 0.0610293\n",
      "\tspeed: 0.0209s/iter; left time: 382.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 223 | Train Loss: 0.0606406 Vali Loss: 0.0735055 Test Loss: 0.0865836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0594858\n",
      "\tspeed: 0.0395s/iter; left time: 717.9466s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603400\n",
      "\tspeed: 0.0225s/iter; left time: 407.7429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0604943 Vali Loss: 0.0733934 Test Loss: 0.0866218\n",
      "Validation loss decreased (0.073438 --> 0.073393).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0621189\n",
      "\tspeed: 0.0405s/iter; left time: 726.9494s\n",
      "\titers: 200, epoch: 20 | loss: 0.0579614\n",
      "\tspeed: 0.0179s/iter; left time: 320.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0603450 Vali Loss: 0.0734274 Test Loss: 0.0866431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0576071\n",
      "\tspeed: 0.0397s/iter; left time: 705.1230s\n",
      "\titers: 200, epoch: 21 | loss: 0.0587716\n",
      "\tspeed: 0.0182s/iter; left time: 320.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0602134 Vali Loss: 0.0735609 Test Loss: 0.0867124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0592390\n",
      "\tspeed: 0.0411s/iter; left time: 719.6329s\n",
      "\titers: 200, epoch: 22 | loss: 0.0672747\n",
      "\tspeed: 0.0205s/iter; left time: 357.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 223 | Train Loss: 0.0601358 Vali Loss: 0.0734848 Test Loss: 0.0864877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0589457\n",
      "\tspeed: 0.0420s/iter; left time: 727.1040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0600802\n",
      "\tspeed: 0.0195s/iter; left time: 334.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0600169 Vali Loss: 0.0735971 Test Loss: 0.0867336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0622105\n",
      "\tspeed: 0.0390s/iter; left time: 665.8311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0587972\n",
      "\tspeed: 0.0185s/iter; left time: 314.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0599399 Vali Loss: 0.0733272 Test Loss: 0.0868346\n",
      "Validation loss decreased (0.073393 --> 0.073327).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0618487\n",
      "\tspeed: 0.0408s/iter; left time: 686.9191s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623286\n",
      "\tspeed: 0.0199s/iter; left time: 332.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0598832 Vali Loss: 0.0733698 Test Loss: 0.0870481\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0628185\n",
      "\tspeed: 0.0403s/iter; left time: 669.1997s\n",
      "\titers: 200, epoch: 26 | loss: 0.0600777\n",
      "\tspeed: 0.0178s/iter; left time: 294.5353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0597476 Vali Loss: 0.0735480 Test Loss: 0.0870731\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584035\n",
      "\tspeed: 0.0386s/iter; left time: 633.3759s\n",
      "\titers: 200, epoch: 27 | loss: 0.0596758\n",
      "\tspeed: 0.0178s/iter; left time: 290.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0597152 Vali Loss: 0.0735673 Test Loss: 0.0869513\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0575937\n",
      "\tspeed: 0.0411s/iter; left time: 664.7704s\n",
      "\titers: 200, epoch: 28 | loss: 0.0598191\n",
      "\tspeed: 0.0194s/iter; left time: 311.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0596151 Vali Loss: 0.0735890 Test Loss: 0.0869191\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602850\n",
      "\tspeed: 0.0385s/iter; left time: 614.2782s\n",
      "\titers: 200, epoch: 29 | loss: 0.0603580\n",
      "\tspeed: 0.0199s/iter; left time: 315.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 223 | Train Loss: 0.0595701 Vali Loss: 0.0735271 Test Loss: 0.0868389\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0609483\n",
      "\tspeed: 0.0398s/iter; left time: 625.4291s\n",
      "\titers: 200, epoch: 30 | loss: 0.0605431\n",
      "\tspeed: 0.0178s/iter; left time: 277.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0595073 Vali Loss: 0.0735774 Test Loss: 0.0868500\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565855\n",
      "\tspeed: 0.0380s/iter; left time: 588.8619s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568368\n",
      "\tspeed: 0.0178s/iter; left time: 273.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0594662 Vali Loss: 0.0736190 Test Loss: 0.0867959\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585387\n",
      "\tspeed: 0.0384s/iter; left time: 586.9124s\n",
      "\titers: 200, epoch: 32 | loss: 0.0621870\n",
      "\tspeed: 0.0179s/iter; left time: 271.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0594207 Vali Loss: 0.0734954 Test Loss: 0.0867695\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0560987\n",
      "\tspeed: 0.0403s/iter; left time: 607.2936s\n",
      "\titers: 200, epoch: 33 | loss: 0.0594956\n",
      "\tspeed: 0.0179s/iter; left time: 267.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0594061 Vali Loss: 0.0736040 Test Loss: 0.0867877\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0592257\n",
      "\tspeed: 0.0398s/iter; left time: 590.9892s\n",
      "\titers: 200, epoch: 34 | loss: 0.0612799\n",
      "\tspeed: 0.0178s/iter; left time: 262.3133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.0593490 Vali Loss: 0.0734889 Test Loss: 0.0869637\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021609371528029442, rmse:0.1470012664794922, mae:0.08683455735445023, rse:0.5693498253822327\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1029223\n",
      "\tspeed: 0.0243s/iter; left time: 539.9811s\n",
      "\titers: 200, epoch: 1 | loss: 0.0873014\n",
      "\tspeed: 0.0203s/iter; left time: 449.2947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 223 | Train Loss: 0.1060672 Vali Loss: 0.0924755 Test Loss: 0.1004355\n",
      "Validation loss decreased (inf --> 0.092476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0753753\n",
      "\tspeed: 0.0444s/iter; left time: 975.9962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723152\n",
      "\tspeed: 0.0240s/iter; left time: 525.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0746971 Vali Loss: 0.0789733 Test Loss: 0.0883853\n",
      "Validation loss decreased (0.092476 --> 0.078973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749349\n",
      "\tspeed: 0.0390s/iter; left time: 849.2280s\n",
      "\titers: 200, epoch: 3 | loss: 0.0635487\n",
      "\tspeed: 0.0181s/iter; left time: 391.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 223 | Train Loss: 0.0682782 Vali Loss: 0.0764451 Test Loss: 0.0874010\n",
      "Validation loss decreased (0.078973 --> 0.076445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650547\n",
      "\tspeed: 0.0431s/iter; left time: 927.6328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0675071\n",
      "\tspeed: 0.0189s/iter; left time: 404.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0665174 Vali Loss: 0.0751456 Test Loss: 0.0865133\n",
      "Validation loss decreased (0.076445 --> 0.075146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633389\n",
      "\tspeed: 0.0399s/iter; left time: 850.2645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628508\n",
      "\tspeed: 0.0180s/iter; left time: 380.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0653938 Vali Loss: 0.0750249 Test Loss: 0.0866540\n",
      "Validation loss decreased (0.075146 --> 0.075025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610570\n",
      "\tspeed: 0.0435s/iter; left time: 916.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0691948\n",
      "\tspeed: 0.0227s/iter; left time: 476.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0645714 Vali Loss: 0.0748224 Test Loss: 0.0866774\n",
      "Validation loss decreased (0.075025 --> 0.074822).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0635364\n",
      "\tspeed: 0.0438s/iter; left time: 913.4307s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676383\n",
      "\tspeed: 0.0196s/iter; left time: 405.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 223 | Train Loss: 0.0640450 Vali Loss: 0.0747084 Test Loss: 0.0860682\n",
      "Validation loss decreased (0.074822 --> 0.074708).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0642655\n",
      "\tspeed: 0.0433s/iter; left time: 894.1643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633054\n",
      "\tspeed: 0.0209s/iter; left time: 430.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0635069 Vali Loss: 0.0743306 Test Loss: 0.0875940\n",
      "Validation loss decreased (0.074708 --> 0.074331).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0672177\n",
      "\tspeed: 0.0429s/iter; left time: 874.8904s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657890\n",
      "\tspeed: 0.0209s/iter; left time: 424.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 223 | Train Loss: 0.0630452 Vali Loss: 0.0741678 Test Loss: 0.0868630\n",
      "Validation loss decreased (0.074331 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632034\n",
      "\tspeed: 0.0434s/iter; left time: 876.3151s\n",
      "\titers: 200, epoch: 10 | loss: 0.0645544\n",
      "\tspeed: 0.0202s/iter; left time: 404.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 223 | Train Loss: 0.0627409 Vali Loss: 0.0743513 Test Loss: 0.0880571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0636334\n",
      "\tspeed: 0.0404s/iter; left time: 806.8377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602807\n",
      "\tspeed: 0.0178s/iter; left time: 353.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0623453 Vali Loss: 0.0742074 Test Loss: 0.0878647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583318\n",
      "\tspeed: 0.0410s/iter; left time: 808.9365s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650040\n",
      "\tspeed: 0.0179s/iter; left time: 352.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0620972 Vali Loss: 0.0737038 Test Loss: 0.0867297\n",
      "Validation loss decreased (0.074168 --> 0.073704).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0613920\n",
      "\tspeed: 0.0414s/iter; left time: 808.6399s\n",
      "\titers: 200, epoch: 13 | loss: 0.0611318\n",
      "\tspeed: 0.0182s/iter; left time: 353.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0618523 Vali Loss: 0.0738235 Test Loss: 0.0875536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0610238\n",
      "\tspeed: 0.0386s/iter; left time: 744.5537s\n",
      "\titers: 200, epoch: 14 | loss: 0.0601860\n",
      "\tspeed: 0.0179s/iter; left time: 343.8556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0615380 Vali Loss: 0.0738372 Test Loss: 0.0877525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598381\n",
      "\tspeed: 0.0387s/iter; left time: 738.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0587940\n",
      "\tspeed: 0.0178s/iter; left time: 338.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0612895 Vali Loss: 0.0739167 Test Loss: 0.0872995\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566209\n",
      "\tspeed: 0.0421s/iter; left time: 794.7425s\n",
      "\titers: 200, epoch: 16 | loss: 0.0571298\n",
      "\tspeed: 0.0183s/iter; left time: 343.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 223 | Train Loss: 0.0611391 Vali Loss: 0.0740395 Test Loss: 0.0877071\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0624488\n",
      "\tspeed: 0.0436s/iter; left time: 813.1598s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577584\n",
      "\tspeed: 0.0198s/iter; left time: 367.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0609111 Vali Loss: 0.0737153 Test Loss: 0.0876156\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0645408\n",
      "\tspeed: 0.0412s/iter; left time: 758.7901s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614708\n",
      "\tspeed: 0.0182s/iter; left time: 332.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0607212 Vali Loss: 0.0740565 Test Loss: 0.0879836\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0585145\n",
      "\tspeed: 0.0441s/iter; left time: 802.3411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0603509\n",
      "\tspeed: 0.0209s/iter; left time: 378.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0606192 Vali Loss: 0.0737144 Test Loss: 0.0875244\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0605584\n",
      "\tspeed: 0.0389s/iter; left time: 698.6056s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584688\n",
      "\tspeed: 0.0180s/iter; left time: 321.6657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0604933 Vali Loss: 0.0737341 Test Loss: 0.0881607\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0649967\n",
      "\tspeed: 0.0399s/iter; left time: 707.6438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591727\n",
      "\tspeed: 0.0178s/iter; left time: 314.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 223 | Train Loss: 0.0603355 Vali Loss: 0.0738130 Test Loss: 0.0877827\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593023\n",
      "\tspeed: 0.0445s/iter; left time: 779.7140s\n",
      "\titers: 200, epoch: 22 | loss: 0.0619041\n",
      "\tspeed: 0.0183s/iter; left time: 319.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 223 | Train Loss: 0.0601923 Vali Loss: 0.0737966 Test Loss: 0.0876334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021043021231889725, rmse:0.1450621336698532, mae:0.08672972023487091, rse:0.5618393421173096\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:46.06s\n",
      "Intermediate time for FR: 00h:23m:12.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1379552\n",
      "\tspeed: 0.0457s/iter; left time: 1019.8141s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160477\n",
      "\tspeed: 0.0178s/iter; left time: 394.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 224 | Train Loss: 0.1433041 Vali Loss: 0.0977655 Test Loss: 0.1001861\n",
      "Validation loss decreased (inf --> 0.097766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0780573\n",
      "\tspeed: 0.0397s/iter; left time: 877.4531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670697\n",
      "\tspeed: 0.0178s/iter; left time: 390.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0783016 Vali Loss: 0.0630192 Test Loss: 0.0662496\n",
      "Validation loss decreased (0.097766 --> 0.063019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0623454\n",
      "\tspeed: 0.0369s/iter; left time: 805.5581s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655507\n",
      "\tspeed: 0.0175s/iter; left time: 381.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0659248 Vali Loss: 0.0605475 Test Loss: 0.0632674\n",
      "Validation loss decreased (0.063019 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630882\n",
      "\tspeed: 0.0372s/iter; left time: 805.2769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0590766\n",
      "\tspeed: 0.0177s/iter; left time: 380.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0628566 Vali Loss: 0.0584909 Test Loss: 0.0608319\n",
      "Validation loss decreased (0.060548 --> 0.058491).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0591956\n",
      "\tspeed: 0.0442s/iter; left time: 946.6197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0613977\n",
      "\tspeed: 0.0240s/iter; left time: 510.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0611276 Vali Loss: 0.0580106 Test Loss: 0.0599504\n",
      "Validation loss decreased (0.058491 --> 0.058011).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577363\n",
      "\tspeed: 0.0466s/iter; left time: 987.1521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0550658\n",
      "\tspeed: 0.0258s/iter; left time: 543.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 224 | Train Loss: 0.0599828 Vali Loss: 0.0571707 Test Loss: 0.0595299\n",
      "Validation loss decreased (0.058011 --> 0.057171).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0601596\n",
      "\tspeed: 0.0470s/iter; left time: 985.0367s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558117\n",
      "\tspeed: 0.0244s/iter; left time: 508.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0591725 Vali Loss: 0.0566996 Test Loss: 0.0588407\n",
      "Validation loss decreased (0.057171 --> 0.056700).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0567679\n",
      "\tspeed: 0.0453s/iter; left time: 938.7148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577220\n",
      "\tspeed: 0.0207s/iter; left time: 427.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0585837 Vali Loss: 0.0563851 Test Loss: 0.0587719\n",
      "Validation loss decreased (0.056700 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0536918\n",
      "\tspeed: 0.0433s/iter; left time: 888.3929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0593248\n",
      "\tspeed: 0.0202s/iter; left time: 412.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0579274 Vali Loss: 0.0560959 Test Loss: 0.0584001\n",
      "Validation loss decreased (0.056385 --> 0.056096).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0576015\n",
      "\tspeed: 0.0392s/iter; left time: 795.0024s\n",
      "\titers: 200, epoch: 10 | loss: 0.0572641\n",
      "\tspeed: 0.0197s/iter; left time: 397.1217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0574487 Vali Loss: 0.0561246 Test Loss: 0.0586067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603743\n",
      "\tspeed: 0.0446s/iter; left time: 894.4247s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529461\n",
      "\tspeed: 0.0243s/iter; left time: 485.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0571570 Vali Loss: 0.0558561 Test Loss: 0.0580777\n",
      "Validation loss decreased (0.056096 --> 0.055856).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538307\n",
      "\tspeed: 0.0408s/iter; left time: 809.1254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0569894\n",
      "\tspeed: 0.0203s/iter; left time: 401.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0567255 Vali Loss: 0.0555736 Test Loss: 0.0576931\n",
      "Validation loss decreased (0.055856 --> 0.055574).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559114\n",
      "\tspeed: 0.0453s/iter; left time: 888.4679s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570156\n",
      "\tspeed: 0.0183s/iter; left time: 357.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0564412 Vali Loss: 0.0555875 Test Loss: 0.0576721\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608026\n",
      "\tspeed: 0.0409s/iter; left time: 793.3031s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548942\n",
      "\tspeed: 0.0202s/iter; left time: 389.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 224 | Train Loss: 0.0562439 Vali Loss: 0.0556266 Test Loss: 0.0576045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0568721\n",
      "\tspeed: 0.0432s/iter; left time: 828.8342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553573\n",
      "\tspeed: 0.0237s/iter; left time: 452.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0559618 Vali Loss: 0.0554153 Test Loss: 0.0574718\n",
      "Validation loss decreased (0.055574 --> 0.055415).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0573713\n",
      "\tspeed: 0.0398s/iter; left time: 754.3022s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561678\n",
      "\tspeed: 0.0175s/iter; left time: 329.9052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0558215 Vali Loss: 0.0551744 Test Loss: 0.0573095\n",
      "Validation loss decreased (0.055415 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589329\n",
      "\tspeed: 0.0376s/iter; left time: 703.8887s\n",
      "\titers: 200, epoch: 17 | loss: 0.0574918\n",
      "\tspeed: 0.0179s/iter; left time: 332.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0556505 Vali Loss: 0.0550482 Test Loss: 0.0572504\n",
      "Validation loss decreased (0.055174 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0534935\n",
      "\tspeed: 0.0414s/iter; left time: 765.8245s\n",
      "\titers: 200, epoch: 18 | loss: 0.0574331\n",
      "\tspeed: 0.0198s/iter; left time: 364.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0554857 Vali Loss: 0.0549875 Test Loss: 0.0572133\n",
      "Validation loss decreased (0.055048 --> 0.054988).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556992\n",
      "\tspeed: 0.0385s/iter; left time: 704.2454s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604655\n",
      "\tspeed: 0.0240s/iter; left time: 435.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0553156 Vali Loss: 0.0548461 Test Loss: 0.0571244\n",
      "Validation loss decreased (0.054988 --> 0.054846).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0546956\n",
      "\tspeed: 0.0414s/iter; left time: 746.4803s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543233\n",
      "\tspeed: 0.0245s/iter; left time: 440.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0551500 Vali Loss: 0.0548050 Test Loss: 0.0570001\n",
      "Validation loss decreased (0.054846 --> 0.054805).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0572998\n",
      "\tspeed: 0.0456s/iter; left time: 812.4846s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540240\n",
      "\tspeed: 0.0193s/iter; left time: 341.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0551207 Vali Loss: 0.0548231 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534088\n",
      "\tspeed: 0.0378s/iter; left time: 664.9020s\n",
      "\titers: 200, epoch: 22 | loss: 0.0502284\n",
      "\tspeed: 0.0173s/iter; left time: 302.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0549312 Vali Loss: 0.0548708 Test Loss: 0.0570204\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0540605\n",
      "\tspeed: 0.0385s/iter; left time: 668.9097s\n",
      "\titers: 200, epoch: 23 | loss: 0.0507261\n",
      "\tspeed: 0.0178s/iter; left time: 306.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0548571 Vali Loss: 0.0547824 Test Loss: 0.0569985\n",
      "Validation loss decreased (0.054805 --> 0.054782).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0583674\n",
      "\tspeed: 0.0442s/iter; left time: 758.5964s\n",
      "\titers: 200, epoch: 24 | loss: 0.0544730\n",
      "\tspeed: 0.0176s/iter; left time: 299.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0547987 Vali Loss: 0.0546288 Test Loss: 0.0570315\n",
      "Validation loss decreased (0.054782 --> 0.054629).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0508277\n",
      "\tspeed: 0.0373s/iter; left time: 631.7015s\n",
      "\titers: 200, epoch: 25 | loss: 0.0581925\n",
      "\tspeed: 0.0194s/iter; left time: 327.1373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0547711 Vali Loss: 0.0544805 Test Loss: 0.0568517\n",
      "Validation loss decreased (0.054629 --> 0.054480).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0556801\n",
      "\tspeed: 0.0391s/iter; left time: 653.4126s\n",
      "\titers: 200, epoch: 26 | loss: 0.0554455\n",
      "\tspeed: 0.0195s/iter; left time: 323.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 224 | Train Loss: 0.0546281 Vali Loss: 0.0546029 Test Loss: 0.0568632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572915\n",
      "\tspeed: 0.0379s/iter; left time: 623.7133s\n",
      "\titers: 200, epoch: 27 | loss: 0.0576790\n",
      "\tspeed: 0.0253s/iter; left time: 414.7405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0545952 Vali Loss: 0.0546437 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0563810\n",
      "\tspeed: 0.0466s/iter; left time: 756.6862s\n",
      "\titers: 200, epoch: 28 | loss: 0.0515816\n",
      "\tspeed: 0.0244s/iter; left time: 393.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0545041 Vali Loss: 0.0544355 Test Loss: 0.0567258\n",
      "Validation loss decreased (0.054480 --> 0.054436).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0575383\n",
      "\tspeed: 0.0415s/iter; left time: 665.5287s\n",
      "\titers: 200, epoch: 29 | loss: 0.0517639\n",
      "\tspeed: 0.0202s/iter; left time: 321.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 224 | Train Loss: 0.0544492 Vali Loss: 0.0544463 Test Loss: 0.0569202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0554202\n",
      "\tspeed: 0.0422s/iter; left time: 667.1427s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573169\n",
      "\tspeed: 0.0204s/iter; left time: 320.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 224 | Train Loss: 0.0544512 Vali Loss: 0.0544945 Test Loss: 0.0567682\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525765\n",
      "\tspeed: 0.0452s/iter; left time: 704.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0568761\n",
      "\tspeed: 0.0243s/iter; left time: 375.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0543604 Vali Loss: 0.0544442 Test Loss: 0.0567680\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0544155\n",
      "\tspeed: 0.0463s/iter; left time: 711.2055s\n",
      "\titers: 200, epoch: 32 | loss: 0.0564592\n",
      "\tspeed: 0.0197s/iter; left time: 301.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0543330 Vali Loss: 0.0544301 Test Loss: 0.0567419\n",
      "Validation loss decreased (0.054436 --> 0.054430).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0549597\n",
      "\tspeed: 0.0429s/iter; left time: 648.7709s\n",
      "\titers: 200, epoch: 33 | loss: 0.0541910\n",
      "\tspeed: 0.0181s/iter; left time: 272.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0543469 Vali Loss: 0.0543835 Test Loss: 0.0567440\n",
      "Validation loss decreased (0.054430 --> 0.054384).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0571987\n",
      "\tspeed: 0.0416s/iter; left time: 620.5499s\n",
      "\titers: 200, epoch: 34 | loss: 0.0567482\n",
      "\tspeed: 0.0201s/iter; left time: 297.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0543108 Vali Loss: 0.0543652 Test Loss: 0.0567222\n",
      "Validation loss decreased (0.054384 --> 0.054365).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535260\n",
      "\tspeed: 0.0423s/iter; left time: 621.8226s\n",
      "\titers: 200, epoch: 35 | loss: 0.0561866\n",
      "\tspeed: 0.0193s/iter; left time: 281.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0542972 Vali Loss: 0.0544265 Test Loss: 0.0567667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0549961\n",
      "\tspeed: 0.0410s/iter; left time: 593.5670s\n",
      "\titers: 200, epoch: 36 | loss: 0.0541536\n",
      "\tspeed: 0.0192s/iter; left time: 275.6673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0542406 Vali Loss: 0.0544166 Test Loss: 0.0566596\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532916\n",
      "\tspeed: 0.0400s/iter; left time: 569.6183s\n",
      "\titers: 200, epoch: 37 | loss: 0.0511241\n",
      "\tspeed: 0.0198s/iter; left time: 280.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 224 | Train Loss: 0.0542641 Vali Loss: 0.0543706 Test Loss: 0.0566760\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0539109\n",
      "\tspeed: 0.0399s/iter; left time: 558.4617s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564077\n",
      "\tspeed: 0.0205s/iter; left time: 285.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 224 | Train Loss: 0.0541845 Vali Loss: 0.0543355 Test Loss: 0.0566975\n",
      "Validation loss decreased (0.054365 --> 0.054336).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0503076\n",
      "\tspeed: 0.0409s/iter; left time: 563.8564s\n",
      "\titers: 200, epoch: 39 | loss: 0.0562198\n",
      "\tspeed: 0.0200s/iter; left time: 273.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0541782 Vali Loss: 0.0543724 Test Loss: 0.0566402\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0552053\n",
      "\tspeed: 0.0407s/iter; left time: 552.2094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0516493\n",
      "\tspeed: 0.0199s/iter; left time: 267.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0543906 Test Loss: 0.0566315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0556425\n",
      "\tspeed: 0.0412s/iter; left time: 550.0056s\n",
      "\titers: 200, epoch: 41 | loss: 0.0509712\n",
      "\tspeed: 0.0201s/iter; left time: 266.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 224 | Train Loss: 0.0541427 Vali Loss: 0.0543536 Test Loss: 0.0566362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523108\n",
      "\tspeed: 0.0422s/iter; left time: 553.7186s\n",
      "\titers: 200, epoch: 42 | loss: 0.0576750\n",
      "\tspeed: 0.0195s/iter; left time: 253.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0541833 Vali Loss: 0.0542894 Test Loss: 0.0566669\n",
      "Validation loss decreased (0.054336 --> 0.054289).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0529656\n",
      "\tspeed: 0.0435s/iter; left time: 561.1621s\n",
      "\titers: 200, epoch: 43 | loss: 0.0502761\n",
      "\tspeed: 0.0229s/iter; left time: 292.3420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0541143 Vali Loss: 0.0543694 Test Loss: 0.0566259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537367\n",
      "\tspeed: 0.0447s/iter; left time: 566.3745s\n",
      "\titers: 200, epoch: 44 | loss: 0.0559055\n",
      "\tspeed: 0.0200s/iter; left time: 251.4707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0541310 Vali Loss: 0.0542568 Test Loss: 0.0566117\n",
      "Validation loss decreased (0.054289 --> 0.054257).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0569029\n",
      "\tspeed: 0.0405s/iter; left time: 504.4566s\n",
      "\titers: 200, epoch: 45 | loss: 0.0579741\n",
      "\tspeed: 0.0183s/iter; left time: 225.8235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0541451 Vali Loss: 0.0543393 Test Loss: 0.0566353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0510111\n",
      "\tspeed: 0.0435s/iter; left time: 531.5669s\n",
      "\titers: 200, epoch: 46 | loss: 0.0570540\n",
      "\tspeed: 0.0194s/iter; left time: 235.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0543384 Test Loss: 0.0565993\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0603271\n",
      "\tspeed: 0.0408s/iter; left time: 489.8614s\n",
      "\titers: 200, epoch: 47 | loss: 0.0489362\n",
      "\tspeed: 0.0221s/iter; left time: 262.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 224 | Train Loss: 0.0541158 Vali Loss: 0.0542949 Test Loss: 0.0566084\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0562014\n",
      "\tspeed: 0.0430s/iter; left time: 506.5203s\n",
      "\titers: 200, epoch: 48 | loss: 0.0527634\n",
      "\tspeed: 0.0175s/iter; left time: 204.8135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0541052 Vali Loss: 0.0542426 Test Loss: 0.0566221\n",
      "Validation loss decreased (0.054257 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0550343\n",
      "\tspeed: 0.0405s/iter; left time: 468.1700s\n",
      "\titers: 200, epoch: 49 | loss: 0.0519099\n",
      "\tspeed: 0.0199s/iter; left time: 227.8234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 224 | Train Loss: 0.0540786 Vali Loss: 0.0543246 Test Loss: 0.0566017\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0535444\n",
      "\tspeed: 0.0454s/iter; left time: 514.6661s\n",
      "\titers: 200, epoch: 50 | loss: 0.0502683\n",
      "\tspeed: 0.0237s/iter; left time: 265.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0540946 Vali Loss: 0.0542993 Test Loss: 0.0566170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525270\n",
      "\tspeed: 0.0416s/iter; left time: 462.1014s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515277\n",
      "\tspeed: 0.0226s/iter; left time: 248.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541030 Vali Loss: 0.0542633 Test Loss: 0.0566191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0528202\n",
      "\tspeed: 0.0388s/iter; left time: 422.3969s\n",
      "\titers: 200, epoch: 52 | loss: 0.0524368\n",
      "\tspeed: 0.0174s/iter; left time: 187.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0540361 Vali Loss: 0.0542905 Test Loss: 0.0565996\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548940\n",
      "\tspeed: 0.0396s/iter; left time: 421.7677s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519573\n",
      "\tspeed: 0.0204s/iter; left time: 214.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0541037 Vali Loss: 0.0542877 Test Loss: 0.0566198\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533164\n",
      "\tspeed: 0.0430s/iter; left time: 448.0185s\n",
      "\titers: 200, epoch: 54 | loss: 0.0578958\n",
      "\tspeed: 0.0241s/iter; left time: 249.1271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0540474 Vali Loss: 0.0542890 Test Loss: 0.0566051\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0548727\n",
      "\tspeed: 0.0412s/iter; left time: 419.9655s\n",
      "\titers: 200, epoch: 55 | loss: 0.0566967\n",
      "\tspeed: 0.0198s/iter; left time: 200.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 224 | Train Loss: 0.0540961 Vali Loss: 0.0543088 Test Loss: 0.0566188\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0531577\n",
      "\tspeed: 0.0392s/iter; left time: 391.2384s\n",
      "\titers: 200, epoch: 56 | loss: 0.0580916\n",
      "\tspeed: 0.0175s/iter; left time: 173.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0540501 Vali Loss: 0.0543088 Test Loss: 0.0566136\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0559601\n",
      "\tspeed: 0.0367s/iter; left time: 358.4146s\n",
      "\titers: 200, epoch: 57 | loss: 0.0543095\n",
      "\tspeed: 0.0174s/iter; left time: 167.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0540529 Vali Loss: 0.0542350 Test Loss: 0.0566049\n",
      "Validation loss decreased (0.054243 --> 0.054235).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0538715\n",
      "\tspeed: 0.0394s/iter; left time: 375.2252s\n",
      "\titers: 200, epoch: 58 | loss: 0.0555631\n",
      "\tspeed: 0.0176s/iter; left time: 165.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.0540707 Vali Loss: 0.0542733 Test Loss: 0.0566099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0560754\n",
      "\tspeed: 0.0395s/iter; left time: 367.5105s\n",
      "\titers: 200, epoch: 59 | loss: 0.0519199\n",
      "\tspeed: 0.0216s/iter; left time: 199.1363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0540248 Vali Loss: 0.0542616 Test Loss: 0.0566028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0571120\n",
      "\tspeed: 0.0394s/iter; left time: 358.0110s\n",
      "\titers: 200, epoch: 60 | loss: 0.0582117\n",
      "\tspeed: 0.0174s/iter; left time: 156.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0542328 Test Loss: 0.0565980\n",
      "Validation loss decreased (0.054235 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0584766\n",
      "\tspeed: 0.0408s/iter; left time: 361.3126s\n",
      "\titers: 200, epoch: 61 | loss: 0.0535091\n",
      "\tspeed: 0.0177s/iter; left time: 154.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 224 | Train Loss: 0.0540387 Vali Loss: 0.0543091 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0581197\n",
      "\tspeed: 0.0361s/iter; left time: 312.1834s\n",
      "\titers: 200, epoch: 62 | loss: 0.0556779\n",
      "\tspeed: 0.0181s/iter; left time: 154.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0540725 Vali Loss: 0.0543238 Test Loss: 0.0566121\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0515098\n",
      "\tspeed: 0.0379s/iter; left time: 318.9160s\n",
      "\titers: 200, epoch: 63 | loss: 0.0547690\n",
      "\tspeed: 0.0175s/iter; left time: 145.5771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0539889 Vali Loss: 0.0542935 Test Loss: 0.0566016\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0558435\n",
      "\tspeed: 0.0362s/iter; left time: 296.3327s\n",
      "\titers: 200, epoch: 64 | loss: 0.0558558\n",
      "\tspeed: 0.0176s/iter; left time: 141.9768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0540476 Vali Loss: 0.0542764 Test Loss: 0.0566100\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0546813\n",
      "\tspeed: 0.0395s/iter; left time: 314.6030s\n",
      "\titers: 200, epoch: 65 | loss: 0.0554467\n",
      "\tspeed: 0.0175s/iter; left time: 137.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0540326 Vali Loss: 0.0543010 Test Loss: 0.0565934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0568983\n",
      "\tspeed: 0.0397s/iter; left time: 306.9717s\n",
      "\titers: 200, epoch: 66 | loss: 0.0544441\n",
      "\tspeed: 0.0206s/iter; left time: 157.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.0540953 Vali Loss: 0.0543162 Test Loss: 0.0565933\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0554599\n",
      "\tspeed: 0.0427s/iter; left time: 321.0730s\n",
      "\titers: 200, epoch: 67 | loss: 0.0513533\n",
      "\tspeed: 0.0207s/iter; left time: 153.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 224 | Train Loss: 0.0540845 Vali Loss: 0.0543076 Test Loss: 0.0566009\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0543297\n",
      "\tspeed: 0.0370s/iter; left time: 269.8459s\n",
      "\titers: 200, epoch: 68 | loss: 0.0517003\n",
      "\tspeed: 0.0173s/iter; left time: 124.6368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0540420 Vali Loss: 0.0542774 Test Loss: 0.0566046\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0578591\n",
      "\tspeed: 0.0356s/iter; left time: 251.9135s\n",
      "\titers: 200, epoch: 69 | loss: 0.0572697\n",
      "\tspeed: 0.0175s/iter; left time: 121.7898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0540791 Vali Loss: 0.0542371 Test Loss: 0.0566058\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0537115\n",
      "\tspeed: 0.0371s/iter; left time: 253.6271s\n",
      "\titers: 200, epoch: 70 | loss: 0.0505972\n",
      "\tspeed: 0.0210s/iter; left time: 141.8764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 224 | Train Loss: 0.0540482 Vali Loss: 0.0542732 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083218105137348, rmse:0.10041522979736328, mae:0.0565979890525341, rse:0.3794197142124176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1359126\n",
      "\tspeed: 0.0225s/iter; left time: 502.7281s\n",
      "\titers: 200, epoch: 1 | loss: 0.1098680\n",
      "\tspeed: 0.0213s/iter; left time: 473.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1422349 Vali Loss: 0.0974500 Test Loss: 0.0992706\n",
      "Validation loss decreased (inf --> 0.097450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0754588\n",
      "\tspeed: 0.0417s/iter; left time: 921.0493s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673907\n",
      "\tspeed: 0.0174s/iter; left time: 382.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 224 | Train Loss: 0.0780355 Vali Loss: 0.0627294 Test Loss: 0.0657381\n",
      "Validation loss decreased (0.097450 --> 0.062729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637678\n",
      "\tspeed: 0.0431s/iter; left time: 942.5154s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663196\n",
      "\tspeed: 0.0196s/iter; left time: 425.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0660164 Vali Loss: 0.0599926 Test Loss: 0.0628002\n",
      "Validation loss decreased (0.062729 --> 0.059993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0638419\n",
      "\tspeed: 0.0413s/iter; left time: 893.2220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635814\n",
      "\tspeed: 0.0202s/iter; left time: 435.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 224 | Train Loss: 0.0630481 Vali Loss: 0.0586561 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.059993 --> 0.058656).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0630238\n",
      "\tspeed: 0.0430s/iter; left time: 921.1678s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610638\n",
      "\tspeed: 0.0176s/iter; left time: 373.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 224 | Train Loss: 0.0612143 Vali Loss: 0.0575957 Test Loss: 0.0601869\n",
      "Validation loss decreased (0.058656 --> 0.057596).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0648216\n",
      "\tspeed: 0.0375s/iter; left time: 794.3087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634050\n",
      "\tspeed: 0.0176s/iter; left time: 370.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0601831 Vali Loss: 0.0573942 Test Loss: 0.0597799\n",
      "Validation loss decreased (0.057596 --> 0.057394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599069\n",
      "\tspeed: 0.0371s/iter; left time: 778.1308s\n",
      "\titers: 200, epoch: 7 | loss: 0.0612065\n",
      "\tspeed: 0.0175s/iter; left time: 364.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0593155 Vali Loss: 0.0566541 Test Loss: 0.0591102\n",
      "Validation loss decreased (0.057394 --> 0.056654).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542986\n",
      "\tspeed: 0.0415s/iter; left time: 859.8482s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572991\n",
      "\tspeed: 0.0223s/iter; left time: 460.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0585377 Vali Loss: 0.0566305 Test Loss: 0.0588562\n",
      "Validation loss decreased (0.056654 --> 0.056631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0640263\n",
      "\tspeed: 0.0471s/iter; left time: 966.1459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615080\n",
      "\tspeed: 0.0202s/iter; left time: 412.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0579915 Vali Loss: 0.0559572 Test Loss: 0.0582891\n",
      "Validation loss decreased (0.056631 --> 0.055957).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577642\n",
      "\tspeed: 0.0505s/iter; left time: 1025.0210s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594756\n",
      "\tspeed: 0.0264s/iter; left time: 532.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0575409 Vali Loss: 0.0558674 Test Loss: 0.0583287\n",
      "Validation loss decreased (0.055957 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579124\n",
      "\tspeed: 0.0448s/iter; left time: 899.5653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0581660\n",
      "\tspeed: 0.0204s/iter; left time: 406.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0571616 Vali Loss: 0.0555863 Test Loss: 0.0582007\n",
      "Validation loss decreased (0.055867 --> 0.055586).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0618948\n",
      "\tspeed: 0.0424s/iter; left time: 840.9896s\n",
      "\titers: 200, epoch: 12 | loss: 0.0521666\n",
      "\tspeed: 0.0205s/iter; left time: 405.2581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0569079 Vali Loss: 0.0554603 Test Loss: 0.0577516\n",
      "Validation loss decreased (0.055586 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0548473\n",
      "\tspeed: 0.0413s/iter; left time: 809.2691s\n",
      "\titers: 200, epoch: 13 | loss: 0.0552182\n",
      "\tspeed: 0.0208s/iter; left time: 405.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0565429 Vali Loss: 0.0553249 Test Loss: 0.0574627\n",
      "Validation loss decreased (0.055460 --> 0.055325).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0554208\n",
      "\tspeed: 0.0444s/iter; left time: 861.4926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0541941\n",
      "\tspeed: 0.0230s/iter; left time: 443.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0562538 Vali Loss: 0.0553683 Test Loss: 0.0575624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0557231\n",
      "\tspeed: 0.0443s/iter; left time: 848.9220s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574080\n",
      "\tspeed: 0.0209s/iter; left time: 397.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0560413 Vali Loss: 0.0551291 Test Loss: 0.0575157\n",
      "Validation loss decreased (0.055325 --> 0.055129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0575104\n",
      "\tspeed: 0.0396s/iter; left time: 749.1542s\n",
      "\titers: 200, epoch: 16 | loss: 0.0551079\n",
      "\tspeed: 0.0208s/iter; left time: 392.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 224 | Train Loss: 0.0557593 Vali Loss: 0.0548837 Test Loss: 0.0574590\n",
      "Validation loss decreased (0.055129 --> 0.054884).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595915\n",
      "\tspeed: 0.0407s/iter; left time: 761.5210s\n",
      "\titers: 200, epoch: 17 | loss: 0.0584150\n",
      "\tspeed: 0.0174s/iter; left time: 323.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0556200 Vali Loss: 0.0549069 Test Loss: 0.0572072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0574168\n",
      "\tspeed: 0.0400s/iter; left time: 740.2444s\n",
      "\titers: 200, epoch: 18 | loss: 0.0581237\n",
      "\tspeed: 0.0177s/iter; left time: 326.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 224 | Train Loss: 0.0554449 Vali Loss: 0.0550244 Test Loss: 0.0573702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542099\n",
      "\tspeed: 0.0398s/iter; left time: 726.2855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0559456\n",
      "\tspeed: 0.0176s/iter; left time: 319.8055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0553786 Vali Loss: 0.0548329 Test Loss: 0.0571894\n",
      "Validation loss decreased (0.054884 --> 0.054833).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0572355\n",
      "\tspeed: 0.0380s/iter; left time: 686.2173s\n",
      "\titers: 200, epoch: 20 | loss: 0.0561926\n",
      "\tspeed: 0.0173s/iter; left time: 310.9383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0551821 Vali Loss: 0.0546544 Test Loss: 0.0570234\n",
      "Validation loss decreased (0.054833 --> 0.054654).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0563121\n",
      "\tspeed: 0.0377s/iter; left time: 671.9930s\n",
      "\titers: 200, epoch: 21 | loss: 0.0511623\n",
      "\tspeed: 0.0173s/iter; left time: 307.3850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0551742 Vali Loss: 0.0547604 Test Loss: 0.0571249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0555600\n",
      "\tspeed: 0.0370s/iter; left time: 651.3281s\n",
      "\titers: 200, epoch: 22 | loss: 0.0522842\n",
      "\tspeed: 0.0177s/iter; left time: 309.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0550073 Vali Loss: 0.0546179 Test Loss: 0.0571097\n",
      "Validation loss decreased (0.054654 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0549146\n",
      "\tspeed: 0.0380s/iter; left time: 660.0129s\n",
      "\titers: 200, epoch: 23 | loss: 0.0585962\n",
      "\tspeed: 0.0176s/iter; left time: 303.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0548645 Vali Loss: 0.0546012 Test Loss: 0.0568507\n",
      "Validation loss decreased (0.054618 --> 0.054601).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522619\n",
      "\tspeed: 0.0411s/iter; left time: 705.5859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0523071\n",
      "\tspeed: 0.0209s/iter; left time: 356.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0547287 Vali Loss: 0.0545045 Test Loss: 0.0567771\n",
      "Validation loss decreased (0.054601 --> 0.054504).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524549\n",
      "\tspeed: 0.0374s/iter; left time: 632.9479s\n",
      "\titers: 200, epoch: 25 | loss: 0.0523958\n",
      "\tspeed: 0.0175s/iter; left time: 294.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0546907 Vali Loss: 0.0543925 Test Loss: 0.0568053\n",
      "Validation loss decreased (0.054504 --> 0.054393).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0491656\n",
      "\tspeed: 0.0375s/iter; left time: 627.0800s\n",
      "\titers: 200, epoch: 26 | loss: 0.0519010\n",
      "\tspeed: 0.0187s/iter; left time: 309.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 224 | Train Loss: 0.0546669 Vali Loss: 0.0544461 Test Loss: 0.0568800\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0501324\n",
      "\tspeed: 0.0378s/iter; left time: 622.8373s\n",
      "\titers: 200, epoch: 27 | loss: 0.0555143\n",
      "\tspeed: 0.0176s/iter; left time: 287.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0545846 Vali Loss: 0.0543533 Test Loss: 0.0567463\n",
      "Validation loss decreased (0.054393 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0519045\n",
      "\tspeed: 0.0415s/iter; left time: 674.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0593164\n",
      "\tspeed: 0.0198s/iter; left time: 319.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0545893 Vali Loss: 0.0543581 Test Loss: 0.0567341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0529863\n",
      "\tspeed: 0.0364s/iter; left time: 583.2380s\n",
      "\titers: 200, epoch: 29 | loss: 0.0542369\n",
      "\tspeed: 0.0178s/iter; left time: 282.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0544853 Vali Loss: 0.0542986 Test Loss: 0.0568295\n",
      "Validation loss decreased (0.054353 --> 0.054299).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555674\n",
      "\tspeed: 0.0386s/iter; left time: 609.8705s\n",
      "\titers: 200, epoch: 30 | loss: 0.0536577\n",
      "\tspeed: 0.0180s/iter; left time: 283.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0544743 Vali Loss: 0.0543639 Test Loss: 0.0568086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0559736\n",
      "\tspeed: 0.0426s/iter; left time: 664.2999s\n",
      "\titers: 200, epoch: 31 | loss: 0.0530356\n",
      "\tspeed: 0.0198s/iter; left time: 307.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 224 | Train Loss: 0.0543727 Vali Loss: 0.0542804 Test Loss: 0.0567701\n",
      "Validation loss decreased (0.054299 --> 0.054280).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0506607\n",
      "\tspeed: 0.0423s/iter; left time: 648.9617s\n",
      "\titers: 200, epoch: 32 | loss: 0.0552089\n",
      "\tspeed: 0.0197s/iter; left time: 301.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 224 | Train Loss: 0.0543940 Vali Loss: 0.0542822 Test Loss: 0.0566895\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0566098\n",
      "\tspeed: 0.0416s/iter; left time: 628.8243s\n",
      "\titers: 200, epoch: 33 | loss: 0.0505462\n",
      "\tspeed: 0.0176s/iter; left time: 264.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0543382 Vali Loss: 0.0542966 Test Loss: 0.0567221\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0536274\n",
      "\tspeed: 0.0372s/iter; left time: 554.7289s\n",
      "\titers: 200, epoch: 34 | loss: 0.0556459\n",
      "\tspeed: 0.0177s/iter; left time: 262.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0542882 Vali Loss: 0.0541794 Test Loss: 0.0567122\n",
      "Validation loss decreased (0.054280 --> 0.054179).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0517977\n",
      "\tspeed: 0.0418s/iter; left time: 614.2475s\n",
      "\titers: 200, epoch: 35 | loss: 0.0515377\n",
      "\tspeed: 0.0187s/iter; left time: 272.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.0542845 Vali Loss: 0.0542402 Test Loss: 0.0566953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0548994\n",
      "\tspeed: 0.0390s/iter; left time: 564.5106s\n",
      "\titers: 200, epoch: 36 | loss: 0.0516339\n",
      "\tspeed: 0.0174s/iter; left time: 249.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0543297 Vali Loss: 0.0541653 Test Loss: 0.0567088\n",
      "Validation loss decreased (0.054179 --> 0.054165).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0532896\n",
      "\tspeed: 0.0374s/iter; left time: 532.2474s\n",
      "\titers: 200, epoch: 37 | loss: 0.0552534\n",
      "\tspeed: 0.0173s/iter; left time: 245.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0542318 Vali Loss: 0.0542396 Test Loss: 0.0566283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0579502\n",
      "\tspeed: 0.0363s/iter; left time: 509.2660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0564580\n",
      "\tspeed: 0.0174s/iter; left time: 241.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0541829 Vali Loss: 0.0542048 Test Loss: 0.0566276\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0524793\n",
      "\tspeed: 0.0436s/iter; left time: 601.4429s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540179\n",
      "\tspeed: 0.0233s/iter; left time: 319.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0542241 Vali Loss: 0.0542069 Test Loss: 0.0566297\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0576975\n",
      "\tspeed: 0.0376s/iter; left time: 509.5911s\n",
      "\titers: 200, epoch: 40 | loss: 0.0566987\n",
      "\tspeed: 0.0200s/iter; left time: 269.4703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 224 | Train Loss: 0.0542656 Vali Loss: 0.0541664 Test Loss: 0.0566543\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545915\n",
      "\tspeed: 0.0367s/iter; left time: 489.2609s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532811\n",
      "\tspeed: 0.0210s/iter; left time: 277.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0542114 Vali Loss: 0.0541793 Test Loss: 0.0566813\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551827\n",
      "\tspeed: 0.0411s/iter; left time: 539.2438s\n",
      "\titers: 200, epoch: 42 | loss: 0.0532943\n",
      "\tspeed: 0.0185s/iter; left time: 241.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 224 | Train Loss: 0.0541279 Vali Loss: 0.0542011 Test Loss: 0.0566544\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552357\n",
      "\tspeed: 0.0401s/iter; left time: 517.6390s\n",
      "\titers: 200, epoch: 43 | loss: 0.0531659\n",
      "\tspeed: 0.0226s/iter; left time: 288.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0541679 Vali Loss: 0.0542149 Test Loss: 0.0566875\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508406\n",
      "\tspeed: 0.0397s/iter; left time: 502.6425s\n",
      "\titers: 200, epoch: 44 | loss: 0.0489071\n",
      "\tspeed: 0.0176s/iter; left time: 220.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0541656 Vali Loss: 0.0542703 Test Loss: 0.0566778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571226\n",
      "\tspeed: 0.0372s/iter; left time: 463.0165s\n",
      "\titers: 200, epoch: 45 | loss: 0.0516223\n",
      "\tspeed: 0.0175s/iter; left time: 216.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0541814 Vali Loss: 0.0541900 Test Loss: 0.0566624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0533346\n",
      "\tspeed: 0.0367s/iter; left time: 448.1339s\n",
      "\titers: 200, epoch: 46 | loss: 0.0554680\n",
      "\tspeed: 0.0176s/iter; left time: 213.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0541046 Vali Loss: 0.0542059 Test Loss: 0.0566667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010069291107356548, rmse:0.10034585744142532, mae:0.05670879781246185, rse:0.37915757298469543\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:52.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1438253\n",
      "\tspeed: 0.0460s/iter; left time: 1024.9099s\n",
      "\titers: 200, epoch: 1 | loss: 0.1208758\n",
      "\tspeed: 0.0179s/iter; left time: 397.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 224 | Train Loss: 0.1473302 Vali Loss: 0.1059266 Test Loss: 0.1091740\n",
      "Validation loss decreased (inf --> 0.105927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0936386\n",
      "\tspeed: 0.0392s/iter; left time: 865.1550s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860985\n",
      "\tspeed: 0.0179s/iter; left time: 392.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0960414 Vali Loss: 0.0816183 Test Loss: 0.0868534\n",
      "Validation loss decreased (0.105927 --> 0.081618).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0869685\n",
      "\tspeed: 0.0384s/iter; left time: 839.2529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824700\n",
      "\tspeed: 0.0177s/iter; left time: 384.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0850344 Vali Loss: 0.0794767 Test Loss: 0.0840807\n",
      "Validation loss decreased (0.081618 --> 0.079477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0811073\n",
      "\tspeed: 0.0395s/iter; left time: 854.8521s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803189\n",
      "\tspeed: 0.0192s/iter; left time: 413.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823571 Vali Loss: 0.0782248 Test Loss: 0.0828857\n",
      "Validation loss decreased (0.079477 --> 0.078225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829862\n",
      "\tspeed: 0.0391s/iter; left time: 837.2694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0771629\n",
      "\tspeed: 0.0180s/iter; left time: 383.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 224 | Train Loss: 0.0807140 Vali Loss: 0.0776065 Test Loss: 0.0829133\n",
      "Validation loss decreased (0.078225 --> 0.077606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808049\n",
      "\tspeed: 0.0381s/iter; left time: 806.9387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791209\n",
      "\tspeed: 0.0175s/iter; left time: 369.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0796624 Vali Loss: 0.0771222 Test Loss: 0.0819657\n",
      "Validation loss decreased (0.077606 --> 0.077122).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0809408\n",
      "\tspeed: 0.0381s/iter; left time: 797.8413s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773605\n",
      "\tspeed: 0.0179s/iter; left time: 373.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0788298 Vali Loss: 0.0770251 Test Loss: 0.0816225\n",
      "Validation loss decreased (0.077122 --> 0.077025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780101\n",
      "\tspeed: 0.0386s/iter; left time: 800.1361s\n",
      "\titers: 200, epoch: 8 | loss: 0.0734982\n",
      "\tspeed: 0.0178s/iter; left time: 366.6406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0781991 Vali Loss: 0.0765766 Test Loss: 0.0813183\n",
      "Validation loss decreased (0.077025 --> 0.076577).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0775502\n",
      "\tspeed: 0.0390s/iter; left time: 800.2133s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727340\n",
      "\tspeed: 0.0179s/iter; left time: 365.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0776098 Vali Loss: 0.0765785 Test Loss: 0.0815433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0742046\n",
      "\tspeed: 0.0384s/iter; left time: 778.6754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804574\n",
      "\tspeed: 0.0179s/iter; left time: 361.6385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0770741 Vali Loss: 0.0760664 Test Loss: 0.0814565\n",
      "Validation loss decreased (0.076577 --> 0.076066).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781170\n",
      "\tspeed: 0.0385s/iter; left time: 771.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763606\n",
      "\tspeed: 0.0177s/iter; left time: 354.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0766591 Vali Loss: 0.0762633 Test Loss: 0.0814268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0788421\n",
      "\tspeed: 0.0386s/iter; left time: 765.1212s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785553\n",
      "\tspeed: 0.0186s/iter; left time: 367.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 224 | Train Loss: 0.0762871 Vali Loss: 0.0763303 Test Loss: 0.0807374\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767044\n",
      "\tspeed: 0.0405s/iter; left time: 794.2752s\n",
      "\titers: 200, epoch: 13 | loss: 0.0790308\n",
      "\tspeed: 0.0190s/iter; left time: 370.3604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0760010 Vali Loss: 0.0760269 Test Loss: 0.0811383\n",
      "Validation loss decreased (0.076066 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0738585\n",
      "\tspeed: 0.0382s/iter; left time: 740.1297s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735675\n",
      "\tspeed: 0.0175s/iter; left time: 337.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0756241 Vali Loss: 0.0759628 Test Loss: 0.0812599\n",
      "Validation loss decreased (0.076027 --> 0.075963).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746233\n",
      "\tspeed: 0.0403s/iter; left time: 773.2452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766651\n",
      "\tspeed: 0.0178s/iter; left time: 340.1740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.0754588 Vali Loss: 0.0756437 Test Loss: 0.0810107\n",
      "Validation loss decreased (0.075963 --> 0.075644).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0798216\n",
      "\tspeed: 0.0379s/iter; left time: 718.3975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0763530\n",
      "\tspeed: 0.0177s/iter; left time: 333.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0750988 Vali Loss: 0.0756608 Test Loss: 0.0809585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0749412\n",
      "\tspeed: 0.0400s/iter; left time: 748.7746s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748506\n",
      "\tspeed: 0.0177s/iter; left time: 329.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0748632 Vali Loss: 0.0757296 Test Loss: 0.0809511\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0732470\n",
      "\tspeed: 0.0383s/iter; left time: 708.6400s\n",
      "\titers: 200, epoch: 18 | loss: 0.0771152\n",
      "\tspeed: 0.0177s/iter; left time: 325.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0746712 Vali Loss: 0.0759519 Test Loss: 0.0808242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0716322\n",
      "\tspeed: 0.0374s/iter; left time: 682.6111s\n",
      "\titers: 200, epoch: 19 | loss: 0.0734277\n",
      "\tspeed: 0.0175s/iter; left time: 318.4366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0744779 Vali Loss: 0.0757884 Test Loss: 0.0807449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0720630\n",
      "\tspeed: 0.0396s/iter; left time: 714.6965s\n",
      "\titers: 200, epoch: 20 | loss: 0.0764352\n",
      "\tspeed: 0.0176s/iter; left time: 315.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.0742645 Vali Loss: 0.0756426 Test Loss: 0.0808228\n",
      "Validation loss decreased (0.075644 --> 0.075643).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752152\n",
      "\tspeed: 0.0425s/iter; left time: 757.8532s\n",
      "\titers: 200, epoch: 21 | loss: 0.0683738\n",
      "\tspeed: 0.0190s/iter; left time: 336.3019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 224 | Train Loss: 0.0741271 Vali Loss: 0.0756992 Test Loss: 0.0806643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0747552\n",
      "\tspeed: 0.0387s/iter; left time: 680.3511s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740042\n",
      "\tspeed: 0.0178s/iter; left time: 311.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 224 | Train Loss: 0.0740510 Vali Loss: 0.0756657 Test Loss: 0.0808825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729785\n",
      "\tspeed: 0.0379s/iter; left time: 658.7155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724722\n",
      "\tspeed: 0.0175s/iter; left time: 302.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0738833 Vali Loss: 0.0756935 Test Loss: 0.0808874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0741584\n",
      "\tspeed: 0.0379s/iter; left time: 650.3920s\n",
      "\titers: 200, epoch: 24 | loss: 0.0702976\n",
      "\tspeed: 0.0176s/iter; left time: 299.2664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0737572 Vali Loss: 0.0755926 Test Loss: 0.0806114\n",
      "Validation loss decreased (0.075643 --> 0.075593).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0726041\n",
      "\tspeed: 0.0387s/iter; left time: 654.9765s\n",
      "\titers: 200, epoch: 25 | loss: 0.0721414\n",
      "\tspeed: 0.0177s/iter; left time: 297.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0735935 Vali Loss: 0.0755621 Test Loss: 0.0806927\n",
      "Validation loss decreased (0.075593 --> 0.075562).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0734444\n",
      "\tspeed: 0.0385s/iter; left time: 643.0189s\n",
      "\titers: 200, epoch: 26 | loss: 0.0754302\n",
      "\tspeed: 0.0175s/iter; left time: 291.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0735225 Vali Loss: 0.0756676 Test Loss: 0.0805907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0747007\n",
      "\tspeed: 0.0378s/iter; left time: 623.2643s\n",
      "\titers: 200, epoch: 27 | loss: 0.0694138\n",
      "\tspeed: 0.0177s/iter; left time: 290.0670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0734549 Vali Loss: 0.0755092 Test Loss: 0.0805312\n",
      "Validation loss decreased (0.075562 --> 0.075509).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0760770\n",
      "\tspeed: 0.0391s/iter; left time: 635.0650s\n",
      "\titers: 200, epoch: 28 | loss: 0.0724863\n",
      "\tspeed: 0.0178s/iter; left time: 287.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0733856 Vali Loss: 0.0755548 Test Loss: 0.0805923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0735273\n",
      "\tspeed: 0.0381s/iter; left time: 610.0264s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731055\n",
      "\tspeed: 0.0177s/iter; left time: 281.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0733169 Vali Loss: 0.0754803 Test Loss: 0.0806061\n",
      "Validation loss decreased (0.075509 --> 0.075480).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0725225\n",
      "\tspeed: 0.0388s/iter; left time: 613.0244s\n",
      "\titers: 200, epoch: 30 | loss: 0.0722679\n",
      "\tspeed: 0.0177s/iter; left time: 278.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0732621 Vali Loss: 0.0754730 Test Loss: 0.0806382\n",
      "Validation loss decreased (0.075480 --> 0.075473).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0735552\n",
      "\tspeed: 0.0406s/iter; left time: 632.5392s\n",
      "\titers: 200, epoch: 31 | loss: 0.0696184\n",
      "\tspeed: 0.0177s/iter; left time: 273.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 224 | Train Loss: 0.0732522 Vali Loss: 0.0753299 Test Loss: 0.0805189\n",
      "Validation loss decreased (0.075473 --> 0.075330).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0748394\n",
      "\tspeed: 0.0394s/iter; left time: 605.2338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749177\n",
      "\tspeed: 0.0178s/iter; left time: 271.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0731558 Vali Loss: 0.0754113 Test Loss: 0.0805488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731158\n",
      "\tspeed: 0.0415s/iter; left time: 628.1651s\n",
      "\titers: 200, epoch: 33 | loss: 0.0764134\n",
      "\tspeed: 0.0190s/iter; left time: 285.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 224 | Train Loss: 0.0731354 Vali Loss: 0.0754464 Test Loss: 0.0805663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0720409\n",
      "\tspeed: 0.0380s/iter; left time: 566.4270s\n",
      "\titers: 200, epoch: 34 | loss: 0.0738428\n",
      "\tspeed: 0.0178s/iter; left time: 262.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 224 | Train Loss: 0.0730683 Vali Loss: 0.0754058 Test Loss: 0.0804376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0698061\n",
      "\tspeed: 0.0400s/iter; left time: 587.5626s\n",
      "\titers: 200, epoch: 35 | loss: 0.0759599\n",
      "\tspeed: 0.0194s/iter; left time: 283.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 224 | Train Loss: 0.0730275 Vali Loss: 0.0754564 Test Loss: 0.0805740\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0716557\n",
      "\tspeed: 0.0385s/iter; left time: 557.2221s\n",
      "\titers: 200, epoch: 36 | loss: 0.0711207\n",
      "\tspeed: 0.0175s/iter; left time: 251.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0730016 Vali Loss: 0.0754517 Test Loss: 0.0805066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755870\n",
      "\tspeed: 0.0383s/iter; left time: 545.3388s\n",
      "\titers: 200, epoch: 37 | loss: 0.0734674\n",
      "\tspeed: 0.0181s/iter; left time: 255.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0729387 Vali Loss: 0.0754124 Test Loss: 0.0805279\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0684947\n",
      "\tspeed: 0.0376s/iter; left time: 526.9358s\n",
      "\titers: 200, epoch: 38 | loss: 0.0758405\n",
      "\tspeed: 0.0177s/iter; left time: 245.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0729181 Vali Loss: 0.0754555 Test Loss: 0.0805209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0743821\n",
      "\tspeed: 0.0375s/iter; left time: 517.0128s\n",
      "\titers: 200, epoch: 39 | loss: 0.0711856\n",
      "\tspeed: 0.0175s/iter; left time: 239.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0728928 Vali Loss: 0.0753763 Test Loss: 0.0805926\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0773584\n",
      "\tspeed: 0.0425s/iter; left time: 576.3701s\n",
      "\titers: 200, epoch: 40 | loss: 0.0719035\n",
      "\tspeed: 0.0231s/iter; left time: 311.2183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0729117 Vali Loss: 0.0754172 Test Loss: 0.0805385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0723396\n",
      "\tspeed: 0.0413s/iter; left time: 551.6058s\n",
      "\titers: 200, epoch: 41 | loss: 0.0712304\n",
      "\tspeed: 0.0176s/iter; left time: 232.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 224 | Train Loss: 0.0729427 Vali Loss: 0.0753424 Test Loss: 0.0805553\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018678918480873108, rmse:0.13667084276676178, mae:0.08051890879869461, rse:0.5167672038078308\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1446110\n",
      "\tspeed: 0.0221s/iter; left time: 493.8308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1253999\n",
      "\tspeed: 0.0199s/iter; left time: 441.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.1496909 Vali Loss: 0.1045320 Test Loss: 0.1075368\n",
      "Validation loss decreased (inf --> 0.104532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0924727\n",
      "\tspeed: 0.0412s/iter; left time: 910.6740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894741\n",
      "\tspeed: 0.0178s/iter; left time: 390.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.0954484 Vali Loss: 0.0817993 Test Loss: 0.0867445\n",
      "Validation loss decreased (0.104532 --> 0.081799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0847295\n",
      "\tspeed: 0.0402s/iter; left time: 878.0263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0820517\n",
      "\tspeed: 0.0180s/iter; left time: 391.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0846861 Vali Loss: 0.0795831 Test Loss: 0.0841799\n",
      "Validation loss decreased (0.081799 --> 0.079583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0826818\n",
      "\tspeed: 0.0404s/iter; left time: 873.8917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826001\n",
      "\tspeed: 0.0179s/iter; left time: 386.0319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 224 | Train Loss: 0.0823463 Vali Loss: 0.0784222 Test Loss: 0.0830313\n",
      "Validation loss decreased (0.079583 --> 0.078422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0834706\n",
      "\tspeed: 0.0389s/iter; left time: 833.0787s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793772\n",
      "\tspeed: 0.0177s/iter; left time: 376.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0808059 Vali Loss: 0.0778977 Test Loss: 0.0820265\n",
      "Validation loss decreased (0.078422 --> 0.077898).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793130\n",
      "\tspeed: 0.0408s/iter; left time: 863.3459s\n",
      "\titers: 200, epoch: 6 | loss: 0.0798471\n",
      "\tspeed: 0.0182s/iter; left time: 382.9665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 224 | Train Loss: 0.0797353 Vali Loss: 0.0771687 Test Loss: 0.0820218\n",
      "Validation loss decreased (0.077898 --> 0.077169).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792806\n",
      "\tspeed: 0.0394s/iter; left time: 825.4901s\n",
      "\titers: 200, epoch: 7 | loss: 0.0804888\n",
      "\tspeed: 0.0179s/iter; left time: 373.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.0788949 Vali Loss: 0.0769688 Test Loss: 0.0814737\n",
      "Validation loss decreased (0.077169 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805822\n",
      "\tspeed: 0.0417s/iter; left time: 865.1671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0799717\n",
      "\tspeed: 0.0187s/iter; left time: 385.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0782915 Vali Loss: 0.0768342 Test Loss: 0.0813357\n",
      "Validation loss decreased (0.076969 --> 0.076834).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787869\n",
      "\tspeed: 0.0384s/iter; left time: 787.5092s\n",
      "\titers: 200, epoch: 9 | loss: 0.0796126\n",
      "\tspeed: 0.0176s/iter; left time: 358.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0777337 Vali Loss: 0.0765885 Test Loss: 0.0811092\n",
      "Validation loss decreased (0.076834 --> 0.076589).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0715174\n",
      "\tspeed: 0.0388s/iter; left time: 786.4551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0793800\n",
      "\tspeed: 0.0177s/iter; left time: 358.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0773026 Vali Loss: 0.0766290 Test Loss: 0.0812185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754477\n",
      "\tspeed: 0.0381s/iter; left time: 764.6416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789837\n",
      "\tspeed: 0.0178s/iter; left time: 354.4071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.0767757 Vali Loss: 0.0764785 Test Loss: 0.0808268\n",
      "Validation loss decreased (0.076589 --> 0.076479).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715470\n",
      "\tspeed: 0.0443s/iter; left time: 879.6698s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762711\n",
      "\tspeed: 0.0199s/iter; left time: 392.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 224 | Train Loss: 0.0764457 Vali Loss: 0.0764530 Test Loss: 0.0807678\n",
      "Validation loss decreased (0.076479 --> 0.076453).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0757492\n",
      "\tspeed: 0.0450s/iter; left time: 883.5416s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821893\n",
      "\tspeed: 0.0204s/iter; left time: 397.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0761522 Vali Loss: 0.0763963 Test Loss: 0.0806580\n",
      "Validation loss decreased (0.076453 --> 0.076396).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0764003\n",
      "\tspeed: 0.0461s/iter; left time: 894.1181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0738080\n",
      "\tspeed: 0.0196s/iter; left time: 378.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0758944 Vali Loss: 0.0761132 Test Loss: 0.0809184\n",
      "Validation loss decreased (0.076396 --> 0.076113).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0746748\n",
      "\tspeed: 0.0406s/iter; left time: 778.9004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0724435\n",
      "\tspeed: 0.0194s/iter; left time: 370.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 224 | Train Loss: 0.0755759 Vali Loss: 0.0764618 Test Loss: 0.0805427\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0719663\n",
      "\tspeed: 0.0390s/iter; left time: 737.9347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0697170\n",
      "\tspeed: 0.0178s/iter; left time: 335.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0753819 Vali Loss: 0.0761848 Test Loss: 0.0806028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727296\n",
      "\tspeed: 0.0406s/iter; left time: 760.1802s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727161\n",
      "\tspeed: 0.0177s/iter; left time: 330.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 224 | Train Loss: 0.0750679 Vali Loss: 0.0762574 Test Loss: 0.0805783\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725658\n",
      "\tspeed: 0.0381s/iter; left time: 703.8773s\n",
      "\titers: 200, epoch: 18 | loss: 0.0764599\n",
      "\tspeed: 0.0178s/iter; left time: 327.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0748732 Vali Loss: 0.0761443 Test Loss: 0.0805745\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0747242\n",
      "\tspeed: 0.0466s/iter; left time: 851.3817s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744604\n",
      "\tspeed: 0.0214s/iter; left time: 388.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0746945 Vali Loss: 0.0761027 Test Loss: 0.0805595\n",
      "Validation loss decreased (0.076113 --> 0.076103).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739140\n",
      "\tspeed: 0.0443s/iter; left time: 798.5066s\n",
      "\titers: 200, epoch: 20 | loss: 0.0799948\n",
      "\tspeed: 0.0225s/iter; left time: 403.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0745287 Vali Loss: 0.0761509 Test Loss: 0.0804114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0718822\n",
      "\tspeed: 0.0403s/iter; left time: 719.0455s\n",
      "\titers: 200, epoch: 21 | loss: 0.0686560\n",
      "\tspeed: 0.0197s/iter; left time: 348.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 224 | Train Loss: 0.0743691 Vali Loss: 0.0761282 Test Loss: 0.0804886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756082\n",
      "\tspeed: 0.0382s/iter; left time: 671.8549s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743395\n",
      "\tspeed: 0.0176s/iter; left time: 307.8186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0742769 Vali Loss: 0.0762186 Test Loss: 0.0808756\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0802817\n",
      "\tspeed: 0.0395s/iter; left time: 686.2851s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747382\n",
      "\tspeed: 0.0194s/iter; left time: 334.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 224 | Train Loss: 0.0740906 Vali Loss: 0.0761006 Test Loss: 0.0809374\n",
      "Validation loss decreased (0.076103 --> 0.076101).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0721726\n",
      "\tspeed: 0.0388s/iter; left time: 665.4127s\n",
      "\titers: 200, epoch: 24 | loss: 0.0764399\n",
      "\tspeed: 0.0179s/iter; left time: 305.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0739739 Vali Loss: 0.0763183 Test Loss: 0.0805535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0713016\n",
      "\tspeed: 0.0377s/iter; left time: 638.2618s\n",
      "\titers: 200, epoch: 25 | loss: 0.0763350\n",
      "\tspeed: 0.0177s/iter; left time: 297.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0739049 Vali Loss: 0.0761669 Test Loss: 0.0804498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0704296\n",
      "\tspeed: 0.0396s/iter; left time: 661.2235s\n",
      "\titers: 200, epoch: 26 | loss: 0.0738422\n",
      "\tspeed: 0.0211s/iter; left time: 350.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 224 | Train Loss: 0.0737833 Vali Loss: 0.0761739 Test Loss: 0.0806323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0736066\n",
      "\tspeed: 0.0397s/iter; left time: 654.4782s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724954\n",
      "\tspeed: 0.0181s/iter; left time: 295.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 224 | Train Loss: 0.0737053 Vali Loss: 0.0761146 Test Loss: 0.0805858\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708030\n",
      "\tspeed: 0.0417s/iter; left time: 678.2211s\n",
      "\titers: 200, epoch: 28 | loss: 0.0726346\n",
      "\tspeed: 0.0224s/iter; left time: 361.8982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0736342 Vali Loss: 0.0761730 Test Loss: 0.0805067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0736985\n",
      "\tspeed: 0.0394s/iter; left time: 631.5932s\n",
      "\titers: 200, epoch: 29 | loss: 0.0757324\n",
      "\tspeed: 0.0175s/iter; left time: 279.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0736515 Vali Loss: 0.0762277 Test Loss: 0.0805709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0738680\n",
      "\tspeed: 0.0382s/iter; left time: 604.3951s\n",
      "\titers: 200, epoch: 30 | loss: 0.0754899\n",
      "\tspeed: 0.0175s/iter; left time: 275.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0735729 Vali Loss: 0.0761100 Test Loss: 0.0804291\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0771352\n",
      "\tspeed: 0.0394s/iter; left time: 614.2084s\n",
      "\titers: 200, epoch: 31 | loss: 0.0740414\n",
      "\tspeed: 0.0175s/iter; left time: 271.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.0734717 Vali Loss: 0.0763483 Test Loss: 0.0805765\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0702331\n",
      "\tspeed: 0.0375s/iter; left time: 576.6210s\n",
      "\titers: 200, epoch: 32 | loss: 0.0758914\n",
      "\tspeed: 0.0181s/iter; left time: 276.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0734446 Vali Loss: 0.0761305 Test Loss: 0.0804661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0723481\n",
      "\tspeed: 0.0372s/iter; left time: 563.5045s\n",
      "\titers: 200, epoch: 33 | loss: 0.0725820\n",
      "\tspeed: 0.0176s/iter; left time: 264.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0733762 Vali Loss: 0.0761667 Test Loss: 0.0805655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018912920728325844, rmse:0.13752426207065582, mae:0.08093737810850143, rse:0.5199940204620361\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:21.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1423216\n",
      "\tspeed: 0.0461s/iter; left time: 1023.0411s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238418\n",
      "\tspeed: 0.0180s/iter; left time: 397.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.1487374 Vali Loss: 0.1077961 Test Loss: 0.1103803\n",
      "Validation loss decreased (inf --> 0.107796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939423\n",
      "\tspeed: 0.0391s/iter; left time: 860.2094s\n",
      "\titers: 200, epoch: 2 | loss: 0.0893055\n",
      "\tspeed: 0.0179s/iter; left time: 392.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0994013 Vali Loss: 0.0860546 Test Loss: 0.0906314\n",
      "Validation loss decreased (0.107796 --> 0.086055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0925718\n",
      "\tspeed: 0.0395s/iter; left time: 859.8668s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874189\n",
      "\tspeed: 0.0179s/iter; left time: 387.7733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0890840 Vali Loss: 0.0842465 Test Loss: 0.0879599\n",
      "Validation loss decreased (0.086055 --> 0.084247).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0881069\n",
      "\tspeed: 0.0411s/iter; left time: 885.5673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0894828\n",
      "\tspeed: 0.0193s/iter; left time: 413.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 223 | Train Loss: 0.0864151 Vali Loss: 0.0837157 Test Loss: 0.0879383\n",
      "Validation loss decreased (0.084247 --> 0.083716).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829716\n",
      "\tspeed: 0.0404s/iter; left time: 860.1269s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826994\n",
      "\tspeed: 0.0179s/iter; left time: 379.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0848429 Vali Loss: 0.0827259 Test Loss: 0.0875212\n",
      "Validation loss decreased (0.083716 --> 0.082726).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817767\n",
      "\tspeed: 0.0409s/iter; left time: 861.8152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0862948\n",
      "\tspeed: 0.0193s/iter; left time: 404.2502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 223 | Train Loss: 0.0836924 Vali Loss: 0.0822996 Test Loss: 0.0872402\n",
      "Validation loss decreased (0.082726 --> 0.082300).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838116\n",
      "\tspeed: 0.0392s/iter; left time: 818.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848943\n",
      "\tspeed: 0.0179s/iter; left time: 370.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0827538 Vali Loss: 0.0820797 Test Loss: 0.0871094\n",
      "Validation loss decreased (0.082300 --> 0.082080).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825785\n",
      "\tspeed: 0.0387s/iter; left time: 799.7960s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793753\n",
      "\tspeed: 0.0179s/iter; left time: 366.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0820263 Vali Loss: 0.0822556 Test Loss: 0.0876831\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0795462\n",
      "\tspeed: 0.0425s/iter; left time: 868.7222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0789129\n",
      "\tspeed: 0.0228s/iter; left time: 464.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0815050 Vali Loss: 0.0815729 Test Loss: 0.0867696\n",
      "Validation loss decreased (0.082080 --> 0.081573).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811481\n",
      "\tspeed: 0.0412s/iter; left time: 831.2948s\n",
      "\titers: 200, epoch: 10 | loss: 0.0825071\n",
      "\tspeed: 0.0183s/iter; left time: 368.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0810133 Vali Loss: 0.0817944 Test Loss: 0.0868367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0821963\n",
      "\tspeed: 0.0398s/iter; left time: 794.0686s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761625\n",
      "\tspeed: 0.0208s/iter; left time: 413.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 223 | Train Loss: 0.0805028 Vali Loss: 0.0818734 Test Loss: 0.0874601\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0790672\n",
      "\tspeed: 0.0383s/iter; left time: 756.6160s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799741\n",
      "\tspeed: 0.0178s/iter; left time: 350.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.0801906 Vali Loss: 0.0817134 Test Loss: 0.0878104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782696\n",
      "\tspeed: 0.0420s/iter; left time: 820.3538s\n",
      "\titers: 200, epoch: 13 | loss: 0.0798471\n",
      "\tspeed: 0.0206s/iter; left time: 400.7098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0798508 Vali Loss: 0.0815302 Test Loss: 0.0871841\n",
      "Validation loss decreased (0.081573 --> 0.081530).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0773299\n",
      "\tspeed: 0.0454s/iter; left time: 876.7918s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797019\n",
      "\tspeed: 0.0185s/iter; left time: 354.6894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 223 | Train Loss: 0.0794928 Vali Loss: 0.0817144 Test Loss: 0.0871146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0791878\n",
      "\tspeed: 0.0386s/iter; left time: 736.6542s\n",
      "\titers: 200, epoch: 15 | loss: 0.0850011\n",
      "\tspeed: 0.0180s/iter; left time: 341.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0791677 Vali Loss: 0.0815923 Test Loss: 0.0870508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0806760\n",
      "\tspeed: 0.0414s/iter; left time: 779.9618s\n",
      "\titers: 200, epoch: 16 | loss: 0.0801392\n",
      "\tspeed: 0.0179s/iter; left time: 336.1305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 223 | Train Loss: 0.0789298 Vali Loss: 0.0816933 Test Loss: 0.0873272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782162\n",
      "\tspeed: 0.0394s/iter; left time: 734.2989s\n",
      "\titers: 200, epoch: 17 | loss: 0.0770024\n",
      "\tspeed: 0.0182s/iter; left time: 337.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0786994 Vali Loss: 0.0814644 Test Loss: 0.0871423\n",
      "Validation loss decreased (0.081530 --> 0.081464).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750689\n",
      "\tspeed: 0.0393s/iter; left time: 723.2489s\n",
      "\titers: 200, epoch: 18 | loss: 0.0791912\n",
      "\tspeed: 0.0179s/iter; left time: 326.9713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0784913 Vali Loss: 0.0817581 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0772508\n",
      "\tspeed: 0.0385s/iter; left time: 700.3244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0785425\n",
      "\tspeed: 0.0179s/iter; left time: 323.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.0782302 Vali Loss: 0.0813190 Test Loss: 0.0870724\n",
      "Validation loss decreased (0.081464 --> 0.081319).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0796085\n",
      "\tspeed: 0.0418s/iter; left time: 750.8243s\n",
      "\titers: 200, epoch: 20 | loss: 0.0747003\n",
      "\tspeed: 0.0179s/iter; left time: 319.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0780742 Vali Loss: 0.0815029 Test Loss: 0.0872391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0798976\n",
      "\tspeed: 0.0385s/iter; left time: 682.9507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0783784\n",
      "\tspeed: 0.0205s/iter; left time: 360.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 223 | Train Loss: 0.0778642 Vali Loss: 0.0814129 Test Loss: 0.0872288\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798767\n",
      "\tspeed: 0.0401s/iter; left time: 701.9505s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798330\n",
      "\tspeed: 0.0185s/iter; left time: 323.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0777549 Vali Loss: 0.0814658 Test Loss: 0.0875085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0734261\n",
      "\tspeed: 0.0395s/iter; left time: 683.3050s\n",
      "\titers: 200, epoch: 23 | loss: 0.0779886\n",
      "\tspeed: 0.0181s/iter; left time: 311.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 223 | Train Loss: 0.0775775 Vali Loss: 0.0814620 Test Loss: 0.0873106\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789265\n",
      "\tspeed: 0.0384s/iter; left time: 655.8847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0768867\n",
      "\tspeed: 0.0181s/iter; left time: 306.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0774439 Vali Loss: 0.0814374 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0773396\n",
      "\tspeed: 0.0389s/iter; left time: 655.6546s\n",
      "\titers: 200, epoch: 25 | loss: 0.0760351\n",
      "\tspeed: 0.0185s/iter; left time: 310.4427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.0773691 Vali Loss: 0.0813845 Test Loss: 0.0871841\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0796533\n",
      "\tspeed: 0.0399s/iter; left time: 662.7052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0774103\n",
      "\tspeed: 0.0180s/iter; left time: 297.4635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.0771835 Vali Loss: 0.0814663 Test Loss: 0.0871791\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742327\n",
      "\tspeed: 0.0372s/iter; left time: 610.6163s\n",
      "\titers: 200, epoch: 27 | loss: 0.0805335\n",
      "\tspeed: 0.0178s/iter; left time: 289.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0771259 Vali Loss: 0.0814744 Test Loss: 0.0872126\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0766790\n",
      "\tspeed: 0.0381s/iter; left time: 616.6928s\n",
      "\titers: 200, epoch: 28 | loss: 0.0775495\n",
      "\tspeed: 0.0179s/iter; left time: 288.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.0770471 Vali Loss: 0.0813009 Test Loss: 0.0870816\n",
      "Validation loss decreased (0.081319 --> 0.081301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0757094\n",
      "\tspeed: 0.0408s/iter; left time: 650.4701s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760654\n",
      "\tspeed: 0.0180s/iter; left time: 285.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0769555 Vali Loss: 0.0812396 Test Loss: 0.0871117\n",
      "Validation loss decreased (0.081301 --> 0.081240).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0767229\n",
      "\tspeed: 0.0404s/iter; left time: 635.6768s\n",
      "\titers: 200, epoch: 30 | loss: 0.0786787\n",
      "\tspeed: 0.0180s/iter; left time: 282.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.0768584 Vali Loss: 0.0815030 Test Loss: 0.0869776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778194\n",
      "\tspeed: 0.0383s/iter; left time: 594.6005s\n",
      "\titers: 200, epoch: 31 | loss: 0.0778298\n",
      "\tspeed: 0.0178s/iter; left time: 274.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0767776 Vali Loss: 0.0813545 Test Loss: 0.0871082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0754501\n",
      "\tspeed: 0.0407s/iter; left time: 622.4346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0764830\n",
      "\tspeed: 0.0179s/iter; left time: 272.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 223 | Train Loss: 0.0767559 Vali Loss: 0.0812562 Test Loss: 0.0870397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0755639\n",
      "\tspeed: 0.0414s/iter; left time: 624.0858s\n",
      "\titers: 200, epoch: 33 | loss: 0.0777980\n",
      "\tspeed: 0.0204s/iter; left time: 305.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 223 | Train Loss: 0.0767118 Vali Loss: 0.0814427 Test Loss: 0.0868835\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0754135\n",
      "\tspeed: 0.0393s/iter; left time: 583.4103s\n",
      "\titers: 200, epoch: 34 | loss: 0.0785940\n",
      "\tspeed: 0.0180s/iter; left time: 264.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0766594 Vali Loss: 0.0814381 Test Loss: 0.0870054\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776752\n",
      "\tspeed: 0.0433s/iter; left time: 633.2336s\n",
      "\titers: 200, epoch: 35 | loss: 0.0752889\n",
      "\tspeed: 0.0219s/iter; left time: 318.3048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0766568 Vali Loss: 0.0813767 Test Loss: 0.0870404\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0754985\n",
      "\tspeed: 0.0434s/iter; left time: 624.6602s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774933\n",
      "\tspeed: 0.0183s/iter; left time: 261.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 223 | Train Loss: 0.0765844 Vali Loss: 0.0814429 Test Loss: 0.0870331\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0767131\n",
      "\tspeed: 0.0404s/iter; left time: 572.0861s\n",
      "\titers: 200, epoch: 37 | loss: 0.0771547\n",
      "\tspeed: 0.0180s/iter; left time: 253.5340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0765541 Vali Loss: 0.0814060 Test Loss: 0.0868510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0774624\n",
      "\tspeed: 0.0379s/iter; left time: 528.8624s\n",
      "\titers: 200, epoch: 38 | loss: 0.0765092\n",
      "\tspeed: 0.0180s/iter; left time: 249.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.0765164 Vali Loss: 0.0814066 Test Loss: 0.0870728\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0766422\n",
      "\tspeed: 0.0387s/iter; left time: 531.8544s\n",
      "\titers: 200, epoch: 39 | loss: 0.0785535\n",
      "\tspeed: 0.0204s/iter; left time: 278.2109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 223 | Train Loss: 0.0765010 Vali Loss: 0.0812689 Test Loss: 0.0869280\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02109212428331375, rmse:0.14523127675056458, mae:0.08711174875497818, rse:0.5496454238891602\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1449288\n",
      "\tspeed: 0.0237s/iter; left time: 527.1092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275386\n",
      "\tspeed: 0.0189s/iter; left time: 416.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.1514120 Vali Loss: 0.1083481 Test Loss: 0.1111070\n",
      "Validation loss decreased (inf --> 0.108348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964038\n",
      "\tspeed: 0.0406s/iter; left time: 891.5062s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950081\n",
      "\tspeed: 0.0182s/iter; left time: 397.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 223 | Train Loss: 0.0995364 Vali Loss: 0.0861125 Test Loss: 0.0903715\n",
      "Validation loss decreased (0.108348 --> 0.086113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903619\n",
      "\tspeed: 0.0439s/iter; left time: 955.2516s\n",
      "\titers: 200, epoch: 3 | loss: 0.0892618\n",
      "\tspeed: 0.0180s/iter; left time: 388.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0891035 Vali Loss: 0.0844135 Test Loss: 0.0887872\n",
      "Validation loss decreased (0.086113 --> 0.084413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0915347\n",
      "\tspeed: 0.0401s/iter; left time: 863.5181s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848709\n",
      "\tspeed: 0.0179s/iter; left time: 384.2669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0866611 Vali Loss: 0.0836004 Test Loss: 0.0878691\n",
      "Validation loss decreased (0.084413 --> 0.083600).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874841\n",
      "\tspeed: 0.0425s/iter; left time: 906.4325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0879956\n",
      "\tspeed: 0.0203s/iter; left time: 430.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 223 | Train Loss: 0.0851195 Vali Loss: 0.0828480 Test Loss: 0.0873044\n",
      "Validation loss decreased (0.083600 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839838\n",
      "\tspeed: 0.0420s/iter; left time: 885.0919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821068\n",
      "\tspeed: 0.0179s/iter; left time: 375.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0839008 Vali Loss: 0.0822585 Test Loss: 0.0870409\n",
      "Validation loss decreased (0.082848 --> 0.082259).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821517\n",
      "\tspeed: 0.0422s/iter; left time: 879.5556s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844231\n",
      "\tspeed: 0.0184s/iter; left time: 381.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0830070 Vali Loss: 0.0822771 Test Loss: 0.0872937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803021\n",
      "\tspeed: 0.0392s/iter; left time: 809.3280s\n",
      "\titers: 200, epoch: 8 | loss: 0.0812417\n",
      "\tspeed: 0.0180s/iter; left time: 368.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0822285 Vali Loss: 0.0821905 Test Loss: 0.0874587\n",
      "Validation loss decreased (0.082259 --> 0.082190).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808798\n",
      "\tspeed: 0.0417s/iter; left time: 851.4096s\n",
      "\titers: 200, epoch: 9 | loss: 0.0797862\n",
      "\tspeed: 0.0180s/iter; left time: 364.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.0815818 Vali Loss: 0.0818749 Test Loss: 0.0877508\n",
      "Validation loss decreased (0.082190 --> 0.081875).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799902\n",
      "\tspeed: 0.0440s/iter; left time: 888.7792s\n",
      "\titers: 200, epoch: 10 | loss: 0.0788336\n",
      "\tspeed: 0.0186s/iter; left time: 372.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 223 | Train Loss: 0.0810375 Vali Loss: 0.0815037 Test Loss: 0.0872590\n",
      "Validation loss decreased (0.081875 --> 0.081504).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795319\n",
      "\tspeed: 0.0391s/iter; left time: 780.5435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794025\n",
      "\tspeed: 0.0180s/iter; left time: 357.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.0806232 Vali Loss: 0.0819767 Test Loss: 0.0874538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821759\n",
      "\tspeed: 0.0420s/iter; left time: 829.3506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778371\n",
      "\tspeed: 0.0198s/iter; left time: 388.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 223 | Train Loss: 0.0801564 Vali Loss: 0.0814462 Test Loss: 0.0873747\n",
      "Validation loss decreased (0.081504 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0842263\n",
      "\tspeed: 0.0417s/iter; left time: 814.4622s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809889\n",
      "\tspeed: 0.0182s/iter; left time: 352.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0797804 Vali Loss: 0.0816962 Test Loss: 0.0877320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0751703\n",
      "\tspeed: 0.0421s/iter; left time: 811.9402s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763598\n",
      "\tspeed: 0.0207s/iter; left time: 397.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0794535 Vali Loss: 0.0814359 Test Loss: 0.0876379\n",
      "Validation loss decreased (0.081446 --> 0.081436).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0789681\n",
      "\tspeed: 0.0400s/iter; left time: 763.7075s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766760\n",
      "\tspeed: 0.0180s/iter; left time: 342.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0791543 Vali Loss: 0.0809303 Test Loss: 0.0873543\n",
      "Validation loss decreased (0.081436 --> 0.080930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803362\n",
      "\tspeed: 0.0399s/iter; left time: 753.0844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774697\n",
      "\tspeed: 0.0182s/iter; left time: 341.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0788688 Vali Loss: 0.0816369 Test Loss: 0.0876021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0793249\n",
      "\tspeed: 0.0407s/iter; left time: 757.9852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790591\n",
      "\tspeed: 0.0200s/iter; left time: 370.2881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 223 | Train Loss: 0.0786432 Vali Loss: 0.0810094 Test Loss: 0.0877025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0760391\n",
      "\tspeed: 0.0409s/iter; left time: 753.7718s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795988\n",
      "\tspeed: 0.0204s/iter; left time: 374.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 223 | Train Loss: 0.0784823 Vali Loss: 0.0814446 Test Loss: 0.0877750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0790216\n",
      "\tspeed: 0.0412s/iter; left time: 749.6815s\n",
      "\titers: 200, epoch: 19 | loss: 0.0839612\n",
      "\tspeed: 0.0182s/iter; left time: 328.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 223 | Train Loss: 0.0782333 Vali Loss: 0.0810218 Test Loss: 0.0872108\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764522\n",
      "\tspeed: 0.0399s/iter; left time: 716.8600s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756822\n",
      "\tspeed: 0.0180s/iter; left time: 321.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0780890 Vali Loss: 0.0807879 Test Loss: 0.0873520\n",
      "Validation loss decreased (0.080930 --> 0.080788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766985\n",
      "\tspeed: 0.0389s/iter; left time: 689.3043s\n",
      "\titers: 200, epoch: 21 | loss: 0.0789640\n",
      "\tspeed: 0.0181s/iter; left time: 319.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0778664 Vali Loss: 0.0809161 Test Loss: 0.0873467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0807523\n",
      "\tspeed: 0.0377s/iter; left time: 660.2344s\n",
      "\titers: 200, epoch: 22 | loss: 0.0760726\n",
      "\tspeed: 0.0180s/iter; left time: 313.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0777179 Vali Loss: 0.0807275 Test Loss: 0.0872172\n",
      "Validation loss decreased (0.080788 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772732\n",
      "\tspeed: 0.0393s/iter; left time: 680.4143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0791408\n",
      "\tspeed: 0.0183s/iter; left time: 314.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.0775855 Vali Loss: 0.0809376 Test Loss: 0.0875355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0792675\n",
      "\tspeed: 0.0397s/iter; left time: 677.4338s\n",
      "\titers: 200, epoch: 24 | loss: 0.0806082\n",
      "\tspeed: 0.0195s/iter; left time: 331.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 223 | Train Loss: 0.0774288 Vali Loss: 0.0809761 Test Loss: 0.0873712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0786049\n",
      "\tspeed: 0.0395s/iter; left time: 665.1974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782466\n",
      "\tspeed: 0.0180s/iter; left time: 301.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.0773741 Vali Loss: 0.0809126 Test Loss: 0.0873566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0797315\n",
      "\tspeed: 0.0417s/iter; left time: 694.0438s\n",
      "\titers: 200, epoch: 26 | loss: 0.0777119\n",
      "\tspeed: 0.0210s/iter; left time: 347.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 223 | Train Loss: 0.0772352 Vali Loss: 0.0808808 Test Loss: 0.0872862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0776568\n",
      "\tspeed: 0.0410s/iter; left time: 671.8824s\n",
      "\titers: 200, epoch: 27 | loss: 0.0756376\n",
      "\tspeed: 0.0179s/iter; left time: 291.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 223 | Train Loss: 0.0771665 Vali Loss: 0.0809822 Test Loss: 0.0873216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762978\n",
      "\tspeed: 0.0376s/iter; left time: 608.6421s\n",
      "\titers: 200, epoch: 28 | loss: 0.0765274\n",
      "\tspeed: 0.0178s/iter; left time: 286.6605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.0770732 Vali Loss: 0.0810418 Test Loss: 0.0872446\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0719681\n",
      "\tspeed: 0.0379s/iter; left time: 605.4086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788069\n",
      "\tspeed: 0.0182s/iter; left time: 288.8801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0769719 Vali Loss: 0.0809646 Test Loss: 0.0873285\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0789183\n",
      "\tspeed: 0.0404s/iter; left time: 635.3260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782066\n",
      "\tspeed: 0.0180s/iter; left time: 281.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 223 | Train Loss: 0.0769468 Vali Loss: 0.0807314 Test Loss: 0.0870685\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0808447\n",
      "\tspeed: 0.0380s/iter; left time: 589.4340s\n",
      "\titers: 200, epoch: 31 | loss: 0.0765283\n",
      "\tspeed: 0.0181s/iter; left time: 278.3549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.0768495 Vali Loss: 0.0806943 Test Loss: 0.0872749\n",
      "Validation loss decreased (0.080727 --> 0.080694).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761573\n",
      "\tspeed: 0.0438s/iter; left time: 668.9799s\n",
      "\titers: 200, epoch: 32 | loss: 0.0757153\n",
      "\tspeed: 0.0182s/iter; left time: 276.4012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 223 | Train Loss: 0.0768053 Vali Loss: 0.0808349 Test Loss: 0.0872295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775786\n",
      "\tspeed: 0.0419s/iter; left time: 631.6551s\n",
      "\titers: 200, epoch: 33 | loss: 0.0767409\n",
      "\tspeed: 0.0190s/iter; left time: 283.6921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 223 | Train Loss: 0.0767355 Vali Loss: 0.0808667 Test Loss: 0.0871681\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0757100\n",
      "\tspeed: 0.0388s/iter; left time: 576.0192s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774558\n",
      "\tspeed: 0.0180s/iter; left time: 265.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 223 | Train Loss: 0.0767543 Vali Loss: 0.0808929 Test Loss: 0.0871076\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778735\n",
      "\tspeed: 0.0407s/iter; left time: 594.7343s\n",
      "\titers: 200, epoch: 35 | loss: 0.0775153\n",
      "\tspeed: 0.0189s/iter; left time: 274.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 223 | Train Loss: 0.0766747 Vali Loss: 0.0807420 Test Loss: 0.0872145\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0747025\n",
      "\tspeed: 0.0386s/iter; left time: 555.6579s\n",
      "\titers: 200, epoch: 36 | loss: 0.0751638\n",
      "\tspeed: 0.0182s/iter; left time: 260.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766659 Vali Loss: 0.0808573 Test Loss: 0.0873167\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0759581\n",
      "\tspeed: 0.0399s/iter; left time: 565.5094s\n",
      "\titers: 200, epoch: 37 | loss: 0.0804632\n",
      "\tspeed: 0.0189s/iter; left time: 265.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 223 | Train Loss: 0.0766658 Vali Loss: 0.0808365 Test Loss: 0.0872206\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0759550\n",
      "\tspeed: 0.0397s/iter; left time: 554.0831s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777812\n",
      "\tspeed: 0.0181s/iter; left time: 251.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.0766106 Vali Loss: 0.0808862 Test Loss: 0.0872444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0806029\n",
      "\tspeed: 0.0399s/iter; left time: 548.0181s\n",
      "\titers: 200, epoch: 39 | loss: 0.0741781\n",
      "\tspeed: 0.0183s/iter; left time: 248.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.0765723 Vali Loss: 0.0807692 Test Loss: 0.0871365\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0759363\n",
      "\tspeed: 0.0406s/iter; left time: 548.8343s\n",
      "\titers: 200, epoch: 40 | loss: 0.0809224\n",
      "\tspeed: 0.0184s/iter; left time: 246.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 223 | Train Loss: 0.0764995 Vali Loss: 0.0808269 Test Loss: 0.0872263\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0751095\n",
      "\tspeed: 0.0400s/iter; left time: 531.8427s\n",
      "\titers: 200, epoch: 41 | loss: 0.0726962\n",
      "\tspeed: 0.0206s/iter; left time: 271.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 223 | Train Loss: 0.0764408 Vali Loss: 0.0807421 Test Loss: 0.0871634\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020868754014372826, rmse:0.14446021616458893, mae:0.08727487176656723, rse:0.5467272400856018\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:06.28s\n",
      "Intermediate time for IT: 00h:27m:20.07s\n",
      "Total time: 02h:04m:37.46s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1448  0.0877\n",
       "        96            0.0377  0.1941  0.1283\n",
       "        168           0.0393  0.1981  0.1339\n",
       "ES      24            0.0098  0.0988  0.0592\n",
       "        96            0.0185  0.1361  0.0861\n",
       "        168           0.0207  0.1439  0.0916\n",
       "FR      24            0.0100  0.1000  0.0548\n",
       "        96            0.0193  0.1390  0.0808\n",
       "        168           0.0213  0.1460  0.0868\n",
       "GB      24            0.0250  0.1582  0.0996\n",
       "        96            0.0418  0.2045  0.1395\n",
       "        168           0.0447  0.2115  0.1468\n",
       "IT      24            0.0101  0.1004  0.0567\n",
       "        96            0.0188  0.1371  0.0807\n",
       "        168           0.0210  0.1448  0.0872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
