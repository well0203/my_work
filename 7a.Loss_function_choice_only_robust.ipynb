{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8668807\n",
      "\tspeed: 0.0673s/iter; left time: 603.4237s\n",
      "\titers: 200, epoch: 1 | loss: 0.7329679\n",
      "\tspeed: 0.0405s/iter; left time: 359.0980s\n",
      "\titers: 300, epoch: 1 | loss: 0.5921891\n",
      "\tspeed: 0.0404s/iter; left time: 353.7675s\n",
      "\titers: 400, epoch: 1 | loss: 0.5284466\n",
      "\tspeed: 0.0405s/iter; left time: 350.3841s\n",
      "\titers: 500, epoch: 1 | loss: 0.4583203\n",
      "\tspeed: 0.0400s/iter; left time: 342.6730s\n",
      "\titers: 600, epoch: 1 | loss: 0.4369217\n",
      "\tspeed: 0.0405s/iter; left time: 342.5500s\n",
      "\titers: 700, epoch: 1 | loss: 0.6045229\n",
      "\tspeed: 0.0403s/iter; left time: 337.2507s\n",
      "\titers: 800, epoch: 1 | loss: 0.4428935\n",
      "\tspeed: 0.0402s/iter; left time: 332.0334s\n",
      "\titers: 900, epoch: 1 | loss: 0.3517039\n",
      "\tspeed: 0.0404s/iter; left time: 330.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.5982595 Vali Loss: 0.5633035 Test Loss: 0.6410481\n",
      "Validation loss decreased (inf --> 0.563303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2530900\n",
      "\tspeed: 0.0971s/iter; left time: 782.5207s\n",
      "\titers: 200, epoch: 2 | loss: 0.4280434\n",
      "\tspeed: 0.0404s/iter; left time: 321.6280s\n",
      "\titers: 300, epoch: 2 | loss: 0.2945775\n",
      "\tspeed: 0.0403s/iter; left time: 316.1732s\n",
      "\titers: 400, epoch: 2 | loss: 0.3808749\n",
      "\tspeed: 0.0405s/iter; left time: 313.8016s\n",
      "\titers: 500, epoch: 2 | loss: 0.2412574\n",
      "\tspeed: 0.0403s/iter; left time: 308.6059s\n",
      "\titers: 600, epoch: 2 | loss: 0.2762078\n",
      "\tspeed: 0.0406s/iter; left time: 306.3896s\n",
      "\titers: 700, epoch: 2 | loss: 0.2622375\n",
      "\tspeed: 0.0407s/iter; left time: 303.5380s\n",
      "\titers: 800, epoch: 2 | loss: 0.3842992\n",
      "\tspeed: 0.0403s/iter; left time: 296.4802s\n",
      "\titers: 900, epoch: 2 | loss: 0.2897162\n",
      "\tspeed: 0.0404s/iter; left time: 293.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.3337178 Vali Loss: 0.4458787 Test Loss: 0.5076840\n",
      "Validation loss decreased (0.563303 --> 0.445879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3126185\n",
      "\tspeed: 0.0982s/iter; left time: 701.9712s\n",
      "\titers: 200, epoch: 3 | loss: 0.2431651\n",
      "\tspeed: 0.0405s/iter; left time: 285.5208s\n",
      "\titers: 300, epoch: 3 | loss: 0.2869850\n",
      "\tspeed: 0.0405s/iter; left time: 281.6171s\n",
      "\titers: 400, epoch: 3 | loss: 0.2651891\n",
      "\tspeed: 0.0403s/iter; left time: 275.8240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3693432\n",
      "\tspeed: 0.0402s/iter; left time: 271.3797s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180302\n",
      "\tspeed: 0.0405s/iter; left time: 269.1318s\n",
      "\titers: 700, epoch: 3 | loss: 0.2797669\n",
      "\tspeed: 0.0402s/iter; left time: 263.5501s\n",
      "\titers: 800, epoch: 3 | loss: 0.2634023\n",
      "\tspeed: 0.0406s/iter; left time: 261.9609s\n",
      "\titers: 900, epoch: 3 | loss: 0.2757514\n",
      "\tspeed: 0.0402s/iter; left time: 255.0208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.2798561 Vali Loss: 0.4500093 Test Loss: 0.4852419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2148001\n",
      "\tspeed: 0.0944s/iter; left time: 589.4222s\n",
      "\titers: 200, epoch: 4 | loss: 0.2167519\n",
      "\tspeed: 0.0405s/iter; left time: 248.5377s\n",
      "\titers: 300, epoch: 4 | loss: 0.2506799\n",
      "\tspeed: 0.0403s/iter; left time: 243.5628s\n",
      "\titers: 400, epoch: 4 | loss: 0.1949622\n",
      "\tspeed: 0.0404s/iter; left time: 239.9481s\n",
      "\titers: 500, epoch: 4 | loss: 0.2937187\n",
      "\tspeed: 0.0404s/iter; left time: 236.1850s\n",
      "\titers: 600, epoch: 4 | loss: 0.2424507\n",
      "\tspeed: 0.0405s/iter; left time: 232.3714s\n",
      "\titers: 700, epoch: 4 | loss: 0.2249872\n",
      "\tspeed: 0.0403s/iter; left time: 227.2137s\n",
      "\titers: 800, epoch: 4 | loss: 0.2772225\n",
      "\tspeed: 0.0405s/iter; left time: 224.2411s\n",
      "\titers: 900, epoch: 4 | loss: 0.2324552\n",
      "\tspeed: 0.0404s/iter; left time: 219.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2384659 Vali Loss: 0.4899858 Test Loss: 0.5276760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1861539\n",
      "\tspeed: 0.0940s/iter; left time: 501.9400s\n",
      "\titers: 200, epoch: 5 | loss: 0.2107085\n",
      "\tspeed: 0.0403s/iter; left time: 210.9640s\n",
      "\titers: 300, epoch: 5 | loss: 0.1716803\n",
      "\tspeed: 0.0402s/iter; left time: 206.6052s\n",
      "\titers: 400, epoch: 5 | loss: 0.2353648\n",
      "\tspeed: 0.0404s/iter; left time: 203.5182s\n",
      "\titers: 500, epoch: 5 | loss: 0.1783587\n",
      "\tspeed: 0.0404s/iter; left time: 199.5351s\n",
      "\titers: 600, epoch: 5 | loss: 0.2087311\n",
      "\tspeed: 0.0404s/iter; left time: 195.4852s\n",
      "\titers: 700, epoch: 5 | loss: 0.1905097\n",
      "\tspeed: 0.0405s/iter; left time: 192.0042s\n",
      "\titers: 800, epoch: 5 | loss: 0.2120116\n",
      "\tspeed: 0.0402s/iter; left time: 186.3854s\n",
      "\titers: 900, epoch: 5 | loss: 0.2095568\n",
      "\tspeed: 0.0402s/iter; left time: 182.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.79s\n",
      "Steps: 906 | Train Loss: 0.1973772 Vali Loss: 0.4915508 Test Loss: 0.5555537\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5078262686729431, rmse:0.7126193046569824, mae:0.4996413290500641, rse:0.5639931559562683\n",
      "Original data scale mse:20262616.0, rmse:4501.4013671875, mae:3016.667236328125, rse:0.22381876409053802\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7432261\n",
      "\tspeed: 0.0427s/iter; left time: 382.1884s\n",
      "\titers: 200, epoch: 1 | loss: 0.6501400\n",
      "\tspeed: 0.0404s/iter; left time: 357.8385s\n",
      "\titers: 300, epoch: 1 | loss: 0.6982846\n",
      "\tspeed: 0.0403s/iter; left time: 353.4222s\n",
      "\titers: 400, epoch: 1 | loss: 0.6108430\n",
      "\tspeed: 0.0404s/iter; left time: 350.0209s\n",
      "\titers: 500, epoch: 1 | loss: 0.5608808\n",
      "\tspeed: 0.0403s/iter; left time: 345.2628s\n",
      "\titers: 600, epoch: 1 | loss: 0.4887934\n",
      "\tspeed: 0.0404s/iter; left time: 342.1140s\n",
      "\titers: 700, epoch: 1 | loss: 0.4168018\n",
      "\tspeed: 0.0406s/iter; left time: 339.4105s\n",
      "\titers: 800, epoch: 1 | loss: 0.5055439\n",
      "\tspeed: 0.0404s/iter; left time: 333.8429s\n",
      "\titers: 900, epoch: 1 | loss: 0.4256987\n",
      "\tspeed: 0.0403s/iter; left time: 329.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.6086861 Vali Loss: 0.5567614 Test Loss: 0.6454746\n",
      "Validation loss decreased (inf --> 0.556761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3540336\n",
      "\tspeed: 0.0972s/iter; left time: 783.0109s\n",
      "\titers: 200, epoch: 2 | loss: 0.3325537\n",
      "\tspeed: 0.0401s/iter; left time: 318.8347s\n",
      "\titers: 300, epoch: 2 | loss: 0.2796101\n",
      "\tspeed: 0.0405s/iter; left time: 317.8302s\n",
      "\titers: 400, epoch: 2 | loss: 0.2513244\n",
      "\tspeed: 0.0404s/iter; left time: 313.1821s\n",
      "\titers: 500, epoch: 2 | loss: 0.3176331\n",
      "\tspeed: 0.0404s/iter; left time: 309.0425s\n",
      "\titers: 600, epoch: 2 | loss: 0.3459046\n",
      "\tspeed: 0.0395s/iter; left time: 298.5772s\n",
      "\titers: 700, epoch: 2 | loss: 0.3034120\n",
      "\tspeed: 0.0404s/iter; left time: 301.2939s\n",
      "\titers: 800, epoch: 2 | loss: 0.2387425\n",
      "\tspeed: 0.0404s/iter; left time: 297.1110s\n",
      "\titers: 900, epoch: 2 | loss: 0.3125600\n",
      "\tspeed: 0.0404s/iter; left time: 293.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3379571 Vali Loss: 0.4827415 Test Loss: 0.5245702\n",
      "Validation loss decreased (0.556761 --> 0.482742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3740808\n",
      "\tspeed: 0.0974s/iter; left time: 695.9911s\n",
      "\titers: 200, epoch: 3 | loss: 0.2651302\n",
      "\tspeed: 0.0399s/iter; left time: 281.5943s\n",
      "\titers: 300, epoch: 3 | loss: 0.2314308\n",
      "\tspeed: 0.0403s/iter; left time: 279.7871s\n",
      "\titers: 400, epoch: 3 | loss: 0.2778544\n",
      "\tspeed: 0.0400s/iter; left time: 274.2782s\n",
      "\titers: 500, epoch: 3 | loss: 0.2816418\n",
      "\tspeed: 0.0399s/iter; left time: 268.9686s\n",
      "\titers: 600, epoch: 3 | loss: 0.2536219\n",
      "\tspeed: 0.0403s/iter; left time: 268.2218s\n",
      "\titers: 700, epoch: 3 | loss: 0.3004388\n",
      "\tspeed: 0.0403s/iter; left time: 263.6812s\n",
      "\titers: 800, epoch: 3 | loss: 0.3086251\n",
      "\tspeed: 0.0405s/iter; left time: 261.0282s\n",
      "\titers: 900, epoch: 3 | loss: 0.2157228\n",
      "\tspeed: 0.0403s/iter; left time: 255.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.70s\n",
      "Steps: 906 | Train Loss: 0.2835519 Vali Loss: 0.4392605 Test Loss: 0.4886339\n",
      "Validation loss decreased (0.482742 --> 0.439261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2430649\n",
      "\tspeed: 0.0986s/iter; left time: 615.6682s\n",
      "\titers: 200, epoch: 4 | loss: 0.2590898\n",
      "\tspeed: 0.0405s/iter; left time: 248.6634s\n",
      "\titers: 300, epoch: 4 | loss: 0.3631294\n",
      "\tspeed: 0.0404s/iter; left time: 244.4230s\n",
      "\titers: 400, epoch: 4 | loss: 0.2209840\n",
      "\tspeed: 0.0404s/iter; left time: 240.3825s\n",
      "\titers: 500, epoch: 4 | loss: 0.2981814\n",
      "\tspeed: 0.0405s/iter; left time: 236.5645s\n",
      "\titers: 600, epoch: 4 | loss: 0.2587925\n",
      "\tspeed: 0.0403s/iter; left time: 231.2822s\n",
      "\titers: 700, epoch: 4 | loss: 0.2709548\n",
      "\tspeed: 0.0404s/iter; left time: 228.1746s\n",
      "\titers: 800, epoch: 4 | loss: 0.1581628\n",
      "\tspeed: 0.0405s/iter; left time: 224.4186s\n",
      "\titers: 900, epoch: 4 | loss: 0.1487662\n",
      "\tspeed: 0.0403s/iter; left time: 219.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.2429381 Vali Loss: 0.4431614 Test Loss: 0.4938792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2189480\n",
      "\tspeed: 0.0947s/iter; left time: 505.5520s\n",
      "\titers: 200, epoch: 5 | loss: 0.1875956\n",
      "\tspeed: 0.0402s/iter; left time: 210.5467s\n",
      "\titers: 300, epoch: 5 | loss: 0.1857948\n",
      "\tspeed: 0.0403s/iter; left time: 207.2118s\n",
      "\titers: 400, epoch: 5 | loss: 0.2114488\n",
      "\tspeed: 0.0402s/iter; left time: 202.6285s\n",
      "\titers: 500, epoch: 5 | loss: 0.1357018\n",
      "\tspeed: 0.0402s/iter; left time: 198.7106s\n",
      "\titers: 600, epoch: 5 | loss: 0.2276186\n",
      "\tspeed: 0.0402s/iter; left time: 194.3955s\n",
      "\titers: 700, epoch: 5 | loss: 0.1714303\n",
      "\tspeed: 0.0403s/iter; left time: 191.0944s\n",
      "\titers: 800, epoch: 5 | loss: 0.2150388\n",
      "\tspeed: 0.0403s/iter; left time: 187.0156s\n",
      "\titers: 900, epoch: 5 | loss: 0.1828143\n",
      "\tspeed: 0.0404s/iter; left time: 183.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.74s\n",
      "Steps: 906 | Train Loss: 0.1994748 Vali Loss: 0.4670032 Test Loss: 0.5031238\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1696045\n",
      "\tspeed: 0.0942s/iter; left time: 417.4865s\n",
      "\titers: 200, epoch: 6 | loss: 0.1791843\n",
      "\tspeed: 0.0404s/iter; left time: 175.1407s\n",
      "\titers: 300, epoch: 6 | loss: 0.2508294\n",
      "\tspeed: 0.0399s/iter; left time: 169.0108s\n",
      "\titers: 400, epoch: 6 | loss: 0.1741999\n",
      "\tspeed: 0.0403s/iter; left time: 166.6140s\n",
      "\titers: 500, epoch: 6 | loss: 0.1608908\n",
      "\tspeed: 0.0404s/iter; left time: 162.8106s\n",
      "\titers: 600, epoch: 6 | loss: 0.1402602\n",
      "\tspeed: 0.0403s/iter; left time: 158.4520s\n",
      "\titers: 700, epoch: 6 | loss: 0.1637850\n",
      "\tspeed: 0.0404s/iter; left time: 154.6559s\n",
      "\titers: 800, epoch: 6 | loss: 0.1464395\n",
      "\tspeed: 0.0402s/iter; left time: 150.1100s\n",
      "\titers: 900, epoch: 6 | loss: 0.1418985\n",
      "\tspeed: 0.0404s/iter; left time: 146.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.75s\n",
      "Steps: 906 | Train Loss: 0.1654440 Vali Loss: 0.5088816 Test Loss: 0.5175062\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.48783740401268005, rmse:0.6984536051750183, mae:0.47903192043304443, rse:0.552781879901886\n",
      "Original data scale mse:19436216.0, rmse:4408.65234375, mae:2875.55859375, rse:0.21920709311962128\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0522838\n",
      "\tspeed: 0.0698s/iter; left time: 624.4904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9666416\n",
      "\tspeed: 0.0442s/iter; left time: 390.4553s\n",
      "\titers: 300, epoch: 1 | loss: 0.9245752\n",
      "\tspeed: 0.0456s/iter; left time: 398.5042s\n",
      "\titers: 400, epoch: 1 | loss: 0.7863439\n",
      "\tspeed: 0.0382s/iter; left time: 329.8482s\n",
      "\titers: 500, epoch: 1 | loss: 0.7835494\n",
      "\tspeed: 0.0354s/iter; left time: 302.2317s\n",
      "\titers: 600, epoch: 1 | loss: 0.6639153\n",
      "\tspeed: 0.0396s/iter; left time: 334.2323s\n",
      "\titers: 700, epoch: 1 | loss: 0.6276757\n",
      "\tspeed: 0.0459s/iter; left time: 382.7436s\n",
      "\titers: 800, epoch: 1 | loss: 0.6528488\n",
      "\tspeed: 0.0470s/iter; left time: 387.5212s\n",
      "\titers: 900, epoch: 1 | loss: 0.6513734\n",
      "\tspeed: 0.0399s/iter; left time: 325.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 904 | Train Loss: 0.8170802 Vali Loss: 0.8335947 Test Loss: 1.0375565\n",
      "Validation loss decreased (inf --> 0.833595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5232227\n",
      "\tspeed: 0.1169s/iter; left time: 939.6959s\n",
      "\titers: 200, epoch: 2 | loss: 0.5794776\n",
      "\tspeed: 0.0451s/iter; left time: 357.6566s\n",
      "\titers: 300, epoch: 2 | loss: 0.5255210\n",
      "\tspeed: 0.0450s/iter; left time: 352.9295s\n",
      "\titers: 400, epoch: 2 | loss: 0.4926725\n",
      "\tspeed: 0.0455s/iter; left time: 351.8337s\n",
      "\titers: 500, epoch: 2 | loss: 0.4981970\n",
      "\tspeed: 0.0445s/iter; left time: 339.8742s\n",
      "\titers: 600, epoch: 2 | loss: 0.5888463\n",
      "\tspeed: 0.0439s/iter; left time: 330.8992s\n",
      "\titers: 700, epoch: 2 | loss: 0.4668635\n",
      "\tspeed: 0.0460s/iter; left time: 342.0554s\n",
      "\titers: 800, epoch: 2 | loss: 0.5131143\n",
      "\tspeed: 0.0455s/iter; left time: 333.7505s\n",
      "\titers: 900, epoch: 2 | loss: 0.4530048\n",
      "\tspeed: 0.0448s/iter; left time: 323.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.07s\n",
      "Steps: 904 | Train Loss: 0.5329359 Vali Loss: 0.6914768 Test Loss: 0.8287142\n",
      "Validation loss decreased (0.833595 --> 0.691477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5407680\n",
      "\tspeed: 0.1172s/iter; left time: 835.8656s\n",
      "\titers: 200, epoch: 3 | loss: 0.3946598\n",
      "\tspeed: 0.0452s/iter; left time: 318.2069s\n",
      "\titers: 300, epoch: 3 | loss: 0.3622131\n",
      "\tspeed: 0.0449s/iter; left time: 310.9466s\n",
      "\titers: 400, epoch: 3 | loss: 0.3672664\n",
      "\tspeed: 0.0455s/iter; left time: 310.6133s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548235\n",
      "\tspeed: 0.0453s/iter; left time: 304.7398s\n",
      "\titers: 600, epoch: 3 | loss: 0.4472606\n",
      "\tspeed: 0.0451s/iter; left time: 299.3724s\n",
      "\titers: 700, epoch: 3 | loss: 0.3666580\n",
      "\tspeed: 0.0452s/iter; left time: 294.9799s\n",
      "\titers: 800, epoch: 3 | loss: 0.4022273\n",
      "\tspeed: 0.0458s/iter; left time: 294.3637s\n",
      "\titers: 900, epoch: 3 | loss: 0.4221560\n",
      "\tspeed: 0.0457s/iter; left time: 289.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 904 | Train Loss: 0.4274466 Vali Loss: 0.7251076 Test Loss: 0.8448725\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3476723\n",
      "\tspeed: 0.1126s/iter; left time: 701.1141s\n",
      "\titers: 200, epoch: 4 | loss: 0.3722265\n",
      "\tspeed: 0.0443s/iter; left time: 271.4568s\n",
      "\titers: 300, epoch: 4 | loss: 0.3409472\n",
      "\tspeed: 0.0443s/iter; left time: 267.2037s\n",
      "\titers: 400, epoch: 4 | loss: 0.3054693\n",
      "\tspeed: 0.0448s/iter; left time: 265.7834s\n",
      "\titers: 500, epoch: 4 | loss: 0.4120376\n",
      "\tspeed: 0.0445s/iter; left time: 259.1972s\n",
      "\titers: 600, epoch: 4 | loss: 0.3229454\n",
      "\tspeed: 0.0447s/iter; left time: 256.2150s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860872\n",
      "\tspeed: 0.0449s/iter; left time: 253.0150s\n",
      "\titers: 800, epoch: 4 | loss: 0.3114266\n",
      "\tspeed: 0.0449s/iter; left time: 248.0279s\n",
      "\titers: 900, epoch: 4 | loss: 0.3609830\n",
      "\tspeed: 0.0449s/iter; left time: 243.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 904 | Train Loss: 0.3587939 Vali Loss: 0.7235217 Test Loss: 0.9472639\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992413\n",
      "\tspeed: 0.1118s/iter; left time: 595.4424s\n",
      "\titers: 200, epoch: 5 | loss: 0.3733294\n",
      "\tspeed: 0.0458s/iter; left time: 239.1042s\n",
      "\titers: 300, epoch: 5 | loss: 0.3371202\n",
      "\tspeed: 0.0456s/iter; left time: 233.7635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3143236\n",
      "\tspeed: 0.0449s/iter; left time: 225.8197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918294\n",
      "\tspeed: 0.0457s/iter; left time: 225.0412s\n",
      "\titers: 600, epoch: 5 | loss: 0.2968202\n",
      "\tspeed: 0.0449s/iter; left time: 216.8685s\n",
      "\titers: 700, epoch: 5 | loss: 0.2790029\n",
      "\tspeed: 0.0450s/iter; left time: 212.7395s\n",
      "\titers: 800, epoch: 5 | loss: 0.2449622\n",
      "\tspeed: 0.0455s/iter; left time: 210.4294s\n",
      "\titers: 900, epoch: 5 | loss: 0.2711503\n",
      "\tspeed: 0.0448s/iter; left time: 202.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.20s\n",
      "Steps: 904 | Train Loss: 0.2995826 Vali Loss: 0.7070563 Test Loss: 0.9387065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8277999758720398, rmse:0.909835159778595, mae:0.6767523288726807, rse:0.7216113805770874\n",
      "Original data scale mse:35706256.0, rmse:5975.47119140625, mae:4163.154296875, rse:0.2975805997848511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9143165\n",
      "\tspeed: 0.0474s/iter; left time: 423.6445s\n",
      "\titers: 200, epoch: 1 | loss: 0.8231269\n",
      "\tspeed: 0.0449s/iter; left time: 397.0791s\n",
      "\titers: 300, epoch: 1 | loss: 0.8590661\n",
      "\tspeed: 0.0444s/iter; left time: 388.3046s\n",
      "\titers: 400, epoch: 1 | loss: 0.8273649\n",
      "\tspeed: 0.0451s/iter; left time: 389.4325s\n",
      "\titers: 500, epoch: 1 | loss: 0.8597592\n",
      "\tspeed: 0.0454s/iter; left time: 387.8899s\n",
      "\titers: 600, epoch: 1 | loss: 0.6699688\n",
      "\tspeed: 0.0458s/iter; left time: 386.4275s\n",
      "\titers: 700, epoch: 1 | loss: 0.9264821\n",
      "\tspeed: 0.0456s/iter; left time: 380.5722s\n",
      "\titers: 800, epoch: 1 | loss: 0.6948530\n",
      "\tspeed: 0.0447s/iter; left time: 368.6162s\n",
      "\titers: 900, epoch: 1 | loss: 0.7380019\n",
      "\tspeed: 0.0456s/iter; left time: 371.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.8259976 Vali Loss: 0.8315275 Test Loss: 1.0468974\n",
      "Validation loss decreased (inf --> 0.831528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6546626\n",
      "\tspeed: 0.1156s/iter; left time: 929.4644s\n",
      "\titers: 200, epoch: 2 | loss: 0.6274150\n",
      "\tspeed: 0.0459s/iter; left time: 364.3706s\n",
      "\titers: 300, epoch: 2 | loss: 0.5482291\n",
      "\tspeed: 0.0455s/iter; left time: 356.7141s\n",
      "\titers: 400, epoch: 2 | loss: 0.4350376\n",
      "\tspeed: 0.0458s/iter; left time: 354.2404s\n",
      "\titers: 500, epoch: 2 | loss: 0.4925019\n",
      "\tspeed: 0.0459s/iter; left time: 350.4855s\n",
      "\titers: 600, epoch: 2 | loss: 0.6154686\n",
      "\tspeed: 0.0447s/iter; left time: 336.8049s\n",
      "\titers: 700, epoch: 2 | loss: 0.5049326\n",
      "\tspeed: 0.0456s/iter; left time: 339.4462s\n",
      "\titers: 800, epoch: 2 | loss: 0.5443966\n",
      "\tspeed: 0.0460s/iter; left time: 337.8572s\n",
      "\titers: 900, epoch: 2 | loss: 0.4095918\n",
      "\tspeed: 0.0453s/iter; left time: 328.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.45s\n",
      "Steps: 904 | Train Loss: 0.5347245 Vali Loss: 0.6814697 Test Loss: 0.8716580\n",
      "Validation loss decreased (0.831528 --> 0.681470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4723068\n",
      "\tspeed: 0.1160s/iter; left time: 827.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.5130894\n",
      "\tspeed: 0.0438s/iter; left time: 308.1525s\n",
      "\titers: 300, epoch: 3 | loss: 0.3773848\n",
      "\tspeed: 0.0456s/iter; left time: 316.1904s\n",
      "\titers: 400, epoch: 3 | loss: 0.3935299\n",
      "\tspeed: 0.0460s/iter; left time: 314.1429s\n",
      "\titers: 500, epoch: 3 | loss: 0.4303985\n",
      "\tspeed: 0.0460s/iter; left time: 309.9916s\n",
      "\titers: 600, epoch: 3 | loss: 0.4050925\n",
      "\tspeed: 0.0412s/iter; left time: 273.4273s\n",
      "\titers: 700, epoch: 3 | loss: 0.4072495\n",
      "\tspeed: 0.0398s/iter; left time: 260.2072s\n",
      "\titers: 800, epoch: 3 | loss: 0.4411655\n",
      "\tspeed: 0.0458s/iter; left time: 294.5232s\n",
      "\titers: 900, epoch: 3 | loss: 0.4036132\n",
      "\tspeed: 0.0434s/iter; left time: 275.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.15s\n",
      "Steps: 904 | Train Loss: 0.4316325 Vali Loss: 0.7312940 Test Loss: 0.8559389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3354936\n",
      "\tspeed: 0.1115s/iter; left time: 694.7992s\n",
      "\titers: 200, epoch: 4 | loss: 0.3472808\n",
      "\tspeed: 0.0454s/iter; left time: 278.1378s\n",
      "\titers: 300, epoch: 4 | loss: 0.3451594\n",
      "\tspeed: 0.0450s/iter; left time: 271.2775s\n",
      "\titers: 400, epoch: 4 | loss: 0.3125092\n",
      "\tspeed: 0.0454s/iter; left time: 269.4098s\n",
      "\titers: 500, epoch: 4 | loss: 0.3426646\n",
      "\tspeed: 0.0457s/iter; left time: 266.5422s\n",
      "\titers: 600, epoch: 4 | loss: 0.3740831\n",
      "\tspeed: 0.0455s/iter; left time: 260.7447s\n",
      "\titers: 700, epoch: 4 | loss: 0.3379540\n",
      "\tspeed: 0.0458s/iter; left time: 257.8905s\n",
      "\titers: 800, epoch: 4 | loss: 0.3604316\n",
      "\tspeed: 0.0454s/iter; left time: 251.0800s\n",
      "\titers: 900, epoch: 4 | loss: 0.3078305\n",
      "\tspeed: 0.0457s/iter; left time: 248.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.21s\n",
      "Steps: 904 | Train Loss: 0.3627788 Vali Loss: 0.7563289 Test Loss: 0.9437141\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2672817\n",
      "\tspeed: 0.1122s/iter; left time: 597.6646s\n",
      "\titers: 200, epoch: 5 | loss: 0.3515173\n",
      "\tspeed: 0.0447s/iter; left time: 233.5756s\n",
      "\titers: 300, epoch: 5 | loss: 0.3082839\n",
      "\tspeed: 0.0458s/iter; left time: 234.6070s\n",
      "\titers: 400, epoch: 5 | loss: 0.3019142\n",
      "\tspeed: 0.0457s/iter; left time: 229.6109s\n",
      "\titers: 500, epoch: 5 | loss: 0.3102745\n",
      "\tspeed: 0.0458s/iter; left time: 225.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.2675474\n",
      "\tspeed: 0.0449s/iter; left time: 216.4237s\n",
      "\titers: 700, epoch: 5 | loss: 0.3005226\n",
      "\tspeed: 0.0455s/iter; left time: 215.0300s\n",
      "\titers: 800, epoch: 5 | loss: 0.3071508\n",
      "\tspeed: 0.0455s/iter; left time: 210.5575s\n",
      "\titers: 900, epoch: 5 | loss: 0.2667807\n",
      "\tspeed: 0.0458s/iter; left time: 207.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.3004628 Vali Loss: 0.7473243 Test Loss: 0.9708486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8711569905281067, rmse:0.9333578944206238, mae:0.6843037009239197, rse:0.740267813205719\n",
      "Original data scale mse:38053568.0, rmse:6168.75732421875, mae:4203.2880859375, rse:0.30720630288124084\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8996492\n",
      "\tspeed: 0.0787s/iter; left time: 701.9904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759548\n",
      "\tspeed: 0.0517s/iter; left time: 456.1258s\n",
      "\titers: 300, epoch: 1 | loss: 0.8695518\n",
      "\tspeed: 0.0520s/iter; left time: 453.8458s\n",
      "\titers: 400, epoch: 1 | loss: 0.8800810\n",
      "\tspeed: 0.0522s/iter; left time: 450.3441s\n",
      "\titers: 500, epoch: 1 | loss: 0.8453556\n",
      "\tspeed: 0.0518s/iter; left time: 441.3187s\n",
      "\titers: 600, epoch: 1 | loss: 0.8907446\n",
      "\tspeed: 0.0518s/iter; left time: 435.9889s\n",
      "\titers: 700, epoch: 1 | loss: 0.8326300\n",
      "\tspeed: 0.0516s/iter; left time: 429.5459s\n",
      "\titers: 800, epoch: 1 | loss: 0.7673663\n",
      "\tspeed: 0.0517s/iter; left time: 424.6406s\n",
      "\titers: 900, epoch: 1 | loss: 0.8367926\n",
      "\tspeed: 0.0520s/iter; left time: 422.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.48s\n",
      "Steps: 902 | Train Loss: 0.8779309 Vali Loss: 0.9823749 Test Loss: 1.2618978\n",
      "Validation loss decreased (inf --> 0.982375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8131427\n",
      "\tspeed: 0.1326s/iter; left time: 1063.6001s\n",
      "\titers: 200, epoch: 2 | loss: 0.7040696\n",
      "\tspeed: 0.0497s/iter; left time: 393.6481s\n",
      "\titers: 300, epoch: 2 | loss: 0.7396861\n",
      "\tspeed: 0.0428s/iter; left time: 334.6602s\n",
      "\titers: 400, epoch: 2 | loss: 0.6244543\n",
      "\tspeed: 0.0430s/iter; left time: 331.9070s\n",
      "\titers: 500, epoch: 2 | loss: 0.6054553\n",
      "\tspeed: 0.0463s/iter; left time: 353.0298s\n",
      "\titers: 600, epoch: 2 | loss: 0.4985499\n",
      "\tspeed: 0.0519s/iter; left time: 390.1802s\n",
      "\titers: 700, epoch: 2 | loss: 0.5293226\n",
      "\tspeed: 0.0530s/iter; left time: 393.2366s\n",
      "\titers: 800, epoch: 2 | loss: 0.6061723\n",
      "\tspeed: 0.0533s/iter; left time: 390.2025s\n",
      "\titers: 900, epoch: 2 | loss: 0.4838333\n",
      "\tspeed: 0.0534s/iter; left time: 385.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 902 | Train Loss: 0.6046631 Vali Loss: 0.7293260 Test Loss: 0.8842466\n",
      "Validation loss decreased (0.982375 --> 0.729326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5083361\n",
      "\tspeed: 0.1365s/iter; left time: 971.3485s\n",
      "\titers: 200, epoch: 3 | loss: 0.4712097\n",
      "\tspeed: 0.0533s/iter; left time: 374.3270s\n",
      "\titers: 300, epoch: 3 | loss: 0.4754631\n",
      "\tspeed: 0.0532s/iter; left time: 367.9887s\n",
      "\titers: 400, epoch: 3 | loss: 0.5324599\n",
      "\tspeed: 0.0530s/iter; left time: 361.3296s\n",
      "\titers: 500, epoch: 3 | loss: 0.4271317\n",
      "\tspeed: 0.0535s/iter; left time: 359.1055s\n",
      "\titers: 600, epoch: 3 | loss: 0.4579096\n",
      "\tspeed: 0.0533s/iter; left time: 352.4637s\n",
      "\titers: 700, epoch: 3 | loss: 0.4870133\n",
      "\tspeed: 0.0531s/iter; left time: 346.2658s\n",
      "\titers: 800, epoch: 3 | loss: 0.4459608\n",
      "\tspeed: 0.0530s/iter; left time: 340.3506s\n",
      "\titers: 900, epoch: 3 | loss: 0.4197437\n",
      "\tspeed: 0.0531s/iter; left time: 335.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.29s\n",
      "Steps: 902 | Train Loss: 0.4552675 Vali Loss: 0.7132370 Test Loss: 0.9254080\n",
      "Validation loss decreased (0.729326 --> 0.713237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3725089\n",
      "\tspeed: 0.1332s/iter; left time: 827.6934s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399079\n",
      "\tspeed: 0.0520s/iter; left time: 317.9541s\n",
      "\titers: 300, epoch: 4 | loss: 0.4262986\n",
      "\tspeed: 0.0521s/iter; left time: 313.3517s\n",
      "\titers: 400, epoch: 4 | loss: 0.3951728\n",
      "\tspeed: 0.0520s/iter; left time: 307.5650s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273083\n",
      "\tspeed: 0.0522s/iter; left time: 303.7103s\n",
      "\titers: 600, epoch: 4 | loss: 0.3536602\n",
      "\tspeed: 0.0521s/iter; left time: 297.7363s\n",
      "\titers: 700, epoch: 4 | loss: 0.3747369\n",
      "\tspeed: 0.0522s/iter; left time: 293.0590s\n",
      "\titers: 800, epoch: 4 | loss: 0.3719158\n",
      "\tspeed: 0.0519s/iter; left time: 286.4453s\n",
      "\titers: 900, epoch: 4 | loss: 0.3601287\n",
      "\tspeed: 0.0517s/iter; left time: 279.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3793745 Vali Loss: 0.7713831 Test Loss: 0.9924561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3638352\n",
      "\tspeed: 0.1206s/iter; left time: 640.5111s\n",
      "\titers: 200, epoch: 5 | loss: 0.3390375\n",
      "\tspeed: 0.0483s/iter; left time: 251.7989s\n",
      "\titers: 300, epoch: 5 | loss: 0.3258272\n",
      "\tspeed: 0.0535s/iter; left time: 273.2921s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470738\n",
      "\tspeed: 0.0525s/iter; left time: 263.0954s\n",
      "\titers: 500, epoch: 5 | loss: 0.2690118\n",
      "\tspeed: 0.0520s/iter; left time: 255.2782s\n",
      "\titers: 600, epoch: 5 | loss: 0.3021259\n",
      "\tspeed: 0.0523s/iter; left time: 251.6927s\n",
      "\titers: 700, epoch: 5 | loss: 0.3265553\n",
      "\tspeed: 0.0522s/iter; left time: 245.9541s\n",
      "\titers: 800, epoch: 5 | loss: 0.2861528\n",
      "\tspeed: 0.0524s/iter; left time: 241.7455s\n",
      "\titers: 900, epoch: 5 | loss: 0.2557895\n",
      "\tspeed: 0.0521s/iter; left time: 235.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.14s\n",
      "Steps: 902 | Train Loss: 0.3167043 Vali Loss: 0.7697710 Test Loss: 0.9987172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2949107\n",
      "\tspeed: 0.1321s/iter; left time: 582.7862s\n",
      "\titers: 200, epoch: 6 | loss: 0.3065024\n",
      "\tspeed: 0.0516s/iter; left time: 222.5171s\n",
      "\titers: 300, epoch: 6 | loss: 0.2583741\n",
      "\tspeed: 0.0517s/iter; left time: 217.6677s\n",
      "\titers: 400, epoch: 6 | loss: 0.3096471\n",
      "\tspeed: 0.0524s/iter; left time: 215.2572s\n",
      "\titers: 500, epoch: 6 | loss: 0.2568293\n",
      "\tspeed: 0.0522s/iter; left time: 209.2352s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391598\n",
      "\tspeed: 0.0520s/iter; left time: 203.5548s\n",
      "\titers: 700, epoch: 6 | loss: 0.2993651\n",
      "\tspeed: 0.0520s/iter; left time: 198.0717s\n",
      "\titers: 800, epoch: 6 | loss: 0.2426711\n",
      "\tspeed: 0.0518s/iter; left time: 192.2212s\n",
      "\titers: 900, epoch: 6 | loss: 0.2972760\n",
      "\tspeed: 0.0521s/iter; left time: 188.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.2691092 Vali Loss: 0.8078781 Test Loss: 1.0506176\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9250379204750061, rmse:0.9617888927459717, mae:0.7022790908813477, rse:0.7619071006774902\n",
      "Original data scale mse:41039112.0, rmse:6406.177734375, mae:4328.85498046875, rse:0.3191865384578705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0736581\n",
      "\tspeed: 0.0547s/iter; left time: 487.7330s\n",
      "\titers: 200, epoch: 1 | loss: 0.8831307\n",
      "\tspeed: 0.0522s/iter; left time: 460.6206s\n",
      "\titers: 300, epoch: 1 | loss: 0.8966042\n",
      "\tspeed: 0.0523s/iter; left time: 455.8479s\n",
      "\titers: 400, epoch: 1 | loss: 0.7405317\n",
      "\tspeed: 0.0521s/iter; left time: 449.3282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9314477\n",
      "\tspeed: 0.0521s/iter; left time: 443.8902s\n",
      "\titers: 600, epoch: 1 | loss: 0.7962927\n",
      "\tspeed: 0.0525s/iter; left time: 441.8787s\n",
      "\titers: 700, epoch: 1 | loss: 0.7819531\n",
      "\tspeed: 0.0524s/iter; left time: 435.6598s\n",
      "\titers: 800, epoch: 1 | loss: 0.7549212\n",
      "\tspeed: 0.0521s/iter; left time: 428.0254s\n",
      "\titers: 900, epoch: 1 | loss: 0.7729616\n",
      "\tspeed: 0.0524s/iter; left time: 425.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.47s\n",
      "Steps: 902 | Train Loss: 0.8827498 Vali Loss: 0.9831725 Test Loss: 1.2678595\n",
      "Validation loss decreased (inf --> 0.983173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6917587\n",
      "\tspeed: 0.1354s/iter; left time: 1085.6047s\n",
      "\titers: 200, epoch: 2 | loss: 0.6385450\n",
      "\tspeed: 0.0521s/iter; left time: 412.4727s\n",
      "\titers: 300, epoch: 2 | loss: 0.6272208\n",
      "\tspeed: 0.0523s/iter; left time: 408.7638s\n",
      "\titers: 400, epoch: 2 | loss: 0.5154302\n",
      "\tspeed: 0.0522s/iter; left time: 402.9912s\n",
      "\titers: 500, epoch: 2 | loss: 0.5767449\n",
      "\tspeed: 0.0520s/iter; left time: 396.1645s\n",
      "\titers: 600, epoch: 2 | loss: 0.5526741\n",
      "\tspeed: 0.0521s/iter; left time: 391.6103s\n",
      "\titers: 700, epoch: 2 | loss: 0.5340019\n",
      "\tspeed: 0.0524s/iter; left time: 388.6995s\n",
      "\titers: 800, epoch: 2 | loss: 0.4381602\n",
      "\tspeed: 0.0523s/iter; left time: 382.7091s\n",
      "\titers: 900, epoch: 2 | loss: 0.4901657\n",
      "\tspeed: 0.0520s/iter; left time: 375.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.6127766 Vali Loss: 0.7626251 Test Loss: 0.8730339\n",
      "Validation loss decreased (0.983173 --> 0.762625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4595468\n",
      "\tspeed: 0.1350s/iter; left time: 961.0225s\n",
      "\titers: 200, epoch: 3 | loss: 0.5015832\n",
      "\tspeed: 0.0525s/iter; left time: 368.0779s\n",
      "\titers: 300, epoch: 3 | loss: 0.5812056\n",
      "\tspeed: 0.0535s/iter; left time: 370.0502s\n",
      "\titers: 400, epoch: 3 | loss: 0.4741263\n",
      "\tspeed: 0.0535s/iter; left time: 365.0458s\n",
      "\titers: 500, epoch: 3 | loss: 0.4783198\n",
      "\tspeed: 0.0526s/iter; left time: 353.2985s\n",
      "\titers: 600, epoch: 3 | loss: 0.4453655\n",
      "\tspeed: 0.0523s/iter; left time: 346.2737s\n",
      "\titers: 700, epoch: 3 | loss: 0.4122199\n",
      "\tspeed: 0.0524s/iter; left time: 341.2192s\n",
      "\titers: 800, epoch: 3 | loss: 0.3615236\n",
      "\tspeed: 0.0523s/iter; left time: 335.7206s\n",
      "\titers: 900, epoch: 3 | loss: 0.4355072\n",
      "\tspeed: 0.0524s/iter; left time: 330.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.75s\n",
      "Steps: 902 | Train Loss: 0.4525444 Vali Loss: 0.7806315 Test Loss: 0.9514728\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4056771\n",
      "\tspeed: 0.1313s/iter; left time: 815.7809s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399343\n",
      "\tspeed: 0.0524s/iter; left time: 320.5630s\n",
      "\titers: 300, epoch: 4 | loss: 0.3804121\n",
      "\tspeed: 0.0523s/iter; left time: 314.8131s\n",
      "\titers: 400, epoch: 4 | loss: 0.3706331\n",
      "\tspeed: 0.0521s/iter; left time: 308.2799s\n",
      "\titers: 500, epoch: 4 | loss: 0.3810227\n",
      "\tspeed: 0.0521s/iter; left time: 302.8650s\n",
      "\titers: 600, epoch: 4 | loss: 0.3974872\n",
      "\tspeed: 0.0520s/iter; left time: 297.2622s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429693\n",
      "\tspeed: 0.0518s/iter; left time: 290.8053s\n",
      "\titers: 800, epoch: 4 | loss: 0.3861212\n",
      "\tspeed: 0.0523s/iter; left time: 288.6178s\n",
      "\titers: 900, epoch: 4 | loss: 0.3614337\n",
      "\tspeed: 0.0526s/iter; left time: 284.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.3713848 Vali Loss: 0.7981377 Test Loss: 0.9633971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2858317\n",
      "\tspeed: 0.1316s/iter; left time: 699.2135s\n",
      "\titers: 200, epoch: 5 | loss: 0.3296789\n",
      "\tspeed: 0.0520s/iter; left time: 271.1108s\n",
      "\titers: 300, epoch: 5 | loss: 0.3004401\n",
      "\tspeed: 0.0526s/iter; left time: 268.9181s\n",
      "\titers: 400, epoch: 5 | loss: 0.3365834\n",
      "\tspeed: 0.0523s/iter; left time: 262.1584s\n",
      "\titers: 500, epoch: 5 | loss: 0.3448044\n",
      "\tspeed: 0.0525s/iter; left time: 257.8601s\n",
      "\titers: 600, epoch: 5 | loss: 0.2779492\n",
      "\tspeed: 0.0523s/iter; left time: 251.4926s\n",
      "\titers: 700, epoch: 5 | loss: 0.2858480\n",
      "\tspeed: 0.0521s/iter; left time: 245.5894s\n",
      "\titers: 800, epoch: 5 | loss: 0.2892428\n",
      "\tspeed: 0.0517s/iter; left time: 238.6400s\n",
      "\titers: 900, epoch: 5 | loss: 0.2999575\n",
      "\tspeed: 0.0521s/iter; left time: 235.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.3065489 Vali Loss: 0.8347104 Test Loss: 1.0182045\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8725519180297852, rmse:0.934104859828949, mae:0.6941571831703186, rse:0.7399765253067017\n",
      "Original data scale mse:37693112.0, rmse:6139.4716796875, mae:4274.00537109375, rse:0.30589795112609863\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9276407\n",
      "\tspeed: 0.0690s/iter; left time: 618.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.8493971\n",
      "\tspeed: 0.0404s/iter; left time: 357.9302s\n",
      "\titers: 300, epoch: 1 | loss: 0.7614538\n",
      "\tspeed: 0.0404s/iter; left time: 354.0471s\n",
      "\titers: 400, epoch: 1 | loss: 0.7148305\n",
      "\tspeed: 0.0404s/iter; left time: 350.0871s\n",
      "\titers: 500, epoch: 1 | loss: 0.6615688\n",
      "\tspeed: 0.0404s/iter; left time: 346.2570s\n",
      "\titers: 600, epoch: 1 | loss: 0.6439044\n",
      "\tspeed: 0.0405s/iter; left time: 343.0893s\n",
      "\titers: 700, epoch: 1 | loss: 0.7704166\n",
      "\tspeed: 0.0404s/iter; left time: 338.1821s\n",
      "\titers: 800, epoch: 1 | loss: 0.6550638\n",
      "\tspeed: 0.0402s/iter; left time: 332.3747s\n",
      "\titers: 900, epoch: 1 | loss: 0.5864573\n",
      "\tspeed: 0.0403s/iter; left time: 328.5380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.7567487 Vali Loss: 0.5543883 Test Loss: 0.6288404\n",
      "Validation loss decreased (inf --> 0.554388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4949431\n",
      "\tspeed: 0.1025s/iter; left time: 825.6501s\n",
      "\titers: 200, epoch: 2 | loss: 0.6551993\n",
      "\tspeed: 0.0405s/iter; left time: 322.4152s\n",
      "\titers: 300, epoch: 2 | loss: 0.5400851\n",
      "\tspeed: 0.0405s/iter; left time: 317.9089s\n",
      "\titers: 400, epoch: 2 | loss: 0.6192174\n",
      "\tspeed: 0.0417s/iter; left time: 323.4003s\n",
      "\titers: 500, epoch: 2 | loss: 0.4943135\n",
      "\tspeed: 0.0404s/iter; left time: 309.2832s\n",
      "\titers: 600, epoch: 2 | loss: 0.5266612\n",
      "\tspeed: 0.0417s/iter; left time: 314.9911s\n",
      "\titers: 700, epoch: 2 | loss: 0.5126165\n",
      "\tspeed: 0.0412s/iter; left time: 307.2258s\n",
      "\titers: 800, epoch: 2 | loss: 0.6232010\n",
      "\tspeed: 0.0410s/iter; left time: 301.8661s\n",
      "\titers: 900, epoch: 2 | loss: 0.5411612\n",
      "\tspeed: 0.0313s/iter; left time: 227.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.50s\n",
      "Steps: 906 | Train Loss: 0.5740920 Vali Loss: 0.4399104 Test Loss: 0.5069085\n",
      "Validation loss decreased (0.554388 --> 0.439910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5629239\n",
      "\tspeed: 0.0861s/iter; left time: 615.5732s\n",
      "\titers: 200, epoch: 3 | loss: 0.4941055\n",
      "\tspeed: 0.0284s/iter; left time: 200.1739s\n",
      "\titers: 300, epoch: 3 | loss: 0.5275605\n",
      "\tspeed: 0.0284s/iter; left time: 197.1906s\n",
      "\titers: 400, epoch: 3 | loss: 0.5161560\n",
      "\tspeed: 0.0287s/iter; left time: 196.5274s\n",
      "\titers: 500, epoch: 3 | loss: 0.5798593\n",
      "\tspeed: 0.0284s/iter; left time: 191.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.5651723\n",
      "\tspeed: 0.0283s/iter; left time: 188.4044s\n",
      "\titers: 700, epoch: 3 | loss: 0.5228499\n",
      "\tspeed: 0.0283s/iter; left time: 185.3295s\n",
      "\titers: 800, epoch: 3 | loss: 0.5283095\n",
      "\tspeed: 0.0317s/iter; left time: 204.2019s\n",
      "\titers: 900, epoch: 3 | loss: 0.5182760\n",
      "\tspeed: 0.0404s/iter; left time: 256.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.66s\n",
      "Steps: 906 | Train Loss: 0.5248068 Vali Loss: 0.4539682 Test Loss: 0.4925095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4896143\n",
      "\tspeed: 0.0975s/iter; left time: 608.7913s\n",
      "\titers: 200, epoch: 4 | loss: 0.4587334\n",
      "\tspeed: 0.0402s/iter; left time: 246.8511s\n",
      "\titers: 300, epoch: 4 | loss: 0.4971539\n",
      "\tspeed: 0.0404s/iter; left time: 244.3505s\n",
      "\titers: 400, epoch: 4 | loss: 0.4374260\n",
      "\tspeed: 0.0402s/iter; left time: 239.0255s\n",
      "\titers: 500, epoch: 4 | loss: 0.5398332\n",
      "\tspeed: 0.0404s/iter; left time: 235.8719s\n",
      "\titers: 600, epoch: 4 | loss: 0.5343698\n",
      "\tspeed: 0.0401s/iter; left time: 230.5465s\n",
      "\titers: 700, epoch: 4 | loss: 0.4609941\n",
      "\tspeed: 0.0410s/iter; left time: 231.2501s\n",
      "\titers: 800, epoch: 4 | loss: 0.5253209\n",
      "\tspeed: 0.0403s/iter; left time: 223.4947s\n",
      "\titers: 900, epoch: 4 | loss: 0.4564810\n",
      "\tspeed: 0.0403s/iter; left time: 219.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.4849790 Vali Loss: 0.4594938 Test Loss: 0.5241997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4823216\n",
      "\tspeed: 0.0956s/iter; left time: 510.4286s\n",
      "\titers: 200, epoch: 5 | loss: 0.4644124\n",
      "\tspeed: 0.0403s/iter; left time: 211.0284s\n",
      "\titers: 300, epoch: 5 | loss: 0.4214824\n",
      "\tspeed: 0.0405s/iter; left time: 207.9915s\n",
      "\titers: 400, epoch: 5 | loss: 0.4996223\n",
      "\tspeed: 0.0423s/iter; left time: 213.2056s\n",
      "\titers: 500, epoch: 5 | loss: 0.4287166\n",
      "\tspeed: 0.0421s/iter; left time: 207.7844s\n",
      "\titers: 600, epoch: 5 | loss: 0.4123247\n",
      "\tspeed: 0.0414s/iter; left time: 200.4523s\n",
      "\titers: 700, epoch: 5 | loss: 0.4194843\n",
      "\tspeed: 0.0418s/iter; left time: 197.8673s\n",
      "\titers: 800, epoch: 5 | loss: 0.4636900\n",
      "\tspeed: 0.0417s/iter; left time: 193.1668s\n",
      "\titers: 900, epoch: 5 | loss: 0.4432615\n",
      "\tspeed: 0.0418s/iter; left time: 189.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 906 | Train Loss: 0.4400303 Vali Loss: 0.4821237 Test Loss: 0.5637830\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5070682764053345, rmse:0.7120872735977173, mae:0.49827083945274353, rse:0.563572108745575\n",
      "Original data scale mse:20156686.0, rmse:4489.61962890625, mae:2999.142578125, rse:0.2232329547405243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8588779\n",
      "\tspeed: 0.0433s/iter; left time: 387.6552s\n",
      "\titers: 200, epoch: 1 | loss: 0.7982945\n",
      "\tspeed: 0.0404s/iter; left time: 358.2111s\n",
      "\titers: 300, epoch: 1 | loss: 0.8250256\n",
      "\tspeed: 0.0410s/iter; left time: 359.5281s\n",
      "\titers: 400, epoch: 1 | loss: 0.7691973\n",
      "\tspeed: 0.0404s/iter; left time: 349.9992s\n",
      "\titers: 500, epoch: 1 | loss: 0.7309195\n",
      "\tspeed: 0.0403s/iter; left time: 345.1850s\n",
      "\titers: 600, epoch: 1 | loss: 0.6879429\n",
      "\tspeed: 0.0405s/iter; left time: 342.4561s\n",
      "\titers: 700, epoch: 1 | loss: 0.6365433\n",
      "\tspeed: 0.0412s/iter; left time: 344.1932s\n",
      "\titers: 800, epoch: 1 | loss: 0.7065768\n",
      "\tspeed: 0.0418s/iter; left time: 344.9825s\n",
      "\titers: 900, epoch: 1 | loss: 0.6446868\n",
      "\tspeed: 0.0414s/iter; left time: 338.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.7622878 Vali Loss: 0.5469300 Test Loss: 0.6323155\n",
      "Validation loss decreased (inf --> 0.546930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5923141\n",
      "\tspeed: 0.1011s/iter; left time: 814.6983s\n",
      "\titers: 200, epoch: 2 | loss: 0.5748015\n",
      "\tspeed: 0.0420s/iter; left time: 333.9280s\n",
      "\titers: 300, epoch: 2 | loss: 0.5269984\n",
      "\tspeed: 0.0399s/iter; left time: 313.5864s\n",
      "\titers: 400, epoch: 2 | loss: 0.5026063\n",
      "\tspeed: 0.0410s/iter; left time: 318.2473s\n",
      "\titers: 500, epoch: 2 | loss: 0.5611269\n",
      "\tspeed: 0.0407s/iter; left time: 311.9162s\n",
      "\titers: 600, epoch: 2 | loss: 0.5893219\n",
      "\tspeed: 0.0404s/iter; left time: 305.4282s\n",
      "\titers: 700, epoch: 2 | loss: 0.5543723\n",
      "\tspeed: 0.0404s/iter; left time: 301.4301s\n",
      "\titers: 800, epoch: 2 | loss: 0.4901477\n",
      "\tspeed: 0.0404s/iter; left time: 297.1698s\n",
      "\titers: 900, epoch: 2 | loss: 0.5559916\n",
      "\tspeed: 0.0376s/iter; left time: 272.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.5776560 Vali Loss: 0.4851062 Test Loss: 0.5314170\n",
      "Validation loss decreased (0.546930 --> 0.485106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6048454\n",
      "\tspeed: 0.1000s/iter; left time: 714.5903s\n",
      "\titers: 200, epoch: 3 | loss: 0.5126129\n",
      "\tspeed: 0.0424s/iter; left time: 298.7109s\n",
      "\titers: 300, epoch: 3 | loss: 0.4772909\n",
      "\tspeed: 0.0429s/iter; left time: 297.8391s\n",
      "\titers: 400, epoch: 3 | loss: 0.5289421\n",
      "\tspeed: 0.0432s/iter; left time: 295.9513s\n",
      "\titers: 500, epoch: 3 | loss: 0.5147277\n",
      "\tspeed: 0.0422s/iter; left time: 284.7096s\n",
      "\titers: 600, epoch: 3 | loss: 0.5077899\n",
      "\tspeed: 0.0414s/iter; left time: 275.1727s\n",
      "\titers: 700, epoch: 3 | loss: 0.5518087\n",
      "\tspeed: 0.0421s/iter; left time: 275.8539s\n",
      "\titers: 800, epoch: 3 | loss: 0.5423992\n",
      "\tspeed: 0.0410s/iter; left time: 264.1897s\n",
      "\titers: 900, epoch: 3 | loss: 0.4665054\n",
      "\tspeed: 0.0404s/iter; left time: 256.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.5296453 Vali Loss: 0.4397265 Test Loss: 0.4830378\n",
      "Validation loss decreased (0.485106 --> 0.439726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4773476\n",
      "\tspeed: 0.0981s/iter; left time: 612.4550s\n",
      "\titers: 200, epoch: 4 | loss: 0.5036800\n",
      "\tspeed: 0.0403s/iter; left time: 247.8418s\n",
      "\titers: 300, epoch: 4 | loss: 0.6146199\n",
      "\tspeed: 0.0402s/iter; left time: 242.8053s\n",
      "\titers: 400, epoch: 4 | loss: 0.4577895\n",
      "\tspeed: 0.0403s/iter; left time: 239.5538s\n",
      "\titers: 500, epoch: 4 | loss: 0.5661929\n",
      "\tspeed: 0.0423s/iter; left time: 247.0214s\n",
      "\titers: 600, epoch: 4 | loss: 0.5100247\n",
      "\tspeed: 0.0294s/iter; left time: 168.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.4980476\n",
      "\tspeed: 0.0284s/iter; left time: 160.3477s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978939\n",
      "\tspeed: 0.0342s/iter; left time: 189.6379s\n",
      "\titers: 900, epoch: 4 | loss: 0.3861069\n",
      "\tspeed: 0.0421s/iter; left time: 229.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.31s\n",
      "Steps: 906 | Train Loss: 0.4899198 Vali Loss: 0.4603651 Test Loss: 0.5041409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4936487\n",
      "\tspeed: 0.0963s/iter; left time: 513.7432s\n",
      "\titers: 200, epoch: 5 | loss: 0.4334660\n",
      "\tspeed: 0.0403s/iter; left time: 211.2733s\n",
      "\titers: 300, epoch: 5 | loss: 0.4235884\n",
      "\tspeed: 0.0405s/iter; left time: 207.8465s\n",
      "\titers: 400, epoch: 5 | loss: 0.4626411\n",
      "\tspeed: 0.0403s/iter; left time: 202.8950s\n",
      "\titers: 500, epoch: 5 | loss: 0.3728518\n",
      "\tspeed: 0.0401s/iter; left time: 198.0847s\n",
      "\titers: 600, epoch: 5 | loss: 0.4660599\n",
      "\tspeed: 0.0404s/iter; left time: 195.5429s\n",
      "\titers: 700, epoch: 5 | loss: 0.4180226\n",
      "\tspeed: 0.0403s/iter; left time: 191.1128s\n",
      "\titers: 800, epoch: 5 | loss: 0.4556598\n",
      "\tspeed: 0.0403s/iter; left time: 187.0751s\n",
      "\titers: 900, epoch: 5 | loss: 0.4162793\n",
      "\tspeed: 0.0403s/iter; left time: 183.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.4432991 Vali Loss: 0.4867482 Test Loss: 0.5200544\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3990616\n",
      "\tspeed: 0.0965s/iter; left time: 427.6229s\n",
      "\titers: 200, epoch: 6 | loss: 0.4005626\n",
      "\tspeed: 0.0425s/iter; left time: 183.9177s\n",
      "\titers: 300, epoch: 6 | loss: 0.4957956\n",
      "\tspeed: 0.0409s/iter; left time: 173.1962s\n",
      "\titers: 400, epoch: 6 | loss: 0.4094400\n",
      "\tspeed: 0.0404s/iter; left time: 166.8591s\n",
      "\titers: 500, epoch: 6 | loss: 0.3923487\n",
      "\tspeed: 0.0403s/iter; left time: 162.5584s\n",
      "\titers: 600, epoch: 6 | loss: 0.3940423\n",
      "\tspeed: 0.0402s/iter; left time: 158.1706s\n",
      "\titers: 700, epoch: 6 | loss: 0.3931371\n",
      "\tspeed: 0.0405s/iter; left time: 155.0205s\n",
      "\titers: 800, epoch: 6 | loss: 0.3574754\n",
      "\tspeed: 0.0405s/iter; left time: 151.0988s\n",
      "\titers: 900, epoch: 6 | loss: 0.3599356\n",
      "\tspeed: 0.0404s/iter; left time: 146.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.4004315 Vali Loss: 0.5209612 Test Loss: 0.5491917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4826447069644928, rmse:0.6947263479232788, mae:0.4775684177875519, rse:0.5498320460319519\n",
      "Original data scale mse:19259186.0, rmse:4388.52880859375, mae:2873.763671875, rse:0.2182064950466156\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0252380\n",
      "\tspeed: 0.0727s/iter; left time: 650.2127s\n",
      "\titers: 200, epoch: 1 | loss: 0.9821252\n",
      "\tspeed: 0.0447s/iter; left time: 395.0234s\n",
      "\titers: 300, epoch: 1 | loss: 0.9594889\n",
      "\tspeed: 0.0457s/iter; left time: 399.8409s\n",
      "\titers: 400, epoch: 1 | loss: 0.8844653\n",
      "\tspeed: 0.0465s/iter; left time: 402.1781s\n",
      "\titers: 500, epoch: 1 | loss: 0.8824679\n",
      "\tspeed: 0.0460s/iter; left time: 392.6459s\n",
      "\titers: 600, epoch: 1 | loss: 0.8055439\n",
      "\tspeed: 0.0464s/iter; left time: 391.3131s\n",
      "\titers: 700, epoch: 1 | loss: 0.7853126\n",
      "\tspeed: 0.0462s/iter; left time: 385.5317s\n",
      "\titers: 800, epoch: 1 | loss: 0.8030834\n",
      "\tspeed: 0.0449s/iter; left time: 369.9513s\n",
      "\titers: 900, epoch: 1 | loss: 0.8041261\n",
      "\tspeed: 0.0460s/iter; left time: 374.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.13s\n",
      "Steps: 904 | Train Loss: 0.8981916 Vali Loss: 0.8284516 Test Loss: 1.0307974\n",
      "Validation loss decreased (inf --> 0.828452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7219144\n",
      "\tspeed: 0.1162s/iter; left time: 933.5109s\n",
      "\titers: 200, epoch: 2 | loss: 0.7597279\n",
      "\tspeed: 0.0388s/iter; left time: 307.9228s\n",
      "\titers: 300, epoch: 2 | loss: 0.7219747\n",
      "\tspeed: 0.0365s/iter; left time: 285.6860s\n",
      "\titers: 400, epoch: 2 | loss: 0.6980771\n",
      "\tspeed: 0.0419s/iter; left time: 324.3215s\n",
      "\titers: 500, epoch: 2 | loss: 0.6995429\n",
      "\tspeed: 0.0356s/iter; left time: 271.7289s\n",
      "\titers: 600, epoch: 2 | loss: 0.7647797\n",
      "\tspeed: 0.0459s/iter; left time: 345.9599s\n",
      "\titers: 700, epoch: 2 | loss: 0.6916636\n",
      "\tspeed: 0.0439s/iter; left time: 326.1169s\n",
      "\titers: 800, epoch: 2 | loss: 0.7342687\n",
      "\tspeed: 0.0460s/iter; left time: 337.8506s\n",
      "\titers: 900, epoch: 2 | loss: 0.6819095\n",
      "\tspeed: 0.0459s/iter; left time: 331.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.7261729 Vali Loss: 0.6847084 Test Loss: 0.8025894\n",
      "Validation loss decreased (0.828452 --> 0.684708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7336022\n",
      "\tspeed: 0.1145s/iter; left time: 816.6285s\n",
      "\titers: 200, epoch: 3 | loss: 0.6408885\n",
      "\tspeed: 0.0441s/iter; left time: 309.9571s\n",
      "\titers: 300, epoch: 3 | loss: 0.6044647\n",
      "\tspeed: 0.0454s/iter; left time: 315.0128s\n",
      "\titers: 400, epoch: 3 | loss: 0.6270521\n",
      "\tspeed: 0.0447s/iter; left time: 305.4366s\n",
      "\titers: 500, epoch: 3 | loss: 0.6593441\n",
      "\tspeed: 0.0440s/iter; left time: 296.5289s\n",
      "\titers: 600, epoch: 3 | loss: 0.6727517\n",
      "\tspeed: 0.0430s/iter; left time: 285.1041s\n",
      "\titers: 700, epoch: 3 | loss: 0.6100384\n",
      "\tspeed: 0.0460s/iter; left time: 300.4643s\n",
      "\titers: 800, epoch: 3 | loss: 0.6660968\n",
      "\tspeed: 0.0431s/iter; left time: 277.5065s\n",
      "\titers: 900, epoch: 3 | loss: 0.6544979\n",
      "\tspeed: 0.0452s/iter; left time: 286.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.61s\n",
      "Steps: 904 | Train Loss: 0.6540388 Vali Loss: 0.6982146 Test Loss: 0.8181267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5878187\n",
      "\tspeed: 0.1091s/iter; left time: 679.7784s\n",
      "\titers: 200, epoch: 4 | loss: 0.5915712\n",
      "\tspeed: 0.0465s/iter; left time: 285.2739s\n",
      "\titers: 300, epoch: 4 | loss: 0.5916324\n",
      "\tspeed: 0.0463s/iter; left time: 279.2914s\n",
      "\titers: 400, epoch: 4 | loss: 0.5480406\n",
      "\tspeed: 0.0460s/iter; left time: 272.6906s\n",
      "\titers: 500, epoch: 4 | loss: 0.6060248\n",
      "\tspeed: 0.0463s/iter; left time: 269.8163s\n",
      "\titers: 600, epoch: 4 | loss: 0.5727869\n",
      "\tspeed: 0.0453s/iter; left time: 259.6532s\n",
      "\titers: 700, epoch: 4 | loss: 0.6088339\n",
      "\tspeed: 0.0368s/iter; left time: 207.3894s\n",
      "\titers: 800, epoch: 4 | loss: 0.5749963\n",
      "\tspeed: 0.0362s/iter; left time: 200.1660s\n",
      "\titers: 900, epoch: 4 | loss: 0.5974422\n",
      "\tspeed: 0.0355s/iter; left time: 192.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 904 | Train Loss: 0.5986204 Vali Loss: 0.7151270 Test Loss: 0.9077851\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5486233\n",
      "\tspeed: 0.1095s/iter; left time: 583.3356s\n",
      "\titers: 200, epoch: 5 | loss: 0.6009266\n",
      "\tspeed: 0.0460s/iter; left time: 240.1314s\n",
      "\titers: 300, epoch: 5 | loss: 0.5961829\n",
      "\tspeed: 0.0449s/iter; left time: 230.2508s\n",
      "\titers: 400, epoch: 5 | loss: 0.5412604\n",
      "\tspeed: 0.0461s/iter; left time: 231.8430s\n",
      "\titers: 500, epoch: 5 | loss: 0.5200085\n",
      "\tspeed: 0.0455s/iter; left time: 224.3296s\n",
      "\titers: 600, epoch: 5 | loss: 0.5370143\n",
      "\tspeed: 0.0458s/iter; left time: 220.8870s\n",
      "\titers: 700, epoch: 5 | loss: 0.5396135\n",
      "\tspeed: 0.0441s/iter; left time: 208.4676s\n",
      "\titers: 800, epoch: 5 | loss: 0.4846662\n",
      "\tspeed: 0.0460s/iter; left time: 212.9798s\n",
      "\titers: 900, epoch: 5 | loss: 0.5213868\n",
      "\tspeed: 0.0459s/iter; left time: 207.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.5498217 Vali Loss: 0.7051411 Test Loss: 0.8774026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8018559813499451, rmse:0.8954641222953796, mae:0.6662679314613342, rse:0.7102134227752686\n",
      "Original data scale mse:34543984.0, rmse:5877.4130859375, mae:4100.0751953125, rse:0.2926972508430481\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9545566\n",
      "\tspeed: 0.0472s/iter; left time: 421.8077s\n",
      "\titers: 200, epoch: 1 | loss: 0.9046481\n",
      "\tspeed: 0.0445s/iter; left time: 393.6427s\n",
      "\titers: 300, epoch: 1 | loss: 0.9244955\n",
      "\tspeed: 0.0442s/iter; left time: 386.5066s\n",
      "\titers: 400, epoch: 1 | loss: 0.9064289\n",
      "\tspeed: 0.0455s/iter; left time: 392.9535s\n",
      "\titers: 500, epoch: 1 | loss: 0.9243618\n",
      "\tspeed: 0.0457s/iter; left time: 390.5690s\n",
      "\titers: 600, epoch: 1 | loss: 0.8122278\n",
      "\tspeed: 0.0456s/iter; left time: 384.9384s\n",
      "\titers: 700, epoch: 1 | loss: 0.9583504\n",
      "\tspeed: 0.0456s/iter; left time: 380.6832s\n",
      "\titers: 800, epoch: 1 | loss: 0.8278310\n",
      "\tspeed: 0.0456s/iter; left time: 375.5682s\n",
      "\titers: 900, epoch: 1 | loss: 0.8535752\n",
      "\tspeed: 0.0450s/iter; left time: 366.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.15s\n",
      "Steps: 904 | Train Loss: 0.9020157 Vali Loss: 0.8226253 Test Loss: 1.0339608\n",
      "Validation loss decreased (inf --> 0.822625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8071152\n",
      "\tspeed: 0.1209s/iter; left time: 971.3800s\n",
      "\titers: 200, epoch: 2 | loss: 0.7878410\n",
      "\tspeed: 0.0450s/iter; left time: 357.1174s\n",
      "\titers: 300, epoch: 2 | loss: 0.7395509\n",
      "\tspeed: 0.0463s/iter; left time: 362.9254s\n",
      "\titers: 400, epoch: 2 | loss: 0.6591961\n",
      "\tspeed: 0.0456s/iter; left time: 352.9293s\n",
      "\titers: 500, epoch: 2 | loss: 0.6968939\n",
      "\tspeed: 0.0446s/iter; left time: 340.5841s\n",
      "\titers: 600, epoch: 2 | loss: 0.7799301\n",
      "\tspeed: 0.0356s/iter; left time: 268.4588s\n",
      "\titers: 700, epoch: 2 | loss: 0.7029775\n",
      "\tspeed: 0.0412s/iter; left time: 306.4490s\n",
      "\titers: 800, epoch: 2 | loss: 0.7345486\n",
      "\tspeed: 0.0355s/iter; left time: 260.6145s\n",
      "\titers: 900, epoch: 2 | loss: 0.6330129\n",
      "\tspeed: 0.0355s/iter; left time: 257.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.7273200 Vali Loss: 0.6909656 Test Loss: 0.8539773\n",
      "Validation loss decreased (0.822625 --> 0.690966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6829980\n",
      "\tspeed: 0.1193s/iter; left time: 850.7608s\n",
      "\titers: 200, epoch: 3 | loss: 0.6691113\n",
      "\tspeed: 0.0464s/iter; left time: 326.3224s\n",
      "\titers: 300, epoch: 3 | loss: 0.6194271\n",
      "\tspeed: 0.0461s/iter; left time: 319.5583s\n",
      "\titers: 400, epoch: 3 | loss: 0.6320899\n",
      "\tspeed: 0.0460s/iter; left time: 314.0888s\n",
      "\titers: 500, epoch: 3 | loss: 0.6391604\n",
      "\tspeed: 0.0459s/iter; left time: 308.9528s\n",
      "\titers: 600, epoch: 3 | loss: 0.6362435\n",
      "\tspeed: 0.0460s/iter; left time: 304.9596s\n",
      "\titers: 700, epoch: 3 | loss: 0.6481073\n",
      "\tspeed: 0.0460s/iter; left time: 300.3485s\n",
      "\titers: 800, epoch: 3 | loss: 0.6707047\n",
      "\tspeed: 0.0455s/iter; left time: 292.7730s\n",
      "\titers: 900, epoch: 3 | loss: 0.6414825\n",
      "\tspeed: 0.0452s/iter; left time: 286.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.6500887 Vali Loss: 0.7310898 Test Loss: 0.8651748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5668097\n",
      "\tspeed: 0.1118s/iter; left time: 696.5705s\n",
      "\titers: 200, epoch: 4 | loss: 0.6010278\n",
      "\tspeed: 0.0453s/iter; left time: 277.9286s\n",
      "\titers: 300, epoch: 4 | loss: 0.5805757\n",
      "\tspeed: 0.0424s/iter; left time: 255.4812s\n",
      "\titers: 400, epoch: 4 | loss: 0.5756222\n",
      "\tspeed: 0.0451s/iter; left time: 267.4973s\n",
      "\titers: 500, epoch: 4 | loss: 0.6019570\n",
      "\tspeed: 0.0453s/iter; left time: 263.8164s\n",
      "\titers: 600, epoch: 4 | loss: 0.5867005\n",
      "\tspeed: 0.0454s/iter; left time: 259.9270s\n",
      "\titers: 700, epoch: 4 | loss: 0.5590611\n",
      "\tspeed: 0.0456s/iter; left time: 256.4669s\n",
      "\titers: 800, epoch: 4 | loss: 0.5786862\n",
      "\tspeed: 0.0455s/iter; left time: 251.4199s\n",
      "\titers: 900, epoch: 4 | loss: 0.5570041\n",
      "\tspeed: 0.0444s/iter; left time: 241.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.91s\n",
      "Steps: 904 | Train Loss: 0.5954686 Vali Loss: 0.7804562 Test Loss: 0.9499455\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5297164\n",
      "\tspeed: 0.1113s/iter; left time: 592.6540s\n",
      "\titers: 200, epoch: 5 | loss: 0.5754976\n",
      "\tspeed: 0.0462s/iter; left time: 241.3270s\n",
      "\titers: 300, epoch: 5 | loss: 0.5536209\n",
      "\tspeed: 0.0453s/iter; left time: 231.9430s\n",
      "\titers: 400, epoch: 5 | loss: 0.5372819\n",
      "\tspeed: 0.0444s/iter; left time: 223.3453s\n",
      "\titers: 500, epoch: 5 | loss: 0.5717360\n",
      "\tspeed: 0.0448s/iter; left time: 220.8070s\n",
      "\titers: 600, epoch: 5 | loss: 0.5239812\n",
      "\tspeed: 0.0450s/iter; left time: 217.0033s\n",
      "\titers: 700, epoch: 5 | loss: 0.5715138\n",
      "\tspeed: 0.0447s/iter; left time: 211.2791s\n",
      "\titers: 800, epoch: 5 | loss: 0.5439026\n",
      "\tspeed: 0.0429s/iter; left time: 198.5007s\n",
      "\titers: 900, epoch: 5 | loss: 0.5221722\n",
      "\tspeed: 0.0443s/iter; left time: 200.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.73s\n",
      "Steps: 904 | Train Loss: 0.5448839 Vali Loss: 0.7546401 Test Loss: 0.9773735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8537888526916504, rmse:0.9240069389343262, mae:0.6723426580429077, rse:0.7328513860702515\n",
      "Original data scale mse:36986492.0, rmse:6081.65185546875, mae:4114.8583984375, rse:0.30286842584609985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9471332\n",
      "\tspeed: 0.0750s/iter; left time: 669.4482s\n",
      "\titers: 200, epoch: 1 | loss: 0.9861875\n",
      "\tspeed: 0.0431s/iter; left time: 379.7759s\n",
      "\titers: 300, epoch: 1 | loss: 0.9315915\n",
      "\tspeed: 0.0427s/iter; left time: 372.5412s\n",
      "\titers: 400, epoch: 1 | loss: 0.9368693\n",
      "\tspeed: 0.0461s/iter; left time: 397.2905s\n",
      "\titers: 500, epoch: 1 | loss: 0.9175271\n",
      "\tspeed: 0.0515s/iter; left time: 439.2397s\n",
      "\titers: 600, epoch: 1 | loss: 0.9426318\n",
      "\tspeed: 0.0520s/iter; left time: 437.9744s\n",
      "\titers: 700, epoch: 1 | loss: 0.9106294\n",
      "\tspeed: 0.0517s/iter; left time: 429.8472s\n",
      "\titers: 800, epoch: 1 | loss: 0.8740443\n",
      "\tspeed: 0.0524s/iter; left time: 430.4814s\n",
      "\titers: 900, epoch: 1 | loss: 0.9128570\n",
      "\tspeed: 0.0523s/iter; left time: 424.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 902 | Train Loss: 0.9340369 Vali Loss: 0.9780082 Test Loss: 1.2568091\n",
      "Validation loss decreased (inf --> 0.978008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9008682\n",
      "\tspeed: 0.1365s/iter; left time: 1094.7834s\n",
      "\titers: 200, epoch: 2 | loss: 0.8331870\n",
      "\tspeed: 0.0528s/iter; left time: 417.9698s\n",
      "\titers: 300, epoch: 2 | loss: 0.8587946\n",
      "\tspeed: 0.0521s/iter; left time: 407.5985s\n",
      "\titers: 400, epoch: 2 | loss: 0.7877640\n",
      "\tspeed: 0.0528s/iter; left time: 407.4444s\n",
      "\titers: 500, epoch: 2 | loss: 0.7759214\n",
      "\tspeed: 0.0531s/iter; left time: 404.8446s\n",
      "\titers: 600, epoch: 2 | loss: 0.7217450\n",
      "\tspeed: 0.0452s/iter; left time: 339.7906s\n",
      "\titers: 700, epoch: 2 | loss: 0.7161107\n",
      "\tspeed: 0.0443s/iter; left time: 328.8212s\n",
      "\titers: 800, epoch: 2 | loss: 0.7566212\n",
      "\tspeed: 0.0443s/iter; left time: 324.1969s\n",
      "\titers: 900, epoch: 2 | loss: 0.7012705\n",
      "\tspeed: 0.0448s/iter; left time: 323.3678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.54s\n",
      "Steps: 902 | Train Loss: 0.7724640 Vali Loss: 0.7328678 Test Loss: 0.8932632\n",
      "Validation loss decreased (0.978008 --> 0.732868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7165682\n",
      "\tspeed: 0.1299s/iter; left time: 924.3434s\n",
      "\titers: 200, epoch: 3 | loss: 0.6870352\n",
      "\tspeed: 0.0523s/iter; left time: 366.7779s\n",
      "\titers: 300, epoch: 3 | loss: 0.6787533\n",
      "\tspeed: 0.0447s/iter; left time: 309.2308s\n",
      "\titers: 400, epoch: 3 | loss: 0.7236806\n",
      "\tspeed: 0.0518s/iter; left time: 353.0435s\n",
      "\titers: 500, epoch: 3 | loss: 0.6608443\n",
      "\tspeed: 0.0518s/iter; left time: 347.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.6809654\n",
      "\tspeed: 0.0532s/iter; left time: 351.8889s\n",
      "\titers: 700, epoch: 3 | loss: 0.6834272\n",
      "\tspeed: 0.0532s/iter; left time: 346.6506s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417248\n",
      "\tspeed: 0.0532s/iter; left time: 341.4206s\n",
      "\titers: 900, epoch: 3 | loss: 0.6610432\n",
      "\tspeed: 0.0523s/iter; left time: 330.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.6721240 Vali Loss: 0.7346251 Test Loss: 0.9027070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6154931\n",
      "\tspeed: 0.1322s/iter; left time: 821.6586s\n",
      "\titers: 200, epoch: 4 | loss: 0.5788427\n",
      "\tspeed: 0.0528s/iter; left time: 322.7613s\n",
      "\titers: 300, epoch: 4 | loss: 0.6534283\n",
      "\tspeed: 0.0525s/iter; left time: 315.9795s\n",
      "\titers: 400, epoch: 4 | loss: 0.6317046\n",
      "\tspeed: 0.0522s/iter; left time: 308.4753s\n",
      "\titers: 500, epoch: 4 | loss: 0.6388951\n",
      "\tspeed: 0.0520s/iter; left time: 302.5895s\n",
      "\titers: 600, epoch: 4 | loss: 0.5904660\n",
      "\tspeed: 0.0517s/iter; left time: 295.4779s\n",
      "\titers: 700, epoch: 4 | loss: 0.6414444\n",
      "\tspeed: 0.0520s/iter; left time: 292.1687s\n",
      "\titers: 800, epoch: 4 | loss: 0.6158543\n",
      "\tspeed: 0.0519s/iter; left time: 286.1611s\n",
      "\titers: 900, epoch: 4 | loss: 0.5860508\n",
      "\tspeed: 0.0521s/iter; left time: 281.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.6109018 Vali Loss: 0.7862337 Test Loss: 1.0190303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6108308\n",
      "\tspeed: 0.1307s/iter; left time: 694.2721s\n",
      "\titers: 200, epoch: 5 | loss: 0.5784037\n",
      "\tspeed: 0.0488s/iter; left time: 254.2279s\n",
      "\titers: 300, epoch: 5 | loss: 0.5641100\n",
      "\tspeed: 0.0428s/iter; left time: 218.9904s\n",
      "\titers: 400, epoch: 5 | loss: 0.5748665\n",
      "\tspeed: 0.0502s/iter; left time: 251.4644s\n",
      "\titers: 500, epoch: 5 | loss: 0.5016975\n",
      "\tspeed: 0.0509s/iter; left time: 250.0087s\n",
      "\titers: 600, epoch: 5 | loss: 0.5542794\n",
      "\tspeed: 0.0491s/iter; left time: 236.2583s\n",
      "\titers: 700, epoch: 5 | loss: 0.5704201\n",
      "\tspeed: 0.0516s/iter; left time: 243.2973s\n",
      "\titers: 800, epoch: 5 | loss: 0.5250012\n",
      "\tspeed: 0.0518s/iter; left time: 239.0809s\n",
      "\titers: 900, epoch: 5 | loss: 0.4947276\n",
      "\tspeed: 0.0521s/iter; left time: 235.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.29s\n",
      "Steps: 902 | Train Loss: 0.5555994 Vali Loss: 0.8196364 Test Loss: 1.0833149\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8934528827667236, rmse:0.9452263712882996, mae:0.6883419156074524, rse:0.7487866282463074\n",
      "Original data scale mse:38815100.0, rmse:6230.1767578125, mae:4220.97314453125, rse:0.3104173243045807\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0656863\n",
      "\tspeed: 0.0543s/iter; left time: 484.7678s\n",
      "\titers: 200, epoch: 1 | loss: 0.9557311\n",
      "\tspeed: 0.0526s/iter; left time: 464.1785s\n",
      "\titers: 300, epoch: 1 | loss: 0.8678913\n",
      "\tspeed: 0.0522s/iter; left time: 455.6580s\n",
      "\titers: 400, epoch: 1 | loss: 0.9394004\n",
      "\tspeed: 0.0521s/iter; left time: 448.8405s\n",
      "\titers: 500, epoch: 1 | loss: 0.9029401\n",
      "\tspeed: 0.0523s/iter; left time: 445.5772s\n",
      "\titers: 600, epoch: 1 | loss: 0.9282050\n",
      "\tspeed: 0.0522s/iter; left time: 439.9808s\n",
      "\titers: 700, epoch: 1 | loss: 0.9335796\n",
      "\tspeed: 0.0519s/iter; left time: 431.8473s\n",
      "\titers: 800, epoch: 1 | loss: 0.8777130\n",
      "\tspeed: 0.0521s/iter; left time: 427.9090s\n",
      "\titers: 900, epoch: 1 | loss: 0.8798903\n",
      "\tspeed: 0.0525s/iter; left time: 425.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.9323759 Vali Loss: 0.9880757 Test Loss: 1.2649819\n",
      "Validation loss decreased (inf --> 0.988076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8998638\n",
      "\tspeed: 0.1343s/iter; left time: 1077.0462s\n",
      "\titers: 200, epoch: 2 | loss: 0.8122976\n",
      "\tspeed: 0.0527s/iter; left time: 417.2423s\n",
      "\titers: 300, epoch: 2 | loss: 0.8411333\n",
      "\tspeed: 0.0521s/iter; left time: 407.6871s\n",
      "\titers: 400, epoch: 2 | loss: 0.7060408\n",
      "\tspeed: 0.0523s/iter; left time: 403.3191s\n",
      "\titers: 500, epoch: 2 | loss: 0.7866837\n",
      "\tspeed: 0.0519s/iter; left time: 395.6479s\n",
      "\titers: 600, epoch: 2 | loss: 0.7293652\n",
      "\tspeed: 0.0519s/iter; left time: 390.3976s\n",
      "\titers: 700, epoch: 2 | loss: 0.7686659\n",
      "\tspeed: 0.0517s/iter; left time: 383.3041s\n",
      "\titers: 800, epoch: 2 | loss: 0.7129799\n",
      "\tspeed: 0.0517s/iter; left time: 378.1765s\n",
      "\titers: 900, epoch: 2 | loss: 0.6920627\n",
      "\tspeed: 0.0516s/iter; left time: 372.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 902 | Train Loss: 0.7832593 Vali Loss: 0.7692808 Test Loss: 0.8737599\n",
      "Validation loss decreased (0.988076 --> 0.769281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6975249\n",
      "\tspeed: 0.1343s/iter; left time: 955.7271s\n",
      "\titers: 200, epoch: 3 | loss: 0.6490678\n",
      "\tspeed: 0.0519s/iter; left time: 363.9434s\n",
      "\titers: 300, epoch: 3 | loss: 0.6470399\n",
      "\tspeed: 0.0517s/iter; left time: 357.4043s\n",
      "\titers: 400, epoch: 3 | loss: 0.6277720\n",
      "\tspeed: 0.0521s/iter; left time: 355.2912s\n",
      "\titers: 500, epoch: 3 | loss: 0.6651936\n",
      "\tspeed: 0.0522s/iter; left time: 350.5084s\n",
      "\titers: 600, epoch: 3 | loss: 0.6629560\n",
      "\tspeed: 0.0519s/iter; left time: 343.2412s\n",
      "\titers: 700, epoch: 3 | loss: 0.6748104\n",
      "\tspeed: 0.0523s/iter; left time: 340.7852s\n",
      "\titers: 800, epoch: 3 | loss: 0.6037708\n",
      "\tspeed: 0.0519s/iter; left time: 332.7354s\n",
      "\titers: 900, epoch: 3 | loss: 0.6436216\n",
      "\tspeed: 0.0519s/iter; left time: 328.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.17s\n",
      "Steps: 902 | Train Loss: 0.6772264 Vali Loss: 0.7475495 Test Loss: 0.9241825\n",
      "Validation loss decreased (0.769281 --> 0.747550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5969893\n",
      "\tspeed: 0.1340s/iter; left time: 832.8541s\n",
      "\titers: 200, epoch: 4 | loss: 0.6450239\n",
      "\tspeed: 0.0521s/iter; left time: 318.7881s\n",
      "\titers: 300, epoch: 4 | loss: 0.6595438\n",
      "\tspeed: 0.0520s/iter; left time: 312.5023s\n",
      "\titers: 400, epoch: 4 | loss: 0.6280913\n",
      "\tspeed: 0.0519s/iter; left time: 306.9417s\n",
      "\titers: 500, epoch: 4 | loss: 0.6201030\n",
      "\tspeed: 0.0519s/iter; left time: 301.8731s\n",
      "\titers: 600, epoch: 4 | loss: 0.6041957\n",
      "\tspeed: 0.0519s/iter; left time: 296.5162s\n",
      "\titers: 700, epoch: 4 | loss: 0.5926436\n",
      "\tspeed: 0.0520s/iter; left time: 291.7249s\n",
      "\titers: 800, epoch: 4 | loss: 0.5527857\n",
      "\tspeed: 0.0520s/iter; left time: 286.5435s\n",
      "\titers: 900, epoch: 4 | loss: 0.6230676\n",
      "\tspeed: 0.0516s/iter; left time: 279.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 902 | Train Loss: 0.6172915 Vali Loss: 0.7728670 Test Loss: 0.9370694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5788156\n",
      "\tspeed: 0.1312s/iter; left time: 696.8861s\n",
      "\titers: 200, epoch: 5 | loss: 0.5334616\n",
      "\tspeed: 0.0519s/iter; left time: 270.3192s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742775\n",
      "\tspeed: 0.0521s/iter; left time: 266.4607s\n",
      "\titers: 400, epoch: 5 | loss: 0.5482292\n",
      "\tspeed: 0.0518s/iter; left time: 259.7512s\n",
      "\titers: 500, epoch: 5 | loss: 0.5712826\n",
      "\tspeed: 0.0518s/iter; left time: 254.5735s\n",
      "\titers: 600, epoch: 5 | loss: 0.5743529\n",
      "\tspeed: 0.0519s/iter; left time: 249.8590s\n",
      "\titers: 700, epoch: 5 | loss: 0.5463770\n",
      "\tspeed: 0.0520s/iter; left time: 245.2405s\n",
      "\titers: 800, epoch: 5 | loss: 0.5580187\n",
      "\tspeed: 0.0519s/iter; left time: 239.6292s\n",
      "\titers: 900, epoch: 5 | loss: 0.5339939\n",
      "\tspeed: 0.0519s/iter; left time: 234.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.5604885 Vali Loss: 0.8126694 Test Loss: 0.9670021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5250809\n",
      "\tspeed: 0.1316s/iter; left time: 580.5166s\n",
      "\titers: 200, epoch: 6 | loss: 0.5023152\n",
      "\tspeed: 0.0521s/iter; left time: 224.4430s\n",
      "\titers: 300, epoch: 6 | loss: 0.4989885\n",
      "\tspeed: 0.0518s/iter; left time: 218.0522s\n",
      "\titers: 400, epoch: 6 | loss: 0.5178986\n",
      "\tspeed: 0.0521s/iter; left time: 214.1746s\n",
      "\titers: 500, epoch: 6 | loss: 0.5457343\n",
      "\tspeed: 0.0521s/iter; left time: 208.9197s\n",
      "\titers: 600, epoch: 6 | loss: 0.5038822\n",
      "\tspeed: 0.0523s/iter; left time: 204.4324s\n",
      "\titers: 700, epoch: 6 | loss: 0.5238547\n",
      "\tspeed: 0.0521s/iter; left time: 198.5567s\n",
      "\titers: 800, epoch: 6 | loss: 0.4924663\n",
      "\tspeed: 0.0520s/iter; left time: 192.9889s\n",
      "\titers: 900, epoch: 6 | loss: 0.5068249\n",
      "\tspeed: 0.0520s/iter; left time: 187.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 902 | Train Loss: 0.5112046 Vali Loss: 0.8424274 Test Loss: 1.0782026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9231351613998413, rmse:0.9607992172241211, mae:0.6902961134910583, rse:0.7611231207847595\n",
      "Original data scale mse:40210260.0, rmse:6341.15625, mae:4216.42529296875, rse:0.3159468472003937\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7215695\n",
      "\tspeed: 0.0676s/iter; left time: 605.6234s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677415\n",
      "\tspeed: 0.0403s/iter; left time: 357.1693s\n",
      "\titers: 300, epoch: 1 | loss: 0.5992011\n",
      "\tspeed: 0.0404s/iter; left time: 354.3081s\n",
      "\titers: 400, epoch: 1 | loss: 0.5512000\n",
      "\tspeed: 0.0404s/iter; left time: 350.1840s\n",
      "\titers: 500, epoch: 1 | loss: 0.5238050\n",
      "\tspeed: 0.0407s/iter; left time: 348.1493s\n",
      "\titers: 600, epoch: 1 | loss: 0.5131288\n",
      "\tspeed: 0.0403s/iter; left time: 341.0431s\n",
      "\titers: 700, epoch: 1 | loss: 0.6015207\n",
      "\tspeed: 0.0404s/iter; left time: 338.0246s\n",
      "\titers: 800, epoch: 1 | loss: 0.5066000\n",
      "\tspeed: 0.0404s/iter; left time: 334.0162s\n",
      "\titers: 900, epoch: 1 | loss: 0.4471631\n",
      "\tspeed: 0.0403s/iter; left time: 328.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.5917037 Vali Loss: 0.5611537 Test Loss: 0.5962256\n",
      "Validation loss decreased (inf --> 0.561154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3709538\n",
      "\tspeed: 0.0998s/iter; left time: 803.8099s\n",
      "\titers: 200, epoch: 2 | loss: 0.4661245\n",
      "\tspeed: 0.0403s/iter; left time: 320.8957s\n",
      "\titers: 300, epoch: 2 | loss: 0.3768515\n",
      "\tspeed: 0.0414s/iter; left time: 325.4341s\n",
      "\titers: 400, epoch: 2 | loss: 0.4144876\n",
      "\tspeed: 0.0414s/iter; left time: 320.6941s\n",
      "\titers: 500, epoch: 2 | loss: 0.3443320\n",
      "\tspeed: 0.0412s/iter; left time: 315.6911s\n",
      "\titers: 600, epoch: 2 | loss: 0.3588921\n",
      "\tspeed: 0.0416s/iter; left time: 313.9284s\n",
      "\titers: 700, epoch: 2 | loss: 0.3583628\n",
      "\tspeed: 0.0415s/iter; left time: 309.5012s\n",
      "\titers: 800, epoch: 2 | loss: 0.4166490\n",
      "\tspeed: 0.0421s/iter; left time: 309.3772s\n",
      "\titers: 900, epoch: 2 | loss: 0.3890607\n",
      "\tspeed: 0.0417s/iter; left time: 302.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.4025906 Vali Loss: 0.4453301 Test Loss: 0.4756032\n",
      "Validation loss decreased (0.561154 --> 0.445330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3711495\n",
      "\tspeed: 0.1017s/iter; left time: 726.7510s\n",
      "\titers: 200, epoch: 3 | loss: 0.3322031\n",
      "\tspeed: 0.0404s/iter; left time: 284.6412s\n",
      "\titers: 300, epoch: 3 | loss: 0.3484581\n",
      "\tspeed: 0.0405s/iter; left time: 281.5820s\n",
      "\titers: 400, epoch: 3 | loss: 0.3441037\n",
      "\tspeed: 0.0402s/iter; left time: 275.0127s\n",
      "\titers: 500, epoch: 3 | loss: 0.4129507\n",
      "\tspeed: 0.0404s/iter; left time: 272.6077s\n",
      "\titers: 600, epoch: 3 | loss: 0.3717259\n",
      "\tspeed: 0.0409s/iter; left time: 271.7203s\n",
      "\titers: 700, epoch: 3 | loss: 0.3695573\n",
      "\tspeed: 0.0425s/iter; left time: 278.1878s\n",
      "\titers: 800, epoch: 3 | loss: 0.3394932\n",
      "\tspeed: 0.0404s/iter; left time: 260.8040s\n",
      "\titers: 900, epoch: 3 | loss: 0.3480455\n",
      "\tspeed: 0.0408s/iter; left time: 259.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 906 | Train Loss: 0.3552150 Vali Loss: 0.4405829 Test Loss: 0.4628681\n",
      "Validation loss decreased (0.445330 --> 0.440583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3240797\n",
      "\tspeed: 0.1041s/iter; left time: 649.8309s\n",
      "\titers: 200, epoch: 4 | loss: 0.3329988\n",
      "\tspeed: 0.0403s/iter; left time: 247.4741s\n",
      "\titers: 300, epoch: 4 | loss: 0.3138479\n",
      "\tspeed: 0.0405s/iter; left time: 244.4778s\n",
      "\titers: 400, epoch: 4 | loss: 0.2903596\n",
      "\tspeed: 0.0405s/iter; left time: 240.5618s\n",
      "\titers: 500, epoch: 4 | loss: 0.3638243\n",
      "\tspeed: 0.0403s/iter; left time: 235.5489s\n",
      "\titers: 600, epoch: 4 | loss: 0.3209779\n",
      "\tspeed: 0.0404s/iter; left time: 232.1537s\n",
      "\titers: 700, epoch: 4 | loss: 0.3025450\n",
      "\tspeed: 0.0404s/iter; left time: 227.8519s\n",
      "\titers: 800, epoch: 4 | loss: 0.3539144\n",
      "\tspeed: 0.0405s/iter; left time: 224.2824s\n",
      "\titers: 900, epoch: 4 | loss: 0.3243295\n",
      "\tspeed: 0.0404s/iter; left time: 220.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.3304306 Vali Loss: 0.4461254 Test Loss: 0.4630463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3200391\n",
      "\tspeed: 0.0964s/iter; left time: 514.6072s\n",
      "\titers: 200, epoch: 5 | loss: 0.3002499\n",
      "\tspeed: 0.0403s/iter; left time: 211.1595s\n",
      "\titers: 300, epoch: 5 | loss: 0.2781452\n",
      "\tspeed: 0.0403s/iter; left time: 207.1676s\n",
      "\titers: 400, epoch: 5 | loss: 0.3169612\n",
      "\tspeed: 0.0404s/iter; left time: 203.3963s\n",
      "\titers: 500, epoch: 5 | loss: 0.3001828\n",
      "\tspeed: 0.0402s/iter; left time: 198.4693s\n",
      "\titers: 600, epoch: 5 | loss: 0.3253998\n",
      "\tspeed: 0.0402s/iter; left time: 194.3856s\n",
      "\titers: 700, epoch: 5 | loss: 0.2686165\n",
      "\tspeed: 0.0419s/iter; left time: 198.3927s\n",
      "\titers: 800, epoch: 5 | loss: 0.3044296\n",
      "\tspeed: 0.0419s/iter; left time: 194.1877s\n",
      "\titers: 900, epoch: 5 | loss: 0.3225136\n",
      "\tspeed: 0.0427s/iter; left time: 193.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.35s\n",
      "Steps: 906 | Train Loss: 0.3035686 Vali Loss: 0.4407153 Test Loss: 0.4767428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2985508\n",
      "\tspeed: 0.0975s/iter; left time: 431.8793s\n",
      "\titers: 200, epoch: 6 | loss: 0.2633336\n",
      "\tspeed: 0.0419s/iter; left time: 181.3550s\n",
      "\titers: 300, epoch: 6 | loss: 0.2996624\n",
      "\tspeed: 0.0356s/iter; left time: 150.6507s\n",
      "\titers: 400, epoch: 6 | loss: 0.2697504\n",
      "\tspeed: 0.0285s/iter; left time: 117.5411s\n",
      "\titers: 500, epoch: 6 | loss: 0.3121417\n",
      "\tspeed: 0.0285s/iter; left time: 114.7979s\n",
      "\titers: 600, epoch: 6 | loss: 0.2498942\n",
      "\tspeed: 0.0414s/iter; left time: 162.7062s\n",
      "\titers: 700, epoch: 6 | loss: 0.2871542\n",
      "\tspeed: 0.0398s/iter; left time: 152.4365s\n",
      "\titers: 800, epoch: 6 | loss: 0.2544069\n",
      "\tspeed: 0.0413s/iter; left time: 154.1128s\n",
      "\titers: 900, epoch: 6 | loss: 0.2554080\n",
      "\tspeed: 0.0418s/iter; left time: 151.7555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.52s\n",
      "Steps: 906 | Train Loss: 0.2803099 Vali Loss: 0.4469062 Test Loss: 0.4820318\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49489977955818176, rmse:0.7034911513328552, mae:0.4627796411514282, rse:0.5567687749862671\n",
      "Original data scale mse:19648216.0, rmse:4432.630859375, mae:2762.43359375, rse:0.22039934992790222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6933636\n",
      "\tspeed: 0.0429s/iter; left time: 384.4640s\n",
      "\titers: 200, epoch: 1 | loss: 0.6457908\n",
      "\tspeed: 0.0403s/iter; left time: 356.8804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5454914\n",
      "\tspeed: 0.0405s/iter; left time: 354.7308s\n",
      "\titers: 400, epoch: 1 | loss: 0.5511503\n",
      "\tspeed: 0.0403s/iter; left time: 349.2656s\n",
      "\titers: 500, epoch: 1 | loss: 0.5786752\n",
      "\tspeed: 0.0404s/iter; left time: 346.1729s\n",
      "\titers: 600, epoch: 1 | loss: 0.5497690\n",
      "\tspeed: 0.0404s/iter; left time: 341.6487s\n",
      "\titers: 700, epoch: 1 | loss: 0.5148432\n",
      "\tspeed: 0.0404s/iter; left time: 337.7848s\n",
      "\titers: 800, epoch: 1 | loss: 0.5002761\n",
      "\tspeed: 0.0404s/iter; left time: 334.0917s\n",
      "\titers: 900, epoch: 1 | loss: 0.5042391\n",
      "\tspeed: 0.0405s/iter; left time: 330.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.5909449 Vali Loss: 0.5603049 Test Loss: 0.6012501\n",
      "Validation loss decreased (inf --> 0.560305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4975006\n",
      "\tspeed: 0.1002s/iter; left time: 807.2858s\n",
      "\titers: 200, epoch: 2 | loss: 0.4123350\n",
      "\tspeed: 0.0416s/iter; left time: 330.7193s\n",
      "\titers: 300, epoch: 2 | loss: 0.3612792\n",
      "\tspeed: 0.0412s/iter; left time: 323.8013s\n",
      "\titers: 400, epoch: 2 | loss: 0.3984689\n",
      "\tspeed: 0.0402s/iter; left time: 311.8624s\n",
      "\titers: 500, epoch: 2 | loss: 0.3699860\n",
      "\tspeed: 0.0404s/iter; left time: 309.0337s\n",
      "\titers: 600, epoch: 2 | loss: 0.3737260\n",
      "\tspeed: 0.0402s/iter; left time: 303.8557s\n",
      "\titers: 700, epoch: 2 | loss: 0.4142011\n",
      "\tspeed: 0.0406s/iter; left time: 302.4482s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857327\n",
      "\tspeed: 0.0407s/iter; left time: 299.3756s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409123\n",
      "\tspeed: 0.0420s/iter; left time: 304.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.4034030 Vali Loss: 0.4392297 Test Loss: 0.4641765\n",
      "Validation loss decreased (0.560305 --> 0.439230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3298930\n",
      "\tspeed: 0.1011s/iter; left time: 723.0670s\n",
      "\titers: 200, epoch: 3 | loss: 0.3437467\n",
      "\tspeed: 0.0403s/iter; left time: 284.2172s\n",
      "\titers: 300, epoch: 3 | loss: 0.4309845\n",
      "\tspeed: 0.0404s/iter; left time: 280.7889s\n",
      "\titers: 400, epoch: 3 | loss: 0.3171408\n",
      "\tspeed: 0.0403s/iter; left time: 276.3169s\n",
      "\titers: 500, epoch: 3 | loss: 0.3937010\n",
      "\tspeed: 0.0402s/iter; left time: 271.4885s\n",
      "\titers: 600, epoch: 3 | loss: 0.3775530\n",
      "\tspeed: 0.0402s/iter; left time: 267.5785s\n",
      "\titers: 700, epoch: 3 | loss: 0.3584513\n",
      "\tspeed: 0.0404s/iter; left time: 264.7731s\n",
      "\titers: 800, epoch: 3 | loss: 0.2602788\n",
      "\tspeed: 0.0405s/iter; left time: 260.8643s\n",
      "\titers: 900, epoch: 3 | loss: 0.2889211\n",
      "\tspeed: 0.0401s/iter; left time: 254.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.3539314 Vali Loss: 0.4312690 Test Loss: 0.4557568\n",
      "Validation loss decreased (0.439230 --> 0.431269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3537179\n",
      "\tspeed: 0.0984s/iter; left time: 614.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.3129574\n",
      "\tspeed: 0.0396s/iter; left time: 243.4234s\n",
      "\titers: 300, epoch: 4 | loss: 0.2914827\n",
      "\tspeed: 0.0404s/iter; left time: 244.4321s\n",
      "\titers: 400, epoch: 4 | loss: 0.3527328\n",
      "\tspeed: 0.0405s/iter; left time: 240.5491s\n",
      "\titers: 500, epoch: 4 | loss: 0.2786991\n",
      "\tspeed: 0.0405s/iter; left time: 236.4983s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483981\n",
      "\tspeed: 0.0404s/iter; left time: 232.0143s\n",
      "\titers: 700, epoch: 4 | loss: 0.3014231\n",
      "\tspeed: 0.0403s/iter; left time: 227.4200s\n",
      "\titers: 800, epoch: 4 | loss: 0.3250557\n",
      "\tspeed: 0.0404s/iter; left time: 224.1115s\n",
      "\titers: 900, epoch: 4 | loss: 0.3409735\n",
      "\tspeed: 0.0406s/iter; left time: 221.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3276601 Vali Loss: 0.4329171 Test Loss: 0.4587655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2832368\n",
      "\tspeed: 0.0956s/iter; left time: 510.4611s\n",
      "\titers: 200, epoch: 5 | loss: 0.3461204\n",
      "\tspeed: 0.0404s/iter; left time: 211.7525s\n",
      "\titers: 300, epoch: 5 | loss: 0.3221009\n",
      "\tspeed: 0.0406s/iter; left time: 208.6126s\n",
      "\titers: 400, epoch: 5 | loss: 0.3311023\n",
      "\tspeed: 0.0403s/iter; left time: 203.1041s\n",
      "\titers: 500, epoch: 5 | loss: 0.2930217\n",
      "\tspeed: 0.0405s/iter; left time: 199.9273s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887761\n",
      "\tspeed: 0.0404s/iter; left time: 195.6071s\n",
      "\titers: 700, epoch: 5 | loss: 0.3053557\n",
      "\tspeed: 0.0405s/iter; left time: 191.6294s\n",
      "\titers: 800, epoch: 5 | loss: 0.2880615\n",
      "\tspeed: 0.0404s/iter; left time: 187.4509s\n",
      "\titers: 900, epoch: 5 | loss: 0.3189270\n",
      "\tspeed: 0.0405s/iter; left time: 183.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.95s\n",
      "Steps: 906 | Train Loss: 0.3014971 Vali Loss: 0.4485994 Test Loss: 0.4587874\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3184680\n",
      "\tspeed: 0.0970s/iter; left time: 429.6966s\n",
      "\titers: 200, epoch: 6 | loss: 0.2596821\n",
      "\tspeed: 0.0405s/iter; left time: 175.2120s\n",
      "\titers: 300, epoch: 6 | loss: 0.2904953\n",
      "\tspeed: 0.0405s/iter; left time: 171.1642s\n",
      "\titers: 400, epoch: 6 | loss: 0.3148658\n",
      "\tspeed: 0.0405s/iter; left time: 167.2058s\n",
      "\titers: 500, epoch: 6 | loss: 0.3033264\n",
      "\tspeed: 0.0403s/iter; left time: 162.5886s\n",
      "\titers: 600, epoch: 6 | loss: 0.3050017\n",
      "\tspeed: 0.0405s/iter; left time: 159.3655s\n",
      "\titers: 700, epoch: 6 | loss: 0.2470572\n",
      "\tspeed: 0.0404s/iter; left time: 154.8099s\n",
      "\titers: 800, epoch: 6 | loss: 0.2386658\n",
      "\tspeed: 0.0405s/iter; left time: 151.0734s\n",
      "\titers: 900, epoch: 6 | loss: 0.2651795\n",
      "\tspeed: 0.0402s/iter; left time: 146.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.2773427 Vali Loss: 0.4407897 Test Loss: 0.4618565\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49027326703071594, rmse:0.7001951932907104, mae:0.45565664768218994, rse:0.5541602373123169\n",
      "Original data scale mse:19207616.0, rmse:4382.6494140625, mae:2741.959716796875, rse:0.2179141640663147\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8046664\n",
      "\tspeed: 0.0724s/iter; left time: 647.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.7705905\n",
      "\tspeed: 0.0457s/iter; left time: 404.1486s\n",
      "\titers: 300, epoch: 1 | loss: 0.7503831\n",
      "\tspeed: 0.0457s/iter; left time: 399.8191s\n",
      "\titers: 400, epoch: 1 | loss: 0.7038482\n",
      "\tspeed: 0.0458s/iter; left time: 396.1757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6970635\n",
      "\tspeed: 0.0459s/iter; left time: 391.6310s\n",
      "\titers: 600, epoch: 1 | loss: 0.6281009\n",
      "\tspeed: 0.0455s/iter; left time: 384.3609s\n",
      "\titers: 700, epoch: 1 | loss: 0.6151747\n",
      "\tspeed: 0.0460s/iter; left time: 383.4296s\n",
      "\titers: 800, epoch: 1 | loss: 0.6306651\n",
      "\tspeed: 0.0459s/iter; left time: 377.9225s\n",
      "\titers: 900, epoch: 1 | loss: 0.6298555\n",
      "\tspeed: 0.0459s/iter; left time: 373.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 904 | Train Loss: 0.7062457 Vali Loss: 0.7044919 Test Loss: 0.7897239\n",
      "Validation loss decreased (inf --> 0.704492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5724813\n",
      "\tspeed: 0.1154s/iter; left time: 927.8498s\n",
      "\titers: 200, epoch: 2 | loss: 0.5583884\n",
      "\tspeed: 0.0458s/iter; left time: 363.6226s\n",
      "\titers: 300, epoch: 2 | loss: 0.5384585\n",
      "\tspeed: 0.0458s/iter; left time: 358.8274s\n",
      "\titers: 400, epoch: 2 | loss: 0.5218018\n",
      "\tspeed: 0.0459s/iter; left time: 355.4223s\n",
      "\titers: 500, epoch: 2 | loss: 0.4906337\n",
      "\tspeed: 0.0457s/iter; left time: 349.3348s\n",
      "\titers: 600, epoch: 2 | loss: 0.5179666\n",
      "\tspeed: 0.0458s/iter; left time: 344.9001s\n",
      "\titers: 700, epoch: 2 | loss: 0.4819083\n",
      "\tspeed: 0.0458s/iter; left time: 340.8807s\n",
      "\titers: 800, epoch: 2 | loss: 0.5324076\n",
      "\tspeed: 0.0459s/iter; left time: 336.6639s\n",
      "\titers: 900, epoch: 2 | loss: 0.4802623\n",
      "\tspeed: 0.0458s/iter; left time: 331.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.68s\n",
      "Steps: 904 | Train Loss: 0.5296305 Vali Loss: 0.5895641 Test Loss: 0.6527810\n",
      "Validation loss decreased (0.704492 --> 0.589564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5235303\n",
      "\tspeed: 0.1110s/iter; left time: 791.5479s\n",
      "\titers: 200, epoch: 3 | loss: 0.4529510\n",
      "\tspeed: 0.0354s/iter; left time: 248.6696s\n",
      "\titers: 300, epoch: 3 | loss: 0.4261545\n",
      "\tspeed: 0.0354s/iter; left time: 245.0847s\n",
      "\titers: 400, epoch: 3 | loss: 0.4284749\n",
      "\tspeed: 0.0355s/iter; left time: 242.4088s\n",
      "\titers: 500, epoch: 3 | loss: 0.4677834\n",
      "\tspeed: 0.0354s/iter; left time: 238.3191s\n",
      "\titers: 600, epoch: 3 | loss: 0.4825233\n",
      "\tspeed: 0.0354s/iter; left time: 234.6645s\n",
      "\titers: 700, epoch: 3 | loss: 0.4077120\n",
      "\tspeed: 0.0354s/iter; left time: 231.4083s\n",
      "\titers: 800, epoch: 3 | loss: 0.4685313\n",
      "\tspeed: 0.0356s/iter; left time: 228.7521s\n",
      "\titers: 900, epoch: 3 | loss: 0.4599987\n",
      "\tspeed: 0.0354s/iter; left time: 224.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 904 | Train Loss: 0.4619799 Vali Loss: 0.5771369 Test Loss: 0.6438022\n",
      "Validation loss decreased (0.589564 --> 0.577137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4089474\n",
      "\tspeed: 0.1143s/iter; left time: 711.7381s\n",
      "\titers: 200, epoch: 4 | loss: 0.4214315\n",
      "\tspeed: 0.0454s/iter; left time: 278.4686s\n",
      "\titers: 300, epoch: 4 | loss: 0.4180072\n",
      "\tspeed: 0.0445s/iter; left time: 268.2094s\n",
      "\titers: 400, epoch: 4 | loss: 0.3611583\n",
      "\tspeed: 0.0457s/iter; left time: 270.9289s\n",
      "\titers: 500, epoch: 4 | loss: 0.4712610\n",
      "\tspeed: 0.0449s/iter; left time: 261.5814s\n",
      "\titers: 600, epoch: 4 | loss: 0.3901211\n",
      "\tspeed: 0.0459s/iter; left time: 262.8894s\n",
      "\titers: 700, epoch: 4 | loss: 0.4416049\n",
      "\tspeed: 0.0457s/iter; left time: 256.9995s\n",
      "\titers: 800, epoch: 4 | loss: 0.4008536\n",
      "\tspeed: 0.0459s/iter; left time: 253.6396s\n",
      "\titers: 900, epoch: 4 | loss: 0.4347542\n",
      "\tspeed: 0.0439s/iter; left time: 238.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.4246630 Vali Loss: 0.5828032 Test Loss: 0.6657495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3883911\n",
      "\tspeed: 0.1116s/iter; left time: 594.3719s\n",
      "\titers: 200, epoch: 5 | loss: 0.4428380\n",
      "\tspeed: 0.0461s/iter; left time: 241.1116s\n",
      "\titers: 300, epoch: 5 | loss: 0.4127674\n",
      "\tspeed: 0.0454s/iter; left time: 232.7100s\n",
      "\titers: 400, epoch: 5 | loss: 0.3990879\n",
      "\tspeed: 0.0456s/iter; left time: 228.9784s\n",
      "\titers: 500, epoch: 5 | loss: 0.3641529\n",
      "\tspeed: 0.0459s/iter; left time: 226.0345s\n",
      "\titers: 600, epoch: 5 | loss: 0.3592767\n",
      "\tspeed: 0.0459s/iter; left time: 221.2863s\n",
      "\titers: 700, epoch: 5 | loss: 0.3591104\n",
      "\tspeed: 0.0461s/iter; left time: 217.8790s\n",
      "\titers: 800, epoch: 5 | loss: 0.3547353\n",
      "\tspeed: 0.0460s/iter; left time: 212.9269s\n",
      "\titers: 900, epoch: 5 | loss: 0.3660108\n",
      "\tspeed: 0.0459s/iter; left time: 207.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 904 | Train Loss: 0.3870160 Vali Loss: 0.5739987 Test Loss: 0.6677375\n",
      "Validation loss decreased (0.577137 --> 0.573999).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3589998\n",
      "\tspeed: 0.1151s/iter; left time: 508.6784s\n",
      "\titers: 200, epoch: 6 | loss: 0.3397861\n",
      "\tspeed: 0.0461s/iter; left time: 199.2801s\n",
      "\titers: 300, epoch: 6 | loss: 0.3761511\n",
      "\tspeed: 0.0461s/iter; left time: 194.7237s\n",
      "\titers: 400, epoch: 6 | loss: 0.3682893\n",
      "\tspeed: 0.0459s/iter; left time: 189.0696s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682757\n",
      "\tspeed: 0.0458s/iter; left time: 184.2603s\n",
      "\titers: 600, epoch: 6 | loss: 0.3621927\n",
      "\tspeed: 0.0458s/iter; left time: 179.5531s\n",
      "\titers: 700, epoch: 6 | loss: 0.3596643\n",
      "\tspeed: 0.0458s/iter; left time: 174.8186s\n",
      "\titers: 800, epoch: 6 | loss: 0.3902473\n",
      "\tspeed: 0.0457s/iter; left time: 169.9050s\n",
      "\titers: 900, epoch: 6 | loss: 0.3462842\n",
      "\tspeed: 0.0459s/iter; left time: 166.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.3578898 Vali Loss: 0.5850427 Test Loss: 0.6497733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3130277\n",
      "\tspeed: 0.1132s/iter; left time: 398.0754s\n",
      "\titers: 200, epoch: 7 | loss: 0.3050972\n",
      "\tspeed: 0.0461s/iter; left time: 157.6356s\n",
      "\titers: 300, epoch: 7 | loss: 0.3185982\n",
      "\tspeed: 0.0450s/iter; left time: 149.1561s\n",
      "\titers: 400, epoch: 7 | loss: 0.3193868\n",
      "\tspeed: 0.0423s/iter; left time: 135.9714s\n",
      "\titers: 500, epoch: 7 | loss: 0.3336236\n",
      "\tspeed: 0.0476s/iter; left time: 148.3270s\n",
      "\titers: 600, epoch: 7 | loss: 0.3138655\n",
      "\tspeed: 0.0461s/iter; left time: 139.0312s\n",
      "\titers: 700, epoch: 7 | loss: 0.3336879\n",
      "\tspeed: 0.0470s/iter; left time: 137.2171s\n",
      "\titers: 800, epoch: 7 | loss: 0.3205555\n",
      "\tspeed: 0.0457s/iter; left time: 128.7554s\n",
      "\titers: 900, epoch: 7 | loss: 0.3355069\n",
      "\tspeed: 0.0458s/iter; left time: 124.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.3297362 Vali Loss: 0.5939113 Test Loss: 0.6703900\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3147684\n",
      "\tspeed: 0.1118s/iter; left time: 292.0150s\n",
      "\titers: 200, epoch: 8 | loss: 0.3183024\n",
      "\tspeed: 0.0460s/iter; left time: 115.4913s\n",
      "\titers: 300, epoch: 8 | loss: 0.3203939\n",
      "\tspeed: 0.0452s/iter; left time: 108.9698s\n",
      "\titers: 400, epoch: 8 | loss: 0.2972348\n",
      "\tspeed: 0.0459s/iter; left time: 106.1980s\n",
      "\titers: 500, epoch: 8 | loss: 0.3417727\n",
      "\tspeed: 0.0457s/iter; left time: 101.2255s\n",
      "\titers: 600, epoch: 8 | loss: 0.3158745\n",
      "\tspeed: 0.0458s/iter; left time: 96.8003s\n",
      "\titers: 700, epoch: 8 | loss: 0.3234260\n",
      "\tspeed: 0.0461s/iter; left time: 92.8591s\n",
      "\titers: 800, epoch: 8 | loss: 0.3083707\n",
      "\tspeed: 0.0458s/iter; left time: 87.6825s\n",
      "\titers: 900, epoch: 8 | loss: 0.3016308\n",
      "\tspeed: 0.0458s/iter; left time: 83.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.3082505 Vali Loss: 0.5874403 Test Loss: 0.6553872\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9519941806793213, rmse:0.9757018685340881, mae:0.6666859984397888, rse:0.7738518118858337\n",
      "Original data scale mse:41247308.0, rmse:6422.40673828125, mae:4063.66357421875, rse:0.31983813643455505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8010994\n",
      "\tspeed: 0.0477s/iter; left time: 426.1691s\n",
      "\titers: 200, epoch: 1 | loss: 0.7328934\n",
      "\tspeed: 0.0455s/iter; left time: 402.6452s\n",
      "\titers: 300, epoch: 1 | loss: 0.6795613\n",
      "\tspeed: 0.0457s/iter; left time: 399.6043s\n",
      "\titers: 400, epoch: 1 | loss: 0.6432170\n",
      "\tspeed: 0.0457s/iter; left time: 394.9619s\n",
      "\titers: 500, epoch: 1 | loss: 0.6418213\n",
      "\tspeed: 0.0447s/iter; left time: 381.7209s\n",
      "\titers: 600, epoch: 1 | loss: 0.6962131\n",
      "\tspeed: 0.0459s/iter; left time: 387.0834s\n",
      "\titers: 700, epoch: 1 | loss: 0.6652902\n",
      "\tspeed: 0.0455s/iter; left time: 379.7670s\n",
      "\titers: 800, epoch: 1 | loss: 0.6485575\n",
      "\tspeed: 0.0461s/iter; left time: 379.7909s\n",
      "\titers: 900, epoch: 1 | loss: 0.6165783\n",
      "\tspeed: 0.0458s/iter; left time: 373.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.51s\n",
      "Steps: 904 | Train Loss: 0.7043722 Vali Loss: 0.7044099 Test Loss: 0.7934921\n",
      "Validation loss decreased (inf --> 0.704410).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5258688\n",
      "\tspeed: 0.1161s/iter; left time: 933.3058s\n",
      "\titers: 200, epoch: 2 | loss: 0.5637795\n",
      "\tspeed: 0.0460s/iter; left time: 364.8862s\n",
      "\titers: 300, epoch: 2 | loss: 0.4972985\n",
      "\tspeed: 0.0458s/iter; left time: 359.2056s\n",
      "\titers: 400, epoch: 2 | loss: 0.5150353\n",
      "\tspeed: 0.0459s/iter; left time: 355.4718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4983087\n",
      "\tspeed: 0.0458s/iter; left time: 349.9889s\n",
      "\titers: 600, epoch: 2 | loss: 0.5076133\n",
      "\tspeed: 0.0459s/iter; left time: 345.9691s\n",
      "\titers: 700, epoch: 2 | loss: 0.5290806\n",
      "\tspeed: 0.0455s/iter; left time: 338.6768s\n",
      "\titers: 800, epoch: 2 | loss: 0.4902735\n",
      "\tspeed: 0.0457s/iter; left time: 335.0613s\n",
      "\titers: 900, epoch: 2 | loss: 0.4747526\n",
      "\tspeed: 0.0454s/iter; left time: 328.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.5341266 Vali Loss: 0.6049233 Test Loss: 0.6428112\n",
      "Validation loss decreased (0.704410 --> 0.604923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4757680\n",
      "\tspeed: 0.1175s/iter; left time: 837.9578s\n",
      "\titers: 200, epoch: 3 | loss: 0.5231443\n",
      "\tspeed: 0.0461s/iter; left time: 324.1669s\n",
      "\titers: 300, epoch: 3 | loss: 0.4881614\n",
      "\tspeed: 0.0458s/iter; left time: 317.6889s\n",
      "\titers: 400, epoch: 3 | loss: 0.4571269\n",
      "\tspeed: 0.0461s/iter; left time: 314.8910s\n",
      "\titers: 500, epoch: 3 | loss: 0.4369162\n",
      "\tspeed: 0.0459s/iter; left time: 309.1930s\n",
      "\titers: 600, epoch: 3 | loss: 0.4874011\n",
      "\tspeed: 0.0461s/iter; left time: 306.0271s\n",
      "\titers: 700, epoch: 3 | loss: 0.4290618\n",
      "\tspeed: 0.0459s/iter; left time: 300.1230s\n",
      "\titers: 800, epoch: 3 | loss: 0.4576441\n",
      "\tspeed: 0.0458s/iter; left time: 294.5411s\n",
      "\titers: 900, epoch: 3 | loss: 0.4671273\n",
      "\tspeed: 0.0458s/iter; left time: 290.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.81s\n",
      "Steps: 904 | Train Loss: 0.4611585 Vali Loss: 0.6028454 Test Loss: 0.6184371\n",
      "Validation loss decreased (0.604923 --> 0.602845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3998677\n",
      "\tspeed: 0.1148s/iter; left time: 715.1837s\n",
      "\titers: 200, epoch: 4 | loss: 0.4132229\n",
      "\tspeed: 0.0461s/iter; left time: 282.7738s\n",
      "\titers: 300, epoch: 4 | loss: 0.4334919\n",
      "\tspeed: 0.0457s/iter; left time: 275.8183s\n",
      "\titers: 400, epoch: 4 | loss: 0.4044308\n",
      "\tspeed: 0.0457s/iter; left time: 270.9796s\n",
      "\titers: 500, epoch: 4 | loss: 0.4421014\n",
      "\tspeed: 0.0456s/iter; left time: 265.8166s\n",
      "\titers: 600, epoch: 4 | loss: 0.3875317\n",
      "\tspeed: 0.0456s/iter; left time: 261.1960s\n",
      "\titers: 700, epoch: 4 | loss: 0.4230910\n",
      "\tspeed: 0.0460s/iter; left time: 258.8495s\n",
      "\titers: 800, epoch: 4 | loss: 0.3707693\n",
      "\tspeed: 0.0463s/iter; left time: 255.8662s\n",
      "\titers: 900, epoch: 4 | loss: 0.3769258\n",
      "\tspeed: 0.0459s/iter; left time: 249.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.62s\n",
      "Steps: 904 | Train Loss: 0.4218997 Vali Loss: 0.5859396 Test Loss: 0.6591363\n",
      "Validation loss decreased (0.602845 --> 0.585940).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3925479\n",
      "\tspeed: 0.1153s/iter; left time: 613.7240s\n",
      "\titers: 200, epoch: 5 | loss: 0.4102021\n",
      "\tspeed: 0.0457s/iter; left time: 238.5659s\n",
      "\titers: 300, epoch: 5 | loss: 0.3620060\n",
      "\tspeed: 0.0458s/iter; left time: 234.5876s\n",
      "\titers: 400, epoch: 5 | loss: 0.3668549\n",
      "\tspeed: 0.0461s/iter; left time: 231.8310s\n",
      "\titers: 500, epoch: 5 | loss: 0.3692132\n",
      "\tspeed: 0.0455s/iter; left time: 224.2338s\n",
      "\titers: 600, epoch: 5 | loss: 0.4087869\n",
      "\tspeed: 0.0459s/iter; left time: 221.3830s\n",
      "\titers: 700, epoch: 5 | loss: 0.4011775\n",
      "\tspeed: 0.0453s/iter; left time: 213.9217s\n",
      "\titers: 800, epoch: 5 | loss: 0.3626934\n",
      "\tspeed: 0.0453s/iter; left time: 209.4461s\n",
      "\titers: 900, epoch: 5 | loss: 0.3683335\n",
      "\tspeed: 0.0457s/iter; left time: 206.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.52s\n",
      "Steps: 904 | Train Loss: 0.3884230 Vali Loss: 0.5717269 Test Loss: 0.6363498\n",
      "Validation loss decreased (0.585940 --> 0.571727).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3924609\n",
      "\tspeed: 0.1149s/iter; left time: 507.9962s\n",
      "\titers: 200, epoch: 6 | loss: 0.3637329\n",
      "\tspeed: 0.0453s/iter; left time: 195.7473s\n",
      "\titers: 300, epoch: 6 | loss: 0.3533712\n",
      "\tspeed: 0.0459s/iter; left time: 193.7855s\n",
      "\titers: 400, epoch: 6 | loss: 0.3886940\n",
      "\tspeed: 0.0461s/iter; left time: 189.7898s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682318\n",
      "\tspeed: 0.0457s/iter; left time: 183.7717s\n",
      "\titers: 600, epoch: 6 | loss: 0.3522940\n",
      "\tspeed: 0.0459s/iter; left time: 179.9156s\n",
      "\titers: 700, epoch: 6 | loss: 0.3701428\n",
      "\tspeed: 0.0457s/iter; left time: 174.6223s\n",
      "\titers: 800, epoch: 6 | loss: 0.3493035\n",
      "\tspeed: 0.0457s/iter; left time: 170.0025s\n",
      "\titers: 900, epoch: 6 | loss: 0.3459255\n",
      "\tspeed: 0.0456s/iter; left time: 165.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 904 | Train Loss: 0.3607185 Vali Loss: 0.5945458 Test Loss: 0.6467904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3271553\n",
      "\tspeed: 0.1123s/iter; left time: 394.9102s\n",
      "\titers: 200, epoch: 7 | loss: 0.3415232\n",
      "\tspeed: 0.0483s/iter; left time: 165.0600s\n",
      "\titers: 300, epoch: 7 | loss: 0.3429954\n",
      "\tspeed: 0.0365s/iter; left time: 121.1208s\n",
      "\titers: 400, epoch: 7 | loss: 0.3336126\n",
      "\tspeed: 0.0354s/iter; left time: 113.9251s\n",
      "\titers: 500, epoch: 7 | loss: 0.3125392\n",
      "\tspeed: 0.0355s/iter; left time: 110.6653s\n",
      "\titers: 600, epoch: 7 | loss: 0.3629393\n",
      "\tspeed: 0.0355s/iter; left time: 106.9565s\n",
      "\titers: 700, epoch: 7 | loss: 0.3249076\n",
      "\tspeed: 0.0354s/iter; left time: 103.3208s\n",
      "\titers: 800, epoch: 7 | loss: 0.3575486\n",
      "\tspeed: 0.0354s/iter; left time: 99.7238s\n",
      "\titers: 900, epoch: 7 | loss: 0.3155114\n",
      "\tspeed: 0.0356s/iter; left time: 96.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.80s\n",
      "Steps: 904 | Train Loss: 0.3354452 Vali Loss: 0.5961151 Test Loss: 0.6505117\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3284198\n",
      "\tspeed: 0.1122s/iter; left time: 293.1909s\n",
      "\titers: 200, epoch: 8 | loss: 0.2889812\n",
      "\tspeed: 0.0462s/iter; left time: 116.0487s\n",
      "\titers: 300, epoch: 8 | loss: 0.3065237\n",
      "\tspeed: 0.0462s/iter; left time: 111.4147s\n",
      "\titers: 400, epoch: 8 | loss: 0.3156983\n",
      "\tspeed: 0.0464s/iter; left time: 107.3252s\n",
      "\titers: 500, epoch: 8 | loss: 0.3216363\n",
      "\tspeed: 0.0462s/iter; left time: 102.2223s\n",
      "\titers: 600, epoch: 8 | loss: 0.2931251\n",
      "\tspeed: 0.0459s/iter; left time: 96.9334s\n",
      "\titers: 700, epoch: 8 | loss: 0.3140359\n",
      "\tspeed: 0.0459s/iter; left time: 92.4110s\n",
      "\titers: 800, epoch: 8 | loss: 0.3071438\n",
      "\tspeed: 0.0459s/iter; left time: 87.7276s\n",
      "\titers: 900, epoch: 8 | loss: 0.3071236\n",
      "\tspeed: 0.0458s/iter; left time: 82.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 904 | Train Loss: 0.3142988 Vali Loss: 0.5842171 Test Loss: 0.6662861\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8675479292869568, rmse:0.9314225316047668, mae:0.6356421113014221, rse:0.7387328743934631\n",
      "Original data scale mse:37667352.0, rmse:6137.37353515625, mae:3862.161865234375, rse:0.3056434094905853\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7432280\n",
      "\tspeed: 0.0807s/iter; left time: 719.8680s\n",
      "\titers: 200, epoch: 1 | loss: 0.7924978\n",
      "\tspeed: 0.0537s/iter; left time: 473.3559s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319275\n",
      "\tspeed: 0.0536s/iter; left time: 467.3100s\n",
      "\titers: 400, epoch: 1 | loss: 0.7333213\n",
      "\tspeed: 0.0523s/iter; left time: 451.1451s\n",
      "\titers: 500, epoch: 1 | loss: 0.7180915\n",
      "\tspeed: 0.0519s/iter; left time: 442.4606s\n",
      "\titers: 600, epoch: 1 | loss: 0.7430111\n",
      "\tspeed: 0.0518s/iter; left time: 436.2132s\n",
      "\titers: 700, epoch: 1 | loss: 0.7065840\n",
      "\tspeed: 0.0520s/iter; left time: 432.7969s\n",
      "\titers: 800, epoch: 1 | loss: 0.6746759\n",
      "\tspeed: 0.0523s/iter; left time: 429.5860s\n",
      "\titers: 900, epoch: 1 | loss: 0.7036165\n",
      "\tspeed: 0.0520s/iter; left time: 422.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.09s\n",
      "Steps: 902 | Train Loss: 0.7345527 Vali Loss: 0.7737989 Test Loss: 0.8803952\n",
      "Validation loss decreased (inf --> 0.773799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6868786\n",
      "\tspeed: 0.1342s/iter; left time: 1075.7972s\n",
      "\titers: 200, epoch: 2 | loss: 0.6350537\n",
      "\tspeed: 0.0522s/iter; left time: 413.4198s\n",
      "\titers: 300, epoch: 2 | loss: 0.6338754\n",
      "\tspeed: 0.0516s/iter; left time: 403.4469s\n",
      "\titers: 400, epoch: 2 | loss: 0.5741463\n",
      "\tspeed: 0.0517s/iter; left time: 398.8507s\n",
      "\titers: 500, epoch: 2 | loss: 0.5673126\n",
      "\tspeed: 0.0514s/iter; left time: 391.7749s\n",
      "\titers: 600, epoch: 2 | loss: 0.5258488\n",
      "\tspeed: 0.0516s/iter; left time: 388.2298s\n",
      "\titers: 700, epoch: 2 | loss: 0.5364168\n",
      "\tspeed: 0.0517s/iter; left time: 383.9168s\n",
      "\titers: 800, epoch: 2 | loss: 0.5658613\n",
      "\tspeed: 0.0514s/iter; left time: 376.3875s\n",
      "\titers: 900, epoch: 2 | loss: 0.4998148\n",
      "\tspeed: 0.0514s/iter; left time: 370.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.5770481 Vali Loss: 0.6151103 Test Loss: 0.6770754\n",
      "Validation loss decreased (0.773799 --> 0.615110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5180974\n",
      "\tspeed: 0.1333s/iter; left time: 949.0086s\n",
      "\titers: 200, epoch: 3 | loss: 0.4734910\n",
      "\tspeed: 0.0516s/iter; left time: 361.8154s\n",
      "\titers: 300, epoch: 3 | loss: 0.4999493\n",
      "\tspeed: 0.0518s/iter; left time: 358.1624s\n",
      "\titers: 400, epoch: 3 | loss: 0.5183615\n",
      "\tspeed: 0.0511s/iter; left time: 348.1803s\n",
      "\titers: 500, epoch: 3 | loss: 0.4752620\n",
      "\tspeed: 0.0426s/iter; left time: 286.2387s\n",
      "\titers: 600, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0515s/iter; left time: 340.5576s\n",
      "\titers: 700, epoch: 3 | loss: 0.5015286\n",
      "\tspeed: 0.0524s/iter; left time: 341.5130s\n",
      "\titers: 800, epoch: 3 | loss: 0.4726277\n",
      "\tspeed: 0.0519s/iter; left time: 333.1788s\n",
      "\titers: 900, epoch: 3 | loss: 0.4481099\n",
      "\tspeed: 0.0521s/iter; left time: 329.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.4826820 Vali Loss: 0.6081653 Test Loss: 0.6789765\n",
      "Validation loss decreased (0.615110 --> 0.608165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4161480\n",
      "\tspeed: 0.1344s/iter; left time: 835.2701s\n",
      "\titers: 200, epoch: 4 | loss: 0.4256495\n",
      "\tspeed: 0.0519s/iter; left time: 317.5265s\n",
      "\titers: 300, epoch: 4 | loss: 0.4600742\n",
      "\tspeed: 0.0520s/iter; left time: 312.4819s\n",
      "\titers: 400, epoch: 4 | loss: 0.4594116\n",
      "\tspeed: 0.0516s/iter; left time: 305.1571s\n",
      "\titers: 500, epoch: 4 | loss: 0.4682472\n",
      "\tspeed: 0.0518s/iter; left time: 301.3343s\n",
      "\titers: 600, epoch: 4 | loss: 0.4279153\n",
      "\tspeed: 0.0517s/iter; left time: 295.3216s\n",
      "\titers: 700, epoch: 4 | loss: 0.4593164\n",
      "\tspeed: 0.0516s/iter; left time: 289.9734s\n",
      "\titers: 800, epoch: 4 | loss: 0.4496114\n",
      "\tspeed: 0.0521s/iter; left time: 287.3274s\n",
      "\titers: 900, epoch: 4 | loss: 0.4105683\n",
      "\tspeed: 0.0517s/iter; left time: 279.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.08s\n",
      "Steps: 902 | Train Loss: 0.4414160 Vali Loss: 0.6163542 Test Loss: 0.6771622\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4379938\n",
      "\tspeed: 0.1297s/iter; left time: 689.1495s\n",
      "\titers: 200, epoch: 5 | loss: 0.4133421\n",
      "\tspeed: 0.0525s/iter; left time: 273.4757s\n",
      "\titers: 300, epoch: 5 | loss: 0.4182612\n",
      "\tspeed: 0.0522s/iter; left time: 266.8148s\n",
      "\titers: 400, epoch: 5 | loss: 0.4328923\n",
      "\tspeed: 0.0520s/iter; left time: 260.7970s\n",
      "\titers: 500, epoch: 5 | loss: 0.3644622\n",
      "\tspeed: 0.0518s/iter; left time: 254.5846s\n",
      "\titers: 600, epoch: 5 | loss: 0.4028292\n",
      "\tspeed: 0.0517s/iter; left time: 248.8532s\n",
      "\titers: 700, epoch: 5 | loss: 0.4268283\n",
      "\tspeed: 0.0518s/iter; left time: 244.0483s\n",
      "\titers: 800, epoch: 5 | loss: 0.3848646\n",
      "\tspeed: 0.0520s/iter; left time: 239.9750s\n",
      "\titers: 900, epoch: 5 | loss: 0.3503802\n",
      "\tspeed: 0.0516s/iter; left time: 232.6932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 902 | Train Loss: 0.4047783 Vali Loss: 0.6162719 Test Loss: 0.7085742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3884669\n",
      "\tspeed: 0.1305s/iter; left time: 575.4842s\n",
      "\titers: 200, epoch: 6 | loss: 0.3919015\n",
      "\tspeed: 0.0521s/iter; left time: 224.6280s\n",
      "\titers: 300, epoch: 6 | loss: 0.3709927\n",
      "\tspeed: 0.0523s/iter; left time: 220.4367s\n",
      "\titers: 400, epoch: 6 | loss: 0.4029219\n",
      "\tspeed: 0.0521s/iter; left time: 214.2599s\n",
      "\titers: 500, epoch: 6 | loss: 0.3664319\n",
      "\tspeed: 0.0522s/iter; left time: 209.3621s\n",
      "\titers: 600, epoch: 6 | loss: 0.3598861\n",
      "\tspeed: 0.0518s/iter; left time: 202.7663s\n",
      "\titers: 700, epoch: 6 | loss: 0.3954958\n",
      "\tspeed: 0.0520s/iter; left time: 198.1453s\n",
      "\titers: 800, epoch: 6 | loss: 0.3583177\n",
      "\tspeed: 0.0514s/iter; left time: 190.6933s\n",
      "\titers: 900, epoch: 6 | loss: 0.3972457\n",
      "\tspeed: 0.0518s/iter; left time: 187.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3720988 Vali Loss: 0.6230050 Test Loss: 0.7020154\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9181895852088928, rmse:0.9582220911979675, mae:0.6792442202568054, rse:0.7590816020965576\n",
      "Original data scale mse:39692484.0, rmse:6300.197265625, mae:4161.8623046875, rse:0.31390610337257385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8304041\n",
      "\tspeed: 0.0544s/iter; left time: 485.0321s\n",
      "\titers: 200, epoch: 1 | loss: 0.7432838\n",
      "\tspeed: 0.0519s/iter; left time: 457.4525s\n",
      "\titers: 300, epoch: 1 | loss: 0.7456986\n",
      "\tspeed: 0.0520s/iter; left time: 453.1677s\n",
      "\titers: 400, epoch: 1 | loss: 0.6537443\n",
      "\tspeed: 0.0519s/iter; left time: 447.2635s\n",
      "\titers: 500, epoch: 1 | loss: 0.7623785\n",
      "\tspeed: 0.0518s/iter; left time: 441.0954s\n",
      "\titers: 600, epoch: 1 | loss: 0.6968405\n",
      "\tspeed: 0.0517s/iter; left time: 435.0291s\n",
      "\titers: 700, epoch: 1 | loss: 0.6879818\n",
      "\tspeed: 0.0513s/iter; left time: 426.7210s\n",
      "\titers: 800, epoch: 1 | loss: 0.6725203\n",
      "\tspeed: 0.0470s/iter; left time: 386.5256s\n",
      "\titers: 900, epoch: 1 | loss: 0.6846584\n",
      "\tspeed: 0.0431s/iter; left time: 349.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.65s\n",
      "Steps: 902 | Train Loss: 0.7359149 Vali Loss: 0.7748347 Test Loss: 0.8825503\n",
      "Validation loss decreased (inf --> 0.774835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6500419\n",
      "\tspeed: 0.1331s/iter; left time: 1067.5603s\n",
      "\titers: 200, epoch: 2 | loss: 0.6053997\n",
      "\tspeed: 0.0523s/iter; left time: 414.5433s\n",
      "\titers: 300, epoch: 2 | loss: 0.5713702\n",
      "\tspeed: 0.0520s/iter; left time: 406.7352s\n",
      "\titers: 400, epoch: 2 | loss: 0.5136937\n",
      "\tspeed: 0.0524s/iter; left time: 404.3244s\n",
      "\titers: 500, epoch: 2 | loss: 0.5401712\n",
      "\tspeed: 0.0520s/iter; left time: 395.8869s\n",
      "\titers: 600, epoch: 2 | loss: 0.5388100\n",
      "\tspeed: 0.0517s/iter; left time: 388.9994s\n",
      "\titers: 700, epoch: 2 | loss: 0.5284830\n",
      "\tspeed: 0.0515s/iter; left time: 382.2624s\n",
      "\titers: 800, epoch: 2 | loss: 0.4723913\n",
      "\tspeed: 0.0515s/iter; left time: 376.6242s\n",
      "\titers: 900, epoch: 2 | loss: 0.4965907\n",
      "\tspeed: 0.0517s/iter; left time: 373.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.13s\n",
      "Steps: 902 | Train Loss: 0.5826588 Vali Loss: 0.6296505 Test Loss: 0.6879032\n",
      "Validation loss decreased (0.774835 --> 0.629650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4773910\n",
      "\tspeed: 0.1347s/iter; left time: 958.8615s\n",
      "\titers: 200, epoch: 3 | loss: 0.5161944\n",
      "\tspeed: 0.0520s/iter; left time: 364.6570s\n",
      "\titers: 300, epoch: 3 | loss: 0.5555186\n",
      "\tspeed: 0.0518s/iter; left time: 357.9759s\n",
      "\titers: 400, epoch: 3 | loss: 0.4888589\n",
      "\tspeed: 0.0513s/iter; left time: 349.9013s\n",
      "\titers: 500, epoch: 3 | loss: 0.4900426\n",
      "\tspeed: 0.0520s/iter; left time: 349.4163s\n",
      "\titers: 600, epoch: 3 | loss: 0.4695053\n",
      "\tspeed: 0.0516s/iter; left time: 341.2672s\n",
      "\titers: 700, epoch: 3 | loss: 0.4767488\n",
      "\tspeed: 0.0516s/iter; left time: 336.1538s\n",
      "\titers: 800, epoch: 3 | loss: 0.4401937\n",
      "\tspeed: 0.0515s/iter; left time: 330.2252s\n",
      "\titers: 900, epoch: 3 | loss: 0.4702183\n",
      "\tspeed: 0.0519s/iter; left time: 328.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.05s\n",
      "Steps: 902 | Train Loss: 0.4825615 Vali Loss: 0.6113480 Test Loss: 0.6961012\n",
      "Validation loss decreased (0.629650 --> 0.611348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552673\n",
      "\tspeed: 0.1341s/iter; left time: 833.5766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4182002\n",
      "\tspeed: 0.0519s/iter; left time: 317.2629s\n",
      "\titers: 300, epoch: 4 | loss: 0.4482407\n",
      "\tspeed: 0.0518s/iter; left time: 311.4085s\n",
      "\titers: 400, epoch: 4 | loss: 0.4379449\n",
      "\tspeed: 0.0520s/iter; left time: 307.3957s\n",
      "\titers: 500, epoch: 4 | loss: 0.4325068\n",
      "\tspeed: 0.0521s/iter; left time: 302.9142s\n",
      "\titers: 600, epoch: 4 | loss: 0.4607576\n",
      "\tspeed: 0.0521s/iter; left time: 297.8501s\n",
      "\titers: 700, epoch: 4 | loss: 0.4113523\n",
      "\tspeed: 0.0522s/iter; left time: 292.8557s\n",
      "\titers: 800, epoch: 4 | loss: 0.4501538\n",
      "\tspeed: 0.0517s/iter; left time: 285.1297s\n",
      "\titers: 900, epoch: 4 | loss: 0.4170002\n",
      "\tspeed: 0.0521s/iter; left time: 282.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.4399437 Vali Loss: 0.6030498 Test Loss: 0.6659666\n",
      "Validation loss decreased (0.611348 --> 0.603050).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3798306\n",
      "\tspeed: 0.1334s/iter; left time: 708.6417s\n",
      "\titers: 200, epoch: 5 | loss: 0.4068514\n",
      "\tspeed: 0.0518s/iter; left time: 270.1549s\n",
      "\titers: 300, epoch: 5 | loss: 0.4011664\n",
      "\tspeed: 0.0518s/iter; left time: 265.0765s\n",
      "\titers: 400, epoch: 5 | loss: 0.4041094\n",
      "\tspeed: 0.0516s/iter; left time: 258.8148s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307121\n",
      "\tspeed: 0.0517s/iter; left time: 253.8068s\n",
      "\titers: 600, epoch: 5 | loss: 0.3717445\n",
      "\tspeed: 0.0520s/iter; left time: 250.4080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3898468\n",
      "\tspeed: 0.0532s/iter; left time: 250.7959s\n",
      "\titers: 800, epoch: 5 | loss: 0.3740286\n",
      "\tspeed: 0.0531s/iter; left time: 245.0274s\n",
      "\titers: 900, epoch: 5 | loss: 0.4056983\n",
      "\tspeed: 0.0531s/iter; left time: 239.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.3987529 Vali Loss: 0.6140500 Test Loss: 0.6948121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3816989\n",
      "\tspeed: 0.1301s/iter; left time: 573.7769s\n",
      "\titers: 200, epoch: 6 | loss: 0.3667590\n",
      "\tspeed: 0.0521s/iter; left time: 224.5628s\n",
      "\titers: 300, epoch: 6 | loss: 0.3843067\n",
      "\tspeed: 0.0518s/iter; left time: 218.3376s\n",
      "\titers: 400, epoch: 6 | loss: 0.3731487\n",
      "\tspeed: 0.0520s/iter; left time: 213.7879s\n",
      "\titers: 500, epoch: 6 | loss: 0.3392414\n",
      "\tspeed: 0.0518s/iter; left time: 207.5796s\n",
      "\titers: 600, epoch: 6 | loss: 0.3976587\n",
      "\tspeed: 0.0521s/iter; left time: 203.6888s\n",
      "\titers: 700, epoch: 6 | loss: 0.3745137\n",
      "\tspeed: 0.0516s/iter; left time: 196.7519s\n",
      "\titers: 800, epoch: 6 | loss: 0.3319488\n",
      "\tspeed: 0.0515s/iter; left time: 191.2482s\n",
      "\titers: 900, epoch: 6 | loss: 0.3574228\n",
      "\tspeed: 0.0516s/iter; left time: 186.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 902 | Train Loss: 0.3675826 Vali Loss: 0.6191680 Test Loss: 0.6964089\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3543683\n",
      "\tspeed: 0.1299s/iter; left time: 455.9251s\n",
      "\titers: 200, epoch: 7 | loss: 0.3584929\n",
      "\tspeed: 0.0523s/iter; left time: 178.2602s\n",
      "\titers: 300, epoch: 7 | loss: 0.3529427\n",
      "\tspeed: 0.0521s/iter; left time: 172.4137s\n",
      "\titers: 400, epoch: 7 | loss: 0.3259368\n",
      "\tspeed: 0.0520s/iter; left time: 166.8200s\n",
      "\titers: 500, epoch: 7 | loss: 0.3047194\n",
      "\tspeed: 0.0522s/iter; left time: 162.1372s\n",
      "\titers: 600, epoch: 7 | loss: 0.3544034\n",
      "\tspeed: 0.0520s/iter; left time: 156.5334s\n",
      "\titers: 700, epoch: 7 | loss: 0.3244225\n",
      "\tspeed: 0.0523s/iter; left time: 152.1703s\n",
      "\titers: 800, epoch: 7 | loss: 0.3500791\n",
      "\tspeed: 0.0520s/iter; left time: 145.9934s\n",
      "\titers: 900, epoch: 7 | loss: 0.3353058\n",
      "\tspeed: 0.0528s/iter; left time: 142.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 902 | Train Loss: 0.3403212 Vali Loss: 0.6217956 Test Loss: 0.7023885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9471843242645264, rmse:0.9732339382171631, mae:0.6660405993461609, rse:0.7709736227989197\n",
      "Original data scale mse:40591140.0, rmse:6371.11767578125, mae:4053.178955078125, rse:0.3174396753311157\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.5528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5078  0.7126  0.4996  0.5640\n",
       "              2         24        0.4878  0.6985  0.4790  0.5528\n",
       "              1         96        0.8278  0.9098  0.6768  0.7216\n",
       "              2         96        0.8712  0.9334  0.6843  0.7403\n",
       "              1         168       0.9250  0.9618  0.7023  0.7619\n",
       "              2         168       0.8726  0.9341  0.6942  0.7400\n",
       "RMSE          1         24        0.5071  0.7121  0.4983  0.5636\n",
       "              2         24        0.4826  0.6947  0.4776  0.5498\n",
       "              1         96        0.8019  0.8955  0.6663  0.7102\n",
       "              2         96        0.8538  0.9240  0.6723  0.7329\n",
       "              1         168       0.8935  0.9452  0.6883  0.7488\n",
       "              2         168       0.9231  0.9608  0.6903  0.7611\n",
       "MAE           1         24        0.4949  0.7035  0.4628  0.5568\n",
       "              2         24        0.4903  0.7002  0.4557  0.5542\n",
       "              1         96        0.9520  0.9757  0.6667  0.7739\n",
       "              2         96        0.8675  0.9314  0.6356  0.7387\n",
       "              1         168       0.9182  0.9582  0.6792  0.7591\n",
       "              2         168       0.9472  0.9732  0.6660  0.7710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20262616.0</td>\n",
       "      <td>4501.4014</td>\n",
       "      <td>3016.6672</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19436216.0</td>\n",
       "      <td>4408.6523</td>\n",
       "      <td>2875.5586</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20156686.0</td>\n",
       "      <td>4489.6196</td>\n",
       "      <td>2999.1426</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19259186.0</td>\n",
       "      <td>4388.5288</td>\n",
       "      <td>2873.7637</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>34543984.0</td>\n",
       "      <td>5877.4131</td>\n",
       "      <td>4100.0752</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36986492.0</td>\n",
       "      <td>6081.6519</td>\n",
       "      <td>4114.8584</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38815100.0</td>\n",
       "      <td>6230.1768</td>\n",
       "      <td>4220.9731</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40210260.0</td>\n",
       "      <td>6341.1562</td>\n",
       "      <td>4216.4253</td>\n",
       "      <td>0.3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19648216.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2762.4336</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19207616.0</td>\n",
       "      <td>4382.6494</td>\n",
       "      <td>2741.9597</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20262616.0  4501.4014  3016.6672  0.2238\n",
       "              2         24        19436216.0  4408.6523  2875.5586  0.2192\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "RMSE          1         24        20156686.0  4489.6196  2999.1426  0.2232\n",
       "              2         24        19259186.0  4388.5288  2873.7637  0.2182\n",
       "              1         96        34543984.0  5877.4131  4100.0752  0.2927\n",
       "              2         96        36986492.0  6081.6519  4114.8584  0.3029\n",
       "              1         168       38815100.0  6230.1768  4220.9731  0.3104\n",
       "              2         168       40210260.0  6341.1562  4216.4253  0.3159\n",
       "MAE           1         24        19648216.0  4432.6309  2762.4336  0.2204\n",
       "              2         24        19207616.0  4382.6494  2741.9597  0.2179\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.7309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4926  0.7018  0.4592  0.5555\n",
       "         MSE            0.4978  0.7055  0.4893  0.5584\n",
       "         RMSE           0.4949  0.7034  0.4879  0.5567\n",
       "96       MAE            0.9098  0.9536  0.6512  0.7563\n",
       "         MSE            0.8495  0.9216  0.6805  0.7309\n",
       "         RMSE           0.8278  0.9097  0.6693  0.7215\n",
       "168      MAE            0.9327  0.9657  0.6726  0.7650\n",
       "         MSE            0.8988  0.9479  0.6982  0.7509\n",
       "         RMSE           0.9083  0.9530  0.6893  0.7550"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19427916.0</td>\n",
       "      <td>4407.6401</td>\n",
       "      <td>2752.1967</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19849416.0</td>\n",
       "      <td>4455.0269</td>\n",
       "      <td>2946.1129</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19707936.0</td>\n",
       "      <td>4439.0742</td>\n",
       "      <td>2936.4531</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35765238.0</td>\n",
       "      <td>5979.5325</td>\n",
       "      <td>4107.4668</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39512680.0</td>\n",
       "      <td>6285.6665</td>\n",
       "      <td>4218.6992</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19427916.0  4407.6401  2752.1967  0.2192\n",
       "         MSE            19849416.0  4455.0269  2946.1129  0.2215\n",
       "         RMSE           19707936.0  4439.0742  2936.4531  0.2207\n",
       "96       MAE            39457330.0  6279.8901  3962.9127  0.3127\n",
       "         MSE            36879912.0  6072.1143  4183.2212  0.3024\n",
       "         RMSE           35765238.0  5979.5325  4107.4668  0.2978\n",
       "168      MAE            40141812.0  6335.6575  4107.5206  0.3157\n",
       "         MSE            39366112.0  6272.8247  4301.4302  0.3125\n",
       "         RMSE           39512680.0  6285.6665  4218.6992  0.3132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4062752\n",
      "\tspeed: 0.0679s/iter; left time: 599.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490731\n",
      "\tspeed: 0.0423s/iter; left time: 369.6214s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447189\n",
      "\tspeed: 0.0423s/iter; left time: 364.8243s\n",
      "\titers: 400, epoch: 1 | loss: 0.4202814\n",
      "\tspeed: 0.0423s/iter; left time: 360.7949s\n",
      "\titers: 500, epoch: 1 | loss: 0.3825126\n",
      "\tspeed: 0.0423s/iter; left time: 356.3038s\n",
      "\titers: 600, epoch: 1 | loss: 0.4463949\n",
      "\tspeed: 0.0423s/iter; left time: 352.4487s\n",
      "\titers: 700, epoch: 1 | loss: 0.3554860\n",
      "\tspeed: 0.0424s/iter; left time: 348.7190s\n",
      "\titers: 800, epoch: 1 | loss: 0.3329375\n",
      "\tspeed: 0.0423s/iter; left time: 344.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.3779395 Vali Loss: 0.4368218 Test Loss: 0.4749455\n",
      "Validation loss decreased (inf --> 0.436822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4321591\n",
      "\tspeed: 0.1555s/iter; left time: 1234.0575s\n",
      "\titers: 200, epoch: 2 | loss: 0.3975809\n",
      "\tspeed: 0.0425s/iter; left time: 333.0563s\n",
      "\titers: 300, epoch: 2 | loss: 0.2834045\n",
      "\tspeed: 0.0423s/iter; left time: 327.4289s\n",
      "\titers: 400, epoch: 2 | loss: 0.2936918\n",
      "\tspeed: 0.0423s/iter; left time: 323.1378s\n",
      "\titers: 500, epoch: 2 | loss: 0.2714845\n",
      "\tspeed: 0.0424s/iter; left time: 319.3444s\n",
      "\titers: 600, epoch: 2 | loss: 0.2872095\n",
      "\tspeed: 0.0424s/iter; left time: 315.6703s\n",
      "\titers: 700, epoch: 2 | loss: 0.3408362\n",
      "\tspeed: 0.0424s/iter; left time: 311.3674s\n",
      "\titers: 800, epoch: 2 | loss: 0.2582404\n",
      "\tspeed: 0.0424s/iter; left time: 306.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3092715 Vali Loss: 0.4199357 Test Loss: 0.4742230\n",
      "Validation loss decreased (0.436822 --> 0.419936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2012810\n",
      "\tspeed: 0.1529s/iter; left time: 1076.8527s\n",
      "\titers: 200, epoch: 3 | loss: 0.2745693\n",
      "\tspeed: 0.0423s/iter; left time: 293.8910s\n",
      "\titers: 300, epoch: 3 | loss: 0.2421604\n",
      "\tspeed: 0.0423s/iter; left time: 289.8235s\n",
      "\titers: 400, epoch: 3 | loss: 0.2551808\n",
      "\tspeed: 0.0423s/iter; left time: 285.4184s\n",
      "\titers: 500, epoch: 3 | loss: 0.2312551\n",
      "\tspeed: 0.0423s/iter; left time: 281.0323s\n",
      "\titers: 600, epoch: 3 | loss: 0.2817569\n",
      "\tspeed: 0.0424s/iter; left time: 277.5837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1640334\n",
      "\tspeed: 0.0424s/iter; left time: 273.0298s\n",
      "\titers: 800, epoch: 3 | loss: 0.3372894\n",
      "\tspeed: 0.0424s/iter; left time: 268.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2761120 Vali Loss: 0.4101853 Test Loss: 0.4503999\n",
      "Validation loss decreased (0.419936 --> 0.410185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537383\n",
      "\tspeed: 0.1525s/iter; left time: 938.3432s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325063\n",
      "\tspeed: 0.0424s/iter; left time: 256.4355s\n",
      "\titers: 300, epoch: 4 | loss: 0.2676595\n",
      "\tspeed: 0.0424s/iter; left time: 252.0785s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086366\n",
      "\tspeed: 0.0424s/iter; left time: 248.0409s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853133\n",
      "\tspeed: 0.0424s/iter; left time: 243.6700s\n",
      "\titers: 600, epoch: 4 | loss: 0.2249607\n",
      "\tspeed: 0.0422s/iter; left time: 238.5343s\n",
      "\titers: 700, epoch: 4 | loss: 0.2668764\n",
      "\tspeed: 0.0423s/iter; left time: 234.8522s\n",
      "\titers: 800, epoch: 4 | loss: 0.2927850\n",
      "\tspeed: 0.0424s/iter; left time: 231.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2687885 Vali Loss: 0.4336080 Test Loss: 0.4734263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2390144\n",
      "\tspeed: 0.1502s/iter; left time: 790.1390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1977134\n",
      "\tspeed: 0.0423s/iter; left time: 218.3652s\n",
      "\titers: 300, epoch: 5 | loss: 0.2724915\n",
      "\tspeed: 0.0423s/iter; left time: 214.0501s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195267\n",
      "\tspeed: 0.0424s/iter; left time: 210.1197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2479026\n",
      "\tspeed: 0.0423s/iter; left time: 205.4403s\n",
      "\titers: 600, epoch: 5 | loss: 0.2113601\n",
      "\tspeed: 0.0424s/iter; left time: 201.8271s\n",
      "\titers: 700, epoch: 5 | loss: 0.2392982\n",
      "\tspeed: 0.0424s/iter; left time: 197.5442s\n",
      "\titers: 800, epoch: 5 | loss: 0.2210716\n",
      "\tspeed: 0.0424s/iter; left time: 193.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2557502 Vali Loss: 0.4083221 Test Loss: 0.4551176\n",
      "Validation loss decreased (0.410185 --> 0.408322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2018318\n",
      "\tspeed: 0.1536s/iter; left time: 670.6467s\n",
      "\titers: 200, epoch: 6 | loss: 0.2799388\n",
      "\tspeed: 0.0424s/iter; left time: 181.0247s\n",
      "\titers: 300, epoch: 6 | loss: 0.1967447\n",
      "\tspeed: 0.0425s/iter; left time: 177.0979s\n",
      "\titers: 400, epoch: 6 | loss: 0.2135415\n",
      "\tspeed: 0.0423s/iter; left time: 172.0800s\n",
      "\titers: 500, epoch: 6 | loss: 0.2062024\n",
      "\tspeed: 0.0423s/iter; left time: 167.8923s\n",
      "\titers: 600, epoch: 6 | loss: 0.2476224\n",
      "\tspeed: 0.0424s/iter; left time: 163.9357s\n",
      "\titers: 700, epoch: 6 | loss: 0.1791212\n",
      "\tspeed: 0.0425s/iter; left time: 160.0147s\n",
      "\titers: 800, epoch: 6 | loss: 0.2224586\n",
      "\tspeed: 0.0424s/iter; left time: 155.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2370440 Vali Loss: 0.4499719 Test Loss: 0.4937295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2283527\n",
      "\tspeed: 0.1506s/iter; left time: 522.9856s\n",
      "\titers: 200, epoch: 7 | loss: 0.2216568\n",
      "\tspeed: 0.0424s/iter; left time: 142.8875s\n",
      "\titers: 300, epoch: 7 | loss: 0.2187734\n",
      "\tspeed: 0.0423s/iter; left time: 138.5007s\n",
      "\titers: 400, epoch: 7 | loss: 0.2077828\n",
      "\tspeed: 0.0423s/iter; left time: 134.1586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1985875\n",
      "\tspeed: 0.0423s/iter; left time: 129.8508s\n",
      "\titers: 600, epoch: 7 | loss: 0.2054232\n",
      "\tspeed: 0.0423s/iter; left time: 125.7131s\n",
      "\titers: 700, epoch: 7 | loss: 0.1703641\n",
      "\tspeed: 0.0423s/iter; left time: 121.5996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1733078\n",
      "\tspeed: 0.0423s/iter; left time: 117.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2119504 Vali Loss: 0.4550525 Test Loss: 0.5188643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2100210\n",
      "\tspeed: 0.1507s/iter; left time: 388.9244s\n",
      "\titers: 200, epoch: 8 | loss: 0.1868386\n",
      "\tspeed: 0.0424s/iter; left time: 105.2177s\n",
      "\titers: 300, epoch: 8 | loss: 0.1724563\n",
      "\tspeed: 0.0423s/iter; left time: 100.7432s\n",
      "\titers: 400, epoch: 8 | loss: 0.2129223\n",
      "\tspeed: 0.0423s/iter; left time: 96.5167s\n",
      "\titers: 500, epoch: 8 | loss: 0.2158544\n",
      "\tspeed: 0.0424s/iter; left time: 92.4012s\n",
      "\titers: 600, epoch: 8 | loss: 0.1620623\n",
      "\tspeed: 0.0425s/iter; left time: 88.3637s\n",
      "\titers: 700, epoch: 8 | loss: 0.1801844\n",
      "\tspeed: 0.0424s/iter; left time: 83.9291s\n",
      "\titers: 800, epoch: 8 | loss: 0.2255919\n",
      "\tspeed: 0.0424s/iter; left time: 79.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.1881337 Vali Loss: 0.4813017 Test Loss: 0.5380040\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45511767268180847, rmse:0.6746240854263306, mae:0.4416392743587494, rse:0.5339223742485046\n",
      "Original data scale mse:17261680.0, rmse:4154.7177734375, mae:2581.17822265625, rse:0.20658095180988312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3967359\n",
      "\tspeed: 0.0443s/iter; left time: 391.4396s\n",
      "\titers: 200, epoch: 1 | loss: 0.4064189\n",
      "\tspeed: 0.0424s/iter; left time: 370.5603s\n",
      "\titers: 300, epoch: 1 | loss: 0.2779341\n",
      "\tspeed: 0.0424s/iter; left time: 366.0447s\n",
      "\titers: 400, epoch: 1 | loss: 0.2643839\n",
      "\tspeed: 0.0424s/iter; left time: 362.0700s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900892\n",
      "\tspeed: 0.0423s/iter; left time: 356.8179s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112502\n",
      "\tspeed: 0.0425s/iter; left time: 353.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.2473065\n",
      "\tspeed: 0.0423s/iter; left time: 347.9740s\n",
      "\titers: 800, epoch: 1 | loss: 0.2575147\n",
      "\tspeed: 0.0423s/iter; left time: 344.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3743255 Vali Loss: 0.4390815 Test Loss: 0.4765824\n",
      "Validation loss decreased (inf --> 0.439081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3144976\n",
      "\tspeed: 0.1532s/iter; left time: 1216.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.2808562\n",
      "\tspeed: 0.0424s/iter; left time: 332.0637s\n",
      "\titers: 300, epoch: 2 | loss: 0.2744709\n",
      "\tspeed: 0.0425s/iter; left time: 328.6438s\n",
      "\titers: 400, epoch: 2 | loss: 0.3588106\n",
      "\tspeed: 0.0424s/iter; left time: 323.6192s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180828\n",
      "\tspeed: 0.0423s/iter; left time: 318.8200s\n",
      "\titers: 600, epoch: 2 | loss: 0.2916528\n",
      "\tspeed: 0.0424s/iter; left time: 315.2543s\n",
      "\titers: 700, epoch: 2 | loss: 0.2639987\n",
      "\tspeed: 0.0425s/iter; left time: 311.7480s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295977\n",
      "\tspeed: 0.0425s/iter; left time: 307.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3134294 Vali Loss: 0.4065219 Test Loss: 0.4498437\n",
      "Validation loss decreased (0.439081 --> 0.406522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2422723\n",
      "\tspeed: 0.1536s/iter; left time: 1082.1756s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763481\n",
      "\tspeed: 0.0423s/iter; left time: 293.5784s\n",
      "\titers: 300, epoch: 3 | loss: 0.2693237\n",
      "\tspeed: 0.0423s/iter; left time: 289.8415s\n",
      "\titers: 400, epoch: 3 | loss: 0.3108239\n",
      "\tspeed: 0.0424s/iter; left time: 286.2577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1933685\n",
      "\tspeed: 0.0425s/iter; left time: 282.6698s\n",
      "\titers: 600, epoch: 3 | loss: 0.2856435\n",
      "\tspeed: 0.0425s/iter; left time: 278.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.2616338\n",
      "\tspeed: 0.0425s/iter; left time: 273.5982s\n",
      "\titers: 800, epoch: 3 | loss: 0.2869773\n",
      "\tspeed: 0.0424s/iter; left time: 268.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2774806 Vali Loss: 0.4149170 Test Loss: 0.4646415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248570\n",
      "\tspeed: 0.1508s/iter; left time: 928.0265s\n",
      "\titers: 200, epoch: 4 | loss: 0.2699777\n",
      "\tspeed: 0.0423s/iter; left time: 255.9761s\n",
      "\titers: 300, epoch: 4 | loss: 0.2988690\n",
      "\tspeed: 0.0424s/iter; left time: 252.1062s\n",
      "\titers: 400, epoch: 4 | loss: 0.2862901\n",
      "\tspeed: 0.0424s/iter; left time: 248.3990s\n",
      "\titers: 500, epoch: 4 | loss: 0.2651158\n",
      "\tspeed: 0.0423s/iter; left time: 243.5503s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613765\n",
      "\tspeed: 0.0423s/iter; left time: 239.0812s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783110\n",
      "\tspeed: 0.0424s/iter; left time: 235.2375s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053535\n",
      "\tspeed: 0.0423s/iter; left time: 230.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2820289 Vali Loss: 0.4095885 Test Loss: 0.4661101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2652097\n",
      "\tspeed: 0.1515s/iter; left time: 796.8502s\n",
      "\titers: 200, epoch: 5 | loss: 0.2383111\n",
      "\tspeed: 0.0423s/iter; left time: 218.2376s\n",
      "\titers: 300, epoch: 5 | loss: 0.2541043\n",
      "\tspeed: 0.0423s/iter; left time: 214.1389s\n",
      "\titers: 400, epoch: 5 | loss: 0.2939530\n",
      "\tspeed: 0.0423s/iter; left time: 209.8434s\n",
      "\titers: 500, epoch: 5 | loss: 0.3624977\n",
      "\tspeed: 0.0423s/iter; left time: 205.5906s\n",
      "\titers: 600, epoch: 5 | loss: 0.2916973\n",
      "\tspeed: 0.0424s/iter; left time: 201.8669s\n",
      "\titers: 700, epoch: 5 | loss: 0.2681513\n",
      "\tspeed: 0.0423s/iter; left time: 197.2126s\n",
      "\titers: 800, epoch: 5 | loss: 0.2681236\n",
      "\tspeed: 0.0424s/iter; left time: 193.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.2520440 Vali Loss: 0.4063278 Test Loss: 0.4664033\n",
      "Validation loss decreased (0.406522 --> 0.406328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3188669\n",
      "\tspeed: 0.1528s/iter; left time: 667.0724s\n",
      "\titers: 200, epoch: 6 | loss: 0.2008031\n",
      "\tspeed: 0.0423s/iter; left time: 180.4956s\n",
      "\titers: 300, epoch: 6 | loss: 0.2052909\n",
      "\tspeed: 0.0423s/iter; left time: 176.3804s\n",
      "\titers: 400, epoch: 6 | loss: 0.2591189\n",
      "\tspeed: 0.0423s/iter; left time: 172.0109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1943497\n",
      "\tspeed: 0.0422s/iter; left time: 167.1677s\n",
      "\titers: 600, epoch: 6 | loss: 0.2352947\n",
      "\tspeed: 0.0422s/iter; left time: 163.0949s\n",
      "\titers: 700, epoch: 6 | loss: 0.2489737\n",
      "\tspeed: 0.0420s/iter; left time: 158.3054s\n",
      "\titers: 800, epoch: 6 | loss: 0.2547600\n",
      "\tspeed: 0.0420s/iter; left time: 153.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.2338442 Vali Loss: 0.4190404 Test Loss: 0.4860373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2307729\n",
      "\tspeed: 0.1512s/iter; left time: 525.1738s\n",
      "\titers: 200, epoch: 7 | loss: 0.3084017\n",
      "\tspeed: 0.0423s/iter; left time: 142.6637s\n",
      "\titers: 300, epoch: 7 | loss: 0.2080216\n",
      "\tspeed: 0.0423s/iter; left time: 138.4167s\n",
      "\titers: 400, epoch: 7 | loss: 0.2292389\n",
      "\tspeed: 0.0423s/iter; left time: 134.1549s\n",
      "\titers: 500, epoch: 7 | loss: 0.1513019\n",
      "\tspeed: 0.0423s/iter; left time: 130.1379s\n",
      "\titers: 600, epoch: 7 | loss: 0.1729813\n",
      "\tspeed: 0.0423s/iter; left time: 125.8568s\n",
      "\titers: 700, epoch: 7 | loss: 0.1880350\n",
      "\tspeed: 0.0424s/iter; left time: 121.7990s\n",
      "\titers: 800, epoch: 7 | loss: 0.1786184\n",
      "\tspeed: 0.0423s/iter; left time: 117.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2103385 Vali Loss: 0.4527536 Test Loss: 0.5490917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1798774\n",
      "\tspeed: 0.1514s/iter; left time: 390.7379s\n",
      "\titers: 200, epoch: 8 | loss: 0.1682350\n",
      "\tspeed: 0.0423s/iter; left time: 105.0200s\n",
      "\titers: 300, epoch: 8 | loss: 0.1307397\n",
      "\tspeed: 0.0425s/iter; left time: 101.0480s\n",
      "\titers: 400, epoch: 8 | loss: 0.2033289\n",
      "\tspeed: 0.0423s/iter; left time: 96.4256s\n",
      "\titers: 500, epoch: 8 | loss: 0.1776353\n",
      "\tspeed: 0.0423s/iter; left time: 92.1877s\n",
      "\titers: 600, epoch: 8 | loss: 0.1967961\n",
      "\tspeed: 0.0423s/iter; left time: 88.0449s\n",
      "\titers: 700, epoch: 8 | loss: 0.1893690\n",
      "\tspeed: 0.0423s/iter; left time: 83.8084s\n",
      "\titers: 800, epoch: 8 | loss: 0.1618215\n",
      "\tspeed: 0.0423s/iter; left time: 79.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1851797 Vali Loss: 0.4516812 Test Loss: 0.5370039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4664033055305481, rmse:0.6829372644424438, mae:0.4505856931209564, rse:0.5405017137527466\n",
      "Original data scale mse:17762658.0, rmse:4214.57666015625, mae:2639.203857421875, rse:0.20955726504325867\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7372616\n",
      "\tspeed: 0.0670s/iter; left time: 590.5372s\n",
      "\titers: 200, epoch: 1 | loss: 0.5333896\n",
      "\tspeed: 0.0427s/iter; left time: 371.7987s\n",
      "\titers: 300, epoch: 1 | loss: 0.5598907\n",
      "\tspeed: 0.0429s/iter; left time: 369.0281s\n",
      "\titers: 400, epoch: 1 | loss: 0.4729436\n",
      "\tspeed: 0.0427s/iter; left time: 363.5738s\n",
      "\titers: 500, epoch: 1 | loss: 0.5560483\n",
      "\tspeed: 0.0428s/iter; left time: 359.5714s\n",
      "\titers: 600, epoch: 1 | loss: 0.4819749\n",
      "\tspeed: 0.0427s/iter; left time: 355.0414s\n",
      "\titers: 700, epoch: 1 | loss: 0.5415132\n",
      "\tspeed: 0.0427s/iter; left time: 350.7844s\n",
      "\titers: 800, epoch: 1 | loss: 0.6243510\n",
      "\tspeed: 0.0428s/iter; left time: 347.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.5668236 Vali Loss: 0.6507477 Test Loss: 0.7603212\n",
      "Validation loss decreased (inf --> 0.650748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5540779\n",
      "\tspeed: 0.1520s/iter; left time: 1203.6075s\n",
      "\titers: 200, epoch: 2 | loss: 0.4847487\n",
      "\tspeed: 0.0428s/iter; left time: 334.7597s\n",
      "\titers: 300, epoch: 2 | loss: 0.4586814\n",
      "\tspeed: 0.0428s/iter; left time: 330.5472s\n",
      "\titers: 400, epoch: 2 | loss: 0.5438913\n",
      "\tspeed: 0.0427s/iter; left time: 325.4002s\n",
      "\titers: 500, epoch: 2 | loss: 0.4111202\n",
      "\tspeed: 0.0428s/iter; left time: 321.4945s\n",
      "\titers: 600, epoch: 2 | loss: 0.3895184\n",
      "\tspeed: 0.0427s/iter; left time: 316.8562s\n",
      "\titers: 700, epoch: 2 | loss: 0.3883051\n",
      "\tspeed: 0.0427s/iter; left time: 312.7519s\n",
      "\titers: 800, epoch: 2 | loss: 0.5433491\n",
      "\tspeed: 0.0427s/iter; left time: 308.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.5033157 Vali Loss: 0.6297555 Test Loss: 0.7439358\n",
      "Validation loss decreased (0.650748 --> 0.629755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4145484\n",
      "\tspeed: 0.1531s/iter; left time: 1076.0209s\n",
      "\titers: 200, epoch: 3 | loss: 0.4595998\n",
      "\tspeed: 0.0428s/iter; left time: 296.6672s\n",
      "\titers: 300, epoch: 3 | loss: 0.4619078\n",
      "\tspeed: 0.0427s/iter; left time: 291.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526187\n",
      "\tspeed: 0.0427s/iter; left time: 287.4733s\n",
      "\titers: 500, epoch: 3 | loss: 0.4454547\n",
      "\tspeed: 0.0428s/iter; left time: 283.4371s\n",
      "\titers: 600, epoch: 3 | loss: 0.3692695\n",
      "\tspeed: 0.0426s/iter; left time: 278.4322s\n",
      "\titers: 700, epoch: 3 | loss: 0.4703220\n",
      "\tspeed: 0.0427s/iter; left time: 274.5120s\n",
      "\titers: 800, epoch: 3 | loss: 0.3812272\n",
      "\tspeed: 0.0428s/iter; left time: 270.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.4455938 Vali Loss: 0.6881084 Test Loss: 0.8548705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4174319\n",
      "\tspeed: 0.1502s/iter; left time: 921.8349s\n",
      "\titers: 200, epoch: 4 | loss: 0.4014978\n",
      "\tspeed: 0.0426s/iter; left time: 257.2844s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054119\n",
      "\tspeed: 0.0427s/iter; left time: 253.3398s\n",
      "\titers: 400, epoch: 4 | loss: 0.3589748\n",
      "\tspeed: 0.0427s/iter; left time: 249.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3653719\n",
      "\tspeed: 0.0427s/iter; left time: 245.0993s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618014\n",
      "\tspeed: 0.0427s/iter; left time: 240.9776s\n",
      "\titers: 700, epoch: 4 | loss: 0.3188422\n",
      "\tspeed: 0.0427s/iter; left time: 236.5605s\n",
      "\titers: 800, epoch: 4 | loss: 0.2926117\n",
      "\tspeed: 0.0427s/iter; left time: 232.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 891 | Train Loss: 0.3568448 Vali Loss: 0.7477230 Test Loss: 0.9618957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811221\n",
      "\tspeed: 0.1508s/iter; left time: 791.3091s\n",
      "\titers: 200, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0427s/iter; left time: 219.8007s\n",
      "\titers: 300, epoch: 5 | loss: 0.3285968\n",
      "\tspeed: 0.0427s/iter; left time: 215.6158s\n",
      "\titers: 400, epoch: 5 | loss: 0.2673545\n",
      "\tspeed: 0.0427s/iter; left time: 211.2512s\n",
      "\titers: 500, epoch: 5 | loss: 0.2493921\n",
      "\tspeed: 0.0427s/iter; left time: 207.0348s\n",
      "\titers: 600, epoch: 5 | loss: 0.2386115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6892s\n",
      "\titers: 700, epoch: 5 | loss: 0.2263911\n",
      "\tspeed: 0.0427s/iter; left time: 198.4134s\n",
      "\titers: 800, epoch: 5 | loss: 0.1957354\n",
      "\tspeed: 0.0427s/iter; left time: 194.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.2605241 Vali Loss: 0.8050478 Test Loss: 0.9919707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7439358234405518, rmse:0.8625171184539795, mae:0.6113150119781494, rse:0.6840823292732239\n",
      "Original data scale mse:30875704.0, rmse:5556.5908203125, mae:3633.89697265625, rse:0.27672022581100464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5473459\n",
      "\tspeed: 0.0440s/iter; left time: 387.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.4877608\n",
      "\tspeed: 0.0428s/iter; left time: 372.4392s\n",
      "\titers: 300, epoch: 1 | loss: 0.6598209\n",
      "\tspeed: 0.0428s/iter; left time: 368.2271s\n",
      "\titers: 400, epoch: 1 | loss: 0.6614044\n",
      "\tspeed: 0.0429s/iter; left time: 364.7257s\n",
      "\titers: 500, epoch: 1 | loss: 0.4741346\n",
      "\tspeed: 0.0427s/iter; left time: 359.2832s\n",
      "\titers: 600, epoch: 1 | loss: 0.6109210\n",
      "\tspeed: 0.0428s/iter; left time: 355.6680s\n",
      "\titers: 700, epoch: 1 | loss: 0.5352585\n",
      "\tspeed: 0.0427s/iter; left time: 350.3490s\n",
      "\titers: 800, epoch: 1 | loss: 0.5013155\n",
      "\tspeed: 0.0427s/iter; left time: 346.3452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.5658269 Vali Loss: 0.6509469 Test Loss: 0.7612176\n",
      "Validation loss decreased (inf --> 0.650947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5183153\n",
      "\tspeed: 0.1529s/iter; left time: 1211.1457s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526019\n",
      "\tspeed: 0.0427s/iter; left time: 333.8961s\n",
      "\titers: 300, epoch: 2 | loss: 0.5071620\n",
      "\tspeed: 0.0427s/iter; left time: 329.6108s\n",
      "\titers: 400, epoch: 2 | loss: 0.4839136\n",
      "\tspeed: 0.0426s/iter; left time: 324.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.3920006\n",
      "\tspeed: 0.0427s/iter; left time: 321.1203s\n",
      "\titers: 600, epoch: 2 | loss: 0.4868114\n",
      "\tspeed: 0.0428s/iter; left time: 317.5724s\n",
      "\titers: 700, epoch: 2 | loss: 0.5634870\n",
      "\tspeed: 0.0427s/iter; left time: 312.2350s\n",
      "\titers: 800, epoch: 2 | loss: 0.4724952\n",
      "\tspeed: 0.0427s/iter; left time: 308.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.5043234 Vali Loss: 0.6191998 Test Loss: 0.7726130\n",
      "Validation loss decreased (0.650947 --> 0.619200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5086631\n",
      "\tspeed: 0.1538s/iter; left time: 1081.2978s\n",
      "\titers: 200, epoch: 3 | loss: 0.4055051\n",
      "\tspeed: 0.0427s/iter; left time: 295.7305s\n",
      "\titers: 300, epoch: 3 | loss: 0.3720219\n",
      "\tspeed: 0.0427s/iter; left time: 291.4443s\n",
      "\titers: 400, epoch: 3 | loss: 0.4331014\n",
      "\tspeed: 0.0427s/iter; left time: 287.2703s\n",
      "\titers: 500, epoch: 3 | loss: 0.3976127\n",
      "\tspeed: 0.0426s/iter; left time: 282.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.4022872\n",
      "\tspeed: 0.0427s/iter; left time: 278.8334s\n",
      "\titers: 700, epoch: 3 | loss: 0.4675071\n",
      "\tspeed: 0.0427s/iter; left time: 274.2666s\n",
      "\titers: 800, epoch: 3 | loss: 0.3814891\n",
      "\tspeed: 0.0427s/iter; left time: 269.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4320488 Vali Loss: 0.6841762 Test Loss: 0.8737969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3273250\n",
      "\tspeed: 0.1505s/iter; left time: 923.9212s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400194\n",
      "\tspeed: 0.0427s/iter; left time: 257.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161496\n",
      "\tspeed: 0.0426s/iter; left time: 253.1537s\n",
      "\titers: 400, epoch: 4 | loss: 0.3390466\n",
      "\tspeed: 0.0427s/iter; left time: 249.2543s\n",
      "\titers: 500, epoch: 4 | loss: 0.2879927\n",
      "\tspeed: 0.0427s/iter; left time: 244.7857s\n",
      "\titers: 600, epoch: 4 | loss: 0.3149875\n",
      "\tspeed: 0.0430s/iter; left time: 242.4409s\n",
      "\titers: 700, epoch: 4 | loss: 0.3463651\n",
      "\tspeed: 0.0427s/iter; left time: 236.6177s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761787\n",
      "\tspeed: 0.0427s/iter; left time: 232.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.3297124 Vali Loss: 0.7400400 Test Loss: 0.9315168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2692976\n",
      "\tspeed: 0.1504s/iter; left time: 789.1331s\n",
      "\titers: 200, epoch: 5 | loss: 0.2221422\n",
      "\tspeed: 0.0427s/iter; left time: 220.0111s\n",
      "\titers: 300, epoch: 5 | loss: 0.2397722\n",
      "\tspeed: 0.0427s/iter; left time: 215.6517s\n",
      "\titers: 400, epoch: 5 | loss: 0.2549823\n",
      "\tspeed: 0.0427s/iter; left time: 211.1870s\n",
      "\titers: 500, epoch: 5 | loss: 0.2158701\n",
      "\tspeed: 0.0427s/iter; left time: 206.9031s\n",
      "\titers: 600, epoch: 5 | loss: 0.2114049\n",
      "\tspeed: 0.0427s/iter; left time: 202.8592s\n",
      "\titers: 700, epoch: 5 | loss: 0.2200302\n",
      "\tspeed: 0.0428s/iter; left time: 198.8283s\n",
      "\titers: 800, epoch: 5 | loss: 0.2109580\n",
      "\tspeed: 0.0426s/iter; left time: 193.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.2433385 Vali Loss: 0.7909078 Test Loss: 1.0188278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7726126909255981, rmse:0.8789839148521423, mae:0.6244558691978455, rse:0.6971425414085388\n",
      "Original data scale mse:32792920.0, rmse:5726.51025390625, mae:3746.37841796875, rse:0.28518226742744446\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7546027\n",
      "\tspeed: 0.0685s/iter; left time: 601.9188s\n",
      "\titers: 200, epoch: 1 | loss: 0.6000124\n",
      "\tspeed: 0.0434s/iter; left time: 377.0916s\n",
      "\titers: 300, epoch: 1 | loss: 0.6143029\n",
      "\tspeed: 0.0434s/iter; left time: 373.0299s\n",
      "\titers: 400, epoch: 1 | loss: 0.7047151\n",
      "\tspeed: 0.0432s/iter; left time: 367.0263s\n",
      "\titers: 500, epoch: 1 | loss: 0.6804361\n",
      "\tspeed: 0.0433s/iter; left time: 363.1118s\n",
      "\titers: 600, epoch: 1 | loss: 0.5855610\n",
      "\tspeed: 0.0432s/iter; left time: 358.4246s\n",
      "\titers: 700, epoch: 1 | loss: 0.5702372\n",
      "\tspeed: 0.0433s/iter; left time: 354.2754s\n",
      "\titers: 800, epoch: 1 | loss: 0.5958639\n",
      "\tspeed: 0.0433s/iter; left time: 350.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.6097435 Vali Loss: 0.6800801 Test Loss: 0.8067515\n",
      "Validation loss decreased (inf --> 0.680080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6113356\n",
      "\tspeed: 0.1570s/iter; left time: 1240.7043s\n",
      "\titers: 200, epoch: 2 | loss: 0.4996085\n",
      "\tspeed: 0.0434s/iter; left time: 338.6026s\n",
      "\titers: 300, epoch: 2 | loss: 0.6496976\n",
      "\tspeed: 0.0434s/iter; left time: 334.2431s\n",
      "\titers: 400, epoch: 2 | loss: 0.5307702\n",
      "\tspeed: 0.0434s/iter; left time: 329.8440s\n",
      "\titers: 500, epoch: 2 | loss: 0.5256283\n",
      "\tspeed: 0.0433s/iter; left time: 324.4753s\n",
      "\titers: 600, epoch: 2 | loss: 0.5327381\n",
      "\tspeed: 0.0432s/iter; left time: 319.7562s\n",
      "\titers: 700, epoch: 2 | loss: 0.4570733\n",
      "\tspeed: 0.0432s/iter; left time: 315.7967s\n",
      "\titers: 800, epoch: 2 | loss: 0.5451870\n",
      "\tspeed: 0.0433s/iter; left time: 311.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5431589 Vali Loss: 0.6531566 Test Loss: 0.8226323\n",
      "Validation loss decreased (0.680080 --> 0.653157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4712646\n",
      "\tspeed: 0.1560s/iter; left time: 1094.2592s\n",
      "\titers: 200, epoch: 3 | loss: 0.4011992\n",
      "\tspeed: 0.0432s/iter; left time: 298.3359s\n",
      "\titers: 300, epoch: 3 | loss: 0.4421045\n",
      "\tspeed: 0.0432s/iter; left time: 294.0255s\n",
      "\titers: 400, epoch: 3 | loss: 0.4903741\n",
      "\tspeed: 0.0431s/iter; left time: 289.5582s\n",
      "\titers: 500, epoch: 3 | loss: 0.4915803\n",
      "\tspeed: 0.0431s/iter; left time: 285.1769s\n",
      "\titers: 600, epoch: 3 | loss: 0.4369896\n",
      "\tspeed: 0.0431s/iter; left time: 280.9883s\n",
      "\titers: 700, epoch: 3 | loss: 0.4332677\n",
      "\tspeed: 0.0432s/iter; left time: 276.8598s\n",
      "\titers: 800, epoch: 3 | loss: 0.3947041\n",
      "\tspeed: 0.0432s/iter; left time: 272.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.4362630 Vali Loss: 0.7709182 Test Loss: 1.0190653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3152215\n",
      "\tspeed: 0.1524s/iter; left time: 933.1655s\n",
      "\titers: 200, epoch: 4 | loss: 0.3043053\n",
      "\tspeed: 0.0432s/iter; left time: 260.4047s\n",
      "\titers: 300, epoch: 4 | loss: 0.3607482\n",
      "\tspeed: 0.0431s/iter; left time: 255.6109s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158475\n",
      "\tspeed: 0.0432s/iter; left time: 251.3440s\n",
      "\titers: 500, epoch: 4 | loss: 0.3114798\n",
      "\tspeed: 0.0432s/iter; left time: 247.1892s\n",
      "\titers: 600, epoch: 4 | loss: 0.2569940\n",
      "\tspeed: 0.0432s/iter; left time: 243.1016s\n",
      "\titers: 700, epoch: 4 | loss: 0.2990108\n",
      "\tspeed: 0.0433s/iter; left time: 239.1715s\n",
      "\titers: 800, epoch: 4 | loss: 0.2757485\n",
      "\tspeed: 0.0432s/iter; left time: 234.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.3139915 Vali Loss: 0.8249027 Test Loss: 1.1139140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653311\n",
      "\tspeed: 0.1534s/iter; left time: 803.1848s\n",
      "\titers: 200, epoch: 5 | loss: 0.2252893\n",
      "\tspeed: 0.0432s/iter; left time: 221.7956s\n",
      "\titers: 300, epoch: 5 | loss: 0.2340532\n",
      "\tspeed: 0.0432s/iter; left time: 217.7169s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358732\n",
      "\tspeed: 0.0432s/iter; left time: 213.0039s\n",
      "\titers: 500, epoch: 5 | loss: 0.2421527\n",
      "\tspeed: 0.0431s/iter; left time: 208.5055s\n",
      "\titers: 600, epoch: 5 | loss: 0.2229267\n",
      "\tspeed: 0.0431s/iter; left time: 204.2013s\n",
      "\titers: 700, epoch: 5 | loss: 0.2323525\n",
      "\tspeed: 0.0432s/iter; left time: 200.3228s\n",
      "\titers: 800, epoch: 5 | loss: 0.1996585\n",
      "\tspeed: 0.0432s/iter; left time: 195.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.2229739 Vali Loss: 0.8824634 Test Loss: 1.1303844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8226325511932373, rmse:0.9069909453392029, mae:0.6497392058372498, rse:0.7184973955154419\n",
      "Original data scale mse:35247892.0, rmse:5936.99365234375, mae:3905.610107421875, rse:0.2958095371723175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7979063\n",
      "\tspeed: 0.0451s/iter; left time: 396.8241s\n",
      "\titers: 200, epoch: 1 | loss: 0.6841452\n",
      "\tspeed: 0.0432s/iter; left time: 375.3620s\n",
      "\titers: 300, epoch: 1 | loss: 0.7397766\n",
      "\tspeed: 0.0432s/iter; left time: 370.8872s\n",
      "\titers: 400, epoch: 1 | loss: 0.6866934\n",
      "\tspeed: 0.0431s/iter; left time: 366.3169s\n",
      "\titers: 500, epoch: 1 | loss: 0.6043772\n",
      "\tspeed: 0.0433s/iter; left time: 363.0868s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847449\n",
      "\tspeed: 0.0434s/iter; left time: 359.8004s\n",
      "\titers: 700, epoch: 1 | loss: 0.5677136\n",
      "\tspeed: 0.0432s/iter; left time: 354.1416s\n",
      "\titers: 800, epoch: 1 | loss: 0.5065239\n",
      "\tspeed: 0.0434s/iter; left time: 351.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.6112015 Vali Loss: 0.6771722 Test Loss: 0.8046841\n",
      "Validation loss decreased (inf --> 0.677172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6040920\n",
      "\tspeed: 0.1561s/iter; left time: 1233.4365s\n",
      "\titers: 200, epoch: 2 | loss: 0.5640650\n",
      "\tspeed: 0.0432s/iter; left time: 336.7035s\n",
      "\titers: 300, epoch: 2 | loss: 0.5824279\n",
      "\tspeed: 0.0433s/iter; left time: 333.2817s\n",
      "\titers: 400, epoch: 2 | loss: 0.5516443\n",
      "\tspeed: 0.0432s/iter; left time: 328.2858s\n",
      "\titers: 500, epoch: 2 | loss: 0.5464745\n",
      "\tspeed: 0.0432s/iter; left time: 324.1682s\n",
      "\titers: 600, epoch: 2 | loss: 0.5696195\n",
      "\tspeed: 0.0432s/iter; left time: 319.6071s\n",
      "\titers: 700, epoch: 2 | loss: 0.4997825\n",
      "\tspeed: 0.0432s/iter; left time: 315.3826s\n",
      "\titers: 800, epoch: 2 | loss: 0.4807952\n",
      "\tspeed: 0.0432s/iter; left time: 310.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.5430961 Vali Loss: 0.6961910 Test Loss: 0.8720690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4384274\n",
      "\tspeed: 0.1543s/iter; left time: 1081.8186s\n",
      "\titers: 200, epoch: 3 | loss: 0.4003488\n",
      "\tspeed: 0.0434s/iter; left time: 299.8521s\n",
      "\titers: 300, epoch: 3 | loss: 0.5147206\n",
      "\tspeed: 0.0432s/iter; left time: 294.4050s\n",
      "\titers: 400, epoch: 3 | loss: 0.5407557\n",
      "\tspeed: 0.0432s/iter; left time: 290.0289s\n",
      "\titers: 500, epoch: 3 | loss: 0.4383535\n",
      "\tspeed: 0.0432s/iter; left time: 285.9180s\n",
      "\titers: 600, epoch: 3 | loss: 0.4661134\n",
      "\tspeed: 0.0433s/iter; left time: 282.1961s\n",
      "\titers: 700, epoch: 3 | loss: 0.4150949\n",
      "\tspeed: 0.0433s/iter; left time: 277.7682s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085022\n",
      "\tspeed: 0.0432s/iter; left time: 272.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4439213 Vali Loss: 0.7267453 Test Loss: 0.9541050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3798918\n",
      "\tspeed: 0.1547s/iter; left time: 947.2197s\n",
      "\titers: 200, epoch: 4 | loss: 0.3046944\n",
      "\tspeed: 0.0432s/iter; left time: 260.1293s\n",
      "\titers: 300, epoch: 4 | loss: 0.3279685\n",
      "\tspeed: 0.0432s/iter; left time: 255.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.3203649\n",
      "\tspeed: 0.0432s/iter; left time: 251.5670s\n",
      "\titers: 500, epoch: 4 | loss: 0.3229451\n",
      "\tspeed: 0.0430s/iter; left time: 246.2402s\n",
      "\titers: 600, epoch: 4 | loss: 0.2853895\n",
      "\tspeed: 0.0430s/iter; left time: 241.6585s\n",
      "\titers: 700, epoch: 4 | loss: 0.3258071\n",
      "\tspeed: 0.0430s/iter; left time: 237.3710s\n",
      "\titers: 800, epoch: 4 | loss: 0.3050725\n",
      "\tspeed: 0.0430s/iter; left time: 233.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.3247702 Vali Loss: 0.8104095 Test Loss: 1.0395817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8046845197677612, rmse:0.8970420956611633, mae:0.64595627784729, rse:0.7106161713600159\n",
      "Original data scale mse:34226872.0, rmse:5850.37353515625, mae:3899.109619140625, rse:0.2914937138557434\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6304526\n",
      "\tspeed: 0.0683s/iter; left time: 602.9611s\n",
      "\titers: 200, epoch: 1 | loss: 0.6647899\n",
      "\tspeed: 0.0426s/iter; left time: 371.7983s\n",
      "\titers: 300, epoch: 1 | loss: 0.5844824\n",
      "\tspeed: 0.0424s/iter; left time: 365.9783s\n",
      "\titers: 400, epoch: 1 | loss: 0.6426585\n",
      "\tspeed: 0.0424s/iter; left time: 361.7525s\n",
      "\titers: 500, epoch: 1 | loss: 0.6155174\n",
      "\tspeed: 0.0425s/iter; left time: 358.2786s\n",
      "\titers: 600, epoch: 1 | loss: 0.6662328\n",
      "\tspeed: 0.0425s/iter; left time: 353.9473s\n",
      "\titers: 700, epoch: 1 | loss: 0.5895321\n",
      "\tspeed: 0.0424s/iter; left time: 349.1764s\n",
      "\titers: 800, epoch: 1 | loss: 0.5740807\n",
      "\tspeed: 0.0424s/iter; left time: 344.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.6036704 Vali Loss: 0.4339436 Test Loss: 0.4720358\n",
      "Validation loss decreased (inf --> 0.433944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6498488\n",
      "\tspeed: 0.1531s/iter; left time: 1215.5868s\n",
      "\titers: 200, epoch: 2 | loss: 0.6380902\n",
      "\tspeed: 0.0425s/iter; left time: 332.7322s\n",
      "\titers: 300, epoch: 2 | loss: 0.5367553\n",
      "\tspeed: 0.0424s/iter; left time: 328.2144s\n",
      "\titers: 400, epoch: 2 | loss: 0.5489156\n",
      "\tspeed: 0.0424s/iter; left time: 323.6393s\n",
      "\titers: 500, epoch: 2 | loss: 0.5260842\n",
      "\tspeed: 0.0425s/iter; left time: 320.3660s\n",
      "\titers: 600, epoch: 2 | loss: 0.5337558\n",
      "\tspeed: 0.0423s/iter; left time: 314.5709s\n",
      "\titers: 700, epoch: 2 | loss: 0.5897491\n",
      "\tspeed: 0.0424s/iter; left time: 311.4112s\n",
      "\titers: 800, epoch: 2 | loss: 0.5088241\n",
      "\tspeed: 0.0425s/iter; left time: 307.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5554133 Vali Loss: 0.4260295 Test Loss: 0.4780068\n",
      "Validation loss decreased (0.433944 --> 0.426029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309910\n",
      "\tspeed: 0.1533s/iter; left time: 1079.7285s\n",
      "\titers: 200, epoch: 3 | loss: 0.5291359\n",
      "\tspeed: 0.0423s/iter; left time: 293.7864s\n",
      "\titers: 300, epoch: 3 | loss: 0.4883050\n",
      "\tspeed: 0.0423s/iter; left time: 289.7883s\n",
      "\titers: 400, epoch: 3 | loss: 0.4879614\n",
      "\tspeed: 0.0424s/iter; left time: 286.2550s\n",
      "\titers: 500, epoch: 3 | loss: 0.4847891\n",
      "\tspeed: 0.0424s/iter; left time: 282.0516s\n",
      "\titers: 600, epoch: 3 | loss: 0.5293490\n",
      "\tspeed: 0.0424s/iter; left time: 277.6713s\n",
      "\titers: 700, epoch: 3 | loss: 0.4065211\n",
      "\tspeed: 0.0424s/iter; left time: 273.1066s\n",
      "\titers: 800, epoch: 3 | loss: 0.5855716\n",
      "\tspeed: 0.0424s/iter; left time: 269.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.5231845 Vali Loss: 0.4079853 Test Loss: 0.4513101\n",
      "Validation loss decreased (0.426029 --> 0.407985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5018351\n",
      "\tspeed: 0.1527s/iter; left time: 939.2845s\n",
      "\titers: 200, epoch: 4 | loss: 0.4895697\n",
      "\tspeed: 0.0424s/iter; left time: 256.6275s\n",
      "\titers: 300, epoch: 4 | loss: 0.5145022\n",
      "\tspeed: 0.0424s/iter; left time: 252.0868s\n",
      "\titers: 400, epoch: 4 | loss: 0.4483052\n",
      "\tspeed: 0.0424s/iter; left time: 248.3293s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109250\n",
      "\tspeed: 0.0424s/iter; left time: 243.7719s\n",
      "\titers: 600, epoch: 4 | loss: 0.4802767\n",
      "\tspeed: 0.0424s/iter; left time: 239.4784s\n",
      "\titers: 700, epoch: 4 | loss: 0.5246813\n",
      "\tspeed: 0.0424s/iter; left time: 235.4710s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321484\n",
      "\tspeed: 0.0423s/iter; left time: 230.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5150838 Vali Loss: 0.4270419 Test Loss: 0.4700336\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4871208\n",
      "\tspeed: 0.1525s/iter; left time: 801.8416s\n",
      "\titers: 200, epoch: 5 | loss: 0.4352125\n",
      "\tspeed: 0.0425s/iter; left time: 219.2843s\n",
      "\titers: 300, epoch: 5 | loss: 0.5049165\n",
      "\tspeed: 0.0424s/iter; left time: 214.2495s\n",
      "\titers: 400, epoch: 5 | loss: 0.4666814\n",
      "\tspeed: 0.0424s/iter; left time: 210.3353s\n",
      "\titers: 500, epoch: 5 | loss: 0.5018875\n",
      "\tspeed: 0.0426s/iter; left time: 206.7576s\n",
      "\titers: 600, epoch: 5 | loss: 0.4701836\n",
      "\tspeed: 0.0425s/iter; left time: 202.3015s\n",
      "\titers: 700, epoch: 5 | loss: 0.5009473\n",
      "\tspeed: 0.0424s/iter; left time: 197.7662s\n",
      "\titers: 800, epoch: 5 | loss: 0.4748931\n",
      "\tspeed: 0.0424s/iter; left time: 193.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.5074182 Vali Loss: 0.4152391 Test Loss: 0.4634299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4203286\n",
      "\tspeed: 0.1519s/iter; left time: 663.1395s\n",
      "\titers: 200, epoch: 6 | loss: 0.5329765\n",
      "\tspeed: 0.0424s/iter; left time: 180.8140s\n",
      "\titers: 300, epoch: 6 | loss: 0.4321128\n",
      "\tspeed: 0.0422s/iter; left time: 175.9150s\n",
      "\titers: 400, epoch: 6 | loss: 0.4385991\n",
      "\tspeed: 0.0424s/iter; left time: 172.3634s\n",
      "\titers: 500, epoch: 6 | loss: 0.4512403\n",
      "\tspeed: 0.0424s/iter; left time: 168.1754s\n",
      "\titers: 600, epoch: 6 | loss: 0.4838388\n",
      "\tspeed: 0.0425s/iter; left time: 164.1365s\n",
      "\titers: 700, epoch: 6 | loss: 0.4213574\n",
      "\tspeed: 0.0424s/iter; left time: 159.6564s\n",
      "\titers: 800, epoch: 6 | loss: 0.4768175\n",
      "\tspeed: 0.0425s/iter; left time: 155.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.4807680 Vali Loss: 0.4451250 Test Loss: 0.4856848\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45131009817123413, rmse:0.6717962026596069, mae:0.44347333908081055, rse:0.5316842198371887\n",
      "Original data scale mse:17305828.0, rmse:4160.02734375, mae:2609.172119140625, rse:0.20684495568275452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7208875\n",
      "\tspeed: 0.0446s/iter; left time: 394.2604s\n",
      "\titers: 200, epoch: 1 | loss: 0.5653324\n",
      "\tspeed: 0.0424s/iter; left time: 370.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.5747016\n",
      "\tspeed: 0.0424s/iter; left time: 366.2074s\n",
      "\titers: 400, epoch: 1 | loss: 0.5493563\n",
      "\tspeed: 0.0424s/iter; left time: 362.0482s\n",
      "\titers: 500, epoch: 1 | loss: 0.5951235\n",
      "\tspeed: 0.0424s/iter; left time: 357.8883s\n",
      "\titers: 600, epoch: 1 | loss: 0.5839962\n",
      "\tspeed: 0.0424s/iter; left time: 353.3596s\n",
      "\titers: 700, epoch: 1 | loss: 0.5883811\n",
      "\tspeed: 0.0426s/iter; left time: 350.4200s\n",
      "\titers: 800, epoch: 1 | loss: 0.6175978\n",
      "\tspeed: 0.0425s/iter; left time: 345.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.6029870 Vali Loss: 0.4296014 Test Loss: 0.4724245\n",
      "Validation loss decreased (inf --> 0.429601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5956693\n",
      "\tspeed: 0.1548s/iter; left time: 1228.5427s\n",
      "\titers: 200, epoch: 2 | loss: 0.6147557\n",
      "\tspeed: 0.0424s/iter; left time: 332.5428s\n",
      "\titers: 300, epoch: 2 | loss: 0.5424049\n",
      "\tspeed: 0.0425s/iter; left time: 328.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.5658551\n",
      "\tspeed: 0.0424s/iter; left time: 323.7582s\n",
      "\titers: 500, epoch: 2 | loss: 0.5137780\n",
      "\tspeed: 0.0424s/iter; left time: 319.8523s\n",
      "\titers: 600, epoch: 2 | loss: 0.5194274\n",
      "\tspeed: 0.0426s/iter; left time: 316.5765s\n",
      "\titers: 700, epoch: 2 | loss: 0.4312453\n",
      "\tspeed: 0.0424s/iter; left time: 311.0337s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377391\n",
      "\tspeed: 0.0425s/iter; left time: 307.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.5573271 Vali Loss: 0.4067231 Test Loss: 0.4517895\n",
      "Validation loss decreased (0.429601 --> 0.406723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4817174\n",
      "\tspeed: 0.1552s/iter; left time: 1093.4068s\n",
      "\titers: 200, epoch: 3 | loss: 0.5098557\n",
      "\tspeed: 0.0424s/iter; left time: 294.5240s\n",
      "\titers: 300, epoch: 3 | loss: 0.4692909\n",
      "\tspeed: 0.0425s/iter; left time: 290.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.4773871\n",
      "\tspeed: 0.0425s/iter; left time: 286.4687s\n",
      "\titers: 500, epoch: 3 | loss: 0.5546513\n",
      "\tspeed: 0.0426s/iter; left time: 282.9506s\n",
      "\titers: 600, epoch: 3 | loss: 0.5032052\n",
      "\tspeed: 0.0422s/iter; left time: 276.2888s\n",
      "\titers: 700, epoch: 3 | loss: 0.4395917\n",
      "\tspeed: 0.0428s/iter; left time: 275.6103s\n",
      "\titers: 800, epoch: 3 | loss: 0.5026121\n",
      "\tspeed: 0.0424s/iter; left time: 269.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.5239807 Vali Loss: 0.4195922 Test Loss: 0.4513127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5083061\n",
      "\tspeed: 0.1526s/iter; left time: 938.8968s\n",
      "\titers: 200, epoch: 4 | loss: 0.4650363\n",
      "\tspeed: 0.0425s/iter; left time: 256.9514s\n",
      "\titers: 300, epoch: 4 | loss: 0.4765425\n",
      "\tspeed: 0.0424s/iter; left time: 252.5899s\n",
      "\titers: 400, epoch: 4 | loss: 0.5530409\n",
      "\tspeed: 0.0426s/iter; left time: 249.0418s\n",
      "\titers: 500, epoch: 4 | loss: 0.5370450\n",
      "\tspeed: 0.0425s/iter; left time: 244.3009s\n",
      "\titers: 600, epoch: 4 | loss: 0.6664306\n",
      "\tspeed: 0.0425s/iter; left time: 240.1234s\n",
      "\titers: 700, epoch: 4 | loss: 0.4789167\n",
      "\tspeed: 0.0425s/iter; left time: 235.7937s\n",
      "\titers: 800, epoch: 4 | loss: 0.5579545\n",
      "\tspeed: 0.0425s/iter; left time: 231.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.5211855 Vali Loss: 0.4197213 Test Loss: 0.4598895\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4809563\n",
      "\tspeed: 0.1527s/iter; left time: 802.9587s\n",
      "\titers: 200, epoch: 5 | loss: 0.4911440\n",
      "\tspeed: 0.0425s/iter; left time: 219.3020s\n",
      "\titers: 300, epoch: 5 | loss: 0.4891045\n",
      "\tspeed: 0.0425s/iter; left time: 214.8820s\n",
      "\titers: 400, epoch: 5 | loss: 0.5189811\n",
      "\tspeed: 0.0425s/iter; left time: 210.5983s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235159\n",
      "\tspeed: 0.0424s/iter; left time: 206.1090s\n",
      "\titers: 600, epoch: 5 | loss: 0.5044044\n",
      "\tspeed: 0.0424s/iter; left time: 201.8627s\n",
      "\titers: 700, epoch: 5 | loss: 0.4964522\n",
      "\tspeed: 0.0425s/iter; left time: 198.0154s\n",
      "\titers: 800, epoch: 5 | loss: 0.5055836\n",
      "\tspeed: 0.0427s/iter; left time: 194.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.4999788 Vali Loss: 0.4229821 Test Loss: 0.4707361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517894387245178, rmse:0.6721528172492981, mae:0.44926226139068604, rse:0.531966507434845\n",
      "Original data scale mse:17345650.0, rmse:4164.81103515625, mae:2657.558349609375, rse:0.20708277821540833\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8564085\n",
      "\tspeed: 0.0680s/iter; left time: 598.7694s\n",
      "\titers: 200, epoch: 1 | loss: 0.7276816\n",
      "\tspeed: 0.0427s/iter; left time: 372.1279s\n",
      "\titers: 300, epoch: 1 | loss: 0.7469753\n",
      "\tspeed: 0.0428s/iter; left time: 368.4669s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862437\n",
      "\tspeed: 0.0428s/iter; left time: 363.9586s\n",
      "\titers: 500, epoch: 1 | loss: 0.7447299\n",
      "\tspeed: 0.0428s/iter; left time: 359.6042s\n",
      "\titers: 600, epoch: 1 | loss: 0.6932904\n",
      "\tspeed: 0.0428s/iter; left time: 355.4343s\n",
      "\titers: 700, epoch: 1 | loss: 0.7336010\n",
      "\tspeed: 0.0428s/iter; left time: 351.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.7876992\n",
      "\tspeed: 0.0427s/iter; left time: 346.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.7489301 Vali Loss: 0.6496119 Test Loss: 0.7595298\n",
      "Validation loss decreased (inf --> 0.649612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7455665\n",
      "\tspeed: 0.1529s/iter; left time: 1211.0281s\n",
      "\titers: 200, epoch: 2 | loss: 0.6923752\n",
      "\tspeed: 0.0428s/iter; left time: 334.4074s\n",
      "\titers: 300, epoch: 2 | loss: 0.6735732\n",
      "\tspeed: 0.0428s/iter; left time: 330.3872s\n",
      "\titers: 400, epoch: 2 | loss: 0.7412770\n",
      "\tspeed: 0.0428s/iter; left time: 326.0852s\n",
      "\titers: 500, epoch: 2 | loss: 0.6404418\n",
      "\tspeed: 0.0428s/iter; left time: 321.7587s\n",
      "\titers: 600, epoch: 2 | loss: 0.6246042\n",
      "\tspeed: 0.0428s/iter; left time: 317.6922s\n",
      "\titers: 700, epoch: 2 | loss: 0.6204208\n",
      "\tspeed: 0.0428s/iter; left time: 313.1966s\n",
      "\titers: 800, epoch: 2 | loss: 0.7364731\n",
      "\tspeed: 0.0428s/iter; left time: 309.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.7072706 Vali Loss: 0.6384751 Test Loss: 0.7534525\n",
      "Validation loss decreased (0.649612 --> 0.638475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6394007\n",
      "\tspeed: 0.1540s/iter; left time: 1082.3165s\n",
      "\titers: 200, epoch: 3 | loss: 0.6838906\n",
      "\tspeed: 0.0427s/iter; left time: 296.1545s\n",
      "\titers: 300, epoch: 3 | loss: 0.6923274\n",
      "\tspeed: 0.0427s/iter; left time: 291.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.6940130\n",
      "\tspeed: 0.0427s/iter; left time: 287.3802s\n",
      "\titers: 500, epoch: 3 | loss: 0.6825750\n",
      "\tspeed: 0.0428s/iter; left time: 283.4176s\n",
      "\titers: 600, epoch: 3 | loss: 0.6074114\n",
      "\tspeed: 0.0428s/iter; left time: 279.4834s\n",
      "\titers: 700, epoch: 3 | loss: 0.6975672\n",
      "\tspeed: 0.0427s/iter; left time: 274.6385s\n",
      "\titers: 800, epoch: 3 | loss: 0.5953272\n",
      "\tspeed: 0.0429s/iter; left time: 271.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.6643052 Vali Loss: 0.6965610 Test Loss: 0.8775428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6318092\n",
      "\tspeed: 0.1515s/iter; left time: 929.6129s\n",
      "\titers: 200, epoch: 4 | loss: 0.6489524\n",
      "\tspeed: 0.0428s/iter; left time: 258.2389s\n",
      "\titers: 300, epoch: 4 | loss: 0.6114253\n",
      "\tspeed: 0.0428s/iter; left time: 254.2544s\n",
      "\titers: 400, epoch: 4 | loss: 0.6083454\n",
      "\tspeed: 0.0428s/iter; left time: 250.0377s\n",
      "\titers: 500, epoch: 4 | loss: 0.5923827\n",
      "\tspeed: 0.0428s/iter; left time: 245.5615s\n",
      "\titers: 600, epoch: 4 | loss: 0.6142623\n",
      "\tspeed: 0.0428s/iter; left time: 241.5447s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633094\n",
      "\tspeed: 0.0428s/iter; left time: 237.1731s\n",
      "\titers: 800, epoch: 4 | loss: 0.5035748\n",
      "\tspeed: 0.0427s/iter; left time: 232.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.5925956 Vali Loss: 0.7727130 Test Loss: 0.9328302\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5578295\n",
      "\tspeed: 0.1509s/iter; left time: 792.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.5414807\n",
      "\tspeed: 0.0427s/iter; left time: 219.8039s\n",
      "\titers: 300, epoch: 5 | loss: 0.5636502\n",
      "\tspeed: 0.0427s/iter; left time: 215.6220s\n",
      "\titers: 400, epoch: 5 | loss: 0.5362424\n",
      "\tspeed: 0.0427s/iter; left time: 211.3051s\n",
      "\titers: 500, epoch: 5 | loss: 0.4829004\n",
      "\tspeed: 0.0427s/iter; left time: 207.0390s\n",
      "\titers: 600, epoch: 5 | loss: 0.4771944\n",
      "\tspeed: 0.0428s/iter; left time: 203.1562s\n",
      "\titers: 700, epoch: 5 | loss: 0.4571800\n",
      "\tspeed: 0.0428s/iter; left time: 199.0780s\n",
      "\titers: 800, epoch: 5 | loss: 0.4408690\n",
      "\tspeed: 0.0428s/iter; left time: 194.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5061452 Vali Loss: 0.8498826 Test Loss: 0.9658751\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7534525394439697, rmse:0.8680164217948914, mae:0.6171937584877014, rse:0.6884440183639526\n",
      "Original data scale mse:31262294.0, rmse:5591.26953125, mae:3673.384033203125, rse:0.2784472107887268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7373669\n",
      "\tspeed: 0.0446s/iter; left time: 392.8948s\n",
      "\titers: 200, epoch: 1 | loss: 0.6961303\n",
      "\tspeed: 0.0427s/iter; left time: 372.2155s\n",
      "\titers: 300, epoch: 1 | loss: 0.8107926\n",
      "\tspeed: 0.0427s/iter; left time: 367.3601s\n",
      "\titers: 400, epoch: 1 | loss: 0.8115740\n",
      "\tspeed: 0.0425s/iter; left time: 361.4023s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878027\n",
      "\tspeed: 0.0426s/iter; left time: 358.4285s\n",
      "\titers: 600, epoch: 1 | loss: 0.7807432\n",
      "\tspeed: 0.0428s/iter; left time: 355.4065s\n",
      "\titers: 700, epoch: 1 | loss: 0.7302145\n",
      "\tspeed: 0.0427s/iter; left time: 350.7357s\n",
      "\titers: 800, epoch: 1 | loss: 0.7058792\n",
      "\tspeed: 0.0428s/iter; left time: 347.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7482038 Vali Loss: 0.6501760 Test Loss: 0.7607240\n",
      "Validation loss decreased (inf --> 0.650176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7201242\n",
      "\tspeed: 0.1530s/iter; left time: 1211.3649s\n",
      "\titers: 200, epoch: 2 | loss: 0.6755181\n",
      "\tspeed: 0.0427s/iter; left time: 334.0633s\n",
      "\titers: 300, epoch: 2 | loss: 0.7100089\n",
      "\tspeed: 0.0428s/iter; left time: 330.0868s\n",
      "\titers: 400, epoch: 2 | loss: 0.6997021\n",
      "\tspeed: 0.0428s/iter; left time: 325.8922s\n",
      "\titers: 500, epoch: 2 | loss: 0.6204954\n",
      "\tspeed: 0.0428s/iter; left time: 321.5709s\n",
      "\titers: 600, epoch: 2 | loss: 0.6984884\n",
      "\tspeed: 0.0427s/iter; left time: 316.7871s\n",
      "\titers: 700, epoch: 2 | loss: 0.7466449\n",
      "\tspeed: 0.0427s/iter; left time: 312.8736s\n",
      "\titers: 800, epoch: 2 | loss: 0.6878006\n",
      "\tspeed: 0.0428s/iter; left time: 308.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7087464 Vali Loss: 0.6216077 Test Loss: 0.7755335\n",
      "Validation loss decreased (0.650176 --> 0.621608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7080504\n",
      "\tspeed: 0.1542s/iter; left time: 1083.7248s\n",
      "\titers: 200, epoch: 3 | loss: 0.6345065\n",
      "\tspeed: 0.0427s/iter; left time: 296.0350s\n",
      "\titers: 300, epoch: 3 | loss: 0.6015949\n",
      "\tspeed: 0.0427s/iter; left time: 291.8595s\n",
      "\titers: 400, epoch: 3 | loss: 0.6569807\n",
      "\tspeed: 0.0428s/iter; left time: 287.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.6287000\n",
      "\tspeed: 0.0429s/iter; left time: 284.1811s\n",
      "\titers: 600, epoch: 3 | loss: 0.6277207\n",
      "\tspeed: 0.0428s/iter; left time: 279.3057s\n",
      "\titers: 700, epoch: 3 | loss: 0.6814144\n",
      "\tspeed: 0.0428s/iter; left time: 275.0404s\n",
      "\titers: 800, epoch: 3 | loss: 0.6294596\n",
      "\tspeed: 0.0428s/iter; left time: 270.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.6558177 Vali Loss: 0.6887955 Test Loss: 0.8492430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6006249\n",
      "\tspeed: 0.1517s/iter; left time: 931.1551s\n",
      "\titers: 200, epoch: 4 | loss: 0.5826002\n",
      "\tspeed: 0.0428s/iter; left time: 258.2005s\n",
      "\titers: 300, epoch: 4 | loss: 0.5727263\n",
      "\tspeed: 0.0428s/iter; left time: 254.3509s\n",
      "\titers: 400, epoch: 4 | loss: 0.5923206\n",
      "\tspeed: 0.0428s/iter; left time: 249.8124s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391967\n",
      "\tspeed: 0.0427s/iter; left time: 245.1838s\n",
      "\titers: 600, epoch: 4 | loss: 0.5598037\n",
      "\tspeed: 0.0427s/iter; left time: 240.8971s\n",
      "\titers: 700, epoch: 4 | loss: 0.5872183\n",
      "\tspeed: 0.0427s/iter; left time: 236.5888s\n",
      "\titers: 800, epoch: 4 | loss: 0.5201843\n",
      "\tspeed: 0.0428s/iter; left time: 232.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5749528 Vali Loss: 0.7418606 Test Loss: 0.9283234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5154231\n",
      "\tspeed: 0.1517s/iter; left time: 795.9826s\n",
      "\titers: 200, epoch: 5 | loss: 0.4713488\n",
      "\tspeed: 0.0427s/iter; left time: 219.9947s\n",
      "\titers: 300, epoch: 5 | loss: 0.4894331\n",
      "\tspeed: 0.0428s/iter; left time: 215.8808s\n",
      "\titers: 400, epoch: 5 | loss: 0.4998905\n",
      "\tspeed: 0.0427s/iter; left time: 211.4325s\n",
      "\titers: 500, epoch: 5 | loss: 0.4573486\n",
      "\tspeed: 0.0428s/iter; left time: 207.3145s\n",
      "\titers: 600, epoch: 5 | loss: 0.4486329\n",
      "\tspeed: 0.0428s/iter; left time: 202.9889s\n",
      "\titers: 700, epoch: 5 | loss: 0.4750489\n",
      "\tspeed: 0.0428s/iter; left time: 198.6629s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578401\n",
      "\tspeed: 0.0427s/iter; left time: 194.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4898551 Vali Loss: 0.7914582 Test Loss: 0.9788902\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7755337357521057, rmse:0.880643904209137, mae:0.6255269646644592, rse:0.6984591484069824\n",
      "Original data scale mse:33044252.0, rmse:5748.4130859375, mae:3757.29541015625, rse:0.2862730324268341\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8679006\n",
      "\tspeed: 0.0679s/iter; left time: 597.0260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7743645\n",
      "\tspeed: 0.0433s/iter; left time: 376.1120s\n",
      "\titers: 300, epoch: 1 | loss: 0.7822117\n",
      "\tspeed: 0.0432s/iter; left time: 371.4445s\n",
      "\titers: 400, epoch: 1 | loss: 0.8378281\n",
      "\tspeed: 0.0435s/iter; left time: 369.2035s\n",
      "\titers: 500, epoch: 1 | loss: 0.8232630\n",
      "\tspeed: 0.0433s/iter; left time: 363.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.7636237\n",
      "\tspeed: 0.0433s/iter; left time: 358.8792s\n",
      "\titers: 700, epoch: 1 | loss: 0.7548945\n",
      "\tspeed: 0.0433s/iter; left time: 354.7984s\n",
      "\titers: 800, epoch: 1 | loss: 0.7713766\n",
      "\tspeed: 0.0433s/iter; left time: 350.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.7772274 Vali Loss: 0.6790550 Test Loss: 0.8057779\n",
      "Validation loss decreased (inf --> 0.679055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7821077\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7803s\n",
      "\titers: 200, epoch: 2 | loss: 0.7020079\n",
      "\tspeed: 0.0434s/iter; left time: 338.3973s\n",
      "\titers: 300, epoch: 2 | loss: 0.8012208\n",
      "\tspeed: 0.0435s/iter; left time: 334.7136s\n",
      "\titers: 400, epoch: 2 | loss: 0.7271333\n",
      "\tspeed: 0.0433s/iter; left time: 329.0446s\n",
      "\titers: 500, epoch: 2 | loss: 0.7285502\n",
      "\tspeed: 0.0433s/iter; left time: 325.2045s\n",
      "\titers: 600, epoch: 2 | loss: 0.7326428\n",
      "\tspeed: 0.0433s/iter; left time: 320.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.6793472\n",
      "\tspeed: 0.0433s/iter; left time: 316.2541s\n",
      "\titers: 800, epoch: 2 | loss: 0.7332686\n",
      "\tspeed: 0.0433s/iter; left time: 311.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.7356485 Vali Loss: 0.6576813 Test Loss: 0.8276157\n",
      "Validation loss decreased (0.679055 --> 0.657681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6861941\n",
      "\tspeed: 0.1559s/iter; left time: 1093.2852s\n",
      "\titers: 200, epoch: 3 | loss: 0.6369764\n",
      "\tspeed: 0.0434s/iter; left time: 300.2822s\n",
      "\titers: 300, epoch: 3 | loss: 0.6813426\n",
      "\tspeed: 0.0433s/iter; left time: 295.1944s\n",
      "\titers: 400, epoch: 3 | loss: 0.6887080\n",
      "\tspeed: 0.0434s/iter; left time: 291.2259s\n",
      "\titers: 500, epoch: 3 | loss: 0.7160903\n",
      "\tspeed: 0.0433s/iter; left time: 286.5825s\n",
      "\titers: 600, epoch: 3 | loss: 0.6524235\n",
      "\tspeed: 0.0433s/iter; left time: 282.3045s\n",
      "\titers: 700, epoch: 3 | loss: 0.6551255\n",
      "\tspeed: 0.0433s/iter; left time: 277.3797s\n",
      "\titers: 800, epoch: 3 | loss: 0.6208397\n",
      "\tspeed: 0.0432s/iter; left time: 273.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.6604352 Vali Loss: 0.7732214 Test Loss: 0.9868738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5560720\n",
      "\tspeed: 0.1521s/iter; left time: 931.1967s\n",
      "\titers: 200, epoch: 4 | loss: 0.5402793\n",
      "\tspeed: 0.0433s/iter; left time: 260.7411s\n",
      "\titers: 300, epoch: 4 | loss: 0.6283324\n",
      "\tspeed: 0.0433s/iter; left time: 256.3194s\n",
      "\titers: 400, epoch: 4 | loss: 0.5678048\n",
      "\tspeed: 0.0433s/iter; left time: 252.1106s\n",
      "\titers: 500, epoch: 4 | loss: 0.5673718\n",
      "\tspeed: 0.0433s/iter; left time: 247.9093s\n",
      "\titers: 600, epoch: 4 | loss: 0.5018236\n",
      "\tspeed: 0.0433s/iter; left time: 243.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.5377899\n",
      "\tspeed: 0.0433s/iter; left time: 239.4047s\n",
      "\titers: 800, epoch: 4 | loss: 0.5352262\n",
      "\tspeed: 0.0434s/iter; left time: 235.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5602547 Vali Loss: 0.7991609 Test Loss: 1.1161594\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5087005\n",
      "\tspeed: 0.1530s/iter; left time: 800.7100s\n",
      "\titers: 200, epoch: 5 | loss: 0.4705424\n",
      "\tspeed: 0.0433s/iter; left time: 222.3024s\n",
      "\titers: 300, epoch: 5 | loss: 0.4730842\n",
      "\tspeed: 0.0434s/iter; left time: 218.5353s\n",
      "\titers: 400, epoch: 5 | loss: 0.4877660\n",
      "\tspeed: 0.0433s/iter; left time: 213.8698s\n",
      "\titers: 500, epoch: 5 | loss: 0.4700000\n",
      "\tspeed: 0.0434s/iter; left time: 209.7451s\n",
      "\titers: 600, epoch: 5 | loss: 0.4700326\n",
      "\tspeed: 0.0433s/iter; left time: 204.9263s\n",
      "\titers: 700, epoch: 5 | loss: 0.4628400\n",
      "\tspeed: 0.0434s/iter; left time: 201.0596s\n",
      "\titers: 800, epoch: 5 | loss: 0.4603879\n",
      "\tspeed: 0.0433s/iter; left time: 196.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4696992 Vali Loss: 0.8641824 Test Loss: 1.1385818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8276155591011047, rmse:0.909733772277832, mae:0.6518822908401489, rse:0.7206702828407288\n",
      "Original data scale mse:35287100.0, rmse:5940.29443359375, mae:3912.64697265625, rse:0.2959740161895752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919598\n",
      "\tspeed: 0.0449s/iter; left time: 394.7934s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255026\n",
      "\tspeed: 0.0432s/iter; left time: 375.7960s\n",
      "\titers: 300, epoch: 1 | loss: 0.8588480\n",
      "\tspeed: 0.0432s/iter; left time: 371.0216s\n",
      "\titers: 400, epoch: 1 | loss: 0.8268682\n",
      "\tspeed: 0.0433s/iter; left time: 367.3549s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757027\n",
      "\tspeed: 0.0433s/iter; left time: 362.9946s\n",
      "\titers: 600, epoch: 1 | loss: 0.6946961\n",
      "\tspeed: 0.0433s/iter; left time: 359.0086s\n",
      "\titers: 700, epoch: 1 | loss: 0.7522021\n",
      "\tspeed: 0.0433s/iter; left time: 354.6110s\n",
      "\titers: 800, epoch: 1 | loss: 0.7110764\n",
      "\tspeed: 0.0433s/iter; left time: 350.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.7784579 Vali Loss: 0.6762899 Test Loss: 0.8039310\n",
      "Validation loss decreased (inf --> 0.676290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7776949\n",
      "\tspeed: 0.1558s/iter; left time: 1230.8541s\n",
      "\titers: 200, epoch: 2 | loss: 0.7495913\n",
      "\tspeed: 0.0433s/iter; left time: 338.1045s\n",
      "\titers: 300, epoch: 2 | loss: 0.7632322\n",
      "\tspeed: 0.0432s/iter; left time: 333.0286s\n",
      "\titers: 400, epoch: 2 | loss: 0.7406695\n",
      "\tspeed: 0.0433s/iter; left time: 329.1651s\n",
      "\titers: 500, epoch: 2 | loss: 0.7516730\n",
      "\tspeed: 0.0432s/iter; left time: 324.3799s\n",
      "\titers: 600, epoch: 2 | loss: 0.7519017\n",
      "\tspeed: 0.0433s/iter; left time: 320.4085s\n",
      "\titers: 700, epoch: 2 | loss: 0.7013571\n",
      "\tspeed: 0.0433s/iter; left time: 316.3720s\n",
      "\titers: 800, epoch: 2 | loss: 0.6977748\n",
      "\tspeed: 0.0433s/iter; left time: 311.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.7361888 Vali Loss: 0.6949371 Test Loss: 0.8629977\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6662261\n",
      "\tspeed: 0.1525s/iter; left time: 1069.2643s\n",
      "\titers: 200, epoch: 3 | loss: 0.6339747\n",
      "\tspeed: 0.0433s/iter; left time: 299.5387s\n",
      "\titers: 300, epoch: 3 | loss: 0.7117482\n",
      "\tspeed: 0.0433s/iter; left time: 294.7726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7264873\n",
      "\tspeed: 0.0433s/iter; left time: 290.5272s\n",
      "\titers: 500, epoch: 3 | loss: 0.6518920\n",
      "\tspeed: 0.0434s/iter; left time: 286.7612s\n",
      "\titers: 600, epoch: 3 | loss: 0.6870541\n",
      "\tspeed: 0.0433s/iter; left time: 282.0510s\n",
      "\titers: 700, epoch: 3 | loss: 0.6374604\n",
      "\tspeed: 0.0434s/iter; left time: 278.2254s\n",
      "\titers: 800, epoch: 3 | loss: 0.6561266\n",
      "\tspeed: 0.0434s/iter; left time: 273.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6618887 Vali Loss: 0.7081003 Test Loss: 0.9726987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6204436\n",
      "\tspeed: 0.1539s/iter; left time: 942.5101s\n",
      "\titers: 200, epoch: 4 | loss: 0.5560814\n",
      "\tspeed: 0.0433s/iter; left time: 260.8545s\n",
      "\titers: 300, epoch: 4 | loss: 0.5717813\n",
      "\tspeed: 0.0432s/iter; left time: 256.1611s\n",
      "\titers: 400, epoch: 4 | loss: 0.5512108\n",
      "\tspeed: 0.0433s/iter; left time: 251.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.5558363\n",
      "\tspeed: 0.0435s/iter; left time: 248.7970s\n",
      "\titers: 600, epoch: 4 | loss: 0.5101167\n",
      "\tspeed: 0.0433s/iter; left time: 243.5595s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733330\n",
      "\tspeed: 0.0433s/iter; left time: 239.1401s\n",
      "\titers: 800, epoch: 4 | loss: 0.5397598\n",
      "\tspeed: 0.0433s/iter; left time: 234.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5612400 Vali Loss: 0.7595485 Test Loss: 1.0782422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8039314150810242, rmse:0.8966222405433655, mae:0.6451408863067627, rse:0.7102835774421692\n",
      "Original data scale mse:34170808.0, rmse:5845.580078125, mae:3891.957763671875, rse:0.2912548780441284\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4695036\n",
      "\tspeed: 0.0677s/iter; left time: 597.7402s\n",
      "\titers: 200, epoch: 1 | loss: 0.4849952\n",
      "\tspeed: 0.0426s/iter; left time: 371.9770s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187118\n",
      "\tspeed: 0.0427s/iter; left time: 368.5911s\n",
      "\titers: 400, epoch: 1 | loss: 0.4342759\n",
      "\tspeed: 0.0424s/iter; left time: 362.0456s\n",
      "\titers: 500, epoch: 1 | loss: 0.4137512\n",
      "\tspeed: 0.0424s/iter; left time: 357.4461s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539363\n",
      "\tspeed: 0.0424s/iter; left time: 352.9844s\n",
      "\titers: 700, epoch: 1 | loss: 0.4049172\n",
      "\tspeed: 0.0424s/iter; left time: 349.1495s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974779\n",
      "\tspeed: 0.0426s/iter; left time: 346.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 893 | Train Loss: 0.4296926 Vali Loss: 0.4422245 Test Loss: 0.4514492\n",
      "Validation loss decreased (inf --> 0.442224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4751551\n",
      "\tspeed: 0.1525s/iter; left time: 1210.6738s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530021\n",
      "\tspeed: 0.0424s/iter; left time: 332.3615s\n",
      "\titers: 300, epoch: 2 | loss: 0.3882786\n",
      "\tspeed: 0.0424s/iter; left time: 327.8379s\n",
      "\titers: 400, epoch: 2 | loss: 0.4140501\n",
      "\tspeed: 0.0424s/iter; left time: 323.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.3746513\n",
      "\tspeed: 0.0424s/iter; left time: 319.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3730287\n",
      "\tspeed: 0.0423s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 2 | loss: 0.4009704\n",
      "\tspeed: 0.0424s/iter; left time: 311.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.3358727\n",
      "\tspeed: 0.0424s/iter; left time: 307.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3956892 Vali Loss: 0.4311240 Test Loss: 0.4466510\n",
      "Validation loss decreased (0.442224 --> 0.431124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2904167\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8511s\n",
      "\titers: 200, epoch: 3 | loss: 0.3576709\n",
      "\tspeed: 0.0424s/iter; left time: 294.3742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3403774\n",
      "\tspeed: 0.0423s/iter; left time: 289.4606s\n",
      "\titers: 400, epoch: 3 | loss: 0.3329291\n",
      "\tspeed: 0.0424s/iter; left time: 285.7193s\n",
      "\titers: 500, epoch: 3 | loss: 0.3230645\n",
      "\tspeed: 0.0424s/iter; left time: 281.5820s\n",
      "\titers: 600, epoch: 3 | loss: 0.3635491\n",
      "\tspeed: 0.0424s/iter; left time: 277.2735s\n",
      "\titers: 700, epoch: 3 | loss: 0.2835732\n",
      "\tspeed: 0.0423s/iter; left time: 272.9224s\n",
      "\titers: 800, epoch: 3 | loss: 0.3851331\n",
      "\tspeed: 0.0424s/iter; left time: 269.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3495539 Vali Loss: 0.4219367 Test Loss: 0.4352997\n",
      "Validation loss decreased (0.431124 --> 0.421937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3447823\n",
      "\tspeed: 0.1539s/iter; left time: 946.7996s\n",
      "\titers: 200, epoch: 4 | loss: 0.3190766\n",
      "\tspeed: 0.0424s/iter; left time: 256.7966s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549941\n",
      "\tspeed: 0.0424s/iter; left time: 252.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2950929\n",
      "\tspeed: 0.0423s/iter; left time: 247.8224s\n",
      "\titers: 500, epoch: 4 | loss: 0.4276862\n",
      "\tspeed: 0.0423s/iter; left time: 243.5792s\n",
      "\titers: 600, epoch: 4 | loss: 0.3246305\n",
      "\tspeed: 0.0424s/iter; left time: 239.7012s\n",
      "\titers: 700, epoch: 4 | loss: 0.3205589\n",
      "\tspeed: 0.0424s/iter; left time: 235.2304s\n",
      "\titers: 800, epoch: 4 | loss: 0.3858584\n",
      "\tspeed: 0.0424s/iter; left time: 231.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3416200 Vali Loss: 0.4134573 Test Loss: 0.4247172\n",
      "Validation loss decreased (0.421937 --> 0.413457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3319281\n",
      "\tspeed: 0.1539s/iter; left time: 809.3437s\n",
      "\titers: 200, epoch: 5 | loss: 0.2934890\n",
      "\tspeed: 0.0424s/iter; left time: 218.5093s\n",
      "\titers: 300, epoch: 5 | loss: 0.3355778\n",
      "\tspeed: 0.0423s/iter; left time: 214.0601s\n",
      "\titers: 400, epoch: 5 | loss: 0.3117720\n",
      "\tspeed: 0.0424s/iter; left time: 210.0868s\n",
      "\titers: 500, epoch: 5 | loss: 0.3203244\n",
      "\tspeed: 0.0424s/iter; left time: 205.8614s\n",
      "\titers: 600, epoch: 5 | loss: 0.2914104\n",
      "\tspeed: 0.0424s/iter; left time: 201.7048s\n",
      "\titers: 700, epoch: 5 | loss: 0.3308161\n",
      "\tspeed: 0.0424s/iter; left time: 197.4604s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173711\n",
      "\tspeed: 0.0425s/iter; left time: 193.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3343107 Vali Loss: 0.4109769 Test Loss: 0.4230208\n",
      "Validation loss decreased (0.413457 --> 0.410977).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2896678\n",
      "\tspeed: 0.1526s/iter; left time: 666.3155s\n",
      "\titers: 200, epoch: 6 | loss: 0.3515523\n",
      "\tspeed: 0.0424s/iter; left time: 180.7143s\n",
      "\titers: 300, epoch: 6 | loss: 0.3070067\n",
      "\tspeed: 0.0423s/iter; left time: 176.3146s\n",
      "\titers: 400, epoch: 6 | loss: 0.2854919\n",
      "\tspeed: 0.0424s/iter; left time: 172.3742s\n",
      "\titers: 500, epoch: 6 | loss: 0.3352777\n",
      "\tspeed: 0.0423s/iter; left time: 167.9545s\n",
      "\titers: 600, epoch: 6 | loss: 0.3287666\n",
      "\tspeed: 0.0424s/iter; left time: 163.8867s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857096\n",
      "\tspeed: 0.0424s/iter; left time: 159.7712s\n",
      "\titers: 800, epoch: 6 | loss: 0.3255485\n",
      "\tspeed: 0.0424s/iter; left time: 155.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.3294495 Vali Loss: 0.4255356 Test Loss: 0.4324502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3365586\n",
      "\tspeed: 0.1510s/iter; left time: 524.5512s\n",
      "\titers: 200, epoch: 7 | loss: 0.3124640\n",
      "\tspeed: 0.0425s/iter; left time: 143.2186s\n",
      "\titers: 300, epoch: 7 | loss: 0.3412698\n",
      "\tspeed: 0.0423s/iter; left time: 138.4806s\n",
      "\titers: 400, epoch: 7 | loss: 0.3270743\n",
      "\tspeed: 0.0424s/iter; left time: 134.5114s\n",
      "\titers: 500, epoch: 7 | loss: 0.3453423\n",
      "\tspeed: 0.0421s/iter; left time: 129.4667s\n",
      "\titers: 600, epoch: 7 | loss: 0.3201989\n",
      "\tspeed: 0.0421s/iter; left time: 125.1563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2999701\n",
      "\tspeed: 0.0424s/iter; left time: 121.8284s\n",
      "\titers: 800, epoch: 7 | loss: 0.3040497\n",
      "\tspeed: 0.0425s/iter; left time: 117.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3237632 Vali Loss: 0.4205632 Test Loss: 0.4347714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3042686\n",
      "\tspeed: 0.1510s/iter; left time: 389.6832s\n",
      "\titers: 200, epoch: 8 | loss: 0.3169928\n",
      "\tspeed: 0.0423s/iter; left time: 105.0182s\n",
      "\titers: 300, epoch: 8 | loss: 0.2797357\n",
      "\tspeed: 0.0423s/iter; left time: 100.7148s\n",
      "\titers: 400, epoch: 8 | loss: 0.3393894\n",
      "\tspeed: 0.0423s/iter; left time: 96.5069s\n",
      "\titers: 500, epoch: 8 | loss: 0.3562687\n",
      "\tspeed: 0.0423s/iter; left time: 92.1845s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649100\n",
      "\tspeed: 0.0423s/iter; left time: 88.0785s\n",
      "\titers: 700, epoch: 8 | loss: 0.3125881\n",
      "\tspeed: 0.0424s/iter; left time: 83.9210s\n",
      "\titers: 800, epoch: 8 | loss: 0.3596777\n",
      "\tspeed: 0.0424s/iter; left time: 79.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3133540 Vali Loss: 0.4209787 Test Loss: 0.4364639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4612430930137634, rmse:0.67914879322052, mae:0.42302075028419495, rse:0.5375033617019653\n",
      "Original data scale mse:17183404.0, rmse:4145.287109375, mae:2456.189453125, rse:0.20611201226711273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4739339\n",
      "\tspeed: 0.0440s/iter; left time: 388.8090s\n",
      "\titers: 200, epoch: 1 | loss: 0.4540531\n",
      "\tspeed: 0.0424s/iter; left time: 369.7961s\n",
      "\titers: 300, epoch: 1 | loss: 0.3691141\n",
      "\tspeed: 0.0424s/iter; left time: 365.9028s\n",
      "\titers: 400, epoch: 1 | loss: 0.3733300\n",
      "\tspeed: 0.0423s/iter; left time: 361.0668s\n",
      "\titers: 500, epoch: 1 | loss: 0.3640547\n",
      "\tspeed: 0.0424s/iter; left time: 357.5223s\n",
      "\titers: 600, epoch: 1 | loss: 0.3699769\n",
      "\tspeed: 0.0424s/iter; left time: 353.0969s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467535\n",
      "\tspeed: 0.0424s/iter; left time: 348.8939s\n",
      "\titers: 800, epoch: 1 | loss: 0.3464169\n",
      "\tspeed: 0.0424s/iter; left time: 344.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.4279929 Vali Loss: 0.4427081 Test Loss: 0.4532785\n",
      "Validation loss decreased (inf --> 0.442708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4089020\n",
      "\tspeed: 0.1550s/iter; left time: 1230.0104s\n",
      "\titers: 200, epoch: 2 | loss: 0.3849083\n",
      "\tspeed: 0.0425s/iter; left time: 332.7663s\n",
      "\titers: 300, epoch: 2 | loss: 0.3607240\n",
      "\tspeed: 0.0426s/iter; left time: 329.8853s\n",
      "\titers: 400, epoch: 2 | loss: 0.4332860\n",
      "\tspeed: 0.0426s/iter; left time: 325.0105s\n",
      "\titers: 500, epoch: 2 | loss: 0.3553748\n",
      "\tspeed: 0.0426s/iter; left time: 321.0306s\n",
      "\titers: 600, epoch: 2 | loss: 0.3558212\n",
      "\tspeed: 0.0426s/iter; left time: 316.4920s\n",
      "\titers: 700, epoch: 2 | loss: 0.3483924\n",
      "\tspeed: 0.0425s/iter; left time: 311.8307s\n",
      "\titers: 800, epoch: 2 | loss: 0.3718648\n",
      "\tspeed: 0.0424s/iter; left time: 307.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.3910895 Vali Loss: 0.4320702 Test Loss: 0.4399559\n",
      "Validation loss decreased (0.442708 --> 0.432070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3337142\n",
      "\tspeed: 0.1540s/iter; left time: 1084.9239s\n",
      "\titers: 200, epoch: 3 | loss: 0.3450969\n",
      "\tspeed: 0.0424s/iter; left time: 294.5996s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313186\n",
      "\tspeed: 0.0424s/iter; left time: 290.4464s\n",
      "\titers: 400, epoch: 3 | loss: 0.3627611\n",
      "\tspeed: 0.0426s/iter; left time: 287.5233s\n",
      "\titers: 500, epoch: 3 | loss: 0.3072940\n",
      "\tspeed: 0.0426s/iter; left time: 282.9629s\n",
      "\titers: 600, epoch: 3 | loss: 0.3159499\n",
      "\tspeed: 0.0424s/iter; left time: 277.3633s\n",
      "\titers: 700, epoch: 3 | loss: 0.3433414\n",
      "\tspeed: 0.0425s/iter; left time: 273.7528s\n",
      "\titers: 800, epoch: 3 | loss: 0.3504495\n",
      "\tspeed: 0.0424s/iter; left time: 268.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3478101 Vali Loss: 0.4106736 Test Loss: 0.4247069\n",
      "Validation loss decreased (0.432070 --> 0.410674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664916\n",
      "\tspeed: 0.1534s/iter; left time: 943.9890s\n",
      "\titers: 200, epoch: 4 | loss: 0.3556045\n",
      "\tspeed: 0.0425s/iter; left time: 257.0485s\n",
      "\titers: 300, epoch: 4 | loss: 0.3436058\n",
      "\tspeed: 0.0424s/iter; left time: 252.1175s\n",
      "\titers: 400, epoch: 4 | loss: 0.3065186\n",
      "\tspeed: 0.0424s/iter; left time: 248.2914s\n",
      "\titers: 500, epoch: 4 | loss: 0.3289182\n",
      "\tspeed: 0.0423s/iter; left time: 243.5285s\n",
      "\titers: 600, epoch: 4 | loss: 0.3316960\n",
      "\tspeed: 0.0424s/iter; left time: 239.5950s\n",
      "\titers: 700, epoch: 4 | loss: 0.3341659\n",
      "\tspeed: 0.0425s/iter; left time: 235.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.2980278\n",
      "\tspeed: 0.0425s/iter; left time: 231.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3400171 Vali Loss: 0.4142010 Test Loss: 0.4281743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3242514\n",
      "\tspeed: 0.1518s/iter; left time: 798.4761s\n",
      "\titers: 200, epoch: 5 | loss: 0.3074272\n",
      "\tspeed: 0.0426s/iter; left time: 219.9973s\n",
      "\titers: 300, epoch: 5 | loss: 0.3388836\n",
      "\tspeed: 0.0426s/iter; left time: 215.2733s\n",
      "\titers: 400, epoch: 5 | loss: 0.3729826\n",
      "\tspeed: 0.0425s/iter; left time: 210.7732s\n",
      "\titers: 500, epoch: 5 | loss: 0.4128991\n",
      "\tspeed: 0.0426s/iter; left time: 207.0960s\n",
      "\titers: 600, epoch: 5 | loss: 0.3496001\n",
      "\tspeed: 0.0427s/iter; left time: 203.1897s\n",
      "\titers: 700, epoch: 5 | loss: 0.3578146\n",
      "\tspeed: 0.0426s/iter; left time: 198.5819s\n",
      "\titers: 800, epoch: 5 | loss: 0.3022088\n",
      "\tspeed: 0.0426s/iter; left time: 194.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.3320721 Vali Loss: 0.4036397 Test Loss: 0.4186656\n",
      "Validation loss decreased (0.410674 --> 0.403640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3790839\n",
      "\tspeed: 0.1552s/iter; left time: 677.4648s\n",
      "\titers: 200, epoch: 6 | loss: 0.2824487\n",
      "\tspeed: 0.0424s/iter; left time: 180.9843s\n",
      "\titers: 300, epoch: 6 | loss: 0.3130301\n",
      "\tspeed: 0.0425s/iter; left time: 177.2606s\n",
      "\titers: 400, epoch: 6 | loss: 0.3765152\n",
      "\tspeed: 0.0424s/iter; left time: 172.3570s\n",
      "\titers: 500, epoch: 6 | loss: 0.2899759\n",
      "\tspeed: 0.0425s/iter; left time: 168.5191s\n",
      "\titers: 600, epoch: 6 | loss: 0.3341354\n",
      "\tspeed: 0.0425s/iter; left time: 164.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.3467826\n",
      "\tspeed: 0.0425s/iter; left time: 160.1688s\n",
      "\titers: 800, epoch: 6 | loss: 0.3329554\n",
      "\tspeed: 0.0425s/iter; left time: 155.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 893 | Train Loss: 0.3288571 Vali Loss: 0.4075786 Test Loss: 0.4223005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471135\n",
      "\tspeed: 0.1524s/iter; left time: 529.1976s\n",
      "\titers: 200, epoch: 7 | loss: 0.3624613\n",
      "\tspeed: 0.0425s/iter; left time: 143.2853s\n",
      "\titers: 300, epoch: 7 | loss: 0.3461682\n",
      "\tspeed: 0.0425s/iter; left time: 138.9486s\n",
      "\titers: 400, epoch: 7 | loss: 0.3192582\n",
      "\tspeed: 0.0426s/iter; left time: 135.0798s\n",
      "\titers: 500, epoch: 7 | loss: 0.2862870\n",
      "\tspeed: 0.0427s/iter; left time: 131.3159s\n",
      "\titers: 600, epoch: 7 | loss: 0.3154697\n",
      "\tspeed: 0.0427s/iter; left time: 126.8909s\n",
      "\titers: 700, epoch: 7 | loss: 0.3064333\n",
      "\tspeed: 0.0427s/iter; left time: 122.6409s\n",
      "\titers: 800, epoch: 7 | loss: 0.3354075\n",
      "\tspeed: 0.0425s/iter; left time: 117.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 893 | Train Loss: 0.3221708 Vali Loss: 0.4098179 Test Loss: 0.4235730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2890800\n",
      "\tspeed: 0.1522s/iter; left time: 392.7008s\n",
      "\titers: 200, epoch: 8 | loss: 0.3243214\n",
      "\tspeed: 0.0427s/iter; left time: 106.0005s\n",
      "\titers: 300, epoch: 8 | loss: 0.2589266\n",
      "\tspeed: 0.0425s/iter; left time: 101.1173s\n",
      "\titers: 400, epoch: 8 | loss: 0.3333530\n",
      "\tspeed: 0.0423s/iter; left time: 96.4767s\n",
      "\titers: 500, epoch: 8 | loss: 0.2846834\n",
      "\tspeed: 0.0424s/iter; left time: 92.4178s\n",
      "\titers: 600, epoch: 8 | loss: 0.3179591\n",
      "\tspeed: 0.0424s/iter; left time: 88.2907s\n",
      "\titers: 700, epoch: 8 | loss: 0.3226090\n",
      "\tspeed: 0.0425s/iter; left time: 84.2358s\n",
      "\titers: 800, epoch: 8 | loss: 0.3119867\n",
      "\tspeed: 0.0425s/iter; left time: 79.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3134166 Vali Loss: 0.4092242 Test Loss: 0.4205885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44546520709991455, rmse:0.6674317717552185, mae:0.41866567730903625, rse:0.5282301306724548\n",
      "Original data scale mse:16678795.0, rmse:4083.968017578125, mae:2431.303955078125, rse:0.20306311547756195\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6374813\n",
      "\tspeed: 0.0668s/iter; left time: 588.6268s\n",
      "\titers: 200, epoch: 1 | loss: 0.5262504\n",
      "\tspeed: 0.0429s/iter; left time: 373.6804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5496212\n",
      "\tspeed: 0.0425s/iter; left time: 366.3395s\n",
      "\titers: 400, epoch: 1 | loss: 0.4834964\n",
      "\tspeed: 0.0427s/iter; left time: 363.0046s\n",
      "\titers: 500, epoch: 1 | loss: 0.5325756\n",
      "\tspeed: 0.0426s/iter; left time: 358.4012s\n",
      "\titers: 600, epoch: 1 | loss: 0.4872109\n",
      "\tspeed: 0.0427s/iter; left time: 354.5742s\n",
      "\titers: 700, epoch: 1 | loss: 0.5237520\n",
      "\tspeed: 0.0429s/iter; left time: 352.3595s\n",
      "\titers: 800, epoch: 1 | loss: 0.5554903\n",
      "\tspeed: 0.0428s/iter; left time: 347.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.5397429 Vali Loss: 0.5700328 Test Loss: 0.6036903\n",
      "Validation loss decreased (inf --> 0.570033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5374577\n",
      "\tspeed: 0.1534s/iter; left time: 1214.5876s\n",
      "\titers: 200, epoch: 2 | loss: 0.5270962\n",
      "\tspeed: 0.0428s/iter; left time: 334.9445s\n",
      "\titers: 300, epoch: 2 | loss: 0.4995303\n",
      "\tspeed: 0.0427s/iter; left time: 329.8634s\n",
      "\titers: 400, epoch: 2 | loss: 0.5156381\n",
      "\tspeed: 0.0428s/iter; left time: 325.8718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4754504\n",
      "\tspeed: 0.0428s/iter; left time: 321.6876s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311262\n",
      "\tspeed: 0.0427s/iter; left time: 316.6085s\n",
      "\titers: 700, epoch: 2 | loss: 0.4329669\n",
      "\tspeed: 0.0429s/iter; left time: 314.0876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5162832\n",
      "\tspeed: 0.0427s/iter; left time: 308.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.5097087 Vali Loss: 0.5559564 Test Loss: 0.5963426\n",
      "Validation loss decreased (0.570033 --> 0.555956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4553922\n",
      "\tspeed: 0.1539s/iter; left time: 1081.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.4781276\n",
      "\tspeed: 0.0428s/iter; left time: 296.3413s\n",
      "\titers: 300, epoch: 3 | loss: 0.5148327\n",
      "\tspeed: 0.0427s/iter; left time: 291.8887s\n",
      "\titers: 400, epoch: 3 | loss: 0.4678192\n",
      "\tspeed: 0.0428s/iter; left time: 287.7050s\n",
      "\titers: 500, epoch: 3 | loss: 0.4578561\n",
      "\tspeed: 0.0428s/iter; left time: 283.4134s\n",
      "\titers: 600, epoch: 3 | loss: 0.4424357\n",
      "\tspeed: 0.0427s/iter; left time: 278.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751456\n",
      "\tspeed: 0.0427s/iter; left time: 274.5151s\n",
      "\titers: 800, epoch: 3 | loss: 0.4236996\n",
      "\tspeed: 0.0427s/iter; left time: 270.0678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4665015 Vali Loss: 0.5722540 Test Loss: 0.6234865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4868843\n",
      "\tspeed: 0.1518s/iter; left time: 932.0490s\n",
      "\titers: 200, epoch: 4 | loss: 0.4776935\n",
      "\tspeed: 0.0428s/iter; left time: 258.3937s\n",
      "\titers: 300, epoch: 4 | loss: 0.4831240\n",
      "\tspeed: 0.0428s/iter; left time: 253.9956s\n",
      "\titers: 400, epoch: 4 | loss: 0.4405861\n",
      "\tspeed: 0.0427s/iter; left time: 249.4328s\n",
      "\titers: 500, epoch: 4 | loss: 0.4349448\n",
      "\tspeed: 0.0428s/iter; left time: 245.3025s\n",
      "\titers: 600, epoch: 4 | loss: 0.4479438\n",
      "\tspeed: 0.0429s/iter; left time: 241.9157s\n",
      "\titers: 700, epoch: 4 | loss: 0.4399997\n",
      "\tspeed: 0.0429s/iter; left time: 237.6722s\n",
      "\titers: 800, epoch: 4 | loss: 0.3783943\n",
      "\tspeed: 0.0429s/iter; left time: 233.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4382588 Vali Loss: 0.5783772 Test Loss: 0.6318021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4318333\n",
      "\tspeed: 0.1513s/iter; left time: 793.8737s\n",
      "\titers: 200, epoch: 5 | loss: 0.3880471\n",
      "\tspeed: 0.0427s/iter; left time: 219.6857s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674024\n",
      "\tspeed: 0.0428s/iter; left time: 216.0979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704361\n",
      "\tspeed: 0.0430s/iter; left time: 212.4841s\n",
      "\titers: 500, epoch: 5 | loss: 0.3912926\n",
      "\tspeed: 0.0428s/iter; left time: 207.3283s\n",
      "\titers: 600, epoch: 5 | loss: 0.3840115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6971s\n",
      "\titers: 700, epoch: 5 | loss: 0.3629414\n",
      "\tspeed: 0.0427s/iter; left time: 198.4789s\n",
      "\titers: 800, epoch: 5 | loss: 0.3453966\n",
      "\tspeed: 0.0427s/iter; left time: 194.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3968851 Vali Loss: 0.5949938 Test Loss: 0.6539372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7655912637710571, rmse:0.8749807476997375, mae:0.5963423848152161, rse:0.6939675807952881\n",
      "Original data scale mse:31555720.0, rmse:5617.44775390625, mae:3527.80322265625, rse:0.27975091338157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5567461\n",
      "\tspeed: 0.0443s/iter; left time: 390.7184s\n",
      "\titers: 200, epoch: 1 | loss: 0.5131473\n",
      "\tspeed: 0.0427s/iter; left time: 372.0392s\n",
      "\titers: 300, epoch: 1 | loss: 0.5688336\n",
      "\tspeed: 0.0427s/iter; left time: 367.3527s\n",
      "\titers: 400, epoch: 1 | loss: 0.5851882\n",
      "\tspeed: 0.0426s/iter; left time: 362.9409s\n",
      "\titers: 500, epoch: 1 | loss: 0.4940234\n",
      "\tspeed: 0.0427s/iter; left time: 359.3432s\n",
      "\titers: 600, epoch: 1 | loss: 0.5569887\n",
      "\tspeed: 0.0427s/iter; left time: 355.1089s\n",
      "\titers: 700, epoch: 1 | loss: 0.5020673\n",
      "\tspeed: 0.0427s/iter; left time: 350.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5009230\n",
      "\tspeed: 0.0427s/iter; left time: 346.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5401562 Vali Loss: 0.5691482 Test Loss: 0.6024293\n",
      "Validation loss decreased (inf --> 0.569148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5425625\n",
      "\tspeed: 0.1539s/iter; left time: 1219.0067s\n",
      "\titers: 200, epoch: 2 | loss: 0.5092666\n",
      "\tspeed: 0.0427s/iter; left time: 333.6463s\n",
      "\titers: 300, epoch: 2 | loss: 0.5347412\n",
      "\tspeed: 0.0427s/iter; left time: 329.3097s\n",
      "\titers: 400, epoch: 2 | loss: 0.5148687\n",
      "\tspeed: 0.0427s/iter; left time: 325.4797s\n",
      "\titers: 500, epoch: 2 | loss: 0.4511907\n",
      "\tspeed: 0.0427s/iter; left time: 321.2890s\n",
      "\titers: 600, epoch: 2 | loss: 0.4812346\n",
      "\tspeed: 0.0427s/iter; left time: 316.8765s\n",
      "\titers: 700, epoch: 2 | loss: 0.5175083\n",
      "\tspeed: 0.0427s/iter; left time: 312.3264s\n",
      "\titers: 800, epoch: 2 | loss: 0.4783387\n",
      "\tspeed: 0.0427s/iter; left time: 308.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.5104276 Vali Loss: 0.5632515 Test Loss: 0.6076972\n",
      "Validation loss decreased (0.569148 --> 0.563251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4891643\n",
      "\tspeed: 0.1538s/iter; left time: 1080.8924s\n",
      "\titers: 200, epoch: 3 | loss: 0.4391293\n",
      "\tspeed: 0.0427s/iter; left time: 295.9464s\n",
      "\titers: 300, epoch: 3 | loss: 0.4282694\n",
      "\tspeed: 0.0427s/iter; left time: 291.3648s\n",
      "\titers: 400, epoch: 3 | loss: 0.4537349\n",
      "\tspeed: 0.0424s/iter; left time: 285.3786s\n",
      "\titers: 500, epoch: 3 | loss: 0.4212231\n",
      "\tspeed: 0.0428s/iter; left time: 283.9576s\n",
      "\titers: 600, epoch: 3 | loss: 0.4614433\n",
      "\tspeed: 0.0427s/iter; left time: 278.6681s\n",
      "\titers: 700, epoch: 3 | loss: 0.5231907\n",
      "\tspeed: 0.0427s/iter; left time: 274.5001s\n",
      "\titers: 800, epoch: 3 | loss: 0.4524678\n",
      "\tspeed: 0.0428s/iter; left time: 270.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.4641792 Vali Loss: 0.5592130 Test Loss: 0.6112368\n",
      "Validation loss decreased (0.563251 --> 0.559213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4562828\n",
      "\tspeed: 0.1539s/iter; left time: 944.6766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4032119\n",
      "\tspeed: 0.0427s/iter; left time: 258.0062s\n",
      "\titers: 300, epoch: 4 | loss: 0.4174506\n",
      "\tspeed: 0.0427s/iter; left time: 253.6510s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366000\n",
      "\tspeed: 0.0426s/iter; left time: 248.9802s\n",
      "\titers: 500, epoch: 4 | loss: 0.3799008\n",
      "\tspeed: 0.0426s/iter; left time: 244.6381s\n",
      "\titers: 600, epoch: 4 | loss: 0.4402491\n",
      "\tspeed: 0.0427s/iter; left time: 240.5559s\n",
      "\titers: 700, epoch: 4 | loss: 0.4542446\n",
      "\tspeed: 0.0427s/iter; left time: 236.7406s\n",
      "\titers: 800, epoch: 4 | loss: 0.4093605\n",
      "\tspeed: 0.0427s/iter; left time: 232.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4341894 Vali Loss: 0.5747357 Test Loss: 0.6246487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3754254\n",
      "\tspeed: 0.1526s/iter; left time: 800.5439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3966073\n",
      "\tspeed: 0.0427s/iter; left time: 219.6991s\n",
      "\titers: 300, epoch: 5 | loss: 0.3927452\n",
      "\tspeed: 0.0427s/iter; left time: 215.6141s\n",
      "\titers: 400, epoch: 5 | loss: 0.4006265\n",
      "\tspeed: 0.0428s/iter; left time: 211.5692s\n",
      "\titers: 500, epoch: 5 | loss: 0.3565641\n",
      "\tspeed: 0.0427s/iter; left time: 207.1230s\n",
      "\titers: 600, epoch: 5 | loss: 0.3645180\n",
      "\tspeed: 0.0427s/iter; left time: 202.7275s\n",
      "\titers: 700, epoch: 5 | loss: 0.3615814\n",
      "\tspeed: 0.0426s/iter; left time: 198.0965s\n",
      "\titers: 800, epoch: 5 | loss: 0.3716194\n",
      "\tspeed: 0.0428s/iter; left time: 194.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.3956859 Vali Loss: 0.5881065 Test Loss: 0.6395448\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3419645\n",
      "\tspeed: 0.1518s/iter; left time: 661.4252s\n",
      "\titers: 200, epoch: 6 | loss: 0.3649749\n",
      "\tspeed: 0.0425s/iter; left time: 181.0643s\n",
      "\titers: 300, epoch: 6 | loss: 0.3397926\n",
      "\tspeed: 0.0425s/iter; left time: 176.5243s\n",
      "\titers: 400, epoch: 6 | loss: 0.3800455\n",
      "\tspeed: 0.0427s/iter; left time: 173.1685s\n",
      "\titers: 500, epoch: 6 | loss: 0.3381722\n",
      "\tspeed: 0.0427s/iter; left time: 168.8047s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673343\n",
      "\tspeed: 0.0427s/iter; left time: 164.7808s\n",
      "\titers: 700, epoch: 6 | loss: 0.3715284\n",
      "\tspeed: 0.0427s/iter; left time: 160.3121s\n",
      "\titers: 800, epoch: 6 | loss: 0.3510702\n",
      "\tspeed: 0.0427s/iter; left time: 156.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.3557695 Vali Loss: 0.5995966 Test Loss: 0.6508650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8202449083328247, rmse:0.9056737422943115, mae:0.6112369298934937, rse:0.7183108925819397\n",
      "Original data scale mse:34537172.0, rmse:5876.83349609375, mae:3631.940673828125, rse:0.2926684021949768\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454177\n",
      "\tspeed: 0.0676s/iter; left time: 594.5601s\n",
      "\titers: 200, epoch: 1 | loss: 0.5544594\n",
      "\tspeed: 0.0434s/iter; left time: 377.3446s\n",
      "\titers: 300, epoch: 1 | loss: 0.5635941\n",
      "\tspeed: 0.0434s/iter; left time: 372.8728s\n",
      "\titers: 400, epoch: 1 | loss: 0.6180624\n",
      "\tspeed: 0.0434s/iter; left time: 368.1762s\n",
      "\titers: 500, epoch: 1 | loss: 0.5999923\n",
      "\tspeed: 0.0432s/iter; left time: 362.8958s\n",
      "\titers: 600, epoch: 1 | loss: 0.5538129\n",
      "\tspeed: 0.0433s/iter; left time: 359.3278s\n",
      "\titers: 700, epoch: 1 | loss: 0.5393959\n",
      "\tspeed: 0.0433s/iter; left time: 354.2748s\n",
      "\titers: 800, epoch: 1 | loss: 0.5381173\n",
      "\tspeed: 0.0433s/iter; left time: 350.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 889 | Train Loss: 0.5633903 Vali Loss: 0.5876741 Test Loss: 0.6291287\n",
      "Validation loss decreased (inf --> 0.587674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5834135\n",
      "\tspeed: 0.1545s/iter; left time: 1221.0624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5220478\n",
      "\tspeed: 0.0434s/iter; left time: 338.3012s\n",
      "\titers: 300, epoch: 2 | loss: 0.5758332\n",
      "\tspeed: 0.0433s/iter; left time: 333.5033s\n",
      "\titers: 400, epoch: 2 | loss: 0.5207759\n",
      "\tspeed: 0.0434s/iter; left time: 329.8133s\n",
      "\titers: 500, epoch: 2 | loss: 0.5079741\n",
      "\tspeed: 0.0433s/iter; left time: 324.9222s\n",
      "\titers: 600, epoch: 2 | loss: 0.5090077\n",
      "\tspeed: 0.0432s/iter; left time: 320.0888s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622243\n",
      "\tspeed: 0.0434s/iter; left time: 317.2569s\n",
      "\titers: 800, epoch: 2 | loss: 0.5246297\n",
      "\tspeed: 0.0433s/iter; left time: 312.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5286044 Vali Loss: 0.5791647 Test Loss: 0.6255860\n",
      "Validation loss decreased (0.587674 --> 0.579165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951027\n",
      "\tspeed: 0.1555s/iter; left time: 1090.4638s\n",
      "\titers: 200, epoch: 3 | loss: 0.4212805\n",
      "\tspeed: 0.0433s/iter; left time: 299.4308s\n",
      "\titers: 300, epoch: 3 | loss: 0.4809437\n",
      "\tspeed: 0.0433s/iter; left time: 294.8038s\n",
      "\titers: 400, epoch: 3 | loss: 0.5490001\n",
      "\tspeed: 0.0433s/iter; left time: 290.3509s\n",
      "\titers: 500, epoch: 3 | loss: 0.5272199\n",
      "\tspeed: 0.0433s/iter; left time: 286.4257s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973647\n",
      "\tspeed: 0.0433s/iter; left time: 281.9563s\n",
      "\titers: 700, epoch: 3 | loss: 0.4791625\n",
      "\tspeed: 0.0433s/iter; left time: 277.8630s\n",
      "\titers: 800, epoch: 3 | loss: 0.4444051\n",
      "\tspeed: 0.0434s/iter; left time: 273.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4811308 Vali Loss: 0.5916529 Test Loss: 0.6518676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4643247\n",
      "\tspeed: 0.1514s/iter; left time: 927.3796s\n",
      "\titers: 200, epoch: 4 | loss: 0.4047467\n",
      "\tspeed: 0.0433s/iter; left time: 260.8542s\n",
      "\titers: 300, epoch: 4 | loss: 0.5270584\n",
      "\tspeed: 0.0433s/iter; left time: 256.4785s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366706\n",
      "\tspeed: 0.0433s/iter; left time: 252.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.4361570\n",
      "\tspeed: 0.0433s/iter; left time: 247.5898s\n",
      "\titers: 600, epoch: 4 | loss: 0.3978770\n",
      "\tspeed: 0.0433s/iter; left time: 243.4390s\n",
      "\titers: 700, epoch: 4 | loss: 0.4258873\n",
      "\tspeed: 0.0432s/iter; left time: 238.8988s\n",
      "\titers: 800, epoch: 4 | loss: 0.4317477\n",
      "\tspeed: 0.0432s/iter; left time: 234.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4384420 Vali Loss: 0.5988257 Test Loss: 0.6685336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3967570\n",
      "\tspeed: 0.1522s/iter; left time: 796.9504s\n",
      "\titers: 200, epoch: 5 | loss: 0.3766952\n",
      "\tspeed: 0.0434s/iter; left time: 222.8755s\n",
      "\titers: 300, epoch: 5 | loss: 0.3889566\n",
      "\tspeed: 0.0434s/iter; left time: 218.2767s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054741\n",
      "\tspeed: 0.0433s/iter; left time: 213.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.4088733\n",
      "\tspeed: 0.0434s/iter; left time: 209.7270s\n",
      "\titers: 600, epoch: 5 | loss: 0.3773878\n",
      "\tspeed: 0.0433s/iter; left time: 204.8636s\n",
      "\titers: 700, epoch: 5 | loss: 0.3832667\n",
      "\tspeed: 0.0433s/iter; left time: 200.6077s\n",
      "\titers: 800, epoch: 5 | loss: 0.3715691\n",
      "\tspeed: 0.0433s/iter; left time: 196.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.3870841 Vali Loss: 0.6039886 Test Loss: 0.6716257\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8244243860244751, rmse:0.9079781770706177, mae:0.6255861520767212, rse:0.7192794680595398\n",
      "Original data scale mse:35018344.0, rmse:5917.6298828125, mae:3745.188720703125, rse:0.29484474658966064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6611432\n",
      "\tspeed: 0.0448s/iter; left time: 394.1709s\n",
      "\titers: 200, epoch: 1 | loss: 0.5944821\n",
      "\tspeed: 0.0433s/iter; left time: 376.1663s\n",
      "\titers: 300, epoch: 1 | loss: 0.6297670\n",
      "\tspeed: 0.0434s/iter; left time: 372.9207s\n",
      "\titers: 400, epoch: 1 | loss: 0.6077808\n",
      "\tspeed: 0.0434s/iter; left time: 368.4377s\n",
      "\titers: 500, epoch: 1 | loss: 0.5648095\n",
      "\tspeed: 0.0433s/iter; left time: 363.7158s\n",
      "\titers: 600, epoch: 1 | loss: 0.4902555\n",
      "\tspeed: 0.0434s/iter; left time: 359.6220s\n",
      "\titers: 700, epoch: 1 | loss: 0.5395623\n",
      "\tspeed: 0.0433s/iter; left time: 354.3923s\n",
      "\titers: 800, epoch: 1 | loss: 0.5115961\n",
      "\tspeed: 0.0433s/iter; left time: 350.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5642094 Vali Loss: 0.5857942 Test Loss: 0.6274691\n",
      "Validation loss decreased (inf --> 0.585794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5886168\n",
      "\tspeed: 0.1535s/iter; left time: 1212.7097s\n",
      "\titers: 200, epoch: 2 | loss: 0.5624777\n",
      "\tspeed: 0.0433s/iter; left time: 337.5492s\n",
      "\titers: 300, epoch: 2 | loss: 0.5613257\n",
      "\tspeed: 0.0434s/iter; left time: 334.1199s\n",
      "\titers: 400, epoch: 2 | loss: 0.5375162\n",
      "\tspeed: 0.0434s/iter; left time: 329.5467s\n",
      "\titers: 500, epoch: 2 | loss: 0.5497366\n",
      "\tspeed: 0.0433s/iter; left time: 324.5267s\n",
      "\titers: 600, epoch: 2 | loss: 0.5392722\n",
      "\tspeed: 0.0433s/iter; left time: 320.3824s\n",
      "\titers: 700, epoch: 2 | loss: 0.4927635\n",
      "\tspeed: 0.0433s/iter; left time: 316.4743s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971849\n",
      "\tspeed: 0.0434s/iter; left time: 312.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5316510 Vali Loss: 0.5887495 Test Loss: 0.6355409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4743690\n",
      "\tspeed: 0.1516s/iter; left time: 1063.4614s\n",
      "\titers: 200, epoch: 3 | loss: 0.4684273\n",
      "\tspeed: 0.0434s/iter; left time: 299.8641s\n",
      "\titers: 300, epoch: 3 | loss: 0.5384349\n",
      "\tspeed: 0.0434s/iter; left time: 295.6602s\n",
      "\titers: 400, epoch: 3 | loss: 0.5281529\n",
      "\tspeed: 0.0433s/iter; left time: 290.6836s\n",
      "\titers: 500, epoch: 3 | loss: 0.4912407\n",
      "\tspeed: 0.0433s/iter; left time: 286.2018s\n",
      "\titers: 600, epoch: 3 | loss: 0.5095457\n",
      "\tspeed: 0.0433s/iter; left time: 282.3354s\n",
      "\titers: 700, epoch: 3 | loss: 0.4622054\n",
      "\tspeed: 0.0433s/iter; left time: 277.5876s\n",
      "\titers: 800, epoch: 3 | loss: 0.4754922\n",
      "\tspeed: 0.0433s/iter; left time: 273.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.4833817 Vali Loss: 0.5937650 Test Loss: 0.6408314\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4836038\n",
      "\tspeed: 0.1509s/iter; left time: 924.0996s\n",
      "\titers: 200, epoch: 4 | loss: 0.4296790\n",
      "\tspeed: 0.0434s/iter; left time: 261.1547s\n",
      "\titers: 300, epoch: 4 | loss: 0.4317384\n",
      "\tspeed: 0.0434s/iter; left time: 256.8122s\n",
      "\titers: 400, epoch: 4 | loss: 0.3970349\n",
      "\tspeed: 0.0433s/iter; left time: 252.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.4507579\n",
      "\tspeed: 0.0435s/iter; left time: 248.7202s\n",
      "\titers: 600, epoch: 4 | loss: 0.4092776\n",
      "\tspeed: 0.0434s/iter; left time: 244.0600s\n",
      "\titers: 700, epoch: 4 | loss: 0.4983984\n",
      "\tspeed: 0.0432s/iter; left time: 238.8728s\n",
      "\titers: 800, epoch: 4 | loss: 0.4482481\n",
      "\tspeed: 0.0433s/iter; left time: 234.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4415455 Vali Loss: 0.6122530 Test Loss: 0.6604525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8160760402679443, rmse:0.9033692479133606, mae:0.6274691224098206, rse:0.715628445148468\n",
      "Original data scale mse:33935912.0, rmse:5825.45361328125, mae:3740.77783203125, rse:0.29025208950042725\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.6841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4551  0.6746  0.4416  0.5339\n",
       "              2         24        0.4664  0.6829  0.4506  0.5405\n",
       "              1         96        0.7439  0.8625  0.6113  0.6841\n",
       "              2         96        0.7726  0.8790  0.6245  0.6971\n",
       "              1         168       0.8226  0.9070  0.6497  0.7185\n",
       "              2         168       0.8047  0.8970  0.6460  0.7106\n",
       "RMSE          1         24        0.4513  0.6718  0.4435  0.5317\n",
       "              2         24        0.4518  0.6722  0.4493  0.5320\n",
       "              1         96        0.7535  0.8680  0.6172  0.6884\n",
       "              2         96        0.7755  0.8806  0.6255  0.6985\n",
       "              1         168       0.8276  0.9097  0.6519  0.7207\n",
       "              2         168       0.8039  0.8966  0.6451  0.7103\n",
       "MAE           1         24        0.4612  0.6791  0.4230  0.5375\n",
       "              2         24        0.4455  0.6674  0.4187  0.5282\n",
       "              1         96        0.7656  0.8750  0.5963  0.6940\n",
       "              2         96        0.8202  0.9057  0.6112  0.7183\n",
       "              1         168       0.8244  0.9080  0.6256  0.7193\n",
       "              2         168       0.8161  0.9034  0.6275  0.7156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17261680.0</td>\n",
       "      <td>4154.7178</td>\n",
       "      <td>2581.1782</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17762658.0</td>\n",
       "      <td>4214.5767</td>\n",
       "      <td>2639.2039</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30875704.0</td>\n",
       "      <td>5556.5908</td>\n",
       "      <td>3633.8970</td>\n",
       "      <td>0.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32792920.0</td>\n",
       "      <td>5726.5103</td>\n",
       "      <td>3746.3784</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35247892.0</td>\n",
       "      <td>5936.9937</td>\n",
       "      <td>3905.6101</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34226872.0</td>\n",
       "      <td>5850.3735</td>\n",
       "      <td>3899.1096</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17305828.0</td>\n",
       "      <td>4160.0273</td>\n",
       "      <td>2609.1721</td>\n",
       "      <td>0.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17345650.0</td>\n",
       "      <td>4164.8110</td>\n",
       "      <td>2657.5583</td>\n",
       "      <td>0.2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31262294.0</td>\n",
       "      <td>5591.2695</td>\n",
       "      <td>3673.3840</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33044252.0</td>\n",
       "      <td>5748.4131</td>\n",
       "      <td>3757.2954</td>\n",
       "      <td>0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35287100.0</td>\n",
       "      <td>5940.2944</td>\n",
       "      <td>3912.6470</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34170808.0</td>\n",
       "      <td>5845.5801</td>\n",
       "      <td>3891.9578</td>\n",
       "      <td>0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17183404.0</td>\n",
       "      <td>4145.2871</td>\n",
       "      <td>2456.1895</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16678795.0</td>\n",
       "      <td>4083.9680</td>\n",
       "      <td>2431.3040</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31555720.0</td>\n",
       "      <td>5617.4478</td>\n",
       "      <td>3527.8032</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34537172.0</td>\n",
       "      <td>5876.8335</td>\n",
       "      <td>3631.9407</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35018344.0</td>\n",
       "      <td>5917.6299</td>\n",
       "      <td>3745.1887</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33935912.0</td>\n",
       "      <td>5825.4536</td>\n",
       "      <td>3740.7778</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17261680.0  4154.7178  2581.1782  0.2066\n",
       "              2         24        17762658.0  4214.5767  2639.2039  0.2096\n",
       "              1         96        30875704.0  5556.5908  3633.8970  0.2767\n",
       "              2         96        32792920.0  5726.5103  3746.3784  0.2852\n",
       "              1         168       35247892.0  5936.9937  3905.6101  0.2958\n",
       "              2         168       34226872.0  5850.3735  3899.1096  0.2915\n",
       "RMSE          1         24        17305828.0  4160.0273  2609.1721  0.2068\n",
       "              2         24        17345650.0  4164.8110  2657.5583  0.2071\n",
       "              1         96        31262294.0  5591.2695  3673.3840  0.2784\n",
       "              2         96        33044252.0  5748.4131  3757.2954  0.2863\n",
       "              1         168       35287100.0  5940.2944  3912.6470  0.2960\n",
       "              2         168       34170808.0  5845.5801  3891.9578  0.2913\n",
       "MAE           1         24        17183404.0  4145.2871  2456.1895  0.2061\n",
       "              2         24        16678795.0  4083.9680  2431.3040  0.2031\n",
       "              1         96        31555720.0  5617.4478  3527.8032  0.2798\n",
       "              2         96        34537172.0  5876.8335  3631.9407  0.2927\n",
       "              1         168       35018344.0  5917.6299  3745.1887  0.2948\n",
       "              2         168       33935912.0  5825.4536  3740.7778  0.2903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5871.54175"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5917.6299 + 5825.4536) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.4461</td>\n",
       "      <td>0.5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4534  0.6733  0.4208  0.5329\n",
       "         MSE            0.4608  0.6788  0.4461  0.5372\n",
       "         RMSE           0.4515  0.6720  0.4464  0.5318\n",
       "96       MAE            0.7929  0.8903  0.6038  0.7061\n",
       "         MSE            0.7583  0.8708  0.6179  0.6906\n",
       "         RMSE           0.7645  0.8743  0.6214  0.6935\n",
       "168      MAE            0.8203  0.9057  0.6265  0.7175\n",
       "         MSE            0.8137  0.9020  0.6478  0.7146\n",
       "         RMSE           0.8158  0.9032  0.6485  0.7155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16931099.5</td>\n",
       "      <td>4114.6276</td>\n",
       "      <td>2443.7467</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17512169.0</td>\n",
       "      <td>4184.6472</td>\n",
       "      <td>2610.1910</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17325739.0</td>\n",
       "      <td>4162.4192</td>\n",
       "      <td>2633.3652</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33046446.0</td>\n",
       "      <td>5747.1406</td>\n",
       "      <td>3579.8719</td>\n",
       "      <td>0.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31834312.0</td>\n",
       "      <td>5641.5505</td>\n",
       "      <td>3690.1377</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32153273.0</td>\n",
       "      <td>5669.8413</td>\n",
       "      <td>3715.3397</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34477128.0</td>\n",
       "      <td>5871.5417</td>\n",
       "      <td>3742.9833</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34737382.0</td>\n",
       "      <td>5893.6836</td>\n",
       "      <td>3902.3599</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34728954.0</td>\n",
       "      <td>5892.9373</td>\n",
       "      <td>3902.3024</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16931099.5  4114.6276  2443.7467  0.2046\n",
       "         MSE            17512169.0  4184.6472  2610.1910  0.2081\n",
       "         RMSE           17325739.0  4162.4192  2633.3652  0.2070\n",
       "96       MAE            33046446.0  5747.1406  3579.8719  0.2862\n",
       "         MSE            31834312.0  5641.5505  3690.1377  0.2810\n",
       "         RMSE           32153273.0  5669.8413  3715.3397  0.2824\n",
       "168      MAE            34477128.0  5871.5417  3742.9833  0.2925\n",
       "         MSE            34737382.0  5893.6836  3902.3599  0.2937\n",
       "         RMSE           34728954.0  5892.9373  3902.3024  0.2936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0942546\n",
      "\tspeed: 0.0700s/iter; left time: 627.7158s\n",
      "\titers: 200, epoch: 1 | loss: 0.0667797\n",
      "\tspeed: 0.0408s/iter; left time: 361.3990s\n",
      "\titers: 300, epoch: 1 | loss: 0.0588467\n",
      "\tspeed: 0.0407s/iter; left time: 356.6063s\n",
      "\titers: 400, epoch: 1 | loss: 0.0457102\n",
      "\tspeed: 0.0405s/iter; left time: 350.7956s\n",
      "\titers: 500, epoch: 1 | loss: 0.0421427\n",
      "\tspeed: 0.0406s/iter; left time: 347.6140s\n",
      "\titers: 600, epoch: 1 | loss: 0.0368923\n",
      "\tspeed: 0.0409s/iter; left time: 345.6893s\n",
      "\titers: 700, epoch: 1 | loss: 0.0460224\n",
      "\tspeed: 0.0412s/iter; left time: 344.5950s\n",
      "\titers: 800, epoch: 1 | loss: 0.0355560\n",
      "\tspeed: 0.0410s/iter; left time: 338.4662s\n",
      "\titers: 900, epoch: 1 | loss: 0.0282983\n",
      "\tspeed: 0.0408s/iter; left time: 332.6258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 906 | Train Loss: 0.0578716 Vali Loss: 0.0328540 Test Loss: 0.0360874\n",
      "Validation loss decreased (inf --> 0.032854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0200453\n",
      "\tspeed: 0.1070s/iter; left time: 861.7894s\n",
      "\titers: 200, epoch: 2 | loss: 0.0261499\n",
      "\tspeed: 0.0409s/iter; left time: 325.3522s\n",
      "\titers: 300, epoch: 2 | loss: 0.0187321\n",
      "\tspeed: 0.0410s/iter; left time: 322.0977s\n",
      "\titers: 400, epoch: 2 | loss: 0.0183808\n",
      "\tspeed: 0.0406s/iter; left time: 315.0277s\n",
      "\titers: 500, epoch: 2 | loss: 0.0152190\n",
      "\tspeed: 0.0404s/iter; left time: 309.5811s\n",
      "\titers: 600, epoch: 2 | loss: 0.0156461\n",
      "\tspeed: 0.0414s/iter; left time: 312.7897s\n",
      "\titers: 700, epoch: 2 | loss: 0.0146780\n",
      "\tspeed: 0.0419s/iter; left time: 312.0975s\n",
      "\titers: 800, epoch: 2 | loss: 0.0206594\n",
      "\tspeed: 0.0400s/iter; left time: 294.5469s\n",
      "\titers: 900, epoch: 2 | loss: 0.0144302\n",
      "\tspeed: 0.0414s/iter; left time: 300.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.39s\n",
      "Steps: 906 | Train Loss: 0.0199861 Vali Loss: 0.0212579 Test Loss: 0.0242976\n",
      "Validation loss decreased (0.032854 --> 0.021258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0159689\n",
      "\tspeed: 0.1015s/iter; left time: 725.9778s\n",
      "\titers: 200, epoch: 3 | loss: 0.0128649\n",
      "\tspeed: 0.0405s/iter; left time: 285.3480s\n",
      "\titers: 300, epoch: 3 | loss: 0.0146372\n",
      "\tspeed: 0.0407s/iter; left time: 283.0179s\n",
      "\titers: 400, epoch: 3 | loss: 0.0158485\n",
      "\tspeed: 0.0406s/iter; left time: 278.0355s\n",
      "\titers: 500, epoch: 3 | loss: 0.0186484\n",
      "\tspeed: 0.0409s/iter; left time: 275.8659s\n",
      "\titers: 600, epoch: 3 | loss: 0.0192382\n",
      "\tspeed: 0.0406s/iter; left time: 270.1737s\n",
      "\titers: 700, epoch: 3 | loss: 0.0138006\n",
      "\tspeed: 0.0407s/iter; left time: 266.8225s\n",
      "\titers: 800, epoch: 3 | loss: 0.0132834\n",
      "\tspeed: 0.0407s/iter; left time: 262.5218s\n",
      "\titers: 900, epoch: 3 | loss: 0.0159991\n",
      "\tspeed: 0.0406s/iter; left time: 257.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.15s\n",
      "Steps: 906 | Train Loss: 0.0146077 Vali Loss: 0.0212980 Test Loss: 0.0228801\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0104485\n",
      "\tspeed: 0.0938s/iter; left time: 585.4653s\n",
      "\titers: 200, epoch: 4 | loss: 0.0125054\n",
      "\tspeed: 0.0410s/iter; left time: 251.9391s\n",
      "\titers: 300, epoch: 4 | loss: 0.0128581\n",
      "\tspeed: 0.0409s/iter; left time: 247.0135s\n",
      "\titers: 400, epoch: 4 | loss: 0.0100157\n",
      "\tspeed: 0.0408s/iter; left time: 242.2898s\n",
      "\titers: 500, epoch: 4 | loss: 0.0132754\n",
      "\tspeed: 0.0407s/iter; left time: 237.9373s\n",
      "\titers: 600, epoch: 4 | loss: 0.0139050\n",
      "\tspeed: 0.0410s/iter; left time: 235.3904s\n",
      "\titers: 700, epoch: 4 | loss: 0.0112287\n",
      "\tspeed: 0.0411s/iter; left time: 231.9881s\n",
      "\titers: 800, epoch: 4 | loss: 0.0141093\n",
      "\tspeed: 0.0412s/iter; left time: 228.4658s\n",
      "\titers: 900, epoch: 4 | loss: 0.0116282\n",
      "\tspeed: 0.0409s/iter; left time: 222.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.0129339 Vali Loss: 0.0229334 Test Loss: 0.0247191\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0140071\n",
      "\tspeed: 0.0824s/iter; left time: 439.5661s\n",
      "\titers: 200, epoch: 5 | loss: 0.0111624\n",
      "\tspeed: 0.0283s/iter; left time: 147.9461s\n",
      "\titers: 300, epoch: 5 | loss: 0.0104040\n",
      "\tspeed: 0.0282s/iter; left time: 145.1094s\n",
      "\titers: 400, epoch: 5 | loss: 0.0135564\n",
      "\tspeed: 0.0282s/iter; left time: 142.0852s\n",
      "\titers: 500, epoch: 5 | loss: 0.0099290\n",
      "\tspeed: 0.0282s/iter; left time: 139.2726s\n",
      "\titers: 600, epoch: 5 | loss: 0.0110839\n",
      "\tspeed: 0.0282s/iter; left time: 136.3802s\n",
      "\titers: 700, epoch: 5 | loss: 0.0107402\n",
      "\tspeed: 0.0282s/iter; left time: 133.7749s\n",
      "\titers: 800, epoch: 5 | loss: 0.0121734\n",
      "\tspeed: 0.0282s/iter; left time: 130.9026s\n",
      "\titers: 900, epoch: 5 | loss: 0.0128513\n",
      "\tspeed: 0.0282s/iter; left time: 127.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 906 | Train Loss: 0.0116328 Vali Loss: 0.0209129 Test Loss: 0.0249126\n",
      "Validation loss decreased (0.021258 --> 0.020913).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0121859\n",
      "\tspeed: 0.1069s/iter; left time: 473.6636s\n",
      "\titers: 200, epoch: 6 | loss: 0.0115178\n",
      "\tspeed: 0.0415s/iter; left time: 179.8720s\n",
      "\titers: 300, epoch: 6 | loss: 0.0104146\n",
      "\tspeed: 0.0408s/iter; left time: 172.4728s\n",
      "\titers: 400, epoch: 6 | loss: 0.0115494\n",
      "\tspeed: 0.0415s/iter; left time: 171.2343s\n",
      "\titers: 500, epoch: 6 | loss: 0.0119643\n",
      "\tspeed: 0.0416s/iter; left time: 167.5382s\n",
      "\titers: 600, epoch: 6 | loss: 0.0081770\n",
      "\tspeed: 0.0417s/iter; left time: 163.8169s\n",
      "\titers: 700, epoch: 6 | loss: 0.0123818\n",
      "\tspeed: 0.0411s/iter; left time: 157.5467s\n",
      "\titers: 800, epoch: 6 | loss: 0.0079767\n",
      "\tspeed: 0.0410s/iter; left time: 153.0460s\n",
      "\titers: 900, epoch: 6 | loss: 0.0072877\n",
      "\tspeed: 0.0409s/iter; left time: 148.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.61s\n",
      "Steps: 906 | Train Loss: 0.0099782 Vali Loss: 0.0219904 Test Loss: 0.0262837\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0073663\n",
      "\tspeed: 0.0946s/iter; left time: 333.4701s\n",
      "\titers: 200, epoch: 7 | loss: 0.0101608\n",
      "\tspeed: 0.0406s/iter; left time: 139.0480s\n",
      "\titers: 300, epoch: 7 | loss: 0.0081983\n",
      "\tspeed: 0.0406s/iter; left time: 135.1511s\n",
      "\titers: 400, epoch: 7 | loss: 0.0104248\n",
      "\tspeed: 0.0405s/iter; left time: 130.6221s\n",
      "\titers: 500, epoch: 7 | loss: 0.0086621\n",
      "\tspeed: 0.0415s/iter; left time: 129.6926s\n",
      "\titers: 600, epoch: 7 | loss: 0.0076589\n",
      "\tspeed: 0.0409s/iter; left time: 123.7931s\n",
      "\titers: 700, epoch: 7 | loss: 0.0073568\n",
      "\tspeed: 0.0407s/iter; left time: 119.0445s\n",
      "\titers: 800, epoch: 7 | loss: 0.0081911\n",
      "\tspeed: 0.0413s/iter; left time: 116.6765s\n",
      "\titers: 900, epoch: 7 | loss: 0.0091360\n",
      "\tspeed: 0.0415s/iter; left time: 113.0128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.0087739 Vali Loss: 0.0225039 Test Loss: 0.0279977\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0083496\n",
      "\tspeed: 0.0946s/iter; left time: 247.8221s\n",
      "\titers: 200, epoch: 8 | loss: 0.0081475\n",
      "\tspeed: 0.0415s/iter; left time: 104.4573s\n",
      "\titers: 300, epoch: 8 | loss: 0.0073608\n",
      "\tspeed: 0.0413s/iter; left time: 99.9306s\n",
      "\titers: 400, epoch: 8 | loss: 0.0073632\n",
      "\tspeed: 0.0408s/iter; left time: 94.5886s\n",
      "\titers: 500, epoch: 8 | loss: 0.0064928\n",
      "\tspeed: 0.0411s/iter; left time: 91.1606s\n",
      "\titers: 600, epoch: 8 | loss: 0.0057923\n",
      "\tspeed: 0.0415s/iter; left time: 87.9722s\n",
      "\titers: 700, epoch: 8 | loss: 0.0083221\n",
      "\tspeed: 0.0413s/iter; left time: 83.3585s\n",
      "\titers: 800, epoch: 8 | loss: 0.0076627\n",
      "\tspeed: 0.0412s/iter; left time: 79.0234s\n",
      "\titers: 900, epoch: 8 | loss: 0.0086224\n",
      "\tspeed: 0.0408s/iter; left time: 74.1826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.0077076 Vali Loss: 0.0230374 Test Loss: 0.0285441\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02496965043246746, rmse:0.15801787376403809, mae:0.10408886522054672, rse:0.55804443359375\n",
      "Original data scale mse:21478470.0, rmse:4634.48681640625, mae:2927.15283203125, rse:0.2304360270500183\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0938398\n",
      "\tspeed: 0.0425s/iter; left time: 381.2046s\n",
      "\titers: 200, epoch: 1 | loss: 0.0642789\n",
      "\tspeed: 0.0407s/iter; left time: 360.2140s\n",
      "\titers: 300, epoch: 1 | loss: 0.0629560\n",
      "\tspeed: 0.0406s/iter; left time: 355.9833s\n",
      "\titers: 400, epoch: 1 | loss: 0.0477485\n",
      "\tspeed: 0.0404s/iter; left time: 350.2551s\n",
      "\titers: 500, epoch: 1 | loss: 0.0532036\n",
      "\tspeed: 0.0405s/iter; left time: 346.9005s\n",
      "\titers: 600, epoch: 1 | loss: 0.0478263\n",
      "\tspeed: 0.0407s/iter; left time: 344.6948s\n",
      "\titers: 700, epoch: 1 | loss: 0.0405289\n",
      "\tspeed: 0.0405s/iter; left time: 338.5439s\n",
      "\titers: 800, epoch: 1 | loss: 0.0288731\n",
      "\tspeed: 0.0408s/iter; left time: 337.3617s\n",
      "\titers: 900, epoch: 1 | loss: 0.0323386\n",
      "\tspeed: 0.0405s/iter; left time: 330.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.06s\n",
      "Steps: 906 | Train Loss: 0.0581791 Vali Loss: 0.0334077 Test Loss: 0.0377991\n",
      "Validation loss decreased (inf --> 0.033408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0285942\n",
      "\tspeed: 0.1028s/iter; left time: 828.3814s\n",
      "\titers: 200, epoch: 2 | loss: 0.0189234\n",
      "\tspeed: 0.0412s/iter; left time: 327.3616s\n",
      "\titers: 300, epoch: 2 | loss: 0.0159083\n",
      "\tspeed: 0.0414s/iter; left time: 325.0453s\n",
      "\titers: 400, epoch: 2 | loss: 0.0204149\n",
      "\tspeed: 0.0415s/iter; left time: 321.6462s\n",
      "\titers: 500, epoch: 2 | loss: 0.0143734\n",
      "\tspeed: 0.0410s/iter; left time: 313.6170s\n",
      "\titers: 600, epoch: 2 | loss: 0.0182881\n",
      "\tspeed: 0.0417s/iter; left time: 314.9621s\n",
      "\titers: 700, epoch: 2 | loss: 0.0160795\n",
      "\tspeed: 0.0416s/iter; left time: 310.1215s\n",
      "\titers: 800, epoch: 2 | loss: 0.0160197\n",
      "\tspeed: 0.0415s/iter; left time: 305.4940s\n",
      "\titers: 900, epoch: 2 | loss: 0.0163546\n",
      "\tspeed: 0.0414s/iter; left time: 300.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.0199710 Vali Loss: 0.0215980 Test Loss: 0.0231432\n",
      "Validation loss decreased (0.033408 --> 0.021598).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0140854\n",
      "\tspeed: 0.1017s/iter; left time: 727.2599s\n",
      "\titers: 200, epoch: 3 | loss: 0.0205783\n",
      "\tspeed: 0.0407s/iter; left time: 287.0602s\n",
      "\titers: 300, epoch: 3 | loss: 0.0187233\n",
      "\tspeed: 0.0412s/iter; left time: 286.5152s\n",
      "\titers: 400, epoch: 3 | loss: 0.0169409\n",
      "\tspeed: 0.0419s/iter; left time: 286.9073s\n",
      "\titers: 500, epoch: 3 | loss: 0.0176392\n",
      "\tspeed: 0.0415s/iter; left time: 279.9987s\n",
      "\titers: 600, epoch: 3 | loss: 0.0134549\n",
      "\tspeed: 0.0407s/iter; left time: 270.3361s\n",
      "\titers: 700, epoch: 3 | loss: 0.0117885\n",
      "\tspeed: 0.0406s/iter; left time: 265.7820s\n",
      "\titers: 800, epoch: 3 | loss: 0.0129310\n",
      "\tspeed: 0.0409s/iter; left time: 263.7808s\n",
      "\titers: 900, epoch: 3 | loss: 0.0140353\n",
      "\tspeed: 0.0408s/iter; left time: 258.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.49s\n",
      "Steps: 906 | Train Loss: 0.0143454 Vali Loss: 0.0208516 Test Loss: 0.0233106\n",
      "Validation loss decreased (0.021598 --> 0.020852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0143937\n",
      "\tspeed: 0.0996s/iter; left time: 621.8131s\n",
      "\titers: 200, epoch: 4 | loss: 0.0103517\n",
      "\tspeed: 0.0417s/iter; left time: 256.3368s\n",
      "\titers: 300, epoch: 4 | loss: 0.0144832\n",
      "\tspeed: 0.0417s/iter; left time: 251.9122s\n",
      "\titers: 400, epoch: 4 | loss: 0.0151069\n",
      "\tspeed: 0.0414s/iter; left time: 245.9329s\n",
      "\titers: 500, epoch: 4 | loss: 0.0142648\n",
      "\tspeed: 0.0417s/iter; left time: 243.5854s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151003\n",
      "\tspeed: 0.0414s/iter; left time: 237.7969s\n",
      "\titers: 700, epoch: 4 | loss: 0.0103973\n",
      "\tspeed: 0.0408s/iter; left time: 230.0350s\n",
      "\titers: 800, epoch: 4 | loss: 0.0104725\n",
      "\tspeed: 0.0410s/iter; left time: 227.0628s\n",
      "\titers: 900, epoch: 4 | loss: 0.0114167\n",
      "\tspeed: 0.0415s/iter; left time: 225.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 906 | Train Loss: 0.0127303 Vali Loss: 0.0203258 Test Loss: 0.0228659\n",
      "Validation loss decreased (0.020852 --> 0.020326).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0112127\n",
      "\tspeed: 0.0981s/iter; left time: 523.5135s\n",
      "\titers: 200, epoch: 5 | loss: 0.0120055\n",
      "\tspeed: 0.0411s/iter; left time: 215.2658s\n",
      "\titers: 300, epoch: 5 | loss: 0.0105872\n",
      "\tspeed: 0.0412s/iter; left time: 211.5021s\n",
      "\titers: 400, epoch: 5 | loss: 0.0095046\n",
      "\tspeed: 0.0408s/iter; left time: 205.7146s\n",
      "\titers: 500, epoch: 5 | loss: 0.0124287\n",
      "\tspeed: 0.0415s/iter; left time: 205.0714s\n",
      "\titers: 600, epoch: 5 | loss: 0.0123740\n",
      "\tspeed: 0.0415s/iter; left time: 200.9555s\n",
      "\titers: 700, epoch: 5 | loss: 0.0126600\n",
      "\tspeed: 0.0414s/iter; left time: 195.8994s\n",
      "\titers: 800, epoch: 5 | loss: 0.0142700\n",
      "\tspeed: 0.0414s/iter; left time: 191.9503s\n",
      "\titers: 900, epoch: 5 | loss: 0.0119086\n",
      "\tspeed: 0.0416s/iter; left time: 188.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.62s\n",
      "Steps: 906 | Train Loss: 0.0110497 Vali Loss: 0.0213849 Test Loss: 0.0252486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0091037\n",
      "\tspeed: 0.0954s/iter; left time: 422.6417s\n",
      "\titers: 200, epoch: 6 | loss: 0.0097279\n",
      "\tspeed: 0.0416s/iter; left time: 180.0149s\n",
      "\titers: 300, epoch: 6 | loss: 0.0106359\n",
      "\tspeed: 0.0418s/iter; left time: 176.7906s\n",
      "\titers: 400, epoch: 6 | loss: 0.0091133\n",
      "\tspeed: 0.0410s/iter; left time: 169.5551s\n",
      "\titers: 500, epoch: 6 | loss: 0.0097699\n",
      "\tspeed: 0.0412s/iter; left time: 165.9132s\n",
      "\titers: 600, epoch: 6 | loss: 0.0069945\n",
      "\tspeed: 0.0410s/iter; left time: 161.0406s\n",
      "\titers: 700, epoch: 6 | loss: 0.0091658\n",
      "\tspeed: 0.0415s/iter; left time: 159.0774s\n",
      "\titers: 800, epoch: 6 | loss: 0.0087391\n",
      "\tspeed: 0.0409s/iter; left time: 152.6115s\n",
      "\titers: 900, epoch: 6 | loss: 0.0090745\n",
      "\tspeed: 0.0410s/iter; left time: 148.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.65s\n",
      "Steps: 906 | Train Loss: 0.0096277 Vali Loss: 0.0212603 Test Loss: 0.0247180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0102733\n",
      "\tspeed: 0.0962s/iter; left time: 338.9697s\n",
      "\titers: 200, epoch: 7 | loss: 0.0070053\n",
      "\tspeed: 0.0411s/iter; left time: 140.6991s\n",
      "\titers: 300, epoch: 7 | loss: 0.0102707\n",
      "\tspeed: 0.0410s/iter; left time: 136.2691s\n",
      "\titers: 400, epoch: 7 | loss: 0.0087207\n",
      "\tspeed: 0.0410s/iter; left time: 132.2213s\n",
      "\titers: 500, epoch: 7 | loss: 0.0102770\n",
      "\tspeed: 0.0408s/iter; left time: 127.3535s\n",
      "\titers: 600, epoch: 7 | loss: 0.0107841\n",
      "\tspeed: 0.0412s/iter; left time: 124.6287s\n",
      "\titers: 700, epoch: 7 | loss: 0.0091903\n",
      "\tspeed: 0.0411s/iter; left time: 120.0760s\n",
      "\titers: 800, epoch: 7 | loss: 0.0090340\n",
      "\tspeed: 0.0409s/iter; left time: 115.6283s\n",
      "\titers: 900, epoch: 7 | loss: 0.0084766\n",
      "\tspeed: 0.0405s/iter; left time: 110.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.41s\n",
      "Steps: 906 | Train Loss: 0.0083809 Vali Loss: 0.0239215 Test Loss: 0.0280777\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022877730429172516, rmse:0.1512538641691208, mae:0.10139743983745575, rse:0.5341570973396301\n",
      "Original data scale mse:19517502.0, rmse:4417.86181640625, mae:2843.488037109375, rse:0.21966499090194702\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0945499\n",
      "\tspeed: 0.0804s/iter; left time: 718.9307s\n",
      "\titers: 200, epoch: 1 | loss: 0.0813206\n",
      "\tspeed: 0.0500s/iter; left time: 442.4028s\n",
      "\titers: 300, epoch: 1 | loss: 0.0689713\n",
      "\tspeed: 0.0493s/iter; left time: 430.5452s\n",
      "\titers: 400, epoch: 1 | loss: 0.0582750\n",
      "\tspeed: 0.0480s/iter; left time: 414.6301s\n",
      "\titers: 500, epoch: 1 | loss: 0.0542483\n",
      "\tspeed: 0.0481s/iter; left time: 410.4966s\n",
      "\titers: 600, epoch: 1 | loss: 0.0503807\n",
      "\tspeed: 0.0480s/iter; left time: 405.2029s\n",
      "\titers: 700, epoch: 1 | loss: 0.0456270\n",
      "\tspeed: 0.0480s/iter; left time: 400.7814s\n",
      "\titers: 800, epoch: 1 | loss: 0.0463673\n",
      "\tspeed: 0.0496s/iter; left time: 408.4281s\n",
      "\titers: 900, epoch: 1 | loss: 0.0438126\n",
      "\tspeed: 0.0504s/iter; left time: 410.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.16s\n",
      "Steps: 904 | Train Loss: 0.0647476 Vali Loss: 0.0486602 Test Loss: 0.0615587\n",
      "Validation loss decreased (inf --> 0.048660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0290388\n",
      "\tspeed: 0.1199s/iter; left time: 963.5849s\n",
      "\titers: 200, epoch: 2 | loss: 0.0303201\n",
      "\tspeed: 0.0482s/iter; left time: 382.4958s\n",
      "\titers: 300, epoch: 2 | loss: 0.0295338\n",
      "\tspeed: 0.0481s/iter; left time: 376.9743s\n",
      "\titers: 400, epoch: 2 | loss: 0.0259183\n",
      "\tspeed: 0.0481s/iter; left time: 372.2034s\n",
      "\titers: 500, epoch: 2 | loss: 0.0269378\n",
      "\tspeed: 0.0480s/iter; left time: 366.3616s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310408\n",
      "\tspeed: 0.0476s/iter; left time: 358.7047s\n",
      "\titers: 700, epoch: 2 | loss: 0.0253571\n",
      "\tspeed: 0.0356s/iter; left time: 264.5605s\n",
      "\titers: 800, epoch: 2 | loss: 0.0286073\n",
      "\tspeed: 0.0355s/iter; left time: 260.6318s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237425\n",
      "\tspeed: 0.0355s/iter; left time: 257.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 904 | Train Loss: 0.0288204 Vali Loss: 0.0342063 Test Loss: 0.0416341\n",
      "Validation loss decreased (0.048660 --> 0.034206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0266491\n",
      "\tspeed: 0.1159s/iter; left time: 826.6766s\n",
      "\titers: 200, epoch: 3 | loss: 0.0200128\n",
      "\tspeed: 0.0477s/iter; left time: 335.3482s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205474\n",
      "\tspeed: 0.0478s/iter; left time: 331.0808s\n",
      "\titers: 400, epoch: 3 | loss: 0.0209371\n",
      "\tspeed: 0.0477s/iter; left time: 325.9392s\n",
      "\titers: 500, epoch: 3 | loss: 0.0211199\n",
      "\tspeed: 0.0478s/iter; left time: 322.0576s\n",
      "\titers: 600, epoch: 3 | loss: 0.0268021\n",
      "\tspeed: 0.0478s/iter; left time: 316.9888s\n",
      "\titers: 700, epoch: 3 | loss: 0.0192956\n",
      "\tspeed: 0.0477s/iter; left time: 311.5624s\n",
      "\titers: 800, epoch: 3 | loss: 0.0224315\n",
      "\tspeed: 0.0476s/iter; left time: 306.4048s\n",
      "\titers: 900, epoch: 3 | loss: 0.0214192\n",
      "\tspeed: 0.0476s/iter; left time: 301.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.0229189 Vali Loss: 0.0342457 Test Loss: 0.0418113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0187121\n",
      "\tspeed: 0.1145s/iter; left time: 713.0368s\n",
      "\titers: 200, epoch: 4 | loss: 0.0181936\n",
      "\tspeed: 0.0478s/iter; left time: 293.1747s\n",
      "\titers: 300, epoch: 4 | loss: 0.0200255\n",
      "\tspeed: 0.0479s/iter; left time: 288.6336s\n",
      "\titers: 400, epoch: 4 | loss: 0.0162172\n",
      "\tspeed: 0.0479s/iter; left time: 284.2420s\n",
      "\titers: 500, epoch: 4 | loss: 0.0216165\n",
      "\tspeed: 0.0481s/iter; left time: 280.3720s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161444\n",
      "\tspeed: 0.0482s/iter; left time: 275.9975s\n",
      "\titers: 700, epoch: 4 | loss: 0.0214690\n",
      "\tspeed: 0.0480s/iter; left time: 270.0373s\n",
      "\titers: 800, epoch: 4 | loss: 0.0181671\n",
      "\tspeed: 0.0481s/iter; left time: 265.8662s\n",
      "\titers: 900, epoch: 4 | loss: 0.0226844\n",
      "\tspeed: 0.0479s/iter; left time: 260.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.64s\n",
      "Steps: 904 | Train Loss: 0.0199593 Vali Loss: 0.0352827 Test Loss: 0.0429098\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0180635\n",
      "\tspeed: 0.1144s/iter; left time: 609.4337s\n",
      "\titers: 200, epoch: 5 | loss: 0.0210786\n",
      "\tspeed: 0.0480s/iter; left time: 250.8851s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164446\n",
      "\tspeed: 0.0480s/iter; left time: 246.1041s\n",
      "\titers: 400, epoch: 5 | loss: 0.0171539\n",
      "\tspeed: 0.0460s/iter; left time: 231.0193s\n",
      "\titers: 500, epoch: 5 | loss: 0.0164758\n",
      "\tspeed: 0.0478s/iter; left time: 235.3526s\n",
      "\titers: 600, epoch: 5 | loss: 0.0173010\n",
      "\tspeed: 0.0479s/iter; left time: 231.1727s\n",
      "\titers: 700, epoch: 5 | loss: 0.0152048\n",
      "\tspeed: 0.0479s/iter; left time: 226.5249s\n",
      "\titers: 800, epoch: 5 | loss: 0.0145456\n",
      "\tspeed: 0.0480s/iter; left time: 221.9807s\n",
      "\titers: 900, epoch: 5 | loss: 0.0151162\n",
      "\tspeed: 0.0479s/iter; left time: 216.8844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.0170921 Vali Loss: 0.0348996 Test Loss: 0.0446376\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041615840047597885, rmse:0.2039996087551117, mae:0.14690826833248138, rse:0.7224038243293762\n",
      "Original data scale mse:38027972.0, rmse:6166.6826171875, mae:4192.33154296875, rse:0.3071029782295227\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0934298\n",
      "\tspeed: 0.0507s/iter; left time: 453.3141s\n",
      "\titers: 200, epoch: 1 | loss: 0.0724698\n",
      "\tspeed: 0.0477s/iter; left time: 421.3680s\n",
      "\titers: 300, epoch: 1 | loss: 0.0670248\n",
      "\tspeed: 0.0478s/iter; left time: 418.0132s\n",
      "\titers: 400, epoch: 1 | loss: 0.0601231\n",
      "\tspeed: 0.0477s/iter; left time: 411.7807s\n",
      "\titers: 500, epoch: 1 | loss: 0.0589422\n",
      "\tspeed: 0.0482s/iter; left time: 411.7008s\n",
      "\titers: 600, epoch: 1 | loss: 0.0493249\n",
      "\tspeed: 0.0504s/iter; left time: 425.6835s\n",
      "\titers: 700, epoch: 1 | loss: 0.0617602\n",
      "\tspeed: 0.0504s/iter; left time: 420.5116s\n",
      "\titers: 800, epoch: 1 | loss: 0.0475968\n",
      "\tspeed: 0.0503s/iter; left time: 414.8698s\n",
      "\titers: 900, epoch: 1 | loss: 0.0497684\n",
      "\tspeed: 0.0505s/iter; left time: 410.8179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.67s\n",
      "Steps: 904 | Train Loss: 0.0670265 Vali Loss: 0.0486257 Test Loss: 0.0613907\n",
      "Validation loss decreased (inf --> 0.048626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0374997\n",
      "\tspeed: 0.1161s/iter; left time: 933.4427s\n",
      "\titers: 200, epoch: 2 | loss: 0.0309897\n",
      "\tspeed: 0.0355s/iter; left time: 281.9439s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294268\n",
      "\tspeed: 0.0355s/iter; left time: 278.3391s\n",
      "\titers: 400, epoch: 2 | loss: 0.0241191\n",
      "\tspeed: 0.0355s/iter; left time: 274.5109s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253514\n",
      "\tspeed: 0.0355s/iter; left time: 271.1455s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310746\n",
      "\tspeed: 0.0355s/iter; left time: 267.6506s\n",
      "\titers: 700, epoch: 2 | loss: 0.0256869\n",
      "\tspeed: 0.0356s/iter; left time: 264.3938s\n",
      "\titers: 800, epoch: 2 | loss: 0.0268583\n",
      "\tspeed: 0.0355s/iter; left time: 260.4595s\n",
      "\titers: 900, epoch: 2 | loss: 0.0207889\n",
      "\tspeed: 0.0355s/iter; left time: 256.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.28s\n",
      "Steps: 904 | Train Loss: 0.0290841 Vali Loss: 0.0344298 Test Loss: 0.0417856\n",
      "Validation loss decreased (0.048626 --> 0.034430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0261266\n",
      "\tspeed: 0.1228s/iter; left time: 876.0529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0260678\n",
      "\tspeed: 0.0478s/iter; left time: 336.0701s\n",
      "\titers: 300, epoch: 3 | loss: 0.0206129\n",
      "\tspeed: 0.0477s/iter; left time: 330.9796s\n",
      "\titers: 400, epoch: 3 | loss: 0.0226454\n",
      "\tspeed: 0.0477s/iter; left time: 325.8309s\n",
      "\titers: 500, epoch: 3 | loss: 0.0228899\n",
      "\tspeed: 0.0478s/iter; left time: 321.8733s\n",
      "\titers: 600, epoch: 3 | loss: 0.0228538\n",
      "\tspeed: 0.0478s/iter; left time: 317.2094s\n",
      "\titers: 700, epoch: 3 | loss: 0.0218899\n",
      "\tspeed: 0.0478s/iter; left time: 312.1683s\n",
      "\titers: 800, epoch: 3 | loss: 0.0265811\n",
      "\tspeed: 0.0478s/iter; left time: 307.1878s\n",
      "\titers: 900, epoch: 3 | loss: 0.0242745\n",
      "\tspeed: 0.0475s/iter; left time: 300.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.0228451 Vali Loss: 0.0336392 Test Loss: 0.0409652\n",
      "Validation loss decreased (0.034430 --> 0.033639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0228310\n",
      "\tspeed: 0.1180s/iter; left time: 735.2555s\n",
      "\titers: 200, epoch: 4 | loss: 0.0209504\n",
      "\tspeed: 0.0479s/iter; left time: 293.7684s\n",
      "\titers: 300, epoch: 4 | loss: 0.0185800\n",
      "\tspeed: 0.0481s/iter; left time: 290.0404s\n",
      "\titers: 400, epoch: 4 | loss: 0.0181875\n",
      "\tspeed: 0.0481s/iter; left time: 284.9501s\n",
      "\titers: 500, epoch: 4 | loss: 0.0187002\n",
      "\tspeed: 0.0481s/iter; left time: 280.4168s\n",
      "\titers: 600, epoch: 4 | loss: 0.0216594\n",
      "\tspeed: 0.0482s/iter; left time: 275.8876s\n",
      "\titers: 700, epoch: 4 | loss: 0.0190073\n",
      "\tspeed: 0.0481s/iter; left time: 270.8143s\n",
      "\titers: 800, epoch: 4 | loss: 0.0199375\n",
      "\tspeed: 0.0479s/iter; left time: 264.9219s\n",
      "\titers: 900, epoch: 4 | loss: 0.0178906\n",
      "\tspeed: 0.0480s/iter; left time: 260.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.70s\n",
      "Steps: 904 | Train Loss: 0.0203049 Vali Loss: 0.0356499 Test Loss: 0.0466749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0140134\n",
      "\tspeed: 0.1147s/iter; left time: 610.7527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0168959\n",
      "\tspeed: 0.0479s/iter; left time: 250.1738s\n",
      "\titers: 300, epoch: 5 | loss: 0.0174581\n",
      "\tspeed: 0.0478s/iter; left time: 245.0479s\n",
      "\titers: 400, epoch: 5 | loss: 0.0161702\n",
      "\tspeed: 0.0480s/iter; left time: 241.3474s\n",
      "\titers: 500, epoch: 5 | loss: 0.0201695\n",
      "\tspeed: 0.0480s/iter; left time: 236.6370s\n",
      "\titers: 600, epoch: 5 | loss: 0.0151612\n",
      "\tspeed: 0.0479s/iter; left time: 231.2103s\n",
      "\titers: 700, epoch: 5 | loss: 0.0207555\n",
      "\tspeed: 0.0480s/iter; left time: 226.9880s\n",
      "\titers: 800, epoch: 5 | loss: 0.0172408\n",
      "\tspeed: 0.0479s/iter; left time: 221.6750s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148860\n",
      "\tspeed: 0.0477s/iter; left time: 215.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.57s\n",
      "Steps: 904 | Train Loss: 0.0178362 Vali Loss: 0.0331190 Test Loss: 0.0419096\n",
      "Validation loss decreased (0.033639 --> 0.033119).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0144145\n",
      "\tspeed: 0.1233s/iter; left time: 545.2123s\n",
      "\titers: 200, epoch: 6 | loss: 0.0169662\n",
      "\tspeed: 0.0479s/iter; left time: 206.7737s\n",
      "\titers: 300, epoch: 6 | loss: 0.0174153\n",
      "\tspeed: 0.0478s/iter; left time: 201.9536s\n",
      "\titers: 400, epoch: 6 | loss: 0.0158803\n",
      "\tspeed: 0.0480s/iter; left time: 197.6887s\n",
      "\titers: 500, epoch: 6 | loss: 0.0153488\n",
      "\tspeed: 0.0479s/iter; left time: 192.4610s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144447\n",
      "\tspeed: 0.0481s/iter; left time: 188.4310s\n",
      "\titers: 700, epoch: 6 | loss: 0.0143681\n",
      "\tspeed: 0.0481s/iter; left time: 183.8511s\n",
      "\titers: 800, epoch: 6 | loss: 0.0135953\n",
      "\tspeed: 0.0479s/iter; left time: 178.3391s\n",
      "\titers: 900, epoch: 6 | loss: 0.0135909\n",
      "\tspeed: 0.0480s/iter; left time: 173.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.68s\n",
      "Steps: 904 | Train Loss: 0.0152141 Vali Loss: 0.0362119 Test Loss: 0.0441905\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0117771\n",
      "\tspeed: 0.1146s/iter; left time: 403.0666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0153151\n",
      "\tspeed: 0.0480s/iter; left time: 164.0703s\n",
      "\titers: 300, epoch: 7 | loss: 0.0163094\n",
      "\tspeed: 0.0481s/iter; left time: 159.5725s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121797\n",
      "\tspeed: 0.0478s/iter; left time: 153.6245s\n",
      "\titers: 500, epoch: 7 | loss: 0.0131824\n",
      "\tspeed: 0.0478s/iter; left time: 148.8505s\n",
      "\titers: 600, epoch: 7 | loss: 0.0118811\n",
      "\tspeed: 0.0480s/iter; left time: 144.7546s\n",
      "\titers: 700, epoch: 7 | loss: 0.0120821\n",
      "\tspeed: 0.0475s/iter; left time: 138.7008s\n",
      "\titers: 800, epoch: 7 | loss: 0.0115689\n",
      "\tspeed: 0.0479s/iter; left time: 135.0149s\n",
      "\titers: 900, epoch: 7 | loss: 0.0110598\n",
      "\tspeed: 0.0479s/iter; left time: 130.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0131583 Vali Loss: 0.0358438 Test Loss: 0.0466085\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0126066\n",
      "\tspeed: 0.1147s/iter; left time: 299.5809s\n",
      "\titers: 200, epoch: 8 | loss: 0.0109178\n",
      "\tspeed: 0.0478s/iter; left time: 120.1959s\n",
      "\titers: 300, epoch: 8 | loss: 0.0105501\n",
      "\tspeed: 0.0479s/iter; left time: 115.6187s\n",
      "\titers: 400, epoch: 8 | loss: 0.0104000\n",
      "\tspeed: 0.0478s/iter; left time: 110.5759s\n",
      "\titers: 500, epoch: 8 | loss: 0.0107914\n",
      "\tspeed: 0.0476s/iter; left time: 105.3679s\n",
      "\titers: 600, epoch: 8 | loss: 0.0112817\n",
      "\tspeed: 0.0480s/iter; left time: 101.3766s\n",
      "\titers: 700, epoch: 8 | loss: 0.0132655\n",
      "\tspeed: 0.0476s/iter; left time: 95.8793s\n",
      "\titers: 800, epoch: 8 | loss: 0.0105933\n",
      "\tspeed: 0.0478s/iter; left time: 91.4673s\n",
      "\titers: 900, epoch: 8 | loss: 0.0097098\n",
      "\tspeed: 0.0479s/iter; left time: 86.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 904 | Train Loss: 0.0114334 Vali Loss: 0.0356914 Test Loss: 0.0472074\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041922442615032196, rmse:0.2047497034072876, mae:0.14136722683906555, rse:0.7250601053237915\n",
      "Original data scale mse:38741736.0, rmse:6224.2861328125, mae:4020.862548828125, rse:0.3099716603755951\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0873523\n",
      "\tspeed: 0.0825s/iter; left time: 736.2686s\n",
      "\titers: 200, epoch: 1 | loss: 0.0789642\n",
      "\tspeed: 0.0538s/iter; left time: 474.3834s\n",
      "\titers: 300, epoch: 1 | loss: 0.0649056\n",
      "\tspeed: 0.0534s/iter; left time: 466.0224s\n",
      "\titers: 400, epoch: 1 | loss: 0.0617752\n",
      "\tspeed: 0.0535s/iter; left time: 461.5456s\n",
      "\titers: 500, epoch: 1 | loss: 0.0583439\n",
      "\tspeed: 0.0538s/iter; left time: 458.6291s\n",
      "\titers: 600, epoch: 1 | loss: 0.0582502\n",
      "\tspeed: 0.0535s/iter; left time: 450.2001s\n",
      "\titers: 700, epoch: 1 | loss: 0.0537353\n",
      "\tspeed: 0.0537s/iter; left time: 447.1793s\n",
      "\titers: 800, epoch: 1 | loss: 0.0514252\n",
      "\tspeed: 0.0536s/iter; left time: 440.7911s\n",
      "\titers: 900, epoch: 1 | loss: 0.0530902\n",
      "\tspeed: 0.0536s/iter; left time: 435.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.13s\n",
      "Steps: 902 | Train Loss: 0.0672486 Vali Loss: 0.0566032 Test Loss: 0.0734987\n",
      "Validation loss decreased (inf --> 0.056603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0474865\n",
      "\tspeed: 0.1366s/iter; left time: 1095.4581s\n",
      "\titers: 200, epoch: 2 | loss: 0.0358440\n",
      "\tspeed: 0.0537s/iter; left time: 425.2152s\n",
      "\titers: 300, epoch: 2 | loss: 0.0414159\n",
      "\tspeed: 0.0537s/iter; left time: 419.9536s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342225\n",
      "\tspeed: 0.0536s/iter; left time: 413.8588s\n",
      "\titers: 500, epoch: 2 | loss: 0.0330931\n",
      "\tspeed: 0.0536s/iter; left time: 408.6210s\n",
      "\titers: 600, epoch: 2 | loss: 0.0289756\n",
      "\tspeed: 0.0536s/iter; left time: 403.0532s\n",
      "\titers: 700, epoch: 2 | loss: 0.0288790\n",
      "\tspeed: 0.0537s/iter; left time: 398.1771s\n",
      "\titers: 800, epoch: 2 | loss: 0.0331658\n",
      "\tspeed: 0.0536s/iter; left time: 392.0846s\n",
      "\titers: 900, epoch: 2 | loss: 0.0241773\n",
      "\tspeed: 0.0533s/iter; left time: 384.8963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0342880 Vali Loss: 0.0365227 Test Loss: 0.0451551\n",
      "Validation loss decreased (0.056603 --> 0.036523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0288659\n",
      "\tspeed: 0.1385s/iter; left time: 985.4032s\n",
      "\titers: 200, epoch: 3 | loss: 0.0243717\n",
      "\tspeed: 0.0537s/iter; left time: 376.5400s\n",
      "\titers: 300, epoch: 3 | loss: 0.0256150\n",
      "\tspeed: 0.0538s/iter; left time: 371.9475s\n",
      "\titers: 400, epoch: 3 | loss: 0.0281696\n",
      "\tspeed: 0.0538s/iter; left time: 366.5797s\n",
      "\titers: 500, epoch: 3 | loss: 0.0227520\n",
      "\tspeed: 0.0537s/iter; left time: 360.7814s\n",
      "\titers: 600, epoch: 3 | loss: 0.0243430\n",
      "\tspeed: 0.0536s/iter; left time: 354.9169s\n",
      "\titers: 700, epoch: 3 | loss: 0.0243500\n",
      "\tspeed: 0.0537s/iter; left time: 349.8627s\n",
      "\titers: 800, epoch: 3 | loss: 0.0246347\n",
      "\tspeed: 0.0537s/iter; left time: 344.3376s\n",
      "\titers: 900, epoch: 3 | loss: 0.0226484\n",
      "\tspeed: 0.0535s/iter; left time: 337.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0242081 Vali Loss: 0.0350496 Test Loss: 0.0419213\n",
      "Validation loss decreased (0.036523 --> 0.035050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0195246\n",
      "\tspeed: 0.1341s/iter; left time: 833.1418s\n",
      "\titers: 200, epoch: 4 | loss: 0.0185972\n",
      "\tspeed: 0.0538s/iter; left time: 329.1871s\n",
      "\titers: 300, epoch: 4 | loss: 0.0225250\n",
      "\tspeed: 0.0535s/iter; left time: 322.1019s\n",
      "\titers: 400, epoch: 4 | loss: 0.0223284\n",
      "\tspeed: 0.0538s/iter; left time: 318.3512s\n",
      "\titers: 500, epoch: 4 | loss: 0.0223749\n",
      "\tspeed: 0.0537s/iter; left time: 312.0035s\n",
      "\titers: 600, epoch: 4 | loss: 0.0182441\n",
      "\tspeed: 0.0536s/iter; left time: 306.5107s\n",
      "\titers: 700, epoch: 4 | loss: 0.0231301\n",
      "\tspeed: 0.0536s/iter; left time: 301.0563s\n",
      "\titers: 800, epoch: 4 | loss: 0.0219780\n",
      "\tspeed: 0.0537s/iter; left time: 296.2411s\n",
      "\titers: 900, epoch: 4 | loss: 0.0195454\n",
      "\tspeed: 0.0537s/iter; left time: 290.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.0208355 Vali Loss: 0.0383455 Test Loss: 0.0469129\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0197092\n",
      "\tspeed: 0.1310s/iter; left time: 696.2320s\n",
      "\titers: 200, epoch: 5 | loss: 0.0191564\n",
      "\tspeed: 0.0537s/iter; left time: 279.6873s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180140\n",
      "\tspeed: 0.0538s/iter; left time: 274.8789s\n",
      "\titers: 400, epoch: 5 | loss: 0.0199376\n",
      "\tspeed: 0.0536s/iter; left time: 268.8492s\n",
      "\titers: 500, epoch: 5 | loss: 0.0148208\n",
      "\tspeed: 0.0535s/iter; left time: 262.8099s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175141\n",
      "\tspeed: 0.0536s/iter; left time: 257.8693s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173887\n",
      "\tspeed: 0.0536s/iter; left time: 252.5322s\n",
      "\titers: 800, epoch: 5 | loss: 0.0157184\n",
      "\tspeed: 0.0537s/iter; left time: 247.8774s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148864\n",
      "\tspeed: 0.0534s/iter; left time: 241.1819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0178738 Vali Loss: 0.0387645 Test Loss: 0.0473018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0163559\n",
      "\tspeed: 0.1305s/iter; left time: 575.5075s\n",
      "\titers: 200, epoch: 6 | loss: 0.0168228\n",
      "\tspeed: 0.0538s/iter; left time: 231.7619s\n",
      "\titers: 300, epoch: 6 | loss: 0.0148977\n",
      "\tspeed: 0.0538s/iter; left time: 226.3885s\n",
      "\titers: 400, epoch: 6 | loss: 0.0183019\n",
      "\tspeed: 0.0539s/iter; left time: 221.4342s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140002\n",
      "\tspeed: 0.0537s/iter; left time: 215.4706s\n",
      "\titers: 600, epoch: 6 | loss: 0.0141699\n",
      "\tspeed: 0.0538s/iter; left time: 210.2261s\n",
      "\titers: 700, epoch: 6 | loss: 0.0162823\n",
      "\tspeed: 0.0537s/iter; left time: 204.7227s\n",
      "\titers: 800, epoch: 6 | loss: 0.0132826\n",
      "\tspeed: 0.0536s/iter; left time: 198.8901s\n",
      "\titers: 900, epoch: 6 | loss: 0.0166660\n",
      "\tspeed: 0.0536s/iter; left time: 193.4376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0152689 Vali Loss: 0.0395027 Test Loss: 0.0494608\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04194251820445061, rmse:0.20479872822761536, mae:0.14613044261932373, rse:0.7255402207374573\n",
      "Original data scale mse:38667512.0, rmse:6218.32080078125, mae:4159.83203125, rse:0.3098265826702118\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0996415\n",
      "\tspeed: 0.0554s/iter; left time: 494.0087s\n",
      "\titers: 200, epoch: 1 | loss: 0.0730885\n",
      "\tspeed: 0.0537s/iter; left time: 473.6945s\n",
      "\titers: 300, epoch: 1 | loss: 0.0679008\n",
      "\tspeed: 0.0538s/iter; left time: 469.0254s\n",
      "\titers: 400, epoch: 1 | loss: 0.0527211\n",
      "\tspeed: 0.0539s/iter; left time: 464.2531s\n",
      "\titers: 500, epoch: 1 | loss: 0.0611140\n",
      "\tspeed: 0.0537s/iter; left time: 457.7350s\n",
      "\titers: 600, epoch: 1 | loss: 0.0541079\n",
      "\tspeed: 0.0537s/iter; left time: 451.9281s\n",
      "\titers: 700, epoch: 1 | loss: 0.0524976\n",
      "\tspeed: 0.0536s/iter; left time: 445.7283s\n",
      "\titers: 800, epoch: 1 | loss: 0.0498116\n",
      "\tspeed: 0.0537s/iter; left time: 441.5276s\n",
      "\titers: 900, epoch: 1 | loss: 0.0514907\n",
      "\tspeed: 0.0541s/iter; left time: 439.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0677858 Vali Loss: 0.0552768 Test Loss: 0.0721760\n",
      "Validation loss decreased (inf --> 0.055277).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0399472\n",
      "\tspeed: 0.1370s/iter; left time: 1098.2554s\n",
      "\titers: 200, epoch: 2 | loss: 0.0345920\n",
      "\tspeed: 0.0534s/iter; left time: 423.2073s\n",
      "\titers: 300, epoch: 2 | loss: 0.0327963\n",
      "\tspeed: 0.0536s/iter; left time: 419.3104s\n",
      "\titers: 400, epoch: 2 | loss: 0.0300119\n",
      "\tspeed: 0.0536s/iter; left time: 413.4709s\n",
      "\titers: 500, epoch: 2 | loss: 0.0309086\n",
      "\tspeed: 0.0535s/iter; left time: 407.2992s\n",
      "\titers: 600, epoch: 2 | loss: 0.0327205\n",
      "\tspeed: 0.0534s/iter; left time: 401.4027s\n",
      "\titers: 700, epoch: 2 | loss: 0.0301898\n",
      "\tspeed: 0.0535s/iter; left time: 396.7848s\n",
      "\titers: 800, epoch: 2 | loss: 0.0246733\n",
      "\tspeed: 0.0534s/iter; left time: 391.0160s\n",
      "\titers: 900, epoch: 2 | loss: 0.0267641\n",
      "\tspeed: 0.0534s/iter; left time: 385.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.0344061 Vali Loss: 0.0406078 Test Loss: 0.0490091\n",
      "Validation loss decreased (0.055277 --> 0.040608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0244818\n",
      "\tspeed: 0.1487s/iter; left time: 1058.5863s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276308\n",
      "\tspeed: 0.0530s/iter; left time: 372.0225s\n",
      "\titers: 300, epoch: 3 | loss: 0.0285101\n",
      "\tspeed: 0.0524s/iter; left time: 362.4821s\n",
      "\titers: 400, epoch: 3 | loss: 0.0247908\n",
      "\tspeed: 0.0529s/iter; left time: 360.8414s\n",
      "\titers: 500, epoch: 3 | loss: 0.0248932\n",
      "\tspeed: 0.0527s/iter; left time: 354.0814s\n",
      "\titers: 600, epoch: 3 | loss: 0.0240189\n",
      "\tspeed: 0.0527s/iter; left time: 348.7810s\n",
      "\titers: 700, epoch: 3 | loss: 0.0220240\n",
      "\tspeed: 0.0528s/iter; left time: 344.3598s\n",
      "\titers: 800, epoch: 3 | loss: 0.0212572\n",
      "\tspeed: 0.0529s/iter; left time: 339.3520s\n",
      "\titers: 900, epoch: 3 | loss: 0.0232297\n",
      "\tspeed: 0.0532s/iter; left time: 336.1426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 902 | Train Loss: 0.0245630 Vali Loss: 0.0353295 Test Loss: 0.0427999\n",
      "Validation loss decreased (0.040608 --> 0.035330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0222516\n",
      "\tspeed: 0.1363s/iter; left time: 847.0935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0187717\n",
      "\tspeed: 0.0536s/iter; left time: 328.0645s\n",
      "\titers: 300, epoch: 4 | loss: 0.0205009\n",
      "\tspeed: 0.0538s/iter; left time: 323.5813s\n",
      "\titers: 400, epoch: 4 | loss: 0.0192620\n",
      "\tspeed: 0.0536s/iter; left time: 317.2180s\n",
      "\titers: 500, epoch: 4 | loss: 0.0217269\n",
      "\tspeed: 0.0535s/iter; left time: 311.1861s\n",
      "\titers: 600, epoch: 4 | loss: 0.0232268\n",
      "\tspeed: 0.0538s/iter; left time: 307.2986s\n",
      "\titers: 700, epoch: 4 | loss: 0.0181606\n",
      "\tspeed: 0.0536s/iter; left time: 301.1740s\n",
      "\titers: 800, epoch: 4 | loss: 0.0204242\n",
      "\tspeed: 0.0534s/iter; left time: 294.5789s\n",
      "\titers: 900, epoch: 4 | loss: 0.0196388\n",
      "\tspeed: 0.0536s/iter; left time: 290.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0210388 Vali Loss: 0.0377036 Test Loss: 0.0474297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0165764\n",
      "\tspeed: 0.1316s/iter; left time: 699.2834s\n",
      "\titers: 200, epoch: 5 | loss: 0.0184076\n",
      "\tspeed: 0.0538s/iter; left time: 280.5277s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180536\n",
      "\tspeed: 0.0538s/iter; left time: 275.1700s\n",
      "\titers: 400, epoch: 5 | loss: 0.0186979\n",
      "\tspeed: 0.0537s/iter; left time: 269.3605s\n",
      "\titers: 500, epoch: 5 | loss: 0.0193929\n",
      "\tspeed: 0.0538s/iter; left time: 264.2389s\n",
      "\titers: 600, epoch: 5 | loss: 0.0152829\n",
      "\tspeed: 0.0538s/iter; left time: 258.8215s\n",
      "\titers: 700, epoch: 5 | loss: 0.0181565\n",
      "\tspeed: 0.0537s/iter; left time: 252.8856s\n",
      "\titers: 800, epoch: 5 | loss: 0.0155313\n",
      "\tspeed: 0.0537s/iter; left time: 247.6362s\n",
      "\titers: 900, epoch: 5 | loss: 0.0167628\n",
      "\tspeed: 0.0536s/iter; left time: 242.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.0181379 Vali Loss: 0.0366080 Test Loss: 0.0473259\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0165936\n",
      "\tspeed: 0.1323s/iter; left time: 583.5683s\n",
      "\titers: 200, epoch: 6 | loss: 0.0156297\n",
      "\tspeed: 0.0539s/iter; left time: 232.2201s\n",
      "\titers: 300, epoch: 6 | loss: 0.0156377\n",
      "\tspeed: 0.0536s/iter; left time: 225.6151s\n",
      "\titers: 400, epoch: 6 | loss: 0.0153034\n",
      "\tspeed: 0.0534s/iter; left time: 219.6238s\n",
      "\titers: 500, epoch: 6 | loss: 0.0144845\n",
      "\tspeed: 0.0536s/iter; left time: 215.1185s\n",
      "\titers: 600, epoch: 6 | loss: 0.0171050\n",
      "\tspeed: 0.0538s/iter; left time: 210.3131s\n",
      "\titers: 700, epoch: 6 | loss: 0.0161407\n",
      "\tspeed: 0.0539s/iter; left time: 205.4423s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129499\n",
      "\tspeed: 0.0537s/iter; left time: 199.3313s\n",
      "\titers: 900, epoch: 6 | loss: 0.0129710\n",
      "\tspeed: 0.0537s/iter; left time: 194.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.0157268 Vali Loss: 0.0384959 Test Loss: 0.0500071\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042809925973415375, rmse:0.20690560340881348, mae:0.14824068546295166, rse:0.7330042123794556\n",
      "Original data scale mse:40122660.0, rmse:6334.2451171875, mae:4268.5029296875, rse:0.31560251116752625\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3044245\n",
      "\tspeed: 0.0756s/iter; left time: 677.2137s\n",
      "\titers: 200, epoch: 1 | loss: 0.2541756\n",
      "\tspeed: 0.0452s/iter; left time: 400.5752s\n",
      "\titers: 300, epoch: 1 | loss: 0.2359411\n",
      "\tspeed: 0.0435s/iter; left time: 381.3559s\n",
      "\titers: 400, epoch: 1 | loss: 0.2080690\n",
      "\tspeed: 0.0449s/iter; left time: 389.0107s\n",
      "\titers: 500, epoch: 1 | loss: 0.1993576\n",
      "\tspeed: 0.0422s/iter; left time: 361.6764s\n",
      "\titers: 600, epoch: 1 | loss: 0.1850158\n",
      "\tspeed: 0.0422s/iter; left time: 356.8153s\n",
      "\titers: 700, epoch: 1 | loss: 0.2074167\n",
      "\tspeed: 0.0421s/iter; left time: 351.7882s\n",
      "\titers: 800, epoch: 1 | loss: 0.1798474\n",
      "\tspeed: 0.0422s/iter; left time: 348.4517s\n",
      "\titers: 900, epoch: 1 | loss: 0.1626024\n",
      "\tspeed: 0.0422s/iter; left time: 344.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 906 | Train Loss: 0.2292621 Vali Loss: 0.0312259 Test Loss: 0.0339099\n",
      "Validation loss decreased (inf --> 0.031226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1436080\n",
      "\tspeed: 0.1036s/iter; left time: 834.1994s\n",
      "\titers: 200, epoch: 2 | loss: 0.1658469\n",
      "\tspeed: 0.0432s/iter; left time: 343.4598s\n",
      "\titers: 300, epoch: 2 | loss: 0.1337088\n",
      "\tspeed: 0.0431s/iter; left time: 338.5820s\n",
      "\titers: 400, epoch: 2 | loss: 0.1365202\n",
      "\tspeed: 0.0425s/iter; left time: 329.3796s\n",
      "\titers: 500, epoch: 2 | loss: 0.1223429\n",
      "\tspeed: 0.0422s/iter; left time: 323.2477s\n",
      "\titers: 600, epoch: 2 | loss: 0.1205767\n",
      "\tspeed: 0.0428s/iter; left time: 323.3256s\n",
      "\titers: 700, epoch: 2 | loss: 0.1182104\n",
      "\tspeed: 0.0431s/iter; left time: 321.2216s\n",
      "\titers: 800, epoch: 2 | loss: 0.1484690\n",
      "\tspeed: 0.0433s/iter; left time: 318.1072s\n",
      "\titers: 900, epoch: 2 | loss: 0.1202950\n",
      "\tspeed: 0.0427s/iter; left time: 309.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.16s\n",
      "Steps: 906 | Train Loss: 0.1393169 Vali Loss: 0.0213747 Test Loss: 0.0251196\n",
      "Validation loss decreased (0.031226 --> 0.021375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1234659\n",
      "\tspeed: 0.0915s/iter; left time: 654.2046s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091781\n",
      "\tspeed: 0.0304s/iter; left time: 214.5712s\n",
      "\titers: 300, epoch: 3 | loss: 0.1174415\n",
      "\tspeed: 0.0457s/iter; left time: 317.3540s\n",
      "\titers: 400, epoch: 3 | loss: 0.1293539\n",
      "\tspeed: 0.0457s/iter; left time: 312.9096s\n",
      "\titers: 500, epoch: 3 | loss: 0.1327087\n",
      "\tspeed: 0.0459s/iter; left time: 310.0185s\n",
      "\titers: 600, epoch: 3 | loss: 0.1358925\n",
      "\tspeed: 0.0462s/iter; left time: 307.1419s\n",
      "\titers: 700, epoch: 3 | loss: 0.1168140\n",
      "\tspeed: 0.0458s/iter; left time: 299.7247s\n",
      "\titers: 800, epoch: 3 | loss: 0.1123386\n",
      "\tspeed: 0.0462s/iter; left time: 297.6363s\n",
      "\titers: 900, epoch: 3 | loss: 0.1164839\n",
      "\tspeed: 0.0464s/iter; left time: 294.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.85s\n",
      "Steps: 906 | Train Loss: 0.1189934 Vali Loss: 0.0215323 Test Loss: 0.0226174\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1026148\n",
      "\tspeed: 0.0970s/iter; left time: 605.7869s\n",
      "\titers: 200, epoch: 4 | loss: 0.1106264\n",
      "\tspeed: 0.0425s/iter; left time: 261.3559s\n",
      "\titers: 300, epoch: 4 | loss: 0.1169095\n",
      "\tspeed: 0.0426s/iter; left time: 257.7163s\n",
      "\titers: 400, epoch: 4 | loss: 0.1024052\n",
      "\tspeed: 0.0420s/iter; left time: 249.4003s\n",
      "\titers: 500, epoch: 4 | loss: 0.1161740\n",
      "\tspeed: 0.0418s/iter; left time: 244.1080s\n",
      "\titers: 600, epoch: 4 | loss: 0.1163085\n",
      "\tspeed: 0.0421s/iter; left time: 241.5704s\n",
      "\titers: 700, epoch: 4 | loss: 0.1058583\n",
      "\tspeed: 0.0422s/iter; left time: 238.1552s\n",
      "\titers: 800, epoch: 4 | loss: 0.1178173\n",
      "\tspeed: 0.0424s/iter; left time: 234.8144s\n",
      "\titers: 900, epoch: 4 | loss: 0.1051704\n",
      "\tspeed: 0.0420s/iter; left time: 228.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.1120337 Vali Loss: 0.0215291 Test Loss: 0.0237347\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1136920\n",
      "\tspeed: 0.0974s/iter; left time: 520.0461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999234\n",
      "\tspeed: 0.0425s/iter; left time: 222.3249s\n",
      "\titers: 300, epoch: 5 | loss: 0.1005163\n",
      "\tspeed: 0.0426s/iter; left time: 219.0033s\n",
      "\titers: 400, epoch: 5 | loss: 0.1132154\n",
      "\tspeed: 0.0425s/iter; left time: 214.0120s\n",
      "\titers: 500, epoch: 5 | loss: 0.0953875\n",
      "\tspeed: 0.0421s/iter; left time: 207.9056s\n",
      "\titers: 600, epoch: 5 | loss: 0.1069302\n",
      "\tspeed: 0.0421s/iter; left time: 203.5432s\n",
      "\titers: 700, epoch: 5 | loss: 0.1032498\n",
      "\tspeed: 0.0421s/iter; left time: 199.3809s\n",
      "\titers: 800, epoch: 5 | loss: 0.1120966\n",
      "\tspeed: 0.0421s/iter; left time: 195.2326s\n",
      "\titers: 900, epoch: 5 | loss: 0.1105405\n",
      "\tspeed: 0.0423s/iter; left time: 192.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 906 | Train Loss: 0.1057751 Vali Loss: 0.0214539 Test Loss: 0.0253474\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025140458717942238, rmse:0.15855742990970612, mae:0.10656960308551788, rse:0.5599498748779297\n",
      "Original data scale mse:20226732.0, rmse:4497.4140625, mae:2958.59619140625, rse:0.2236204892396927\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2595895\n",
      "\tspeed: 0.0449s/iter; left time: 401.9492s\n",
      "\titers: 200, epoch: 1 | loss: 0.2608878\n",
      "\tspeed: 0.0428s/iter; left time: 378.8627s\n",
      "\titers: 300, epoch: 1 | loss: 0.2372577\n",
      "\tspeed: 0.0429s/iter; left time: 375.9413s\n",
      "\titers: 400, epoch: 1 | loss: 0.2196511\n",
      "\tspeed: 0.0419s/iter; left time: 362.9133s\n",
      "\titers: 500, epoch: 1 | loss: 0.2175351\n",
      "\tspeed: 0.0418s/iter; left time: 357.8264s\n",
      "\titers: 600, epoch: 1 | loss: 0.1980118\n",
      "\tspeed: 0.0418s/iter; left time: 354.0548s\n",
      "\titers: 700, epoch: 1 | loss: 0.1874889\n",
      "\tspeed: 0.0443s/iter; left time: 370.4003s\n",
      "\titers: 800, epoch: 1 | loss: 0.1916354\n",
      "\tspeed: 0.0453s/iter; left time: 374.5693s\n",
      "\titers: 900, epoch: 1 | loss: 0.1750810\n",
      "\tspeed: 0.0422s/iter; left time: 344.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.14s\n",
      "Steps: 906 | Train Loss: 0.2307725 Vali Loss: 0.0320970 Test Loss: 0.0358286\n",
      "Validation loss decreased (inf --> 0.032097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1507739\n",
      "\tspeed: 0.1047s/iter; left time: 842.9745s\n",
      "\titers: 200, epoch: 2 | loss: 0.1655973\n",
      "\tspeed: 0.0429s/iter; left time: 341.2961s\n",
      "\titers: 300, epoch: 2 | loss: 0.1238459\n",
      "\tspeed: 0.0421s/iter; left time: 330.8285s\n",
      "\titers: 400, epoch: 2 | loss: 0.1277618\n",
      "\tspeed: 0.0428s/iter; left time: 331.5396s\n",
      "\titers: 500, epoch: 2 | loss: 0.1319637\n",
      "\tspeed: 0.0426s/iter; left time: 326.0439s\n",
      "\titers: 600, epoch: 2 | loss: 0.1444153\n",
      "\tspeed: 0.0423s/iter; left time: 319.6187s\n",
      "\titers: 700, epoch: 2 | loss: 0.1221743\n",
      "\tspeed: 0.0422s/iter; left time: 314.3985s\n",
      "\titers: 800, epoch: 2 | loss: 0.1195042\n",
      "\tspeed: 0.0454s/iter; left time: 333.8014s\n",
      "\titers: 900, epoch: 2 | loss: 0.1323075\n",
      "\tspeed: 0.0427s/iter; left time: 309.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.11s\n",
      "Steps: 906 | Train Loss: 0.1392018 Vali Loss: 0.0237769 Test Loss: 0.0260980\n",
      "Validation loss decreased (0.032097 --> 0.023777).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1315212\n",
      "\tspeed: 0.1017s/iter; left time: 727.0007s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110490\n",
      "\tspeed: 0.0425s/iter; left time: 299.5826s\n",
      "\titers: 300, epoch: 3 | loss: 0.1065218\n",
      "\tspeed: 0.0424s/iter; left time: 294.9460s\n",
      "\titers: 400, epoch: 3 | loss: 0.1213241\n",
      "\tspeed: 0.0427s/iter; left time: 292.4168s\n",
      "\titers: 500, epoch: 3 | loss: 0.1188660\n",
      "\tspeed: 0.0426s/iter; left time: 287.2155s\n",
      "\titers: 600, epoch: 3 | loss: 0.1148553\n",
      "\tspeed: 0.0429s/iter; left time: 285.2754s\n",
      "\titers: 700, epoch: 3 | loss: 0.1197077\n",
      "\tspeed: 0.0433s/iter; left time: 283.2620s\n",
      "\titers: 800, epoch: 3 | loss: 0.1219010\n",
      "\tspeed: 0.0430s/iter; left time: 277.3380s\n",
      "\titers: 900, epoch: 3 | loss: 0.1039494\n",
      "\tspeed: 0.0430s/iter; left time: 273.1271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.04s\n",
      "Steps: 906 | Train Loss: 0.1192013 Vali Loss: 0.0214143 Test Loss: 0.0234998\n",
      "Validation loss decreased (0.023777 --> 0.021414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1082590\n",
      "\tspeed: 0.1016s/iter; left time: 634.5072s\n",
      "\titers: 200, epoch: 4 | loss: 0.1080726\n",
      "\tspeed: 0.0422s/iter; left time: 259.5234s\n",
      "\titers: 300, epoch: 4 | loss: 0.1309506\n",
      "\tspeed: 0.0426s/iter; left time: 257.6589s\n",
      "\titers: 400, epoch: 4 | loss: 0.1074475\n",
      "\tspeed: 0.0426s/iter; left time: 253.2057s\n",
      "\titers: 500, epoch: 4 | loss: 0.1255920\n",
      "\tspeed: 0.0423s/iter; left time: 247.3923s\n",
      "\titers: 600, epoch: 4 | loss: 0.1189473\n",
      "\tspeed: 0.0426s/iter; left time: 244.7748s\n",
      "\titers: 700, epoch: 4 | loss: 0.1094264\n",
      "\tspeed: 0.0427s/iter; left time: 240.6936s\n",
      "\titers: 800, epoch: 4 | loss: 0.0985998\n",
      "\tspeed: 0.0425s/iter; left time: 235.4349s\n",
      "\titers: 900, epoch: 4 | loss: 0.0951604\n",
      "\tspeed: 0.0423s/iter; left time: 230.1889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 906 | Train Loss: 0.1119296 Vali Loss: 0.0210033 Test Loss: 0.0229962\n",
      "Validation loss decreased (0.021414 --> 0.021003).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1206323\n",
      "\tspeed: 0.1032s/iter; left time: 550.9744s\n",
      "\titers: 200, epoch: 5 | loss: 0.1025492\n",
      "\tspeed: 0.0422s/iter; left time: 221.0341s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958860\n",
      "\tspeed: 0.0464s/iter; left time: 238.2039s\n",
      "\titers: 400, epoch: 5 | loss: 0.1053028\n",
      "\tspeed: 0.0465s/iter; left time: 234.2991s\n",
      "\titers: 500, epoch: 5 | loss: 0.0911213\n",
      "\tspeed: 0.0457s/iter; left time: 225.4931s\n",
      "\titers: 600, epoch: 5 | loss: 0.1147761\n",
      "\tspeed: 0.0461s/iter; left time: 222.8288s\n",
      "\titers: 700, epoch: 5 | loss: 0.0964720\n",
      "\tspeed: 0.0450s/iter; left time: 212.9695s\n",
      "\titers: 800, epoch: 5 | loss: 0.0956109\n",
      "\tspeed: 0.0424s/iter; left time: 196.6276s\n",
      "\titers: 900, epoch: 5 | loss: 0.1076336\n",
      "\tspeed: 0.0422s/iter; left time: 191.3419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 906 | Train Loss: 0.1052212 Vali Loss: 0.0230487 Test Loss: 0.0248546\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0975094\n",
      "\tspeed: 0.0976s/iter; left time: 432.6329s\n",
      "\titers: 200, epoch: 6 | loss: 0.1022177\n",
      "\tspeed: 0.0415s/iter; left time: 179.8468s\n",
      "\titers: 300, epoch: 6 | loss: 0.1188942\n",
      "\tspeed: 0.0420s/iter; left time: 177.5846s\n",
      "\titers: 400, epoch: 6 | loss: 0.1018972\n",
      "\tspeed: 0.0430s/iter; left time: 177.5288s\n",
      "\titers: 500, epoch: 6 | loss: 0.1062510\n",
      "\tspeed: 0.0419s/iter; left time: 168.7636s\n",
      "\titers: 600, epoch: 6 | loss: 0.0971001\n",
      "\tspeed: 0.0422s/iter; left time: 165.7171s\n",
      "\titers: 700, epoch: 6 | loss: 0.0943823\n",
      "\tspeed: 0.0425s/iter; left time: 162.6849s\n",
      "\titers: 800, epoch: 6 | loss: 0.0997844\n",
      "\tspeed: 0.0420s/iter; left time: 156.7798s\n",
      "\titers: 900, epoch: 6 | loss: 0.0909821\n",
      "\tspeed: 0.0421s/iter; left time: 152.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.0983646 Vali Loss: 0.0231138 Test Loss: 0.0255483\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1109275\n",
      "\tspeed: 0.1026s/iter; left time: 361.5863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0878093\n",
      "\tspeed: 0.0461s/iter; left time: 157.9592s\n",
      "\titers: 300, epoch: 7 | loss: 0.0889100\n",
      "\tspeed: 0.0305s/iter; left time: 101.3052s\n",
      "\titers: 400, epoch: 7 | loss: 0.1003922\n",
      "\tspeed: 0.0303s/iter; left time: 97.8166s\n",
      "\titers: 500, epoch: 7 | loss: 0.0935495\n",
      "\tspeed: 0.0349s/iter; left time: 109.0133s\n",
      "\titers: 600, epoch: 7 | loss: 0.0867671\n",
      "\tspeed: 0.0460s/iter; left time: 139.0098s\n",
      "\titers: 700, epoch: 7 | loss: 0.0835018\n",
      "\tspeed: 0.0458s/iter; left time: 133.9576s\n",
      "\titers: 800, epoch: 7 | loss: 0.0924193\n",
      "\tspeed: 0.0460s/iter; left time: 130.0904s\n",
      "\titers: 900, epoch: 7 | loss: 0.0836910\n",
      "\tspeed: 0.0458s/iter; left time: 124.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0906459 Vali Loss: 0.0246819 Test Loss: 0.0273251\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022993577644228935, rmse:0.15163633227348328, mae:0.10003083199262619, rse:0.53550785779953\n",
      "Original data scale mse:19474288.0, rmse:4412.96826171875, mae:2820.479248046875, rse:0.21942166984081268\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3050602\n",
      "\tspeed: 0.0781s/iter; left time: 698.3855s\n",
      "\titers: 200, epoch: 1 | loss: 0.2792929\n",
      "\tspeed: 0.0504s/iter; left time: 445.2401s\n",
      "\titers: 300, epoch: 1 | loss: 0.2580291\n",
      "\tspeed: 0.0477s/iter; left time: 416.5160s\n",
      "\titers: 400, epoch: 1 | loss: 0.2379579\n",
      "\tspeed: 0.0476s/iter; left time: 411.3502s\n",
      "\titers: 500, epoch: 1 | loss: 0.2285644\n",
      "\tspeed: 0.0476s/iter; left time: 406.2006s\n",
      "\titers: 600, epoch: 1 | loss: 0.2200543\n",
      "\tspeed: 0.0473s/iter; left time: 399.5404s\n",
      "\titers: 700, epoch: 1 | loss: 0.2084320\n",
      "\tspeed: 0.0476s/iter; left time: 396.6160s\n",
      "\titers: 800, epoch: 1 | loss: 0.2090365\n",
      "\tspeed: 0.0479s/iter; left time: 395.0435s\n",
      "\titers: 900, epoch: 1 | loss: 0.2044081\n",
      "\tspeed: 0.0480s/iter; left time: 390.6186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.25s\n",
      "Steps: 904 | Train Loss: 0.2474488 Vali Loss: 0.0465068 Test Loss: 0.0587189\n",
      "Validation loss decreased (inf --> 0.046507).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1707423\n",
      "\tspeed: 0.1223s/iter; left time: 983.0254s\n",
      "\titers: 200, epoch: 2 | loss: 0.1756015\n",
      "\tspeed: 0.0504s/iter; left time: 400.1047s\n",
      "\titers: 300, epoch: 2 | loss: 0.1726436\n",
      "\tspeed: 0.0503s/iter; left time: 393.9451s\n",
      "\titers: 400, epoch: 2 | loss: 0.1585707\n",
      "\tspeed: 0.0502s/iter; left time: 388.6009s\n",
      "\titers: 500, epoch: 2 | loss: 0.1642121\n",
      "\tspeed: 0.0503s/iter; left time: 384.2773s\n",
      "\titers: 600, epoch: 2 | loss: 0.1724601\n",
      "\tspeed: 0.0505s/iter; left time: 380.9353s\n",
      "\titers: 700, epoch: 2 | loss: 0.1577658\n",
      "\tspeed: 0.0505s/iter; left time: 375.9311s\n",
      "\titers: 800, epoch: 2 | loss: 0.1684639\n",
      "\tspeed: 0.0504s/iter; left time: 369.9190s\n",
      "\titers: 900, epoch: 2 | loss: 0.1521902\n",
      "\tspeed: 0.0504s/iter; left time: 364.9993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 904 | Train Loss: 0.1675332 Vali Loss: 0.0336258 Test Loss: 0.0410545\n",
      "Validation loss decreased (0.046507 --> 0.033626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1651728\n",
      "\tspeed: 0.1064s/iter; left time: 758.8851s\n",
      "\titers: 200, epoch: 3 | loss: 0.1408958\n",
      "\tspeed: 0.0354s/iter; left time: 249.0608s\n",
      "\titers: 300, epoch: 3 | loss: 0.1396739\n",
      "\tspeed: 0.0354s/iter; left time: 245.5360s\n",
      "\titers: 400, epoch: 3 | loss: 0.1394162\n",
      "\tspeed: 0.0354s/iter; left time: 241.6826s\n",
      "\titers: 500, epoch: 3 | loss: 0.1471861\n",
      "\tspeed: 0.0354s/iter; left time: 238.4769s\n",
      "\titers: 600, epoch: 3 | loss: 0.1604891\n",
      "\tspeed: 0.0354s/iter; left time: 235.0967s\n",
      "\titers: 700, epoch: 3 | loss: 0.1398279\n",
      "\tspeed: 0.0354s/iter; left time: 231.3749s\n",
      "\titers: 800, epoch: 3 | loss: 0.1480567\n",
      "\tspeed: 0.0354s/iter; left time: 227.6947s\n",
      "\titers: 900, epoch: 3 | loss: 0.1475054\n",
      "\tspeed: 0.0387s/iter; left time: 244.9664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.70s\n",
      "Steps: 904 | Train Loss: 0.1492850 Vali Loss: 0.0337527 Test Loss: 0.0420692\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1347107\n",
      "\tspeed: 0.1146s/iter; left time: 713.6439s\n",
      "\titers: 200, epoch: 4 | loss: 0.1328156\n",
      "\tspeed: 0.0477s/iter; left time: 292.3445s\n",
      "\titers: 300, epoch: 4 | loss: 0.1383835\n",
      "\tspeed: 0.0477s/iter; left time: 287.3725s\n",
      "\titers: 400, epoch: 4 | loss: 0.1231011\n",
      "\tspeed: 0.0477s/iter; left time: 282.7877s\n",
      "\titers: 500, epoch: 4 | loss: 0.1435674\n",
      "\tspeed: 0.0477s/iter; left time: 278.1344s\n",
      "\titers: 600, epoch: 4 | loss: 0.1305622\n",
      "\tspeed: 0.0477s/iter; left time: 273.0500s\n",
      "\titers: 700, epoch: 4 | loss: 0.1443142\n",
      "\tspeed: 0.0475s/iter; left time: 267.6419s\n",
      "\titers: 800, epoch: 4 | loss: 0.1291650\n",
      "\tspeed: 0.0471s/iter; left time: 260.2952s\n",
      "\titers: 900, epoch: 4 | loss: 0.1457163\n",
      "\tspeed: 0.0474s/iter; left time: 257.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.26s\n",
      "Steps: 904 | Train Loss: 0.1390550 Vali Loss: 0.0356938 Test Loss: 0.0444108\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1368660\n",
      "\tspeed: 0.1168s/iter; left time: 622.2204s\n",
      "\titers: 200, epoch: 5 | loss: 0.1410505\n",
      "\tspeed: 0.0472s/iter; left time: 246.4697s\n",
      "\titers: 300, epoch: 5 | loss: 0.1253819\n",
      "\tspeed: 0.0483s/iter; left time: 247.7688s\n",
      "\titers: 400, epoch: 5 | loss: 0.1291719\n",
      "\tspeed: 0.0479s/iter; left time: 240.6349s\n",
      "\titers: 500, epoch: 5 | loss: 0.1253986\n",
      "\tspeed: 0.0488s/iter; left time: 240.5403s\n",
      "\titers: 600, epoch: 5 | loss: 0.1274677\n",
      "\tspeed: 0.0504s/iter; left time: 243.3136s\n",
      "\titers: 700, epoch: 5 | loss: 0.1198974\n",
      "\tspeed: 0.0494s/iter; left time: 233.3008s\n",
      "\titers: 800, epoch: 5 | loss: 0.1168309\n",
      "\tspeed: 0.0478s/iter; left time: 220.9980s\n",
      "\titers: 900, epoch: 5 | loss: 0.1229431\n",
      "\tspeed: 0.0477s/iter; left time: 215.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.00s\n",
      "Steps: 904 | Train Loss: 0.1276485 Vali Loss: 0.0351315 Test Loss: 0.0445958\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04103325307369232, rmse:0.20256666839122772, mae:0.1448090672492981, rse:0.7173295021057129\n",
      "Original data scale mse:36910216.0, rmse:6075.3779296875, mae:4103.126953125, rse:0.30255600810050964\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3033006\n",
      "\tspeed: 0.0527s/iter; left time: 470.7883s\n",
      "\titers: 200, epoch: 1 | loss: 0.2656540\n",
      "\tspeed: 0.0505s/iter; left time: 446.2560s\n",
      "\titers: 300, epoch: 1 | loss: 0.2539203\n",
      "\tspeed: 0.0503s/iter; left time: 440.0465s\n",
      "\titers: 400, epoch: 1 | loss: 0.2405170\n",
      "\tspeed: 0.0504s/iter; left time: 435.1958s\n",
      "\titers: 500, epoch: 1 | loss: 0.2386315\n",
      "\tspeed: 0.0504s/iter; left time: 430.8299s\n",
      "\titers: 600, epoch: 1 | loss: 0.2180775\n",
      "\tspeed: 0.0489s/iter; left time: 412.7733s\n",
      "\titers: 700, epoch: 1 | loss: 0.2443407\n",
      "\tspeed: 0.0476s/iter; left time: 396.7101s\n",
      "\titers: 800, epoch: 1 | loss: 0.2130085\n",
      "\tspeed: 0.0499s/iter; left time: 411.0398s\n",
      "\titers: 900, epoch: 1 | loss: 0.2177016\n",
      "\tspeed: 0.0504s/iter; left time: 410.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.40s\n",
      "Steps: 904 | Train Loss: 0.2510130 Vali Loss: 0.0469525 Test Loss: 0.0592683\n",
      "Validation loss decreased (inf --> 0.046953).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1928810\n",
      "\tspeed: 0.1219s/iter; left time: 979.8434s\n",
      "\titers: 200, epoch: 2 | loss: 0.1737615\n",
      "\tspeed: 0.0478s/iter; left time: 379.2192s\n",
      "\titers: 300, epoch: 2 | loss: 0.1708919\n",
      "\tspeed: 0.0477s/iter; left time: 373.5658s\n",
      "\titers: 400, epoch: 2 | loss: 0.1574111\n",
      "\tspeed: 0.0475s/iter; left time: 367.3809s\n",
      "\titers: 500, epoch: 2 | loss: 0.1583550\n",
      "\tspeed: 0.0475s/iter; left time: 362.7301s\n",
      "\titers: 600, epoch: 2 | loss: 0.1736619\n",
      "\tspeed: 0.0476s/iter; left time: 359.0177s\n",
      "\titers: 700, epoch: 2 | loss: 0.1612795\n",
      "\tspeed: 0.0476s/iter; left time: 354.1433s\n",
      "\titers: 800, epoch: 2 | loss: 0.1629753\n",
      "\tspeed: 0.0478s/iter; left time: 350.6080s\n",
      "\titers: 900, epoch: 2 | loss: 0.1445371\n",
      "\tspeed: 0.0477s/iter; left time: 344.9093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.1683245 Vali Loss: 0.0335551 Test Loss: 0.0415100\n",
      "Validation loss decreased (0.046953 --> 0.033555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1596928\n",
      "\tspeed: 0.1188s/iter; left time: 847.1477s\n",
      "\titers: 200, epoch: 3 | loss: 0.1593727\n",
      "\tspeed: 0.0474s/iter; left time: 333.1254s\n",
      "\titers: 300, epoch: 3 | loss: 0.1426084\n",
      "\tspeed: 0.0476s/iter; left time: 329.7261s\n",
      "\titers: 400, epoch: 3 | loss: 0.1490009\n",
      "\tspeed: 0.0475s/iter; left time: 324.7389s\n",
      "\titers: 500, epoch: 3 | loss: 0.1475351\n",
      "\tspeed: 0.0476s/iter; left time: 320.2214s\n",
      "\titers: 600, epoch: 3 | loss: 0.1512032\n",
      "\tspeed: 0.0474s/iter; left time: 314.5922s\n",
      "\titers: 700, epoch: 3 | loss: 0.1463389\n",
      "\tspeed: 0.0473s/iter; left time: 309.1003s\n",
      "\titers: 800, epoch: 3 | loss: 0.1608187\n",
      "\tspeed: 0.0475s/iter; left time: 305.5488s\n",
      "\titers: 900, epoch: 3 | loss: 0.1560631\n",
      "\tspeed: 0.0474s/iter; left time: 300.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.1491675 Vali Loss: 0.0331871 Test Loss: 0.0418654\n",
      "Validation loss decreased (0.033555 --> 0.033187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1472884\n",
      "\tspeed: 0.1183s/iter; left time: 737.0817s\n",
      "\titers: 200, epoch: 4 | loss: 0.1476162\n",
      "\tspeed: 0.0477s/iter; left time: 292.2439s\n",
      "\titers: 300, epoch: 4 | loss: 0.1375844\n",
      "\tspeed: 0.0474s/iter; left time: 285.6144s\n",
      "\titers: 400, epoch: 4 | loss: 0.1338737\n",
      "\tspeed: 0.0476s/iter; left time: 282.1596s\n",
      "\titers: 500, epoch: 4 | loss: 0.1385023\n",
      "\tspeed: 0.0477s/iter; left time: 277.8313s\n",
      "\titers: 600, epoch: 4 | loss: 0.1450797\n",
      "\tspeed: 0.0476s/iter; left time: 272.9438s\n",
      "\titers: 700, epoch: 4 | loss: 0.1402115\n",
      "\tspeed: 0.0477s/iter; left time: 268.4205s\n",
      "\titers: 800, epoch: 4 | loss: 0.1368200\n",
      "\tspeed: 0.0478s/iter; left time: 264.1160s\n",
      "\titers: 900, epoch: 4 | loss: 0.1321137\n",
      "\tspeed: 0.0476s/iter; left time: 258.1608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.38s\n",
      "Steps: 904 | Train Loss: 0.1401779 Vali Loss: 0.0347146 Test Loss: 0.0455525\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1162099\n",
      "\tspeed: 0.1147s/iter; left time: 610.5134s\n",
      "\titers: 200, epoch: 5 | loss: 0.1308444\n",
      "\tspeed: 0.0474s/iter; left time: 247.5895s\n",
      "\titers: 300, epoch: 5 | loss: 0.1344330\n",
      "\tspeed: 0.0474s/iter; left time: 242.6779s\n",
      "\titers: 400, epoch: 5 | loss: 0.1229379\n",
      "\tspeed: 0.0474s/iter; left time: 238.1923s\n",
      "\titers: 500, epoch: 5 | loss: 0.1343827\n",
      "\tspeed: 0.0476s/iter; left time: 234.3293s\n",
      "\titers: 600, epoch: 5 | loss: 0.1198288\n",
      "\tspeed: 0.0473s/iter; left time: 228.3916s\n",
      "\titers: 700, epoch: 5 | loss: 0.1365760\n",
      "\tspeed: 0.0475s/iter; left time: 224.5180s\n",
      "\titers: 800, epoch: 5 | loss: 0.1273134\n",
      "\tspeed: 0.0475s/iter; left time: 219.7608s\n",
      "\titers: 900, epoch: 5 | loss: 0.1240884\n",
      "\tspeed: 0.0476s/iter; left time: 215.4504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.1306954 Vali Loss: 0.0344826 Test Loss: 0.0431674\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1184841\n",
      "\tspeed: 0.1141s/iter; left time: 504.3543s\n",
      "\titers: 200, epoch: 6 | loss: 0.1300571\n",
      "\tspeed: 0.0477s/iter; left time: 206.1272s\n",
      "\titers: 300, epoch: 6 | loss: 0.1251907\n",
      "\tspeed: 0.0478s/iter; left time: 201.9175s\n",
      "\titers: 400, epoch: 6 | loss: 0.1189657\n",
      "\tspeed: 0.0477s/iter; left time: 196.7519s\n",
      "\titers: 500, epoch: 6 | loss: 0.1225212\n",
      "\tspeed: 0.0478s/iter; left time: 192.0400s\n",
      "\titers: 600, epoch: 6 | loss: 0.1154039\n",
      "\tspeed: 0.0474s/iter; left time: 186.0062s\n",
      "\titers: 700, epoch: 6 | loss: 0.1176639\n",
      "\tspeed: 0.0475s/iter; left time: 181.5044s\n",
      "\titers: 800, epoch: 6 | loss: 0.1150488\n",
      "\tspeed: 0.0474s/iter; left time: 176.3909s\n",
      "\titers: 900, epoch: 6 | loss: 0.1111033\n",
      "\tspeed: 0.0476s/iter; left time: 172.2562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.1199580 Vali Loss: 0.0392481 Test Loss: 0.0465440\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04188527911901474, rmse:0.20465894043445587, mae:0.1424560695886612, rse:0.7247387170791626\n",
      "Original data scale mse:38137348.0, rmse:6175.54443359375, mae:4037.75927734375, rse:0.3075443208217621\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2926495\n",
      "\tspeed: 0.0844s/iter; left time: 752.9933s\n",
      "\titers: 200, epoch: 1 | loss: 0.2759382\n",
      "\tspeed: 0.0537s/iter; left time: 473.6639s\n",
      "\titers: 300, epoch: 1 | loss: 0.2516454\n",
      "\tspeed: 0.0535s/iter; left time: 466.1599s\n",
      "\titers: 400, epoch: 1 | loss: 0.2446894\n",
      "\tspeed: 0.0535s/iter; left time: 460.8136s\n",
      "\titers: 500, epoch: 1 | loss: 0.2390247\n",
      "\tspeed: 0.0537s/iter; left time: 457.8701s\n",
      "\titers: 600, epoch: 1 | loss: 0.2378901\n",
      "\tspeed: 0.0536s/iter; left time: 451.6392s\n",
      "\titers: 700, epoch: 1 | loss: 0.2287076\n",
      "\tspeed: 0.0534s/iter; left time: 443.9600s\n",
      "\titers: 800, epoch: 1 | loss: 0.2237932\n",
      "\tspeed: 0.0537s/iter; left time: 441.7604s\n",
      "\titers: 900, epoch: 1 | loss: 0.2274978\n",
      "\tspeed: 0.0538s/iter; left time: 436.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.25s\n",
      "Steps: 902 | Train Loss: 0.2537300 Vali Loss: 0.0554739 Test Loss: 0.0720860\n",
      "Validation loss decreased (inf --> 0.055474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2111945\n",
      "\tspeed: 0.1353s/iter; left time: 1084.8407s\n",
      "\titers: 200, epoch: 2 | loss: 0.1888788\n",
      "\tspeed: 0.0537s/iter; left time: 425.4315s\n",
      "\titers: 300, epoch: 2 | loss: 0.2003660\n",
      "\tspeed: 0.0539s/iter; left time: 421.1136s\n",
      "\titers: 400, epoch: 2 | loss: 0.1833679\n",
      "\tspeed: 0.0537s/iter; left time: 414.7454s\n",
      "\titers: 500, epoch: 2 | loss: 0.1778117\n",
      "\tspeed: 0.0540s/iter; left time: 411.5908s\n",
      "\titers: 600, epoch: 2 | loss: 0.1675996\n",
      "\tspeed: 0.0539s/iter; left time: 404.9248s\n",
      "\titers: 700, epoch: 2 | loss: 0.1670957\n",
      "\tspeed: 0.0539s/iter; left time: 400.2321s\n",
      "\titers: 800, epoch: 2 | loss: 0.1790987\n",
      "\tspeed: 0.0535s/iter; left time: 391.3275s\n",
      "\titers: 900, epoch: 2 | loss: 0.1498518\n",
      "\tspeed: 0.0540s/iter; left time: 390.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.85s\n",
      "Steps: 902 | Train Loss: 0.1816401 Vali Loss: 0.0353314 Test Loss: 0.0436157\n",
      "Validation loss decreased (0.055474 --> 0.035331).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1658780\n",
      "\tspeed: 0.1365s/iter; left time: 971.7080s\n",
      "\titers: 200, epoch: 3 | loss: 0.1539436\n",
      "\tspeed: 0.0539s/iter; left time: 378.1427s\n",
      "\titers: 300, epoch: 3 | loss: 0.1573724\n",
      "\tspeed: 0.0538s/iter; left time: 372.1556s\n",
      "\titers: 400, epoch: 3 | loss: 0.1706105\n",
      "\tspeed: 0.0538s/iter; left time: 366.8453s\n",
      "\titers: 500, epoch: 3 | loss: 0.1472732\n",
      "\tspeed: 0.0539s/iter; left time: 362.1113s\n",
      "\titers: 600, epoch: 3 | loss: 0.1535669\n",
      "\tspeed: 0.0537s/iter; left time: 355.3648s\n",
      "\titers: 700, epoch: 3 | loss: 0.1553864\n",
      "\tspeed: 0.0538s/iter; left time: 350.4386s\n",
      "\titers: 800, epoch: 3 | loss: 0.1544610\n",
      "\tspeed: 0.0537s/iter; left time: 344.8392s\n",
      "\titers: 900, epoch: 3 | loss: 0.1476951\n",
      "\tspeed: 0.0539s/iter; left time: 340.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 902 | Train Loss: 0.1532935 Vali Loss: 0.0348557 Test Loss: 0.0415470\n",
      "Validation loss decreased (0.035331 --> 0.034856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1365672\n",
      "\tspeed: 0.1353s/iter; left time: 841.1260s\n",
      "\titers: 200, epoch: 4 | loss: 0.1337031\n",
      "\tspeed: 0.0539s/iter; left time: 329.4726s\n",
      "\titers: 300, epoch: 4 | loss: 0.1502062\n",
      "\tspeed: 0.0538s/iter; left time: 323.8578s\n",
      "\titers: 400, epoch: 4 | loss: 0.1468889\n",
      "\tspeed: 0.0537s/iter; left time: 317.3534s\n",
      "\titers: 500, epoch: 4 | loss: 0.1529484\n",
      "\tspeed: 0.0536s/iter; left time: 311.9329s\n",
      "\titers: 600, epoch: 4 | loss: 0.1329334\n",
      "\tspeed: 0.0538s/iter; left time: 307.2036s\n",
      "\titers: 700, epoch: 4 | loss: 0.1536939\n",
      "\tspeed: 0.0537s/iter; left time: 301.5138s\n",
      "\titers: 800, epoch: 4 | loss: 0.1441478\n",
      "\tspeed: 0.0537s/iter; left time: 296.1831s\n",
      "\titers: 900, epoch: 4 | loss: 0.1344999\n",
      "\tspeed: 0.0536s/iter; left time: 290.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.1418212 Vali Loss: 0.0379184 Test Loss: 0.0469089\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1399765\n",
      "\tspeed: 0.1319s/iter; left time: 700.6899s\n",
      "\titers: 200, epoch: 5 | loss: 0.1334775\n",
      "\tspeed: 0.0536s/iter; left time: 279.6502s\n",
      "\titers: 300, epoch: 5 | loss: 0.1285665\n",
      "\tspeed: 0.0539s/iter; left time: 275.7352s\n",
      "\titers: 400, epoch: 5 | loss: 0.1392056\n",
      "\tspeed: 0.0539s/iter; left time: 270.3621s\n",
      "\titers: 500, epoch: 5 | loss: 0.1215379\n",
      "\tspeed: 0.0539s/iter; left time: 264.9537s\n",
      "\titers: 600, epoch: 5 | loss: 0.1303193\n",
      "\tspeed: 0.0537s/iter; left time: 258.3738s\n",
      "\titers: 700, epoch: 5 | loss: 0.1267691\n",
      "\tspeed: 0.0538s/iter; left time: 253.5886s\n",
      "\titers: 800, epoch: 5 | loss: 0.1245160\n",
      "\tspeed: 0.0538s/iter; left time: 248.0065s\n",
      "\titers: 900, epoch: 5 | loss: 0.1172705\n",
      "\tspeed: 0.0536s/iter; left time: 242.0793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.1298998 Vali Loss: 0.0396953 Test Loss: 0.0485864\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1218988\n",
      "\tspeed: 0.1316s/iter; left time: 580.3267s\n",
      "\titers: 200, epoch: 6 | loss: 0.1267436\n",
      "\tspeed: 0.0538s/iter; left time: 231.9743s\n",
      "\titers: 300, epoch: 6 | loss: 0.1143450\n",
      "\tspeed: 0.0537s/iter; left time: 226.0899s\n",
      "\titers: 400, epoch: 6 | loss: 0.1284699\n",
      "\tspeed: 0.0538s/iter; left time: 221.1135s\n",
      "\titers: 500, epoch: 6 | loss: 0.1149280\n",
      "\tspeed: 0.0537s/iter; left time: 215.3660s\n",
      "\titers: 600, epoch: 6 | loss: 0.1126125\n",
      "\tspeed: 0.0537s/iter; left time: 209.8899s\n",
      "\titers: 700, epoch: 6 | loss: 0.1189998\n",
      "\tspeed: 0.0536s/iter; left time: 204.4408s\n",
      "\titers: 800, epoch: 6 | loss: 0.1114934\n",
      "\tspeed: 0.0536s/iter; left time: 198.7814s\n",
      "\titers: 900, epoch: 6 | loss: 0.1228147\n",
      "\tspeed: 0.0535s/iter; left time: 193.1487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1195825 Vali Loss: 0.0401932 Test Loss: 0.0509725\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.041561320424079895, rmse:0.2038659304380417, mae:0.14510895311832428, rse:0.7222356200218201\n",
      "Original data scale mse:38455032.0, rmse:6201.2119140625, mae:4132.53271484375, rse:0.30897417664527893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3113247\n",
      "\tspeed: 0.0565s/iter; left time: 503.7476s\n",
      "\titers: 200, epoch: 1 | loss: 0.2668369\n",
      "\tspeed: 0.0538s/iter; left time: 474.3546s\n",
      "\titers: 300, epoch: 1 | loss: 0.2556839\n",
      "\tspeed: 0.0538s/iter; left time: 469.0089s\n",
      "\titers: 400, epoch: 1 | loss: 0.2252100\n",
      "\tspeed: 0.0537s/iter; left time: 462.8217s\n",
      "\titers: 500, epoch: 1 | loss: 0.2424131\n",
      "\tspeed: 0.0538s/iter; left time: 458.7640s\n",
      "\titers: 600, epoch: 1 | loss: 0.2288676\n",
      "\tspeed: 0.0538s/iter; left time: 452.6889s\n",
      "\titers: 700, epoch: 1 | loss: 0.2255107\n",
      "\tspeed: 0.0538s/iter; left time: 447.3104s\n",
      "\titers: 800, epoch: 1 | loss: 0.2196986\n",
      "\tspeed: 0.0538s/iter; left time: 441.8829s\n",
      "\titers: 900, epoch: 1 | loss: 0.2234770\n",
      "\tspeed: 0.0536s/iter; left time: 435.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 902 | Train Loss: 0.2539692 Vali Loss: 0.0544385 Test Loss: 0.0711512\n",
      "Validation loss decreased (inf --> 0.054439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2002301\n",
      "\tspeed: 0.1369s/iter; left time: 1097.6334s\n",
      "\titers: 200, epoch: 2 | loss: 0.1902201\n",
      "\tspeed: 0.0537s/iter; left time: 425.2088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1814798\n",
      "\tspeed: 0.0540s/iter; left time: 422.1479s\n",
      "\titers: 400, epoch: 2 | loss: 0.1707954\n",
      "\tspeed: 0.0538s/iter; left time: 415.3305s\n",
      "\titers: 500, epoch: 2 | loss: 0.1734090\n",
      "\tspeed: 0.0538s/iter; left time: 410.2490s\n",
      "\titers: 600, epoch: 2 | loss: 0.1803765\n",
      "\tspeed: 0.0535s/iter; left time: 402.3966s\n",
      "\titers: 700, epoch: 2 | loss: 0.1676639\n",
      "\tspeed: 0.0535s/iter; left time: 396.9880s\n",
      "\titers: 800, epoch: 2 | loss: 0.1515651\n",
      "\tspeed: 0.0538s/iter; left time: 393.6638s\n",
      "\titers: 900, epoch: 2 | loss: 0.1576114\n",
      "\tspeed: 0.0538s/iter; left time: 388.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.1831233 Vali Loss: 0.0411337 Test Loss: 0.0487919\n",
      "Validation loss decreased (0.054439 --> 0.041134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1539670\n",
      "\tspeed: 0.1363s/iter; left time: 969.7555s\n",
      "\titers: 200, epoch: 3 | loss: 0.1628677\n",
      "\tspeed: 0.0538s/iter; left time: 377.4586s\n",
      "\titers: 300, epoch: 3 | loss: 0.1688538\n",
      "\tspeed: 0.0536s/iter; left time: 370.9110s\n",
      "\titers: 400, epoch: 3 | loss: 0.1600339\n",
      "\tspeed: 0.0537s/iter; left time: 365.7726s\n",
      "\titers: 500, epoch: 3 | loss: 0.1580702\n",
      "\tspeed: 0.0537s/iter; left time: 360.7385s\n",
      "\titers: 600, epoch: 3 | loss: 0.1543265\n",
      "\tspeed: 0.0537s/iter; left time: 355.4255s\n",
      "\titers: 700, epoch: 3 | loss: 0.1496884\n",
      "\tspeed: 0.0537s/iter; left time: 349.7671s\n",
      "\titers: 800, epoch: 3 | loss: 0.1444830\n",
      "\tspeed: 0.0535s/iter; left time: 343.5058s\n",
      "\titers: 900, epoch: 3 | loss: 0.1467203\n",
      "\tspeed: 0.0535s/iter; left time: 338.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.1542953 Vali Loss: 0.0354638 Test Loss: 0.0431497\n",
      "Validation loss decreased (0.041134 --> 0.035464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1480040\n",
      "\tspeed: 0.1360s/iter; left time: 845.5179s\n",
      "\titers: 200, epoch: 4 | loss: 0.1369039\n",
      "\tspeed: 0.0538s/iter; left time: 329.0979s\n",
      "\titers: 300, epoch: 4 | loss: 0.1432847\n",
      "\tspeed: 0.0537s/iter; left time: 323.1930s\n",
      "\titers: 400, epoch: 4 | loss: 0.1397676\n",
      "\tspeed: 0.0539s/iter; left time: 318.6197s\n",
      "\titers: 500, epoch: 4 | loss: 0.1429798\n",
      "\tspeed: 0.0538s/iter; left time: 312.9058s\n",
      "\titers: 600, epoch: 4 | loss: 0.1483091\n",
      "\tspeed: 0.0537s/iter; left time: 306.9805s\n",
      "\titers: 700, epoch: 4 | loss: 0.1336518\n",
      "\tspeed: 0.0537s/iter; left time: 301.6189s\n",
      "\titers: 800, epoch: 4 | loss: 0.1385359\n",
      "\tspeed: 0.0537s/iter; left time: 296.0877s\n",
      "\titers: 900, epoch: 4 | loss: 0.1367240\n",
      "\tspeed: 0.0538s/iter; left time: 291.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.1427702 Vali Loss: 0.0372985 Test Loss: 0.0459323\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1259555\n",
      "\tspeed: 0.1322s/iter; left time: 702.3514s\n",
      "\titers: 200, epoch: 5 | loss: 0.1316517\n",
      "\tspeed: 0.0538s/iter; left time: 280.3851s\n",
      "\titers: 300, epoch: 5 | loss: 0.1307634\n",
      "\tspeed: 0.0539s/iter; left time: 275.3648s\n",
      "\titers: 400, epoch: 5 | loss: 0.1369316\n",
      "\tspeed: 0.0537s/iter; left time: 269.0117s\n",
      "\titers: 500, epoch: 5 | loss: 0.1391668\n",
      "\tspeed: 0.0539s/iter; left time: 265.0516s\n",
      "\titers: 600, epoch: 5 | loss: 0.1236826\n",
      "\tspeed: 0.0534s/iter; left time: 257.1278s\n",
      "\titers: 700, epoch: 5 | loss: 0.1305160\n",
      "\tspeed: 0.0537s/iter; left time: 253.1924s\n",
      "\titers: 800, epoch: 5 | loss: 0.1278001\n",
      "\tspeed: 0.0539s/iter; left time: 248.4260s\n",
      "\titers: 900, epoch: 5 | loss: 0.1261872\n",
      "\tspeed: 0.0539s/iter; left time: 243.1384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.1319320 Vali Loss: 0.0381629 Test Loss: 0.0498999\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1268972\n",
      "\tspeed: 0.1317s/iter; left time: 580.8704s\n",
      "\titers: 200, epoch: 6 | loss: 0.1211389\n",
      "\tspeed: 0.0538s/iter; left time: 231.7858s\n",
      "\titers: 300, epoch: 6 | loss: 0.1249150\n",
      "\tspeed: 0.0537s/iter; left time: 226.0132s\n",
      "\titers: 400, epoch: 6 | loss: 0.1167591\n",
      "\tspeed: 0.0537s/iter; left time: 220.7569s\n",
      "\titers: 500, epoch: 6 | loss: 0.1198143\n",
      "\tspeed: 0.0538s/iter; left time: 215.8014s\n",
      "\titers: 600, epoch: 6 | loss: 0.1263515\n",
      "\tspeed: 0.0538s/iter; left time: 210.3897s\n",
      "\titers: 700, epoch: 6 | loss: 0.1237719\n",
      "\tspeed: 0.0535s/iter; left time: 203.9407s\n",
      "\titers: 800, epoch: 6 | loss: 0.1125178\n",
      "\tspeed: 0.0535s/iter; left time: 198.5471s\n",
      "\titers: 900, epoch: 6 | loss: 0.1126838\n",
      "\tspeed: 0.0537s/iter; left time: 193.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1220499 Vali Loss: 0.0388611 Test Loss: 0.0490557\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04315508157014847, rmse:0.2077380120754242, mae:0.1485593318939209, rse:0.7359532117843628\n",
      "Original data scale mse:40330176.0, rmse:6350.6044921875, mae:4271.23583984375, rse:0.3164176046848297\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2242578\n",
      "\tspeed: 0.0725s/iter; left time: 650.0106s\n",
      "\titers: 200, epoch: 1 | loss: 0.1898357\n",
      "\tspeed: 0.0420s/iter; left time: 371.7293s\n",
      "\titers: 300, epoch: 1 | loss: 0.1789733\n",
      "\tspeed: 0.0412s/iter; left time: 360.7032s\n",
      "\titers: 400, epoch: 1 | loss: 0.1563358\n",
      "\tspeed: 0.0408s/iter; left time: 353.5666s\n",
      "\titers: 500, epoch: 1 | loss: 0.1528879\n",
      "\tspeed: 0.0447s/iter; left time: 382.2834s\n",
      "\titers: 600, epoch: 1 | loss: 0.1442027\n",
      "\tspeed: 0.0453s/iter; left time: 383.4218s\n",
      "\titers: 700, epoch: 1 | loss: 0.1612527\n",
      "\tspeed: 0.0454s/iter; left time: 379.8701s\n",
      "\titers: 800, epoch: 1 | loss: 0.1469584\n",
      "\tspeed: 0.0455s/iter; left time: 375.9019s\n",
      "\titers: 900, epoch: 1 | loss: 0.1317047\n",
      "\tspeed: 0.0457s/iter; left time: 373.2978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.29s\n",
      "Steps: 906 | Train Loss: 0.1751491 Vali Loss: 0.1478380 Test Loss: 0.1567377\n",
      "Validation loss decreased (inf --> 0.147838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1182877\n",
      "\tspeed: 0.1023s/iter; left time: 823.8732s\n",
      "\titers: 200, epoch: 2 | loss: 0.1345648\n",
      "\tspeed: 0.0458s/iter; left time: 364.6610s\n",
      "\titers: 300, epoch: 2 | loss: 0.1065895\n",
      "\tspeed: 0.0460s/iter; left time: 361.2539s\n",
      "\titers: 400, epoch: 2 | loss: 0.0933015\n",
      "\tspeed: 0.0459s/iter; left time: 356.1907s\n",
      "\titers: 500, epoch: 2 | loss: 0.0904975\n",
      "\tspeed: 0.0462s/iter; left time: 353.6962s\n",
      "\titers: 600, epoch: 2 | loss: 0.0893114\n",
      "\tspeed: 0.0461s/iter; left time: 348.4494s\n",
      "\titers: 700, epoch: 2 | loss: 0.0859625\n",
      "\tspeed: 0.0455s/iter; left time: 339.1846s\n",
      "\titers: 800, epoch: 2 | loss: 0.1043300\n",
      "\tspeed: 0.0463s/iter; left time: 340.3797s\n",
      "\titers: 900, epoch: 2 | loss: 0.0872503\n",
      "\tspeed: 0.0461s/iter; left time: 334.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 906 | Train Loss: 0.1040518 Vali Loss: 0.0984693 Test Loss: 0.1067379\n",
      "Validation loss decreased (0.147838 --> 0.098469).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818719\n",
      "\tspeed: 0.1072s/iter; left time: 766.3893s\n",
      "\titers: 200, epoch: 3 | loss: 0.0733229\n",
      "\tspeed: 0.0467s/iter; left time: 329.2906s\n",
      "\titers: 300, epoch: 3 | loss: 0.0786101\n",
      "\tspeed: 0.0463s/iter; left time: 321.9820s\n",
      "\titers: 400, epoch: 3 | loss: 0.0841790\n",
      "\tspeed: 0.0463s/iter; left time: 317.4203s\n",
      "\titers: 500, epoch: 3 | loss: 0.0886876\n",
      "\tspeed: 0.0462s/iter; left time: 311.7402s\n",
      "\titers: 600, epoch: 3 | loss: 0.0879167\n",
      "\tspeed: 0.0456s/iter; left time: 303.1527s\n",
      "\titers: 700, epoch: 3 | loss: 0.0797993\n",
      "\tspeed: 0.0467s/iter; left time: 305.9932s\n",
      "\titers: 800, epoch: 3 | loss: 0.0734361\n",
      "\tspeed: 0.0458s/iter; left time: 295.1245s\n",
      "\titers: 900, epoch: 3 | loss: 0.0759469\n",
      "\tspeed: 0.0463s/iter; left time: 293.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.19s\n",
      "Steps: 906 | Train Loss: 0.0804971 Vali Loss: 0.0948412 Test Loss: 0.0987356\n",
      "Validation loss decreased (0.098469 --> 0.094841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0642318\n",
      "\tspeed: 0.1045s/iter; left time: 652.3535s\n",
      "\titers: 200, epoch: 4 | loss: 0.0718670\n",
      "\tspeed: 0.0461s/iter; left time: 283.1297s\n",
      "\titers: 300, epoch: 4 | loss: 0.0737519\n",
      "\tspeed: 0.0461s/iter; left time: 278.3082s\n",
      "\titers: 400, epoch: 4 | loss: 0.0626771\n",
      "\tspeed: 0.0463s/iter; left time: 275.3659s\n",
      "\titers: 500, epoch: 4 | loss: 0.0802833\n",
      "\tspeed: 0.0459s/iter; left time: 267.9427s\n",
      "\titers: 600, epoch: 4 | loss: 0.0729032\n",
      "\tspeed: 0.0462s/iter; left time: 265.2842s\n",
      "\titers: 700, epoch: 4 | loss: 0.0714076\n",
      "\tspeed: 0.0459s/iter; left time: 258.9103s\n",
      "\titers: 800, epoch: 4 | loss: 0.0793254\n",
      "\tspeed: 0.0448s/iter; left time: 248.2672s\n",
      "\titers: 900, epoch: 4 | loss: 0.0715816\n",
      "\tspeed: 0.0457s/iter; left time: 248.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 906 | Train Loss: 0.0747579 Vali Loss: 0.0942132 Test Loss: 0.0991149\n",
      "Validation loss decreased (0.094841 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734457\n",
      "\tspeed: 0.1062s/iter; left time: 566.7797s\n",
      "\titers: 200, epoch: 5 | loss: 0.0635436\n",
      "\tspeed: 0.0455s/iter; left time: 238.0296s\n",
      "\titers: 300, epoch: 5 | loss: 0.0630266\n",
      "\tspeed: 0.0453s/iter; left time: 232.6167s\n",
      "\titers: 400, epoch: 5 | loss: 0.0745912\n",
      "\tspeed: 0.0454s/iter; left time: 228.4972s\n",
      "\titers: 500, epoch: 5 | loss: 0.0656142\n",
      "\tspeed: 0.0458s/iter; left time: 226.3559s\n",
      "\titers: 600, epoch: 5 | loss: 0.0726853\n",
      "\tspeed: 0.0447s/iter; left time: 216.2456s\n",
      "\titers: 700, epoch: 5 | loss: 0.0620390\n",
      "\tspeed: 0.0447s/iter; left time: 211.5371s\n",
      "\titers: 800, epoch: 5 | loss: 0.0712027\n",
      "\tspeed: 0.0456s/iter; left time: 211.4913s\n",
      "\titers: 900, epoch: 5 | loss: 0.0770849\n",
      "\tspeed: 0.0448s/iter; left time: 203.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.29s\n",
      "Steps: 906 | Train Loss: 0.0701890 Vali Loss: 0.0943323 Test Loss: 0.1031515\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0754840\n",
      "\tspeed: 0.1005s/iter; left time: 445.1818s\n",
      "\titers: 200, epoch: 6 | loss: 0.0691707\n",
      "\tspeed: 0.0446s/iter; left time: 192.9565s\n",
      "\titers: 300, epoch: 6 | loss: 0.0682686\n",
      "\tspeed: 0.0414s/iter; left time: 174.9972s\n",
      "\titers: 400, epoch: 6 | loss: 0.0671632\n",
      "\tspeed: 0.0418s/iter; left time: 172.5815s\n",
      "\titers: 500, epoch: 6 | loss: 0.0660435\n",
      "\tspeed: 0.0409s/iter; left time: 164.9983s\n",
      "\titers: 600, epoch: 6 | loss: 0.0615367\n",
      "\tspeed: 0.0411s/iter; left time: 161.7411s\n",
      "\titers: 700, epoch: 6 | loss: 0.0730367\n",
      "\tspeed: 0.0413s/iter; left time: 158.3831s\n",
      "\titers: 800, epoch: 6 | loss: 0.0604000\n",
      "\tspeed: 0.0409s/iter; left time: 152.5891s\n",
      "\titers: 900, epoch: 6 | loss: 0.0591007\n",
      "\tspeed: 0.0412s/iter; left time: 149.4527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.0658827 Vali Loss: 0.0926875 Test Loss: 0.1001576\n",
      "Validation loss decreased (0.094213 --> 0.092688).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595968\n",
      "\tspeed: 0.1023s/iter; left time: 360.4638s\n",
      "\titers: 200, epoch: 7 | loss: 0.0638212\n",
      "\tspeed: 0.0419s/iter; left time: 143.6088s\n",
      "\titers: 300, epoch: 7 | loss: 0.0653568\n",
      "\tspeed: 0.0416s/iter; left time: 138.2431s\n",
      "\titers: 400, epoch: 7 | loss: 0.0698452\n",
      "\tspeed: 0.0421s/iter; left time: 135.8982s\n",
      "\titers: 500, epoch: 7 | loss: 0.0636178\n",
      "\tspeed: 0.0425s/iter; left time: 132.8777s\n",
      "\titers: 600, epoch: 7 | loss: 0.0604861\n",
      "\tspeed: 0.0422s/iter; left time: 127.7809s\n",
      "\titers: 700, epoch: 7 | loss: 0.0573631\n",
      "\tspeed: 0.0424s/iter; left time: 123.9554s\n",
      "\titers: 800, epoch: 7 | loss: 0.0619043\n",
      "\tspeed: 0.0409s/iter; left time: 115.6549s\n",
      "\titers: 900, epoch: 7 | loss: 0.0663653\n",
      "\tspeed: 0.0415s/iter; left time: 112.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 906 | Train Loss: 0.0620958 Vali Loss: 0.0929043 Test Loss: 0.1012591\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0586540\n",
      "\tspeed: 0.0959s/iter; left time: 251.1811s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570356\n",
      "\tspeed: 0.0420s/iter; left time: 105.7774s\n",
      "\titers: 300, epoch: 8 | loss: 0.0614286\n",
      "\tspeed: 0.0414s/iter; left time: 100.2437s\n",
      "\titers: 400, epoch: 8 | loss: 0.0557369\n",
      "\tspeed: 0.0418s/iter; left time: 96.9505s\n",
      "\titers: 500, epoch: 8 | loss: 0.0580302\n",
      "\tspeed: 0.0415s/iter; left time: 91.9913s\n",
      "\titers: 600, epoch: 8 | loss: 0.0533425\n",
      "\tspeed: 0.0413s/iter; left time: 87.5763s\n",
      "\titers: 700, epoch: 8 | loss: 0.0671045\n",
      "\tspeed: 0.0416s/iter; left time: 84.0866s\n",
      "\titers: 800, epoch: 8 | loss: 0.0617950\n",
      "\tspeed: 0.0413s/iter; left time: 79.3067s\n",
      "\titers: 900, epoch: 8 | loss: 0.0624347\n",
      "\tspeed: 0.0416s/iter; left time: 75.6381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 906 | Train Loss: 0.0588377 Vali Loss: 0.0950490 Test Loss: 0.1016366\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547856\n",
      "\tspeed: 0.0960s/iter; left time: 164.4069s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544514\n",
      "\tspeed: 0.0415s/iter; left time: 66.9476s\n",
      "\titers: 300, epoch: 9 | loss: 0.0549416\n",
      "\tspeed: 0.0416s/iter; left time: 62.9729s\n",
      "\titers: 400, epoch: 9 | loss: 0.0452026\n",
      "\tspeed: 0.0412s/iter; left time: 58.2491s\n",
      "\titers: 500, epoch: 9 | loss: 0.0623649\n",
      "\tspeed: 0.0409s/iter; left time: 53.6435s\n",
      "\titers: 600, epoch: 9 | loss: 0.0527327\n",
      "\tspeed: 0.0408s/iter; left time: 49.4744s\n",
      "\titers: 700, epoch: 9 | loss: 0.0464450\n",
      "\tspeed: 0.0410s/iter; left time: 45.6056s\n",
      "\titers: 800, epoch: 9 | loss: 0.0578498\n",
      "\tspeed: 0.0413s/iter; left time: 41.8026s\n",
      "\titers: 900, epoch: 9 | loss: 0.0538073\n",
      "\tspeed: 0.0411s/iter; left time: 37.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.60s\n",
      "Steps: 906 | Train Loss: 0.0553605 Vali Loss: 0.0962622 Test Loss: 0.1036498\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02428990602493286, rmse:0.15585219860076904, mae:0.10028143227100372, rse:0.5503962635993958\n",
      "Original data scale mse:21054224.0, rmse:4588.48828125, mae:2843.177734375, rse:0.22814887762069702\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2398754\n",
      "\tspeed: 0.0435s/iter; left time: 389.8503s\n",
      "\titers: 200, epoch: 1 | loss: 0.1856430\n",
      "\tspeed: 0.0404s/iter; left time: 357.9499s\n",
      "\titers: 300, epoch: 1 | loss: 0.1713152\n",
      "\tspeed: 0.0413s/iter; left time: 362.2326s\n",
      "\titers: 400, epoch: 1 | loss: 0.1687666\n",
      "\tspeed: 0.0408s/iter; left time: 353.7627s\n",
      "\titers: 500, epoch: 1 | loss: 0.1446649\n",
      "\tspeed: 0.0412s/iter; left time: 352.8009s\n",
      "\titers: 600, epoch: 1 | loss: 0.1513872\n",
      "\tspeed: 0.0414s/iter; left time: 350.3684s\n",
      "\titers: 700, epoch: 1 | loss: 0.1499691\n",
      "\tspeed: 0.0418s/iter; left time: 349.8712s\n",
      "\titers: 800, epoch: 1 | loss: 0.1507011\n",
      "\tspeed: 0.0412s/iter; left time: 340.0420s\n",
      "\titers: 900, epoch: 1 | loss: 0.1491221\n",
      "\tspeed: 0.0408s/iter; left time: 333.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.60s\n",
      "Steps: 906 | Train Loss: 0.1721454 Vali Loss: 0.1453274 Test Loss: 0.1554676\n",
      "Validation loss decreased (inf --> 0.145327).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1367854\n",
      "\tspeed: 0.1040s/iter; left time: 837.3232s\n",
      "\titers: 200, epoch: 2 | loss: 0.1436689\n",
      "\tspeed: 0.0423s/iter; left time: 336.6013s\n",
      "\titers: 300, epoch: 2 | loss: 0.1178042\n",
      "\tspeed: 0.0423s/iter; left time: 331.9771s\n",
      "\titers: 400, epoch: 2 | loss: 0.1216650\n",
      "\tspeed: 0.0427s/iter; left time: 331.1619s\n",
      "\titers: 500, epoch: 2 | loss: 0.1117384\n",
      "\tspeed: 0.0422s/iter; left time: 323.2580s\n",
      "\titers: 600, epoch: 2 | loss: 0.1006765\n",
      "\tspeed: 0.0421s/iter; left time: 318.3355s\n",
      "\titers: 700, epoch: 2 | loss: 0.1048252\n",
      "\tspeed: 0.0423s/iter; left time: 315.0200s\n",
      "\titers: 800, epoch: 2 | loss: 0.1010501\n",
      "\tspeed: 0.0414s/iter; left time: 304.5439s\n",
      "\titers: 900, epoch: 2 | loss: 0.0956941\n",
      "\tspeed: 0.0420s/iter; left time: 304.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 906 | Train Loss: 0.1168003 Vali Loss: 0.1239653 Test Loss: 0.1346233\n",
      "Validation loss decreased (0.145327 --> 0.123965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1117251\n",
      "\tspeed: 0.1039s/iter; left time: 742.6213s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945623\n",
      "\tspeed: 0.0424s/iter; left time: 298.5649s\n",
      "\titers: 300, epoch: 3 | loss: 0.1088686\n",
      "\tspeed: 0.0422s/iter; left time: 292.9194s\n",
      "\titers: 400, epoch: 3 | loss: 0.1032642\n",
      "\tspeed: 0.0418s/iter; left time: 286.3089s\n",
      "\titers: 500, epoch: 3 | loss: 0.1057146\n",
      "\tspeed: 0.0418s/iter; left time: 282.1651s\n",
      "\titers: 600, epoch: 3 | loss: 0.1101636\n",
      "\tspeed: 0.0422s/iter; left time: 280.7591s\n",
      "\titers: 700, epoch: 3 | loss: 0.0980100\n",
      "\tspeed: 0.0419s/iter; left time: 274.4427s\n",
      "\titers: 800, epoch: 3 | loss: 0.0908421\n",
      "\tspeed: 0.0419s/iter; left time: 270.3413s\n",
      "\titers: 900, epoch: 3 | loss: 0.0937770\n",
      "\tspeed: 0.0417s/iter; left time: 264.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 906 | Train Loss: 0.0995902 Vali Loss: 0.1212749 Test Loss: 0.1346379\n",
      "Validation loss decreased (0.123965 --> 0.121275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892682\n",
      "\tspeed: 0.1009s/iter; left time: 630.1567s\n",
      "\titers: 200, epoch: 4 | loss: 0.0957315\n",
      "\tspeed: 0.0426s/iter; left time: 261.7159s\n",
      "\titers: 300, epoch: 4 | loss: 0.1004061\n",
      "\tspeed: 0.0429s/iter; left time: 259.0213s\n",
      "\titers: 400, epoch: 4 | loss: 0.0986237\n",
      "\tspeed: 0.0433s/iter; left time: 257.3565s\n",
      "\titers: 500, epoch: 4 | loss: 0.1025814\n",
      "\tspeed: 0.0426s/iter; left time: 248.6978s\n",
      "\titers: 600, epoch: 4 | loss: 0.0974615\n",
      "\tspeed: 0.0427s/iter; left time: 245.4352s\n",
      "\titers: 700, epoch: 4 | loss: 0.0962705\n",
      "\tspeed: 0.0432s/iter; left time: 243.5245s\n",
      "\titers: 800, epoch: 4 | loss: 0.1142599\n",
      "\tspeed: 0.0426s/iter; left time: 236.2723s\n",
      "\titers: 900, epoch: 4 | loss: 0.1030049\n",
      "\tspeed: 0.0429s/iter; left time: 233.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.09s\n",
      "Steps: 906 | Train Loss: 0.0947139 Vali Loss: 0.1200141 Test Loss: 0.1341392\n",
      "Validation loss decreased (0.121275 --> 0.120014).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791858\n",
      "\tspeed: 0.1046s/iter; left time: 558.0106s\n",
      "\titers: 200, epoch: 5 | loss: 0.0867286\n",
      "\tspeed: 0.0458s/iter; left time: 239.7717s\n",
      "\titers: 300, epoch: 5 | loss: 0.0983167\n",
      "\tspeed: 0.0454s/iter; left time: 233.0174s\n",
      "\titers: 400, epoch: 5 | loss: 0.0940453\n",
      "\tspeed: 0.0449s/iter; left time: 226.3567s\n",
      "\titers: 500, epoch: 5 | loss: 0.0883916\n",
      "\tspeed: 0.0455s/iter; left time: 224.8256s\n",
      "\titers: 600, epoch: 5 | loss: 0.0810032\n",
      "\tspeed: 0.0454s/iter; left time: 219.4685s\n",
      "\titers: 700, epoch: 5 | loss: 0.0885094\n",
      "\tspeed: 0.0458s/iter; left time: 216.7408s\n",
      "\titers: 800, epoch: 5 | loss: 0.0834468\n",
      "\tspeed: 0.0455s/iter; left time: 210.8197s\n",
      "\titers: 900, epoch: 5 | loss: 0.0845016\n",
      "\tspeed: 0.0450s/iter; left time: 204.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.43s\n",
      "Steps: 906 | Train Loss: 0.0901976 Vali Loss: 0.1183101 Test Loss: 0.1362442\n",
      "Validation loss decreased (0.120014 --> 0.118310).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904852\n",
      "\tspeed: 0.1026s/iter; left time: 454.4632s\n",
      "\titers: 200, epoch: 6 | loss: 0.0860661\n",
      "\tspeed: 0.0427s/iter; left time: 185.1467s\n",
      "\titers: 300, epoch: 6 | loss: 0.0953179\n",
      "\tspeed: 0.0423s/iter; left time: 178.9851s\n",
      "\titers: 400, epoch: 6 | loss: 0.0882991\n",
      "\tspeed: 0.0427s/iter; left time: 176.2718s\n",
      "\titers: 500, epoch: 6 | loss: 0.0900472\n",
      "\tspeed: 0.0425s/iter; left time: 171.3693s\n",
      "\titers: 600, epoch: 6 | loss: 0.0927474\n",
      "\tspeed: 0.0418s/iter; left time: 164.1588s\n",
      "\titers: 700, epoch: 6 | loss: 0.0931357\n",
      "\tspeed: 0.0424s/iter; left time: 162.2969s\n",
      "\titers: 800, epoch: 6 | loss: 0.0883807\n",
      "\tspeed: 0.0425s/iter; left time: 158.7150s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831026\n",
      "\tspeed: 0.0417s/iter; left time: 151.3560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 906 | Train Loss: 0.0864103 Vali Loss: 0.1206650 Test Loss: 0.1355586\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0921505\n",
      "\tspeed: 0.0991s/iter; left time: 349.3771s\n",
      "\titers: 200, epoch: 7 | loss: 0.0885938\n",
      "\tspeed: 0.0423s/iter; left time: 144.9604s\n",
      "\titers: 300, epoch: 7 | loss: 0.0844395\n",
      "\tspeed: 0.0410s/iter; left time: 136.3709s\n",
      "\titers: 400, epoch: 7 | loss: 0.0734793\n",
      "\tspeed: 0.0418s/iter; left time: 134.6488s\n",
      "\titers: 500, epoch: 7 | loss: 0.0862103\n",
      "\tspeed: 0.0418s/iter; left time: 130.6232s\n",
      "\titers: 600, epoch: 7 | loss: 0.0811895\n",
      "\tspeed: 0.0421s/iter; left time: 127.2037s\n",
      "\titers: 700, epoch: 7 | loss: 0.0868509\n",
      "\tspeed: 0.0416s/iter; left time: 121.7380s\n",
      "\titers: 800, epoch: 7 | loss: 0.0813473\n",
      "\tspeed: 0.0453s/iter; left time: 127.8969s\n",
      "\titers: 900, epoch: 7 | loss: 0.0785179\n",
      "\tspeed: 0.0458s/iter; left time: 124.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.06s\n",
      "Steps: 906 | Train Loss: 0.0824528 Vali Loss: 0.1243991 Test Loss: 0.1378392\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0794904\n",
      "\tspeed: 0.0979s/iter; left time: 256.4764s\n",
      "\titers: 200, epoch: 8 | loss: 0.0707949\n",
      "\tspeed: 0.0420s/iter; left time: 105.8470s\n",
      "\titers: 300, epoch: 8 | loss: 0.0853107\n",
      "\tspeed: 0.0423s/iter; left time: 102.3940s\n",
      "\titers: 400, epoch: 8 | loss: 0.0743418\n",
      "\tspeed: 0.0418s/iter; left time: 96.8516s\n",
      "\titers: 500, epoch: 8 | loss: 0.0784529\n",
      "\tspeed: 0.0416s/iter; left time: 92.2456s\n",
      "\titers: 600, epoch: 8 | loss: 0.0759883\n",
      "\tspeed: 0.0461s/iter; left time: 97.7547s\n",
      "\titers: 700, epoch: 8 | loss: 0.0777603\n",
      "\tspeed: 0.0458s/iter; left time: 92.4739s\n",
      "\titers: 800, epoch: 8 | loss: 0.0783959\n",
      "\tspeed: 0.0417s/iter; left time: 79.9886s\n",
      "\titers: 900, epoch: 8 | loss: 0.0811906\n",
      "\tspeed: 0.0416s/iter; left time: 75.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.03s\n",
      "Steps: 906 | Train Loss: 0.0787350 Vali Loss: 0.1227477 Test Loss: 0.1377678\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.049023713916540146, rmse:0.2214130014181137, mae:0.1361154168844223, rse:0.7819259762763977\n",
      "Original data scale mse:43415168.0, rmse:6589.0185546875, mae:3892.1005859375, rse:0.3276193141937256\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2246122\n",
      "\tspeed: 0.0766s/iter; left time: 684.5962s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081167\n",
      "\tspeed: 0.0478s/iter; left time: 422.3950s\n",
      "\titers: 300, epoch: 1 | loss: 0.1920674\n",
      "\tspeed: 0.0477s/iter; left time: 417.2155s\n",
      "\titers: 400, epoch: 1 | loss: 0.1789065\n",
      "\tspeed: 0.0477s/iter; left time: 412.1276s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717356\n",
      "\tspeed: 0.0477s/iter; left time: 407.4011s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616433\n",
      "\tspeed: 0.0477s/iter; left time: 402.5688s\n",
      "\titers: 700, epoch: 1 | loss: 0.1571472\n",
      "\tspeed: 0.0476s/iter; left time: 396.7013s\n",
      "\titers: 800, epoch: 1 | loss: 0.1616814\n",
      "\tspeed: 0.0465s/iter; left time: 383.5230s\n",
      "\titers: 900, epoch: 1 | loss: 0.1596366\n",
      "\tspeed: 0.0480s/iter; left time: 390.8968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.76s\n",
      "Steps: 904 | Train Loss: 0.1861247 Vali Loss: 0.1693542 Test Loss: 0.1905535\n",
      "Validation loss decreased (inf --> 0.169354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1489258\n",
      "\tspeed: 0.1198s/iter; left time: 962.4461s\n",
      "\titers: 200, epoch: 2 | loss: 0.1441848\n",
      "\tspeed: 0.0501s/iter; left time: 397.5552s\n",
      "\titers: 300, epoch: 2 | loss: 0.1349168\n",
      "\tspeed: 0.0503s/iter; left time: 393.9881s\n",
      "\titers: 400, epoch: 2 | loss: 0.1247658\n",
      "\tspeed: 0.0502s/iter; left time: 388.4870s\n",
      "\titers: 500, epoch: 2 | loss: 0.1154853\n",
      "\tspeed: 0.0501s/iter; left time: 382.6325s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227886\n",
      "\tspeed: 0.0503s/iter; left time: 379.0314s\n",
      "\titers: 700, epoch: 2 | loss: 0.1144098\n",
      "\tspeed: 0.0503s/iter; left time: 374.3143s\n",
      "\titers: 800, epoch: 2 | loss: 0.1222551\n",
      "\tspeed: 0.0503s/iter; left time: 369.2331s\n",
      "\titers: 900, epoch: 2 | loss: 0.1097277\n",
      "\tspeed: 0.0492s/iter; left time: 356.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.57s\n",
      "Steps: 904 | Train Loss: 0.1286928 Vali Loss: 0.1329564 Test Loss: 0.1465919\n",
      "Validation loss decreased (0.169354 --> 0.132956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156913\n",
      "\tspeed: 0.1178s/iter; left time: 840.5194s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975211\n",
      "\tspeed: 0.0476s/iter; left time: 335.0737s\n",
      "\titers: 300, epoch: 3 | loss: 0.1011100\n",
      "\tspeed: 0.0475s/iter; left time: 329.4588s\n",
      "\titers: 400, epoch: 3 | loss: 0.0964197\n",
      "\tspeed: 0.0473s/iter; left time: 323.3032s\n",
      "\titers: 500, epoch: 3 | loss: 0.1049682\n",
      "\tspeed: 0.0477s/iter; left time: 321.3351s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179357\n",
      "\tspeed: 0.0476s/iter; left time: 315.7179s\n",
      "\titers: 700, epoch: 3 | loss: 0.0949325\n",
      "\tspeed: 0.0475s/iter; left time: 310.6207s\n",
      "\titers: 800, epoch: 3 | loss: 0.1066777\n",
      "\tspeed: 0.0474s/iter; left time: 305.0717s\n",
      "\titers: 900, epoch: 3 | loss: 0.1093972\n",
      "\tspeed: 0.0474s/iter; left time: 300.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.1063339 Vali Loss: 0.1264300 Test Loss: 0.1395350\n",
      "Validation loss decreased (0.132956 --> 0.126430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966239\n",
      "\tspeed: 0.1168s/iter; left time: 727.2813s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967393\n",
      "\tspeed: 0.0476s/iter; left time: 291.9313s\n",
      "\titers: 300, epoch: 4 | loss: 0.0974483\n",
      "\tspeed: 0.0475s/iter; left time: 286.5496s\n",
      "\titers: 400, epoch: 4 | loss: 0.0835162\n",
      "\tspeed: 0.0476s/iter; left time: 282.2574s\n",
      "\titers: 500, epoch: 4 | loss: 0.1076640\n",
      "\tspeed: 0.0477s/iter; left time: 278.2330s\n",
      "\titers: 600, epoch: 4 | loss: 0.0894532\n",
      "\tspeed: 0.0477s/iter; left time: 273.1273s\n",
      "\titers: 700, epoch: 4 | loss: 0.1045760\n",
      "\tspeed: 0.0478s/iter; left time: 268.9783s\n",
      "\titers: 800, epoch: 4 | loss: 0.0914320\n",
      "\tspeed: 0.0475s/iter; left time: 262.7435s\n",
      "\titers: 900, epoch: 4 | loss: 0.1015885\n",
      "\tspeed: 0.0447s/iter; left time: 242.9459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.0977769 Vali Loss: 0.1318640 Test Loss: 0.1405835\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0893329\n",
      "\tspeed: 0.1141s/iter; left time: 607.3401s\n",
      "\titers: 200, epoch: 5 | loss: 0.1042083\n",
      "\tspeed: 0.0477s/iter; left time: 249.2042s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933421\n",
      "\tspeed: 0.0477s/iter; left time: 244.6439s\n",
      "\titers: 400, epoch: 5 | loss: 0.0931832\n",
      "\tspeed: 0.0477s/iter; left time: 239.4942s\n",
      "\titers: 500, epoch: 5 | loss: 0.0885474\n",
      "\tspeed: 0.0478s/iter; left time: 235.5157s\n",
      "\titers: 600, epoch: 5 | loss: 0.0869318\n",
      "\tspeed: 0.0475s/iter; left time: 229.3520s\n",
      "\titers: 700, epoch: 5 | loss: 0.0834743\n",
      "\tspeed: 0.0477s/iter; left time: 225.2079s\n",
      "\titers: 800, epoch: 5 | loss: 0.0820703\n",
      "\tspeed: 0.0472s/iter; left time: 218.4459s\n",
      "\titers: 900, epoch: 5 | loss: 0.0915056\n",
      "\tspeed: 0.0474s/iter; left time: 214.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.29s\n",
      "Steps: 904 | Train Loss: 0.0905559 Vali Loss: 0.1254451 Test Loss: 0.1421491\n",
      "Validation loss decreased (0.126430 --> 0.125445).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856860\n",
      "\tspeed: 0.1170s/iter; left time: 517.1642s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736776\n",
      "\tspeed: 0.0473s/iter; left time: 204.5221s\n",
      "\titers: 300, epoch: 6 | loss: 0.0857565\n",
      "\tspeed: 0.0474s/iter; left time: 200.0387s\n",
      "\titers: 400, epoch: 6 | loss: 0.0888394\n",
      "\tspeed: 0.0474s/iter; left time: 195.3220s\n",
      "\titers: 500, epoch: 6 | loss: 0.0817830\n",
      "\tspeed: 0.0474s/iter; left time: 190.7686s\n",
      "\titers: 600, epoch: 6 | loss: 0.0856055\n",
      "\tspeed: 0.0475s/iter; left time: 186.3789s\n",
      "\titers: 700, epoch: 6 | loss: 0.0784503\n",
      "\tspeed: 0.0474s/iter; left time: 180.9669s\n",
      "\titers: 800, epoch: 6 | loss: 0.0899893\n",
      "\tspeed: 0.0473s/iter; left time: 175.9523s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813079\n",
      "\tspeed: 0.0472s/iter; left time: 171.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.0840287 Vali Loss: 0.1298426 Test Loss: 0.1410313\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0734346\n",
      "\tspeed: 0.1150s/iter; left time: 404.3763s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739107\n",
      "\tspeed: 0.0480s/iter; left time: 163.9014s\n",
      "\titers: 300, epoch: 7 | loss: 0.0758579\n",
      "\tspeed: 0.0480s/iter; left time: 159.0662s\n",
      "\titers: 400, epoch: 7 | loss: 0.0730996\n",
      "\tspeed: 0.0478s/iter; left time: 153.8890s\n",
      "\titers: 500, epoch: 7 | loss: 0.0801694\n",
      "\tspeed: 0.0479s/iter; left time: 149.1838s\n",
      "\titers: 600, epoch: 7 | loss: 0.0745910\n",
      "\tspeed: 0.0477s/iter; left time: 143.8985s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786007\n",
      "\tspeed: 0.0478s/iter; left time: 139.5066s\n",
      "\titers: 800, epoch: 7 | loss: 0.0737484\n",
      "\tspeed: 0.0478s/iter; left time: 134.5833s\n",
      "\titers: 900, epoch: 7 | loss: 0.0823639\n",
      "\tspeed: 0.0478s/iter; left time: 129.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.0780969 Vali Loss: 0.1301674 Test Loss: 0.1462440\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0773419\n",
      "\tspeed: 0.1137s/iter; left time: 297.0339s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745791\n",
      "\tspeed: 0.0475s/iter; left time: 119.4015s\n",
      "\titers: 300, epoch: 8 | loss: 0.0757380\n",
      "\tspeed: 0.0475s/iter; left time: 114.5924s\n",
      "\titers: 400, epoch: 8 | loss: 0.0745323\n",
      "\tspeed: 0.0475s/iter; left time: 109.8397s\n",
      "\titers: 500, epoch: 8 | loss: 0.0775097\n",
      "\tspeed: 0.0476s/iter; left time: 105.2775s\n",
      "\titers: 600, epoch: 8 | loss: 0.0751869\n",
      "\tspeed: 0.0475s/iter; left time: 100.2757s\n",
      "\titers: 700, epoch: 8 | loss: 0.0781270\n",
      "\tspeed: 0.0476s/iter; left time: 95.9122s\n",
      "\titers: 800, epoch: 8 | loss: 0.0685896\n",
      "\tspeed: 0.0476s/iter; left time: 91.0042s\n",
      "\titers: 900, epoch: 8 | loss: 0.0697254\n",
      "\tspeed: 0.0476s/iter; left time: 86.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.0732840 Vali Loss: 0.1306358 Test Loss: 0.1448181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.045397039502859116, rmse:0.21306580305099487, mae:0.14210247993469238, rse:0.7545090913772583\n",
      "Original data scale mse:40688736.0, rmse:6378.7724609375, mae:4003.507568359375, rse:0.31766512989997864\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2301333\n",
      "\tspeed: 0.0500s/iter; left time: 447.0137s\n",
      "\titers: 200, epoch: 1 | loss: 0.1951126\n",
      "\tspeed: 0.0478s/iter; left time: 422.4199s\n",
      "\titers: 300, epoch: 1 | loss: 0.1723979\n",
      "\tspeed: 0.0480s/iter; left time: 419.3318s\n",
      "\titers: 400, epoch: 1 | loss: 0.1629347\n",
      "\tspeed: 0.0477s/iter; left time: 412.2920s\n",
      "\titers: 500, epoch: 1 | loss: 0.1636003\n",
      "\tspeed: 0.0478s/iter; left time: 408.3158s\n",
      "\titers: 600, epoch: 1 | loss: 0.1724814\n",
      "\tspeed: 0.0488s/iter; left time: 411.9863s\n",
      "\titers: 700, epoch: 1 | loss: 0.1671904\n",
      "\tspeed: 0.0502s/iter; left time: 418.4229s\n",
      "\titers: 800, epoch: 1 | loss: 0.1681524\n",
      "\tspeed: 0.0498s/iter; left time: 410.4301s\n",
      "\titers: 900, epoch: 1 | loss: 0.1574399\n",
      "\tspeed: 0.0488s/iter; left time: 397.4146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.17s\n",
      "Steps: 904 | Train Loss: 0.1846326 Vali Loss: 0.1673415 Test Loss: 0.1887328\n",
      "Validation loss decreased (inf --> 0.167341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451383\n",
      "\tspeed: 0.1212s/iter; left time: 974.4672s\n",
      "\titers: 200, epoch: 2 | loss: 0.1455005\n",
      "\tspeed: 0.0477s/iter; left time: 378.3367s\n",
      "\titers: 300, epoch: 2 | loss: 0.1271278\n",
      "\tspeed: 0.0477s/iter; left time: 373.6870s\n",
      "\titers: 400, epoch: 2 | loss: 0.1205615\n",
      "\tspeed: 0.0476s/iter; left time: 368.4213s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160921\n",
      "\tspeed: 0.0476s/iter; left time: 363.5420s\n",
      "\titers: 600, epoch: 2 | loss: 0.1196285\n",
      "\tspeed: 0.0475s/iter; left time: 357.8634s\n",
      "\titers: 700, epoch: 2 | loss: 0.1190385\n",
      "\tspeed: 0.0476s/iter; left time: 353.8770s\n",
      "\titers: 800, epoch: 2 | loss: 0.1101898\n",
      "\tspeed: 0.0471s/iter; left time: 345.2306s\n",
      "\titers: 900, epoch: 2 | loss: 0.1044184\n",
      "\tspeed: 0.0474s/iter; left time: 342.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.29s\n",
      "Steps: 904 | Train Loss: 0.1283991 Vali Loss: 0.1355134 Test Loss: 0.1446352\n",
      "Validation loss decreased (0.167341 --> 0.135513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039385\n",
      "\tspeed: 0.1215s/iter; left time: 866.3886s\n",
      "\titers: 200, epoch: 3 | loss: 0.1261861\n",
      "\tspeed: 0.0477s/iter; left time: 335.1434s\n",
      "\titers: 300, epoch: 3 | loss: 0.1150491\n",
      "\tspeed: 0.0475s/iter; left time: 329.6268s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001509\n",
      "\tspeed: 0.0476s/iter; left time: 325.1672s\n",
      "\titers: 500, epoch: 3 | loss: 0.0977131\n",
      "\tspeed: 0.0476s/iter; left time: 320.4054s\n",
      "\titers: 600, epoch: 3 | loss: 0.1125626\n",
      "\tspeed: 0.0477s/iter; left time: 316.2451s\n",
      "\titers: 700, epoch: 3 | loss: 0.0982501\n",
      "\tspeed: 0.0478s/iter; left time: 312.2386s\n",
      "\titers: 800, epoch: 3 | loss: 0.1015485\n",
      "\tspeed: 0.0475s/iter; left time: 305.5349s\n",
      "\titers: 900, epoch: 3 | loss: 0.1056257\n",
      "\tspeed: 0.0476s/iter; left time: 301.2429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.34s\n",
      "Steps: 904 | Train Loss: 0.1050790 Vali Loss: 0.1275464 Test Loss: 0.1397778\n",
      "Validation loss decreased (0.135513 --> 0.127546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961418\n",
      "\tspeed: 0.1181s/iter; left time: 735.8718s\n",
      "\titers: 200, epoch: 4 | loss: 0.1005371\n",
      "\tspeed: 0.0481s/iter; left time: 294.6778s\n",
      "\titers: 300, epoch: 4 | loss: 0.0996916\n",
      "\tspeed: 0.0476s/iter; left time: 287.0609s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910206\n",
      "\tspeed: 0.0476s/iter; left time: 282.4551s\n",
      "\titers: 500, epoch: 4 | loss: 0.1074546\n",
      "\tspeed: 0.0475s/iter; left time: 277.0089s\n",
      "\titers: 600, epoch: 4 | loss: 0.0947664\n",
      "\tspeed: 0.0476s/iter; left time: 272.8884s\n",
      "\titers: 700, epoch: 4 | loss: 0.0980362\n",
      "\tspeed: 0.0479s/iter; left time: 269.7480s\n",
      "\titers: 800, epoch: 4 | loss: 0.0869908\n",
      "\tspeed: 0.0479s/iter; left time: 264.9840s\n",
      "\titers: 900, epoch: 4 | loss: 0.0859004\n",
      "\tspeed: 0.0478s/iter; left time: 259.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.47s\n",
      "Steps: 904 | Train Loss: 0.0974901 Vali Loss: 0.1262636 Test Loss: 0.1426535\n",
      "Validation loss decreased (0.127546 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958850\n",
      "\tspeed: 0.1185s/iter; left time: 631.0066s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915819\n",
      "\tspeed: 0.0473s/iter; left time: 247.1980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0879767\n",
      "\tspeed: 0.0475s/iter; left time: 243.4579s\n",
      "\titers: 400, epoch: 5 | loss: 0.0803326\n",
      "\tspeed: 0.0474s/iter; left time: 238.0850s\n",
      "\titers: 500, epoch: 5 | loss: 0.0850065\n",
      "\tspeed: 0.0475s/iter; left time: 233.7860s\n",
      "\titers: 600, epoch: 5 | loss: 0.0890771\n",
      "\tspeed: 0.0476s/iter; left time: 229.6892s\n",
      "\titers: 700, epoch: 5 | loss: 0.0929132\n",
      "\tspeed: 0.0474s/iter; left time: 224.1027s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846247\n",
      "\tspeed: 0.0475s/iter; left time: 219.7021s\n",
      "\titers: 900, epoch: 5 | loss: 0.0851368\n",
      "\tspeed: 0.0474s/iter; left time: 214.6123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.21s\n",
      "Steps: 904 | Train Loss: 0.0912254 Vali Loss: 0.1260705 Test Loss: 0.1398559\n",
      "Validation loss decreased (0.126264 --> 0.126071).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0966838\n",
      "\tspeed: 0.1180s/iter; left time: 521.6061s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888424\n",
      "\tspeed: 0.0478s/iter; left time: 206.4158s\n",
      "\titers: 300, epoch: 6 | loss: 0.0831272\n",
      "\tspeed: 0.0474s/iter; left time: 199.9933s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903139\n",
      "\tspeed: 0.0474s/iter; left time: 195.1566s\n",
      "\titers: 500, epoch: 6 | loss: 0.0874166\n",
      "\tspeed: 0.0474s/iter; left time: 190.7842s\n",
      "\titers: 600, epoch: 6 | loss: 0.0912243\n",
      "\tspeed: 0.0475s/iter; left time: 186.3248s\n",
      "\titers: 700, epoch: 6 | loss: 0.0895760\n",
      "\tspeed: 0.0475s/iter; left time: 181.5964s\n",
      "\titers: 800, epoch: 6 | loss: 0.0793183\n",
      "\tspeed: 0.0473s/iter; left time: 176.1254s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831427\n",
      "\tspeed: 0.0474s/iter; left time: 171.5682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.0851726 Vali Loss: 0.1282148 Test Loss: 0.1443390\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754341\n",
      "\tspeed: 0.1169s/iter; left time: 411.1184s\n",
      "\titers: 200, epoch: 7 | loss: 0.0798553\n",
      "\tspeed: 0.0479s/iter; left time: 163.7177s\n",
      "\titers: 300, epoch: 7 | loss: 0.0775340\n",
      "\tspeed: 0.0479s/iter; left time: 158.7545s\n",
      "\titers: 400, epoch: 7 | loss: 0.0785744\n",
      "\tspeed: 0.0477s/iter; left time: 153.5118s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772450\n",
      "\tspeed: 0.0477s/iter; left time: 148.6140s\n",
      "\titers: 600, epoch: 7 | loss: 0.0841917\n",
      "\tspeed: 0.0504s/iter; left time: 152.0504s\n",
      "\titers: 700, epoch: 7 | loss: 0.0775137\n",
      "\tspeed: 0.0503s/iter; left time: 146.8029s\n",
      "\titers: 800, epoch: 7 | loss: 0.0842347\n",
      "\tspeed: 0.0499s/iter; left time: 140.6118s\n",
      "\titers: 900, epoch: 7 | loss: 0.0790158\n",
      "\tspeed: 0.0502s/iter; left time: 136.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.54s\n",
      "Steps: 904 | Train Loss: 0.0794048 Vali Loss: 0.1288580 Test Loss: 0.1445608\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0741648\n",
      "\tspeed: 0.1143s/iter; left time: 298.7918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0693042\n",
      "\tspeed: 0.0476s/iter; left time: 119.5015s\n",
      "\titers: 300, epoch: 8 | loss: 0.0753945\n",
      "\tspeed: 0.0477s/iter; left time: 115.0869s\n",
      "\titers: 400, epoch: 8 | loss: 0.0730816\n",
      "\tspeed: 0.0475s/iter; left time: 109.8324s\n",
      "\titers: 500, epoch: 8 | loss: 0.0720230\n",
      "\tspeed: 0.0475s/iter; left time: 105.0902s\n",
      "\titers: 600, epoch: 8 | loss: 0.0695945\n",
      "\tspeed: 0.0474s/iter; left time: 100.1734s\n",
      "\titers: 700, epoch: 8 | loss: 0.0733338\n",
      "\tspeed: 0.0476s/iter; left time: 95.8067s\n",
      "\titers: 800, epoch: 8 | loss: 0.0721483\n",
      "\tspeed: 0.0475s/iter; left time: 90.9388s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699571\n",
      "\tspeed: 0.0476s/iter; left time: 86.2755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.0741621 Vali Loss: 0.1269441 Test Loss: 0.1441041\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04406126216053963, rmse:0.20990774035453796, mae:0.13983353972434998, rse:0.7433257699012756\n",
      "Original data scale mse:38573712.0, rmse:6210.77392578125, mae:3890.927490234375, rse:0.3092987537384033\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2147408\n",
      "\tspeed: 0.0844s/iter; left time: 752.5271s\n",
      "\titers: 200, epoch: 1 | loss: 0.2049752\n",
      "\tspeed: 0.0544s/iter; left time: 480.0236s\n",
      "\titers: 300, epoch: 1 | loss: 0.1858589\n",
      "\tspeed: 0.0534s/iter; left time: 465.6800s\n",
      "\titers: 400, epoch: 1 | loss: 0.1819223\n",
      "\tspeed: 0.0533s/iter; left time: 459.9233s\n",
      "\titers: 500, epoch: 1 | loss: 0.1769616\n",
      "\tspeed: 0.0533s/iter; left time: 454.0801s\n",
      "\titers: 600, epoch: 1 | loss: 0.1786938\n",
      "\tspeed: 0.0532s/iter; left time: 448.0498s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688549\n",
      "\tspeed: 0.0536s/iter; left time: 446.0571s\n",
      "\titers: 800, epoch: 1 | loss: 0.1654620\n",
      "\tspeed: 0.0532s/iter; left time: 437.0259s\n",
      "\titers: 900, epoch: 1 | loss: 0.1702404\n",
      "\tspeed: 0.0539s/iter; left time: 437.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.15s\n",
      "Steps: 902 | Train Loss: 0.1895083 Vali Loss: 0.1759074 Test Loss: 0.1999528\n",
      "Validation loss decreased (inf --> 0.175907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651679\n",
      "\tspeed: 0.1349s/iter; left time: 1081.8961s\n",
      "\titers: 200, epoch: 2 | loss: 0.1541310\n",
      "\tspeed: 0.0538s/iter; left time: 426.2249s\n",
      "\titers: 300, epoch: 2 | loss: 0.1586817\n",
      "\tspeed: 0.0534s/iter; left time: 417.8857s\n",
      "\titers: 400, epoch: 2 | loss: 0.1454573\n",
      "\tspeed: 0.0537s/iter; left time: 414.2687s\n",
      "\titers: 500, epoch: 2 | loss: 0.1384664\n",
      "\tspeed: 0.0536s/iter; left time: 408.4807s\n",
      "\titers: 600, epoch: 2 | loss: 0.1333779\n",
      "\tspeed: 0.0538s/iter; left time: 404.1857s\n",
      "\titers: 700, epoch: 2 | loss: 0.1278873\n",
      "\tspeed: 0.0538s/iter; left time: 398.9881s\n",
      "\titers: 800, epoch: 2 | loss: 0.1431116\n",
      "\tspeed: 0.0538s/iter; left time: 393.9117s\n",
      "\titers: 900, epoch: 2 | loss: 0.1280995\n",
      "\tspeed: 0.0537s/iter; left time: 387.3605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.1441035 Vali Loss: 0.1519851 Test Loss: 0.1711886\n",
      "Validation loss decreased (0.175907 --> 0.151985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377297\n",
      "\tspeed: 0.1353s/iter; left time: 962.9312s\n",
      "\titers: 200, epoch: 3 | loss: 0.1210781\n",
      "\tspeed: 0.0537s/iter; left time: 376.5384s\n",
      "\titers: 300, epoch: 3 | loss: 0.1198194\n",
      "\tspeed: 0.0536s/iter; left time: 371.0440s\n",
      "\titers: 400, epoch: 3 | loss: 0.1224196\n",
      "\tspeed: 0.0536s/iter; left time: 365.6868s\n",
      "\titers: 500, epoch: 3 | loss: 0.1074672\n",
      "\tspeed: 0.0536s/iter; left time: 359.7538s\n",
      "\titers: 600, epoch: 3 | loss: 0.1116899\n",
      "\tspeed: 0.0536s/iter; left time: 354.5666s\n",
      "\titers: 700, epoch: 3 | loss: 0.1112872\n",
      "\tspeed: 0.0537s/iter; left time: 349.8568s\n",
      "\titers: 800, epoch: 3 | loss: 0.1100388\n",
      "\tspeed: 0.0537s/iter; left time: 344.3599s\n",
      "\titers: 900, epoch: 3 | loss: 0.1070697\n",
      "\tspeed: 0.0537s/iter; left time: 339.3175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1143792 Vali Loss: 0.1312807 Test Loss: 0.1447967\n",
      "Validation loss decreased (0.151985 --> 0.131281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993531\n",
      "\tspeed: 0.1366s/iter; left time: 849.1048s\n",
      "\titers: 200, epoch: 4 | loss: 0.0976536\n",
      "\tspeed: 0.0537s/iter; left time: 328.6756s\n",
      "\titers: 300, epoch: 4 | loss: 0.1099965\n",
      "\tspeed: 0.0537s/iter; left time: 323.0815s\n",
      "\titers: 400, epoch: 4 | loss: 0.1085633\n",
      "\tspeed: 0.0538s/iter; left time: 318.0533s\n",
      "\titers: 500, epoch: 4 | loss: 0.1053810\n",
      "\tspeed: 0.0536s/iter; left time: 311.8871s\n",
      "\titers: 600, epoch: 4 | loss: 0.0958832\n",
      "\tspeed: 0.0534s/iter; left time: 305.3794s\n",
      "\titers: 700, epoch: 4 | loss: 0.1085369\n",
      "\tspeed: 0.0533s/iter; left time: 299.5085s\n",
      "\titers: 800, epoch: 4 | loss: 0.1051037\n",
      "\tspeed: 0.0536s/iter; left time: 295.5138s\n",
      "\titers: 900, epoch: 4 | loss: 0.0943609\n",
      "\tspeed: 0.0536s/iter; left time: 290.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1017112 Vali Loss: 0.1352619 Test Loss: 0.1506488\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1000706\n",
      "\tspeed: 0.1328s/iter; left time: 705.5015s\n",
      "\titers: 200, epoch: 5 | loss: 0.0926405\n",
      "\tspeed: 0.0536s/iter; left time: 279.6510s\n",
      "\titers: 300, epoch: 5 | loss: 0.0950490\n",
      "\tspeed: 0.0539s/iter; left time: 275.4698s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976274\n",
      "\tspeed: 0.0537s/iter; left time: 268.9795s\n",
      "\titers: 500, epoch: 5 | loss: 0.0843251\n",
      "\tspeed: 0.0536s/iter; left time: 263.3051s\n",
      "\titers: 600, epoch: 5 | loss: 0.0954909\n",
      "\tspeed: 0.0536s/iter; left time: 258.0546s\n",
      "\titers: 700, epoch: 5 | loss: 0.0944040\n",
      "\tspeed: 0.0537s/iter; left time: 253.1218s\n",
      "\titers: 800, epoch: 5 | loss: 0.0896012\n",
      "\tspeed: 0.0538s/iter; left time: 248.1191s\n",
      "\titers: 900, epoch: 5 | loss: 0.0822994\n",
      "\tspeed: 0.0538s/iter; left time: 242.6411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0932891 Vali Loss: 0.1389595 Test Loss: 0.1535437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0876330\n",
      "\tspeed: 0.1323s/iter; left time: 583.5504s\n",
      "\titers: 200, epoch: 6 | loss: 0.0893045\n",
      "\tspeed: 0.0539s/iter; left time: 232.1882s\n",
      "\titers: 300, epoch: 6 | loss: 0.0815809\n",
      "\tspeed: 0.0539s/iter; left time: 226.9240s\n",
      "\titers: 400, epoch: 6 | loss: 0.0949811\n",
      "\tspeed: 0.0535s/iter; left time: 219.8712s\n",
      "\titers: 500, epoch: 6 | loss: 0.0837089\n",
      "\tspeed: 0.0537s/iter; left time: 215.2059s\n",
      "\titers: 600, epoch: 6 | loss: 0.0823262\n",
      "\tspeed: 0.0533s/iter; left time: 208.4497s\n",
      "\titers: 700, epoch: 6 | loss: 0.0879384\n",
      "\tspeed: 0.0538s/iter; left time: 205.0885s\n",
      "\titers: 800, epoch: 6 | loss: 0.0795501\n",
      "\tspeed: 0.0535s/iter; left time: 198.5937s\n",
      "\titers: 900, epoch: 6 | loss: 0.0906194\n",
      "\tspeed: 0.0532s/iter; left time: 192.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0859014 Vali Loss: 0.1372263 Test Loss: 0.1539112\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04394709691405296, rmse:0.2096356302499771, mae:0.14478307962417603, rse:0.7426759004592896\n",
      "Original data scale mse:39822152.0, rmse:6310.4794921875, mae:4082.469482421875, rse:0.31441840529441833\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2321397\n",
      "\tspeed: 0.0453s/iter; left time: 403.8943s\n",
      "\titers: 200, epoch: 1 | loss: 0.1973691\n",
      "\tspeed: 0.0428s/iter; left time: 377.8423s\n",
      "\titers: 300, epoch: 1 | loss: 0.1899634\n",
      "\tspeed: 0.0428s/iter; left time: 373.6296s\n",
      "\titers: 400, epoch: 1 | loss: 0.1636305\n",
      "\tspeed: 0.0428s/iter; left time: 369.2176s\n",
      "\titers: 500, epoch: 1 | loss: 0.1814534\n",
      "\tspeed: 0.0428s/iter; left time: 364.8918s\n",
      "\titers: 600, epoch: 1 | loss: 0.1696513\n",
      "\tspeed: 0.0428s/iter; left time: 360.4121s\n",
      "\titers: 700, epoch: 1 | loss: 0.1682921\n",
      "\tspeed: 0.0428s/iter; left time: 356.3557s\n",
      "\titers: 800, epoch: 1 | loss: 0.1633812\n",
      "\tspeed: 0.0428s/iter; left time: 352.1331s\n",
      "\titers: 900, epoch: 1 | loss: 0.1687731\n",
      "\tspeed: 0.0428s/iter; left time: 347.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 902 | Train Loss: 0.1893847 Vali Loss: 0.1745064 Test Loss: 0.1995509\n",
      "Validation loss decreased (inf --> 0.174506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1527932\n",
      "\tspeed: 0.1364s/iter; left time: 1094.1890s\n",
      "\titers: 200, epoch: 2 | loss: 0.1483294\n",
      "\tspeed: 0.0536s/iter; left time: 424.7139s\n",
      "\titers: 300, epoch: 2 | loss: 0.1427017\n",
      "\tspeed: 0.0537s/iter; left time: 419.5394s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373652\n",
      "\tspeed: 0.0536s/iter; left time: 413.8958s\n",
      "\titers: 500, epoch: 2 | loss: 0.1404201\n",
      "\tspeed: 0.0537s/iter; left time: 408.7945s\n",
      "\titers: 600, epoch: 2 | loss: 0.1426174\n",
      "\tspeed: 0.0534s/iter; left time: 401.8065s\n",
      "\titers: 700, epoch: 2 | loss: 0.1350924\n",
      "\tspeed: 0.0535s/iter; left time: 396.9304s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242686\n",
      "\tspeed: 0.0535s/iter; left time: 391.6150s\n",
      "\titers: 900, epoch: 2 | loss: 0.1295320\n",
      "\tspeed: 0.0535s/iter; left time: 385.9883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.1452574 Vali Loss: 0.1592431 Test Loss: 0.1785243\n",
      "Validation loss decreased (0.174506 --> 0.159243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216370\n",
      "\tspeed: 0.1350s/iter; left time: 960.6596s\n",
      "\titers: 200, epoch: 3 | loss: 0.1274602\n",
      "\tspeed: 0.0536s/iter; left time: 376.1184s\n",
      "\titers: 300, epoch: 3 | loss: 0.1250435\n",
      "\tspeed: 0.0535s/iter; left time: 370.1860s\n",
      "\titers: 400, epoch: 3 | loss: 0.1166226\n",
      "\tspeed: 0.0537s/iter; left time: 365.8595s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175315\n",
      "\tspeed: 0.0536s/iter; left time: 359.9996s\n",
      "\titers: 600, epoch: 3 | loss: 0.1078033\n",
      "\tspeed: 0.0535s/iter; left time: 354.0505s\n",
      "\titers: 700, epoch: 3 | loss: 0.1084212\n",
      "\tspeed: 0.0534s/iter; left time: 348.2309s\n",
      "\titers: 800, epoch: 3 | loss: 0.1020218\n",
      "\tspeed: 0.0533s/iter; left time: 342.0026s\n",
      "\titers: 900, epoch: 3 | loss: 0.1084920\n",
      "\tspeed: 0.0536s/iter; left time: 338.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1151611 Vali Loss: 0.1308115 Test Loss: 0.1448318\n",
      "Validation loss decreased (0.159243 --> 0.130811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1048867\n",
      "\tspeed: 0.1360s/iter; left time: 845.4010s\n",
      "\titers: 200, epoch: 4 | loss: 0.0964195\n",
      "\tspeed: 0.0537s/iter; left time: 328.1689s\n",
      "\titers: 300, epoch: 4 | loss: 0.1035071\n",
      "\tspeed: 0.0538s/iter; left time: 323.4828s\n",
      "\titers: 400, epoch: 4 | loss: 0.1002823\n",
      "\tspeed: 0.0538s/iter; left time: 318.1358s\n",
      "\titers: 500, epoch: 4 | loss: 0.1016895\n",
      "\tspeed: 0.0536s/iter; left time: 311.8232s\n",
      "\titers: 600, epoch: 4 | loss: 0.1110194\n",
      "\tspeed: 0.0537s/iter; left time: 307.1581s\n",
      "\titers: 700, epoch: 4 | loss: 0.0958979\n",
      "\tspeed: 0.0537s/iter; left time: 301.5589s\n",
      "\titers: 800, epoch: 4 | loss: 0.1013383\n",
      "\tspeed: 0.0537s/iter; left time: 296.0334s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973082\n",
      "\tspeed: 0.0537s/iter; left time: 290.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.77s\n",
      "Steps: 902 | Train Loss: 0.1012365 Vali Loss: 0.1355156 Test Loss: 0.1474784\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882527\n",
      "\tspeed: 0.1359s/iter; left time: 721.8029s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935989\n",
      "\tspeed: 0.0537s/iter; left time: 280.1440s\n",
      "\titers: 300, epoch: 5 | loss: 0.0921567\n",
      "\tspeed: 0.0537s/iter; left time: 274.8168s\n",
      "\titers: 400, epoch: 5 | loss: 0.0977337\n",
      "\tspeed: 0.0536s/iter; left time: 268.6083s\n",
      "\titers: 500, epoch: 5 | loss: 0.1000321\n",
      "\tspeed: 0.0537s/iter; left time: 263.6669s\n",
      "\titers: 600, epoch: 5 | loss: 0.0865251\n",
      "\tspeed: 0.0538s/iter; left time: 259.1644s\n",
      "\titers: 700, epoch: 5 | loss: 0.0922151\n",
      "\tspeed: 0.0537s/iter; left time: 253.0635s\n",
      "\titers: 800, epoch: 5 | loss: 0.0845081\n",
      "\tspeed: 0.0536s/iter; left time: 247.3660s\n",
      "\titers: 900, epoch: 5 | loss: 0.0910032\n",
      "\tspeed: 0.0538s/iter; left time: 242.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.0929604 Vali Loss: 0.1366524 Test Loss: 0.1539558\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0900509\n",
      "\tspeed: 0.1331s/iter; left time: 586.9460s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848731\n",
      "\tspeed: 0.0537s/iter; left time: 231.6547s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875704\n",
      "\tspeed: 0.0536s/iter; left time: 225.7914s\n",
      "\titers: 400, epoch: 6 | loss: 0.0834398\n",
      "\tspeed: 0.0537s/iter; left time: 220.9433s\n",
      "\titers: 500, epoch: 6 | loss: 0.0816596\n",
      "\tspeed: 0.0536s/iter; left time: 215.0474s\n",
      "\titers: 600, epoch: 6 | loss: 0.0911666\n",
      "\tspeed: 0.0537s/iter; left time: 209.8499s\n",
      "\titers: 700, epoch: 6 | loss: 0.0888930\n",
      "\tspeed: 0.0537s/iter; left time: 204.6476s\n",
      "\titers: 800, epoch: 6 | loss: 0.0769717\n",
      "\tspeed: 0.0538s/iter; left time: 199.5199s\n",
      "\titers: 900, epoch: 6 | loss: 0.0764168\n",
      "\tspeed: 0.0536s/iter; left time: 193.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.0858187 Vali Loss: 0.1359175 Test Loss: 0.1564617\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04477142170071602, rmse:0.21159258484840393, mae:0.14479929208755493, rse:0.7496087551116943\n",
      "Original data scale mse:41195184.0, rmse:6418.34765625, mae:4090.05419921875, rse:0.31979289650917053\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.7251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.7247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.7360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.7819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.7545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0250  0.1580  0.1041  0.5580\n",
       "              2         24        0.0229  0.1513  0.1014  0.5342\n",
       "              1         96        0.0416  0.2040  0.1469  0.7224\n",
       "              2         96        0.0419  0.2047  0.1414  0.7251\n",
       "              1         168       0.0419  0.2048  0.1461  0.7255\n",
       "              2         168       0.0428  0.2069  0.1482  0.7330\n",
       "RMSE          1         24        0.0251  0.1586  0.1066  0.5599\n",
       "              2         24        0.0230  0.1516  0.1000  0.5355\n",
       "              1         96        0.0410  0.2026  0.1448  0.7173\n",
       "              2         96        0.0419  0.2047  0.1425  0.7247\n",
       "              1         168       0.0416  0.2039  0.1451  0.7222\n",
       "              2         168       0.0432  0.2077  0.1486  0.7360\n",
       "MAE           1         24        0.0243  0.1559  0.1003  0.5504\n",
       "              2         24        0.0490  0.2214  0.1361  0.7819\n",
       "              1         96        0.0454  0.2131  0.1421  0.7545\n",
       "              2         96        0.0441  0.2099  0.1398  0.7433\n",
       "              1         168       0.0439  0.2096  0.1448  0.7427\n",
       "              2         168       0.0448  0.2116  0.1448  0.7496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21478470.0</td>\n",
       "      <td>4634.4868</td>\n",
       "      <td>2927.1528</td>\n",
       "      <td>0.2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19517502.0</td>\n",
       "      <td>4417.8618</td>\n",
       "      <td>2843.4880</td>\n",
       "      <td>0.2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38027972.0</td>\n",
       "      <td>6166.6826</td>\n",
       "      <td>4192.3315</td>\n",
       "      <td>0.3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38741736.0</td>\n",
       "      <td>6224.2861</td>\n",
       "      <td>4020.8625</td>\n",
       "      <td>0.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38667512.0</td>\n",
       "      <td>6218.3208</td>\n",
       "      <td>4159.8320</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40122660.0</td>\n",
       "      <td>6334.2451</td>\n",
       "      <td>4268.5029</td>\n",
       "      <td>0.3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20226732.0</td>\n",
       "      <td>4497.4141</td>\n",
       "      <td>2958.5962</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19474288.0</td>\n",
       "      <td>4412.9683</td>\n",
       "      <td>2820.4792</td>\n",
       "      <td>0.2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36910216.0</td>\n",
       "      <td>6075.3779</td>\n",
       "      <td>4103.1270</td>\n",
       "      <td>0.3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38137348.0</td>\n",
       "      <td>6175.5444</td>\n",
       "      <td>4037.7593</td>\n",
       "      <td>0.3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38455032.0</td>\n",
       "      <td>6201.2119</td>\n",
       "      <td>4132.5327</td>\n",
       "      <td>0.3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40330176.0</td>\n",
       "      <td>6350.6045</td>\n",
       "      <td>4271.2358</td>\n",
       "      <td>0.3164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21054224.0</td>\n",
       "      <td>4588.4883</td>\n",
       "      <td>2843.1777</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>43415168.0</td>\n",
       "      <td>6589.0186</td>\n",
       "      <td>3892.1006</td>\n",
       "      <td>0.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>40688736.0</td>\n",
       "      <td>6378.7725</td>\n",
       "      <td>4003.5076</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38573712.0</td>\n",
       "      <td>6210.7739</td>\n",
       "      <td>3890.9275</td>\n",
       "      <td>0.3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39822152.0</td>\n",
       "      <td>6310.4795</td>\n",
       "      <td>4082.4695</td>\n",
       "      <td>0.3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>41195184.0</td>\n",
       "      <td>6418.3477</td>\n",
       "      <td>4090.0542</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        21478470.0  4634.4868  2927.1528  0.2304\n",
       "              2         24        19517502.0  4417.8618  2843.4880  0.2197\n",
       "              1         96        38027972.0  6166.6826  4192.3315  0.3071\n",
       "              2         96        38741736.0  6224.2861  4020.8625  0.3100\n",
       "              1         168       38667512.0  6218.3208  4159.8320  0.3098\n",
       "              2         168       40122660.0  6334.2451  4268.5029  0.3156\n",
       "RMSE          1         24        20226732.0  4497.4141  2958.5962  0.2236\n",
       "              2         24        19474288.0  4412.9683  2820.4792  0.2194\n",
       "              1         96        36910216.0  6075.3779  4103.1270  0.3026\n",
       "              2         96        38137348.0  6175.5444  4037.7593  0.3075\n",
       "              1         168       38455032.0  6201.2119  4132.5327  0.3090\n",
       "              2         168       40330176.0  6350.6045  4271.2358  0.3164\n",
       "MAE           1         24        21054224.0  4588.4883  2843.1777  0.2281\n",
       "              2         24        43415168.0  6589.0186  3892.1006  0.3276\n",
       "              1         96        40688736.0  6378.7725  4003.5076  0.3177\n",
       "              2         96        38573712.0  6210.7739  3890.9275  0.3093\n",
       "              1         168       39822152.0  6310.4795  4082.4695  0.3144\n",
       "              2         168       41195184.0  6418.3477  4090.0542  0.3198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.5477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.7291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0367  0.1886  0.1182  0.6662\n",
       "         MSE            0.0239  0.1546  0.1027  0.5461\n",
       "         RMSE           0.0241  0.1551  0.1033  0.5477\n",
       "96       MAE            0.0447  0.2115  0.1410  0.7489\n",
       "         MSE            0.0418  0.2044  0.1441  0.7237\n",
       "         RMSE           0.0415  0.2036  0.1436  0.7210\n",
       "168      MAE            0.0444  0.2106  0.1448  0.7461\n",
       "         MSE            0.0424  0.2059  0.1472  0.7293\n",
       "         RMSE           0.0424  0.2058  0.1468  0.7291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32234696.0</td>\n",
       "      <td>5588.7534</td>\n",
       "      <td>3367.6392</td>\n",
       "      <td>0.2779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>20497986.0</td>\n",
       "      <td>4526.1743</td>\n",
       "      <td>2885.3204</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19850510.0</td>\n",
       "      <td>4455.1912</td>\n",
       "      <td>2889.5377</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39631224.0</td>\n",
       "      <td>6294.7732</td>\n",
       "      <td>3947.2175</td>\n",
       "      <td>0.3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38384854.0</td>\n",
       "      <td>6195.4844</td>\n",
       "      <td>4106.5970</td>\n",
       "      <td>0.3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37523782.0</td>\n",
       "      <td>6125.4612</td>\n",
       "      <td>4070.4431</td>\n",
       "      <td>0.3051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40508668.0</td>\n",
       "      <td>6364.4136</td>\n",
       "      <td>4086.2618</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39395086.0</td>\n",
       "      <td>6276.2830</td>\n",
       "      <td>4214.1675</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39392604.0</td>\n",
       "      <td>6275.9082</td>\n",
       "      <td>4201.8843</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            32234696.0  5588.7534  3367.6392  0.2779\n",
       "         MSE            20497986.0  4526.1743  2885.3204  0.2251\n",
       "         RMSE           19850510.0  4455.1912  2889.5377  0.2215\n",
       "96       MAE            39631224.0  6294.7732  3947.2175  0.3135\n",
       "         MSE            38384854.0  6195.4844  4106.5970  0.3085\n",
       "         RMSE           37523782.0  6125.4612  4070.4431  0.3051\n",
       "168      MAE            40508668.0  6364.4136  4086.2618  0.3171\n",
       "         MSE            39395086.0  6276.2830  4214.1675  0.3127\n",
       "         RMSE           39392604.0  6275.9082  4201.8843  0.3127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0186265\n",
      "\tspeed: 0.0673s/iter; left time: 593.9052s\n",
      "\titers: 200, epoch: 1 | loss: 0.0204422\n",
      "\tspeed: 0.0425s/iter; left time: 371.4124s\n",
      "\titers: 300, epoch: 1 | loss: 0.0158871\n",
      "\tspeed: 0.0424s/iter; left time: 365.6571s\n",
      "\titers: 400, epoch: 1 | loss: 0.0188983\n",
      "\tspeed: 0.0424s/iter; left time: 361.4986s\n",
      "\titers: 500, epoch: 1 | loss: 0.0171893\n",
      "\tspeed: 0.0424s/iter; left time: 357.1421s\n",
      "\titers: 600, epoch: 1 | loss: 0.0204163\n",
      "\tspeed: 0.0423s/iter; left time: 352.6107s\n",
      "\titers: 700, epoch: 1 | loss: 0.0160199\n",
      "\tspeed: 0.0425s/iter; left time: 350.0541s\n",
      "\titers: 800, epoch: 1 | loss: 0.0154415\n",
      "\tspeed: 0.0425s/iter; left time: 345.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 893 | Train Loss: 0.0172390 Vali Loss: 0.0207930 Test Loss: 0.0224516\n",
      "Validation loss decreased (inf --> 0.020793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0187046\n",
      "\tspeed: 0.1538s/iter; left time: 1221.0351s\n",
      "\titers: 200, epoch: 2 | loss: 0.0174998\n",
      "\tspeed: 0.0424s/iter; left time: 332.1015s\n",
      "\titers: 300, epoch: 2 | loss: 0.0124051\n",
      "\tspeed: 0.0424s/iter; left time: 327.8057s\n",
      "\titers: 400, epoch: 2 | loss: 0.0135999\n",
      "\tspeed: 0.0424s/iter; left time: 323.6658s\n",
      "\titers: 500, epoch: 2 | loss: 0.0125794\n",
      "\tspeed: 0.0423s/iter; left time: 319.0117s\n",
      "\titers: 600, epoch: 2 | loss: 0.0132403\n",
      "\tspeed: 0.0423s/iter; left time: 314.2585s\n",
      "\titers: 700, epoch: 2 | loss: 0.0160454\n",
      "\tspeed: 0.0424s/iter; left time: 310.8119s\n",
      "\titers: 800, epoch: 2 | loss: 0.0115534\n",
      "\tspeed: 0.0423s/iter; left time: 306.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0140562 Vali Loss: 0.0199467 Test Loss: 0.0225555\n",
      "Validation loss decreased (0.020793 --> 0.019947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0083730\n",
      "\tspeed: 0.1528s/iter; left time: 1076.2789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0124742\n",
      "\tspeed: 0.0424s/iter; left time: 294.2786s\n",
      "\titers: 300, epoch: 3 | loss: 0.0106130\n",
      "\tspeed: 0.0423s/iter; left time: 289.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.0110241\n",
      "\tspeed: 0.0424s/iter; left time: 285.8635s\n",
      "\titers: 500, epoch: 3 | loss: 0.0102109\n",
      "\tspeed: 0.0423s/iter; left time: 281.2480s\n",
      "\titers: 600, epoch: 3 | loss: 0.0130316\n",
      "\tspeed: 0.0424s/iter; left time: 277.7369s\n",
      "\titers: 700, epoch: 3 | loss: 0.0093260\n",
      "\tspeed: 0.0424s/iter; left time: 273.1356s\n",
      "\titers: 800, epoch: 3 | loss: 0.0157502\n",
      "\tspeed: 0.0423s/iter; left time: 268.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0125945 Vali Loss: 0.0193660 Test Loss: 0.0214509\n",
      "Validation loss decreased (0.019947 --> 0.019366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121307\n",
      "\tspeed: 0.1530s/iter; left time: 941.0394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0111028\n",
      "\tspeed: 0.0423s/iter; left time: 256.0373s\n",
      "\titers: 300, epoch: 4 | loss: 0.0134106\n",
      "\tspeed: 0.0423s/iter; left time: 252.0329s\n",
      "\titers: 400, epoch: 4 | loss: 0.0094057\n",
      "\tspeed: 0.0423s/iter; left time: 247.6997s\n",
      "\titers: 500, epoch: 4 | loss: 0.0171544\n",
      "\tspeed: 0.0423s/iter; left time: 243.5040s\n",
      "\titers: 600, epoch: 4 | loss: 0.0112910\n",
      "\tspeed: 0.0424s/iter; left time: 239.5752s\n",
      "\titers: 700, epoch: 4 | loss: 0.0110425\n",
      "\tspeed: 0.0423s/iter; left time: 235.0488s\n",
      "\titers: 800, epoch: 4 | loss: 0.0135985\n",
      "\tspeed: 0.0423s/iter; left time: 230.7220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.0120672 Vali Loss: 0.0202044 Test Loss: 0.0227893\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0104726\n",
      "\tspeed: 0.1516s/iter; left time: 797.0310s\n",
      "\titers: 200, epoch: 5 | loss: 0.0081487\n",
      "\tspeed: 0.0425s/iter; left time: 219.0523s\n",
      "\titers: 300, epoch: 5 | loss: 0.0113901\n",
      "\tspeed: 0.0423s/iter; left time: 214.0969s\n",
      "\titers: 400, epoch: 5 | loss: 0.0103068\n",
      "\tspeed: 0.0425s/iter; left time: 210.5952s\n",
      "\titers: 500, epoch: 5 | loss: 0.0112572\n",
      "\tspeed: 0.0424s/iter; left time: 206.1605s\n",
      "\titers: 600, epoch: 5 | loss: 0.0088546\n",
      "\tspeed: 0.0423s/iter; left time: 201.1860s\n",
      "\titers: 700, epoch: 5 | loss: 0.0099310\n",
      "\tspeed: 0.0423s/iter; left time: 197.1133s\n",
      "\titers: 800, epoch: 5 | loss: 0.0101148\n",
      "\tspeed: 0.0424s/iter; left time: 193.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0115217 Vali Loss: 0.0200888 Test Loss: 0.0223086\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0080665\n",
      "\tspeed: 0.1511s/iter; left time: 659.5094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0134688\n",
      "\tspeed: 0.0425s/iter; left time: 181.3065s\n",
      "\titers: 300, epoch: 6 | loss: 0.0091302\n",
      "\tspeed: 0.0423s/iter; left time: 176.3581s\n",
      "\titers: 400, epoch: 6 | loss: 0.0082836\n",
      "\tspeed: 0.0424s/iter; left time: 172.2351s\n",
      "\titers: 500, epoch: 6 | loss: 0.0096623\n",
      "\tspeed: 0.0423s/iter; left time: 167.8155s\n",
      "\titers: 600, epoch: 6 | loss: 0.0109867\n",
      "\tspeed: 0.0426s/iter; left time: 164.5528s\n",
      "\titers: 700, epoch: 6 | loss: 0.0099595\n",
      "\tspeed: 0.0425s/iter; left time: 160.0556s\n",
      "\titers: 800, epoch: 6 | loss: 0.0100367\n",
      "\tspeed: 0.0424s/iter; left time: 155.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0106920 Vali Loss: 0.0210210 Test Loss: 0.0233727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021450931206345558, rmse:0.1464613676071167, mae:0.09386222064495087, rse:0.5172322988510132\n",
      "Original data scale mse:17161886.0, rmse:4142.6904296875, mae:2553.821044921875, rse:0.20598293840885162\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0241524\n",
      "\tspeed: 0.0442s/iter; left time: 390.5160s\n",
      "\titers: 200, epoch: 1 | loss: 0.0150888\n",
      "\tspeed: 0.0424s/iter; left time: 369.8921s\n",
      "\titers: 300, epoch: 1 | loss: 0.0153452\n",
      "\tspeed: 0.0425s/iter; left time: 366.5297s\n",
      "\titers: 400, epoch: 1 | loss: 0.0137540\n",
      "\tspeed: 0.0424s/iter; left time: 362.1092s\n",
      "\titers: 500, epoch: 1 | loss: 0.0163585\n",
      "\tspeed: 0.0427s/iter; left time: 359.7273s\n",
      "\titers: 600, epoch: 1 | loss: 0.0158045\n",
      "\tspeed: 0.0424s/iter; left time: 353.3610s\n",
      "\titers: 700, epoch: 1 | loss: 0.0160179\n",
      "\tspeed: 0.0426s/iter; left time: 350.4453s\n",
      "\titers: 800, epoch: 1 | loss: 0.0174562\n",
      "\tspeed: 0.0425s/iter; left time: 345.5916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.0171803 Vali Loss: 0.0206600 Test Loss: 0.0225042\n",
      "Validation loss decreased (inf --> 0.020660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0152778\n",
      "\tspeed: 0.1551s/iter; left time: 1230.9770s\n",
      "\titers: 200, epoch: 2 | loss: 0.0156064\n",
      "\tspeed: 0.0425s/iter; left time: 332.9020s\n",
      "\titers: 300, epoch: 2 | loss: 0.0138266\n",
      "\tspeed: 0.0424s/iter; left time: 328.0051s\n",
      "\titers: 400, epoch: 2 | loss: 0.0139048\n",
      "\tspeed: 0.0423s/iter; left time: 323.3082s\n",
      "\titers: 500, epoch: 2 | loss: 0.0117401\n",
      "\tspeed: 0.0425s/iter; left time: 320.1448s\n",
      "\titers: 600, epoch: 2 | loss: 0.0119023\n",
      "\tspeed: 0.0426s/iter; left time: 316.7337s\n",
      "\titers: 700, epoch: 2 | loss: 0.0089794\n",
      "\tspeed: 0.0424s/iter; left time: 311.1197s\n",
      "\titers: 800, epoch: 2 | loss: 0.0132081\n",
      "\tspeed: 0.0424s/iter; left time: 306.7376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0139596 Vali Loss: 0.0192198 Test Loss: 0.0214212\n",
      "Validation loss decreased (0.020660 --> 0.019220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0099537\n",
      "\tspeed: 0.1540s/iter; left time: 1084.6870s\n",
      "\titers: 200, epoch: 3 | loss: 0.0112865\n",
      "\tspeed: 0.0424s/iter; left time: 294.6619s\n",
      "\titers: 300, epoch: 3 | loss: 0.0108359\n",
      "\tspeed: 0.0424s/iter; left time: 290.2200s\n",
      "\titers: 400, epoch: 3 | loss: 0.0110285\n",
      "\tspeed: 0.0424s/iter; left time: 285.8407s\n",
      "\titers: 500, epoch: 3 | loss: 0.0130919\n",
      "\tspeed: 0.0424s/iter; left time: 281.7735s\n",
      "\titers: 600, epoch: 3 | loss: 0.0122870\n",
      "\tspeed: 0.0424s/iter; left time: 277.7073s\n",
      "\titers: 700, epoch: 3 | loss: 0.0091051\n",
      "\tspeed: 0.0425s/iter; left time: 274.2129s\n",
      "\titers: 800, epoch: 3 | loss: 0.0105469\n",
      "\tspeed: 0.0424s/iter; left time: 269.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.0125011 Vali Loss: 0.0193032 Test Loss: 0.0212502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0114234\n",
      "\tspeed: 0.1530s/iter; left time: 940.9590s\n",
      "\titers: 200, epoch: 4 | loss: 0.0096694\n",
      "\tspeed: 0.0424s/iter; left time: 256.8145s\n",
      "\titers: 300, epoch: 4 | loss: 0.0103410\n",
      "\tspeed: 0.0425s/iter; left time: 252.6979s\n",
      "\titers: 400, epoch: 4 | loss: 0.0144069\n",
      "\tspeed: 0.0424s/iter; left time: 248.2136s\n",
      "\titers: 500, epoch: 4 | loss: 0.0133314\n",
      "\tspeed: 0.0424s/iter; left time: 244.1232s\n",
      "\titers: 600, epoch: 4 | loss: 0.0128110\n",
      "\tspeed: 0.0424s/iter; left time: 239.8968s\n",
      "\titers: 700, epoch: 4 | loss: 0.0100962\n",
      "\tspeed: 0.0426s/iter; left time: 236.5666s\n",
      "\titers: 800, epoch: 4 | loss: 0.0136120\n",
      "\tspeed: 0.0424s/iter; left time: 231.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0119852 Vali Loss: 0.0194677 Test Loss: 0.0217007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0108032\n",
      "\tspeed: 0.1539s/iter; left time: 809.6166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0102258\n",
      "\tspeed: 0.0425s/iter; left time: 219.2864s\n",
      "\titers: 300, epoch: 5 | loss: 0.0108887\n",
      "\tspeed: 0.0426s/iter; left time: 215.5382s\n",
      "\titers: 400, epoch: 5 | loss: 0.0120689\n",
      "\tspeed: 0.0424s/iter; left time: 210.1471s\n",
      "\titers: 500, epoch: 5 | loss: 0.0079460\n",
      "\tspeed: 0.0423s/iter; left time: 205.3764s\n",
      "\titers: 600, epoch: 5 | loss: 0.0108227\n",
      "\tspeed: 0.0425s/iter; left time: 202.4742s\n",
      "\titers: 700, epoch: 5 | loss: 0.0108111\n",
      "\tspeed: 0.0425s/iter; left time: 197.9847s\n",
      "\titers: 800, epoch: 5 | loss: 0.0116400\n",
      "\tspeed: 0.0424s/iter; left time: 193.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.0113180 Vali Loss: 0.0201557 Test Loss: 0.0224901\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02142123319208622, rmse:0.14635995030403137, mae:0.09442413598299026, rse:0.5168741345405579\n",
      "Original data scale mse:17119326.0, rmse:4137.55078125, mae:2579.4404296875, rse:0.20572736859321594\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0331177\n",
      "\tspeed: 0.0688s/iter; left time: 605.8631s\n",
      "\titers: 200, epoch: 1 | loss: 0.0241566\n",
      "\tspeed: 0.0428s/iter; left time: 372.7624s\n",
      "\titers: 300, epoch: 1 | loss: 0.0251843\n",
      "\tspeed: 0.0427s/iter; left time: 367.4077s\n",
      "\titers: 400, epoch: 1 | loss: 0.0215071\n",
      "\tspeed: 0.0427s/iter; left time: 363.3859s\n",
      "\titers: 500, epoch: 1 | loss: 0.0252792\n",
      "\tspeed: 0.0427s/iter; left time: 359.2813s\n",
      "\titers: 600, epoch: 1 | loss: 0.0215467\n",
      "\tspeed: 0.0427s/iter; left time: 355.2290s\n",
      "\titers: 700, epoch: 1 | loss: 0.0244969\n",
      "\tspeed: 0.0427s/iter; left time: 350.9236s\n",
      "\titers: 800, epoch: 1 | loss: 0.0285908\n",
      "\tspeed: 0.0427s/iter; left time: 346.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 891 | Train Loss: 0.0256955 Vali Loss: 0.0307555 Test Loss: 0.0356706\n",
      "Validation loss decreased (inf --> 0.030756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0246738\n",
      "\tspeed: 0.1551s/iter; left time: 1228.1205s\n",
      "\titers: 200, epoch: 2 | loss: 0.0222918\n",
      "\tspeed: 0.0427s/iter; left time: 333.7058s\n",
      "\titers: 300, epoch: 2 | loss: 0.0204998\n",
      "\tspeed: 0.0426s/iter; left time: 329.2395s\n",
      "\titers: 400, epoch: 2 | loss: 0.0239871\n",
      "\tspeed: 0.0428s/iter; left time: 325.9742s\n",
      "\titers: 500, epoch: 2 | loss: 0.0186084\n",
      "\tspeed: 0.0428s/iter; left time: 321.9454s\n",
      "\titers: 600, epoch: 2 | loss: 0.0180444\n",
      "\tspeed: 0.0427s/iter; left time: 316.8058s\n",
      "\titers: 700, epoch: 2 | loss: 0.0181111\n",
      "\tspeed: 0.0427s/iter; left time: 312.7314s\n",
      "\titers: 800, epoch: 2 | loss: 0.0241413\n",
      "\tspeed: 0.0427s/iter; left time: 308.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.0226432 Vali Loss: 0.0295111 Test Loss: 0.0350451\n",
      "Validation loss decreased (0.030756 --> 0.029511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185620\n",
      "\tspeed: 0.1567s/iter; left time: 1101.4137s\n",
      "\titers: 200, epoch: 3 | loss: 0.0206256\n",
      "\tspeed: 0.0427s/iter; left time: 295.6153s\n",
      "\titers: 300, epoch: 3 | loss: 0.0214388\n",
      "\tspeed: 0.0427s/iter; left time: 291.7330s\n",
      "\titers: 400, epoch: 3 | loss: 0.0203976\n",
      "\tspeed: 0.0427s/iter; left time: 287.2029s\n",
      "\titers: 500, epoch: 3 | loss: 0.0208142\n",
      "\tspeed: 0.0427s/iter; left time: 283.1082s\n",
      "\titers: 600, epoch: 3 | loss: 0.0176320\n",
      "\tspeed: 0.0428s/iter; left time: 279.1515s\n",
      "\titers: 700, epoch: 3 | loss: 0.0211789\n",
      "\tspeed: 0.0427s/iter; left time: 274.3333s\n",
      "\titers: 800, epoch: 3 | loss: 0.0161145\n",
      "\tspeed: 0.0427s/iter; left time: 270.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.0200725 Vali Loss: 0.0318672 Test Loss: 0.0379946\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0187531\n",
      "\tspeed: 0.1520s/iter; left time: 933.2700s\n",
      "\titers: 200, epoch: 4 | loss: 0.0186870\n",
      "\tspeed: 0.0428s/iter; left time: 258.3443s\n",
      "\titers: 300, epoch: 4 | loss: 0.0185298\n",
      "\tspeed: 0.0429s/iter; left time: 254.6091s\n",
      "\titers: 400, epoch: 4 | loss: 0.0159659\n",
      "\tspeed: 0.0426s/iter; left time: 248.8959s\n",
      "\titers: 500, epoch: 4 | loss: 0.0174854\n",
      "\tspeed: 0.0428s/iter; left time: 245.4871s\n",
      "\titers: 600, epoch: 4 | loss: 0.0168278\n",
      "\tspeed: 0.0429s/iter; left time: 241.8599s\n",
      "\titers: 700, epoch: 4 | loss: 0.0153451\n",
      "\tspeed: 0.0427s/iter; left time: 236.4684s\n",
      "\titers: 800, epoch: 4 | loss: 0.0127366\n",
      "\tspeed: 0.0427s/iter; left time: 232.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.0159453 Vali Loss: 0.0339835 Test Loss: 0.0441837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0123417\n",
      "\tspeed: 0.1516s/iter; left time: 795.6708s\n",
      "\titers: 200, epoch: 5 | loss: 0.0116674\n",
      "\tspeed: 0.0424s/iter; left time: 218.1896s\n",
      "\titers: 300, epoch: 5 | loss: 0.0138313\n",
      "\tspeed: 0.0427s/iter; left time: 215.5624s\n",
      "\titers: 400, epoch: 5 | loss: 0.0120017\n",
      "\tspeed: 0.0428s/iter; left time: 211.5992s\n",
      "\titers: 500, epoch: 5 | loss: 0.0106340\n",
      "\tspeed: 0.0426s/iter; left time: 206.4859s\n",
      "\titers: 600, epoch: 5 | loss: 0.0108038\n",
      "\tspeed: 0.0427s/iter; left time: 202.8386s\n",
      "\titers: 700, epoch: 5 | loss: 0.0110587\n",
      "\tspeed: 0.0426s/iter; left time: 198.1594s\n",
      "\titers: 800, epoch: 5 | loss: 0.0086651\n",
      "\tspeed: 0.0427s/iter; left time: 194.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.0115554 Vali Loss: 0.0384158 Test Loss: 0.0489048\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.035045064985752106, rmse:0.1872032731771469, mae:0.12920968234539032, rse:0.6629246473312378\n",
      "Original data scale mse:30968164.0, rmse:5564.90478515625, mae:3569.146484375, rse:0.2771342396736145\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0252734\n",
      "\tspeed: 0.0445s/iter; left time: 392.1205s\n",
      "\titers: 200, epoch: 1 | loss: 0.0225215\n",
      "\tspeed: 0.0426s/iter; left time: 371.3740s\n",
      "\titers: 300, epoch: 1 | loss: 0.0298266\n",
      "\tspeed: 0.0426s/iter; left time: 367.0374s\n",
      "\titers: 400, epoch: 1 | loss: 0.0298059\n",
      "\tspeed: 0.0427s/iter; left time: 363.0781s\n",
      "\titers: 500, epoch: 1 | loss: 0.0215589\n",
      "\tspeed: 0.0427s/iter; left time: 358.8407s\n",
      "\titers: 600, epoch: 1 | loss: 0.0275637\n",
      "\tspeed: 0.0427s/iter; left time: 355.0823s\n",
      "\titers: 700, epoch: 1 | loss: 0.0242801\n",
      "\tspeed: 0.0427s/iter; left time: 350.3681s\n",
      "\titers: 800, epoch: 1 | loss: 0.0225968\n",
      "\tspeed: 0.0426s/iter; left time: 345.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.0256559 Vali Loss: 0.0307612 Test Loss: 0.0356008\n",
      "Validation loss decreased (inf --> 0.030761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0234988\n",
      "\tspeed: 0.1564s/iter; left time: 1238.5551s\n",
      "\titers: 200, epoch: 2 | loss: 0.0206265\n",
      "\tspeed: 0.0428s/iter; left time: 334.7831s\n",
      "\titers: 300, epoch: 2 | loss: 0.0227529\n",
      "\tspeed: 0.0427s/iter; left time: 329.8608s\n",
      "\titers: 400, epoch: 2 | loss: 0.0226817\n",
      "\tspeed: 0.0428s/iter; left time: 325.8458s\n",
      "\titers: 500, epoch: 2 | loss: 0.0179773\n",
      "\tspeed: 0.0428s/iter; left time: 321.5871s\n",
      "\titers: 600, epoch: 2 | loss: 0.0216318\n",
      "\tspeed: 0.0427s/iter; left time: 316.9104s\n",
      "\titers: 700, epoch: 2 | loss: 0.0251577\n",
      "\tspeed: 0.0427s/iter; left time: 312.4019s\n",
      "\titers: 800, epoch: 2 | loss: 0.0213571\n",
      "\tspeed: 0.0427s/iter; left time: 308.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.0226894 Vali Loss: 0.0294289 Test Loss: 0.0360354\n",
      "Validation loss decreased (0.030761 --> 0.029429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0220962\n",
      "\tspeed: 0.1567s/iter; left time: 1101.4733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0182221\n",
      "\tspeed: 0.0428s/iter; left time: 296.4807s\n",
      "\titers: 300, epoch: 3 | loss: 0.0183425\n",
      "\tspeed: 0.0427s/iter; left time: 291.8833s\n",
      "\titers: 400, epoch: 3 | loss: 0.0183479\n",
      "\tspeed: 0.0426s/iter; left time: 286.9705s\n",
      "\titers: 500, epoch: 3 | loss: 0.0169455\n",
      "\tspeed: 0.0427s/iter; left time: 283.0014s\n",
      "\titers: 600, epoch: 3 | loss: 0.0196326\n",
      "\tspeed: 0.0426s/iter; left time: 278.3288s\n",
      "\titers: 700, epoch: 3 | loss: 0.0224708\n",
      "\tspeed: 0.0427s/iter; left time: 274.3768s\n",
      "\titers: 800, epoch: 3 | loss: 0.0191012\n",
      "\tspeed: 0.0427s/iter; left time: 270.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.0196020 Vali Loss: 0.0333951 Test Loss: 0.0427147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0156322\n",
      "\tspeed: 0.1528s/iter; left time: 938.0043s\n",
      "\titers: 200, epoch: 4 | loss: 0.0144624\n",
      "\tspeed: 0.0428s/iter; left time: 258.4770s\n",
      "\titers: 300, epoch: 4 | loss: 0.0155768\n",
      "\tspeed: 0.0428s/iter; left time: 254.0572s\n",
      "\titers: 400, epoch: 4 | loss: 0.0152853\n",
      "\tspeed: 0.0427s/iter; left time: 249.0260s\n",
      "\titers: 500, epoch: 4 | loss: 0.0136205\n",
      "\tspeed: 0.0427s/iter; left time: 244.7655s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151473\n",
      "\tspeed: 0.0427s/iter; left time: 240.4703s\n",
      "\titers: 700, epoch: 4 | loss: 0.0167133\n",
      "\tspeed: 0.0427s/iter; left time: 236.6188s\n",
      "\titers: 800, epoch: 4 | loss: 0.0141558\n",
      "\tspeed: 0.0427s/iter; left time: 232.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.0154854 Vali Loss: 0.0368914 Test Loss: 0.0445472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0125562\n",
      "\tspeed: 0.1529s/iter; left time: 802.0953s\n",
      "\titers: 200, epoch: 5 | loss: 0.0119047\n",
      "\tspeed: 0.0428s/iter; left time: 220.1003s\n",
      "\titers: 300, epoch: 5 | loss: 0.0114228\n",
      "\tspeed: 0.0428s/iter; left time: 216.1855s\n",
      "\titers: 400, epoch: 5 | loss: 0.0124558\n",
      "\tspeed: 0.0429s/iter; left time: 211.9926s\n",
      "\titers: 500, epoch: 5 | loss: 0.0095058\n",
      "\tspeed: 0.0428s/iter; left time: 207.6617s\n",
      "\titers: 600, epoch: 5 | loss: 0.0092139\n",
      "\tspeed: 0.0428s/iter; left time: 202.9588s\n",
      "\titers: 700, epoch: 5 | loss: 0.0101714\n",
      "\tspeed: 0.0427s/iter; left time: 198.3543s\n",
      "\titers: 800, epoch: 5 | loss: 0.0099094\n",
      "\tspeed: 0.0427s/iter; left time: 194.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.0113700 Vali Loss: 0.0386358 Test Loss: 0.0474626\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03603537380695343, rmse:0.18982985615730286, mae:0.13202139735221863, rse:0.6722258925437927\n",
      "Original data scale mse:32859850.0, rmse:5732.35107421875, mae:3690.53515625, rse:0.28547313809394836\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0336958\n",
      "\tspeed: 0.0675s/iter; left time: 593.0589s\n",
      "\titers: 200, epoch: 1 | loss: 0.0275518\n",
      "\tspeed: 0.0433s/iter; left time: 375.9451s\n",
      "\titers: 300, epoch: 1 | loss: 0.0277910\n",
      "\tspeed: 0.0432s/iter; left time: 371.1693s\n",
      "\titers: 400, epoch: 1 | loss: 0.0320238\n",
      "\tspeed: 0.0433s/iter; left time: 367.7548s\n",
      "\titers: 500, epoch: 1 | loss: 0.0305507\n",
      "\tspeed: 0.0433s/iter; left time: 363.0654s\n",
      "\titers: 600, epoch: 1 | loss: 0.0266151\n",
      "\tspeed: 0.0432s/iter; left time: 358.4262s\n",
      "\titers: 700, epoch: 1 | loss: 0.0258001\n",
      "\tspeed: 0.0433s/iter; left time: 354.4698s\n",
      "\titers: 800, epoch: 1 | loss: 0.0265895\n",
      "\tspeed: 0.0432s/iter; left time: 349.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 889 | Train Loss: 0.0275991 Vali Loss: 0.0321770 Test Loss: 0.0377074\n",
      "Validation loss decreased (inf --> 0.032177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0269805\n",
      "\tspeed: 0.1560s/iter; left time: 1233.0749s\n",
      "\titers: 200, epoch: 2 | loss: 0.0223709\n",
      "\tspeed: 0.0432s/iter; left time: 336.9347s\n",
      "\titers: 300, epoch: 2 | loss: 0.0284553\n",
      "\tspeed: 0.0432s/iter; left time: 333.0484s\n",
      "\titers: 400, epoch: 2 | loss: 0.0243248\n",
      "\tspeed: 0.0432s/iter; left time: 328.7509s\n",
      "\titers: 500, epoch: 2 | loss: 0.0235313\n",
      "\tspeed: 0.0432s/iter; left time: 324.2022s\n",
      "\titers: 600, epoch: 2 | loss: 0.0243723\n",
      "\tspeed: 0.0432s/iter; left time: 320.0285s\n",
      "\titers: 700, epoch: 2 | loss: 0.0205655\n",
      "\tspeed: 0.0432s/iter; left time: 315.2636s\n",
      "\titers: 800, epoch: 2 | loss: 0.0245541\n",
      "\tspeed: 0.0432s/iter; left time: 311.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.0243995 Vali Loss: 0.0313660 Test Loss: 0.0386110\n",
      "Validation loss decreased (0.032177 --> 0.031366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0219679\n",
      "\tspeed: 0.1570s/iter; left time: 1101.0176s\n",
      "\titers: 200, epoch: 3 | loss: 0.0185651\n",
      "\tspeed: 0.0432s/iter; left time: 298.9773s\n",
      "\titers: 300, epoch: 3 | loss: 0.0216196\n",
      "\tspeed: 0.0432s/iter; left time: 294.5004s\n",
      "\titers: 400, epoch: 3 | loss: 0.0229394\n",
      "\tspeed: 0.0432s/iter; left time: 289.8230s\n",
      "\titers: 500, epoch: 3 | loss: 0.0231433\n",
      "\tspeed: 0.0432s/iter; left time: 285.8395s\n",
      "\titers: 600, epoch: 3 | loss: 0.0202164\n",
      "\tspeed: 0.0433s/iter; left time: 281.8551s\n",
      "\titers: 700, epoch: 3 | loss: 0.0192351\n",
      "\tspeed: 0.0432s/iter; left time: 277.1798s\n",
      "\titers: 800, epoch: 3 | loss: 0.0171767\n",
      "\tspeed: 0.0433s/iter; left time: 273.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.0199984 Vali Loss: 0.0360289 Test Loss: 0.0455055\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0162297\n",
      "\tspeed: 0.1534s/iter; left time: 939.1968s\n",
      "\titers: 200, epoch: 4 | loss: 0.0124574\n",
      "\tspeed: 0.0432s/iter; left time: 260.2186s\n",
      "\titers: 300, epoch: 4 | loss: 0.0172678\n",
      "\tspeed: 0.0433s/iter; left time: 256.2979s\n",
      "\titers: 400, epoch: 4 | loss: 0.0153522\n",
      "\tspeed: 0.0433s/iter; left time: 252.2440s\n",
      "\titers: 500, epoch: 4 | loss: 0.0137240\n",
      "\tspeed: 0.0433s/iter; left time: 247.8063s\n",
      "\titers: 600, epoch: 4 | loss: 0.0138512\n",
      "\tspeed: 0.0432s/iter; left time: 243.2112s\n",
      "\titers: 700, epoch: 4 | loss: 0.0129080\n",
      "\tspeed: 0.0432s/iter; left time: 238.8926s\n",
      "\titers: 800, epoch: 4 | loss: 0.0131985\n",
      "\tspeed: 0.0432s/iter; left time: 234.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.0146474 Vali Loss: 0.0382402 Test Loss: 0.0497850\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0118652\n",
      "\tspeed: 0.1537s/iter; left time: 804.4823s\n",
      "\titers: 200, epoch: 5 | loss: 0.0103289\n",
      "\tspeed: 0.0432s/iter; left time: 221.8596s\n",
      "\titers: 300, epoch: 5 | loss: 0.0110708\n",
      "\tspeed: 0.0433s/iter; left time: 218.1787s\n",
      "\titers: 400, epoch: 5 | loss: 0.0107497\n",
      "\tspeed: 0.0433s/iter; left time: 213.5859s\n",
      "\titers: 500, epoch: 5 | loss: 0.0105743\n",
      "\tspeed: 0.0434s/iter; left time: 209.6938s\n",
      "\titers: 600, epoch: 5 | loss: 0.0096314\n",
      "\tspeed: 0.0433s/iter; left time: 204.8333s\n",
      "\titers: 700, epoch: 5 | loss: 0.0106433\n",
      "\tspeed: 0.0433s/iter; left time: 200.7063s\n",
      "\titers: 800, epoch: 5 | loss: 0.0091215\n",
      "\tspeed: 0.0432s/iter; left time: 196.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0104776 Vali Loss: 0.0408016 Test Loss: 0.0518497\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03861093893647194, rmse:0.19649666547775269, mae:0.13665854930877686, rse:0.6961284875869751\n",
      "Original data scale mse:35078208.0, rmse:5922.68603515625, mae:3812.864501953125, rse:0.29509666562080383\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0359611\n",
      "\tspeed: 0.0456s/iter; left time: 400.9014s\n",
      "\titers: 200, epoch: 1 | loss: 0.0305847\n",
      "\tspeed: 0.0432s/iter; left time: 375.6016s\n",
      "\titers: 300, epoch: 1 | loss: 0.0329304\n",
      "\tspeed: 0.0433s/iter; left time: 371.7022s\n",
      "\titers: 400, epoch: 1 | loss: 0.0310998\n",
      "\tspeed: 0.0432s/iter; left time: 366.6693s\n",
      "\titers: 500, epoch: 1 | loss: 0.0275226\n",
      "\tspeed: 0.0433s/iter; left time: 362.9298s\n",
      "\titers: 600, epoch: 1 | loss: 0.0220132\n",
      "\tspeed: 0.0433s/iter; left time: 358.7802s\n",
      "\titers: 700, epoch: 1 | loss: 0.0255434\n",
      "\tspeed: 0.0432s/iter; left time: 353.8894s\n",
      "\titers: 800, epoch: 1 | loss: 0.0230196\n",
      "\tspeed: 0.0432s/iter; left time: 349.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.0276503 Vali Loss: 0.0320385 Test Loss: 0.0376059\n",
      "Validation loss decreased (inf --> 0.032038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0272676\n",
      "\tspeed: 0.1604s/iter; left time: 1267.5499s\n",
      "\titers: 200, epoch: 2 | loss: 0.0250907\n",
      "\tspeed: 0.0433s/iter; left time: 337.6219s\n",
      "\titers: 300, epoch: 2 | loss: 0.0260860\n",
      "\tspeed: 0.0432s/iter; left time: 332.7208s\n",
      "\titers: 400, epoch: 2 | loss: 0.0250327\n",
      "\tspeed: 0.0432s/iter; left time: 328.5671s\n",
      "\titers: 500, epoch: 2 | loss: 0.0255473\n",
      "\tspeed: 0.0432s/iter; left time: 324.3145s\n",
      "\titers: 600, epoch: 2 | loss: 0.0246568\n",
      "\tspeed: 0.0430s/iter; left time: 318.2438s\n",
      "\titers: 700, epoch: 2 | loss: 0.0225364\n",
      "\tspeed: 0.0430s/iter; left time: 314.0164s\n",
      "\titers: 800, epoch: 2 | loss: 0.0225365\n",
      "\tspeed: 0.0431s/iter; left time: 310.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.0244215 Vali Loss: 0.0325945 Test Loss: 0.0400992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0186854\n",
      "\tspeed: 0.1547s/iter; left time: 1084.8794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0189317\n",
      "\tspeed: 0.0432s/iter; left time: 298.5707s\n",
      "\titers: 300, epoch: 3 | loss: 0.0232559\n",
      "\tspeed: 0.0431s/iter; left time: 293.3315s\n",
      "\titers: 400, epoch: 3 | loss: 0.0214100\n",
      "\tspeed: 0.0433s/iter; left time: 290.5354s\n",
      "\titers: 500, epoch: 3 | loss: 0.0183989\n",
      "\tspeed: 0.0432s/iter; left time: 285.8838s\n",
      "\titers: 600, epoch: 3 | loss: 0.0202461\n",
      "\tspeed: 0.0432s/iter; left time: 281.1114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0178831\n",
      "\tspeed: 0.0432s/iter; left time: 277.1765s\n",
      "\titers: 800, epoch: 3 | loss: 0.0169872\n",
      "\tspeed: 0.0432s/iter; left time: 272.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 889 | Train Loss: 0.0194532 Vali Loss: 0.0351343 Test Loss: 0.0476060\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0156688\n",
      "\tspeed: 0.1542s/iter; left time: 944.4341s\n",
      "\titers: 200, epoch: 4 | loss: 0.0136872\n",
      "\tspeed: 0.0433s/iter; left time: 261.0068s\n",
      "\titers: 300, epoch: 4 | loss: 0.0140966\n",
      "\tspeed: 0.0433s/iter; left time: 256.3088s\n",
      "\titers: 400, epoch: 4 | loss: 0.0138336\n",
      "\tspeed: 0.0432s/iter; left time: 251.7475s\n",
      "\titers: 500, epoch: 4 | loss: 0.0124785\n",
      "\tspeed: 0.0432s/iter; left time: 247.4439s\n",
      "\titers: 600, epoch: 4 | loss: 0.0119031\n",
      "\tspeed: 0.0433s/iter; left time: 243.3074s\n",
      "\titers: 700, epoch: 4 | loss: 0.0155341\n",
      "\tspeed: 0.0432s/iter; left time: 238.6934s\n",
      "\titers: 800, epoch: 4 | loss: 0.0122225\n",
      "\tspeed: 0.0432s/iter; left time: 234.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0139439 Vali Loss: 0.0402674 Test Loss: 0.0492468\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0376058854162693, rmse:0.19392237067222595, mae:0.1368750035762787, rse:0.6870085597038269\n",
      "Original data scale mse:34050108.0, rmse:5835.2470703125, mae:3839.478271484375, rse:0.290740042924881\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1350967\n",
      "\tspeed: 0.0675s/iter; left time: 596.3538s\n",
      "\titers: 200, epoch: 1 | loss: 0.1420312\n",
      "\tspeed: 0.0425s/iter; left time: 371.3936s\n",
      "\titers: 300, epoch: 1 | loss: 0.1255292\n",
      "\tspeed: 0.0425s/iter; left time: 366.8999s\n",
      "\titers: 400, epoch: 1 | loss: 0.1363435\n",
      "\tspeed: 0.0425s/iter; left time: 362.7567s\n",
      "\titers: 500, epoch: 1 | loss: 0.1305171\n",
      "\tspeed: 0.0425s/iter; left time: 358.7195s\n",
      "\titers: 600, epoch: 1 | loss: 0.1424945\n",
      "\tspeed: 0.0425s/iter; left time: 353.8047s\n",
      "\titers: 700, epoch: 1 | loss: 0.1252133\n",
      "\tspeed: 0.0427s/iter; left time: 351.3114s\n",
      "\titers: 800, epoch: 1 | loss: 0.1236854\n",
      "\tspeed: 0.0425s/iter; left time: 345.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.1290060 Vali Loss: 0.0206608 Test Loss: 0.0223194\n",
      "Validation loss decreased (inf --> 0.020661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1363344\n",
      "\tspeed: 0.1542s/iter; left time: 1224.1825s\n",
      "\titers: 200, epoch: 2 | loss: 0.1335109\n",
      "\tspeed: 0.0426s/iter; left time: 333.7850s\n",
      "\titers: 300, epoch: 2 | loss: 0.1115886\n",
      "\tspeed: 0.0425s/iter; left time: 328.7855s\n",
      "\titers: 400, epoch: 2 | loss: 0.1164773\n",
      "\tspeed: 0.0425s/iter; left time: 324.6873s\n",
      "\titers: 500, epoch: 2 | loss: 0.1129846\n",
      "\tspeed: 0.0425s/iter; left time: 320.4549s\n",
      "\titers: 600, epoch: 2 | loss: 0.1131861\n",
      "\tspeed: 0.0425s/iter; left time: 316.1980s\n",
      "\titers: 700, epoch: 2 | loss: 0.1245049\n",
      "\tspeed: 0.0424s/iter; left time: 311.3802s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075016\n",
      "\tspeed: 0.0425s/iter; left time: 307.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.1182092 Vali Loss: 0.0202321 Test Loss: 0.0226576\n",
      "Validation loss decreased (0.020661 --> 0.020232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0917212\n",
      "\tspeed: 0.1554s/iter; left time: 1094.4983s\n",
      "\titers: 200, epoch: 3 | loss: 0.1115365\n",
      "\tspeed: 0.0426s/iter; left time: 295.6504s\n",
      "\titers: 300, epoch: 3 | loss: 0.1022477\n",
      "\tspeed: 0.0426s/iter; left time: 291.3312s\n",
      "\titers: 400, epoch: 3 | loss: 0.1051710\n",
      "\tspeed: 0.0425s/iter; left time: 286.8327s\n",
      "\titers: 500, epoch: 3 | loss: 0.1028769\n",
      "\tspeed: 0.0425s/iter; left time: 282.1794s\n",
      "\titers: 600, epoch: 3 | loss: 0.1118995\n",
      "\tspeed: 0.0425s/iter; left time: 277.8460s\n",
      "\titers: 700, epoch: 3 | loss: 0.0920849\n",
      "\tspeed: 0.0426s/iter; left time: 274.5434s\n",
      "\titers: 800, epoch: 3 | loss: 0.1228990\n",
      "\tspeed: 0.0424s/iter; left time: 269.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.1119564 Vali Loss: 0.0195025 Test Loss: 0.0215181\n",
      "Validation loss decreased (0.020232 --> 0.019503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1056295\n",
      "\tspeed: 0.1549s/iter; left time: 953.1333s\n",
      "\titers: 200, epoch: 4 | loss: 0.1062738\n",
      "\tspeed: 0.0425s/iter; left time: 257.3976s\n",
      "\titers: 300, epoch: 4 | loss: 0.1069851\n",
      "\tspeed: 0.0425s/iter; left time: 252.6865s\n",
      "\titers: 400, epoch: 4 | loss: 0.0964099\n",
      "\tspeed: 0.0424s/iter; left time: 248.3499s\n",
      "\titers: 500, epoch: 4 | loss: 0.1313533\n",
      "\tspeed: 0.0426s/iter; left time: 244.9283s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023512\n",
      "\tspeed: 0.0425s/iter; left time: 240.3528s\n",
      "\titers: 700, epoch: 4 | loss: 0.1074806\n",
      "\tspeed: 0.0424s/iter; left time: 235.5697s\n",
      "\titers: 800, epoch: 4 | loss: 0.1164315\n",
      "\tspeed: 0.0424s/iter; left time: 231.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.1090867 Vali Loss: 0.0199321 Test Loss: 0.0221008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1024238\n",
      "\tspeed: 0.1528s/iter; left time: 803.4116s\n",
      "\titers: 200, epoch: 5 | loss: 0.0909193\n",
      "\tspeed: 0.0426s/iter; left time: 219.8146s\n",
      "\titers: 300, epoch: 5 | loss: 0.1086716\n",
      "\tspeed: 0.0425s/iter; left time: 215.0014s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993418\n",
      "\tspeed: 0.0425s/iter; left time: 210.6249s\n",
      "\titers: 500, epoch: 5 | loss: 0.1037285\n",
      "\tspeed: 0.0425s/iter; left time: 206.4401s\n",
      "\titers: 600, epoch: 5 | loss: 0.0967105\n",
      "\tspeed: 0.0424s/iter; left time: 201.7542s\n",
      "\titers: 700, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0425s/iter; left time: 198.0248s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025381\n",
      "\tspeed: 0.0426s/iter; left time: 194.0126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.1068112 Vali Loss: 0.0196992 Test Loss: 0.0221876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0923343\n",
      "\tspeed: 0.1523s/iter; left time: 665.0950s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151687\n",
      "\tspeed: 0.0424s/iter; left time: 180.9051s\n",
      "\titers: 300, epoch: 6 | loss: 0.0963678\n",
      "\tspeed: 0.0424s/iter; left time: 176.7065s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901735\n",
      "\tspeed: 0.0424s/iter; left time: 172.4124s\n",
      "\titers: 500, epoch: 6 | loss: 0.0988669\n",
      "\tspeed: 0.0427s/iter; left time: 169.2106s\n",
      "\titers: 600, epoch: 6 | loss: 0.1059128\n",
      "\tspeed: 0.0426s/iter; left time: 164.7692s\n",
      "\titers: 700, epoch: 6 | loss: 0.0918537\n",
      "\tspeed: 0.0426s/iter; left time: 160.3288s\n",
      "\titers: 800, epoch: 6 | loss: 0.1067557\n",
      "\tspeed: 0.0424s/iter; left time: 155.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.1031106 Vali Loss: 0.0214505 Test Loss: 0.0241462\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021518126130104065, rmse:0.14669057726860046, mae:0.0940595418214798, rse:0.5180417895317078\n",
      "Original data scale mse:17274290.0, rmse:4156.23486328125, mae:2560.883056640625, rse:0.20665638148784637\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1545426\n",
      "\tspeed: 0.0445s/iter; left time: 393.3964s\n",
      "\titers: 200, epoch: 1 | loss: 0.1211924\n",
      "\tspeed: 0.0424s/iter; left time: 370.4084s\n",
      "\titers: 300, epoch: 1 | loss: 0.1232815\n",
      "\tspeed: 0.0425s/iter; left time: 366.5918s\n",
      "\titers: 400, epoch: 1 | loss: 0.1164890\n",
      "\tspeed: 0.0424s/iter; left time: 361.9116s\n",
      "\titers: 500, epoch: 1 | loss: 0.1270251\n",
      "\tspeed: 0.0424s/iter; left time: 357.7636s\n",
      "\titers: 600, epoch: 1 | loss: 0.1249656\n",
      "\tspeed: 0.0425s/iter; left time: 353.6757s\n",
      "\titers: 700, epoch: 1 | loss: 0.1255756\n",
      "\tspeed: 0.0425s/iter; left time: 350.1521s\n",
      "\titers: 800, epoch: 1 | loss: 0.1321101\n",
      "\tspeed: 0.0425s/iter; left time: 345.7987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.1289450 Vali Loss: 0.0205260 Test Loss: 0.0223603\n",
      "Validation loss decreased (inf --> 0.020526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1247080\n",
      "\tspeed: 0.1555s/iter; left time: 1234.3744s\n",
      "\titers: 200, epoch: 2 | loss: 0.1241332\n",
      "\tspeed: 0.0424s/iter; left time: 332.6072s\n",
      "\titers: 300, epoch: 2 | loss: 0.1169892\n",
      "\tspeed: 0.0425s/iter; left time: 328.5593s\n",
      "\titers: 400, epoch: 2 | loss: 0.1169359\n",
      "\tspeed: 0.0425s/iter; left time: 324.3965s\n",
      "\titers: 500, epoch: 2 | loss: 0.1100132\n",
      "\tspeed: 0.0424s/iter; left time: 319.7414s\n",
      "\titers: 600, epoch: 2 | loss: 0.1097182\n",
      "\tspeed: 0.0427s/iter; left time: 317.2649s\n",
      "\titers: 700, epoch: 2 | loss: 0.0934435\n",
      "\tspeed: 0.0427s/iter; left time: 313.1296s\n",
      "\titers: 800, epoch: 2 | loss: 0.1157354\n",
      "\tspeed: 0.0425s/iter; left time: 307.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.1178395 Vali Loss: 0.0192519 Test Loss: 0.0214008\n",
      "Validation loss decreased (0.020526 --> 0.019252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0992918\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059680\n",
      "\tspeed: 0.0425s/iter; left time: 294.9487s\n",
      "\titers: 300, epoch: 3 | loss: 0.1040523\n",
      "\tspeed: 0.0426s/iter; left time: 291.4055s\n",
      "\titers: 400, epoch: 3 | loss: 0.1044981\n",
      "\tspeed: 0.0425s/iter; left time: 286.3297s\n",
      "\titers: 500, epoch: 3 | loss: 0.1093330\n",
      "\tspeed: 0.0424s/iter; left time: 281.7873s\n",
      "\titers: 600, epoch: 3 | loss: 0.1081880\n",
      "\tspeed: 0.0424s/iter; left time: 277.5301s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950932\n",
      "\tspeed: 0.0424s/iter; left time: 273.0997s\n",
      "\titers: 800, epoch: 3 | loss: 0.1036208\n",
      "\tspeed: 0.0425s/iter; left time: 269.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1118597 Vali Loss: 0.0194159 Test Loss: 0.0213597\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077452\n",
      "\tspeed: 0.1516s/iter; left time: 932.9019s\n",
      "\titers: 200, epoch: 4 | loss: 0.0975025\n",
      "\tspeed: 0.0425s/iter; left time: 257.2398s\n",
      "\titers: 300, epoch: 4 | loss: 0.1057355\n",
      "\tspeed: 0.0425s/iter; left time: 252.7828s\n",
      "\titers: 400, epoch: 4 | loss: 0.1173507\n",
      "\tspeed: 0.0425s/iter; left time: 248.8110s\n",
      "\titers: 500, epoch: 4 | loss: 0.1149111\n",
      "\tspeed: 0.0425s/iter; left time: 244.5340s\n",
      "\titers: 600, epoch: 4 | loss: 0.1181302\n",
      "\tspeed: 0.0425s/iter; left time: 240.1403s\n",
      "\titers: 700, epoch: 4 | loss: 0.1015757\n",
      "\tspeed: 0.0424s/iter; left time: 235.5759s\n",
      "\titers: 800, epoch: 4 | loss: 0.1176182\n",
      "\tspeed: 0.0425s/iter; left time: 231.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1092216 Vali Loss: 0.0199139 Test Loss: 0.0219621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1028859\n",
      "\tspeed: 0.1511s/iter; left time: 794.5016s\n",
      "\titers: 200, epoch: 5 | loss: 0.1025548\n",
      "\tspeed: 0.0425s/iter; left time: 219.4566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1054140\n",
      "\tspeed: 0.0425s/iter; left time: 214.8455s\n",
      "\titers: 400, epoch: 5 | loss: 0.1111270\n",
      "\tspeed: 0.0425s/iter; left time: 210.7226s\n",
      "\titers: 500, epoch: 5 | loss: 0.0901895\n",
      "\tspeed: 0.0425s/iter; left time: 206.2743s\n",
      "\titers: 600, epoch: 5 | loss: 0.1091653\n",
      "\tspeed: 0.0425s/iter; left time: 202.0335s\n",
      "\titers: 700, epoch: 5 | loss: 0.1024881\n",
      "\tspeed: 0.0424s/iter; left time: 197.7389s\n",
      "\titers: 800, epoch: 5 | loss: 0.1036616\n",
      "\tspeed: 0.0426s/iter; left time: 194.3663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1065149 Vali Loss: 0.0199545 Test Loss: 0.0224478\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02140084095299244, rmse:0.14629025757312775, mae:0.09408330172300339, rse:0.5166280269622803\n",
      "Original data scale mse:17063130.0, rmse:4130.75439453125, mae:2569.022216796875, rse:0.20538942515850067\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1814623\n",
      "\tspeed: 0.0676s/iter; left time: 595.9939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1549098\n",
      "\tspeed: 0.0428s/iter; left time: 372.5763s\n",
      "\titers: 300, epoch: 1 | loss: 0.1584294\n",
      "\tspeed: 0.0428s/iter; left time: 368.8041s\n",
      "\titers: 400, epoch: 1 | loss: 0.1463351\n",
      "\tspeed: 0.0428s/iter; left time: 364.0468s\n",
      "\titers: 500, epoch: 1 | loss: 0.1587598\n",
      "\tspeed: 0.0429s/iter; left time: 360.7863s\n",
      "\titers: 600, epoch: 1 | loss: 0.1465916\n",
      "\tspeed: 0.0429s/iter; left time: 356.2721s\n",
      "\titers: 700, epoch: 1 | loss: 0.1560166\n",
      "\tspeed: 0.0428s/iter; left time: 351.3457s\n",
      "\titers: 800, epoch: 1 | loss: 0.1685595\n",
      "\tspeed: 0.0429s/iter; left time: 347.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.1594781 Vali Loss: 0.0307007 Test Loss: 0.0356316\n",
      "Validation loss decreased (inf --> 0.030701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1568940\n",
      "\tspeed: 0.1541s/iter; left time: 1220.4008s\n",
      "\titers: 200, epoch: 2 | loss: 0.1489389\n",
      "\tspeed: 0.0430s/iter; left time: 335.9917s\n",
      "\titers: 300, epoch: 2 | loss: 0.1422157\n",
      "\tspeed: 0.0429s/iter; left time: 331.3679s\n",
      "\titers: 400, epoch: 2 | loss: 0.1543713\n",
      "\tspeed: 0.0428s/iter; left time: 326.0290s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362207\n",
      "\tspeed: 0.0429s/iter; left time: 322.5290s\n",
      "\titers: 600, epoch: 2 | loss: 0.1331256\n",
      "\tspeed: 0.0428s/iter; left time: 317.3910s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337022\n",
      "\tspeed: 0.0428s/iter; left time: 313.4602s\n",
      "\titers: 800, epoch: 2 | loss: 0.1568871\n",
      "\tspeed: 0.0428s/iter; left time: 309.1001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.1500987 Vali Loss: 0.0296340 Test Loss: 0.0350939\n",
      "Validation loss decreased (0.030701 --> 0.029634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377389\n",
      "\tspeed: 0.1593s/iter; left time: 1119.9292s\n",
      "\titers: 200, epoch: 3 | loss: 0.1435285\n",
      "\tspeed: 0.0429s/iter; left time: 297.3758s\n",
      "\titers: 300, epoch: 3 | loss: 0.1495669\n",
      "\tspeed: 0.0430s/iter; left time: 293.4450s\n",
      "\titers: 400, epoch: 3 | loss: 0.1420835\n",
      "\tspeed: 0.0429s/iter; left time: 288.8701s\n",
      "\titers: 500, epoch: 3 | loss: 0.1486267\n",
      "\tspeed: 0.0429s/iter; left time: 284.1410s\n",
      "\titers: 600, epoch: 3 | loss: 0.1295402\n",
      "\tspeed: 0.0428s/iter; left time: 279.2172s\n",
      "\titers: 700, epoch: 3 | loss: 0.1468042\n",
      "\tspeed: 0.0428s/iter; left time: 275.2522s\n",
      "\titers: 800, epoch: 3 | loss: 0.1282526\n",
      "\tspeed: 0.0427s/iter; left time: 270.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 891 | Train Loss: 0.1414028 Vali Loss: 0.0320937 Test Loss: 0.0387196\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1363539\n",
      "\tspeed: 0.1522s/iter; left time: 934.2523s\n",
      "\titers: 200, epoch: 4 | loss: 0.1375028\n",
      "\tspeed: 0.0428s/iter; left time: 258.4950s\n",
      "\titers: 300, epoch: 4 | loss: 0.1330649\n",
      "\tspeed: 0.0428s/iter; left time: 253.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.1284030\n",
      "\tspeed: 0.0429s/iter; left time: 250.5335s\n",
      "\titers: 500, epoch: 4 | loss: 0.1296627\n",
      "\tspeed: 0.0428s/iter; left time: 245.4922s\n",
      "\titers: 600, epoch: 4 | loss: 0.1217408\n",
      "\tspeed: 0.0428s/iter; left time: 241.3009s\n",
      "\titers: 700, epoch: 4 | loss: 0.1244254\n",
      "\tspeed: 0.0428s/iter; left time: 237.0389s\n",
      "\titers: 800, epoch: 4 | loss: 0.1128398\n",
      "\tspeed: 0.0428s/iter; left time: 232.7588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.1260484 Vali Loss: 0.0348196 Test Loss: 0.0468632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105387\n",
      "\tspeed: 0.1519s/iter; left time: 796.8976s\n",
      "\titers: 200, epoch: 5 | loss: 0.1118334\n",
      "\tspeed: 0.0428s/iter; left time: 220.1709s\n",
      "\titers: 300, epoch: 5 | loss: 0.1173432\n",
      "\tspeed: 0.0430s/iter; left time: 217.1784s\n",
      "\titers: 400, epoch: 5 | loss: 0.1127749\n",
      "\tspeed: 0.0429s/iter; left time: 212.2728s\n",
      "\titers: 500, epoch: 5 | loss: 0.1049295\n",
      "\tspeed: 0.0430s/iter; left time: 208.4322s\n",
      "\titers: 600, epoch: 5 | loss: 0.1025971\n",
      "\tspeed: 0.0430s/iter; left time: 203.9761s\n",
      "\titers: 700, epoch: 5 | loss: 0.0991172\n",
      "\tspeed: 0.0430s/iter; left time: 199.7494s\n",
      "\titers: 800, epoch: 5 | loss: 0.0887636\n",
      "\tspeed: 0.0429s/iter; left time: 194.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.1064233 Vali Loss: 0.0383373 Test Loss: 0.0480545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03509388864040375, rmse:0.1873336285352707, mae:0.1296379417181015, rse:0.6633862853050232\n",
      "Original data scale mse:31071448.0, rmse:5574.1767578125, mae:3584.55615234375, rse:0.27759599685668945\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1584388\n",
      "\tspeed: 0.0446s/iter; left time: 393.3571s\n",
      "\titers: 200, epoch: 1 | loss: 0.1495694\n",
      "\tspeed: 0.0428s/iter; left time: 372.7798s\n",
      "\titers: 300, epoch: 1 | loss: 0.1723920\n",
      "\tspeed: 0.0427s/iter; left time: 367.9340s\n",
      "\titers: 400, epoch: 1 | loss: 0.1723190\n",
      "\tspeed: 0.0428s/iter; left time: 363.9423s\n",
      "\titers: 500, epoch: 1 | loss: 0.1466329\n",
      "\tspeed: 0.0429s/iter; left time: 360.4431s\n",
      "\titers: 600, epoch: 1 | loss: 0.1658001\n",
      "\tspeed: 0.0429s/iter; left time: 356.3060s\n",
      "\titers: 700, epoch: 1 | loss: 0.1555168\n",
      "\tspeed: 0.0428s/iter; left time: 351.3839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1498767\n",
      "\tspeed: 0.0427s/iter; left time: 346.4501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1593405 Vali Loss: 0.0307201 Test Loss: 0.0355679\n",
      "Validation loss decreased (inf --> 0.030720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1528472\n",
      "\tspeed: 0.1564s/iter; left time: 1238.8918s\n",
      "\titers: 200, epoch: 2 | loss: 0.1434784\n",
      "\tspeed: 0.0429s/iter; left time: 335.3442s\n",
      "\titers: 300, epoch: 2 | loss: 0.1505392\n",
      "\tspeed: 0.0427s/iter; left time: 329.8248s\n",
      "\titers: 400, epoch: 2 | loss: 0.1501380\n",
      "\tspeed: 0.0428s/iter; left time: 325.8127s\n",
      "\titers: 500, epoch: 2 | loss: 0.1336639\n",
      "\tspeed: 0.0430s/iter; left time: 323.3080s\n",
      "\titers: 600, epoch: 2 | loss: 0.1500371\n",
      "\tspeed: 0.0429s/iter; left time: 317.9597s\n",
      "\titers: 700, epoch: 2 | loss: 0.1574402\n",
      "\tspeed: 0.0429s/iter; left time: 313.8828s\n",
      "\titers: 800, epoch: 2 | loss: 0.1472396\n",
      "\tspeed: 0.0429s/iter; left time: 309.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 891 | Train Loss: 0.1503738 Vali Loss: 0.0293700 Test Loss: 0.0361260\n",
      "Validation loss decreased (0.030720 --> 0.029370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1470705\n",
      "\tspeed: 0.1549s/iter; left time: 1088.5264s\n",
      "\titers: 200, epoch: 3 | loss: 0.1376615\n",
      "\tspeed: 0.0428s/iter; left time: 296.8484s\n",
      "\titers: 300, epoch: 3 | loss: 0.1335509\n",
      "\tspeed: 0.0430s/iter; left time: 293.6047s\n",
      "\titers: 400, epoch: 3 | loss: 0.1365210\n",
      "\tspeed: 0.0429s/iter; left time: 288.8365s\n",
      "\titers: 500, epoch: 3 | loss: 0.1323292\n",
      "\tspeed: 0.0428s/iter; left time: 283.5409s\n",
      "\titers: 600, epoch: 3 | loss: 0.1371632\n",
      "\tspeed: 0.0428s/iter; left time: 279.5432s\n",
      "\titers: 700, epoch: 3 | loss: 0.1484529\n",
      "\tspeed: 0.0428s/iter; left time: 275.3581s\n",
      "\titers: 800, epoch: 3 | loss: 0.1351569\n",
      "\tspeed: 0.0428s/iter; left time: 271.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.1398348 Vali Loss: 0.0332601 Test Loss: 0.0410655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1267863\n",
      "\tspeed: 0.1523s/iter; left time: 934.6339s\n",
      "\titers: 200, epoch: 4 | loss: 0.1216621\n",
      "\tspeed: 0.0429s/iter; left time: 259.0478s\n",
      "\titers: 300, epoch: 4 | loss: 0.1244940\n",
      "\tspeed: 0.0428s/iter; left time: 254.0617s\n",
      "\titers: 400, epoch: 4 | loss: 0.1225908\n",
      "\tspeed: 0.0428s/iter; left time: 249.8053s\n",
      "\titers: 500, epoch: 4 | loss: 0.1150749\n",
      "\tspeed: 0.0426s/iter; left time: 244.2097s\n",
      "\titers: 600, epoch: 4 | loss: 0.1234124\n",
      "\tspeed: 0.0426s/iter; left time: 240.3710s\n",
      "\titers: 700, epoch: 4 | loss: 0.1311453\n",
      "\tspeed: 0.0428s/iter; left time: 237.1677s\n",
      "\titers: 800, epoch: 4 | loss: 0.1176136\n",
      "\tspeed: 0.0428s/iter; left time: 232.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1248351 Vali Loss: 0.0351462 Test Loss: 0.0437282\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1090962\n",
      "\tspeed: 0.1532s/iter; left time: 803.6812s\n",
      "\titers: 200, epoch: 5 | loss: 0.1051212\n",
      "\tspeed: 0.0429s/iter; left time: 220.7234s\n",
      "\titers: 300, epoch: 5 | loss: 0.1058841\n",
      "\tspeed: 0.0427s/iter; left time: 215.6150s\n",
      "\titers: 400, epoch: 5 | loss: 0.1100815\n",
      "\tspeed: 0.0425s/iter; left time: 210.0150s\n",
      "\titers: 500, epoch: 5 | loss: 0.1009246\n",
      "\tspeed: 0.0427s/iter; left time: 206.7734s\n",
      "\titers: 600, epoch: 5 | loss: 0.0994223\n",
      "\tspeed: 0.0428s/iter; left time: 203.1194s\n",
      "\titers: 700, epoch: 5 | loss: 0.0988644\n",
      "\tspeed: 0.0428s/iter; left time: 199.0226s\n",
      "\titers: 800, epoch: 5 | loss: 0.1001475\n",
      "\tspeed: 0.0428s/iter; left time: 194.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1068320 Vali Loss: 0.0393032 Test Loss: 0.0478743\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03612596541643143, rmse:0.190068319439888, mae:0.1320345103740692, rse:0.6730703115463257\n",
      "Original data scale mse:32765476.0, rmse:5724.11376953125, mae:3690.989990234375, rse:0.28506290912628174\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1833597\n",
      "\tspeed: 0.0671s/iter; left time: 589.5732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1659133\n",
      "\tspeed: 0.0433s/iter; left time: 375.9150s\n",
      "\titers: 300, epoch: 1 | loss: 0.1663503\n",
      "\tspeed: 0.0433s/iter; left time: 371.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1786418\n",
      "\tspeed: 0.0432s/iter; left time: 367.1758s\n",
      "\titers: 500, epoch: 1 | loss: 0.1744389\n",
      "\tspeed: 0.0432s/iter; left time: 362.8451s\n",
      "\titers: 600, epoch: 1 | loss: 0.1627810\n",
      "\tspeed: 0.0433s/iter; left time: 358.7164s\n",
      "\titers: 700, epoch: 1 | loss: 0.1605619\n",
      "\tspeed: 0.0433s/iter; left time: 354.5673s\n",
      "\titers: 800, epoch: 1 | loss: 0.1629204\n",
      "\tspeed: 0.0433s/iter; left time: 350.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 889 | Train Loss: 0.1653704 Vali Loss: 0.0321301 Test Loss: 0.0376642\n",
      "Validation loss decreased (inf --> 0.032130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1640930\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7653s\n",
      "\titers: 200, epoch: 2 | loss: 0.1498783\n",
      "\tspeed: 0.0433s/iter; left time: 337.5559s\n",
      "\titers: 300, epoch: 2 | loss: 0.1684814\n",
      "\tspeed: 0.0434s/iter; left time: 333.9663s\n",
      "\titers: 400, epoch: 2 | loss: 0.1556837\n",
      "\tspeed: 0.0434s/iter; left time: 329.6220s\n",
      "\titers: 500, epoch: 2 | loss: 0.1532064\n",
      "\tspeed: 0.0434s/iter; left time: 325.4889s\n",
      "\titers: 600, epoch: 2 | loss: 0.1554348\n",
      "\tspeed: 0.0433s/iter; left time: 320.2604s\n",
      "\titers: 700, epoch: 2 | loss: 0.1436202\n",
      "\tspeed: 0.0433s/iter; left time: 316.2454s\n",
      "\titers: 800, epoch: 2 | loss: 0.1553872\n",
      "\tspeed: 0.0434s/iter; left time: 312.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.1559100 Vali Loss: 0.0321198 Test Loss: 0.0385519\n",
      "Validation loss decreased (0.032130 --> 0.032120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1463879\n",
      "\tspeed: 0.1570s/iter; left time: 1100.7400s\n",
      "\titers: 200, epoch: 3 | loss: 0.1366018\n",
      "\tspeed: 0.0433s/iter; left time: 299.0091s\n",
      "\titers: 300, epoch: 3 | loss: 0.1475531\n",
      "\tspeed: 0.0433s/iter; left time: 294.7994s\n",
      "\titers: 400, epoch: 3 | loss: 0.1528376\n",
      "\tspeed: 0.0433s/iter; left time: 290.8106s\n",
      "\titers: 500, epoch: 3 | loss: 0.1497862\n",
      "\tspeed: 0.0432s/iter; left time: 285.7162s\n",
      "\titers: 600, epoch: 3 | loss: 0.1434129\n",
      "\tspeed: 0.0433s/iter; left time: 281.7983s\n",
      "\titers: 700, epoch: 3 | loss: 0.1414113\n",
      "\tspeed: 0.0432s/iter; left time: 277.3371s\n",
      "\titers: 800, epoch: 3 | loss: 0.1361767\n",
      "\tspeed: 0.0432s/iter; left time: 272.8447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.1413851 Vali Loss: 0.0361166 Test Loss: 0.0448900\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1258863\n",
      "\tspeed: 0.1529s/iter; left time: 936.1930s\n",
      "\titers: 200, epoch: 4 | loss: 0.1157237\n",
      "\tspeed: 0.0433s/iter; left time: 260.5720s\n",
      "\titers: 300, epoch: 4 | loss: 0.1304979\n",
      "\tspeed: 0.0433s/iter; left time: 256.2144s\n",
      "\titers: 400, epoch: 4 | loss: 0.1218902\n",
      "\tspeed: 0.0433s/iter; left time: 252.0212s\n",
      "\titers: 500, epoch: 4 | loss: 0.1187251\n",
      "\tspeed: 0.0434s/iter; left time: 248.4861s\n",
      "\titers: 600, epoch: 4 | loss: 0.1098248\n",
      "\tspeed: 0.0433s/iter; left time: 243.4990s\n",
      "\titers: 700, epoch: 4 | loss: 0.1150657\n",
      "\tspeed: 0.0433s/iter; left time: 239.2571s\n",
      "\titers: 800, epoch: 4 | loss: 0.1137168\n",
      "\tspeed: 0.0433s/iter; left time: 235.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1197595 Vali Loss: 0.0386829 Test Loss: 0.0492161\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095584\n",
      "\tspeed: 0.1527s/iter; left time: 799.4026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997966\n",
      "\tspeed: 0.0433s/iter; left time: 222.5521s\n",
      "\titers: 300, epoch: 5 | loss: 0.1038068\n",
      "\tspeed: 0.0434s/iter; left time: 218.4263s\n",
      "\titers: 400, epoch: 5 | loss: 0.1009282\n",
      "\tspeed: 0.0432s/iter; left time: 213.4164s\n",
      "\titers: 500, epoch: 5 | loss: 0.1003426\n",
      "\tspeed: 0.0433s/iter; left time: 209.1226s\n",
      "\titers: 600, epoch: 5 | loss: 0.0962209\n",
      "\tspeed: 0.0433s/iter; left time: 204.9426s\n",
      "\titers: 700, epoch: 5 | loss: 0.1001341\n",
      "\tspeed: 0.0432s/iter; left time: 200.3518s\n",
      "\titers: 800, epoch: 5 | loss: 0.0953031\n",
      "\tspeed: 0.0433s/iter; left time: 196.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1005519 Vali Loss: 0.0405882 Test Loss: 0.0512522\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03855190426111221, rmse:0.19634638726711273, mae:0.13726891577243805, rse:0.6955961585044861\n",
      "Original data scale mse:34756880.0, rmse:5895.49658203125, mae:3835.135009765625, rse:0.29374197125434875\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1893356\n",
      "\tspeed: 0.0456s/iter; left time: 400.8901s\n",
      "\titers: 200, epoch: 1 | loss: 0.1745470\n",
      "\tspeed: 0.0433s/iter; left time: 376.3877s\n",
      "\titers: 300, epoch: 1 | loss: 0.1811636\n",
      "\tspeed: 0.0433s/iter; left time: 371.8289s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759656\n",
      "\tspeed: 0.0433s/iter; left time: 367.7388s\n",
      "\titers: 500, epoch: 1 | loss: 0.1655199\n",
      "\tspeed: 0.0433s/iter; left time: 363.4309s\n",
      "\titers: 600, epoch: 1 | loss: 0.1480404\n",
      "\tspeed: 0.0435s/iter; left time: 360.7893s\n",
      "\titers: 700, epoch: 1 | loss: 0.1595656\n",
      "\tspeed: 0.0433s/iter; left time: 354.3005s\n",
      "\titers: 800, epoch: 1 | loss: 0.1515472\n",
      "\tspeed: 0.0433s/iter; left time: 350.3796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 889 | Train Loss: 0.1655817 Vali Loss: 0.0319932 Test Loss: 0.0375708\n",
      "Validation loss decreased (inf --> 0.031993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651777\n",
      "\tspeed: 0.1572s/iter; left time: 1242.3328s\n",
      "\titers: 200, epoch: 2 | loss: 0.1581006\n",
      "\tspeed: 0.0433s/iter; left time: 337.7233s\n",
      "\titers: 300, epoch: 2 | loss: 0.1623181\n",
      "\tspeed: 0.0434s/iter; left time: 334.3975s\n",
      "\titers: 400, epoch: 2 | loss: 0.1586005\n",
      "\tspeed: 0.0435s/iter; left time: 330.8515s\n",
      "\titers: 500, epoch: 2 | loss: 0.1598203\n",
      "\tspeed: 0.0436s/iter; left time: 326.7911s\n",
      "\titers: 600, epoch: 2 | loss: 0.1567608\n",
      "\tspeed: 0.0434s/iter; left time: 321.0831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1486650\n",
      "\tspeed: 0.0434s/iter; left time: 317.1089s\n",
      "\titers: 800, epoch: 2 | loss: 0.1487565\n",
      "\tspeed: 0.0434s/iter; left time: 312.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.1560612 Vali Loss: 0.0327080 Test Loss: 0.0405051\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1369832\n",
      "\tspeed: 0.1558s/iter; left time: 1092.6650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1387993\n",
      "\tspeed: 0.0433s/iter; left time: 299.3142s\n",
      "\titers: 300, epoch: 3 | loss: 0.1552020\n",
      "\tspeed: 0.0434s/iter; left time: 295.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.1466940\n",
      "\tspeed: 0.0434s/iter; left time: 291.1661s\n",
      "\titers: 500, epoch: 3 | loss: 0.1334032\n",
      "\tspeed: 0.0435s/iter; left time: 287.8082s\n",
      "\titers: 600, epoch: 3 | loss: 0.1432761\n",
      "\tspeed: 0.0433s/iter; left time: 282.0641s\n",
      "\titers: 700, epoch: 3 | loss: 0.1340335\n",
      "\tspeed: 0.0434s/iter; left time: 278.4751s\n",
      "\titers: 800, epoch: 3 | loss: 0.1315754\n",
      "\tspeed: 0.0434s/iter; left time: 273.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 889 | Train Loss: 0.1402110 Vali Loss: 0.0368857 Test Loss: 0.0443950\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1251242\n",
      "\tspeed: 0.1545s/iter; left time: 945.8634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1200764\n",
      "\tspeed: 0.0434s/iter; left time: 261.5699s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197645\n",
      "\tspeed: 0.0433s/iter; left time: 256.5109s\n",
      "\titers: 400, epoch: 4 | loss: 0.1145095\n",
      "\tspeed: 0.0434s/iter; left time: 252.7418s\n",
      "\titers: 500, epoch: 4 | loss: 0.1136019\n",
      "\tspeed: 0.0434s/iter; left time: 248.2165s\n",
      "\titers: 600, epoch: 4 | loss: 0.1082838\n",
      "\tspeed: 0.0433s/iter; left time: 243.2750s\n",
      "\titers: 700, epoch: 4 | loss: 0.1237357\n",
      "\tspeed: 0.0434s/iter; left time: 239.6804s\n",
      "\titers: 800, epoch: 4 | loss: 0.1096122\n",
      "\tspeed: 0.0433s/iter; left time: 234.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.1184306 Vali Loss: 0.0396475 Test Loss: 0.0498719\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03757075220346451, rmse:0.19383175671100616, mae:0.13670550286769867, rse:0.6866875886917114\n",
      "Original data scale mse:33994724.0, rmse:5830.49951171875, mae:3832.401611328125, rse:0.29050347208976746\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0982269\n",
      "\tspeed: 0.0685s/iter; left time: 604.5934s\n",
      "\titers: 200, epoch: 1 | loss: 0.1013101\n",
      "\tspeed: 0.0425s/iter; left time: 370.7379s\n",
      "\titers: 300, epoch: 1 | loss: 0.0868055\n",
      "\tspeed: 0.0424s/iter; left time: 366.0140s\n",
      "\titers: 400, epoch: 1 | loss: 0.0897896\n",
      "\tspeed: 0.0425s/iter; left time: 362.3425s\n",
      "\titers: 500, epoch: 1 | loss: 0.0854713\n",
      "\tspeed: 0.0424s/iter; left time: 357.5310s\n",
      "\titers: 600, epoch: 1 | loss: 0.0940049\n",
      "\tspeed: 0.0425s/iter; left time: 353.8167s\n",
      "\titers: 700, epoch: 1 | loss: 0.0845092\n",
      "\tspeed: 0.0425s/iter; left time: 349.8106s\n",
      "\titers: 800, epoch: 1 | loss: 0.0827740\n",
      "\tspeed: 0.0423s/iter; left time: 343.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 893 | Train Loss: 0.0894404 Vali Loss: 0.0932369 Test Loss: 0.0948404\n",
      "Validation loss decreased (inf --> 0.093237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0930060\n",
      "\tspeed: 0.1547s/iter; left time: 1227.8678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0909547\n",
      "\tspeed: 0.0422s/iter; left time: 330.4414s\n",
      "\titers: 300, epoch: 2 | loss: 0.0749568\n",
      "\tspeed: 0.0423s/iter; left time: 327.0418s\n",
      "\titers: 400, epoch: 2 | loss: 0.0837843\n",
      "\tspeed: 0.0421s/iter; left time: 321.5717s\n",
      "\titers: 500, epoch: 2 | loss: 0.0746110\n",
      "\tspeed: 0.0424s/iter; left time: 319.6912s\n",
      "\titers: 600, epoch: 2 | loss: 0.0760855\n",
      "\tspeed: 0.0424s/iter; left time: 315.5403s\n",
      "\titers: 700, epoch: 2 | loss: 0.0800584\n",
      "\tspeed: 0.0424s/iter; left time: 311.4405s\n",
      "\titers: 800, epoch: 2 | loss: 0.0686675\n",
      "\tspeed: 0.0424s/iter; left time: 306.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.0785074 Vali Loss: 0.0889835 Test Loss: 0.0917395\n",
      "Validation loss decreased (0.093237 --> 0.088983).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0594261\n",
      "\tspeed: 0.1537s/iter; left time: 1082.9652s\n",
      "\titers: 200, epoch: 3 | loss: 0.0736717\n",
      "\tspeed: 0.0424s/iter; left time: 294.4839s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689235\n",
      "\tspeed: 0.0424s/iter; left time: 290.1999s\n",
      "\titers: 400, epoch: 3 | loss: 0.0703454\n",
      "\tspeed: 0.0424s/iter; left time: 285.8444s\n",
      "\titers: 500, epoch: 3 | loss: 0.0640562\n",
      "\tspeed: 0.0426s/iter; left time: 282.7980s\n",
      "\titers: 600, epoch: 3 | loss: 0.0739933\n",
      "\tspeed: 0.0425s/iter; left time: 277.9191s\n",
      "\titers: 700, epoch: 3 | loss: 0.0605377\n",
      "\tspeed: 0.0424s/iter; left time: 273.3293s\n",
      "\titers: 800, epoch: 3 | loss: 0.0779187\n",
      "\tspeed: 0.0424s/iter; left time: 269.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0719159 Vali Loss: 0.0878696 Test Loss: 0.0904880\n",
      "Validation loss decreased (0.088983 --> 0.087870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0705446\n",
      "\tspeed: 0.1535s/iter; left time: 944.5809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0677454\n",
      "\tspeed: 0.0424s/iter; left time: 256.4181s\n",
      "\titers: 300, epoch: 4 | loss: 0.0742365\n",
      "\tspeed: 0.0423s/iter; left time: 251.9970s\n",
      "\titers: 400, epoch: 4 | loss: 0.0595334\n",
      "\tspeed: 0.0424s/iter; left time: 247.9410s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863025\n",
      "\tspeed: 0.0424s/iter; left time: 243.6109s\n",
      "\titers: 600, epoch: 4 | loss: 0.0667366\n",
      "\tspeed: 0.0424s/iter; left time: 239.3752s\n",
      "\titers: 700, epoch: 4 | loss: 0.0623034\n",
      "\tspeed: 0.0424s/iter; left time: 235.3015s\n",
      "\titers: 800, epoch: 4 | loss: 0.0761746\n",
      "\tspeed: 0.0426s/iter; left time: 232.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0699605 Vali Loss: 0.0880479 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689419\n",
      "\tspeed: 0.1506s/iter; left time: 792.2078s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578706\n",
      "\tspeed: 0.0424s/iter; left time: 218.5295s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662531\n",
      "\tspeed: 0.0424s/iter; left time: 214.3156s\n",
      "\titers: 400, epoch: 5 | loss: 0.0638737\n",
      "\tspeed: 0.0424s/iter; left time: 210.0910s\n",
      "\titers: 500, epoch: 5 | loss: 0.0668011\n",
      "\tspeed: 0.0425s/iter; left time: 206.3862s\n",
      "\titers: 600, epoch: 5 | loss: 0.0606949\n",
      "\tspeed: 0.0425s/iter; left time: 202.3035s\n",
      "\titers: 700, epoch: 5 | loss: 0.0667649\n",
      "\tspeed: 0.0424s/iter; left time: 197.6456s\n",
      "\titers: 800, epoch: 5 | loss: 0.0646159\n",
      "\tspeed: 0.0424s/iter; left time: 193.3645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0685865 Vali Loss: 0.0866732 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.087870 --> 0.086673).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605314\n",
      "\tspeed: 0.1537s/iter; left time: 670.9046s\n",
      "\titers: 200, epoch: 6 | loss: 0.0723072\n",
      "\tspeed: 0.0425s/iter; left time: 181.1335s\n",
      "\titers: 300, epoch: 6 | loss: 0.0621333\n",
      "\tspeed: 0.0423s/iter; left time: 176.2196s\n",
      "\titers: 400, epoch: 6 | loss: 0.0597321\n",
      "\tspeed: 0.0424s/iter; left time: 172.4385s\n",
      "\titers: 500, epoch: 6 | loss: 0.0682577\n",
      "\tspeed: 0.0424s/iter; left time: 167.9765s\n",
      "\titers: 600, epoch: 6 | loss: 0.0698579\n",
      "\tspeed: 0.0424s/iter; left time: 163.8742s\n",
      "\titers: 700, epoch: 6 | loss: 0.0574603\n",
      "\tspeed: 0.0424s/iter; left time: 159.5559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0658379\n",
      "\tspeed: 0.0425s/iter; left time: 155.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0670818 Vali Loss: 0.0868470 Test Loss: 0.0906652\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0681261\n",
      "\tspeed: 0.1512s/iter; left time: 525.0611s\n",
      "\titers: 200, epoch: 7 | loss: 0.0641372\n",
      "\tspeed: 0.0427s/iter; left time: 143.8685s\n",
      "\titers: 300, epoch: 7 | loss: 0.0653514\n",
      "\tspeed: 0.0425s/iter; left time: 139.0200s\n",
      "\titers: 400, epoch: 7 | loss: 0.0666691\n",
      "\tspeed: 0.0424s/iter; left time: 134.6223s\n",
      "\titers: 500, epoch: 7 | loss: 0.0718581\n",
      "\tspeed: 0.0423s/iter; left time: 130.1402s\n",
      "\titers: 600, epoch: 7 | loss: 0.0614609\n",
      "\tspeed: 0.0424s/iter; left time: 126.0281s\n",
      "\titers: 700, epoch: 7 | loss: 0.0597905\n",
      "\tspeed: 0.0424s/iter; left time: 121.8266s\n",
      "\titers: 800, epoch: 7 | loss: 0.0616782\n",
      "\tspeed: 0.0423s/iter; left time: 117.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0654795 Vali Loss: 0.0877799 Test Loss: 0.0917357\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0623620\n",
      "\tspeed: 0.1513s/iter; left time: 390.4644s\n",
      "\titers: 200, epoch: 8 | loss: 0.0624125\n",
      "\tspeed: 0.0425s/iter; left time: 105.4512s\n",
      "\titers: 300, epoch: 8 | loss: 0.0587036\n",
      "\tspeed: 0.0424s/iter; left time: 100.9106s\n",
      "\titers: 400, epoch: 8 | loss: 0.0662080\n",
      "\tspeed: 0.0424s/iter; left time: 96.6471s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704325\n",
      "\tspeed: 0.0424s/iter; left time: 92.4376s\n",
      "\titers: 600, epoch: 8 | loss: 0.0537593\n",
      "\tspeed: 0.0424s/iter; left time: 88.2434s\n",
      "\titers: 700, epoch: 8 | loss: 0.0606119\n",
      "\tspeed: 0.0423s/iter; left time: 83.7985s\n",
      "\titers: 800, epoch: 8 | loss: 0.0711017\n",
      "\tspeed: 0.0424s/iter; left time: 79.6650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.0634904 Vali Loss: 0.0889440 Test Loss: 0.0918915\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021896962076425552, rmse:0.14797621965408325, mae:0.09019491076469421, rse:0.5225819945335388\n",
      "Original data scale mse:16924342.0, rmse:4113.92041015625, mae:2418.190673828125, rse:0.20455242693424225\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0992375\n",
      "\tspeed: 0.0443s/iter; left time: 391.3833s\n",
      "\titers: 200, epoch: 1 | loss: 0.0934699\n",
      "\tspeed: 0.0424s/iter; left time: 370.4709s\n",
      "\titers: 300, epoch: 1 | loss: 0.0782871\n",
      "\tspeed: 0.0424s/iter; left time: 366.2412s\n",
      "\titers: 400, epoch: 1 | loss: 0.0772246\n",
      "\tspeed: 0.0424s/iter; left time: 361.4961s\n",
      "\titers: 500, epoch: 1 | loss: 0.0751684\n",
      "\tspeed: 0.0424s/iter; left time: 357.1913s\n",
      "\titers: 600, epoch: 1 | loss: 0.0776297\n",
      "\tspeed: 0.0424s/iter; left time: 353.0025s\n",
      "\titers: 700, epoch: 1 | loss: 0.0724057\n",
      "\tspeed: 0.0425s/iter; left time: 349.9609s\n",
      "\titers: 800, epoch: 1 | loss: 0.0723183\n",
      "\tspeed: 0.0424s/iter; left time: 344.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0892226 Vali Loss: 0.0935710 Test Loss: 0.0953618\n",
      "Validation loss decreased (inf --> 0.093571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877377\n",
      "\tspeed: 0.1548s/iter; left time: 1229.1005s\n",
      "\titers: 200, epoch: 2 | loss: 0.0765526\n",
      "\tspeed: 0.0424s/iter; left time: 332.6611s\n",
      "\titers: 300, epoch: 2 | loss: 0.0742970\n",
      "\tspeed: 0.0424s/iter; left time: 327.7887s\n",
      "\titers: 400, epoch: 2 | loss: 0.0868176\n",
      "\tspeed: 0.0424s/iter; left time: 323.6582s\n",
      "\titers: 500, epoch: 2 | loss: 0.0724310\n",
      "\tspeed: 0.0424s/iter; left time: 319.3410s\n",
      "\titers: 600, epoch: 2 | loss: 0.0747986\n",
      "\tspeed: 0.0425s/iter; left time: 316.0833s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763848\n",
      "\tspeed: 0.0425s/iter; left time: 311.6705s\n",
      "\titers: 800, epoch: 2 | loss: 0.0782857\n",
      "\tspeed: 0.0424s/iter; left time: 306.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0785560 Vali Loss: 0.0900949 Test Loss: 0.0926300\n",
      "Validation loss decreased (0.093571 --> 0.090095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0660076\n",
      "\tspeed: 0.1559s/iter; left time: 1098.1421s\n",
      "\titers: 200, epoch: 3 | loss: 0.0703183\n",
      "\tspeed: 0.0424s/iter; left time: 294.4382s\n",
      "\titers: 300, epoch: 3 | loss: 0.0690660\n",
      "\tspeed: 0.0425s/iter; left time: 290.6555s\n",
      "\titers: 400, epoch: 3 | loss: 0.0783872\n",
      "\tspeed: 0.0425s/iter; left time: 286.8301s\n",
      "\titers: 500, epoch: 3 | loss: 0.0600328\n",
      "\tspeed: 0.0425s/iter; left time: 282.4685s\n",
      "\titers: 600, epoch: 3 | loss: 0.0638266\n",
      "\tspeed: 0.0424s/iter; left time: 277.7843s\n",
      "\titers: 700, epoch: 3 | loss: 0.0695692\n",
      "\tspeed: 0.0424s/iter; left time: 273.2920s\n",
      "\titers: 800, epoch: 3 | loss: 0.0735985\n",
      "\tspeed: 0.0424s/iter; left time: 269.0299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.0718675 Vali Loss: 0.0914021 Test Loss: 0.0939478\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0765364\n",
      "\tspeed: 0.1514s/iter; left time: 931.6673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741287\n",
      "\tspeed: 0.0424s/iter; left time: 256.4916s\n",
      "\titers: 300, epoch: 4 | loss: 0.0738798\n",
      "\tspeed: 0.0424s/iter; left time: 252.5723s\n",
      "\titers: 400, epoch: 4 | loss: 0.0612318\n",
      "\tspeed: 0.0424s/iter; left time: 247.9087s\n",
      "\titers: 500, epoch: 4 | loss: 0.0693761\n",
      "\tspeed: 0.0424s/iter; left time: 243.7100s\n",
      "\titers: 600, epoch: 4 | loss: 0.0697355\n",
      "\tspeed: 0.0424s/iter; left time: 239.6710s\n",
      "\titers: 700, epoch: 4 | loss: 0.0700700\n",
      "\tspeed: 0.0424s/iter; left time: 235.6105s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630878\n",
      "\tspeed: 0.0425s/iter; left time: 231.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0706836 Vali Loss: 0.0880876 Test Loss: 0.0918040\n",
      "Validation loss decreased (0.090095 --> 0.088088).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0688232\n",
      "\tspeed: 0.1544s/iter; left time: 811.9215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646626\n",
      "\tspeed: 0.0425s/iter; left time: 219.2256s\n",
      "\titers: 300, epoch: 5 | loss: 0.0689990\n",
      "\tspeed: 0.0424s/iter; left time: 214.5066s\n",
      "\titers: 400, epoch: 5 | loss: 0.0776107\n",
      "\tspeed: 0.0424s/iter; left time: 210.2767s\n",
      "\titers: 500, epoch: 5 | loss: 0.0861132\n",
      "\tspeed: 0.0424s/iter; left time: 205.9477s\n",
      "\titers: 600, epoch: 5 | loss: 0.0704510\n",
      "\tspeed: 0.0424s/iter; left time: 201.7200s\n",
      "\titers: 700, epoch: 5 | loss: 0.0740028\n",
      "\tspeed: 0.0424s/iter; left time: 197.3903s\n",
      "\titers: 800, epoch: 5 | loss: 0.0660616\n",
      "\tspeed: 0.0424s/iter; left time: 193.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0687371 Vali Loss: 0.0862890 Test Loss: 0.0896654\n",
      "Validation loss decreased (0.088088 --> 0.086289).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0763484\n",
      "\tspeed: 0.1543s/iter; left time: 673.4607s\n",
      "\titers: 200, epoch: 6 | loss: 0.0589041\n",
      "\tspeed: 0.0422s/iter; left time: 180.1654s\n",
      "\titers: 300, epoch: 6 | loss: 0.0648005\n",
      "\tspeed: 0.0423s/iter; left time: 176.2567s\n",
      "\titers: 400, epoch: 6 | loss: 0.0721593\n",
      "\tspeed: 0.0424s/iter; left time: 172.2236s\n",
      "\titers: 500, epoch: 6 | loss: 0.0596429\n",
      "\tspeed: 0.0424s/iter; left time: 168.2345s\n",
      "\titers: 600, epoch: 6 | loss: 0.0690015\n",
      "\tspeed: 0.0424s/iter; left time: 163.8142s\n",
      "\titers: 700, epoch: 6 | loss: 0.0736667\n",
      "\tspeed: 0.0424s/iter; left time: 159.7389s\n",
      "\titers: 800, epoch: 6 | loss: 0.0691755\n",
      "\tspeed: 0.0423s/iter; left time: 155.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0676042 Vali Loss: 0.0860627 Test Loss: 0.0895480\n",
      "Validation loss decreased (0.086289 --> 0.086063).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0711707\n",
      "\tspeed: 0.1550s/iter; left time: 538.1762s\n",
      "\titers: 200, epoch: 7 | loss: 0.0754958\n",
      "\tspeed: 0.0424s/iter; left time: 142.9924s\n",
      "\titers: 300, epoch: 7 | loss: 0.0697669\n",
      "\tspeed: 0.0424s/iter; left time: 138.7071s\n",
      "\titers: 400, epoch: 7 | loss: 0.0649212\n",
      "\tspeed: 0.0424s/iter; left time: 134.5828s\n",
      "\titers: 500, epoch: 7 | loss: 0.0594330\n",
      "\tspeed: 0.0424s/iter; left time: 130.1759s\n",
      "\titers: 600, epoch: 7 | loss: 0.0632876\n",
      "\tspeed: 0.0424s/iter; left time: 126.0848s\n",
      "\titers: 700, epoch: 7 | loss: 0.0637645\n",
      "\tspeed: 0.0424s/iter; left time: 121.7083s\n",
      "\titers: 800, epoch: 7 | loss: 0.0697547\n",
      "\tspeed: 0.0424s/iter; left time: 117.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.0658465 Vali Loss: 0.0862527 Test Loss: 0.0907334\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0606774\n",
      "\tspeed: 0.1524s/iter; left time: 393.1962s\n",
      "\titers: 200, epoch: 8 | loss: 0.0595161\n",
      "\tspeed: 0.0426s/iter; left time: 105.6261s\n",
      "\titers: 300, epoch: 8 | loss: 0.0535491\n",
      "\tspeed: 0.0424s/iter; left time: 100.8890s\n",
      "\titers: 400, epoch: 8 | loss: 0.0670822\n",
      "\tspeed: 0.0425s/iter; left time: 96.8624s\n",
      "\titers: 500, epoch: 8 | loss: 0.0586945\n",
      "\tspeed: 0.0424s/iter; left time: 92.3912s\n",
      "\titers: 600, epoch: 8 | loss: 0.0657744\n",
      "\tspeed: 0.0424s/iter; left time: 88.0980s\n",
      "\titers: 700, epoch: 8 | loss: 0.0653217\n",
      "\tspeed: 0.0425s/iter; left time: 84.0540s\n",
      "\titers: 800, epoch: 8 | loss: 0.0639375\n",
      "\tspeed: 0.0424s/iter; left time: 79.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.0641070 Vali Loss: 0.0877166 Test Loss: 0.0916218\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738917\n",
      "\tspeed: 0.1527s/iter; left time: 257.6140s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668606\n",
      "\tspeed: 0.0424s/iter; left time: 67.2771s\n",
      "\titers: 300, epoch: 9 | loss: 0.0544539\n",
      "\tspeed: 0.0424s/iter; left time: 63.0541s\n",
      "\titers: 400, epoch: 9 | loss: 0.0573254\n",
      "\tspeed: 0.0424s/iter; left time: 58.8119s\n",
      "\titers: 500, epoch: 9 | loss: 0.0561938\n",
      "\tspeed: 0.0424s/iter; left time: 54.6251s\n",
      "\titers: 600, epoch: 9 | loss: 0.0634413\n",
      "\tspeed: 0.0425s/iter; left time: 50.4472s\n",
      "\titers: 700, epoch: 9 | loss: 0.0612848\n",
      "\tspeed: 0.0425s/iter; left time: 46.1514s\n",
      "\titers: 800, epoch: 9 | loss: 0.0573156\n",
      "\tspeed: 0.0424s/iter; left time: 41.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.0622550 Vali Loss: 0.0885687 Test Loss: 0.0938942\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021253786981105804, rmse:0.14578679203987122, mae:0.0895480364561081, rse:0.5148499608039856\n",
      "Original data scale mse:16638304.0, rmse:4079.0078125, mae:2411.266845703125, rse:0.20281648635864258\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1334426\n",
      "\tspeed: 0.0676s/iter; left time: 595.3266s\n",
      "\titers: 200, epoch: 1 | loss: 0.1103007\n",
      "\tspeed: 0.0427s/iter; left time: 372.3552s\n",
      "\titers: 300, epoch: 1 | loss: 0.1152367\n",
      "\tspeed: 0.0428s/iter; left time: 368.4814s\n",
      "\titers: 400, epoch: 1 | loss: 0.1013051\n",
      "\tspeed: 0.0428s/iter; left time: 364.5939s\n",
      "\titers: 500, epoch: 1 | loss: 0.1121939\n",
      "\tspeed: 0.0429s/iter; left time: 360.7216s\n",
      "\titers: 600, epoch: 1 | loss: 0.1019219\n",
      "\tspeed: 0.0429s/iter; left time: 356.5013s\n",
      "\titers: 700, epoch: 1 | loss: 0.1099762\n",
      "\tspeed: 0.0427s/iter; left time: 350.9776s\n",
      "\titers: 800, epoch: 1 | loss: 0.1171699\n",
      "\tspeed: 0.0427s/iter; left time: 346.7401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.1133261 Vali Loss: 0.1209122 Test Loss: 0.1280698\n",
      "Validation loss decreased (inf --> 0.120912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1131083\n",
      "\tspeed: 0.1545s/iter; left time: 1223.2759s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019299\n",
      "\tspeed: 0.0427s/iter; left time: 333.8170s\n",
      "\titers: 300, epoch: 2 | loss: 0.0981942\n",
      "\tspeed: 0.0427s/iter; left time: 329.8722s\n",
      "\titers: 400, epoch: 2 | loss: 0.1060563\n",
      "\tspeed: 0.0427s/iter; left time: 325.4710s\n",
      "\titers: 500, epoch: 2 | loss: 0.0967019\n",
      "\tspeed: 0.0427s/iter; left time: 321.4287s\n",
      "\titers: 600, epoch: 2 | loss: 0.0905631\n",
      "\tspeed: 0.0427s/iter; left time: 317.1375s\n",
      "\titers: 700, epoch: 2 | loss: 0.0895246\n",
      "\tspeed: 0.0427s/iter; left time: 312.6622s\n",
      "\titers: 800, epoch: 2 | loss: 0.1078703\n",
      "\tspeed: 0.0427s/iter; left time: 308.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1039308 Vali Loss: 0.1175602 Test Loss: 0.1257358\n",
      "Validation loss decreased (0.120912 --> 0.117560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0929911\n",
      "\tspeed: 0.1533s/iter; left time: 1077.6925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0966166\n",
      "\tspeed: 0.0427s/iter; left time: 296.0208s\n",
      "\titers: 300, epoch: 3 | loss: 0.1044126\n",
      "\tspeed: 0.0428s/iter; left time: 292.1870s\n",
      "\titers: 400, epoch: 3 | loss: 0.0966799\n",
      "\tspeed: 0.0427s/iter; left time: 287.2806s\n",
      "\titers: 500, epoch: 3 | loss: 0.0936324\n",
      "\tspeed: 0.0427s/iter; left time: 282.9075s\n",
      "\titers: 600, epoch: 3 | loss: 0.0916234\n",
      "\tspeed: 0.0427s/iter; left time: 278.7239s\n",
      "\titers: 700, epoch: 3 | loss: 0.0973616\n",
      "\tspeed: 0.0425s/iter; left time: 273.3839s\n",
      "\titers: 800, epoch: 3 | loss: 0.0827569\n",
      "\tspeed: 0.0425s/iter; left time: 269.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.0964571 Vali Loss: 0.1191284 Test Loss: 0.1293793\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0983466\n",
      "\tspeed: 0.1522s/iter; left time: 934.4355s\n",
      "\titers: 200, epoch: 4 | loss: 0.1001360\n",
      "\tspeed: 0.0429s/iter; left time: 259.0395s\n",
      "\titers: 300, epoch: 4 | loss: 0.1007725\n",
      "\tspeed: 0.0428s/iter; left time: 254.2022s\n",
      "\titers: 400, epoch: 4 | loss: 0.0891830\n",
      "\tspeed: 0.0429s/iter; left time: 250.2723s\n",
      "\titers: 500, epoch: 4 | loss: 0.0891175\n",
      "\tspeed: 0.0427s/iter; left time: 245.1813s\n",
      "\titers: 600, epoch: 4 | loss: 0.0923178\n",
      "\tspeed: 0.0427s/iter; left time: 240.8333s\n",
      "\titers: 700, epoch: 4 | loss: 0.0921811\n",
      "\tspeed: 0.0428s/iter; left time: 237.2184s\n",
      "\titers: 800, epoch: 4 | loss: 0.0803595\n",
      "\tspeed: 0.0427s/iter; left time: 232.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.0896301 Vali Loss: 0.1220919 Test Loss: 0.1360420\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0865810\n",
      "\tspeed: 0.1512s/iter; left time: 793.3066s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802722\n",
      "\tspeed: 0.0430s/iter; left time: 221.2712s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982361\n",
      "\tspeed: 0.0428s/iter; left time: 215.9371s\n",
      "\titers: 400, epoch: 5 | loss: 0.0758405\n",
      "\tspeed: 0.0428s/iter; left time: 211.6121s\n",
      "\titers: 500, epoch: 5 | loss: 0.0794196\n",
      "\tspeed: 0.0428s/iter; left time: 207.4097s\n",
      "\titers: 600, epoch: 5 | loss: 0.0786633\n",
      "\tspeed: 0.0428s/iter; left time: 202.9780s\n",
      "\titers: 700, epoch: 5 | loss: 0.0719079\n",
      "\tspeed: 0.0428s/iter; left time: 198.9922s\n",
      "\titers: 800, epoch: 5 | loss: 0.0690903\n",
      "\tspeed: 0.0427s/iter; left time: 194.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.0804969 Vali Loss: 0.1255576 Test Loss: 0.1390364\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03539472818374634, rmse:0.18813486397266388, mae:0.1257358193397522, rse:0.6662235856056213\n",
      "Original data scale mse:31024660.0, rmse:5569.978515625, mae:3461.25146484375, rse:0.2773869037628174\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1164240\n",
      "\tspeed: 0.0444s/iter; left time: 391.2675s\n",
      "\titers: 200, epoch: 1 | loss: 0.1082931\n",
      "\tspeed: 0.0427s/iter; left time: 371.7160s\n",
      "\titers: 300, epoch: 1 | loss: 0.1195490\n",
      "\tspeed: 0.0427s/iter; left time: 367.4500s\n",
      "\titers: 400, epoch: 1 | loss: 0.1225900\n",
      "\tspeed: 0.0427s/iter; left time: 363.4643s\n",
      "\titers: 500, epoch: 1 | loss: 0.1040627\n",
      "\tspeed: 0.0426s/iter; left time: 358.5863s\n",
      "\titers: 600, epoch: 1 | loss: 0.1160977\n",
      "\tspeed: 0.0427s/iter; left time: 355.2786s\n",
      "\titers: 700, epoch: 1 | loss: 0.1054960\n",
      "\tspeed: 0.0427s/iter; left time: 350.8912s\n",
      "\titers: 800, epoch: 1 | loss: 0.1049798\n",
      "\tspeed: 0.0427s/iter; left time: 346.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.1133533 Vali Loss: 0.1207216 Test Loss: 0.1277026\n",
      "Validation loss decreased (inf --> 0.120722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122422\n",
      "\tspeed: 0.1548s/iter; left time: 1226.1465s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985058\n",
      "\tspeed: 0.0428s/iter; left time: 334.5103s\n",
      "\titers: 300, epoch: 2 | loss: 0.1053138\n",
      "\tspeed: 0.0427s/iter; left time: 329.8008s\n",
      "\titers: 400, epoch: 2 | loss: 0.1024959\n",
      "\tspeed: 0.0427s/iter; left time: 325.7378s\n",
      "\titers: 500, epoch: 2 | loss: 0.0940722\n",
      "\tspeed: 0.0427s/iter; left time: 321.4620s\n",
      "\titers: 600, epoch: 2 | loss: 0.0998174\n",
      "\tspeed: 0.0428s/iter; left time: 317.4071s\n",
      "\titers: 700, epoch: 2 | loss: 0.1079098\n",
      "\tspeed: 0.0428s/iter; left time: 313.4563s\n",
      "\titers: 800, epoch: 2 | loss: 0.1000197\n",
      "\tspeed: 0.0428s/iter; left time: 309.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1038058 Vali Loss: 0.1185285 Test Loss: 0.1285185\n",
      "Validation loss decreased (0.120722 --> 0.118529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1014842\n",
      "\tspeed: 0.1564s/iter; left time: 1099.5696s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938777\n",
      "\tspeed: 0.0428s/iter; left time: 296.3505s\n",
      "\titers: 300, epoch: 3 | loss: 0.0884656\n",
      "\tspeed: 0.0427s/iter; left time: 291.9129s\n",
      "\titers: 400, epoch: 3 | loss: 0.0926556\n",
      "\tspeed: 0.0426s/iter; left time: 286.9812s\n",
      "\titers: 500, epoch: 3 | loss: 0.0902297\n",
      "\tspeed: 0.0427s/iter; left time: 282.9399s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933597\n",
      "\tspeed: 0.0428s/iter; left time: 279.1819s\n",
      "\titers: 700, epoch: 3 | loss: 0.1058115\n",
      "\tspeed: 0.0428s/iter; left time: 275.4824s\n",
      "\titers: 800, epoch: 3 | loss: 0.0954820\n",
      "\tspeed: 0.0427s/iter; left time: 270.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.0961568 Vali Loss: 0.1192591 Test Loss: 0.1301049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0917138\n",
      "\tspeed: 0.1514s/iter; left time: 929.2653s\n",
      "\titers: 200, epoch: 4 | loss: 0.0832180\n",
      "\tspeed: 0.0427s/iter; left time: 257.8285s\n",
      "\titers: 300, epoch: 4 | loss: 0.0878894\n",
      "\tspeed: 0.0427s/iter; left time: 253.5029s\n",
      "\titers: 400, epoch: 4 | loss: 0.0908128\n",
      "\tspeed: 0.0427s/iter; left time: 249.3812s\n",
      "\titers: 500, epoch: 4 | loss: 0.0796713\n",
      "\tspeed: 0.0428s/iter; left time: 245.5945s\n",
      "\titers: 600, epoch: 4 | loss: 0.0906177\n",
      "\tspeed: 0.0427s/iter; left time: 240.9307s\n",
      "\titers: 700, epoch: 4 | loss: 0.0917859\n",
      "\tspeed: 0.0427s/iter; left time: 236.5848s\n",
      "\titers: 800, epoch: 4 | loss: 0.0861579\n",
      "\tspeed: 0.0427s/iter; left time: 232.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.0894545 Vali Loss: 0.1225607 Test Loss: 0.1323293\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785693\n",
      "\tspeed: 0.1510s/iter; left time: 792.0939s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785203\n",
      "\tspeed: 0.0427s/iter; left time: 219.6958s\n",
      "\titers: 300, epoch: 5 | loss: 0.0808796\n",
      "\tspeed: 0.0428s/iter; left time: 215.8889s\n",
      "\titers: 400, epoch: 5 | loss: 0.0829185\n",
      "\tspeed: 0.0429s/iter; left time: 212.0397s\n",
      "\titers: 500, epoch: 5 | loss: 0.0714023\n",
      "\tspeed: 0.0428s/iter; left time: 207.3207s\n",
      "\titers: 600, epoch: 5 | loss: 0.0729096\n",
      "\tspeed: 0.0428s/iter; left time: 203.2341s\n",
      "\titers: 700, epoch: 5 | loss: 0.0732635\n",
      "\tspeed: 0.0427s/iter; left time: 198.6462s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749141\n",
      "\tspeed: 0.0427s/iter; left time: 194.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.0799470 Vali Loss: 0.1262512 Test Loss: 0.1356284\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03782464563846588, rmse:0.1944855898618698, mae:0.12851838767528534, rse:0.6887127757072449\n",
      "Original data scale mse:33443530.0, rmse:5783.0380859375, mae:3538.765869140625, rse:0.28799739480018616\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1349828\n",
      "\tspeed: 0.0682s/iter; left time: 599.9826s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171150\n",
      "\tspeed: 0.0434s/iter; left time: 377.0507s\n",
      "\titers: 300, epoch: 1 | loss: 0.1186465\n",
      "\tspeed: 0.0433s/iter; left time: 372.2884s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300746\n",
      "\tspeed: 0.0433s/iter; left time: 367.7777s\n",
      "\titers: 500, epoch: 1 | loss: 0.1262776\n",
      "\tspeed: 0.0432s/iter; left time: 362.6258s\n",
      "\titers: 600, epoch: 1 | loss: 0.1169523\n",
      "\tspeed: 0.0433s/iter; left time: 358.8795s\n",
      "\titers: 700, epoch: 1 | loss: 0.1133561\n",
      "\tspeed: 0.0433s/iter; left time: 354.3301s\n",
      "\titers: 800, epoch: 1 | loss: 0.1126298\n",
      "\tspeed: 0.0433s/iter; left time: 350.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.1184658 Vali Loss: 0.1249427 Test Loss: 0.1337868\n",
      "Validation loss decreased (inf --> 0.124943).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1202174\n",
      "\tspeed: 0.1566s/iter; left time: 1237.2609s\n",
      "\titers: 200, epoch: 2 | loss: 0.1027493\n",
      "\tspeed: 0.0433s/iter; left time: 337.9787s\n",
      "\titers: 300, epoch: 2 | loss: 0.1184897\n",
      "\tspeed: 0.0433s/iter; left time: 333.5297s\n",
      "\titers: 400, epoch: 2 | loss: 0.1071200\n",
      "\tspeed: 0.0433s/iter; left time: 329.1377s\n",
      "\titers: 500, epoch: 2 | loss: 0.1045601\n",
      "\tspeed: 0.0433s/iter; left time: 324.9134s\n",
      "\titers: 600, epoch: 2 | loss: 0.1052938\n",
      "\tspeed: 0.0433s/iter; left time: 320.4096s\n",
      "\titers: 700, epoch: 2 | loss: 0.0975450\n",
      "\tspeed: 0.0433s/iter; left time: 316.1600s\n",
      "\titers: 800, epoch: 2 | loss: 0.1092773\n",
      "\tspeed: 0.0433s/iter; left time: 311.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.1081579 Vali Loss: 0.1224794 Test Loss: 0.1339633\n",
      "Validation loss decreased (0.124943 --> 0.122479).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1025385\n",
      "\tspeed: 0.1561s/iter; left time: 1094.7564s\n",
      "\titers: 200, epoch: 3 | loss: 0.0882827\n",
      "\tspeed: 0.0433s/iter; left time: 299.2001s\n",
      "\titers: 300, epoch: 3 | loss: 0.0990098\n",
      "\tspeed: 0.0433s/iter; left time: 294.9712s\n",
      "\titers: 400, epoch: 3 | loss: 0.1090137\n",
      "\tspeed: 0.0433s/iter; left time: 290.4176s\n",
      "\titers: 500, epoch: 3 | loss: 0.1056821\n",
      "\tspeed: 0.0435s/iter; left time: 287.5143s\n",
      "\titers: 600, epoch: 3 | loss: 0.1015013\n",
      "\tspeed: 0.0434s/iter; left time: 282.8398s\n",
      "\titers: 700, epoch: 3 | loss: 0.0988214\n",
      "\tspeed: 0.0432s/iter; left time: 277.3490s\n",
      "\titers: 800, epoch: 3 | loss: 0.0921170\n",
      "\tspeed: 0.0434s/iter; left time: 273.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0983127 Vali Loss: 0.1265134 Test Loss: 0.1395640\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0880410\n",
      "\tspeed: 0.1510s/iter; left time: 924.5625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0798025\n",
      "\tspeed: 0.0432s/iter; left time: 260.3133s\n",
      "\titers: 300, epoch: 4 | loss: 0.0979441\n",
      "\tspeed: 0.0434s/iter; left time: 257.0936s\n",
      "\titers: 400, epoch: 4 | loss: 0.0861223\n",
      "\tspeed: 0.0433s/iter; left time: 252.3061s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869310\n",
      "\tspeed: 0.0433s/iter; left time: 247.7644s\n",
      "\titers: 600, epoch: 4 | loss: 0.0757373\n",
      "\tspeed: 0.0434s/iter; left time: 244.2571s\n",
      "\titers: 700, epoch: 4 | loss: 0.0835298\n",
      "\tspeed: 0.0433s/iter; left time: 238.9210s\n",
      "\titers: 800, epoch: 4 | loss: 0.0831103\n",
      "\tspeed: 0.0434s/iter; left time: 235.2642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.0864388 Vali Loss: 0.1293963 Test Loss: 0.1473150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0775075\n",
      "\tspeed: 0.1507s/iter; left time: 789.0607s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723159\n",
      "\tspeed: 0.0435s/iter; left time: 223.1570s\n",
      "\titers: 300, epoch: 5 | loss: 0.0751024\n",
      "\tspeed: 0.0434s/iter; left time: 218.2749s\n",
      "\titers: 400, epoch: 5 | loss: 0.0762491\n",
      "\tspeed: 0.0435s/iter; left time: 214.5913s\n",
      "\titers: 500, epoch: 5 | loss: 0.0781353\n",
      "\tspeed: 0.0433s/iter; left time: 209.4697s\n",
      "\titers: 600, epoch: 5 | loss: 0.0721987\n",
      "\tspeed: 0.0433s/iter; left time: 204.9027s\n",
      "\titers: 700, epoch: 5 | loss: 0.0738901\n",
      "\tspeed: 0.0432s/iter; left time: 200.4601s\n",
      "\titers: 800, epoch: 5 | loss: 0.0699378\n",
      "\tspeed: 0.0433s/iter; left time: 196.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.0739823 Vali Loss: 0.1330833 Test Loss: 0.1492142\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03864600136876106, rmse:0.19658586382865906, mae:0.13396330177783966, rse:0.696444571018219\n",
      "Original data scale mse:34850600.0, rmse:5903.439453125, mae:3733.352783203125, rse:0.29413774609565735\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1386947\n",
      "\tspeed: 0.0450s/iter; left time: 395.3493s\n",
      "\titers: 200, epoch: 1 | loss: 0.1249647\n",
      "\tspeed: 0.0433s/iter; left time: 375.9273s\n",
      "\titers: 300, epoch: 1 | loss: 0.1322309\n",
      "\tspeed: 0.0433s/iter; left time: 371.5956s\n",
      "\titers: 400, epoch: 1 | loss: 0.1278038\n",
      "\tspeed: 0.0433s/iter; left time: 367.3453s\n",
      "\titers: 500, epoch: 1 | loss: 0.1187004\n",
      "\tspeed: 0.0434s/iter; left time: 364.1323s\n",
      "\titers: 600, epoch: 1 | loss: 0.1030896\n",
      "\tspeed: 0.0434s/iter; left time: 359.7246s\n",
      "\titers: 700, epoch: 1 | loss: 0.1130229\n",
      "\tspeed: 0.0433s/iter; left time: 354.3209s\n",
      "\titers: 800, epoch: 1 | loss: 0.1079229\n",
      "\tspeed: 0.0432s/iter; left time: 349.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1185558 Vali Loss: 0.1246863 Test Loss: 0.1332831\n",
      "Validation loss decreased (inf --> 0.124686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1147446\n",
      "\tspeed: 0.1543s/iter; left time: 1219.5108s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133322\n",
      "\tspeed: 0.0434s/iter; left time: 338.6678s\n",
      "\titers: 300, epoch: 2 | loss: 0.1136076\n",
      "\tspeed: 0.0433s/iter; left time: 333.6482s\n",
      "\titers: 400, epoch: 2 | loss: 0.1091938\n",
      "\tspeed: 0.0434s/iter; left time: 329.8867s\n",
      "\titers: 500, epoch: 2 | loss: 0.1148756\n",
      "\tspeed: 0.0432s/iter; left time: 324.2885s\n",
      "\titers: 600, epoch: 2 | loss: 0.1102323\n",
      "\tspeed: 0.0432s/iter; left time: 319.9440s\n",
      "\titers: 700, epoch: 2 | loss: 0.1040421\n",
      "\tspeed: 0.0432s/iter; left time: 315.6592s\n",
      "\titers: 800, epoch: 2 | loss: 0.1039490\n",
      "\tspeed: 0.0432s/iter; left time: 311.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.1088817 Vali Loss: 0.1228524 Test Loss: 0.1343368\n",
      "Validation loss decreased (0.124686 --> 0.122852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963996\n",
      "\tspeed: 0.1539s/iter; left time: 1079.1743s\n",
      "\titers: 200, epoch: 3 | loss: 0.0965821\n",
      "\tspeed: 0.0433s/iter; left time: 299.0419s\n",
      "\titers: 300, epoch: 3 | loss: 0.1092963\n",
      "\tspeed: 0.0432s/iter; left time: 294.5014s\n",
      "\titers: 400, epoch: 3 | loss: 0.1067763\n",
      "\tspeed: 0.0432s/iter; left time: 290.0873s\n",
      "\titers: 500, epoch: 3 | loss: 0.0976135\n",
      "\tspeed: 0.0433s/iter; left time: 286.1568s\n",
      "\titers: 600, epoch: 3 | loss: 0.1015769\n",
      "\tspeed: 0.0433s/iter; left time: 282.0217s\n",
      "\titers: 700, epoch: 3 | loss: 0.0944862\n",
      "\tspeed: 0.0432s/iter; left time: 277.2727s\n",
      "\titers: 800, epoch: 3 | loss: 0.0962675\n",
      "\tspeed: 0.0433s/iter; left time: 273.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.0989200 Vali Loss: 0.1238697 Test Loss: 0.1394016\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0953746\n",
      "\tspeed: 0.1514s/iter; left time: 927.4587s\n",
      "\titers: 200, epoch: 4 | loss: 0.0847741\n",
      "\tspeed: 0.0433s/iter; left time: 260.8284s\n",
      "\titers: 300, epoch: 4 | loss: 0.0851369\n",
      "\tspeed: 0.0433s/iter; left time: 256.7374s\n",
      "\titers: 400, epoch: 4 | loss: 0.0809225\n",
      "\tspeed: 0.0433s/iter; left time: 252.3377s\n",
      "\titers: 500, epoch: 4 | loss: 0.0888828\n",
      "\tspeed: 0.0433s/iter; left time: 247.7859s\n",
      "\titers: 600, epoch: 4 | loss: 0.0775692\n",
      "\tspeed: 0.0433s/iter; left time: 243.2575s\n",
      "\titers: 700, epoch: 4 | loss: 0.0932631\n",
      "\tspeed: 0.0433s/iter; left time: 239.0073s\n",
      "\titers: 800, epoch: 4 | loss: 0.0834410\n",
      "\tspeed: 0.0433s/iter; left time: 235.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.0869942 Vali Loss: 0.1296563 Test Loss: 0.1460391\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808855\n",
      "\tspeed: 0.1516s/iter; left time: 793.7185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774749\n",
      "\tspeed: 0.0433s/iter; left time: 222.2263s\n",
      "\titers: 300, epoch: 5 | loss: 0.0710423\n",
      "\tspeed: 0.0432s/iter; left time: 217.7287s\n",
      "\titers: 400, epoch: 5 | loss: 0.0726677\n",
      "\tspeed: 0.0433s/iter; left time: 213.5688s\n",
      "\titers: 500, epoch: 5 | loss: 0.0670229\n",
      "\tspeed: 0.0433s/iter; left time: 209.3161s\n",
      "\titers: 600, epoch: 5 | loss: 0.0768453\n",
      "\tspeed: 0.0433s/iter; left time: 205.0339s\n",
      "\titers: 700, epoch: 5 | loss: 0.0667815\n",
      "\tspeed: 0.0432s/iter; left time: 200.4275s\n",
      "\titers: 800, epoch: 5 | loss: 0.0742408\n",
      "\tspeed: 0.0434s/iter; left time: 196.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.0746226 Vali Loss: 0.1301747 Test Loss: 0.1443116\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03962956741452217, rmse:0.1990717649459839, mae:0.13433684408664703, rse:0.7052512764930725\n",
      "Original data scale mse:35550684.0, rmse:5962.439453125, mae:3720.859130859375, rse:0.29707738757133484\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.6629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.6722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.5148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.7053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loss_function  Iteration  Pred_len     MSE    RMSE     MAE     RSE\n",
       "0            MSE          1        24  0.0215  0.1465  0.0939  0.5172\n",
       "1            MSE          2        24  0.0214  0.1464  0.0944  0.5169\n",
       "2            MSE          1        96  0.0350  0.1872  0.1292  0.6629\n",
       "3            MSE          2        96  0.0360  0.1898  0.1320  0.6722\n",
       "4            MSE          1       168  0.0386  0.1965  0.1367  0.6961\n",
       "5            MSE          2       168  0.0376  0.1939  0.1369  0.6870\n",
       "6           RMSE          1        24  0.0215  0.1467  0.0941  0.5180\n",
       "7           RMSE          2        24  0.0214  0.1463  0.0941  0.5166\n",
       "8           RMSE          1        96  0.0351  0.1873  0.1296  0.6634\n",
       "9           RMSE          2        96  0.0361  0.1901  0.1320  0.6731\n",
       "10          RMSE          1       168  0.0386  0.1963  0.1373  0.6956\n",
       "11          RMSE          2       168  0.0376  0.1938  0.1367  0.6867\n",
       "12           MAE          1        24  0.0219  0.1480  0.0902  0.5226\n",
       "13           MAE          2        24  0.0213  0.1458  0.0895  0.5148\n",
       "14           MAE          1        96  0.0354  0.1881  0.1257  0.6662\n",
       "15           MAE          2        96  0.0378  0.1945  0.1285  0.6887\n",
       "16           MAE          1       168  0.0386  0.1966  0.1340  0.6964\n",
       "17           MAE          2       168  0.0396  0.1991  0.1343  0.7053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17161886.0</td>\n",
       "      <td>4142.6904</td>\n",
       "      <td>2553.8210</td>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17119326.0</td>\n",
       "      <td>4137.5508</td>\n",
       "      <td>2579.4404</td>\n",
       "      <td>0.2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30968164.0</td>\n",
       "      <td>5564.9048</td>\n",
       "      <td>3569.1465</td>\n",
       "      <td>0.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32859850.0</td>\n",
       "      <td>5732.3511</td>\n",
       "      <td>3690.5352</td>\n",
       "      <td>0.2855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35078208.0</td>\n",
       "      <td>5922.6860</td>\n",
       "      <td>3812.8645</td>\n",
       "      <td>0.2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34050108.0</td>\n",
       "      <td>5835.2471</td>\n",
       "      <td>3839.4783</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17274290.0</td>\n",
       "      <td>4156.2349</td>\n",
       "      <td>2560.8831</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17063130.0</td>\n",
       "      <td>4130.7544</td>\n",
       "      <td>2569.0222</td>\n",
       "      <td>0.2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31071448.0</td>\n",
       "      <td>5574.1768</td>\n",
       "      <td>3584.5562</td>\n",
       "      <td>0.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32765476.0</td>\n",
       "      <td>5724.1138</td>\n",
       "      <td>3690.9900</td>\n",
       "      <td>0.2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34756880.0</td>\n",
       "      <td>5895.4966</td>\n",
       "      <td>3835.1350</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33994724.0</td>\n",
       "      <td>5830.4995</td>\n",
       "      <td>3832.4016</td>\n",
       "      <td>0.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16924342.0</td>\n",
       "      <td>4113.9204</td>\n",
       "      <td>2418.1907</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16638304.0</td>\n",
       "      <td>4079.0078</td>\n",
       "      <td>2411.2668</td>\n",
       "      <td>0.2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31024660.0</td>\n",
       "      <td>5569.9785</td>\n",
       "      <td>3461.2515</td>\n",
       "      <td>0.2774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33443530.0</td>\n",
       "      <td>5783.0381</td>\n",
       "      <td>3538.7659</td>\n",
       "      <td>0.2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34850600.0</td>\n",
       "      <td>5903.4395</td>\n",
       "      <td>3733.3528</td>\n",
       "      <td>0.2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35550684.0</td>\n",
       "      <td>5962.4395</td>\n",
       "      <td>3720.8591</td>\n",
       "      <td>0.2971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17161886.0  4142.6904  2553.8210  0.2060\n",
       "              2         24        17119326.0  4137.5508  2579.4404  0.2057\n",
       "              1         96        30968164.0  5564.9048  3569.1465  0.2771\n",
       "              2         96        32859850.0  5732.3511  3690.5352  0.2855\n",
       "              1         168       35078208.0  5922.6860  3812.8645  0.2951\n",
       "              2         168       34050108.0  5835.2471  3839.4783  0.2907\n",
       "RMSE          1         24        17274290.0  4156.2349  2560.8831  0.2067\n",
       "              2         24        17063130.0  4130.7544  2569.0222  0.2054\n",
       "              1         96        31071448.0  5574.1768  3584.5562  0.2776\n",
       "              2         96        32765476.0  5724.1138  3690.9900  0.2851\n",
       "              1         168       34756880.0  5895.4966  3835.1350  0.2937\n",
       "              2         168       33994724.0  5830.4995  3832.4016  0.2905\n",
       "MAE           1         24        16924342.0  4113.9204  2418.1907  0.2046\n",
       "              2         24        16638304.0  4079.0078  2411.2668  0.2028\n",
       "              1         96        31024660.0  5569.9785  3461.2515  0.2774\n",
       "              2         96        33443530.0  5783.0381  3538.7659  0.2880\n",
       "              1         168       34850600.0  5903.4395  3733.3528  0.2941\n",
       "              2         168       35550684.0  5962.4395  3720.8591  0.2971"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.6682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1952</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0216  0.1469  0.0899  0.5187\n",
       "         MSE            0.0214  0.1464  0.0941  0.5171\n",
       "         RMSE           0.0215  0.1465  0.0941  0.5173\n",
       "96       MAE            0.0366  0.1913  0.1271  0.6775\n",
       "         MSE            0.0355  0.1885  0.1306  0.6676\n",
       "         RMSE           0.0356  0.1887  0.1308  0.6682\n",
       "168      MAE            0.0391  0.1978  0.1342  0.7008\n",
       "         MSE            0.0381  0.1952  0.1368  0.6916\n",
       "         RMSE           0.0381  0.1951  0.1370  0.6911"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16781323.0</td>\n",
       "      <td>4096.4641</td>\n",
       "      <td>2414.7288</td>\n",
       "      <td>0.2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17140606.0</td>\n",
       "      <td>4140.1206</td>\n",
       "      <td>2566.6307</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17168710.0</td>\n",
       "      <td>4143.4946</td>\n",
       "      <td>2564.9526</td>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32234095.0</td>\n",
       "      <td>5676.5083</td>\n",
       "      <td>3500.0087</td>\n",
       "      <td>0.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31914007.0</td>\n",
       "      <td>5648.6279</td>\n",
       "      <td>3629.8408</td>\n",
       "      <td>0.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>31918462.0</td>\n",
       "      <td>5649.1453</td>\n",
       "      <td>3637.7731</td>\n",
       "      <td>0.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35200642.0</td>\n",
       "      <td>5932.9395</td>\n",
       "      <td>3727.1060</td>\n",
       "      <td>0.2956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34564158.0</td>\n",
       "      <td>5878.9666</td>\n",
       "      <td>3826.1714</td>\n",
       "      <td>0.2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34375802.0</td>\n",
       "      <td>5862.9980</td>\n",
       "      <td>3833.7683</td>\n",
       "      <td>0.2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16781323.0  4096.4641  2414.7288  0.2037\n",
       "         MSE            17140606.0  4140.1206  2566.6307  0.2059\n",
       "         RMSE           17168710.0  4143.4946  2564.9526  0.2060\n",
       "96       MAE            32234095.0  5676.5083  3500.0087  0.2827\n",
       "         MSE            31914007.0  5648.6279  3629.8408  0.2813\n",
       "         RMSE           31918462.0  5649.1453  3637.7731  0.2813\n",
       "168      MAE            35200642.0  5932.9395  3727.1060  0.2956\n",
       "         MSE            34564158.0  5878.9666  3826.1714  0.2929\n",
       "         RMSE           34375802.0  5862.9980  3833.7683  0.2921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MinMax Scaler (0, 5) Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_5_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 100, epoch: 1 | loss: 1.2955509\n",
      "\tspeed: 0.0741s/iter; left time: 663.7305s\n",
      "\titers: 200, epoch: 1 | loss: 0.9552944\n",
      "\tspeed: 0.0421s/iter; left time: 373.4564s\n",
      "\titers: 300, epoch: 1 | loss: 0.7724751\n",
      "\tspeed: 0.0422s/iter; left time: 370.0596s\n",
      "\titers: 400, epoch: 1 | loss: 0.6487309\n",
      "\tspeed: 0.0443s/iter; left time: 383.8937s\n",
      "\titers: 500, epoch: 1 | loss: 0.5562119\n",
      "\tspeed: 0.0465s/iter; left time: 397.7432s\n",
      "\titers: 600, epoch: 1 | loss: 0.4853845\n",
      "\tspeed: 0.0464s/iter; left time: 392.8360s\n",
      "\titers: 700, epoch: 1 | loss: 0.7075042\n",
      "\tspeed: 0.0463s/iter; left time: 387.1326s\n",
      "\titers: 800, epoch: 1 | loss: 0.5475918\n",
      "\tspeed: 0.0459s/iter; left time: 378.8497s\n",
      "\titers: 900, epoch: 1 | loss: 0.4198295\n",
      "\tspeed: 0.0462s/iter; left time: 377.1901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 906 | Train Loss: 0.8569615 Vali Loss: 0.6873081 Test Loss: 0.7878568\n",
      "Validation loss decreased (inf --> 0.687308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2908996\n",
      "\tspeed: 0.1045s/iter; left time: 841.5384s\n",
      "\titers: 200, epoch: 2 | loss: 0.4945736\n",
      "\tspeed: 0.0459s/iter; left time: 364.9231s\n",
      "\titers: 300, epoch: 2 | loss: 0.3492992\n",
      "\tspeed: 0.0461s/iter; left time: 361.8923s\n",
      "\titers: 400, epoch: 2 | loss: 0.4507950\n",
      "\tspeed: 0.0458s/iter; left time: 355.4533s\n",
      "\titers: 500, epoch: 2 | loss: 0.2832457\n",
      "\tspeed: 0.0450s/iter; left time: 344.1111s\n",
      "\titers: 600, epoch: 2 | loss: 0.3258670\n",
      "\tspeed: 0.0420s/iter; left time: 317.5177s\n",
      "\titers: 700, epoch: 2 | loss: 0.3025336\n",
      "\tspeed: 0.0426s/iter; left time: 317.7499s\n",
      "\titers: 800, epoch: 2 | loss: 0.4511547\n",
      "\tspeed: 0.0416s/iter; left time: 306.1753s\n",
      "\titers: 900, epoch: 2 | loss: 0.3327818\n",
      "\tspeed: 0.0419s/iter; left time: 304.1730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.18s\n",
      "Steps: 906 | Train Loss: 0.3932838 Vali Loss: 0.5326899 Test Loss: 0.6160156\n",
      "Validation loss decreased (0.687308 --> 0.532690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3571615\n",
      "\tspeed: 0.1025s/iter; left time: 733.0268s\n",
      "\titers: 200, epoch: 3 | loss: 0.2843337\n",
      "\tspeed: 0.0420s/iter; left time: 296.0519s\n",
      "\titers: 300, epoch: 3 | loss: 0.3252126\n",
      "\tspeed: 0.0415s/iter; left time: 288.6860s\n",
      "\titers: 400, epoch: 3 | loss: 0.3026650\n",
      "\tspeed: 0.0421s/iter; left time: 288.2197s\n",
      "\titers: 500, epoch: 3 | loss: 0.4236715\n",
      "\tspeed: 0.0417s/iter; left time: 281.4176s\n",
      "\titers: 600, epoch: 3 | loss: 0.3850143\n",
      "\tspeed: 0.0417s/iter; left time: 277.3647s\n",
      "\titers: 700, epoch: 3 | loss: 0.3521188\n",
      "\tspeed: 0.0415s/iter; left time: 271.9266s\n",
      "\titers: 800, epoch: 3 | loss: 0.3191999\n",
      "\tspeed: 0.0421s/iter; left time: 271.7201s\n",
      "\titers: 900, epoch: 3 | loss: 0.3292238\n",
      "\tspeed: 0.0419s/iter; left time: 265.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 906 | Train Loss: 0.3358734 Vali Loss: 0.5323205 Test Loss: 0.5856130\n",
      "Validation loss decreased (0.532690 --> 0.532320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2747155\n",
      "\tspeed: 0.1026s/iter; left time: 640.5060s\n",
      "\titers: 200, epoch: 4 | loss: 0.3039421\n",
      "\tspeed: 0.0421s/iter; left time: 258.4194s\n",
      "\titers: 300, epoch: 4 | loss: 0.2959844\n",
      "\tspeed: 0.0418s/iter; left time: 252.5021s\n",
      "\titers: 400, epoch: 4 | loss: 0.2454495\n",
      "\tspeed: 0.0414s/iter; left time: 245.9832s\n",
      "\titers: 500, epoch: 4 | loss: 0.3527941\n",
      "\tspeed: 0.0419s/iter; left time: 244.7111s\n",
      "\titers: 600, epoch: 4 | loss: 0.2963355\n",
      "\tspeed: 0.0422s/iter; left time: 242.3420s\n",
      "\titers: 700, epoch: 4 | loss: 0.2859131\n",
      "\tspeed: 0.0409s/iter; left time: 230.5801s\n",
      "\titers: 800, epoch: 4 | loss: 0.3464130\n",
      "\tspeed: 0.0425s/iter; left time: 235.5686s\n",
      "\titers: 900, epoch: 4 | loss: 0.2799308\n",
      "\tspeed: 0.0420s/iter; left time: 228.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 906 | Train Loss: 0.3039945 Vali Loss: 0.5309961 Test Loss: 0.5822682\n",
      "Validation loss decreased (0.532320 --> 0.530996).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2833566\n",
      "\tspeed: 0.0989s/iter; left time: 527.9522s\n",
      "\titers: 200, epoch: 5 | loss: 0.2757988\n",
      "\tspeed: 0.0416s/iter; left time: 217.7760s\n",
      "\titers: 300, epoch: 5 | loss: 0.2590825\n",
      "\tspeed: 0.0415s/iter; left time: 213.0183s\n",
      "\titers: 400, epoch: 5 | loss: 0.3419651\n",
      "\tspeed: 0.0413s/iter; left time: 207.8484s\n",
      "\titers: 500, epoch: 5 | loss: 0.2305000\n",
      "\tspeed: 0.0411s/iter; left time: 202.8313s\n",
      "\titers: 600, epoch: 5 | loss: 0.3045399\n",
      "\tspeed: 0.0419s/iter; left time: 202.5038s\n",
      "\titers: 700, epoch: 5 | loss: 0.2622735\n",
      "\tspeed: 0.0409s/iter; left time: 193.5808s\n",
      "\titers: 800, epoch: 5 | loss: 0.2602548\n",
      "\tspeed: 0.0416s/iter; left time: 192.9355s\n",
      "\titers: 900, epoch: 5 | loss: 0.2675554\n",
      "\tspeed: 0.0417s/iter; left time: 189.1591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 906 | Train Loss: 0.2700340 Vali Loss: 0.5452632 Test Loss: 0.6085476\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2595244\n",
      "\tspeed: 0.0964s/iter; left time: 427.0594s\n",
      "\titers: 200, epoch: 6 | loss: 0.2291697\n",
      "\tspeed: 0.0425s/iter; left time: 183.9688s\n",
      "\titers: 300, epoch: 6 | loss: 0.2172824\n",
      "\tspeed: 0.0420s/iter; left time: 177.7288s\n",
      "\titers: 400, epoch: 6 | loss: 0.2253064\n",
      "\tspeed: 0.0417s/iter; left time: 172.1265s\n",
      "\titers: 500, epoch: 6 | loss: 0.2702653\n",
      "\tspeed: 0.0423s/iter; left time: 170.5485s\n",
      "\titers: 600, epoch: 6 | loss: 0.2020460\n",
      "\tspeed: 0.0425s/iter; left time: 167.2609s\n",
      "\titers: 700, epoch: 6 | loss: 0.2571706\n",
      "\tspeed: 0.0420s/iter; left time: 160.8347s\n",
      "\titers: 800, epoch: 6 | loss: 0.1847658\n",
      "\tspeed: 0.0423s/iter; left time: 157.7243s\n",
      "\titers: 900, epoch: 6 | loss: 0.1856422\n",
      "\tspeed: 0.0422s/iter; left time: 153.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 906 | Train Loss: 0.2338159 Vali Loss: 0.5474004 Test Loss: 0.6261350\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1740544\n",
      "\tspeed: 0.0986s/iter; left time: 347.6459s\n",
      "\titers: 200, epoch: 7 | loss: 0.2262328\n",
      "\tspeed: 0.0427s/iter; left time: 146.3884s\n",
      "\titers: 300, epoch: 7 | loss: 0.2010648\n",
      "\tspeed: 0.0418s/iter; left time: 139.1227s\n",
      "\titers: 400, epoch: 7 | loss: 0.2405860\n",
      "\tspeed: 0.0425s/iter; left time: 136.9432s\n",
      "\titers: 500, epoch: 7 | loss: 0.2178580\n",
      "\tspeed: 0.0428s/iter; left time: 133.6670s\n",
      "\titers: 600, epoch: 7 | loss: 0.2132667\n",
      "\tspeed: 0.0423s/iter; left time: 127.8723s\n",
      "\titers: 700, epoch: 7 | loss: 0.2092524\n",
      "\tspeed: 0.0425s/iter; left time: 124.3866s\n",
      "\titers: 800, epoch: 7 | loss: 0.1882412\n",
      "\tspeed: 0.0425s/iter; left time: 120.0819s\n",
      "\titers: 900, epoch: 7 | loss: 0.1777569\n",
      "\tspeed: 0.0420s/iter; left time: 114.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 906 | Train Loss: 0.1979352 Vali Loss: 0.5492589 Test Loss: 0.6682735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5821053981781006, rmse:0.7629583477973938, mae:0.507258951663971, rse:0.5388815999031067\n",
      "Original data scale mse:19813680.0, rmse:4451.255859375, mae:2843.837890625, rse:0.22132542729377747\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.4652840\n",
      "\tspeed: 0.0441s/iter; left time: 394.7447s\n",
      "\titers: 200, epoch: 1 | loss: 1.0085156\n",
      "\tspeed: 0.0420s/iter; left time: 372.4115s\n",
      "\titers: 300, epoch: 1 | loss: 0.8448955\n",
      "\tspeed: 0.0418s/iter; left time: 365.9440s\n",
      "\titers: 400, epoch: 1 | loss: 0.6875272\n",
      "\tspeed: 0.0420s/iter; left time: 363.4197s\n",
      "\titers: 500, epoch: 1 | loss: 0.6479842\n",
      "\tspeed: 0.0417s/iter; left time: 356.9306s\n",
      "\titers: 600, epoch: 1 | loss: 0.5280257\n",
      "\tspeed: 0.0421s/iter; left time: 356.2943s\n",
      "\titers: 700, epoch: 1 | loss: 0.5537811\n",
      "\tspeed: 0.0418s/iter; left time: 349.1911s\n",
      "\titers: 800, epoch: 1 | loss: 0.5322759\n",
      "\tspeed: 0.0414s/iter; left time: 342.3344s\n",
      "\titers: 900, epoch: 1 | loss: 0.4476770\n",
      "\tspeed: 0.0416s/iter; left time: 339.1351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 906 | Train Loss: 0.8519401 Vali Loss: 0.6956597 Test Loss: 0.7996026\n",
      "Validation loss decreased (inf --> 0.695660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3601714\n",
      "\tspeed: 0.1036s/iter; left time: 834.5366s\n",
      "\titers: 200, epoch: 2 | loss: 0.4070456\n",
      "\tspeed: 0.0422s/iter; left time: 336.0380s\n",
      "\titers: 300, epoch: 2 | loss: 0.5432580\n",
      "\tspeed: 0.0430s/iter; left time: 337.7428s\n",
      "\titers: 400, epoch: 2 | loss: 0.3387829\n",
      "\tspeed: 0.0426s/iter; left time: 330.4870s\n",
      "\titers: 500, epoch: 2 | loss: 0.4461557\n",
      "\tspeed: 0.0424s/iter; left time: 324.8676s\n",
      "\titers: 600, epoch: 2 | loss: 0.4543307\n",
      "\tspeed: 0.0427s/iter; left time: 322.6258s\n",
      "\titers: 700, epoch: 2 | loss: 0.3566880\n",
      "\tspeed: 0.0428s/iter; left time: 318.7344s\n",
      "\titers: 800, epoch: 2 | loss: 0.2431573\n",
      "\tspeed: 0.0429s/iter; left time: 315.3682s\n",
      "\titers: 900, epoch: 2 | loss: 0.2864605\n",
      "\tspeed: 0.0427s/iter; left time: 309.7035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 906 | Train Loss: 0.3926978 Vali Loss: 0.5371435 Test Loss: 0.6098121\n",
      "Validation loss decreased (0.695660 --> 0.537144).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3862467\n",
      "\tspeed: 0.1043s/iter; left time: 745.7377s\n",
      "\titers: 200, epoch: 3 | loss: 0.2747766\n",
      "\tspeed: 0.0426s/iter; left time: 300.0097s\n",
      "\titers: 300, epoch: 3 | loss: 0.2612053\n",
      "\tspeed: 0.0418s/iter; left time: 290.6114s\n",
      "\titers: 400, epoch: 3 | loss: 0.3759600\n",
      "\tspeed: 0.0424s/iter; left time: 290.3571s\n",
      "\titers: 500, epoch: 3 | loss: 0.2369541\n",
      "\tspeed: 0.0428s/iter; left time: 289.0868s\n",
      "\titers: 600, epoch: 3 | loss: 0.3624022\n",
      "\tspeed: 0.0424s/iter; left time: 281.9784s\n",
      "\titers: 700, epoch: 3 | loss: 0.3059808\n",
      "\tspeed: 0.0426s/iter; left time: 278.8671s\n",
      "\titers: 800, epoch: 3 | loss: 0.3212331\n",
      "\tspeed: 0.0427s/iter; left time: 275.0987s\n",
      "\titers: 900, epoch: 3 | loss: 0.3600551\n",
      "\tspeed: 0.0426s/iter; left time: 270.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 906 | Train Loss: 0.3345295 Vali Loss: 0.5267611 Test Loss: 0.5628039\n",
      "Validation loss decreased (0.537144 --> 0.526761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3000818\n",
      "\tspeed: 0.1004s/iter; left time: 626.9277s\n",
      "\titers: 200, epoch: 4 | loss: 0.4251096\n",
      "\tspeed: 0.0417s/iter; left time: 256.2227s\n",
      "\titers: 300, epoch: 4 | loss: 0.3802286\n",
      "\tspeed: 0.0421s/iter; left time: 254.1258s\n",
      "\titers: 400, epoch: 4 | loss: 0.3725364\n",
      "\tspeed: 0.0419s/iter; left time: 249.1114s\n",
      "\titers: 500, epoch: 4 | loss: 0.3290046\n",
      "\tspeed: 0.0417s/iter; left time: 243.8045s\n",
      "\titers: 600, epoch: 4 | loss: 0.2688568\n",
      "\tspeed: 0.0416s/iter; left time: 238.6449s\n",
      "\titers: 700, epoch: 4 | loss: 0.2857059\n",
      "\tspeed: 0.0420s/iter; left time: 236.7495s\n",
      "\titers: 800, epoch: 4 | loss: 0.2991520\n",
      "\tspeed: 0.0425s/iter; left time: 235.8439s\n",
      "\titers: 900, epoch: 4 | loss: 0.3079047\n",
      "\tspeed: 0.0421s/iter; left time: 228.9017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.3037070 Vali Loss: 0.5354905 Test Loss: 0.5876449\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3295012\n",
      "\tspeed: 0.0970s/iter; left time: 517.8620s\n",
      "\titers: 200, epoch: 5 | loss: 0.2528384\n",
      "\tspeed: 0.0415s/iter; left time: 217.1357s\n",
      "\titers: 300, epoch: 5 | loss: 0.3216209\n",
      "\tspeed: 0.0413s/iter; left time: 212.3707s\n",
      "\titers: 400, epoch: 5 | loss: 0.3265002\n",
      "\tspeed: 0.0413s/iter; left time: 207.8605s\n",
      "\titers: 500, epoch: 5 | loss: 0.3523935\n",
      "\tspeed: 0.0417s/iter; left time: 205.7172s\n",
      "\titers: 600, epoch: 5 | loss: 0.3028996\n",
      "\tspeed: 0.0418s/iter; left time: 202.2249s\n",
      "\titers: 700, epoch: 5 | loss: 0.2140381\n",
      "\tspeed: 0.0441s/iter; left time: 209.0597s\n",
      "\titers: 800, epoch: 5 | loss: 0.2248073\n",
      "\tspeed: 0.0457s/iter; left time: 211.9077s\n",
      "\titers: 900, epoch: 5 | loss: 0.2590304\n",
      "\tspeed: 0.0428s/iter; left time: 194.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 906 | Train Loss: 0.2722360 Vali Loss: 0.5554773 Test Loss: 0.6083224\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1954984\n",
      "\tspeed: 0.1019s/iter; left time: 451.7180s\n",
      "\titers: 200, epoch: 6 | loss: 0.2298577\n",
      "\tspeed: 0.0458s/iter; left time: 198.3382s\n",
      "\titers: 300, epoch: 6 | loss: 0.2375662\n",
      "\tspeed: 0.0453s/iter; left time: 191.7972s\n",
      "\titers: 400, epoch: 6 | loss: 0.2018877\n",
      "\tspeed: 0.0433s/iter; left time: 179.0724s\n",
      "\titers: 500, epoch: 6 | loss: 0.2554982\n",
      "\tspeed: 0.0419s/iter; left time: 168.8133s\n",
      "\titers: 600, epoch: 6 | loss: 0.2617479\n",
      "\tspeed: 0.0418s/iter; left time: 164.3685s\n",
      "\titers: 700, epoch: 6 | loss: 0.2499321\n",
      "\tspeed: 0.0419s/iter; left time: 160.3996s\n",
      "\titers: 800, epoch: 6 | loss: 0.3894339\n",
      "\tspeed: 0.0420s/iter; left time: 156.6211s\n",
      "\titers: 900, epoch: 6 | loss: 0.2492436\n",
      "\tspeed: 0.0420s/iter; left time: 152.4904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.42s\n",
      "Steps: 906 | Train Loss: 0.2354576 Vali Loss: 0.5647299 Test Loss: 0.6250629\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5617363452911377, rmse:0.7494907379150391, mae:0.5069934725761414, rse:0.5293693542480469\n",
      "Original data scale mse:18792862.0, rmse:4335.0732421875, mae:2853.94873046875, rse:0.2155485898256302\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.5280497\n",
      "\tspeed: 0.0763s/iter; left time: 682.1174s\n",
      "\titers: 200, epoch: 1 | loss: 1.1644326\n",
      "\tspeed: 0.0479s/iter; left time: 423.4197s\n",
      "\titers: 300, epoch: 1 | loss: 1.1131778\n",
      "\tspeed: 0.0479s/iter; left time: 418.3573s\n",
      "\titers: 400, epoch: 1 | loss: 0.9590992\n",
      "\tspeed: 0.0477s/iter; left time: 412.5022s\n",
      "\titers: 500, epoch: 1 | loss: 0.9247752\n",
      "\tspeed: 0.0477s/iter; left time: 407.0377s\n",
      "\titers: 600, epoch: 1 | loss: 0.7794565\n",
      "\tspeed: 0.0477s/iter; left time: 402.4615s\n",
      "\titers: 700, epoch: 1 | loss: 0.7564425\n",
      "\tspeed: 0.0477s/iter; left time: 397.9503s\n",
      "\titers: 800, epoch: 1 | loss: 0.7696915\n",
      "\tspeed: 0.0477s/iter; left time: 392.9644s\n",
      "\titers: 900, epoch: 1 | loss: 0.7584702\n",
      "\tspeed: 0.0483s/iter; left time: 393.5222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 904 | Train Loss: 1.1024237 Vali Loss: 1.0262518 Test Loss: 1.2655040\n",
      "Validation loss decreased (inf --> 1.026252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6087893\n",
      "\tspeed: 0.1179s/iter; left time: 947.5344s\n",
      "\titers: 200, epoch: 2 | loss: 0.6793842\n",
      "\tspeed: 0.0475s/iter; left time: 376.9935s\n",
      "\titers: 300, epoch: 2 | loss: 0.6456058\n",
      "\tspeed: 0.0475s/iter; left time: 372.3156s\n",
      "\titers: 400, epoch: 2 | loss: 0.5556484\n",
      "\tspeed: 0.0476s/iter; left time: 368.2285s\n",
      "\titers: 500, epoch: 2 | loss: 0.5931317\n",
      "\tspeed: 0.0475s/iter; left time: 363.1310s\n",
      "\titers: 600, epoch: 2 | loss: 0.6895592\n",
      "\tspeed: 0.0475s/iter; left time: 358.1559s\n",
      "\titers: 700, epoch: 2 | loss: 0.5512100\n",
      "\tspeed: 0.0475s/iter; left time: 353.6110s\n",
      "\titers: 800, epoch: 2 | loss: 0.6794570\n",
      "\tspeed: 0.0475s/iter; left time: 348.5182s\n",
      "\titers: 900, epoch: 2 | loss: 0.5509934\n",
      "\tspeed: 0.0476s/iter; left time: 344.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.6233279 Vali Loss: 0.8254015 Test Loss: 1.0094067\n",
      "Validation loss decreased (1.026252 --> 0.825401).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6882565\n",
      "\tspeed: 0.1213s/iter; left time: 865.4346s\n",
      "\titers: 200, epoch: 3 | loss: 0.4772428\n",
      "\tspeed: 0.0481s/iter; left time: 338.3984s\n",
      "\titers: 300, epoch: 3 | loss: 0.4577460\n",
      "\tspeed: 0.0479s/iter; left time: 332.1371s\n",
      "\titers: 400, epoch: 3 | loss: 0.4775720\n",
      "\tspeed: 0.0480s/iter; left time: 327.6519s\n",
      "\titers: 500, epoch: 3 | loss: 0.5146258\n",
      "\tspeed: 0.0479s/iter; left time: 322.6101s\n",
      "\titers: 600, epoch: 3 | loss: 0.5902147\n",
      "\tspeed: 0.0476s/iter; left time: 315.4312s\n",
      "\titers: 700, epoch: 3 | loss: 0.4888110\n",
      "\tspeed: 0.0500s/iter; left time: 326.7286s\n",
      "\titers: 800, epoch: 3 | loss: 0.5227294\n",
      "\tspeed: 0.0500s/iter; left time: 321.4300s\n",
      "\titers: 900, epoch: 3 | loss: 0.4940016\n",
      "\tspeed: 0.0481s/iter; left time: 304.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.24s\n",
      "Steps: 904 | Train Loss: 0.5307778 Vali Loss: 0.8081633 Test Loss: 0.9764747\n",
      "Validation loss decreased (0.825401 --> 0.808163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4368933\n",
      "\tspeed: 0.1191s/iter; left time: 741.7257s\n",
      "\titers: 200, epoch: 4 | loss: 0.4292979\n",
      "\tspeed: 0.0472s/iter; left time: 289.4026s\n",
      "\titers: 300, epoch: 4 | loss: 0.5011086\n",
      "\tspeed: 0.0473s/iter; left time: 285.3340s\n",
      "\titers: 400, epoch: 4 | loss: 0.3658071\n",
      "\tspeed: 0.0475s/iter; left time: 281.7932s\n",
      "\titers: 500, epoch: 4 | loss: 0.4801082\n",
      "\tspeed: 0.0478s/iter; left time: 278.6440s\n",
      "\titers: 600, epoch: 4 | loss: 0.4290215\n",
      "\tspeed: 0.0474s/iter; left time: 271.5053s\n",
      "\titers: 700, epoch: 4 | loss: 0.5015376\n",
      "\tspeed: 0.0468s/iter; left time: 263.3917s\n",
      "\titers: 800, epoch: 4 | loss: 0.4699356\n",
      "\tspeed: 0.0473s/iter; left time: 261.6025s\n",
      "\titers: 900, epoch: 4 | loss: 0.5180930\n",
      "\tspeed: 0.0472s/iter; left time: 256.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.4758516 Vali Loss: 0.8289881 Test Loss: 1.0929605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3858493\n",
      "\tspeed: 0.1143s/iter; left time: 608.6889s\n",
      "\titers: 200, epoch: 5 | loss: 0.5209685\n",
      "\tspeed: 0.0478s/iter; left time: 249.8269s\n",
      "\titers: 300, epoch: 5 | loss: 0.4700291\n",
      "\tspeed: 0.0478s/iter; left time: 245.1971s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054962\n",
      "\tspeed: 0.0475s/iter; left time: 238.6963s\n",
      "\titers: 500, epoch: 5 | loss: 0.3731504\n",
      "\tspeed: 0.0472s/iter; left time: 232.4344s\n",
      "\titers: 600, epoch: 5 | loss: 0.3807411\n",
      "\tspeed: 0.0475s/iter; left time: 229.2316s\n",
      "\titers: 700, epoch: 5 | loss: 0.3726144\n",
      "\tspeed: 0.0479s/iter; left time: 226.4752s\n",
      "\titers: 800, epoch: 5 | loss: 0.3669539\n",
      "\tspeed: 0.0479s/iter; left time: 221.6378s\n",
      "\titers: 900, epoch: 5 | loss: 0.3571638\n",
      "\tspeed: 0.0476s/iter; left time: 215.2425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 904 | Train Loss: 0.4060127 Vali Loss: 0.8449715 Test Loss: 1.0926709\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3537230\n",
      "\tspeed: 0.1145s/iter; left time: 506.3464s\n",
      "\titers: 200, epoch: 6 | loss: 0.3213464\n",
      "\tspeed: 0.0480s/iter; left time: 207.4926s\n",
      "\titers: 300, epoch: 6 | loss: 0.3506277\n",
      "\tspeed: 0.0478s/iter; left time: 201.8850s\n",
      "\titers: 400, epoch: 6 | loss: 0.3212157\n",
      "\tspeed: 0.0478s/iter; left time: 197.0472s\n",
      "\titers: 500, epoch: 6 | loss: 0.3315085\n",
      "\tspeed: 0.0478s/iter; left time: 192.0180s\n",
      "\titers: 600, epoch: 6 | loss: 0.3451603\n",
      "\tspeed: 0.0478s/iter; left time: 187.2679s\n",
      "\titers: 700, epoch: 6 | loss: 0.3058777\n",
      "\tspeed: 0.0478s/iter; left time: 182.7990s\n",
      "\titers: 800, epoch: 6 | loss: 0.3436225\n",
      "\tspeed: 0.0474s/iter; left time: 176.2028s\n",
      "\titers: 900, epoch: 6 | loss: 0.3178578\n",
      "\tspeed: 0.0472s/iter; left time: 170.9853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 904 | Train Loss: 0.3413911 Vali Loss: 0.8514896 Test Loss: 1.1427082\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.975433886051178, rmse:0.9876405596733093, mae:0.7069133520126343, rse:0.6994871497154236\n",
      "Original data scale mse:35925668.0, rmse:5993.80224609375, mae:4037.148193359375, rse:0.29849353432655334\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.4440839\n",
      "\tspeed: 0.0493s/iter; left time: 440.3832s\n",
      "\titers: 200, epoch: 1 | loss: 1.1649430\n",
      "\tspeed: 0.0463s/iter; left time: 409.2866s\n",
      "\titers: 300, epoch: 1 | loss: 0.9966143\n",
      "\tspeed: 0.0471s/iter; left time: 412.0009s\n",
      "\titers: 400, epoch: 1 | loss: 0.8752734\n",
      "\tspeed: 0.0468s/iter; left time: 404.6868s\n",
      "\titers: 500, epoch: 1 | loss: 0.9763706\n",
      "\tspeed: 0.0471s/iter; left time: 401.8808s\n",
      "\titers: 600, epoch: 1 | loss: 0.9641672\n",
      "\tspeed: 0.0468s/iter; left time: 395.2825s\n",
      "\titers: 700, epoch: 1 | loss: 0.7721155\n",
      "\tspeed: 0.0472s/iter; left time: 393.3943s\n",
      "\titers: 800, epoch: 1 | loss: 0.8730059\n",
      "\tspeed: 0.0471s/iter; left time: 388.3116s\n",
      "\titers: 900, epoch: 1 | loss: 0.6850500\n",
      "\tspeed: 0.0472s/iter; left time: 384.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.75s\n",
      "Steps: 904 | Train Loss: 1.0689406 Vali Loss: 0.9995072 Test Loss: 1.2439942\n",
      "Validation loss decreased (inf --> 0.999507).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7019956\n",
      "\tspeed: 0.1184s/iter; left time: 951.8515s\n",
      "\titers: 200, epoch: 2 | loss: 0.7590117\n",
      "\tspeed: 0.0477s/iter; left time: 378.2914s\n",
      "\titers: 300, epoch: 2 | loss: 0.5875075\n",
      "\tspeed: 0.0477s/iter; left time: 373.7233s\n",
      "\titers: 400, epoch: 2 | loss: 0.5684905\n",
      "\tspeed: 0.0468s/iter; left time: 361.7765s\n",
      "\titers: 500, epoch: 2 | loss: 0.5972313\n",
      "\tspeed: 0.0474s/iter; left time: 361.9769s\n",
      "\titers: 600, epoch: 2 | loss: 0.5984773\n",
      "\tspeed: 0.0473s/iter; left time: 356.8471s\n",
      "\titers: 700, epoch: 2 | loss: 0.5725051\n",
      "\tspeed: 0.0474s/iter; left time: 352.4304s\n",
      "\titers: 800, epoch: 2 | loss: 0.6971973\n",
      "\tspeed: 0.0475s/iter; left time: 348.7589s\n",
      "\titers: 900, epoch: 2 | loss: 0.5548949\n",
      "\tspeed: 0.0474s/iter; left time: 342.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.6198973 Vali Loss: 0.8641512 Test Loss: 0.9902377\n",
      "Validation loss decreased (0.999507 --> 0.864151).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6008136\n",
      "\tspeed: 0.1192s/iter; left time: 850.2023s\n",
      "\titers: 200, epoch: 3 | loss: 0.5296080\n",
      "\tspeed: 0.0472s/iter; left time: 332.0644s\n",
      "\titers: 300, epoch: 3 | loss: 0.4584014\n",
      "\tspeed: 0.0473s/iter; left time: 328.0649s\n",
      "\titers: 400, epoch: 3 | loss: 0.4370990\n",
      "\tspeed: 0.0473s/iter; left time: 323.4091s\n",
      "\titers: 500, epoch: 3 | loss: 0.4291144\n",
      "\tspeed: 0.0474s/iter; left time: 318.9924s\n",
      "\titers: 600, epoch: 3 | loss: 0.5539563\n",
      "\tspeed: 0.0473s/iter; left time: 313.7963s\n",
      "\titers: 700, epoch: 3 | loss: 0.4875292\n",
      "\tspeed: 0.0471s/iter; left time: 307.8671s\n",
      "\titers: 800, epoch: 3 | loss: 0.5426211\n",
      "\tspeed: 0.0460s/iter; left time: 295.7631s\n",
      "\titers: 900, epoch: 3 | loss: 0.4500065\n",
      "\tspeed: 0.0472s/iter; left time: 298.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.5258819 Vali Loss: 0.8253639 Test Loss: 1.0204122\n",
      "Validation loss decreased (0.864151 --> 0.825364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3754670\n",
      "\tspeed: 0.1181s/iter; left time: 735.8799s\n",
      "\titers: 200, epoch: 4 | loss: 0.4929804\n",
      "\tspeed: 0.0477s/iter; left time: 292.6241s\n",
      "\titers: 300, epoch: 4 | loss: 0.4894058\n",
      "\tspeed: 0.0478s/iter; left time: 288.3344s\n",
      "\titers: 400, epoch: 4 | loss: 0.4133273\n",
      "\tspeed: 0.0477s/iter; left time: 282.8989s\n",
      "\titers: 500, epoch: 4 | loss: 0.4616161\n",
      "\tspeed: 0.0476s/iter; left time: 277.3758s\n",
      "\titers: 600, epoch: 4 | loss: 0.4256289\n",
      "\tspeed: 0.0477s/iter; left time: 273.4059s\n",
      "\titers: 700, epoch: 4 | loss: 0.5438569\n",
      "\tspeed: 0.0476s/iter; left time: 268.1176s\n",
      "\titers: 800, epoch: 4 | loss: 0.4589882\n",
      "\tspeed: 0.0476s/iter; left time: 262.9199s\n",
      "\titers: 900, epoch: 4 | loss: 0.3972329\n",
      "\tspeed: 0.0477s/iter; left time: 259.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.42s\n",
      "Steps: 904 | Train Loss: 0.4699618 Vali Loss: 0.8311289 Test Loss: 1.0106529\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4016162\n",
      "\tspeed: 0.1139s/iter; left time: 606.7352s\n",
      "\titers: 200, epoch: 5 | loss: 0.5320279\n",
      "\tspeed: 0.0475s/iter; left time: 248.2187s\n",
      "\titers: 300, epoch: 5 | loss: 0.4389344\n",
      "\tspeed: 0.0476s/iter; left time: 244.0317s\n",
      "\titers: 400, epoch: 5 | loss: 0.4123844\n",
      "\tspeed: 0.0473s/iter; left time: 237.9205s\n",
      "\titers: 500, epoch: 5 | loss: 0.3748077\n",
      "\tspeed: 0.0474s/iter; left time: 233.3759s\n",
      "\titers: 600, epoch: 5 | loss: 0.4336455\n",
      "\tspeed: 0.0472s/iter; left time: 227.8580s\n",
      "\titers: 700, epoch: 5 | loss: 0.3758558\n",
      "\tspeed: 0.0473s/iter; left time: 223.6857s\n",
      "\titers: 800, epoch: 5 | loss: 0.4053825\n",
      "\tspeed: 0.0473s/iter; left time: 218.8912s\n",
      "\titers: 900, epoch: 5 | loss: 0.3536071\n",
      "\tspeed: 0.0472s/iter; left time: 213.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.3973393 Vali Loss: 0.8362059 Test Loss: 1.0399212\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2987453\n",
      "\tspeed: 0.1139s/iter; left time: 503.3744s\n",
      "\titers: 200, epoch: 6 | loss: 0.3543702\n",
      "\tspeed: 0.0475s/iter; left time: 205.0463s\n",
      "\titers: 300, epoch: 6 | loss: 0.4303695\n",
      "\tspeed: 0.0474s/iter; left time: 200.1590s\n",
      "\titers: 400, epoch: 6 | loss: 0.3217377\n",
      "\tspeed: 0.0474s/iter; left time: 195.3698s\n",
      "\titers: 500, epoch: 6 | loss: 0.3200426\n",
      "\tspeed: 0.0472s/iter; left time: 189.8770s\n",
      "\titers: 600, epoch: 6 | loss: 0.3239762\n",
      "\tspeed: 0.0472s/iter; left time: 185.0042s\n",
      "\titers: 700, epoch: 6 | loss: 0.2763830\n",
      "\tspeed: 0.0473s/iter; left time: 180.8556s\n",
      "\titers: 800, epoch: 6 | loss: 0.2769291\n",
      "\tspeed: 0.0473s/iter; left time: 175.9567s\n",
      "\titers: 900, epoch: 6 | loss: 0.2449794\n",
      "\tspeed: 0.0474s/iter; left time: 171.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.3360984 Vali Loss: 0.8888221 Test Loss: 1.1497846\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0202168226242065, rmse:1.010057806968689, mae:0.7201172113418579, rse:0.7153639793395996\n",
      "Original data scale mse:38556932.0, rmse:6209.4228515625, mae:4125.36767578125, rse:0.3092315196990967\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.4513035\n",
      "\tspeed: 0.0841s/iter; left time: 749.9329s\n",
      "\titers: 200, epoch: 1 | loss: 1.1868569\n",
      "\tspeed: 0.0537s/iter; left time: 473.7043s\n",
      "\titers: 300, epoch: 1 | loss: 1.0591309\n",
      "\tspeed: 0.0536s/iter; left time: 467.3272s\n",
      "\titers: 400, epoch: 1 | loss: 1.0550537\n",
      "\tspeed: 0.0540s/iter; left time: 465.4534s\n",
      "\titers: 500, epoch: 1 | loss: 1.0072999\n",
      "\tspeed: 0.0539s/iter; left time: 459.1737s\n",
      "\titers: 600, epoch: 1 | loss: 1.0573289\n",
      "\tspeed: 0.0538s/iter; left time: 453.1811s\n",
      "\titers: 700, epoch: 1 | loss: 0.9892762\n",
      "\tspeed: 0.0540s/iter; left time: 449.1197s\n",
      "\titers: 800, epoch: 1 | loss: 0.9284863\n",
      "\tspeed: 0.0541s/iter; left time: 444.9948s\n",
      "\titers: 900, epoch: 1 | loss: 0.9779816\n",
      "\tspeed: 0.0538s/iter; left time: 437.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.41s\n",
      "Steps: 902 | Train Loss: 1.1794277 Vali Loss: 1.2373216 Test Loss: 1.5648240\n",
      "Validation loss decreased (inf --> 1.237322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9446259\n",
      "\tspeed: 0.1343s/iter; left time: 1077.2779s\n",
      "\titers: 200, epoch: 2 | loss: 0.8056012\n",
      "\tspeed: 0.0539s/iter; left time: 426.6388s\n",
      "\titers: 300, epoch: 2 | loss: 0.9009757\n",
      "\tspeed: 0.0540s/iter; left time: 421.8762s\n",
      "\titers: 400, epoch: 2 | loss: 0.7335182\n",
      "\tspeed: 0.0535s/iter; left time: 412.7227s\n",
      "\titers: 500, epoch: 2 | loss: 0.6838488\n",
      "\tspeed: 0.0536s/iter; left time: 408.7437s\n",
      "\titers: 600, epoch: 2 | loss: 0.5971779\n",
      "\tspeed: 0.0537s/iter; left time: 403.8211s\n",
      "\titers: 700, epoch: 2 | loss: 0.5830911\n",
      "\tspeed: 0.0538s/iter; left time: 399.1743s\n",
      "\titers: 800, epoch: 2 | loss: 0.7226333\n",
      "\tspeed: 0.0537s/iter; left time: 393.0218s\n",
      "\titers: 900, epoch: 2 | loss: 0.5437814\n",
      "\tspeed: 0.0536s/iter; left time: 387.1148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.7098930 Vali Loss: 0.8560510 Test Loss: 1.0574535\n",
      "Validation loss decreased (1.237322 --> 0.856051).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6522908\n",
      "\tspeed: 0.1378s/iter; left time: 980.5782s\n",
      "\titers: 200, epoch: 3 | loss: 0.5614790\n",
      "\tspeed: 0.0539s/iter; left time: 377.9883s\n",
      "\titers: 300, epoch: 3 | loss: 0.5661032\n",
      "\tspeed: 0.0535s/iter; left time: 370.3667s\n",
      "\titers: 400, epoch: 3 | loss: 0.6395341\n",
      "\tspeed: 0.0537s/iter; left time: 366.2873s\n",
      "\titers: 500, epoch: 3 | loss: 0.5893967\n",
      "\tspeed: 0.0537s/iter; left time: 360.4713s\n",
      "\titers: 600, epoch: 3 | loss: 0.5753616\n",
      "\tspeed: 0.0536s/iter; left time: 354.9581s\n",
      "\titers: 700, epoch: 3 | loss: 0.5785540\n",
      "\tspeed: 0.0537s/iter; left time: 350.0742s\n",
      "\titers: 800, epoch: 3 | loss: 0.5669529\n",
      "\tspeed: 0.0536s/iter; left time: 343.9208s\n",
      "\titers: 900, epoch: 3 | loss: 0.5270591\n",
      "\tspeed: 0.0537s/iter; left time: 338.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.5598285 Vali Loss: 0.8425306 Test Loss: 1.0459061\n",
      "Validation loss decreased (0.856051 --> 0.842531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4489958\n",
      "\tspeed: 0.1344s/iter; left time: 835.4460s\n",
      "\titers: 200, epoch: 4 | loss: 0.4196067\n",
      "\tspeed: 0.0534s/iter; left time: 326.3973s\n",
      "\titers: 300, epoch: 4 | loss: 0.5201551\n",
      "\tspeed: 0.0537s/iter; left time: 323.1941s\n",
      "\titers: 400, epoch: 4 | loss: 0.5129791\n",
      "\tspeed: 0.0539s/iter; left time: 318.5540s\n",
      "\titers: 500, epoch: 4 | loss: 0.5178872\n",
      "\tspeed: 0.0537s/iter; left time: 312.2427s\n",
      "\titers: 600, epoch: 4 | loss: 0.4545621\n",
      "\tspeed: 0.0539s/iter; left time: 307.8022s\n",
      "\titers: 700, epoch: 4 | loss: 0.5170161\n",
      "\tspeed: 0.0538s/iter; left time: 301.9010s\n",
      "\titers: 800, epoch: 4 | loss: 0.5029768\n",
      "\tspeed: 0.0537s/iter; left time: 296.3445s\n",
      "\titers: 900, epoch: 4 | loss: 0.4715585\n",
      "\tspeed: 0.0538s/iter; left time: 291.1229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.4856403 Vali Loss: 0.8650920 Test Loss: 1.1256214\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4903401\n",
      "\tspeed: 0.1336s/iter; left time: 709.5696s\n",
      "\titers: 200, epoch: 5 | loss: 0.4387870\n",
      "\tspeed: 0.0536s/iter; left time: 279.2608s\n",
      "\titers: 300, epoch: 5 | loss: 0.4559324\n",
      "\tspeed: 0.0535s/iter; left time: 273.3397s\n",
      "\titers: 400, epoch: 5 | loss: 0.4750988\n",
      "\tspeed: 0.0534s/iter; left time: 267.6441s\n",
      "\titers: 500, epoch: 5 | loss: 0.3438237\n",
      "\tspeed: 0.0537s/iter; left time: 263.7354s\n",
      "\titers: 600, epoch: 5 | loss: 0.4019723\n",
      "\tspeed: 0.0538s/iter; left time: 258.8025s\n",
      "\titers: 700, epoch: 5 | loss: 0.4279053\n",
      "\tspeed: 0.0538s/iter; left time: 253.3244s\n",
      "\titers: 800, epoch: 5 | loss: 0.3727010\n",
      "\tspeed: 0.0538s/iter; left time: 248.0986s\n",
      "\titers: 900, epoch: 5 | loss: 0.3272199\n",
      "\tspeed: 0.0535s/iter; left time: 241.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.4068201 Vali Loss: 0.9181381 Test Loss: 1.1648233\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3629528\n",
      "\tspeed: 0.1330s/iter; left time: 586.5872s\n",
      "\titers: 200, epoch: 6 | loss: 0.3692802\n",
      "\tspeed: 0.0534s/iter; left time: 230.0419s\n",
      "\titers: 300, epoch: 6 | loss: 0.3483662\n",
      "\tspeed: 0.0534s/iter; left time: 224.9029s\n",
      "\titers: 400, epoch: 6 | loss: 0.3967043\n",
      "\tspeed: 0.0533s/iter; left time: 219.2919s\n",
      "\titers: 500, epoch: 6 | loss: 0.3151745\n",
      "\tspeed: 0.0533s/iter; left time: 213.6203s\n",
      "\titers: 600, epoch: 6 | loss: 0.3188320\n",
      "\tspeed: 0.0537s/iter; left time: 209.8512s\n",
      "\titers: 700, epoch: 6 | loss: 0.3500941\n",
      "\tspeed: 0.0536s/iter; left time: 204.0941s\n",
      "\titers: 800, epoch: 6 | loss: 0.3061586\n",
      "\tspeed: 0.0535s/iter; left time: 198.4727s\n",
      "\titers: 900, epoch: 6 | loss: 0.3686934\n",
      "\tspeed: 0.0536s/iter; left time: 193.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.3409146 Vali Loss: 0.9748651 Test Loss: 1.1818019\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0452449321746826, rmse:1.0223722457885742, mae:0.7262387871742249, rse:0.7243914604187012\n",
      "Original data scale mse:38648844.0, rmse:6216.8193359375, mae:4132.9208984375, rse:0.30975180864334106\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.7759011\n",
      "\tspeed: 0.0560s/iter; left time: 499.5571s\n",
      "\titers: 200, epoch: 1 | loss: 1.1779013\n",
      "\tspeed: 0.0538s/iter; left time: 474.5228s\n",
      "\titers: 300, epoch: 1 | loss: 1.0837777\n",
      "\tspeed: 0.0536s/iter; left time: 467.5363s\n",
      "\titers: 400, epoch: 1 | loss: 0.9068947\n",
      "\tspeed: 0.0536s/iter; left time: 462.5004s\n",
      "\titers: 500, epoch: 1 | loss: 1.1048275\n",
      "\tspeed: 0.0536s/iter; left time: 457.0638s\n",
      "\titers: 600, epoch: 1 | loss: 0.9778019\n",
      "\tspeed: 0.0535s/iter; left time: 450.7672s\n",
      "\titers: 700, epoch: 1 | loss: 0.9391892\n",
      "\tspeed: 0.0537s/iter; left time: 447.0940s\n",
      "\titers: 800, epoch: 1 | loss: 0.9034569\n",
      "\tspeed: 0.0537s/iter; left time: 441.7807s\n",
      "\titers: 900, epoch: 1 | loss: 0.9367726\n",
      "\tspeed: 0.0536s/iter; left time: 435.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 1.2006944 Vali Loss: 1.2343884 Test Loss: 1.5785624\n",
      "Validation loss decreased (inf --> 1.234388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7927101\n",
      "\tspeed: 0.1383s/iter; left time: 1108.6808s\n",
      "\titers: 200, epoch: 2 | loss: 0.7444984\n",
      "\tspeed: 0.0539s/iter; left time: 426.5778s\n",
      "\titers: 300, epoch: 2 | loss: 0.7557555\n",
      "\tspeed: 0.0541s/iter; left time: 422.6326s\n",
      "\titers: 400, epoch: 2 | loss: 0.6308638\n",
      "\tspeed: 0.0541s/iter; left time: 417.6194s\n",
      "\titers: 500, epoch: 2 | loss: 0.6542862\n",
      "\tspeed: 0.0542s/iter; left time: 412.6382s\n",
      "\titers: 600, epoch: 2 | loss: 0.6680411\n",
      "\tspeed: 0.0542s/iter; left time: 407.4122s\n",
      "\titers: 700, epoch: 2 | loss: 0.6337645\n",
      "\tspeed: 0.0536s/iter; left time: 397.4910s\n",
      "\titers: 800, epoch: 2 | loss: 0.5177450\n",
      "\tspeed: 0.0538s/iter; left time: 393.9697s\n",
      "\titers: 900, epoch: 2 | loss: 0.5789130\n",
      "\tspeed: 0.0537s/iter; left time: 387.3388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.04s\n",
      "Steps: 902 | Train Loss: 0.7192984 Vali Loss: 0.9098053 Test Loss: 1.0436571\n",
      "Validation loss decreased (1.234388 --> 0.909805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5317430\n",
      "\tspeed: 0.1372s/iter; left time: 976.2920s\n",
      "\titers: 200, epoch: 3 | loss: 0.6248262\n",
      "\tspeed: 0.0537s/iter; left time: 376.8020s\n",
      "\titers: 300, epoch: 3 | loss: 0.6871318\n",
      "\tspeed: 0.0533s/iter; left time: 368.6804s\n",
      "\titers: 400, epoch: 3 | loss: 0.5867053\n",
      "\tspeed: 0.0528s/iter; left time: 359.6454s\n",
      "\titers: 500, epoch: 3 | loss: 0.5596285\n",
      "\tspeed: 0.0532s/iter; left time: 357.6532s\n",
      "\titers: 600, epoch: 3 | loss: 0.5453044\n",
      "\tspeed: 0.0533s/iter; left time: 352.9156s\n",
      "\titers: 700, epoch: 3 | loss: 0.5318028\n",
      "\tspeed: 0.0534s/iter; left time: 348.2350s\n",
      "\titers: 800, epoch: 3 | loss: 0.5164596\n",
      "\tspeed: 0.0535s/iter; left time: 343.4071s\n",
      "\titers: 900, epoch: 3 | loss: 0.5555614\n",
      "\tspeed: 0.0534s/iter; left time: 337.5074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.5591548 Vali Loss: 0.8504422 Test Loss: 1.0497766\n",
      "Validation loss decreased (0.909805 --> 0.850442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5382196\n",
      "\tspeed: 0.1367s/iter; left time: 849.3122s\n",
      "\titers: 200, epoch: 4 | loss: 0.4266947\n",
      "\tspeed: 0.0535s/iter; left time: 326.9485s\n",
      "\titers: 300, epoch: 4 | loss: 0.4917541\n",
      "\tspeed: 0.0535s/iter; left time: 321.5373s\n",
      "\titers: 400, epoch: 4 | loss: 0.4566099\n",
      "\tspeed: 0.0534s/iter; left time: 315.8160s\n",
      "\titers: 500, epoch: 4 | loss: 0.4442234\n",
      "\tspeed: 0.0536s/iter; left time: 311.6257s\n",
      "\titers: 600, epoch: 4 | loss: 0.4840673\n",
      "\tspeed: 0.0536s/iter; left time: 306.0411s\n",
      "\titers: 700, epoch: 4 | loss: 0.4515627\n",
      "\tspeed: 0.0535s/iter; left time: 300.6604s\n",
      "\titers: 800, epoch: 4 | loss: 0.4724911\n",
      "\tspeed: 0.0536s/iter; left time: 295.8326s\n",
      "\titers: 900, epoch: 4 | loss: 0.4940455\n",
      "\tspeed: 0.0536s/iter; left time: 290.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.4817320 Vali Loss: 0.9070774 Test Loss: 1.0855894\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3666081\n",
      "\tspeed: 0.1322s/iter; left time: 702.6137s\n",
      "\titers: 200, epoch: 5 | loss: 0.4185818\n",
      "\tspeed: 0.0538s/iter; left time: 280.2501s\n",
      "\titers: 300, epoch: 5 | loss: 0.3793826\n",
      "\tspeed: 0.0538s/iter; left time: 274.9459s\n",
      "\titers: 400, epoch: 5 | loss: 0.3913236\n",
      "\tspeed: 0.0535s/iter; left time: 268.0983s\n",
      "\titers: 500, epoch: 5 | loss: 0.4524700\n",
      "\tspeed: 0.0536s/iter; left time: 263.3851s\n",
      "\titers: 600, epoch: 5 | loss: 0.3544087\n",
      "\tspeed: 0.0536s/iter; left time: 257.7487s\n",
      "\titers: 700, epoch: 5 | loss: 0.3681715\n",
      "\tspeed: 0.0538s/iter; left time: 253.4574s\n",
      "\titers: 800, epoch: 5 | loss: 0.3650162\n",
      "\tspeed: 0.0538s/iter; left time: 248.3493s\n",
      "\titers: 900, epoch: 5 | loss: 0.4134011\n",
      "\tspeed: 0.0535s/iter; left time: 241.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.4067762 Vali Loss: 0.9315615 Test Loss: 1.1446359\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3505681\n",
      "\tspeed: 0.1320s/iter; left time: 582.2128s\n",
      "\titers: 200, epoch: 6 | loss: 0.3519717\n",
      "\tspeed: 0.0534s/iter; left time: 230.1585s\n",
      "\titers: 300, epoch: 6 | loss: 0.3504041\n",
      "\tspeed: 0.0535s/iter; left time: 225.3400s\n",
      "\titers: 400, epoch: 6 | loss: 0.3286889\n",
      "\tspeed: 0.0536s/iter; left time: 220.4681s\n",
      "\titers: 500, epoch: 6 | loss: 0.2953203\n",
      "\tspeed: 0.0533s/iter; left time: 213.7685s\n",
      "\titers: 600, epoch: 6 | loss: 0.3667930\n",
      "\tspeed: 0.0536s/iter; left time: 209.6808s\n",
      "\titers: 700, epoch: 6 | loss: 0.3523478\n",
      "\tspeed: 0.0537s/iter; left time: 204.7297s\n",
      "\titers: 800, epoch: 6 | loss: 0.2885244\n",
      "\tspeed: 0.0535s/iter; left time: 198.7232s\n",
      "\titers: 900, epoch: 6 | loss: 0.3104544\n",
      "\tspeed: 0.0536s/iter; left time: 193.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.3442164 Vali Loss: 0.9564841 Test Loss: 1.2238871\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.048880934715271, rmse:1.024148941040039, mae:0.7293751835823059, rse:0.7256502509117126\n",
      "Original data scale mse:39350824.0, rmse:6273.0234375, mae:4192.4599609375, rse:0.31255215406417847\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1237323\n",
      "\tspeed: 0.0749s/iter; left time: 671.2866s\n",
      "\titers: 200, epoch: 1 | loss: 0.9561383\n",
      "\tspeed: 0.0464s/iter; left time: 411.5910s\n",
      "\titers: 300, epoch: 1 | loss: 0.8474175\n",
      "\tspeed: 0.0456s/iter; left time: 399.6692s\n",
      "\titers: 400, epoch: 1 | loss: 0.7676063\n",
      "\tspeed: 0.0417s/iter; left time: 361.5819s\n",
      "\titers: 500, epoch: 1 | loss: 0.7165276\n",
      "\tspeed: 0.0304s/iter; left time: 260.1004s\n",
      "\titers: 600, epoch: 1 | loss: 0.6738873\n",
      "\tspeed: 0.0336s/iter; left time: 284.3248s\n",
      "\titers: 700, epoch: 1 | loss: 0.8236557\n",
      "\tspeed: 0.0462s/iter; left time: 386.3085s\n",
      "\titers: 800, epoch: 1 | loss: 0.7245541\n",
      "\tspeed: 0.0461s/iter; left time: 380.9803s\n",
      "\titers: 900, epoch: 1 | loss: 0.6327443\n",
      "\tspeed: 0.0462s/iter; left time: 376.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.22s\n",
      "Steps: 906 | Train Loss: 0.8698494 Vali Loss: 0.6667461 Test Loss: 0.7621074\n",
      "Validation loss decreased (inf --> 0.666746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5410139\n",
      "\tspeed: 0.1063s/iter; left time: 855.9915s\n",
      "\titers: 200, epoch: 2 | loss: 0.7109172\n",
      "\tspeed: 0.0467s/iter; left time: 371.4670s\n",
      "\titers: 300, epoch: 2 | loss: 0.5930956\n",
      "\tspeed: 0.0468s/iter; left time: 367.7063s\n",
      "\titers: 400, epoch: 2 | loss: 0.6642184\n",
      "\tspeed: 0.0467s/iter; left time: 362.3482s\n",
      "\titers: 500, epoch: 2 | loss: 0.5361748\n",
      "\tspeed: 0.0430s/iter; left time: 329.3536s\n",
      "\titers: 600, epoch: 2 | loss: 0.5665941\n",
      "\tspeed: 0.0420s/iter; left time: 316.9415s\n",
      "\titers: 700, epoch: 2 | loss: 0.5478184\n",
      "\tspeed: 0.0420s/iter; left time: 313.1766s\n",
      "\titers: 800, epoch: 2 | loss: 0.6663943\n",
      "\tspeed: 0.0414s/iter; left time: 304.2862s\n",
      "\titers: 900, epoch: 2 | loss: 0.5855762\n",
      "\tspeed: 0.0426s/iter; left time: 308.7155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.33s\n",
      "Steps: 906 | Train Loss: 0.6228900 Vali Loss: 0.5350450 Test Loss: 0.6245825\n",
      "Validation loss decreased (0.666746 --> 0.535045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5986111\n",
      "\tspeed: 0.1013s/iter; left time: 723.8451s\n",
      "\titers: 200, epoch: 3 | loss: 0.5372777\n",
      "\tspeed: 0.0428s/iter; left time: 301.5022s\n",
      "\titers: 300, epoch: 3 | loss: 0.5830756\n",
      "\tspeed: 0.0423s/iter; left time: 294.1666s\n",
      "\titers: 400, epoch: 3 | loss: 0.5572116\n",
      "\tspeed: 0.0425s/iter; left time: 291.3330s\n",
      "\titers: 500, epoch: 3 | loss: 0.6312300\n",
      "\tspeed: 0.0426s/iter; left time: 287.2253s\n",
      "\titers: 600, epoch: 3 | loss: 0.6290894\n",
      "\tspeed: 0.0420s/iter; left time: 279.5611s\n",
      "\titers: 700, epoch: 3 | loss: 0.5897519\n",
      "\tspeed: 0.0428s/iter; left time: 279.9907s\n",
      "\titers: 800, epoch: 3 | loss: 0.5932396\n",
      "\tspeed: 0.0423s/iter; left time: 272.4950s\n",
      "\titers: 900, epoch: 3 | loss: 0.5767737\n",
      "\tspeed: 0.0429s/iter; left time: 272.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.78s\n",
      "Steps: 906 | Train Loss: 0.5760266 Vali Loss: 0.5332815 Test Loss: 0.5809225\n",
      "Validation loss decreased (0.535045 --> 0.533282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5270418\n",
      "\tspeed: 0.1020s/iter; left time: 636.5462s\n",
      "\titers: 200, epoch: 4 | loss: 0.5455442\n",
      "\tspeed: 0.0424s/iter; left time: 260.7125s\n",
      "\titers: 300, epoch: 4 | loss: 0.5627331\n",
      "\tspeed: 0.0417s/iter; left time: 252.0099s\n",
      "\titers: 400, epoch: 4 | loss: 0.4967361\n",
      "\tspeed: 0.0423s/iter; left time: 251.6199s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109886\n",
      "\tspeed: 0.0423s/iter; left time: 247.4086s\n",
      "\titers: 600, epoch: 4 | loss: 0.5364010\n",
      "\tspeed: 0.0426s/iter; left time: 244.3917s\n",
      "\titers: 700, epoch: 4 | loss: 0.5456307\n",
      "\tspeed: 0.0424s/iter; left time: 239.3526s\n",
      "\titers: 800, epoch: 4 | loss: 0.5774807\n",
      "\tspeed: 0.0422s/iter; left time: 233.8516s\n",
      "\titers: 900, epoch: 4 | loss: 0.5393867\n",
      "\tspeed: 0.0420s/iter; left time: 228.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 906 | Train Loss: 0.5475209 Vali Loss: 0.5265018 Test Loss: 0.5841780\n",
      "Validation loss decreased (0.533282 --> 0.526502).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5496544\n",
      "\tspeed: 0.1004s/iter; left time: 536.0724s\n",
      "\titers: 200, epoch: 5 | loss: 0.5365326\n",
      "\tspeed: 0.0422s/iter; left time: 221.0508s\n",
      "\titers: 300, epoch: 5 | loss: 0.4639795\n",
      "\tspeed: 0.0421s/iter; left time: 216.4375s\n",
      "\titers: 400, epoch: 5 | loss: 0.5828627\n",
      "\tspeed: 0.0421s/iter; left time: 211.9637s\n",
      "\titers: 500, epoch: 5 | loss: 0.4869540\n",
      "\tspeed: 0.0418s/iter; left time: 206.4084s\n",
      "\titers: 600, epoch: 5 | loss: 0.5083256\n",
      "\tspeed: 0.0420s/iter; left time: 203.3517s\n",
      "\titers: 700, epoch: 5 | loss: 0.4804469\n",
      "\tspeed: 0.0417s/iter; left time: 197.4495s\n",
      "\titers: 800, epoch: 5 | loss: 0.5289673\n",
      "\tspeed: 0.0420s/iter; left time: 194.7637s\n",
      "\titers: 900, epoch: 5 | loss: 0.5208501\n",
      "\tspeed: 0.0415s/iter; left time: 188.4499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 906 | Train Loss: 0.5125856 Vali Loss: 0.5473724 Test Loss: 0.6019589\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5046539\n",
      "\tspeed: 0.0965s/iter; left time: 427.4331s\n",
      "\titers: 200, epoch: 6 | loss: 0.4690288\n",
      "\tspeed: 0.0416s/iter; left time: 180.1945s\n",
      "\titers: 300, epoch: 6 | loss: 0.4722730\n",
      "\tspeed: 0.0419s/iter; left time: 177.2705s\n",
      "\titers: 400, epoch: 6 | loss: 0.4994407\n",
      "\tspeed: 0.0417s/iter; left time: 172.1999s\n",
      "\titers: 500, epoch: 6 | loss: 0.4835857\n",
      "\tspeed: 0.0415s/iter; left time: 167.2207s\n",
      "\titers: 600, epoch: 6 | loss: 0.4320669\n",
      "\tspeed: 0.0414s/iter; left time: 162.6740s\n",
      "\titers: 700, epoch: 6 | loss: 0.4604870\n",
      "\tspeed: 0.0420s/iter; left time: 161.0037s\n",
      "\titers: 800, epoch: 6 | loss: 0.4212856\n",
      "\tspeed: 0.0413s/iter; left time: 154.0105s\n",
      "\titers: 900, epoch: 6 | loss: 0.4144059\n",
      "\tspeed: 0.0410s/iter; left time: 149.0500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 906 | Train Loss: 0.4731633 Vali Loss: 0.5595579 Test Loss: 0.6468086\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4206629\n",
      "\tspeed: 0.0973s/iter; left time: 342.8309s\n",
      "\titers: 200, epoch: 7 | loss: 0.4250834\n",
      "\tspeed: 0.0436s/iter; left time: 149.4400s\n",
      "\titers: 300, epoch: 7 | loss: 0.4404673\n",
      "\tspeed: 0.0419s/iter; left time: 139.1977s\n",
      "\titers: 400, epoch: 7 | loss: 0.5036768\n",
      "\tspeed: 0.0421s/iter; left time: 135.6429s\n",
      "\titers: 500, epoch: 7 | loss: 0.4230961\n",
      "\tspeed: 0.0421s/iter; left time: 131.7072s\n",
      "\titers: 600, epoch: 7 | loss: 0.4683108\n",
      "\tspeed: 0.0421s/iter; left time: 127.4405s\n",
      "\titers: 700, epoch: 7 | loss: 0.4173360\n",
      "\tspeed: 0.0423s/iter; left time: 123.6727s\n",
      "\titers: 800, epoch: 7 | loss: 0.4593600\n",
      "\tspeed: 0.0423s/iter; left time: 119.4707s\n",
      "\titers: 900, epoch: 7 | loss: 0.4185330\n",
      "\tspeed: 0.0425s/iter; left time: 115.7351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 906 | Train Loss: 0.4343612 Vali Loss: 0.5635132 Test Loss: 0.6613390\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5836709141731262, rmse:0.7639836072921753, mae:0.5080409646034241, rse:0.5396057367324829\n",
      "Original data scale mse:20211562.0, rmse:4495.72705078125, mae:2858.91748046875, rse:0.22353661060333252\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1926942\n",
      "\tspeed: 0.0441s/iter; left time: 395.2588s\n",
      "\titers: 200, epoch: 1 | loss: 0.9813661\n",
      "\tspeed: 0.0420s/iter; left time: 372.3568s\n",
      "\titers: 300, epoch: 1 | loss: 0.8897092\n",
      "\tspeed: 0.0416s/iter; left time: 364.2165s\n",
      "\titers: 400, epoch: 1 | loss: 0.7964033\n",
      "\tspeed: 0.0417s/iter; left time: 360.8841s\n",
      "\titers: 500, epoch: 1 | loss: 0.7646300\n",
      "\tspeed: 0.0424s/iter; left time: 363.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.6984826\n",
      "\tspeed: 0.0419s/iter; left time: 354.7159s\n",
      "\titers: 700, epoch: 1 | loss: 0.7223364\n",
      "\tspeed: 0.0419s/iter; left time: 350.6474s\n",
      "\titers: 800, epoch: 1 | loss: 0.7149761\n",
      "\tspeed: 0.0423s/iter; left time: 349.3344s\n",
      "\titers: 900, epoch: 1 | loss: 0.6552395\n",
      "\tspeed: 0.0421s/iter; left time: 343.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 906 | Train Loss: 0.8713845 Vali Loss: 0.6711577 Test Loss: 0.7695574\n",
      "Validation loss decreased (inf --> 0.671158).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5893251\n",
      "\tspeed: 0.1030s/iter; left time: 829.5489s\n",
      "\titers: 200, epoch: 2 | loss: 0.6332479\n",
      "\tspeed: 0.0443s/iter; left time: 352.6885s\n",
      "\titers: 300, epoch: 2 | loss: 0.7431655\n",
      "\tspeed: 0.0450s/iter; left time: 353.5180s\n",
      "\titers: 400, epoch: 2 | loss: 0.5791567\n",
      "\tspeed: 0.0429s/iter; left time: 332.4912s\n",
      "\titers: 500, epoch: 2 | loss: 0.6707392\n",
      "\tspeed: 0.0433s/iter; left time: 331.6080s\n",
      "\titers: 600, epoch: 2 | loss: 0.6733871\n",
      "\tspeed: 0.0453s/iter; left time: 342.2957s\n",
      "\titers: 700, epoch: 2 | loss: 0.5892128\n",
      "\tspeed: 0.0444s/iter; left time: 331.0384s\n",
      "\titers: 800, epoch: 2 | loss: 0.4884300\n",
      "\tspeed: 0.0426s/iter; left time: 313.1846s\n",
      "\titers: 900, epoch: 2 | loss: 0.5249476\n",
      "\tspeed: 0.0421s/iter; left time: 305.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.09s\n",
      "Steps: 906 | Train Loss: 0.6215420 Vali Loss: 0.5357817 Test Loss: 0.6018389\n",
      "Validation loss decreased (0.671158 --> 0.535782).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6222262\n",
      "\tspeed: 0.1028s/iter; left time: 735.2380s\n",
      "\titers: 200, epoch: 3 | loss: 0.5183086\n",
      "\tspeed: 0.0415s/iter; left time: 292.7876s\n",
      "\titers: 300, epoch: 3 | loss: 0.5093386\n",
      "\tspeed: 0.0415s/iter; left time: 288.5265s\n",
      "\titers: 400, epoch: 3 | loss: 0.6005334\n",
      "\tspeed: 0.0409s/iter; left time: 280.2148s\n",
      "\titers: 500, epoch: 3 | loss: 0.4889997\n",
      "\tspeed: 0.0412s/iter; left time: 278.0887s\n",
      "\titers: 600, epoch: 3 | loss: 0.6026074\n",
      "\tspeed: 0.0409s/iter; left time: 271.8378s\n",
      "\titers: 700, epoch: 3 | loss: 0.5483033\n",
      "\tspeed: 0.0412s/iter; left time: 269.6628s\n",
      "\titers: 800, epoch: 3 | loss: 0.5508869\n",
      "\tspeed: 0.0411s/iter; left time: 264.8635s\n",
      "\titers: 900, epoch: 3 | loss: 0.6050845\n",
      "\tspeed: 0.0409s/iter; left time: 259.8329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.65s\n",
      "Steps: 906 | Train Loss: 0.5736331 Vali Loss: 0.5244440 Test Loss: 0.5541033\n",
      "Validation loss decreased (0.535782 --> 0.524444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5121648\n",
      "\tspeed: 0.1031s/iter; left time: 643.9566s\n",
      "\titers: 200, epoch: 4 | loss: 0.6408150\n",
      "\tspeed: 0.0418s/iter; left time: 256.7853s\n",
      "\titers: 300, epoch: 4 | loss: 0.6157270\n",
      "\tspeed: 0.0421s/iter; left time: 254.4535s\n",
      "\titers: 400, epoch: 4 | loss: 0.5974339\n",
      "\tspeed: 0.0418s/iter; left time: 248.2926s\n",
      "\titers: 500, epoch: 4 | loss: 0.5601347\n",
      "\tspeed: 0.0420s/iter; left time: 245.5990s\n",
      "\titers: 600, epoch: 4 | loss: 0.5198681\n",
      "\tspeed: 0.0419s/iter; left time: 240.9114s\n",
      "\titers: 700, epoch: 4 | loss: 0.5365813\n",
      "\tspeed: 0.0420s/iter; left time: 237.1955s\n",
      "\titers: 800, epoch: 4 | loss: 0.5616918\n",
      "\tspeed: 0.0424s/iter; left time: 235.0873s\n",
      "\titers: 900, epoch: 4 | loss: 0.5758591\n",
      "\tspeed: 0.0419s/iter; left time: 228.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 906 | Train Loss: 0.5476390 Vali Loss: 0.5400928 Test Loss: 0.5803221\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5727783\n",
      "\tspeed: 0.0973s/iter; left time: 519.5195s\n",
      "\titers: 200, epoch: 5 | loss: 0.4978659\n",
      "\tspeed: 0.0421s/iter; left time: 220.2571s\n",
      "\titers: 300, epoch: 5 | loss: 0.5518112\n",
      "\tspeed: 0.0415s/iter; left time: 213.3735s\n",
      "\titers: 400, epoch: 5 | loss: 0.5911642\n",
      "\tspeed: 0.0420s/iter; left time: 211.6142s\n",
      "\titers: 500, epoch: 5 | loss: 0.5986532\n",
      "\tspeed: 0.0417s/iter; left time: 205.7273s\n",
      "\titers: 600, epoch: 5 | loss: 0.5656121\n",
      "\tspeed: 0.0422s/iter; left time: 204.2318s\n",
      "\titers: 700, epoch: 5 | loss: 0.4992448\n",
      "\tspeed: 0.0419s/iter; left time: 198.5714s\n",
      "\titers: 800, epoch: 5 | loss: 0.4832042\n",
      "\tspeed: 0.0422s/iter; left time: 195.5986s\n",
      "\titers: 900, epoch: 5 | loss: 0.5102739\n",
      "\tspeed: 0.0418s/iter; left time: 189.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 906 | Train Loss: 0.5181514 Vali Loss: 0.5874133 Test Loss: 0.6052595\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4550738\n",
      "\tspeed: 0.0978s/iter; left time: 433.2110s\n",
      "\titers: 200, epoch: 6 | loss: 0.4682621\n",
      "\tspeed: 0.0424s/iter; left time: 183.6404s\n",
      "\titers: 300, epoch: 6 | loss: 0.4742517\n",
      "\tspeed: 0.0428s/iter; left time: 181.1412s\n",
      "\titers: 400, epoch: 6 | loss: 0.4768448\n",
      "\tspeed: 0.0419s/iter; left time: 173.2431s\n",
      "\titers: 500, epoch: 6 | loss: 0.4968096\n",
      "\tspeed: 0.0425s/iter; left time: 171.1480s\n",
      "\titers: 600, epoch: 6 | loss: 0.5207300\n",
      "\tspeed: 0.0420s/iter; left time: 165.2694s\n",
      "\titers: 700, epoch: 6 | loss: 0.5106579\n",
      "\tspeed: 0.0423s/iter; left time: 162.0674s\n",
      "\titers: 800, epoch: 6 | loss: 0.5777311\n",
      "\tspeed: 0.0426s/iter; left time: 158.9766s\n",
      "\titers: 900, epoch: 6 | loss: 0.4878045\n",
      "\tspeed: 0.0427s/iter; left time: 154.9635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 906 | Train Loss: 0.4814399 Vali Loss: 0.5787742 Test Loss: 0.6105032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5530824661254883, rmse:0.7436951398849487, mae:0.5012215971946716, rse:0.5252758860588074\n",
      "Original data scale mse:18355966.0, rmse:4284.38623046875, mae:2809.9755859375, rse:0.21302832663059235\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.2258205\n",
      "\tspeed: 0.0735s/iter; left time: 656.9941s\n",
      "\titers: 200, epoch: 1 | loss: 1.0751767\n",
      "\tspeed: 0.0445s/iter; left time: 393.0136s\n",
      "\titers: 300, epoch: 1 | loss: 1.0438138\n",
      "\tspeed: 0.0478s/iter; left time: 418.2159s\n",
      "\titers: 400, epoch: 1 | loss: 0.9662235\n",
      "\tspeed: 0.0480s/iter; left time: 414.6282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9472792\n",
      "\tspeed: 0.0478s/iter; left time: 408.1575s\n",
      "\titers: 600, epoch: 1 | loss: 0.8591858\n",
      "\tspeed: 0.0479s/iter; left time: 404.3451s\n",
      "\titers: 700, epoch: 1 | loss: 0.8508393\n",
      "\tspeed: 0.0472s/iter; left time: 393.5511s\n",
      "\titers: 800, epoch: 1 | loss: 0.8616284\n",
      "\tspeed: 0.0461s/iter; left time: 379.6635s\n",
      "\titers: 900, epoch: 1 | loss: 0.8617458\n",
      "\tspeed: 0.0469s/iter; left time: 381.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 1.0194455 Vali Loss: 1.0087975 Test Loss: 1.2392421\n",
      "Validation loss decreased (inf --> 1.008798).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7766200\n",
      "\tspeed: 0.1172s/iter; left time: 941.8704s\n",
      "\titers: 200, epoch: 2 | loss: 0.8155171\n",
      "\tspeed: 0.0475s/iter; left time: 376.7602s\n",
      "\titers: 300, epoch: 2 | loss: 0.7960852\n",
      "\tspeed: 0.0475s/iter; left time: 372.2202s\n",
      "\titers: 400, epoch: 2 | loss: 0.7479156\n",
      "\tspeed: 0.0476s/iter; left time: 368.1713s\n",
      "\titers: 500, epoch: 2 | loss: 0.7679280\n",
      "\tspeed: 0.0476s/iter; left time: 363.8742s\n",
      "\titers: 600, epoch: 2 | loss: 0.8167887\n",
      "\tspeed: 0.0476s/iter; left time: 358.6132s\n",
      "\titers: 700, epoch: 2 | loss: 0.7435757\n",
      "\tspeed: 0.0475s/iter; left time: 353.3628s\n",
      "\titers: 800, epoch: 2 | loss: 0.8145493\n",
      "\tspeed: 0.0475s/iter; left time: 348.6128s\n",
      "\titers: 900, epoch: 2 | loss: 0.7303040\n",
      "\tspeed: 0.0475s/iter; left time: 343.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.7839754 Vali Loss: 0.8323682 Test Loss: 1.0063807\n",
      "Validation loss decreased (1.008798 --> 0.832368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8219219\n",
      "\tspeed: 0.1190s/iter; left time: 848.9625s\n",
      "\titers: 200, epoch: 3 | loss: 0.6949050\n",
      "\tspeed: 0.0480s/iter; left time: 337.5675s\n",
      "\titers: 300, epoch: 3 | loss: 0.6721224\n",
      "\tspeed: 0.0478s/iter; left time: 331.1105s\n",
      "\titers: 400, epoch: 3 | loss: 0.6962958\n",
      "\tspeed: 0.0477s/iter; left time: 325.9327s\n",
      "\titers: 500, epoch: 3 | loss: 0.7266185\n",
      "\tspeed: 0.0475s/iter; left time: 319.6000s\n",
      "\titers: 600, epoch: 3 | loss: 0.7807701\n",
      "\tspeed: 0.0474s/iter; left time: 314.3424s\n",
      "\titers: 700, epoch: 3 | loss: 0.7041007\n",
      "\tspeed: 0.0474s/iter; left time: 309.9825s\n",
      "\titers: 800, epoch: 3 | loss: 0.7182363\n",
      "\tspeed: 0.0474s/iter; left time: 304.9743s\n",
      "\titers: 900, epoch: 3 | loss: 0.6948757\n",
      "\tspeed: 0.0475s/iter; left time: 300.6990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.7227120 Vali Loss: 0.8124940 Test Loss: 0.9797342\n",
      "Validation loss decreased (0.832368 --> 0.812494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6503370\n",
      "\tspeed: 0.1257s/iter; left time: 782.7841s\n",
      "\titers: 200, epoch: 4 | loss: 0.6602300\n",
      "\tspeed: 0.0478s/iter; left time: 292.8133s\n",
      "\titers: 300, epoch: 4 | loss: 0.6976317\n",
      "\tspeed: 0.0478s/iter; left time: 288.4145s\n",
      "\titers: 400, epoch: 4 | loss: 0.6228531\n",
      "\tspeed: 0.0478s/iter; left time: 283.4910s\n",
      "\titers: 500, epoch: 4 | loss: 0.6780560\n",
      "\tspeed: 0.0471s/iter; left time: 274.3438s\n",
      "\titers: 600, epoch: 4 | loss: 0.6398390\n",
      "\tspeed: 0.0477s/iter; left time: 273.2071s\n",
      "\titers: 700, epoch: 4 | loss: 0.7038734\n",
      "\tspeed: 0.0474s/iter; left time: 266.6562s\n",
      "\titers: 800, epoch: 4 | loss: 0.6779256\n",
      "\tspeed: 0.0473s/iter; left time: 261.4953s\n",
      "\titers: 900, epoch: 4 | loss: 0.7179054\n",
      "\tspeed: 0.0472s/iter; left time: 256.1863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.6829791 Vali Loss: 0.8675241 Test Loss: 1.0935892\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6284392\n",
      "\tspeed: 0.1146s/iter; left time: 610.0844s\n",
      "\titers: 200, epoch: 5 | loss: 0.7099816\n",
      "\tspeed: 0.0478s/iter; left time: 249.6091s\n",
      "\titers: 300, epoch: 5 | loss: 0.6924280\n",
      "\tspeed: 0.0477s/iter; left time: 244.6267s\n",
      "\titers: 400, epoch: 5 | loss: 0.6455995\n",
      "\tspeed: 0.0479s/iter; left time: 240.7453s\n",
      "\titers: 500, epoch: 5 | loss: 0.6053495\n",
      "\tspeed: 0.0478s/iter; left time: 235.3719s\n",
      "\titers: 600, epoch: 5 | loss: 0.5920177\n",
      "\tspeed: 0.0478s/iter; left time: 230.7387s\n",
      "\titers: 700, epoch: 5 | loss: 0.5735717\n",
      "\tspeed: 0.0478s/iter; left time: 225.9932s\n",
      "\titers: 800, epoch: 5 | loss: 0.5689034\n",
      "\tspeed: 0.0478s/iter; left time: 221.1616s\n",
      "\titers: 900, epoch: 5 | loss: 0.5826128\n",
      "\tspeed: 0.0477s/iter; left time: 215.8261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.6299373 Vali Loss: 0.8429289 Test Loss: 1.0731412\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5944178\n",
      "\tspeed: 0.1138s/iter; left time: 503.2127s\n",
      "\titers: 200, epoch: 6 | loss: 0.5540605\n",
      "\tspeed: 0.0474s/iter; left time: 204.7646s\n",
      "\titers: 300, epoch: 6 | loss: 0.5924846\n",
      "\tspeed: 0.0474s/iter; left time: 200.1078s\n",
      "\titers: 400, epoch: 6 | loss: 0.5680408\n",
      "\tspeed: 0.0474s/iter; left time: 195.2896s\n",
      "\titers: 500, epoch: 6 | loss: 0.5852675\n",
      "\tspeed: 0.0475s/iter; left time: 190.8733s\n",
      "\titers: 600, epoch: 6 | loss: 0.5776537\n",
      "\tspeed: 0.0474s/iter; left time: 185.9233s\n",
      "\titers: 700, epoch: 6 | loss: 0.5698752\n",
      "\tspeed: 0.0474s/iter; left time: 181.1694s\n",
      "\titers: 800, epoch: 6 | loss: 0.5963567\n",
      "\tspeed: 0.0473s/iter; left time: 176.1528s\n",
      "\titers: 900, epoch: 6 | loss: 0.5641557\n",
      "\tspeed: 0.0473s/iter; left time: 171.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.5778267 Vali Loss: 0.8574352 Test Loss: 1.1003662\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9789762496948242, rmse:0.9894322752952576, mae:0.7047417759895325, rse:0.7007561326026917\n",
      "Original data scale mse:35732984.0, rmse:5977.70703125, mae:4005.14990234375, rse:0.2976920008659363\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1875412\n",
      "\tspeed: 0.0493s/iter; left time: 440.5307s\n",
      "\titers: 200, epoch: 1 | loss: 1.0709082\n",
      "\tspeed: 0.0473s/iter; left time: 418.0590s\n",
      "\titers: 300, epoch: 1 | loss: 0.9891061\n",
      "\tspeed: 0.0474s/iter; left time: 414.0887s\n",
      "\titers: 400, epoch: 1 | loss: 0.9204989\n",
      "\tspeed: 0.0473s/iter; left time: 408.8827s\n",
      "\titers: 500, epoch: 1 | loss: 0.9677376\n",
      "\tspeed: 0.0474s/iter; left time: 405.0159s\n",
      "\titers: 600, epoch: 1 | loss: 0.9638656\n",
      "\tspeed: 0.0383s/iter; left time: 322.9128s\n",
      "\titers: 700, epoch: 1 | loss: 0.8599298\n",
      "\tspeed: 0.0353s/iter; left time: 294.7906s\n",
      "\titers: 800, epoch: 1 | loss: 0.9270185\n",
      "\tspeed: 0.0353s/iter; left time: 291.1296s\n",
      "\titers: 900, epoch: 1 | loss: 0.8140124\n",
      "\tspeed: 0.0353s/iter; left time: 287.4706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 904 | Train Loss: 1.0052747 Vali Loss: 0.9816191 Test Loss: 1.2181979\n",
      "Validation loss decreased (inf --> 0.981619).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8358104\n",
      "\tspeed: 0.1195s/iter; left time: 960.1935s\n",
      "\titers: 200, epoch: 2 | loss: 0.8695145\n",
      "\tspeed: 0.0476s/iter; left time: 377.7517s\n",
      "\titers: 300, epoch: 2 | loss: 0.7639196\n",
      "\tspeed: 0.0476s/iter; left time: 372.7023s\n",
      "\titers: 400, epoch: 2 | loss: 0.7585706\n",
      "\tspeed: 0.0475s/iter; left time: 367.6723s\n",
      "\titers: 500, epoch: 2 | loss: 0.7589309\n",
      "\tspeed: 0.0475s/iter; left time: 362.4358s\n",
      "\titers: 600, epoch: 2 | loss: 0.7741919\n",
      "\tspeed: 0.0475s/iter; left time: 357.8386s\n",
      "\titers: 700, epoch: 2 | loss: 0.7519351\n",
      "\tspeed: 0.0475s/iter; left time: 353.4943s\n",
      "\titers: 800, epoch: 2 | loss: 0.8365265\n",
      "\tspeed: 0.0475s/iter; left time: 348.5116s\n",
      "\titers: 900, epoch: 2 | loss: 0.7460730\n",
      "\tspeed: 0.0476s/iter; left time: 344.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.7832088 Vali Loss: 0.8856352 Test Loss: 1.0061268\n",
      "Validation loss decreased (0.981619 --> 0.885635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7648516\n",
      "\tspeed: 0.1183s/iter; left time: 843.9080s\n",
      "\titers: 200, epoch: 3 | loss: 0.7298470\n",
      "\tspeed: 0.0477s/iter; left time: 335.5923s\n",
      "\titers: 300, epoch: 3 | loss: 0.6734920\n",
      "\tspeed: 0.0478s/iter; left time: 331.3152s\n",
      "\titers: 400, epoch: 3 | loss: 0.6659358\n",
      "\tspeed: 0.0476s/iter; left time: 325.1773s\n",
      "\titers: 500, epoch: 3 | loss: 0.6424951\n",
      "\tspeed: 0.0477s/iter; left time: 320.8960s\n",
      "\titers: 600, epoch: 3 | loss: 0.7355320\n",
      "\tspeed: 0.0477s/iter; left time: 316.5348s\n",
      "\titers: 700, epoch: 3 | loss: 0.6586006\n",
      "\tspeed: 0.0477s/iter; left time: 311.9238s\n",
      "\titers: 800, epoch: 3 | loss: 0.7381254\n",
      "\tspeed: 0.0478s/iter; left time: 307.7928s\n",
      "\titers: 900, epoch: 3 | loss: 0.6472455\n",
      "\tspeed: 0.0477s/iter; left time: 301.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.7215242 Vali Loss: 0.8340941 Test Loss: 1.0333551\n",
      "Validation loss decreased (0.885635 --> 0.834094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6028351\n",
      "\tspeed: 0.1177s/iter; left time: 733.2440s\n",
      "\titers: 200, epoch: 4 | loss: 0.6857756\n",
      "\tspeed: 0.0474s/iter; left time: 290.2350s\n",
      "\titers: 300, epoch: 4 | loss: 0.6858776\n",
      "\tspeed: 0.0473s/iter; left time: 285.2921s\n",
      "\titers: 400, epoch: 4 | loss: 0.6503389\n",
      "\tspeed: 0.0472s/iter; left time: 279.7048s\n",
      "\titers: 500, epoch: 4 | loss: 0.6935008\n",
      "\tspeed: 0.0477s/iter; left time: 278.0140s\n",
      "\titers: 600, epoch: 4 | loss: 0.6744983\n",
      "\tspeed: 0.0476s/iter; left time: 272.4299s\n",
      "\titers: 700, epoch: 4 | loss: 0.7216479\n",
      "\tspeed: 0.0476s/iter; left time: 267.7137s\n",
      "\titers: 800, epoch: 4 | loss: 0.6560860\n",
      "\tspeed: 0.0475s/iter; left time: 262.7961s\n",
      "\titers: 900, epoch: 4 | loss: 0.6124276\n",
      "\tspeed: 0.0475s/iter; left time: 257.8497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.6756247 Vali Loss: 0.8417673 Test Loss: 1.0208774\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5757141\n",
      "\tspeed: 0.1142s/iter; left time: 608.0612s\n",
      "\titers: 200, epoch: 5 | loss: 0.6822524\n",
      "\tspeed: 0.0475s/iter; left time: 248.0814s\n",
      "\titers: 300, epoch: 5 | loss: 0.6473578\n",
      "\tspeed: 0.0472s/iter; left time: 241.9206s\n",
      "\titers: 400, epoch: 5 | loss: 0.6352772\n",
      "\tspeed: 0.0472s/iter; left time: 236.9848s\n",
      "\titers: 500, epoch: 5 | loss: 0.6144392\n",
      "\tspeed: 0.0471s/iter; left time: 232.0132s\n",
      "\titers: 600, epoch: 5 | loss: 0.6395044\n",
      "\tspeed: 0.0472s/iter; left time: 227.5136s\n",
      "\titers: 700, epoch: 5 | loss: 0.6014526\n",
      "\tspeed: 0.0471s/iter; left time: 222.6442s\n",
      "\titers: 800, epoch: 5 | loss: 0.6005722\n",
      "\tspeed: 0.0472s/iter; left time: 218.5155s\n",
      "\titers: 900, epoch: 5 | loss: 0.5722402\n",
      "\tspeed: 0.0473s/iter; left time: 214.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.6152800 Vali Loss: 0.8373604 Test Loss: 1.0382894\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5379657\n",
      "\tspeed: 0.1144s/iter; left time: 505.6089s\n",
      "\titers: 200, epoch: 6 | loss: 0.5922204\n",
      "\tspeed: 0.0472s/iter; left time: 203.9273s\n",
      "\titers: 300, epoch: 6 | loss: 0.6198031\n",
      "\tspeed: 0.0474s/iter; left time: 200.0985s\n",
      "\titers: 400, epoch: 6 | loss: 0.5562665\n",
      "\tspeed: 0.0474s/iter; left time: 195.1535s\n",
      "\titers: 500, epoch: 6 | loss: 0.5584222\n",
      "\tspeed: 0.0472s/iter; left time: 189.9032s\n",
      "\titers: 600, epoch: 6 | loss: 0.5328361\n",
      "\tspeed: 0.0473s/iter; left time: 185.2761s\n",
      "\titers: 700, epoch: 6 | loss: 0.5177387\n",
      "\tspeed: 0.0474s/iter; left time: 180.9531s\n",
      "\titers: 800, epoch: 6 | loss: 0.5166710\n",
      "\tspeed: 0.0475s/iter; left time: 176.6713s\n",
      "\titers: 900, epoch: 6 | loss: 0.4979071\n",
      "\tspeed: 0.0474s/iter; left time: 171.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.5611980 Vali Loss: 0.8777289 Test Loss: 1.1463212\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0341898202896118, rmse:1.0169512033462524, mae:0.7237978577613831, rse:0.7202461361885071\n",
      "Original data scale mse:40138628.0, rmse:6335.50537109375, mae:4191.2890625, rse:0.31551048159599304\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1947978\n",
      "\tspeed: 0.0840s/iter; left time: 749.0702s\n",
      "\titers: 200, epoch: 1 | loss: 1.0805407\n",
      "\tspeed: 0.0539s/iter; left time: 475.7490s\n",
      "\titers: 300, epoch: 1 | loss: 1.0233463\n",
      "\tspeed: 0.0539s/iter; left time: 469.8914s\n",
      "\titers: 400, epoch: 1 | loss: 1.0212480\n",
      "\tspeed: 0.0537s/iter; left time: 463.2679s\n",
      "\titers: 500, epoch: 1 | loss: 0.9969036\n",
      "\tspeed: 0.0537s/iter; left time: 457.2597s\n",
      "\titers: 600, epoch: 1 | loss: 1.0220670\n",
      "\tspeed: 0.0535s/iter; left time: 450.1842s\n",
      "\titers: 700, epoch: 1 | loss: 0.9881644\n",
      "\tspeed: 0.0539s/iter; left time: 448.4209s\n",
      "\titers: 800, epoch: 1 | loss: 0.9545212\n",
      "\tspeed: 0.0539s/iter; left time: 443.0922s\n",
      "\titers: 900, epoch: 1 | loss: 0.9805778\n",
      "\tspeed: 0.0539s/iter; left time: 437.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.30s\n",
      "Steps: 902 | Train Loss: 1.0651113 Vali Loss: 1.2206563 Test Loss: 1.5429937\n",
      "Validation loss decreased (inf --> 1.220656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9728360\n",
      "\tspeed: 0.1348s/iter; left time: 1081.0593s\n",
      "\titers: 200, epoch: 2 | loss: 0.8959047\n",
      "\tspeed: 0.0537s/iter; left time: 425.0693s\n",
      "\titers: 300, epoch: 2 | loss: 0.9416983\n",
      "\tspeed: 0.0538s/iter; left time: 420.3843s\n",
      "\titers: 400, epoch: 2 | loss: 0.8410810\n",
      "\tspeed: 0.0538s/iter; left time: 415.2366s\n",
      "\titers: 500, epoch: 2 | loss: 0.8146811\n",
      "\tspeed: 0.0536s/iter; left time: 408.6642s\n",
      "\titers: 600, epoch: 2 | loss: 0.7613934\n",
      "\tspeed: 0.0538s/iter; left time: 404.4355s\n",
      "\titers: 700, epoch: 2 | loss: 0.7551066\n",
      "\tspeed: 0.0537s/iter; left time: 398.6179s\n",
      "\titers: 800, epoch: 2 | loss: 0.8480883\n",
      "\tspeed: 0.0539s/iter; left time: 394.2638s\n",
      "\titers: 900, epoch: 2 | loss: 0.7299631\n",
      "\tspeed: 0.0538s/iter; left time: 388.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.8332839 Vali Loss: 0.8419805 Test Loss: 1.0390695\n",
      "Validation loss decreased (1.220656 --> 0.841980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8131673\n",
      "\tspeed: 0.1345s/iter; left time: 957.4871s\n",
      "\titers: 200, epoch: 3 | loss: 0.7452924\n",
      "\tspeed: 0.0537s/iter; left time: 376.6808s\n",
      "\titers: 300, epoch: 3 | loss: 0.7622706\n",
      "\tspeed: 0.0540s/iter; left time: 373.6491s\n",
      "\titers: 400, epoch: 3 | loss: 0.7973822\n",
      "\tspeed: 0.0532s/iter; left time: 362.4638s\n",
      "\titers: 500, epoch: 3 | loss: 0.7529505\n",
      "\tspeed: 0.0537s/iter; left time: 360.5820s\n",
      "\titers: 600, epoch: 3 | loss: 0.7562136\n",
      "\tspeed: 0.0538s/iter; left time: 355.7521s\n",
      "\titers: 700, epoch: 3 | loss: 0.7613166\n",
      "\tspeed: 0.0539s/iter; left time: 351.2401s\n",
      "\titers: 800, epoch: 3 | loss: 0.7488498\n",
      "\tspeed: 0.0537s/iter; left time: 344.7213s\n",
      "\titers: 900, epoch: 3 | loss: 0.7207263\n",
      "\tspeed: 0.0538s/iter; left time: 339.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.7430436 Vali Loss: 0.8601449 Test Loss: 1.0440882\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6741490\n",
      "\tspeed: 0.1315s/iter; left time: 817.4670s\n",
      "\titers: 200, epoch: 4 | loss: 0.6768814\n",
      "\tspeed: 0.0539s/iter; left time: 329.6494s\n",
      "\titers: 300, epoch: 4 | loss: 0.7058569\n",
      "\tspeed: 0.0538s/iter; left time: 323.6515s\n",
      "\titers: 400, epoch: 4 | loss: 0.7016816\n",
      "\tspeed: 0.0540s/iter; left time: 319.2090s\n",
      "\titers: 500, epoch: 4 | loss: 0.7063848\n",
      "\tspeed: 0.0536s/iter; left time: 311.7737s\n",
      "\titers: 600, epoch: 4 | loss: 0.6629942\n",
      "\tspeed: 0.0538s/iter; left time: 307.4888s\n",
      "\titers: 700, epoch: 4 | loss: 0.6855446\n",
      "\tspeed: 0.0540s/iter; left time: 303.0321s\n",
      "\titers: 800, epoch: 4 | loss: 0.6862767\n",
      "\tspeed: 0.0539s/iter; left time: 297.1781s\n",
      "\titers: 900, epoch: 4 | loss: 0.6515035\n",
      "\tspeed: 0.0536s/iter; left time: 290.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.6877037 Vali Loss: 0.8755004 Test Loss: 1.1476339\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6977223\n",
      "\tspeed: 0.1313s/iter; left time: 697.4867s\n",
      "\titers: 200, epoch: 5 | loss: 0.6579342\n",
      "\tspeed: 0.0538s/iter; left time: 280.4943s\n",
      "\titers: 300, epoch: 5 | loss: 0.6619189\n",
      "\tspeed: 0.0539s/iter; left time: 275.3694s\n",
      "\titers: 400, epoch: 5 | loss: 0.6503311\n",
      "\tspeed: 0.0538s/iter; left time: 269.4883s\n",
      "\titers: 500, epoch: 5 | loss: 0.5772440\n",
      "\tspeed: 0.0539s/iter; left time: 264.8413s\n",
      "\titers: 600, epoch: 5 | loss: 0.6027458\n",
      "\tspeed: 0.0538s/iter; left time: 259.1660s\n",
      "\titers: 700, epoch: 5 | loss: 0.6194048\n",
      "\tspeed: 0.0537s/iter; left time: 253.1669s\n",
      "\titers: 800, epoch: 5 | loss: 0.5974443\n",
      "\tspeed: 0.0536s/iter; left time: 247.3354s\n",
      "\titers: 900, epoch: 5 | loss: 0.5542493\n",
      "\tspeed: 0.0537s/iter; left time: 242.2372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.6255995 Vali Loss: 0.9266499 Test Loss: 1.2246740\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0388625860214233, rmse:1.0192461013793945, mae:0.7245185375213623, rse:0.7221764922142029\n",
      "Original data scale mse:38251312.0, rmse:6184.7646484375, mae:4112.1064453125, rse:0.3081546723842621\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.3593889\n",
      "\tspeed: 0.0569s/iter; left time: 507.8929s\n",
      "\titers: 200, epoch: 1 | loss: 1.0367478\n",
      "\tspeed: 0.0545s/iter; left time: 480.5275s\n",
      "\titers: 300, epoch: 1 | loss: 0.9562916\n",
      "\tspeed: 0.0538s/iter; left time: 468.9250s\n",
      "\titers: 400, epoch: 1 | loss: 1.0198210\n",
      "\tspeed: 0.0539s/iter; left time: 464.3204s\n",
      "\titers: 500, epoch: 1 | loss: 0.9781577\n",
      "\tspeed: 0.0543s/iter; left time: 462.2819s\n",
      "\titers: 600, epoch: 1 | loss: 1.0063375\n",
      "\tspeed: 0.0539s/iter; left time: 454.0259s\n",
      "\titers: 700, epoch: 1 | loss: 1.0100294\n",
      "\tspeed: 0.0545s/iter; left time: 453.7762s\n",
      "\titers: 800, epoch: 1 | loss: 0.9429232\n",
      "\tspeed: 0.0539s/iter; left time: 442.8018s\n",
      "\titers: 900, epoch: 1 | loss: 0.9574505\n",
      "\tspeed: 0.0540s/iter; left time: 438.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.16s\n",
      "Steps: 902 | Train Loss: 1.0659430 Vali Loss: 1.2328447 Test Loss: 1.5477989\n",
      "Validation loss decreased (inf --> 1.232845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9769861\n",
      "\tspeed: 0.1376s/iter; left time: 1103.4328s\n",
      "\titers: 200, epoch: 2 | loss: 0.8432201\n",
      "\tspeed: 0.0537s/iter; left time: 425.4732s\n",
      "\titers: 300, epoch: 2 | loss: 0.8766646\n",
      "\tspeed: 0.0536s/iter; left time: 418.9180s\n",
      "\titers: 400, epoch: 2 | loss: 0.7458099\n",
      "\tspeed: 0.0538s/iter; left time: 415.0566s\n",
      "\titers: 500, epoch: 2 | loss: 0.8436472\n",
      "\tspeed: 0.0537s/iter; left time: 409.1472s\n",
      "\titers: 600, epoch: 2 | loss: 0.7611384\n",
      "\tspeed: 0.0537s/iter; left time: 403.5408s\n",
      "\titers: 700, epoch: 2 | loss: 0.7919884\n",
      "\tspeed: 0.0536s/iter; left time: 397.3435s\n",
      "\titers: 800, epoch: 2 | loss: 0.7483846\n",
      "\tspeed: 0.0537s/iter; left time: 393.1754s\n",
      "\titers: 900, epoch: 2 | loss: 0.7463714\n",
      "\tspeed: 0.0536s/iter; left time: 386.9468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.8330790 Vali Loss: 0.8854052 Test Loss: 1.0593328\n",
      "Validation loss decreased (1.232845 --> 0.885405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7578739\n",
      "\tspeed: 0.1362s/iter; left time: 969.6763s\n",
      "\titers: 200, epoch: 3 | loss: 0.7240906\n",
      "\tspeed: 0.0537s/iter; left time: 376.9696s\n",
      "\titers: 300, epoch: 3 | loss: 0.6992152\n",
      "\tspeed: 0.0536s/iter; left time: 371.0825s\n",
      "\titers: 400, epoch: 3 | loss: 0.6870955\n",
      "\tspeed: 0.0538s/iter; left time: 366.4597s\n",
      "\titers: 500, epoch: 3 | loss: 0.7317780\n",
      "\tspeed: 0.0536s/iter; left time: 359.8955s\n",
      "\titers: 600, epoch: 3 | loss: 0.7237553\n",
      "\tspeed: 0.0534s/iter; left time: 353.6278s\n",
      "\titers: 700, epoch: 3 | loss: 0.7336797\n",
      "\tspeed: 0.0538s/iter; left time: 350.4640s\n",
      "\titers: 800, epoch: 3 | loss: 0.6564544\n",
      "\tspeed: 0.0535s/iter; left time: 343.1219s\n",
      "\titers: 900, epoch: 3 | loss: 0.7107512\n",
      "\tspeed: 0.0537s/iter; left time: 339.0067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.7440021 Vali Loss: 0.8750057 Test Loss: 1.0693815\n",
      "Validation loss decreased (0.885405 --> 0.875006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6738966\n",
      "\tspeed: 0.1378s/iter; left time: 856.3202s\n",
      "\titers: 200, epoch: 4 | loss: 0.7107143\n",
      "\tspeed: 0.0538s/iter; left time: 328.9764s\n",
      "\titers: 300, epoch: 4 | loss: 0.7438474\n",
      "\tspeed: 0.0537s/iter; left time: 323.2387s\n",
      "\titers: 400, epoch: 4 | loss: 0.7128040\n",
      "\tspeed: 0.0537s/iter; left time: 317.5372s\n",
      "\titers: 500, epoch: 4 | loss: 0.7348254\n",
      "\tspeed: 0.0538s/iter; left time: 313.1191s\n",
      "\titers: 600, epoch: 4 | loss: 0.7033203\n",
      "\tspeed: 0.0536s/iter; left time: 306.1973s\n",
      "\titers: 700, epoch: 4 | loss: 0.6679760\n",
      "\tspeed: 0.0537s/iter; left time: 301.3018s\n",
      "\titers: 800, epoch: 4 | loss: 0.6176459\n",
      "\tspeed: 0.0537s/iter; left time: 296.0416s\n",
      "\titers: 900, epoch: 4 | loss: 0.6694947\n",
      "\tspeed: 0.0539s/iter; left time: 291.6243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.6916700 Vali Loss: 0.8642597 Test Loss: 1.1406615\n",
      "Validation loss decreased (0.875006 --> 0.864260).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6732173\n",
      "\tspeed: 0.1376s/iter; left time: 731.2502s\n",
      "\titers: 200, epoch: 5 | loss: 0.6253882\n",
      "\tspeed: 0.0538s/iter; left time: 280.6004s\n",
      "\titers: 300, epoch: 5 | loss: 0.6420274\n",
      "\tspeed: 0.0537s/iter; left time: 274.6239s\n",
      "\titers: 400, epoch: 5 | loss: 0.6057575\n",
      "\tspeed: 0.0538s/iter; left time: 269.5507s\n",
      "\titers: 500, epoch: 5 | loss: 0.6308406\n",
      "\tspeed: 0.0537s/iter; left time: 263.6197s\n",
      "\titers: 600, epoch: 5 | loss: 0.6349139\n",
      "\tspeed: 0.0537s/iter; left time: 258.4333s\n",
      "\titers: 700, epoch: 5 | loss: 0.6143259\n",
      "\tspeed: 0.0537s/iter; left time: 253.2358s\n",
      "\titers: 800, epoch: 5 | loss: 0.6445004\n",
      "\tspeed: 0.0539s/iter; left time: 248.5738s\n",
      "\titers: 900, epoch: 5 | loss: 0.6381221\n",
      "\tspeed: 0.0535s/iter; left time: 241.6606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.6346200 Vali Loss: 0.9304065 Test Loss: 1.1384140\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5721164\n",
      "\tspeed: 0.1324s/iter; left time: 583.8264s\n",
      "\titers: 200, epoch: 6 | loss: 0.5961891\n",
      "\tspeed: 0.0538s/iter; left time: 231.7838s\n",
      "\titers: 300, epoch: 6 | loss: 0.5824158\n",
      "\tspeed: 0.0539s/iter; left time: 226.8614s\n",
      "\titers: 400, epoch: 6 | loss: 0.5874233\n",
      "\tspeed: 0.0539s/iter; left time: 221.6239s\n",
      "\titers: 500, epoch: 6 | loss: 0.5880659\n",
      "\tspeed: 0.0538s/iter; left time: 215.9163s\n",
      "\titers: 600, epoch: 6 | loss: 0.5491968\n",
      "\tspeed: 0.0539s/iter; left time: 210.9109s\n",
      "\titers: 700, epoch: 6 | loss: 0.5841874\n",
      "\tspeed: 0.0537s/iter; left time: 204.6814s\n",
      "\titers: 800, epoch: 6 | loss: 0.5479693\n",
      "\tspeed: 0.0538s/iter; left time: 199.6509s\n",
      "\titers: 900, epoch: 6 | loss: 0.5772721\n",
      "\tspeed: 0.0535s/iter; left time: 193.2240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.77s\n",
      "Steps: 902 | Train Loss: 0.5808660 Vali Loss: 0.9301687 Test Loss: 1.2305624\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5661423\n",
      "\tspeed: 0.1327s/iter; left time: 465.4915s\n",
      "\titers: 200, epoch: 7 | loss: 0.5480683\n",
      "\tspeed: 0.0538s/iter; left time: 183.5166s\n",
      "\titers: 300, epoch: 7 | loss: 0.5643963\n",
      "\tspeed: 0.0537s/iter; left time: 177.7307s\n",
      "\titers: 400, epoch: 7 | loss: 0.5158062\n",
      "\tspeed: 0.0537s/iter; left time: 172.2825s\n",
      "\titers: 500, epoch: 7 | loss: 0.5193092\n",
      "\tspeed: 0.0538s/iter; left time: 167.2903s\n",
      "\titers: 600, epoch: 7 | loss: 0.5830152\n",
      "\tspeed: 0.0537s/iter; left time: 161.6132s\n",
      "\titers: 700, epoch: 7 | loss: 0.5339118\n",
      "\tspeed: 0.0536s/iter; left time: 155.9280s\n",
      "\titers: 800, epoch: 7 | loss: 0.4983934\n",
      "\tspeed: 0.0536s/iter; left time: 150.5271s\n",
      "\titers: 900, epoch: 7 | loss: 0.5183693\n",
      "\tspeed: 0.0537s/iter; left time: 145.3830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.5368747 Vali Loss: 0.9846078 Test Loss: 1.2634605\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.14153254032135, rmse:1.0684252977371216, mae:0.7631654739379883, rse:0.7570218443870544\n",
      "Original data scale mse:43871052.0, rmse:6623.5224609375, mae:4414.62255859375, rse:0.33001571893692017\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8215804\n",
      "\tspeed: 0.0710s/iter; left time: 635.9433s\n",
      "\titers: 200, epoch: 1 | loss: 0.7340425\n",
      "\tspeed: 0.0422s/iter; left time: 374.0406s\n",
      "\titers: 300, epoch: 1 | loss: 0.6676869\n",
      "\tspeed: 0.0416s/iter; left time: 364.5890s\n",
      "\titers: 400, epoch: 1 | loss: 0.6016252\n",
      "\tspeed: 0.0422s/iter; left time: 365.6405s\n",
      "\titers: 500, epoch: 1 | loss: 0.5677063\n",
      "\tspeed: 0.0409s/iter; left time: 350.3492s\n",
      "\titers: 600, epoch: 1 | loss: 0.5159410\n",
      "\tspeed: 0.0418s/iter; left time: 353.6310s\n",
      "\titers: 700, epoch: 1 | loss: 0.6329608\n",
      "\tspeed: 0.0412s/iter; left time: 344.5936s\n",
      "\titers: 800, epoch: 1 | loss: 0.5323271\n",
      "\tspeed: 0.0413s/iter; left time: 341.3677s\n",
      "\titers: 900, epoch: 1 | loss: 0.4647965\n",
      "\tspeed: 0.0412s/iter; left time: 336.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.6630838 Vali Loss: 0.5831255 Test Loss: 0.6188620\n",
      "Validation loss decreased (inf --> 0.583125).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3771373\n",
      "\tspeed: 0.1010s/iter; left time: 813.9382s\n",
      "\titers: 200, epoch: 2 | loss: 0.4977087\n",
      "\tspeed: 0.0422s/iter; left time: 335.3037s\n",
      "\titers: 300, epoch: 2 | loss: 0.4099578\n",
      "\tspeed: 0.0426s/iter; left time: 334.2675s\n",
      "\titers: 400, epoch: 2 | loss: 0.4390189\n",
      "\tspeed: 0.0415s/iter; left time: 321.9547s\n",
      "\titers: 500, epoch: 2 | loss: 0.3627845\n",
      "\tspeed: 0.0420s/iter; left time: 321.6187s\n",
      "\titers: 600, epoch: 2 | loss: 0.3869960\n",
      "\tspeed: 0.0421s/iter; left time: 318.3819s\n",
      "\titers: 700, epoch: 2 | loss: 0.3812953\n",
      "\tspeed: 0.0423s/iter; left time: 315.6841s\n",
      "\titers: 800, epoch: 2 | loss: 0.4554070\n",
      "\tspeed: 0.0421s/iter; left time: 309.5240s\n",
      "\titers: 900, epoch: 2 | loss: 0.4173861\n",
      "\tspeed: 0.0416s/iter; left time: 301.8944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 906 | Train Loss: 0.4297311 Vali Loss: 0.4789501 Test Loss: 0.5152006\n",
      "Validation loss decreased (0.583125 --> 0.478950).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3921083\n",
      "\tspeed: 0.0989s/iter; left time: 706.7846s\n",
      "\titers: 200, epoch: 3 | loss: 0.3476584\n",
      "\tspeed: 0.0416s/iter; left time: 293.4962s\n",
      "\titers: 300, epoch: 3 | loss: 0.3849903\n",
      "\tspeed: 0.0412s/iter; left time: 286.0270s\n",
      "\titers: 400, epoch: 3 | loss: 0.3697471\n",
      "\tspeed: 0.0411s/iter; left time: 281.7989s\n",
      "\titers: 500, epoch: 3 | loss: 0.4369237\n",
      "\tspeed: 0.0411s/iter; left time: 277.4355s\n",
      "\titers: 600, epoch: 3 | loss: 0.4183702\n",
      "\tspeed: 0.0411s/iter; left time: 273.4499s\n",
      "\titers: 700, epoch: 3 | loss: 0.4059889\n",
      "\tspeed: 0.0409s/iter; left time: 267.9084s\n",
      "\titers: 800, epoch: 3 | loss: 0.3744805\n",
      "\tspeed: 0.0415s/iter; left time: 267.4503s\n",
      "\titers: 900, epoch: 3 | loss: 0.3688411\n",
      "\tspeed: 0.0410s/iter; left time: 260.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.62s\n",
      "Steps: 906 | Train Loss: 0.3836633 Vali Loss: 0.4733172 Test Loss: 0.5011420\n",
      "Validation loss decreased (0.478950 --> 0.473317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3312873\n",
      "\tspeed: 0.1035s/iter; left time: 646.3324s\n",
      "\titers: 200, epoch: 4 | loss: 0.3703912\n",
      "\tspeed: 0.0416s/iter; left time: 255.3274s\n",
      "\titers: 300, epoch: 4 | loss: 0.3408947\n",
      "\tspeed: 0.0414s/iter; left time: 250.1984s\n",
      "\titers: 400, epoch: 4 | loss: 0.3194427\n",
      "\tspeed: 0.0409s/iter; left time: 243.1464s\n",
      "\titers: 500, epoch: 4 | loss: 0.3950619\n",
      "\tspeed: 0.0416s/iter; left time: 243.1170s\n",
      "\titers: 600, epoch: 4 | loss: 0.3436214\n",
      "\tspeed: 0.0408s/iter; left time: 234.4297s\n",
      "\titers: 700, epoch: 4 | loss: 0.3383271\n",
      "\tspeed: 0.0411s/iter; left time: 232.1092s\n",
      "\titers: 800, epoch: 4 | loss: 0.4065529\n",
      "\tspeed: 0.0416s/iter; left time: 230.4836s\n",
      "\titers: 900, epoch: 4 | loss: 0.3512607\n",
      "\tspeed: 0.0417s/iter; left time: 227.0920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.3614989 Vali Loss: 0.4654749 Test Loss: 0.4831934\n",
      "Validation loss decreased (0.473317 --> 0.465475).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3609648\n",
      "\tspeed: 0.1053s/iter; left time: 561.8522s\n",
      "\titers: 200, epoch: 5 | loss: 0.3308532\n",
      "\tspeed: 0.0412s/iter; left time: 215.8473s\n",
      "\titers: 300, epoch: 5 | loss: 0.2958168\n",
      "\tspeed: 0.0415s/iter; left time: 213.4049s\n",
      "\titers: 400, epoch: 5 | loss: 0.3693123\n",
      "\tspeed: 0.0416s/iter; left time: 209.5006s\n",
      "\titers: 500, epoch: 5 | loss: 0.3340417\n",
      "\tspeed: 0.0419s/iter; left time: 207.0890s\n",
      "\titers: 600, epoch: 5 | loss: 0.3647210\n",
      "\tspeed: 0.0414s/iter; left time: 200.4684s\n",
      "\titers: 700, epoch: 5 | loss: 0.3017252\n",
      "\tspeed: 0.0411s/iter; left time: 194.6988s\n",
      "\titers: 800, epoch: 5 | loss: 0.3568510\n",
      "\tspeed: 0.0414s/iter; left time: 192.0882s\n",
      "\titers: 900, epoch: 5 | loss: 0.3661846\n",
      "\tspeed: 0.0417s/iter; left time: 188.9717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.3394660 Vali Loss: 0.4655959 Test Loss: 0.4963616\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3381905\n",
      "\tspeed: 0.0957s/iter; left time: 423.9652s\n",
      "\titers: 200, epoch: 6 | loss: 0.3152276\n",
      "\tspeed: 0.0416s/iter; left time: 180.0676s\n",
      "\titers: 300, epoch: 6 | loss: 0.3125099\n",
      "\tspeed: 0.0411s/iter; left time: 173.9069s\n",
      "\titers: 400, epoch: 6 | loss: 0.3194456\n",
      "\tspeed: 0.0421s/iter; left time: 173.7443s\n",
      "\titers: 500, epoch: 6 | loss: 0.3368088\n",
      "\tspeed: 0.0413s/iter; left time: 166.5414s\n",
      "\titers: 600, epoch: 6 | loss: 0.2825433\n",
      "\tspeed: 0.0421s/iter; left time: 165.6317s\n",
      "\titers: 700, epoch: 6 | loss: 0.3300673\n",
      "\tspeed: 0.0417s/iter; left time: 159.6293s\n",
      "\titers: 800, epoch: 6 | loss: 0.2893016\n",
      "\tspeed: 0.0414s/iter; left time: 154.6043s\n",
      "\titers: 900, epoch: 6 | loss: 0.2938738\n",
      "\tspeed: 0.0418s/iter; left time: 151.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 906 | Train Loss: 0.3200244 Vali Loss: 0.4571894 Test Loss: 0.5082989\n",
      "Validation loss decreased (0.465475 --> 0.457189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2987775\n",
      "\tspeed: 0.0998s/iter; left time: 351.7339s\n",
      "\titers: 200, epoch: 7 | loss: 0.3472452\n",
      "\tspeed: 0.0409s/iter; left time: 140.0954s\n",
      "\titers: 300, epoch: 7 | loss: 0.3364459\n",
      "\tspeed: 0.0409s/iter; left time: 136.0495s\n",
      "\titers: 400, epoch: 7 | loss: 0.3506747\n",
      "\tspeed: 0.0407s/iter; left time: 131.1803s\n",
      "\titers: 500, epoch: 7 | loss: 0.2833876\n",
      "\tspeed: 0.0407s/iter; left time: 127.1948s\n",
      "\titers: 600, epoch: 7 | loss: 0.3112932\n",
      "\tspeed: 0.0409s/iter; left time: 123.7916s\n",
      "\titers: 700, epoch: 7 | loss: 0.3031738\n",
      "\tspeed: 0.0410s/iter; left time: 120.0510s\n",
      "\titers: 800, epoch: 7 | loss: 0.3065676\n",
      "\tspeed: 0.0414s/iter; left time: 116.8239s\n",
      "\titers: 900, epoch: 7 | loss: 0.3001534\n",
      "\tspeed: 0.0409s/iter; left time: 111.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.41s\n",
      "Steps: 906 | Train Loss: 0.2977701 Vali Loss: 0.4570362 Test Loss: 0.5153617\n",
      "Validation loss decreased (0.457189 --> 0.457036).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2868835\n",
      "\tspeed: 0.1008s/iter; left time: 263.9094s\n",
      "\titers: 200, epoch: 8 | loss: 0.2874367\n",
      "\tspeed: 0.0421s/iter; left time: 105.9790s\n",
      "\titers: 300, epoch: 8 | loss: 0.2843250\n",
      "\tspeed: 0.0424s/iter; left time: 102.5031s\n",
      "\titers: 400, epoch: 8 | loss: 0.2909996\n",
      "\tspeed: 0.0421s/iter; left time: 97.5780s\n",
      "\titers: 500, epoch: 8 | loss: 0.2424565\n",
      "\tspeed: 0.0420s/iter; left time: 93.2890s\n",
      "\titers: 600, epoch: 8 | loss: 0.2464985\n",
      "\tspeed: 0.0421s/iter; left time: 89.1705s\n",
      "\titers: 700, epoch: 8 | loss: 0.3050784\n",
      "\tspeed: 0.0418s/iter; left time: 84.3861s\n",
      "\titers: 800, epoch: 8 | loss: 0.3176151\n",
      "\tspeed: 0.0414s/iter; left time: 79.4861s\n",
      "\titers: 900, epoch: 8 | loss: 0.2773587\n",
      "\tspeed: 0.0418s/iter; left time: 75.9466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 906 | Train Loss: 0.2776493 Vali Loss: 0.4785967 Test Loss: 0.5177383\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2721704\n",
      "\tspeed: 0.0962s/iter; left time: 164.7632s\n",
      "\titers: 200, epoch: 9 | loss: 0.2560851\n",
      "\tspeed: 0.0414s/iter; left time: 66.7795s\n",
      "\titers: 300, epoch: 9 | loss: 0.2507009\n",
      "\tspeed: 0.0420s/iter; left time: 63.6176s\n",
      "\titers: 400, epoch: 9 | loss: 0.2249037\n",
      "\tspeed: 0.0419s/iter; left time: 59.2648s\n",
      "\titers: 500, epoch: 9 | loss: 0.2938058\n",
      "\tspeed: 0.0414s/iter; left time: 54.3841s\n",
      "\titers: 600, epoch: 9 | loss: 0.2440750\n",
      "\tspeed: 0.0420s/iter; left time: 50.9863s\n",
      "\titers: 700, epoch: 9 | loss: 0.2338870\n",
      "\tspeed: 0.0421s/iter; left time: 46.8433s\n",
      "\titers: 800, epoch: 9 | loss: 0.2551986\n",
      "\tspeed: 0.0427s/iter; left time: 43.2187s\n",
      "\titers: 900, epoch: 9 | loss: 0.2636540\n",
      "\tspeed: 0.0420s/iter; left time: 38.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 906 | Train Loss: 0.2598963 Vali Loss: 0.4722528 Test Loss: 0.5138612\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2168256\n",
      "\tspeed: 0.0962s/iter; left time: 77.6597s\n",
      "\titers: 200, epoch: 10 | loss: 0.2395929\n",
      "\tspeed: 0.0420s/iter; left time: 29.7037s\n",
      "\titers: 300, epoch: 10 | loss: 0.2337080\n",
      "\tspeed: 0.0416s/iter; left time: 25.2338s\n",
      "\titers: 400, epoch: 10 | loss: 0.2397047\n",
      "\tspeed: 0.0413s/iter; left time: 20.9567s\n",
      "\titers: 500, epoch: 10 | loss: 0.2422493\n",
      "\tspeed: 0.0410s/iter; left time: 16.6936s\n",
      "\titers: 600, epoch: 10 | loss: 0.2268523\n",
      "\tspeed: 0.0415s/iter; left time: 12.7286s\n",
      "\titers: 700, epoch: 10 | loss: 0.2348336\n",
      "\tspeed: 0.0412s/iter; left time: 8.5208s\n",
      "\titers: 800, epoch: 10 | loss: 0.2468491\n",
      "\tspeed: 0.0414s/iter; left time: 4.4335s\n",
      "\titers: 900, epoch: 10 | loss: 0.2230680\n",
      "\tspeed: 0.0412s/iter; left time: 0.2884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.2442937 Vali Loss: 0.4771433 Test Loss: 0.5069581\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.6487476229667664, rmse:0.8054487109184265, mae:0.5156450867652893, rse:0.568892776966095\n",
      "Original data scale mse:22829454.0, rmse:4778.017578125, mae:2917.666015625, rse:0.23757266998291016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8899755\n",
      "\tspeed: 0.0445s/iter; left time: 399.0743s\n",
      "\titers: 200, epoch: 1 | loss: 0.8364363\n",
      "\tspeed: 0.0408s/iter; left time: 361.4886s\n",
      "\titers: 300, epoch: 1 | loss: 0.6922052\n",
      "\tspeed: 0.0417s/iter; left time: 365.3229s\n",
      "\titers: 400, epoch: 1 | loss: 0.7003053\n",
      "\tspeed: 0.0419s/iter; left time: 363.0282s\n",
      "\titers: 500, epoch: 1 | loss: 0.6410112\n",
      "\tspeed: 0.0422s/iter; left time: 361.6171s\n",
      "\titers: 600, epoch: 1 | loss: 0.5387596\n",
      "\tspeed: 0.0427s/iter; left time: 360.9133s\n",
      "\titers: 700, epoch: 1 | loss: 0.5007063\n",
      "\tspeed: 0.0428s/iter; left time: 358.0872s\n",
      "\titers: 800, epoch: 1 | loss: 0.4797053\n",
      "\tspeed: 0.0422s/iter; left time: 348.2107s\n",
      "\titers: 900, epoch: 1 | loss: 0.4850058\n",
      "\tspeed: 0.0419s/iter; left time: 342.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 906 | Train Loss: 0.6741569 Vali Loss: 0.5860541 Test Loss: 0.6255392\n",
      "Validation loss decreased (inf --> 0.586054).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4500560\n",
      "\tspeed: 0.0998s/iter; left time: 803.8412s\n",
      "\titers: 200, epoch: 2 | loss: 0.4213663\n",
      "\tspeed: 0.0411s/iter; left time: 327.0330s\n",
      "\titers: 300, epoch: 2 | loss: 0.4624331\n",
      "\tspeed: 0.0412s/iter; left time: 323.6069s\n",
      "\titers: 400, epoch: 2 | loss: 0.4592268\n",
      "\tspeed: 0.0410s/iter; left time: 318.1228s\n",
      "\titers: 500, epoch: 2 | loss: 0.4630963\n",
      "\tspeed: 0.0409s/iter; left time: 312.9498s\n",
      "\titers: 600, epoch: 2 | loss: 0.4708211\n",
      "\tspeed: 0.0413s/iter; left time: 312.0644s\n",
      "\titers: 700, epoch: 2 | loss: 0.4336411\n",
      "\tspeed: 0.0415s/iter; left time: 309.6497s\n",
      "\titers: 800, epoch: 2 | loss: 0.3728358\n",
      "\tspeed: 0.0411s/iter; left time: 302.1375s\n",
      "\titers: 900, epoch: 2 | loss: 0.3855370\n",
      "\tspeed: 0.0409s/iter; left time: 297.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.59s\n",
      "Steps: 906 | Train Loss: 0.4282083 Vali Loss: 0.4797900 Test Loss: 0.5115393\n",
      "Validation loss decreased (0.586054 --> 0.479790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3773729\n",
      "\tspeed: 0.0991s/iter; left time: 708.5355s\n",
      "\titers: 200, epoch: 3 | loss: 0.3910038\n",
      "\tspeed: 0.0411s/iter; left time: 289.3901s\n",
      "\titers: 300, epoch: 3 | loss: 0.3710051\n",
      "\tspeed: 0.0408s/iter; left time: 283.4756s\n",
      "\titers: 400, epoch: 3 | loss: 0.3715049\n",
      "\tspeed: 0.0413s/iter; left time: 282.6784s\n",
      "\titers: 500, epoch: 3 | loss: 0.4018357\n",
      "\tspeed: 0.0409s/iter; left time: 276.0446s\n",
      "\titers: 600, epoch: 3 | loss: 0.3454407\n",
      "\tspeed: 0.0412s/iter; left time: 273.9579s\n",
      "\titers: 700, epoch: 3 | loss: 0.3729830\n",
      "\tspeed: 0.0411s/iter; left time: 269.4255s\n",
      "\titers: 800, epoch: 3 | loss: 0.4398901\n",
      "\tspeed: 0.0412s/iter; left time: 265.9000s\n",
      "\titers: 900, epoch: 3 | loss: 0.4333330\n",
      "\tspeed: 0.0409s/iter; left time: 259.9349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.3784432 Vali Loss: 0.4538562 Test Loss: 0.4757619\n",
      "Validation loss decreased (0.479790 --> 0.453856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3272770\n",
      "\tspeed: 0.0999s/iter; left time: 623.8617s\n",
      "\titers: 200, epoch: 4 | loss: 0.3562804\n",
      "\tspeed: 0.0422s/iter; left time: 259.2392s\n",
      "\titers: 300, epoch: 4 | loss: 0.3909039\n",
      "\tspeed: 0.0423s/iter; left time: 255.7123s\n",
      "\titers: 400, epoch: 4 | loss: 0.3692440\n",
      "\tspeed: 0.0415s/iter; left time: 246.6389s\n",
      "\titers: 500, epoch: 4 | loss: 0.3756211\n",
      "\tspeed: 0.0423s/iter; left time: 247.4446s\n",
      "\titers: 600, epoch: 4 | loss: 0.2831044\n",
      "\tspeed: 0.0423s/iter; left time: 242.6686s\n",
      "\titers: 700, epoch: 4 | loss: 0.3274312\n",
      "\tspeed: 0.0417s/iter; left time: 235.5401s\n",
      "\titers: 800, epoch: 4 | loss: 0.3439961\n",
      "\tspeed: 0.0422s/iter; left time: 234.1134s\n",
      "\titers: 900, epoch: 4 | loss: 0.3253009\n",
      "\tspeed: 0.0423s/iter; left time: 230.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.3552166 Vali Loss: 0.4533563 Test Loss: 0.4944520\n",
      "Validation loss decreased (0.453856 --> 0.453356).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3947728\n",
      "\tspeed: 0.1013s/iter; left time: 540.9039s\n",
      "\titers: 200, epoch: 5 | loss: 0.3120843\n",
      "\tspeed: 0.0416s/iter; left time: 217.6419s\n",
      "\titers: 300, epoch: 5 | loss: 0.3701042\n",
      "\tspeed: 0.0414s/iter; left time: 212.4868s\n",
      "\titers: 400, epoch: 5 | loss: 0.3691570\n",
      "\tspeed: 0.0419s/iter; left time: 211.2011s\n",
      "\titers: 500, epoch: 5 | loss: 0.3299272\n",
      "\tspeed: 0.0424s/iter; left time: 209.2585s\n",
      "\titers: 600, epoch: 5 | loss: 0.3652367\n",
      "\tspeed: 0.0414s/iter; left time: 200.2626s\n",
      "\titers: 700, epoch: 5 | loss: 0.3585016\n",
      "\tspeed: 0.0415s/iter; left time: 196.8049s\n",
      "\titers: 800, epoch: 5 | loss: 0.3336183\n",
      "\tspeed: 0.0418s/iter; left time: 193.8016s\n",
      "\titers: 900, epoch: 5 | loss: 0.2850974\n",
      "\tspeed: 0.0418s/iter; left time: 189.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 906 | Train Loss: 0.3365494 Vali Loss: 0.4597277 Test Loss: 0.4925344\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3360326\n",
      "\tspeed: 0.0986s/iter; left time: 436.7189s\n",
      "\titers: 200, epoch: 6 | loss: 0.3765206\n",
      "\tspeed: 0.0428s/iter; left time: 185.2557s\n",
      "\titers: 300, epoch: 6 | loss: 0.3099653\n",
      "\tspeed: 0.0424s/iter; left time: 179.4750s\n",
      "\titers: 400, epoch: 6 | loss: 0.2737060\n",
      "\tspeed: 0.0426s/iter; left time: 176.0637s\n",
      "\titers: 500, epoch: 6 | loss: 0.3072108\n",
      "\tspeed: 0.0424s/iter; left time: 171.0452s\n",
      "\titers: 600, epoch: 6 | loss: 0.3093444\n",
      "\tspeed: 0.0427s/iter; left time: 168.0224s\n",
      "\titers: 700, epoch: 6 | loss: 0.2977930\n",
      "\tspeed: 0.0422s/iter; left time: 161.5253s\n",
      "\titers: 800, epoch: 6 | loss: 0.3408779\n",
      "\tspeed: 0.0424s/iter; left time: 158.2721s\n",
      "\titers: 900, epoch: 6 | loss: 0.3138795\n",
      "\tspeed: 0.0429s/iter; left time: 155.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.76s\n",
      "Steps: 906 | Train Loss: 0.3170537 Vali Loss: 0.4661587 Test Loss: 0.5026929\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3064246\n",
      "\tspeed: 0.0978s/iter; left time: 344.6975s\n",
      "\titers: 200, epoch: 7 | loss: 0.2834108\n",
      "\tspeed: 0.0421s/iter; left time: 144.0872s\n",
      "\titers: 300, epoch: 7 | loss: 0.3296257\n",
      "\tspeed: 0.0422s/iter; left time: 140.1601s\n",
      "\titers: 400, epoch: 7 | loss: 0.2797140\n",
      "\tspeed: 0.0422s/iter; left time: 136.0752s\n",
      "\titers: 500, epoch: 7 | loss: 0.2748996\n",
      "\tspeed: 0.0422s/iter; left time: 131.7922s\n",
      "\titers: 600, epoch: 7 | loss: 0.2563794\n",
      "\tspeed: 0.0419s/iter; left time: 126.7063s\n",
      "\titers: 700, epoch: 7 | loss: 0.2700790\n",
      "\tspeed: 0.0419s/iter; left time: 122.6286s\n",
      "\titers: 800, epoch: 7 | loss: 0.2922874\n",
      "\tspeed: 0.0416s/iter; left time: 117.6045s\n",
      "\titers: 900, epoch: 7 | loss: 0.3014714\n",
      "\tspeed: 0.0416s/iter; left time: 113.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.2970921 Vali Loss: 0.4662874 Test Loss: 0.5006680\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5677363872528076, rmse:0.7534828186035156, mae:0.4944019317626953, rse:0.5321890115737915\n",
      "Original data scale mse:19457170.0, rmse:4411.0283203125, mae:2774.205078125, rse:0.2193252146244049\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9102181\n",
      "\tspeed: 0.0796s/iter; left time: 711.5740s\n",
      "\titers: 200, epoch: 1 | loss: 0.8352563\n",
      "\tspeed: 0.0504s/iter; left time: 445.9520s\n",
      "\titers: 300, epoch: 1 | loss: 0.8127864\n",
      "\tspeed: 0.0502s/iter; left time: 438.4718s\n",
      "\titers: 400, epoch: 1 | loss: 0.7703711\n",
      "\tspeed: 0.0506s/iter; left time: 436.8833s\n",
      "\titers: 500, epoch: 1 | loss: 0.7553347\n",
      "\tspeed: 0.0505s/iter; left time: 431.0778s\n",
      "\titers: 600, epoch: 1 | loss: 0.6957842\n",
      "\tspeed: 0.0504s/iter; left time: 425.8089s\n",
      "\titers: 700, epoch: 1 | loss: 0.6802933\n",
      "\tspeed: 0.0501s/iter; left time: 418.2195s\n",
      "\titers: 800, epoch: 1 | loss: 0.6807583\n",
      "\tspeed: 0.0502s/iter; left time: 413.3431s\n",
      "\titers: 900, epoch: 1 | loss: 0.6779354\n",
      "\tspeed: 0.0503s/iter; left time: 409.8889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.26s\n",
      "Steps: 904 | Train Loss: 0.7934198 Vali Loss: 0.7660141 Test Loss: 0.8531764\n",
      "Validation loss decreased (inf --> 0.766014).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6005991\n",
      "\tspeed: 0.1199s/iter; left time: 963.2918s\n",
      "\titers: 200, epoch: 2 | loss: 0.5920650\n",
      "\tspeed: 0.0486s/iter; left time: 386.0293s\n",
      "\titers: 300, epoch: 2 | loss: 0.5928144\n",
      "\tspeed: 0.0480s/iter; left time: 375.9819s\n",
      "\titers: 400, epoch: 2 | loss: 0.5497922\n",
      "\tspeed: 0.0479s/iter; left time: 370.5062s\n",
      "\titers: 500, epoch: 2 | loss: 0.5299858\n",
      "\tspeed: 0.0480s/iter; left time: 366.2890s\n",
      "\titers: 600, epoch: 2 | loss: 0.5649956\n",
      "\tspeed: 0.0479s/iter; left time: 361.1437s\n",
      "\titers: 700, epoch: 2 | loss: 0.5198504\n",
      "\tspeed: 0.0479s/iter; left time: 356.2983s\n",
      "\titers: 800, epoch: 2 | loss: 0.5747349\n",
      "\tspeed: 0.0480s/iter; left time: 352.1720s\n",
      "\titers: 900, epoch: 2 | loss: 0.5264161\n",
      "\tspeed: 0.0479s/iter; left time: 346.9756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.94s\n",
      "Steps: 904 | Train Loss: 0.5655994 Vali Loss: 0.6318875 Test Loss: 0.7062410\n",
      "Validation loss decreased (0.766014 --> 0.631887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5809160\n",
      "\tspeed: 0.1194s/iter; left time: 851.8459s\n",
      "\titers: 200, epoch: 3 | loss: 0.4719096\n",
      "\tspeed: 0.0479s/iter; left time: 336.8453s\n",
      "\titers: 300, epoch: 3 | loss: 0.4699241\n",
      "\tspeed: 0.0480s/iter; left time: 333.0081s\n",
      "\titers: 400, epoch: 3 | loss: 0.4817919\n",
      "\tspeed: 0.0478s/iter; left time: 326.7343s\n",
      "\titers: 500, epoch: 3 | loss: 0.5096378\n",
      "\tspeed: 0.0480s/iter; left time: 323.2876s\n",
      "\titers: 600, epoch: 3 | loss: 0.5442539\n",
      "\tspeed: 0.0478s/iter; left time: 317.2892s\n",
      "\titers: 700, epoch: 3 | loss: 0.4634534\n",
      "\tspeed: 0.0478s/iter; left time: 312.4647s\n",
      "\titers: 800, epoch: 3 | loss: 0.5066699\n",
      "\tspeed: 0.0479s/iter; left time: 308.1337s\n",
      "\titers: 900, epoch: 3 | loss: 0.4983327\n",
      "\tspeed: 0.0478s/iter; left time: 303.0004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.59s\n",
      "Steps: 904 | Train Loss: 0.5019958 Vali Loss: 0.6197063 Test Loss: 0.6924624\n",
      "Validation loss decreased (0.631887 --> 0.619706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4398247\n",
      "\tspeed: 0.1170s/iter; left time: 728.7547s\n",
      "\titers: 200, epoch: 4 | loss: 0.4549312\n",
      "\tspeed: 0.0476s/iter; left time: 292.0112s\n",
      "\titers: 300, epoch: 4 | loss: 0.4815702\n",
      "\tspeed: 0.0476s/iter; left time: 287.1210s\n",
      "\titers: 400, epoch: 4 | loss: 0.4106808\n",
      "\tspeed: 0.0478s/iter; left time: 283.3349s\n",
      "\titers: 500, epoch: 4 | loss: 0.4839717\n",
      "\tspeed: 0.0476s/iter; left time: 277.7103s\n",
      "\titers: 600, epoch: 4 | loss: 0.4223243\n",
      "\tspeed: 0.0478s/iter; left time: 273.8719s\n",
      "\titers: 700, epoch: 4 | loss: 0.4891415\n",
      "\tspeed: 0.0476s/iter; left time: 268.0147s\n",
      "\titers: 800, epoch: 4 | loss: 0.4607472\n",
      "\tspeed: 0.0474s/iter; left time: 262.0754s\n",
      "\titers: 900, epoch: 4 | loss: 0.4918444\n",
      "\tspeed: 0.0475s/iter; left time: 257.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.34s\n",
      "Steps: 904 | Train Loss: 0.4727358 Vali Loss: 0.6211005 Test Loss: 0.7050804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4377528\n",
      "\tspeed: 0.1144s/iter; left time: 609.0054s\n",
      "\titers: 200, epoch: 5 | loss: 0.4881567\n",
      "\tspeed: 0.0480s/iter; left time: 250.8733s\n",
      "\titers: 300, epoch: 5 | loss: 0.4722354\n",
      "\tspeed: 0.0481s/iter; left time: 246.3016s\n",
      "\titers: 400, epoch: 5 | loss: 0.4676666\n",
      "\tspeed: 0.0480s/iter; left time: 240.9981s\n",
      "\titers: 500, epoch: 5 | loss: 0.3962851\n",
      "\tspeed: 0.0480s/iter; left time: 236.2729s\n",
      "\titers: 600, epoch: 5 | loss: 0.4309969\n",
      "\tspeed: 0.0480s/iter; left time: 231.7595s\n",
      "\titers: 700, epoch: 5 | loss: 0.4166131\n",
      "\tspeed: 0.0480s/iter; left time: 226.9984s\n",
      "\titers: 800, epoch: 5 | loss: 0.3744484\n",
      "\tspeed: 0.0480s/iter; left time: 222.1632s\n",
      "\titers: 900, epoch: 5 | loss: 0.4104685\n",
      "\tspeed: 0.0480s/iter; left time: 217.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.65s\n",
      "Steps: 904 | Train Loss: 0.4377368 Vali Loss: 0.6116882 Test Loss: 0.7315316\n",
      "Validation loss decreased (0.619706 --> 0.611688).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3988077\n",
      "\tspeed: 0.1170s/iter; left time: 517.3431s\n",
      "\titers: 200, epoch: 6 | loss: 0.3815190\n",
      "\tspeed: 0.0476s/iter; left time: 205.7452s\n",
      "\titers: 300, epoch: 6 | loss: 0.4018876\n",
      "\tspeed: 0.0475s/iter; left time: 200.5269s\n",
      "\titers: 400, epoch: 6 | loss: 0.4126396\n",
      "\tspeed: 0.0476s/iter; left time: 196.1354s\n",
      "\titers: 500, epoch: 6 | loss: 0.3998081\n",
      "\tspeed: 0.0476s/iter; left time: 191.4015s\n",
      "\titers: 600, epoch: 6 | loss: 0.4140124\n",
      "\tspeed: 0.0475s/iter; left time: 186.2136s\n",
      "\titers: 700, epoch: 6 | loss: 0.3929665\n",
      "\tspeed: 0.0475s/iter; left time: 181.6628s\n",
      "\titers: 800, epoch: 6 | loss: 0.4206937\n",
      "\tspeed: 0.0475s/iter; left time: 176.8353s\n",
      "\titers: 900, epoch: 6 | loss: 0.4011725\n",
      "\tspeed: 0.0476s/iter; left time: 172.4652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.4037644 Vali Loss: 0.6171958 Test Loss: 0.7233231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3382178\n",
      "\tspeed: 0.1138s/iter; left time: 400.2576s\n",
      "\titers: 200, epoch: 7 | loss: 0.3303524\n",
      "\tspeed: 0.0475s/iter; left time: 162.4401s\n",
      "\titers: 300, epoch: 7 | loss: 0.3617322\n",
      "\tspeed: 0.0479s/iter; left time: 158.9294s\n",
      "\titers: 400, epoch: 7 | loss: 0.3665047\n",
      "\tspeed: 0.0477s/iter; left time: 153.4238s\n",
      "\titers: 500, epoch: 7 | loss: 0.3506428\n",
      "\tspeed: 0.0479s/iter; left time: 149.2076s\n",
      "\titers: 600, epoch: 7 | loss: 0.3479131\n",
      "\tspeed: 0.0476s/iter; left time: 143.7056s\n",
      "\titers: 700, epoch: 7 | loss: 0.3816132\n",
      "\tspeed: 0.0478s/iter; left time: 139.4391s\n",
      "\titers: 800, epoch: 7 | loss: 0.3623883\n",
      "\tspeed: 0.0494s/iter; left time: 139.0449s\n",
      "\titers: 900, epoch: 7 | loss: 0.3592669\n",
      "\tspeed: 0.0504s/iter; left time: 136.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.83s\n",
      "Steps: 904 | Train Loss: 0.3709147 Vali Loss: 0.6296008 Test Loss: 0.7274906\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3531027\n",
      "\tspeed: 0.1170s/iter; left time: 305.7731s\n",
      "\titers: 200, epoch: 8 | loss: 0.3672871\n",
      "\tspeed: 0.0484s/iter; left time: 121.5900s\n",
      "\titers: 300, epoch: 8 | loss: 0.3625405\n",
      "\tspeed: 0.0479s/iter; left time: 115.5511s\n",
      "\titers: 400, epoch: 8 | loss: 0.3402949\n",
      "\tspeed: 0.0477s/iter; left time: 110.3422s\n",
      "\titers: 500, epoch: 8 | loss: 0.3736580\n",
      "\tspeed: 0.0477s/iter; left time: 105.5927s\n",
      "\titers: 600, epoch: 8 | loss: 0.3674063\n",
      "\tspeed: 0.0477s/iter; left time: 100.8275s\n",
      "\titers: 700, epoch: 8 | loss: 0.3437903\n",
      "\tspeed: 0.0477s/iter; left time: 95.9982s\n",
      "\titers: 800, epoch: 8 | loss: 0.3295695\n",
      "\tspeed: 0.0478s/iter; left time: 91.5058s\n",
      "\titers: 900, epoch: 8 | loss: 0.3289976\n",
      "\tspeed: 0.0478s/iter; left time: 86.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.79s\n",
      "Steps: 904 | Train Loss: 0.3450342 Vali Loss: 0.6330314 Test Loss: 0.7277969\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.1340248584747314, rmse:1.0649060010910034, mae:0.7311239242553711, rse:0.7542097568511963\n",
      "Original data scale mse:42587312.0, rmse:6525.8955078125, mae:4191.62890625, rse:0.32499197125434875\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9949392\n",
      "\tspeed: 0.0523s/iter; left time: 467.9678s\n",
      "\titers: 200, epoch: 1 | loss: 0.8061899\n",
      "\tspeed: 0.0488s/iter; left time: 431.5962s\n",
      "\titers: 300, epoch: 1 | loss: 0.7373991\n",
      "\tspeed: 0.0485s/iter; left time: 424.0624s\n",
      "\titers: 400, epoch: 1 | loss: 0.6995111\n",
      "\tspeed: 0.0477s/iter; left time: 412.2530s\n",
      "\titers: 500, epoch: 1 | loss: 0.7024124\n",
      "\tspeed: 0.0474s/iter; left time: 404.6018s\n",
      "\titers: 600, epoch: 1 | loss: 0.7354332\n",
      "\tspeed: 0.0476s/iter; left time: 401.3773s\n",
      "\titers: 700, epoch: 1 | loss: 0.7113137\n",
      "\tspeed: 0.0478s/iter; left time: 398.9133s\n",
      "\titers: 800, epoch: 1 | loss: 0.6863198\n",
      "\tspeed: 0.0481s/iter; left time: 396.6314s\n",
      "\titers: 900, epoch: 1 | loss: 0.6429592\n",
      "\tspeed: 0.0504s/iter; left time: 410.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.16s\n",
      "Steps: 904 | Train Loss: 0.7875817 Vali Loss: 0.7530460 Test Loss: 0.8438248\n",
      "Validation loss decreased (inf --> 0.753046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5613745\n",
      "\tspeed: 0.1197s/iter; left time: 961.7480s\n",
      "\titers: 200, epoch: 2 | loss: 0.5919114\n",
      "\tspeed: 0.0471s/iter; left time: 374.1598s\n",
      "\titers: 300, epoch: 2 | loss: 0.5276534\n",
      "\tspeed: 0.0480s/iter; left time: 375.9743s\n",
      "\titers: 400, epoch: 2 | loss: 0.5335710\n",
      "\tspeed: 0.0479s/iter; left time: 370.2811s\n",
      "\titers: 500, epoch: 2 | loss: 0.5411240\n",
      "\tspeed: 0.0477s/iter; left time: 364.6504s\n",
      "\titers: 600, epoch: 2 | loss: 0.5586331\n",
      "\tspeed: 0.0476s/iter; left time: 358.8711s\n",
      "\titers: 700, epoch: 2 | loss: 0.5584943\n",
      "\tspeed: 0.0478s/iter; left time: 355.8544s\n",
      "\titers: 800, epoch: 2 | loss: 0.5198619\n",
      "\tspeed: 0.0480s/iter; left time: 351.9407s\n",
      "\titers: 900, epoch: 2 | loss: 0.5035214\n",
      "\tspeed: 0.0477s/iter; left time: 345.1134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 904 | Train Loss: 0.5643217 Vali Loss: 0.6316887 Test Loss: 0.6966246\n",
      "Validation loss decreased (0.753046 --> 0.631689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5051592\n",
      "\tspeed: 0.1193s/iter; left time: 851.1000s\n",
      "\titers: 200, epoch: 3 | loss: 0.5862759\n",
      "\tspeed: 0.0481s/iter; left time: 337.9587s\n",
      "\titers: 300, epoch: 3 | loss: 0.5428197\n",
      "\tspeed: 0.0481s/iter; left time: 333.3112s\n",
      "\titers: 400, epoch: 3 | loss: 0.4956426\n",
      "\tspeed: 0.0480s/iter; left time: 327.9311s\n",
      "\titers: 500, epoch: 3 | loss: 0.4680121\n",
      "\tspeed: 0.0481s/iter; left time: 323.5832s\n",
      "\titers: 600, epoch: 3 | loss: 0.5172967\n",
      "\tspeed: 0.0478s/iter; left time: 317.3852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4615197\n",
      "\tspeed: 0.0480s/iter; left time: 313.4489s\n",
      "\titers: 800, epoch: 3 | loss: 0.4927020\n",
      "\tspeed: 0.0480s/iter; left time: 308.7049s\n",
      "\titers: 900, epoch: 3 | loss: 0.5369892\n",
      "\tspeed: 0.0478s/iter; left time: 302.9871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.66s\n",
      "Steps: 904 | Train Loss: 0.5022240 Vali Loss: 0.6159849 Test Loss: 0.6869023\n",
      "Validation loss decreased (0.631689 --> 0.615985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4533613\n",
      "\tspeed: 0.1216s/iter; left time: 757.4509s\n",
      "\titers: 200, epoch: 4 | loss: 0.4764120\n",
      "\tspeed: 0.0506s/iter; left time: 309.9826s\n",
      "\titers: 300, epoch: 4 | loss: 0.4886743\n",
      "\tspeed: 0.0502s/iter; left time: 302.7705s\n",
      "\titers: 400, epoch: 4 | loss: 0.4563621\n",
      "\tspeed: 0.0482s/iter; left time: 285.4898s\n",
      "\titers: 500, epoch: 4 | loss: 0.4554276\n",
      "\tspeed: 0.0479s/iter; left time: 279.1977s\n",
      "\titers: 600, epoch: 4 | loss: 0.4652305\n",
      "\tspeed: 0.0480s/iter; left time: 274.7225s\n",
      "\titers: 700, epoch: 4 | loss: 0.4585883\n",
      "\tspeed: 0.0480s/iter; left time: 270.3791s\n",
      "\titers: 800, epoch: 4 | loss: 0.4163417\n",
      "\tspeed: 0.0482s/iter; left time: 266.4844s\n",
      "\titers: 900, epoch: 4 | loss: 0.4330878\n",
      "\tspeed: 0.0480s/iter; left time: 260.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.38s\n",
      "Steps: 904 | Train Loss: 0.4739475 Vali Loss: 0.6131756 Test Loss: 0.7152678\n",
      "Validation loss decreased (0.615985 --> 0.613176).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4378204\n",
      "\tspeed: 0.1190s/iter; left time: 633.4299s\n",
      "\titers: 200, epoch: 5 | loss: 0.4644983\n",
      "\tspeed: 0.0498s/iter; left time: 260.0933s\n",
      "\titers: 300, epoch: 5 | loss: 0.4228581\n",
      "\tspeed: 0.0506s/iter; left time: 259.4268s\n",
      "\titers: 400, epoch: 5 | loss: 0.3952292\n",
      "\tspeed: 0.0505s/iter; left time: 253.9488s\n",
      "\titers: 500, epoch: 5 | loss: 0.4381110\n",
      "\tspeed: 0.0501s/iter; left time: 246.9333s\n",
      "\titers: 600, epoch: 5 | loss: 0.4482695\n",
      "\tspeed: 0.0505s/iter; left time: 243.8269s\n",
      "\titers: 700, epoch: 5 | loss: 0.4733983\n",
      "\tspeed: 0.0502s/iter; left time: 237.3868s\n",
      "\titers: 800, epoch: 5 | loss: 0.4329626\n",
      "\tspeed: 0.0505s/iter; left time: 233.7748s\n",
      "\titers: 900, epoch: 5 | loss: 0.4278652\n",
      "\tspeed: 0.0504s/iter; left time: 227.9361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 904 | Train Loss: 0.4403939 Vali Loss: 0.6085291 Test Loss: 0.7080616\n",
      "Validation loss decreased (0.613176 --> 0.608529).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4458174\n",
      "\tspeed: 0.1189s/iter; left time: 525.8425s\n",
      "\titers: 200, epoch: 6 | loss: 0.4127825\n",
      "\tspeed: 0.0477s/iter; left time: 206.0026s\n",
      "\titers: 300, epoch: 6 | loss: 0.4211327\n",
      "\tspeed: 0.0471s/iter; left time: 198.6229s\n",
      "\titers: 400, epoch: 6 | loss: 0.4280051\n",
      "\tspeed: 0.0479s/iter; left time: 197.1993s\n",
      "\titers: 500, epoch: 6 | loss: 0.4055932\n",
      "\tspeed: 0.0478s/iter; left time: 192.2443s\n",
      "\titers: 600, epoch: 6 | loss: 0.4090059\n",
      "\tspeed: 0.0478s/iter; left time: 187.4235s\n",
      "\titers: 700, epoch: 6 | loss: 0.4191148\n",
      "\tspeed: 0.0478s/iter; left time: 182.5147s\n",
      "\titers: 800, epoch: 6 | loss: 0.3827613\n",
      "\tspeed: 0.0478s/iter; left time: 177.7755s\n",
      "\titers: 900, epoch: 6 | loss: 0.3823107\n",
      "\tspeed: 0.0477s/iter; left time: 172.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.48s\n",
      "Steps: 904 | Train Loss: 0.4065567 Vali Loss: 0.6270532 Test Loss: 0.7241490\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3648003\n",
      "\tspeed: 0.1148s/iter; left time: 403.9242s\n",
      "\titers: 200, epoch: 7 | loss: 0.3671430\n",
      "\tspeed: 0.0485s/iter; left time: 165.5728s\n",
      "\titers: 300, epoch: 7 | loss: 0.3830301\n",
      "\tspeed: 0.0485s/iter; left time: 160.9143s\n",
      "\titers: 400, epoch: 7 | loss: 0.3641279\n",
      "\tspeed: 0.0485s/iter; left time: 156.0000s\n",
      "\titers: 500, epoch: 7 | loss: 0.3655484\n",
      "\tspeed: 0.0483s/iter; left time: 150.4750s\n",
      "\titers: 600, epoch: 7 | loss: 0.4013045\n",
      "\tspeed: 0.0485s/iter; left time: 146.3175s\n",
      "\titers: 700, epoch: 7 | loss: 0.3788806\n",
      "\tspeed: 0.0485s/iter; left time: 141.4226s\n",
      "\titers: 800, epoch: 7 | loss: 0.3975182\n",
      "\tspeed: 0.0485s/iter; left time: 136.6902s\n",
      "\titers: 900, epoch: 7 | loss: 0.3585406\n",
      "\tspeed: 0.0484s/iter; left time: 131.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.03s\n",
      "Steps: 904 | Train Loss: 0.3769450 Vali Loss: 0.6411112 Test Loss: 0.7439349\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3620191\n",
      "\tspeed: 0.1146s/iter; left time: 299.3725s\n",
      "\titers: 200, epoch: 8 | loss: 0.3261688\n",
      "\tspeed: 0.0493s/iter; left time: 123.8223s\n",
      "\titers: 300, epoch: 8 | loss: 0.3479829\n",
      "\tspeed: 0.0506s/iter; left time: 121.9818s\n",
      "\titers: 400, epoch: 8 | loss: 0.3641526\n",
      "\tspeed: 0.0505s/iter; left time: 116.8587s\n",
      "\titers: 500, epoch: 8 | loss: 0.3393639\n",
      "\tspeed: 0.0504s/iter; left time: 111.6277s\n",
      "\titers: 600, epoch: 8 | loss: 0.3139465\n",
      "\tspeed: 0.0502s/iter; left time: 106.1751s\n",
      "\titers: 700, epoch: 8 | loss: 0.3470483\n",
      "\tspeed: 0.0503s/iter; left time: 101.3074s\n",
      "\titers: 800, epoch: 8 | loss: 0.3374607\n",
      "\tspeed: 0.0505s/iter; left time: 96.6642s\n",
      "\titers: 900, epoch: 8 | loss: 0.3540194\n",
      "\tspeed: 0.0506s/iter; left time: 91.7958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.52s\n",
      "Steps: 904 | Train Loss: 0.3511952 Vali Loss: 0.6427029 Test Loss: 0.7460396\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0730987787246704, rmse:1.0359047651290894, mae:0.7072945237159729, rse:0.7336698174476624\n",
      "Original data scale mse:40022552.0, rmse:6326.337890625, mae:4028.88720703125, rse:0.31505391001701355\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8846306\n",
      "\tspeed: 0.0836s/iter; left time: 745.6361s\n",
      "\titers: 200, epoch: 1 | loss: 0.8518029\n",
      "\tspeed: 0.0545s/iter; left time: 480.8195s\n",
      "\titers: 300, epoch: 1 | loss: 0.7927679\n",
      "\tspeed: 0.0538s/iter; left time: 469.5779s\n",
      "\titers: 400, epoch: 1 | loss: 0.7959605\n",
      "\tspeed: 0.0537s/iter; left time: 462.6265s\n",
      "\titers: 500, epoch: 1 | loss: 0.7779122\n",
      "\tspeed: 0.0537s/iter; left time: 457.6177s\n",
      "\titers: 600, epoch: 1 | loss: 0.8002670\n",
      "\tspeed: 0.0536s/iter; left time: 451.6359s\n",
      "\titers: 700, epoch: 1 | loss: 0.7668347\n",
      "\tspeed: 0.0538s/iter; left time: 447.9882s\n",
      "\titers: 800, epoch: 1 | loss: 0.7417139\n",
      "\tspeed: 0.0543s/iter; left time: 446.4593s\n",
      "\titers: 900, epoch: 1 | loss: 0.7623810\n",
      "\tspeed: 0.0543s/iter; left time: 441.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.50s\n",
      "Steps: 902 | Train Loss: 0.8235997 Vali Loss: 0.8645070 Test Loss: 0.9771948\n",
      "Validation loss decreased (inf --> 0.864507).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7357517\n",
      "\tspeed: 0.1367s/iter; left time: 1096.0268s\n",
      "\titers: 200, epoch: 2 | loss: 0.6775665\n",
      "\tspeed: 0.0538s/iter; left time: 426.3827s\n",
      "\titers: 300, epoch: 2 | loss: 0.6941202\n",
      "\tspeed: 0.0537s/iter; left time: 420.2104s\n",
      "\titers: 400, epoch: 2 | loss: 0.6182607\n",
      "\tspeed: 0.0540s/iter; left time: 416.5561s\n",
      "\titers: 500, epoch: 2 | loss: 0.5892654\n",
      "\tspeed: 0.0540s/iter; left time: 411.0894s\n",
      "\titers: 600, epoch: 2 | loss: 0.5567015\n",
      "\tspeed: 0.0544s/iter; left time: 409.3908s\n",
      "\titers: 700, epoch: 2 | loss: 0.5462503\n",
      "\tspeed: 0.0545s/iter; left time: 404.3972s\n",
      "\titers: 800, epoch: 2 | loss: 0.5940535\n",
      "\tspeed: 0.0544s/iter; left time: 398.0019s\n",
      "\titers: 900, epoch: 2 | loss: 0.5299127\n",
      "\tspeed: 0.0544s/iter; left time: 392.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.15s\n",
      "Steps: 902 | Train Loss: 0.6147895 Vali Loss: 0.6469601 Test Loss: 0.7199959\n",
      "Validation loss decreased (0.864507 --> 0.646960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5862113\n",
      "\tspeed: 0.1352s/iter; left time: 962.3206s\n",
      "\titers: 200, epoch: 3 | loss: 0.5205126\n",
      "\tspeed: 0.0540s/iter; left time: 378.6930s\n",
      "\titers: 300, epoch: 3 | loss: 0.5347909\n",
      "\tspeed: 0.0537s/iter; left time: 371.5925s\n",
      "\titers: 400, epoch: 3 | loss: 0.5657836\n",
      "\tspeed: 0.0537s/iter; left time: 365.8643s\n",
      "\titers: 500, epoch: 3 | loss: 0.5331751\n",
      "\tspeed: 0.0537s/iter; left time: 360.8464s\n",
      "\titers: 600, epoch: 3 | loss: 0.5299889\n",
      "\tspeed: 0.0534s/iter; left time: 353.4404s\n",
      "\titers: 700, epoch: 3 | loss: 0.5363218\n",
      "\tspeed: 0.0536s/iter; left time: 349.2349s\n",
      "\titers: 800, epoch: 3 | loss: 0.5176891\n",
      "\tspeed: 0.0537s/iter; left time: 344.7848s\n",
      "\titers: 900, epoch: 3 | loss: 0.5101404\n",
      "\tspeed: 0.0537s/iter; left time: 339.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.5243541 Vali Loss: 0.6358743 Test Loss: 0.7098188\n",
      "Validation loss decreased (0.646960 --> 0.635874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4579452\n",
      "\tspeed: 0.1354s/iter; left time: 841.7172s\n",
      "\titers: 200, epoch: 4 | loss: 0.4581067\n",
      "\tspeed: 0.0539s/iter; left time: 329.4988s\n",
      "\titers: 300, epoch: 4 | loss: 0.5066717\n",
      "\tspeed: 0.0536s/iter; left time: 322.6011s\n",
      "\titers: 400, epoch: 4 | loss: 0.4910929\n",
      "\tspeed: 0.0539s/iter; left time: 318.5869s\n",
      "\titers: 500, epoch: 4 | loss: 0.5026969\n",
      "\tspeed: 0.0535s/iter; left time: 311.3476s\n",
      "\titers: 600, epoch: 4 | loss: 0.4575081\n",
      "\tspeed: 0.0537s/iter; left time: 307.1207s\n",
      "\titers: 700, epoch: 4 | loss: 0.4831530\n",
      "\tspeed: 0.0537s/iter; left time: 301.3811s\n",
      "\titers: 800, epoch: 4 | loss: 0.4855972\n",
      "\tspeed: 0.0530s/iter; left time: 292.4295s\n",
      "\titers: 900, epoch: 4 | loss: 0.4564104\n",
      "\tspeed: 0.0537s/iter; left time: 290.7755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.4847265 Vali Loss: 0.6346475 Test Loss: 0.7316934\n",
      "Validation loss decreased (0.635874 --> 0.634647).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4837843\n",
      "\tspeed: 0.1362s/iter; left time: 723.8588s\n",
      "\titers: 200, epoch: 5 | loss: 0.4691080\n",
      "\tspeed: 0.0539s/iter; left time: 280.8369s\n",
      "\titers: 300, epoch: 5 | loss: 0.4528074\n",
      "\tspeed: 0.0538s/iter; left time: 275.0256s\n",
      "\titers: 400, epoch: 5 | loss: 0.4738817\n",
      "\tspeed: 0.0537s/iter; left time: 269.4014s\n",
      "\titers: 500, epoch: 5 | loss: 0.3760054\n",
      "\tspeed: 0.0538s/iter; left time: 264.1444s\n",
      "\titers: 600, epoch: 5 | loss: 0.4394573\n",
      "\tspeed: 0.0538s/iter; left time: 259.0220s\n",
      "\titers: 700, epoch: 5 | loss: 0.4445860\n",
      "\tspeed: 0.0536s/iter; left time: 252.6848s\n",
      "\titers: 800, epoch: 5 | loss: 0.4306514\n",
      "\tspeed: 0.0537s/iter; left time: 247.8864s\n",
      "\titers: 900, epoch: 5 | loss: 0.4049932\n",
      "\tspeed: 0.0537s/iter; left time: 242.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.4419550 Vali Loss: 0.6558889 Test Loss: 0.7420041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4142314\n",
      "\tspeed: 0.1323s/iter; left time: 583.3838s\n",
      "\titers: 200, epoch: 6 | loss: 0.4261995\n",
      "\tspeed: 0.0537s/iter; left time: 231.5660s\n",
      "\titers: 300, epoch: 6 | loss: 0.3990280\n",
      "\tspeed: 0.0538s/iter; left time: 226.6467s\n",
      "\titers: 400, epoch: 6 | loss: 0.4382677\n",
      "\tspeed: 0.0535s/iter; left time: 220.1282s\n",
      "\titers: 500, epoch: 6 | loss: 0.3904198\n",
      "\tspeed: 0.0538s/iter; left time: 215.7405s\n",
      "\titers: 600, epoch: 6 | loss: 0.3950638\n",
      "\tspeed: 0.0537s/iter; left time: 210.1266s\n",
      "\titers: 700, epoch: 6 | loss: 0.4117355\n",
      "\tspeed: 0.0536s/iter; left time: 204.3564s\n",
      "\titers: 800, epoch: 6 | loss: 0.3758099\n",
      "\tspeed: 0.0534s/iter; left time: 197.9931s\n",
      "\titers: 900, epoch: 6 | loss: 0.4197530\n",
      "\tspeed: 0.0536s/iter; left time: 193.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.4047420 Vali Loss: 0.6660158 Test Loss: 0.7500989\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3597244\n",
      "\tspeed: 0.1324s/iter; left time: 464.7261s\n",
      "\titers: 200, epoch: 7 | loss: 0.3653745\n",
      "\tspeed: 0.0539s/iter; left time: 183.6257s\n",
      "\titers: 300, epoch: 7 | loss: 0.3912660\n",
      "\tspeed: 0.0539s/iter; left time: 178.4348s\n",
      "\titers: 400, epoch: 7 | loss: 0.3771539\n",
      "\tspeed: 0.0539s/iter; left time: 172.9128s\n",
      "\titers: 500, epoch: 7 | loss: 0.3489423\n",
      "\tspeed: 0.0539s/iter; left time: 167.4515s\n",
      "\titers: 600, epoch: 7 | loss: 0.3654443\n",
      "\tspeed: 0.0539s/iter; left time: 162.1581s\n",
      "\titers: 700, epoch: 7 | loss: 0.3621597\n",
      "\tspeed: 0.0538s/iter; left time: 156.5695s\n",
      "\titers: 800, epoch: 7 | loss: 0.3509176\n",
      "\tspeed: 0.0536s/iter; left time: 150.6940s\n",
      "\titers: 900, epoch: 7 | loss: 0.3679426\n",
      "\tspeed: 0.0537s/iter; left time: 145.5705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.3748105 Vali Loss: 0.6631452 Test Loss: 0.7585071\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.1462680101394653, rmse:1.0706390142440796, mae:0.7319367527961731, rse:0.7585904002189636\n",
      "Original data scale mse:43425884.0, rmse:6589.83203125, mae:4181.650390625, rse:0.3283371031284332\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9820722\n",
      "\tspeed: 0.0560s/iter; left time: 499.6053s\n",
      "\titers: 200, epoch: 1 | loss: 0.8091466\n",
      "\tspeed: 0.0540s/iter; left time: 476.0204s\n",
      "\titers: 300, epoch: 1 | loss: 0.7912192\n",
      "\tspeed: 0.0538s/iter; left time: 469.2853s\n",
      "\titers: 400, epoch: 1 | loss: 0.7516202\n",
      "\tspeed: 0.0538s/iter; left time: 464.0372s\n",
      "\titers: 500, epoch: 1 | loss: 0.7821637\n",
      "\tspeed: 0.0536s/iter; left time: 456.4231s\n",
      "\titers: 600, epoch: 1 | loss: 0.7884973\n",
      "\tspeed: 0.0537s/iter; left time: 451.8126s\n",
      "\titers: 700, epoch: 1 | loss: 0.7586529\n",
      "\tspeed: 0.0536s/iter; left time: 446.3660s\n",
      "\titers: 800, epoch: 1 | loss: 0.7272879\n",
      "\tspeed: 0.0536s/iter; left time: 440.2650s\n",
      "\titers: 900, epoch: 1 | loss: 0.7413532\n",
      "\tspeed: 0.0536s/iter; left time: 435.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.8373404 Vali Loss: 0.8698030 Test Loss: 0.9833975\n",
      "Validation loss decreased (inf --> 0.869803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6709264\n",
      "\tspeed: 0.1370s/iter; left time: 1098.5080s\n",
      "\titers: 200, epoch: 2 | loss: 0.7037471\n",
      "\tspeed: 0.0535s/iter; left time: 423.4407s\n",
      "\titers: 300, epoch: 2 | loss: 0.6900402\n",
      "\tspeed: 0.0536s/iter; left time: 418.9238s\n",
      "\titers: 400, epoch: 2 | loss: 0.6219226\n",
      "\tspeed: 0.0535s/iter; left time: 412.6066s\n",
      "\titers: 500, epoch: 2 | loss: 0.6176269\n",
      "\tspeed: 0.0536s/iter; left time: 408.0891s\n",
      "\titers: 600, epoch: 2 | loss: 0.5839619\n",
      "\tspeed: 0.0536s/iter; left time: 402.8298s\n",
      "\titers: 700, epoch: 2 | loss: 0.5815917\n",
      "\tspeed: 0.0537s/iter; left time: 398.2430s\n",
      "\titers: 800, epoch: 2 | loss: 0.5410003\n",
      "\tspeed: 0.0538s/iter; left time: 393.4817s\n",
      "\titers: 900, epoch: 2 | loss: 0.5676069\n",
      "\tspeed: 0.0536s/iter; left time: 387.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.6209445 Vali Loss: 0.6708670 Test Loss: 0.7410677\n",
      "Validation loss decreased (0.869803 --> 0.670867).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5300220\n",
      "\tspeed: 0.1398s/iter; left time: 995.2328s\n",
      "\titers: 200, epoch: 3 | loss: 0.5099648\n",
      "\tspeed: 0.0537s/iter; left time: 376.7374s\n",
      "\titers: 300, epoch: 3 | loss: 0.5191158\n",
      "\tspeed: 0.0539s/iter; left time: 373.1428s\n",
      "\titers: 400, epoch: 3 | loss: 0.5015079\n",
      "\tspeed: 0.0537s/iter; left time: 365.7992s\n",
      "\titers: 500, epoch: 3 | loss: 0.5269877\n",
      "\tspeed: 0.0537s/iter; left time: 360.6129s\n",
      "\titers: 600, epoch: 3 | loss: 0.5647386\n",
      "\tspeed: 0.0538s/iter; left time: 355.6739s\n",
      "\titers: 700, epoch: 3 | loss: 0.4793418\n",
      "\tspeed: 0.0537s/iter; left time: 350.2547s\n",
      "\titers: 800, epoch: 3 | loss: 0.5591546\n",
      "\tspeed: 0.0537s/iter; left time: 344.6441s\n",
      "\titers: 900, epoch: 3 | loss: 0.4998805\n",
      "\tspeed: 0.0537s/iter; left time: 339.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.5267572 Vali Loss: 0.6456291 Test Loss: 0.7023995\n",
      "Validation loss decreased (0.670867 --> 0.645629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4390603\n",
      "\tspeed: 0.1382s/iter; left time: 859.0928s\n",
      "\titers: 200, epoch: 4 | loss: 0.4913748\n",
      "\tspeed: 0.0537s/iter; left time: 328.5999s\n",
      "\titers: 300, epoch: 4 | loss: 0.5024523\n",
      "\tspeed: 0.0538s/iter; left time: 323.4056s\n",
      "\titers: 400, epoch: 4 | loss: 0.5081977\n",
      "\tspeed: 0.0538s/iter; left time: 318.2908s\n",
      "\titers: 500, epoch: 4 | loss: 0.5454877\n",
      "\tspeed: 0.0538s/iter; left time: 312.5616s\n",
      "\titers: 600, epoch: 4 | loss: 0.4477499\n",
      "\tspeed: 0.0539s/iter; left time: 307.8456s\n",
      "\titers: 700, epoch: 4 | loss: 0.4986390\n",
      "\tspeed: 0.0536s/iter; left time: 301.1258s\n",
      "\titers: 800, epoch: 4 | loss: 0.4580439\n",
      "\tspeed: 0.0537s/iter; left time: 296.1315s\n",
      "\titers: 900, epoch: 4 | loss: 0.4907460\n",
      "\tspeed: 0.0539s/iter; left time: 291.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.4871874 Vali Loss: 0.6488603 Test Loss: 0.7241992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4679678\n",
      "\tspeed: 0.1213s/iter; left time: 644.4786s\n",
      "\titers: 200, epoch: 5 | loss: 0.4386187\n",
      "\tspeed: 0.0428s/iter; left time: 223.1648s\n",
      "\titers: 300, epoch: 5 | loss: 0.4504304\n",
      "\tspeed: 0.0518s/iter; left time: 264.9765s\n",
      "\titers: 400, epoch: 5 | loss: 0.4288036\n",
      "\tspeed: 0.0538s/iter; left time: 269.7555s\n",
      "\titers: 500, epoch: 5 | loss: 0.4115148\n",
      "\tspeed: 0.0538s/iter; left time: 264.2112s\n",
      "\titers: 600, epoch: 5 | loss: 0.4677192\n",
      "\tspeed: 0.0540s/iter; left time: 259.6649s\n",
      "\titers: 700, epoch: 5 | loss: 0.4463263\n",
      "\tspeed: 0.0537s/iter; left time: 253.2022s\n",
      "\titers: 800, epoch: 5 | loss: 0.3936732\n",
      "\tspeed: 0.0538s/iter; left time: 247.9550s\n",
      "\titers: 900, epoch: 5 | loss: 0.4100214\n",
      "\tspeed: 0.0537s/iter; left time: 242.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.43s\n",
      "Steps: 902 | Train Loss: 0.4442705 Vali Loss: 0.6636744 Test Loss: 0.7509598\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4347021\n",
      "\tspeed: 0.1320s/iter; left time: 582.4708s\n",
      "\titers: 200, epoch: 6 | loss: 0.4301532\n",
      "\tspeed: 0.0539s/iter; left time: 232.2086s\n",
      "\titers: 300, epoch: 6 | loss: 0.4260470\n",
      "\tspeed: 0.0539s/iter; left time: 227.0619s\n",
      "\titers: 400, epoch: 6 | loss: 0.3970055\n",
      "\tspeed: 0.0538s/iter; left time: 221.3725s\n",
      "\titers: 500, epoch: 6 | loss: 0.3567777\n",
      "\tspeed: 0.0539s/iter; left time: 216.2202s\n",
      "\titers: 600, epoch: 6 | loss: 0.4205867\n",
      "\tspeed: 0.0537s/iter; left time: 209.8971s\n",
      "\titers: 700, epoch: 6 | loss: 0.3984048\n",
      "\tspeed: 0.0538s/iter; left time: 204.9991s\n",
      "\titers: 800, epoch: 6 | loss: 0.4369097\n",
      "\tspeed: 0.0538s/iter; left time: 199.4860s\n",
      "\titers: 900, epoch: 6 | loss: 0.4066767\n",
      "\tspeed: 0.0537s/iter; left time: 193.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.4066603 Vali Loss: 0.6555923 Test Loss: 0.7415594\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0771197080612183, rmse:1.0378438234329224, mae:0.702481746673584, rse:0.7353537082672119\n",
      "Original data scale mse:38044424.0, rmse:6168.01611328125, mae:3964.067138671875, rse:0.30732017755508423\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5821</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.5389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5617</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>0.6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0202</td>\n",
       "      <td>1.0101</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0452</td>\n",
       "      <td>1.0224</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.7244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0489</td>\n",
       "      <td>1.0241</td>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>0.5253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0342</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.7202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0389</td>\n",
       "      <td>1.0192</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.1415</td>\n",
       "      <td>1.0684</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.5689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>1.1340</td>\n",
       "      <td>1.0649</td>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.7542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0731</td>\n",
       "      <td>1.0359</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.7337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.1463</td>\n",
       "      <td>1.0706</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0771</td>\n",
       "      <td>1.0378</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.7354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5821  0.7630  0.5073  0.5389\n",
       "              2         24        0.5617  0.7495  0.5070  0.5294\n",
       "              1         96        0.9754  0.9876  0.7069  0.6995\n",
       "              2         96        1.0202  1.0101  0.7201  0.7154\n",
       "              1         168       1.0452  1.0224  0.7262  0.7244\n",
       "              2         168       1.0489  1.0241  0.7294  0.7257\n",
       "RMSE          1         24        0.5837  0.7640  0.5080  0.5396\n",
       "              2         24        0.5531  0.7437  0.5012  0.5253\n",
       "              1         96        0.9790  0.9894  0.7047  0.7008\n",
       "              2         96        1.0342  1.0170  0.7238  0.7202\n",
       "              1         168       1.0389  1.0192  0.7245  0.7222\n",
       "              2         168       1.1415  1.0684  0.7632  0.7570\n",
       "MAE           1         24        0.6487  0.8054  0.5156  0.5689\n",
       "              2         24        0.5677  0.7535  0.4944  0.5322\n",
       "              1         96        1.1340  1.0649  0.7311  0.7542\n",
       "              2         96        1.0731  1.0359  0.7073  0.7337\n",
       "              1         168       1.1463  1.0706  0.7319  0.7586\n",
       "              2         168       1.0771  1.0378  0.7025  0.7354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19813680.0</td>\n",
       "      <td>4451.2559</td>\n",
       "      <td>2843.8379</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18792862.0</td>\n",
       "      <td>4335.0732</td>\n",
       "      <td>2853.9487</td>\n",
       "      <td>0.2155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35925668.0</td>\n",
       "      <td>5993.8022</td>\n",
       "      <td>4037.1482</td>\n",
       "      <td>0.2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38556932.0</td>\n",
       "      <td>6209.4229</td>\n",
       "      <td>4125.3677</td>\n",
       "      <td>0.3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38648844.0</td>\n",
       "      <td>6216.8193</td>\n",
       "      <td>4132.9209</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39350824.0</td>\n",
       "      <td>6273.0234</td>\n",
       "      <td>4192.4600</td>\n",
       "      <td>0.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20211562.0</td>\n",
       "      <td>4495.7271</td>\n",
       "      <td>2858.9175</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18355966.0</td>\n",
       "      <td>4284.3862</td>\n",
       "      <td>2809.9756</td>\n",
       "      <td>0.2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35732984.0</td>\n",
       "      <td>5977.7070</td>\n",
       "      <td>4005.1499</td>\n",
       "      <td>0.2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>40138628.0</td>\n",
       "      <td>6335.5054</td>\n",
       "      <td>4191.2891</td>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38251312.0</td>\n",
       "      <td>6184.7646</td>\n",
       "      <td>4112.1064</td>\n",
       "      <td>0.3082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>43871052.0</td>\n",
       "      <td>6623.5225</td>\n",
       "      <td>4414.6226</td>\n",
       "      <td>0.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>22829454.0</td>\n",
       "      <td>4778.0176</td>\n",
       "      <td>2917.6660</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19457170.0</td>\n",
       "      <td>4411.0283</td>\n",
       "      <td>2774.2051</td>\n",
       "      <td>0.2193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>42587312.0</td>\n",
       "      <td>6525.8955</td>\n",
       "      <td>4191.6289</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>40022552.0</td>\n",
       "      <td>6326.3379</td>\n",
       "      <td>4028.8872</td>\n",
       "      <td>0.3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>43425884.0</td>\n",
       "      <td>6589.8320</td>\n",
       "      <td>4181.6504</td>\n",
       "      <td>0.3283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38044424.0</td>\n",
       "      <td>6168.0161</td>\n",
       "      <td>3964.0671</td>\n",
       "      <td>0.3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        19813680.0  4451.2559  2843.8379  0.2213\n",
       "              2         24        18792862.0  4335.0732  2853.9487  0.2155\n",
       "              1         96        35925668.0  5993.8022  4037.1482  0.2985\n",
       "              2         96        38556932.0  6209.4229  4125.3677  0.3092\n",
       "              1         168       38648844.0  6216.8193  4132.9209  0.3098\n",
       "              2         168       39350824.0  6273.0234  4192.4600  0.3126\n",
       "RMSE          1         24        20211562.0  4495.7271  2858.9175  0.2235\n",
       "              2         24        18355966.0  4284.3862  2809.9756  0.2130\n",
       "              1         96        35732984.0  5977.7070  4005.1499  0.2977\n",
       "              2         96        40138628.0  6335.5054  4191.2891  0.3155\n",
       "              1         168       38251312.0  6184.7646  4112.1064  0.3082\n",
       "              2         168       43871052.0  6623.5225  4414.6226  0.3300\n",
       "MAE           1         24        22829454.0  4778.0176  2917.6660  0.2376\n",
       "              2         24        19457170.0  4411.0283  2774.2051  0.2193\n",
       "              1         96        42587312.0  6525.8955  4191.6289  0.3250\n",
       "              2         96        40022552.0  6326.3379  4028.8872  0.3151\n",
       "              1         168       43425884.0  6589.8320  4181.6504  0.3283\n",
       "              2         168       38044424.0  6168.0161  3964.0671  0.3073"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.5505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.5324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.1036</td>\n",
       "      <td>1.0504</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.7439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.7074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.0066</td>\n",
       "      <td>1.0032</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.1117</td>\n",
       "      <td>1.0542</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.7470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.0471</td>\n",
       "      <td>1.0233</td>\n",
       "      <td>0.7278</td>\n",
       "      <td>0.7250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.0902</td>\n",
       "      <td>1.0438</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.7396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.6082  0.7795  0.5050  0.5505\n",
       "         MSE            0.5719  0.7562  0.5071  0.5341\n",
       "         RMSE           0.5684  0.7538  0.5046  0.5324\n",
       "96       MAE            1.1036  1.0504  0.7192  0.7439\n",
       "         MSE            0.9978  0.9988  0.7135  0.7074\n",
       "         RMSE           1.0066  1.0032  0.7143  0.7105\n",
       "168      MAE            1.1117  1.0542  0.7172  0.7470\n",
       "         MSE            1.0471  1.0233  0.7278  0.7250\n",
       "         RMSE           1.0902  1.0438  0.7438  0.7396"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>21143312.0</td>\n",
       "      <td>4594.5229</td>\n",
       "      <td>2845.9355</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19303271.0</td>\n",
       "      <td>4393.1646</td>\n",
       "      <td>2848.8933</td>\n",
       "      <td>0.2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19283764.0</td>\n",
       "      <td>4390.0566</td>\n",
       "      <td>2834.4465</td>\n",
       "      <td>0.2183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>41304932.0</td>\n",
       "      <td>6426.1167</td>\n",
       "      <td>4110.2581</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37241300.0</td>\n",
       "      <td>6101.6125</td>\n",
       "      <td>4081.2579</td>\n",
       "      <td>0.3039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37935806.0</td>\n",
       "      <td>6156.6062</td>\n",
       "      <td>4098.2195</td>\n",
       "      <td>0.3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40735154.0</td>\n",
       "      <td>6378.9241</td>\n",
       "      <td>4072.8588</td>\n",
       "      <td>0.3178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38999834.0</td>\n",
       "      <td>6244.9214</td>\n",
       "      <td>4162.6904</td>\n",
       "      <td>0.3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>41061182.0</td>\n",
       "      <td>6404.1436</td>\n",
       "      <td>4263.3645</td>\n",
       "      <td>0.3191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            21143312.0  4594.5229  2845.9355  0.2284\n",
       "         MSE            19303271.0  4393.1646  2848.8933  0.2184\n",
       "         RMSE           19283764.0  4390.0566  2834.4465  0.2183\n",
       "96       MAE            41304932.0  6426.1167  4110.2581  0.3200\n",
       "         MSE            37241300.0  6101.6125  4081.2579  0.3039\n",
       "         RMSE           37935806.0  6156.6062  4098.2195  0.3066\n",
       "168      MAE            40735154.0  6378.9241  4072.8588  0.3178\n",
       "         MSE            38999834.0  6244.9214  4162.6904  0.3112\n",
       "         RMSE           41061182.0  6404.1436  4263.3645  0.3191"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MinMax Scaler (0, 5) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4656270\n",
      "\tspeed: 0.0680s/iter; left time: 600.2860s\n",
      "\titers: 200, epoch: 1 | loss: 0.5110030\n",
      "\tspeed: 0.0423s/iter; left time: 369.5231s\n",
      "\titers: 300, epoch: 1 | loss: 0.3971398\n",
      "\tspeed: 0.0423s/iter; left time: 365.1950s\n",
      "\titers: 400, epoch: 1 | loss: 0.4724059\n",
      "\tspeed: 0.0423s/iter; left time: 361.0856s\n",
      "\titers: 500, epoch: 1 | loss: 0.4296758\n",
      "\tspeed: 0.0424s/iter; left time: 357.1115s\n",
      "\titers: 600, epoch: 1 | loss: 0.5103601\n",
      "\tspeed: 0.0424s/iter; left time: 353.4812s\n",
      "\titers: 700, epoch: 1 | loss: 0.4004532\n",
      "\tspeed: 0.0425s/iter; left time: 349.6438s\n",
      "\titers: 800, epoch: 1 | loss: 0.3859911\n",
      "\tspeed: 0.0424s/iter; left time: 344.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 893 | Train Loss: 0.4309311 Vali Loss: 0.5197790 Test Loss: 0.5612504\n",
      "Validation loss decreased (inf --> 0.519779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4673970\n",
      "\tspeed: 0.1684s/iter; left time: 1337.0103s\n",
      "\titers: 200, epoch: 2 | loss: 0.4356568\n",
      "\tspeed: 0.0423s/iter; left time: 331.7119s\n",
      "\titers: 300, epoch: 2 | loss: 0.3171702\n",
      "\tspeed: 0.0423s/iter; left time: 327.3750s\n",
      "\titers: 400, epoch: 2 | loss: 0.3395650\n",
      "\tspeed: 0.0423s/iter; left time: 323.0549s\n",
      "\titers: 500, epoch: 2 | loss: 0.3131536\n",
      "\tspeed: 0.0424s/iter; left time: 319.9852s\n",
      "\titers: 600, epoch: 2 | loss: 0.3246500\n",
      "\tspeed: 0.0424s/iter; left time: 315.6517s\n",
      "\titers: 700, epoch: 2 | loss: 0.4090817\n",
      "\tspeed: 0.0425s/iter; left time: 311.8041s\n",
      "\titers: 800, epoch: 2 | loss: 0.2851637\n",
      "\tspeed: 0.0424s/iter; left time: 307.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3515757 Vali Loss: 0.4965481 Test Loss: 0.5603388\n",
      "Validation loss decreased (0.519779 --> 0.496548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2174761\n",
      "\tspeed: 0.1554s/iter; left time: 1094.8972s\n",
      "\titers: 200, epoch: 3 | loss: 0.3121274\n",
      "\tspeed: 0.0424s/iter; left time: 294.2245s\n",
      "\titers: 300, epoch: 3 | loss: 0.2684462\n",
      "\tspeed: 0.0423s/iter; left time: 289.8282s\n",
      "\titers: 400, epoch: 3 | loss: 0.2812676\n",
      "\tspeed: 0.0423s/iter; left time: 285.3022s\n",
      "\titers: 500, epoch: 3 | loss: 0.2635065\n",
      "\tspeed: 0.0423s/iter; left time: 281.3313s\n",
      "\titers: 600, epoch: 3 | loss: 0.3215250\n",
      "\tspeed: 0.0423s/iter; left time: 277.0803s\n",
      "\titers: 700, epoch: 3 | loss: 0.2103586\n",
      "\tspeed: 0.0424s/iter; left time: 273.1495s\n",
      "\titers: 800, epoch: 3 | loss: 0.3945894\n",
      "\tspeed: 0.0424s/iter; left time: 269.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3141996 Vali Loss: 0.4829666 Test Loss: 0.5359982\n",
      "Validation loss decreased (0.496548 --> 0.482967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2828036\n",
      "\tspeed: 0.1545s/iter; left time: 950.7245s\n",
      "\titers: 200, epoch: 4 | loss: 0.2767180\n",
      "\tspeed: 0.0423s/iter; left time: 255.9525s\n",
      "\titers: 300, epoch: 4 | loss: 0.2992713\n",
      "\tspeed: 0.0423s/iter; left time: 251.5505s\n",
      "\titers: 400, epoch: 4 | loss: 0.2384365\n",
      "\tspeed: 0.0423s/iter; left time: 247.4506s\n",
      "\titers: 500, epoch: 4 | loss: 0.4255137\n",
      "\tspeed: 0.0423s/iter; left time: 243.1893s\n",
      "\titers: 600, epoch: 4 | loss: 0.2825825\n",
      "\tspeed: 0.0423s/iter; left time: 239.2157s\n",
      "\titers: 700, epoch: 4 | loss: 0.2804815\n",
      "\tspeed: 0.0423s/iter; left time: 234.7915s\n",
      "\titers: 800, epoch: 4 | loss: 0.3347242\n",
      "\tspeed: 0.0423s/iter; left time: 230.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2990380 Vali Loss: 0.5123403 Test Loss: 0.5688564\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2691970\n",
      "\tspeed: 0.1517s/iter; left time: 797.8017s\n",
      "\titers: 200, epoch: 5 | loss: 0.1995186\n",
      "\tspeed: 0.0423s/iter; left time: 218.3784s\n",
      "\titers: 300, epoch: 5 | loss: 0.2896351\n",
      "\tspeed: 0.0423s/iter; left time: 214.1028s\n",
      "\titers: 400, epoch: 5 | loss: 0.2515764\n",
      "\tspeed: 0.0423s/iter; left time: 209.9088s\n",
      "\titers: 500, epoch: 5 | loss: 0.2692604\n",
      "\tspeed: 0.0423s/iter; left time: 205.5707s\n",
      "\titers: 600, epoch: 5 | loss: 0.2318180\n",
      "\tspeed: 0.0425s/iter; left time: 202.2676s\n",
      "\titers: 700, epoch: 5 | loss: 0.2501515\n",
      "\tspeed: 0.0425s/iter; left time: 198.1003s\n",
      "\titers: 800, epoch: 5 | loss: 0.2452033\n",
      "\tspeed: 0.0425s/iter; left time: 193.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2856611 Vali Loss: 0.5026611 Test Loss: 0.5593529\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2028114\n",
      "\tspeed: 0.2671s/iter; left time: 1166.1383s\n",
      "\titers: 200, epoch: 6 | loss: 0.3331312\n",
      "\tspeed: 0.0424s/iter; left time: 180.7570s\n",
      "\titers: 300, epoch: 6 | loss: 0.2206999\n",
      "\tspeed: 0.0423s/iter; left time: 176.2620s\n",
      "\titers: 400, epoch: 6 | loss: 0.2196445\n",
      "\tspeed: 0.0423s/iter; left time: 171.9285s\n",
      "\titers: 500, epoch: 6 | loss: 0.2342782\n",
      "\tspeed: 0.0423s/iter; left time: 167.7730s\n",
      "\titers: 600, epoch: 6 | loss: 0.2662649\n",
      "\tspeed: 0.0423s/iter; left time: 163.4648s\n",
      "\titers: 700, epoch: 6 | loss: 0.2196340\n",
      "\tspeed: 0.0423s/iter; left time: 159.2444s\n",
      "\titers: 800, epoch: 6 | loss: 0.2722157\n",
      "\tspeed: 0.0423s/iter; left time: 155.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 893 | Train Loss: 0.2669793 Vali Loss: 0.5280640 Test Loss: 0.5799114\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5359982252120972, rmse:0.7321190237998962, mae:0.4715895354747772, rse:0.5170996189117432\n",
      "Original data scale mse:17142486.0, rmse:4140.3486328125, mae:2565.93017578125, rse:0.2058664858341217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6037697\n",
      "\tspeed: 0.0441s/iter; left time: 389.3568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3771969\n",
      "\tspeed: 0.0423s/iter; left time: 369.6921s\n",
      "\titers: 300, epoch: 1 | loss: 0.3836134\n",
      "\tspeed: 0.0423s/iter; left time: 365.2813s\n",
      "\titers: 400, epoch: 1 | loss: 0.3438064\n",
      "\tspeed: 0.0423s/iter; left time: 361.1465s\n",
      "\titers: 500, epoch: 1 | loss: 0.4089257\n",
      "\tspeed: 0.0423s/iter; left time: 356.8538s\n",
      "\titers: 600, epoch: 1 | loss: 0.3950746\n",
      "\tspeed: 0.0423s/iter; left time: 352.5088s\n",
      "\titers: 700, epoch: 1 | loss: 0.4003910\n",
      "\tspeed: 0.0424s/iter; left time: 349.0812s\n",
      "\titers: 800, epoch: 1 | loss: 0.4363948\n",
      "\tspeed: 0.0425s/iter; left time: 345.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.4294658 Vali Loss: 0.5164565 Test Loss: 0.5625684\n",
      "Validation loss decreased (inf --> 0.516457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3819644\n",
      "\tspeed: 0.1556s/iter; left time: 1234.8753s\n",
      "\titers: 200, epoch: 2 | loss: 0.3901756\n",
      "\tspeed: 0.0423s/iter; left time: 331.7168s\n",
      "\titers: 300, epoch: 2 | loss: 0.3439750\n",
      "\tspeed: 0.0423s/iter; left time: 327.5122s\n",
      "\titers: 400, epoch: 2 | loss: 0.3466608\n",
      "\tspeed: 0.0423s/iter; left time: 323.2715s\n",
      "\titers: 500, epoch: 2 | loss: 0.2938568\n",
      "\tspeed: 0.0423s/iter; left time: 318.9609s\n",
      "\titers: 600, epoch: 2 | loss: 0.2978078\n",
      "\tspeed: 0.0423s/iter; left time: 314.9720s\n",
      "\titers: 700, epoch: 2 | loss: 0.2196671\n",
      "\tspeed: 0.0423s/iter; left time: 310.5481s\n",
      "\titers: 800, epoch: 2 | loss: 0.3304714\n",
      "\tspeed: 0.0423s/iter; left time: 306.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3487419 Vali Loss: 0.4804365 Test Loss: 0.5332819\n",
      "Validation loss decreased (0.516457 --> 0.480437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2389299\n",
      "\tspeed: 0.1544s/iter; left time: 1087.7267s\n",
      "\titers: 200, epoch: 3 | loss: 0.2873178\n",
      "\tspeed: 0.0423s/iter; left time: 293.8482s\n",
      "\titers: 300, epoch: 3 | loss: 0.2713190\n",
      "\tspeed: 0.0423s/iter; left time: 289.8681s\n",
      "\titers: 400, epoch: 3 | loss: 0.2747884\n",
      "\tspeed: 0.0423s/iter; left time: 285.4832s\n",
      "\titers: 500, epoch: 3 | loss: 0.3144275\n",
      "\tspeed: 0.0423s/iter; left time: 281.2543s\n",
      "\titers: 600, epoch: 3 | loss: 0.3013924\n",
      "\tspeed: 0.0424s/iter; left time: 277.1899s\n",
      "\titers: 700, epoch: 3 | loss: 0.2300563\n",
      "\tspeed: 0.0424s/iter; left time: 273.0034s\n",
      "\titers: 800, epoch: 3 | loss: 0.2656597\n",
      "\tspeed: 0.0424s/iter; left time: 268.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3137160 Vali Loss: 0.4867498 Test Loss: 0.5305008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3111697\n",
      "\tspeed: 0.1537s/iter; left time: 945.7710s\n",
      "\titers: 200, epoch: 4 | loss: 0.2462101\n",
      "\tspeed: 0.0425s/iter; left time: 257.2291s\n",
      "\titers: 300, epoch: 4 | loss: 0.2547868\n",
      "\tspeed: 0.0425s/iter; left time: 252.8192s\n",
      "\titers: 400, epoch: 4 | loss: 0.3583602\n",
      "\tspeed: 0.0424s/iter; left time: 248.2358s\n",
      "\titers: 500, epoch: 4 | loss: 0.3384153\n",
      "\tspeed: 0.0424s/iter; left time: 243.6945s\n",
      "\titers: 600, epoch: 4 | loss: 0.3245361\n",
      "\tspeed: 0.0424s/iter; left time: 239.4055s\n",
      "\titers: 700, epoch: 4 | loss: 0.2552437\n",
      "\tspeed: 0.0423s/iter; left time: 235.1211s\n",
      "\titers: 800, epoch: 4 | loss: 0.3549815\n",
      "\tspeed: 0.0423s/iter; left time: 230.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3017702 Vali Loss: 0.4986320 Test Loss: 0.5499063\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2787005\n",
      "\tspeed: 0.1528s/iter; left time: 803.3578s\n",
      "\titers: 200, epoch: 5 | loss: 0.2782376\n",
      "\tspeed: 0.0423s/iter; left time: 218.0661s\n",
      "\titers: 300, epoch: 5 | loss: 0.2727273\n",
      "\tspeed: 0.0423s/iter; left time: 213.9147s\n",
      "\titers: 400, epoch: 5 | loss: 0.3005618\n",
      "\tspeed: 0.0423s/iter; left time: 209.7075s\n",
      "\titers: 500, epoch: 5 | loss: 0.2054943\n",
      "\tspeed: 0.0423s/iter; left time: 205.7079s\n",
      "\titers: 600, epoch: 5 | loss: 0.2875345\n",
      "\tspeed: 0.0424s/iter; left time: 201.6123s\n",
      "\titers: 700, epoch: 5 | loss: 0.2824540\n",
      "\tspeed: 0.0424s/iter; left time: 197.3153s\n",
      "\titers: 800, epoch: 5 | loss: 0.3032054\n",
      "\tspeed: 0.0423s/iter; left time: 192.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2867706 Vali Loss: 0.4970104 Test Loss: 0.5531650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5332819819450378, rmse:0.7302615642547607, mae:0.47118669748306274, rse:0.5157877206802368\n",
      "Original data scale mse:17089198.0, rmse:4133.908203125, mae:2575.789794921875, rse:0.20554625988006592\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8278993\n",
      "\tspeed: 0.0688s/iter; left time: 605.9933s\n",
      "\titers: 200, epoch: 1 | loss: 0.6038724\n",
      "\tspeed: 0.0427s/iter; left time: 372.0152s\n",
      "\titers: 300, epoch: 1 | loss: 0.6295652\n",
      "\tspeed: 0.0427s/iter; left time: 367.6742s\n",
      "\titers: 400, epoch: 1 | loss: 0.5376123\n",
      "\tspeed: 0.0428s/iter; left time: 364.0575s\n",
      "\titers: 500, epoch: 1 | loss: 0.6319175\n",
      "\tspeed: 0.0428s/iter; left time: 360.3147s\n",
      "\titers: 600, epoch: 1 | loss: 0.5386626\n",
      "\tspeed: 0.0427s/iter; left time: 355.0724s\n",
      "\titers: 700, epoch: 1 | loss: 0.6122574\n",
      "\tspeed: 0.0427s/iter; left time: 350.6330s\n",
      "\titers: 800, epoch: 1 | loss: 0.7145953\n",
      "\tspeed: 0.0428s/iter; left time: 347.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.6423050 Vali Loss: 0.7688189 Test Loss: 0.8917395\n",
      "Validation loss decreased (inf --> 0.768819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6163427\n",
      "\tspeed: 0.1562s/iter; left time: 1237.2242s\n",
      "\titers: 200, epoch: 2 | loss: 0.5539962\n",
      "\tspeed: 0.0428s/iter; left time: 334.7335s\n",
      "\titers: 300, epoch: 2 | loss: 0.5114649\n",
      "\tspeed: 0.0429s/iter; left time: 330.8273s\n",
      "\titers: 400, epoch: 2 | loss: 0.5971324\n",
      "\tspeed: 0.0427s/iter; left time: 325.6860s\n",
      "\titers: 500, epoch: 2 | loss: 0.4633757\n",
      "\tspeed: 0.0426s/iter; left time: 320.6288s\n",
      "\titers: 600, epoch: 2 | loss: 0.4485228\n",
      "\tspeed: 0.0426s/iter; left time: 316.2793s\n",
      "\titers: 700, epoch: 2 | loss: 0.4506913\n",
      "\tspeed: 0.0427s/iter; left time: 312.2153s\n",
      "\titers: 800, epoch: 2 | loss: 0.6008626\n",
      "\tspeed: 0.0427s/iter; left time: 308.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5660410 Vali Loss: 0.7442201 Test Loss: 0.8908184\n",
      "Validation loss decreased (0.768819 --> 0.744220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4703613\n",
      "\tspeed: 0.1548s/iter; left time: 1088.1671s\n",
      "\titers: 200, epoch: 3 | loss: 0.5118814\n",
      "\tspeed: 0.0426s/iter; left time: 295.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.5528710\n",
      "\tspeed: 0.0427s/iter; left time: 291.3820s\n",
      "\titers: 400, epoch: 3 | loss: 0.5358756\n",
      "\tspeed: 0.0427s/iter; left time: 287.1619s\n",
      "\titers: 500, epoch: 3 | loss: 0.5238606\n",
      "\tspeed: 0.0427s/iter; left time: 282.9118s\n",
      "\titers: 600, epoch: 3 | loss: 0.4330128\n",
      "\tspeed: 0.0428s/iter; left time: 279.1231s\n",
      "\titers: 700, epoch: 3 | loss: 0.5498765\n",
      "\tspeed: 0.0429s/iter; left time: 275.5729s\n",
      "\titers: 800, epoch: 3 | loss: 0.4306593\n",
      "\tspeed: 0.0427s/iter; left time: 270.4857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.5068210 Vali Loss: 0.7821410 Test Loss: 0.9479443\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4938156\n",
      "\tspeed: 0.1524s/iter; left time: 935.1885s\n",
      "\titers: 200, epoch: 4 | loss: 0.4349649\n",
      "\tspeed: 0.0426s/iter; left time: 257.4360s\n",
      "\titers: 300, epoch: 4 | loss: 0.4609250\n",
      "\tspeed: 0.0427s/iter; left time: 253.3497s\n",
      "\titers: 400, epoch: 4 | loss: 0.3898872\n",
      "\tspeed: 0.0426s/iter; left time: 248.9437s\n",
      "\titers: 500, epoch: 4 | loss: 0.4437929\n",
      "\tspeed: 0.0426s/iter; left time: 244.6958s\n",
      "\titers: 600, epoch: 4 | loss: 0.4189924\n",
      "\tspeed: 0.0428s/iter; left time: 241.0953s\n",
      "\titers: 700, epoch: 4 | loss: 0.3600709\n",
      "\tspeed: 0.0427s/iter; left time: 236.2969s\n",
      "\titers: 800, epoch: 4 | loss: 0.3423872\n",
      "\tspeed: 0.0426s/iter; left time: 231.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.4118306 Vali Loss: 0.8718202 Test Loss: 1.1182163\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3254093\n",
      "\tspeed: 0.1529s/iter; left time: 802.0681s\n",
      "\titers: 200, epoch: 5 | loss: 0.3052867\n",
      "\tspeed: 0.0428s/iter; left time: 220.1539s\n",
      "\titers: 300, epoch: 5 | loss: 0.3813921\n",
      "\tspeed: 0.0428s/iter; left time: 216.1833s\n",
      "\titers: 400, epoch: 5 | loss: 0.3014647\n",
      "\tspeed: 0.0429s/iter; left time: 212.1196s\n",
      "\titers: 500, epoch: 5 | loss: 0.2612903\n",
      "\tspeed: 0.0425s/iter; left time: 206.1806s\n",
      "\titers: 600, epoch: 5 | loss: 0.2786329\n",
      "\tspeed: 0.0424s/iter; left time: 201.3329s\n",
      "\titers: 700, epoch: 5 | loss: 0.2839034\n",
      "\tspeed: 0.0424s/iter; left time: 197.0478s\n",
      "\titers: 800, epoch: 5 | loss: 0.2142394\n",
      "\tspeed: 0.0427s/iter; left time: 194.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.3004238 Vali Loss: 0.9838397 Test Loss: 1.1906240\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8908179998397827, rmse:0.9438315629959106, mae:0.6565252542495728, rse:0.6684598326683044\n",
      "Original data scale mse:31524144.0, rmse:5614.63671875, mae:3636.78857421875, rse:0.2796109616756439\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6317953\n",
      "\tspeed: 0.0458s/iter; left time: 403.9148s\n",
      "\titers: 200, epoch: 1 | loss: 0.5629824\n",
      "\tspeed: 0.0429s/iter; left time: 373.5946s\n",
      "\titers: 300, epoch: 1 | loss: 0.7455637\n",
      "\tspeed: 0.0429s/iter; left time: 369.6010s\n",
      "\titers: 400, epoch: 1 | loss: 0.7450652\n",
      "\tspeed: 0.0431s/iter; left time: 367.2045s\n",
      "\titers: 500, epoch: 1 | loss: 0.5389226\n",
      "\tspeed: 0.0430s/iter; left time: 361.8676s\n",
      "\titers: 600, epoch: 1 | loss: 0.6889573\n",
      "\tspeed: 0.0428s/iter; left time: 355.9971s\n",
      "\titers: 700, epoch: 1 | loss: 0.6068897\n",
      "\tspeed: 0.0430s/iter; left time: 352.7879s\n",
      "\titers: 800, epoch: 1 | loss: 0.5648360\n",
      "\tspeed: 0.0430s/iter; left time: 348.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 891 | Train Loss: 0.6413217 Vali Loss: 0.7689846 Test Loss: 0.8899951\n",
      "Validation loss decreased (inf --> 0.768985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5875531\n",
      "\tspeed: 0.3445s/iter; left time: 2728.7032s\n",
      "\titers: 200, epoch: 2 | loss: 0.5150722\n",
      "\tspeed: 0.0430s/iter; left time: 336.6027s\n",
      "\titers: 300, epoch: 2 | loss: 0.5703558\n",
      "\tspeed: 0.0430s/iter; left time: 331.9402s\n",
      "\titers: 400, epoch: 2 | loss: 0.5623621\n",
      "\tspeed: 0.0431s/iter; left time: 328.1285s\n",
      "\titers: 500, epoch: 2 | loss: 0.4505966\n",
      "\tspeed: 0.0431s/iter; left time: 323.9094s\n",
      "\titers: 600, epoch: 2 | loss: 0.5413593\n",
      "\tspeed: 0.0430s/iter; left time: 319.4233s\n",
      "\titers: 700, epoch: 2 | loss: 0.6330453\n",
      "\tspeed: 0.0430s/iter; left time: 315.0075s\n",
      "\titers: 800, epoch: 2 | loss: 0.5263315\n",
      "\tspeed: 0.0430s/iter; left time: 310.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 891 | Train Loss: 0.5671854 Vali Loss: 0.7379254 Test Loss: 0.9084540\n",
      "Validation loss decreased (0.768985 --> 0.737925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5623419\n",
      "\tspeed: 0.1807s/iter; left time: 1270.1703s\n",
      "\titers: 200, epoch: 3 | loss: 0.4651122\n",
      "\tspeed: 0.0427s/iter; left time: 295.9986s\n",
      "\titers: 300, epoch: 3 | loss: 0.4539438\n",
      "\tspeed: 0.0433s/iter; left time: 295.7922s\n",
      "\titers: 400, epoch: 3 | loss: 0.4711712\n",
      "\tspeed: 0.0427s/iter; left time: 287.6020s\n",
      "\titers: 500, epoch: 3 | loss: 0.4152882\n",
      "\tspeed: 0.0429s/iter; left time: 284.2105s\n",
      "\titers: 600, epoch: 3 | loss: 0.4669675\n",
      "\tspeed: 0.0429s/iter; left time: 279.7919s\n",
      "\titers: 700, epoch: 3 | loss: 0.5520155\n",
      "\tspeed: 0.0429s/iter; left time: 275.7671s\n",
      "\titers: 800, epoch: 3 | loss: 0.4687671\n",
      "\tspeed: 0.0478s/iter; left time: 302.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.97s\n",
      "Steps: 891 | Train Loss: 0.4879980 Vali Loss: 0.8375823 Test Loss: 1.0407987\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3903616\n",
      "\tspeed: 0.1551s/iter; left time: 951.7724s\n",
      "\titers: 200, epoch: 4 | loss: 0.3537689\n",
      "\tspeed: 0.0428s/iter; left time: 258.2044s\n",
      "\titers: 300, epoch: 4 | loss: 0.3786092\n",
      "\tspeed: 0.0428s/iter; left time: 254.2189s\n",
      "\titers: 400, epoch: 4 | loss: 0.3805289\n",
      "\tspeed: 0.0428s/iter; left time: 249.5748s\n",
      "\titers: 500, epoch: 4 | loss: 0.3416398\n",
      "\tspeed: 0.0428s/iter; left time: 245.5103s\n",
      "\titers: 600, epoch: 4 | loss: 0.4058864\n",
      "\tspeed: 0.0428s/iter; left time: 241.1793s\n",
      "\titers: 700, epoch: 4 | loss: 0.4049347\n",
      "\tspeed: 0.0427s/iter; left time: 236.6719s\n",
      "\titers: 800, epoch: 4 | loss: 0.3261061\n",
      "\tspeed: 0.0428s/iter; left time: 232.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 891 | Train Loss: 0.3844667 Vali Loss: 0.9129781 Test Loss: 1.1212429\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3127576\n",
      "\tspeed: 0.1548s/iter; left time: 812.2075s\n",
      "\titers: 200, epoch: 5 | loss: 0.2717496\n",
      "\tspeed: 0.0428s/iter; left time: 220.4400s\n",
      "\titers: 300, epoch: 5 | loss: 0.2817279\n",
      "\tspeed: 0.0428s/iter; left time: 216.2523s\n",
      "\titers: 400, epoch: 5 | loss: 0.3021301\n",
      "\tspeed: 0.0429s/iter; left time: 212.1614s\n",
      "\titers: 500, epoch: 5 | loss: 0.2466028\n",
      "\tspeed: 0.0428s/iter; left time: 207.6434s\n",
      "\titers: 600, epoch: 5 | loss: 0.2534030\n",
      "\tspeed: 0.0428s/iter; left time: 203.3012s\n",
      "\titers: 700, epoch: 5 | loss: 0.2385753\n",
      "\tspeed: 0.0428s/iter; left time: 198.7760s\n",
      "\titers: 800, epoch: 5 | loss: 0.2541228\n",
      "\tspeed: 0.0427s/iter; left time: 194.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 891 | Train Loss: 0.2832126 Vali Loss: 0.9814568 Test Loss: 1.1798006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9084542989730835, rmse:0.9531286954879761, mae:0.6624035835266113, rse:0.6750444769859314\n",
      "Original data scale mse:33323196.0, rmse:5772.62451171875, mae:3707.9365234375, rse:0.28747883439064026\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8423463\n",
      "\tspeed: 0.0689s/iter; left time: 605.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.6887416\n",
      "\tspeed: 0.0434s/iter; left time: 377.1364s\n",
      "\titers: 300, epoch: 1 | loss: 0.6946626\n",
      "\tspeed: 0.0434s/iter; left time: 372.5815s\n",
      "\titers: 400, epoch: 1 | loss: 0.8003882\n",
      "\tspeed: 0.0433s/iter; left time: 367.2763s\n",
      "\titers: 500, epoch: 1 | loss: 0.7636173\n",
      "\tspeed: 0.0433s/iter; left time: 363.4738s\n",
      "\titers: 600, epoch: 1 | loss: 0.6651494\n",
      "\tspeed: 0.0434s/iter; left time: 359.7002s\n",
      "\titers: 700, epoch: 1 | loss: 0.6448402\n",
      "\tspeed: 0.0433s/iter; left time: 354.9926s\n",
      "\titers: 800, epoch: 1 | loss: 0.6646598\n",
      "\tspeed: 0.0432s/iter; left time: 349.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.99s\n",
      "Steps: 889 | Train Loss: 0.6898776 Vali Loss: 0.8043511 Test Loss: 0.9426315\n",
      "Validation loss decreased (inf --> 0.804351).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6748342\n",
      "\tspeed: 0.1550s/iter; left time: 1224.5222s\n",
      "\titers: 200, epoch: 2 | loss: 0.5596135\n",
      "\tspeed: 0.0432s/iter; left time: 337.1768s\n",
      "\titers: 300, epoch: 2 | loss: 0.7116277\n",
      "\tspeed: 0.0455s/iter; left time: 350.7496s\n",
      "\titers: 400, epoch: 2 | loss: 0.6107412\n",
      "\tspeed: 0.0433s/iter; left time: 328.9202s\n",
      "\titers: 500, epoch: 2 | loss: 0.5883464\n",
      "\tspeed: 0.0431s/iter; left time: 323.4477s\n",
      "\titers: 600, epoch: 2 | loss: 0.6085504\n",
      "\tspeed: 0.0432s/iter; left time: 319.4093s\n",
      "\titers: 700, epoch: 2 | loss: 0.5117664\n",
      "\tspeed: 0.0431s/iter; left time: 315.0273s\n",
      "\titers: 800, epoch: 2 | loss: 0.6124936\n",
      "\tspeed: 0.0432s/iter; left time: 310.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.6098587 Vali Loss: 0.7803329 Test Loss: 0.9641665\n",
      "Validation loss decreased (0.804351 --> 0.780333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5402963\n",
      "\tspeed: 0.2760s/iter; left time: 1935.3040s\n",
      "\titers: 200, epoch: 3 | loss: 0.4605748\n",
      "\tspeed: 0.0432s/iter; left time: 298.7192s\n",
      "\titers: 300, epoch: 3 | loss: 0.5269380\n",
      "\tspeed: 0.0432s/iter; left time: 294.1242s\n",
      "\titers: 400, epoch: 3 | loss: 0.5939116\n",
      "\tspeed: 0.0432s/iter; left time: 289.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.5763918\n",
      "\tspeed: 0.0432s/iter; left time: 285.7392s\n",
      "\titers: 600, epoch: 3 | loss: 0.5075799\n",
      "\tspeed: 0.0432s/iter; left time: 281.3265s\n",
      "\titers: 700, epoch: 3 | loss: 0.5064101\n",
      "\tspeed: 0.0432s/iter; left time: 277.1074s\n",
      "\titers: 800, epoch: 3 | loss: 0.4175353\n",
      "\tspeed: 0.0432s/iter; left time: 272.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5010041 Vali Loss: 0.9032961 Test Loss: 1.1624815\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4022630\n",
      "\tspeed: 0.1532s/iter; left time: 938.2019s\n",
      "\titers: 200, epoch: 4 | loss: 0.3030237\n",
      "\tspeed: 0.0432s/iter; left time: 260.2977s\n",
      "\titers: 300, epoch: 4 | loss: 0.4377613\n",
      "\tspeed: 0.0432s/iter; left time: 255.6956s\n",
      "\titers: 400, epoch: 4 | loss: 0.3710336\n",
      "\tspeed: 0.0434s/iter; left time: 252.5122s\n",
      "\titers: 500, epoch: 4 | loss: 0.3408263\n",
      "\tspeed: 0.0434s/iter; left time: 248.1573s\n",
      "\titers: 600, epoch: 4 | loss: 0.3300887\n",
      "\tspeed: 0.0432s/iter; left time: 242.7354s\n",
      "\titers: 700, epoch: 4 | loss: 0.3234510\n",
      "\tspeed: 0.0432s/iter; left time: 238.5891s\n",
      "\titers: 800, epoch: 4 | loss: 0.3449729\n",
      "\tspeed: 0.0432s/iter; left time: 234.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3657371 Vali Loss: 0.9667520 Test Loss: 1.2501959\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2918168\n",
      "\tspeed: 0.1533s/iter; left time: 802.5243s\n",
      "\titers: 200, epoch: 5 | loss: 0.2457817\n",
      "\tspeed: 0.0432s/iter; left time: 221.8286s\n",
      "\titers: 300, epoch: 5 | loss: 0.2578150\n",
      "\tspeed: 0.0432s/iter; left time: 217.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.2630793\n",
      "\tspeed: 0.0432s/iter; left time: 213.1579s\n",
      "\titers: 500, epoch: 5 | loss: 0.2566573\n",
      "\tspeed: 0.0432s/iter; left time: 208.9260s\n",
      "\titers: 600, epoch: 5 | loss: 0.2400267\n",
      "\tspeed: 0.0433s/iter; left time: 204.9223s\n",
      "\titers: 700, epoch: 5 | loss: 0.2633997\n",
      "\tspeed: 0.0433s/iter; left time: 200.8110s\n",
      "\titers: 800, epoch: 5 | loss: 0.2333903\n",
      "\tspeed: 0.0431s/iter; left time: 195.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.2611890 Vali Loss: 1.0183774 Test Loss: 1.2775590\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9641668200492859, rmse:0.9819199442863464, mae:0.6851017475128174, rse:0.6957293748855591\n",
      "Original data scale mse:34983416.0, rmse:5914.67822265625, mae:3824.748291015625, rse:0.29469767212867737\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8989682\n",
      "\tspeed: 0.0454s/iter; left time: 398.8716s\n",
      "\titers: 200, epoch: 1 | loss: 0.7645496\n",
      "\tspeed: 0.0434s/iter; left time: 376.7750s\n",
      "\titers: 300, epoch: 1 | loss: 0.8230890\n",
      "\tspeed: 0.0433s/iter; left time: 371.9020s\n",
      "\titers: 400, epoch: 1 | loss: 0.7773031\n",
      "\tspeed: 0.0433s/iter; left time: 367.2498s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878774\n",
      "\tspeed: 0.0432s/iter; left time: 362.2598s\n",
      "\titers: 600, epoch: 1 | loss: 0.5502109\n",
      "\tspeed: 0.0431s/iter; left time: 357.6968s\n",
      "\titers: 700, epoch: 1 | loss: 0.6384642\n",
      "\tspeed: 0.0431s/iter; left time: 353.4354s\n",
      "\titers: 800, epoch: 1 | loss: 0.5753661\n",
      "\tspeed: 0.0432s/iter; left time: 349.2297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.6911542 Vali Loss: 0.8009039 Test Loss: 0.9401131\n",
      "Validation loss decreased (inf --> 0.800904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6818369\n",
      "\tspeed: 0.1586s/iter; left time: 1252.9541s\n",
      "\titers: 200, epoch: 2 | loss: 0.6272230\n",
      "\tspeed: 0.0433s/iter; left time: 337.8720s\n",
      "\titers: 300, epoch: 2 | loss: 0.6506723\n",
      "\tspeed: 0.0433s/iter; left time: 333.6223s\n",
      "\titers: 400, epoch: 2 | loss: 0.6304458\n",
      "\tspeed: 0.0433s/iter; left time: 329.3743s\n",
      "\titers: 500, epoch: 2 | loss: 0.6337780\n",
      "\tspeed: 0.0433s/iter; left time: 324.8774s\n",
      "\titers: 600, epoch: 2 | loss: 0.6134414\n",
      "\tspeed: 0.0432s/iter; left time: 319.4604s\n",
      "\titers: 700, epoch: 2 | loss: 0.5528743\n",
      "\tspeed: 0.0431s/iter; left time: 315.0709s\n",
      "\titers: 800, epoch: 2 | loss: 0.5577848\n",
      "\tspeed: 0.0432s/iter; left time: 311.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.6106333 Vali Loss: 0.8133070 Test Loss: 0.9921194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4732625\n",
      "\tspeed: 0.1541s/iter; left time: 1080.7412s\n",
      "\titers: 200, epoch: 3 | loss: 0.4967950\n",
      "\tspeed: 0.0432s/iter; left time: 298.5250s\n",
      "\titers: 300, epoch: 3 | loss: 0.5958800\n",
      "\tspeed: 0.0432s/iter; left time: 294.0491s\n",
      "\titers: 400, epoch: 3 | loss: 0.5501659\n",
      "\tspeed: 0.0432s/iter; left time: 290.1464s\n",
      "\titers: 500, epoch: 3 | loss: 0.4554381\n",
      "\tspeed: 0.0433s/iter; left time: 286.6728s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987608\n",
      "\tspeed: 0.0434s/iter; left time: 282.3565s\n",
      "\titers: 700, epoch: 3 | loss: 0.4254252\n",
      "\tspeed: 0.0433s/iter; left time: 277.5447s\n",
      "\titers: 800, epoch: 3 | loss: 0.4345360\n",
      "\tspeed: 0.0433s/iter; left time: 273.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.4889395 Vali Loss: 0.9113695 Test Loss: 1.1426848\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3911357\n",
      "\tspeed: 0.1562s/iter; left time: 956.2855s\n",
      "\titers: 200, epoch: 4 | loss: 0.3470968\n",
      "\tspeed: 0.0433s/iter; left time: 260.6937s\n",
      "\titers: 300, epoch: 4 | loss: 0.3864773\n",
      "\tspeed: 0.0432s/iter; left time: 256.1994s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158895\n",
      "\tspeed: 0.0433s/iter; left time: 251.9442s\n",
      "\titers: 500, epoch: 4 | loss: 0.3102552\n",
      "\tspeed: 0.0433s/iter; left time: 247.7422s\n",
      "\titers: 600, epoch: 4 | loss: 0.2958286\n",
      "\tspeed: 0.0433s/iter; left time: 243.4766s\n",
      "\titers: 700, epoch: 4 | loss: 0.4046688\n",
      "\tspeed: 0.0433s/iter; left time: 239.3613s\n",
      "\titers: 800, epoch: 4 | loss: 0.3076833\n",
      "\tspeed: 0.0432s/iter; left time: 234.3935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.3503729 Vali Loss: 0.9891915 Test Loss: 1.2129408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9401134252548218, rmse:0.9695944786071777, mae:0.6843422055244446, rse:0.686996340751648\n",
      "Original data scale mse:34048708.0, rmse:5835.126953125, mae:3839.20703125, rse:0.29073405265808105\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6754712\n",
      "\tspeed: 0.0666s/iter; left time: 587.9911s\n",
      "\titers: 200, epoch: 1 | loss: 0.7101395\n",
      "\tspeed: 0.0423s/iter; left time: 369.7272s\n",
      "\titers: 300, epoch: 1 | loss: 0.6276323\n",
      "\tspeed: 0.0423s/iter; left time: 365.5170s\n",
      "\titers: 400, epoch: 1 | loss: 0.6817048\n",
      "\tspeed: 0.0424s/iter; left time: 361.3959s\n",
      "\titers: 500, epoch: 1 | loss: 0.6525702\n",
      "\tspeed: 0.0424s/iter; left time: 357.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.7124592\n",
      "\tspeed: 0.0425s/iter; left time: 353.7763s\n",
      "\titers: 700, epoch: 1 | loss: 0.6260682\n",
      "\tspeed: 0.0424s/iter; left time: 349.1807s\n",
      "\titers: 800, epoch: 1 | loss: 0.6184115\n",
      "\tspeed: 0.0424s/iter; left time: 344.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 893 | Train Loss: 0.6450163 Vali Loss: 0.5165060 Test Loss: 0.5579700\n",
      "Validation loss decreased (inf --> 0.516506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6814403\n",
      "\tspeed: 0.1540s/iter; left time: 1222.2837s\n",
      "\titers: 200, epoch: 2 | loss: 0.6670058\n",
      "\tspeed: 0.0424s/iter; left time: 332.0060s\n",
      "\titers: 300, epoch: 2 | loss: 0.5597287\n",
      "\tspeed: 0.0424s/iter; left time: 327.9246s\n",
      "\titers: 400, epoch: 2 | loss: 0.5846981\n",
      "\tspeed: 0.0424s/iter; left time: 323.9910s\n",
      "\titers: 500, epoch: 2 | loss: 0.5702143\n",
      "\tspeed: 0.0424s/iter; left time: 319.5276s\n",
      "\titers: 600, epoch: 2 | loss: 0.5664347\n",
      "\tspeed: 0.0424s/iter; left time: 315.4016s\n",
      "\titers: 700, epoch: 2 | loss: 0.6306669\n",
      "\tspeed: 0.0423s/iter; left time: 310.6824s\n",
      "\titers: 800, epoch: 2 | loss: 0.5331949\n",
      "\tspeed: 0.0424s/iter; left time: 306.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5906245 Vali Loss: 0.5072792 Test Loss: 0.5701486\n",
      "Validation loss decreased (0.516506 --> 0.507279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4579810\n",
      "\tspeed: 0.1538s/iter; left time: 1083.8224s\n",
      "\titers: 200, epoch: 3 | loss: 0.5568446\n",
      "\tspeed: 0.0424s/iter; left time: 294.4856s\n",
      "\titers: 300, epoch: 3 | loss: 0.5167010\n",
      "\tspeed: 0.0424s/iter; left time: 290.1108s\n",
      "\titers: 400, epoch: 3 | loss: 0.5265319\n",
      "\tspeed: 0.0424s/iter; left time: 285.7789s\n",
      "\titers: 500, epoch: 3 | loss: 0.5188911\n",
      "\tspeed: 0.0424s/iter; left time: 281.6386s\n",
      "\titers: 600, epoch: 3 | loss: 0.5589418\n",
      "\tspeed: 0.0424s/iter; left time: 277.4769s\n",
      "\titers: 700, epoch: 3 | loss: 0.4617535\n",
      "\tspeed: 0.0424s/iter; left time: 273.2816s\n",
      "\titers: 800, epoch: 3 | loss: 0.6220068\n",
      "\tspeed: 0.0424s/iter; left time: 268.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5592992 Vali Loss: 0.4873188 Test Loss: 0.5413601\n",
      "Validation loss decreased (0.507279 --> 0.487319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5277045\n",
      "\tspeed: 0.1538s/iter; left time: 946.2794s\n",
      "\titers: 200, epoch: 4 | loss: 0.5318843\n",
      "\tspeed: 0.0425s/iter; left time: 257.0233s\n",
      "\titers: 300, epoch: 4 | loss: 0.5635965\n",
      "\tspeed: 0.0424s/iter; left time: 252.6174s\n",
      "\titers: 400, epoch: 4 | loss: 0.4812858\n",
      "\tspeed: 0.0424s/iter; left time: 248.2491s\n",
      "\titers: 500, epoch: 4 | loss: 0.6520225\n",
      "\tspeed: 0.0424s/iter; left time: 243.9387s\n",
      "\titers: 600, epoch: 4 | loss: 0.5258859\n",
      "\tspeed: 0.0424s/iter; left time: 239.5052s\n",
      "\titers: 700, epoch: 4 | loss: 0.5317817\n",
      "\tspeed: 0.0424s/iter; left time: 235.2013s\n",
      "\titers: 800, epoch: 4 | loss: 0.5896013\n",
      "\tspeed: 0.0424s/iter; left time: 231.0366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5458888 Vali Loss: 0.4998872 Test Loss: 0.5571514\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5163347\n",
      "\tspeed: 0.1514s/iter; left time: 796.1003s\n",
      "\titers: 200, epoch: 5 | loss: 0.4502283\n",
      "\tspeed: 0.0424s/iter; left time: 218.5055s\n",
      "\titers: 300, epoch: 5 | loss: 0.5401963\n",
      "\tspeed: 0.0424s/iter; left time: 214.3341s\n",
      "\titers: 400, epoch: 5 | loss: 0.4901792\n",
      "\tspeed: 0.0424s/iter; left time: 210.1131s\n",
      "\titers: 500, epoch: 5 | loss: 0.5244539\n",
      "\tspeed: 0.0424s/iter; left time: 205.9654s\n",
      "\titers: 600, epoch: 5 | loss: 0.4853182\n",
      "\tspeed: 0.0424s/iter; left time: 201.6616s\n",
      "\titers: 700, epoch: 5 | loss: 0.4985727\n",
      "\tspeed: 0.0424s/iter; left time: 197.5407s\n",
      "\titers: 800, epoch: 5 | loss: 0.5109956\n",
      "\tspeed: 0.0424s/iter; left time: 193.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5330377 Vali Loss: 0.4936864 Test Loss: 0.5552840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4607729\n",
      "\tspeed: 0.1508s/iter; left time: 658.3398s\n",
      "\titers: 200, epoch: 6 | loss: 0.5782619\n",
      "\tspeed: 0.0424s/iter; left time: 180.7674s\n",
      "\titers: 300, epoch: 6 | loss: 0.4794590\n",
      "\tspeed: 0.0424s/iter; left time: 176.5570s\n",
      "\titers: 400, epoch: 6 | loss: 0.4478363\n",
      "\tspeed: 0.0424s/iter; left time: 172.2667s\n",
      "\titers: 500, epoch: 6 | loss: 0.4971766\n",
      "\tspeed: 0.0424s/iter; left time: 168.1886s\n",
      "\titers: 600, epoch: 6 | loss: 0.5216733\n",
      "\tspeed: 0.0424s/iter; left time: 163.8817s\n",
      "\titers: 700, epoch: 6 | loss: 0.4696542\n",
      "\tspeed: 0.0424s/iter; left time: 159.6340s\n",
      "\titers: 800, epoch: 6 | loss: 0.5198758\n",
      "\tspeed: 0.0423s/iter; left time: 155.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.5150506 Vali Loss: 0.5277114 Test Loss: 0.5962812\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.541360080242157, rmse:0.7357717752456665, mae:0.4735095798969269, rse:0.5196795463562012\n",
      "Original data scale mse:17373884.0, rmse:4168.19921875, mae:2577.19970703125, rse:0.20725126564502716\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7726961\n",
      "\tspeed: 0.0443s/iter; left time: 391.3494s\n",
      "\titers: 200, epoch: 1 | loss: 0.6059537\n",
      "\tspeed: 0.0424s/iter; left time: 369.8848s\n",
      "\titers: 300, epoch: 1 | loss: 0.6163989\n",
      "\tspeed: 0.0424s/iter; left time: 365.5749s\n",
      "\titers: 400, epoch: 1 | loss: 0.5824293\n",
      "\tspeed: 0.0424s/iter; left time: 361.3066s\n",
      "\titers: 500, epoch: 1 | loss: 0.6351153\n",
      "\tspeed: 0.0424s/iter; left time: 357.1417s\n",
      "\titers: 600, epoch: 1 | loss: 0.6248137\n",
      "\tspeed: 0.0424s/iter; left time: 353.1953s\n",
      "\titers: 700, epoch: 1 | loss: 0.6278644\n",
      "\tspeed: 0.0424s/iter; left time: 348.6996s\n",
      "\titers: 800, epoch: 1 | loss: 0.6605453\n",
      "\tspeed: 0.0424s/iter; left time: 344.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.6447119 Vali Loss: 0.5131364 Test Loss: 0.5589977\n",
      "Validation loss decreased (inf --> 0.513136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6233028\n",
      "\tspeed: 0.1532s/iter; left time: 1216.2992s\n",
      "\titers: 200, epoch: 2 | loss: 0.6205671\n",
      "\tspeed: 0.0424s/iter; left time: 332.1024s\n",
      "\titers: 300, epoch: 2 | loss: 0.5819731\n",
      "\tspeed: 0.0424s/iter; left time: 328.2915s\n",
      "\titers: 400, epoch: 2 | loss: 0.5888925\n",
      "\tspeed: 0.0424s/iter; left time: 323.6642s\n",
      "\titers: 500, epoch: 2 | loss: 0.5449930\n",
      "\tspeed: 0.0424s/iter; left time: 319.4739s\n",
      "\titers: 600, epoch: 2 | loss: 0.5444065\n",
      "\tspeed: 0.0424s/iter; left time: 315.2054s\n",
      "\titers: 700, epoch: 2 | loss: 0.4697540\n",
      "\tspeed: 0.0424s/iter; left time: 310.9400s\n",
      "\titers: 800, epoch: 2 | loss: 0.5700103\n",
      "\tspeed: 0.0424s/iter; left time: 306.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5880509 Vali Loss: 0.4787750 Test Loss: 0.5329764\n",
      "Validation loss decreased (0.513136 --> 0.478775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951581\n",
      "\tspeed: 0.1549s/iter; left time: 1091.5986s\n",
      "\titers: 200, epoch: 3 | loss: 0.5364272\n",
      "\tspeed: 0.0424s/iter; left time: 294.1517s\n",
      "\titers: 300, epoch: 3 | loss: 0.5284150\n",
      "\tspeed: 0.0422s/iter; left time: 289.0908s\n",
      "\titers: 400, epoch: 3 | loss: 0.5314249\n",
      "\tspeed: 0.0420s/iter; left time: 283.3949s\n",
      "\titers: 500, epoch: 3 | loss: 0.5645924\n",
      "\tspeed: 0.0420s/iter; left time: 279.1288s\n",
      "\titers: 600, epoch: 3 | loss: 0.5532307\n",
      "\tspeed: 0.0420s/iter; left time: 274.8464s\n",
      "\titers: 700, epoch: 3 | loss: 0.4775830\n",
      "\tspeed: 0.0421s/iter; left time: 271.4398s\n",
      "\titers: 800, epoch: 3 | loss: 0.5216519\n",
      "\tspeed: 0.0424s/iter; left time: 269.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 893 | Train Loss: 0.5578060 Vali Loss: 0.4862626 Test Loss: 0.5300143\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5355194\n",
      "\tspeed: 0.1517s/iter; left time: 932.9814s\n",
      "\titers: 200, epoch: 4 | loss: 0.4946832\n",
      "\tspeed: 0.0424s/iter; left time: 256.6434s\n",
      "\titers: 300, epoch: 4 | loss: 0.5068822\n",
      "\tspeed: 0.0424s/iter; left time: 252.4185s\n",
      "\titers: 400, epoch: 4 | loss: 0.6041967\n",
      "\tspeed: 0.0424s/iter; left time: 248.0808s\n",
      "\titers: 500, epoch: 4 | loss: 0.5789028\n",
      "\tspeed: 0.0424s/iter; left time: 243.9592s\n",
      "\titers: 600, epoch: 4 | loss: 0.5656914\n",
      "\tspeed: 0.0424s/iter; left time: 239.6540s\n",
      "\titers: 700, epoch: 4 | loss: 0.5129171\n",
      "\tspeed: 0.0424s/iter; left time: 235.3099s\n",
      "\titers: 800, epoch: 4 | loss: 0.6202127\n",
      "\tspeed: 0.0424s/iter; left time: 231.3925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5469150 Vali Loss: 0.4848965 Test Loss: 0.5420186\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5302015\n",
      "\tspeed: 0.1515s/iter; left time: 796.7560s\n",
      "\titers: 200, epoch: 5 | loss: 0.5042916\n",
      "\tspeed: 0.0424s/iter; left time: 218.6067s\n",
      "\titers: 300, epoch: 5 | loss: 0.5241135\n",
      "\tspeed: 0.0424s/iter; left time: 214.6364s\n",
      "\titers: 400, epoch: 5 | loss: 0.5491605\n",
      "\tspeed: 0.0424s/iter; left time: 210.3903s\n",
      "\titers: 500, epoch: 5 | loss: 0.4557428\n",
      "\tspeed: 0.0424s/iter; left time: 206.0324s\n",
      "\titers: 600, epoch: 5 | loss: 0.5351239\n",
      "\tspeed: 0.0424s/iter; left time: 201.7688s\n",
      "\titers: 700, epoch: 5 | loss: 0.5237975\n",
      "\tspeed: 0.0425s/iter; left time: 197.9415s\n",
      "\titers: 800, epoch: 5 | loss: 0.5267522\n",
      "\tspeed: 0.0424s/iter; left time: 193.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5303102 Vali Loss: 0.4967465 Test Loss: 0.5540982\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5329764485359192, rmse:0.7300523519515991, mae:0.4693261682987213, rse:0.5156399607658386\n",
      "Original data scale mse:17012618.0, rmse:4124.6357421875, mae:2558.65478515625, rse:0.20508518815040588\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9072943\n",
      "\tspeed: 0.0666s/iter; left time: 586.5749s\n",
      "\titers: 200, epoch: 1 | loss: 0.7745368\n",
      "\tspeed: 0.0428s/iter; left time: 372.9163s\n",
      "\titers: 300, epoch: 1 | loss: 0.7921324\n",
      "\tspeed: 0.0429s/iter; left time: 369.5536s\n",
      "\titers: 400, epoch: 1 | loss: 0.7316535\n",
      "\tspeed: 0.0429s/iter; left time: 364.7730s\n",
      "\titers: 500, epoch: 1 | loss: 0.7937814\n",
      "\tspeed: 0.0428s/iter; left time: 360.3231s\n",
      "\titers: 600, epoch: 1 | loss: 0.7329593\n",
      "\tspeed: 0.0429s/iter; left time: 356.6311s\n",
      "\titers: 700, epoch: 1 | loss: 0.7800491\n",
      "\tspeed: 0.0428s/iter; left time: 351.3251s\n",
      "\titers: 800, epoch: 1 | loss: 0.8427641\n",
      "\tspeed: 0.0428s/iter; left time: 347.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 891 | Train Loss: 0.7973685 Vali Loss: 0.7674942 Test Loss: 0.8907766\n",
      "Validation loss decreased (inf --> 0.767494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7844130\n",
      "\tspeed: 0.1589s/iter; left time: 1258.4288s\n",
      "\titers: 200, epoch: 2 | loss: 0.7444956\n",
      "\tspeed: 0.0425s/iter; left time: 332.1698s\n",
      "\titers: 300, epoch: 2 | loss: 0.7098117\n",
      "\tspeed: 0.0427s/iter; left time: 329.7814s\n",
      "\titers: 400, epoch: 2 | loss: 0.7739899\n",
      "\tspeed: 0.0428s/iter; left time: 325.9925s\n",
      "\titers: 500, epoch: 2 | loss: 0.6824423\n",
      "\tspeed: 0.0429s/iter; left time: 322.9323s\n",
      "\titers: 600, epoch: 2 | loss: 0.6675106\n",
      "\tspeed: 0.0427s/iter; left time: 317.1387s\n",
      "\titers: 700, epoch: 2 | loss: 0.6693790\n",
      "\tspeed: 0.0427s/iter; left time: 312.3453s\n",
      "\titers: 800, epoch: 2 | loss: 0.7720233\n",
      "\tspeed: 0.0427s/iter; left time: 308.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.7507204 Vali Loss: 0.7470321 Test Loss: 0.8934081\n",
      "Validation loss decreased (0.767494 --> 0.747032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6790479\n",
      "\tspeed: 0.1556s/iter; left time: 1093.7773s\n",
      "\titers: 200, epoch: 3 | loss: 0.7169223\n",
      "\tspeed: 0.0430s/iter; left time: 298.0066s\n",
      "\titers: 300, epoch: 3 | loss: 0.7404110\n",
      "\tspeed: 0.0430s/iter; left time: 293.6726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7179118\n",
      "\tspeed: 0.0430s/iter; left time: 289.3036s\n",
      "\titers: 500, epoch: 3 | loss: 0.7387559\n",
      "\tspeed: 0.0430s/iter; left time: 284.9844s\n",
      "\titers: 600, epoch: 3 | loss: 0.6473467\n",
      "\tspeed: 0.0431s/iter; left time: 281.4925s\n",
      "\titers: 700, epoch: 3 | loss: 0.7375371\n",
      "\tspeed: 0.0428s/iter; left time: 275.2802s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417627\n",
      "\tspeed: 0.0428s/iter; left time: 270.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.7086069 Vali Loss: 0.8069890 Test Loss: 0.9786863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.7076966\n",
      "\tspeed: 0.1535s/iter; left time: 941.9272s\n",
      "\titers: 200, epoch: 4 | loss: 0.6562591\n",
      "\tspeed: 0.0429s/iter; left time: 259.0190s\n",
      "\titers: 300, epoch: 4 | loss: 0.6606339\n",
      "\tspeed: 0.0430s/iter; left time: 255.3595s\n",
      "\titers: 400, epoch: 4 | loss: 0.6214097\n",
      "\tspeed: 0.0430s/iter; left time: 251.1035s\n",
      "\titers: 500, epoch: 4 | loss: 0.6445979\n",
      "\tspeed: 0.0430s/iter; left time: 246.5406s\n",
      "\titers: 600, epoch: 4 | loss: 0.6321785\n",
      "\tspeed: 0.0430s/iter; left time: 242.3687s\n",
      "\titers: 700, epoch: 4 | loss: 0.6020027\n",
      "\tspeed: 0.0428s/iter; left time: 237.1898s\n",
      "\titers: 800, epoch: 4 | loss: 0.5724365\n",
      "\tspeed: 0.0430s/iter; left time: 233.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.6302950 Vali Loss: 0.8989606 Test Loss: 1.1877890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5547186\n",
      "\tspeed: 0.1534s/iter; left time: 804.6727s\n",
      "\titers: 200, epoch: 5 | loss: 0.5274258\n",
      "\tspeed: 0.0428s/iter; left time: 220.3161s\n",
      "\titers: 300, epoch: 5 | loss: 0.5890260\n",
      "\tspeed: 0.0428s/iter; left time: 215.9630s\n",
      "\titers: 400, epoch: 5 | loss: 0.5521280\n",
      "\tspeed: 0.0428s/iter; left time: 211.6745s\n",
      "\titers: 500, epoch: 5 | loss: 0.5069917\n",
      "\tspeed: 0.0429s/iter; left time: 207.7658s\n",
      "\titers: 600, epoch: 5 | loss: 0.5339789\n",
      "\tspeed: 0.0428s/iter; left time: 203.0759s\n",
      "\titers: 700, epoch: 5 | loss: 0.5004116\n",
      "\tspeed: 0.0428s/iter; left time: 198.7789s\n",
      "\titers: 800, epoch: 5 | loss: 0.4469998\n",
      "\tspeed: 0.0429s/iter; left time: 194.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.5319949 Vali Loss: 0.9941885 Test Loss: 1.2660173\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8934080600738525, rmse:0.945202648639679, mae:0.655841588973999, rse:0.6694309115409851\n",
      "Original data scale mse:31708800.0, rmse:5631.056640625, mae:3635.224365234375, rse:0.2804286777973175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7921820\n",
      "\tspeed: 0.0452s/iter; left time: 398.0818s\n",
      "\titers: 200, epoch: 1 | loss: 0.7478287\n",
      "\tspeed: 0.0428s/iter; left time: 372.4500s\n",
      "\titers: 300, epoch: 1 | loss: 0.8619333\n",
      "\tspeed: 0.0428s/iter; left time: 368.4515s\n",
      "\titers: 400, epoch: 1 | loss: 0.8615767\n",
      "\tspeed: 0.0428s/iter; left time: 364.3418s\n",
      "\titers: 500, epoch: 1 | loss: 0.7331536\n",
      "\tspeed: 0.0428s/iter; left time: 360.3199s\n",
      "\titers: 600, epoch: 1 | loss: 0.8289680\n",
      "\tspeed: 0.0428s/iter; left time: 355.4386s\n",
      "\titers: 700, epoch: 1 | loss: 0.7775533\n",
      "\tspeed: 0.0427s/iter; left time: 350.3145s\n",
      "\titers: 800, epoch: 1 | loss: 0.7493660\n",
      "\tspeed: 0.0428s/iter; left time: 347.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 891 | Train Loss: 0.7966817 Vali Loss: 0.7679877 Test Loss: 0.8891835\n",
      "Validation loss decreased (inf --> 0.767988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7641521\n",
      "\tspeed: 0.2606s/iter; left time: 2064.0676s\n",
      "\titers: 200, epoch: 2 | loss: 0.7173153\n",
      "\tspeed: 0.0428s/iter; left time: 334.5930s\n",
      "\titers: 300, epoch: 2 | loss: 0.7534215\n",
      "\tspeed: 0.0429s/iter; left time: 331.1852s\n",
      "\titers: 400, epoch: 2 | loss: 0.7517242\n",
      "\tspeed: 0.0429s/iter; left time: 326.5406s\n",
      "\titers: 500, epoch: 2 | loss: 0.6673782\n",
      "\tspeed: 0.0428s/iter; left time: 322.2277s\n",
      "\titers: 600, epoch: 2 | loss: 0.7381619\n",
      "\tspeed: 0.0428s/iter; left time: 317.5233s\n",
      "\titers: 700, epoch: 2 | loss: 0.7908342\n",
      "\tspeed: 0.0428s/iter; left time: 313.5241s\n",
      "\titers: 800, epoch: 2 | loss: 0.7319562\n",
      "\tspeed: 0.0429s/iter; left time: 309.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.7515677 Vali Loss: 0.7341306 Test Loss: 0.8943844\n",
      "Validation loss decreased (0.767988 --> 0.734131).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7432774\n",
      "\tspeed: 0.1566s/iter; left time: 1100.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.6817322\n",
      "\tspeed: 0.0428s/iter; left time: 296.6205s\n",
      "\titers: 300, epoch: 3 | loss: 0.6664633\n",
      "\tspeed: 0.0429s/iter; left time: 292.8387s\n",
      "\titers: 400, epoch: 3 | loss: 0.6838632\n",
      "\tspeed: 0.0429s/iter; left time: 288.6988s\n",
      "\titers: 500, epoch: 3 | loss: 0.6565572\n",
      "\tspeed: 0.0429s/iter; left time: 284.3194s\n",
      "\titers: 600, epoch: 3 | loss: 0.6840335\n",
      "\tspeed: 0.0428s/iter; left time: 279.5226s\n",
      "\titers: 700, epoch: 3 | loss: 0.7336498\n",
      "\tspeed: 0.0428s/iter; left time: 275.1810s\n",
      "\titers: 800, epoch: 3 | loss: 0.6862341\n",
      "\tspeed: 0.0429s/iter; left time: 271.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 891 | Train Loss: 0.6975347 Vali Loss: 0.8341798 Test Loss: 1.0216969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6175885\n",
      "\tspeed: 0.1546s/iter; left time: 948.9183s\n",
      "\titers: 200, epoch: 4 | loss: 0.6141663\n",
      "\tspeed: 0.0428s/iter; left time: 258.3516s\n",
      "\titers: 300, epoch: 4 | loss: 0.5967645\n",
      "\tspeed: 0.0428s/iter; left time: 254.1426s\n",
      "\titers: 400, epoch: 4 | loss: 0.6194391\n",
      "\tspeed: 0.0429s/iter; left time: 250.3682s\n",
      "\titers: 500, epoch: 4 | loss: 0.5925292\n",
      "\tspeed: 0.0428s/iter; left time: 245.4361s\n",
      "\titers: 600, epoch: 4 | loss: 0.6434478\n",
      "\tspeed: 0.0428s/iter; left time: 241.4089s\n",
      "\titers: 700, epoch: 4 | loss: 0.6507165\n",
      "\tspeed: 0.0429s/iter; left time: 237.4084s\n",
      "\titers: 800, epoch: 4 | loss: 0.5963517\n",
      "\tspeed: 0.0428s/iter; left time: 232.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.6205907 Vali Loss: 0.8795088 Test Loss: 1.1223147\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5440584\n",
      "\tspeed: 0.1554s/iter; left time: 815.3312s\n",
      "\titers: 200, epoch: 5 | loss: 0.5360005\n",
      "\tspeed: 0.0428s/iter; left time: 220.4603s\n",
      "\titers: 300, epoch: 5 | loss: 0.5228936\n",
      "\tspeed: 0.0428s/iter; left time: 216.1012s\n",
      "\titers: 400, epoch: 5 | loss: 0.5408643\n",
      "\tspeed: 0.0428s/iter; left time: 211.7026s\n",
      "\titers: 500, epoch: 5 | loss: 0.5106289\n",
      "\tspeed: 0.0428s/iter; left time: 207.4522s\n",
      "\titers: 600, epoch: 5 | loss: 0.5052796\n",
      "\tspeed: 0.0428s/iter; left time: 203.2973s\n",
      "\titers: 700, epoch: 5 | loss: 0.4890420\n",
      "\tspeed: 0.0428s/iter; left time: 199.0203s\n",
      "\titers: 800, epoch: 5 | loss: 0.4911533\n",
      "\tspeed: 0.0429s/iter; left time: 195.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 891 | Train Loss: 0.5313087 Vali Loss: 0.9454769 Test Loss: 1.2332697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8943842649459839, rmse:0.9457189440727234, mae:0.6557129621505737, rse:0.6697965264320374\n",
      "Original data scale mse:32409162.0, rmse:5692.904296875, mae:3661.599609375, rse:0.2835087180137634\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9167823\n",
      "\tspeed: 0.0687s/iter; left time: 604.2715s\n",
      "\titers: 200, epoch: 1 | loss: 0.8295469\n",
      "\tspeed: 0.0433s/iter; left time: 376.0475s\n",
      "\titers: 300, epoch: 1 | loss: 0.8317216\n",
      "\tspeed: 0.0433s/iter; left time: 371.6268s\n",
      "\titers: 400, epoch: 1 | loss: 0.8931627\n",
      "\tspeed: 0.0432s/iter; left time: 366.7504s\n",
      "\titers: 500, epoch: 1 | loss: 0.8721631\n",
      "\tspeed: 0.0432s/iter; left time: 362.8045s\n",
      "\titers: 600, epoch: 1 | loss: 0.8138520\n",
      "\tspeed: 0.0432s/iter; left time: 358.3676s\n",
      "\titers: 700, epoch: 1 | loss: 0.8027763\n",
      "\tspeed: 0.0432s/iter; left time: 353.9759s\n",
      "\titers: 800, epoch: 1 | loss: 0.8145867\n",
      "\tspeed: 0.0432s/iter; left time: 349.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 889 | Train Loss: 0.8268264 Vali Loss: 0.8032295 Test Loss: 0.9415814\n",
      "Validation loss decreased (inf --> 0.803229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8204240\n",
      "\tspeed: 0.1607s/iter; left time: 1270.1863s\n",
      "\titers: 200, epoch: 2 | loss: 0.7494366\n",
      "\tspeed: 0.0434s/iter; left time: 338.4654s\n",
      "\titers: 300, epoch: 2 | loss: 0.8417456\n",
      "\tspeed: 0.0433s/iter; left time: 333.2409s\n",
      "\titers: 400, epoch: 2 | loss: 0.7746405\n",
      "\tspeed: 0.0444s/iter; left time: 337.6818s\n",
      "\titers: 500, epoch: 2 | loss: 0.7686574\n",
      "\tspeed: 0.0433s/iter; left time: 324.5066s\n",
      "\titers: 600, epoch: 2 | loss: 0.7710716\n",
      "\tspeed: 0.0434s/iter; left time: 321.1571s\n",
      "\titers: 700, epoch: 2 | loss: 0.7105362\n",
      "\tspeed: 0.0433s/iter; left time: 315.9657s\n",
      "\titers: 800, epoch: 2 | loss: 0.7757682\n",
      "\tspeed: 0.0569s/iter; left time: 409.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 889 | Train Loss: 0.7785878 Vali Loss: 0.7858058 Test Loss: 0.9804038\n",
      "Validation loss decreased (0.803229 --> 0.785806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7292283\n",
      "\tspeed: 0.1557s/iter; left time: 1091.8102s\n",
      "\titers: 200, epoch: 3 | loss: 0.6727266\n",
      "\tspeed: 0.0433s/iter; left time: 299.3696s\n",
      "\titers: 300, epoch: 3 | loss: 0.7174317\n",
      "\tspeed: 0.0433s/iter; left time: 294.8711s\n",
      "\titers: 400, epoch: 3 | loss: 0.7796643\n",
      "\tspeed: 0.0433s/iter; left time: 290.5017s\n",
      "\titers: 500, epoch: 3 | loss: 0.7546417\n",
      "\tspeed: 0.0437s/iter; left time: 288.8821s\n",
      "\titers: 600, epoch: 3 | loss: 0.7066151\n",
      "\tspeed: 0.0434s/iter; left time: 282.4372s\n",
      "\titers: 700, epoch: 3 | loss: 0.6877860\n",
      "\tspeed: 0.0434s/iter; left time: 278.2088s\n",
      "\titers: 800, epoch: 3 | loss: 0.6526594\n",
      "\tspeed: 0.0430s/iter; left time: 271.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6998830 Vali Loss: 0.9058384 Test Loss: 1.1331638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6271045\n",
      "\tspeed: 0.1532s/iter; left time: 938.0345s\n",
      "\titers: 200, epoch: 4 | loss: 0.5641999\n",
      "\tspeed: 0.0433s/iter; left time: 260.5441s\n",
      "\titers: 300, epoch: 4 | loss: 0.6434276\n",
      "\tspeed: 0.0433s/iter; left time: 256.2563s\n",
      "\titers: 400, epoch: 4 | loss: 0.6088561\n",
      "\tspeed: 0.0433s/iter; left time: 251.9317s\n",
      "\titers: 500, epoch: 4 | loss: 0.5735807\n",
      "\tspeed: 0.0433s/iter; left time: 247.6358s\n",
      "\titers: 600, epoch: 4 | loss: 0.5746859\n",
      "\tspeed: 0.0433s/iter; left time: 243.4668s\n",
      "\titers: 700, epoch: 4 | loss: 0.5727103\n",
      "\tspeed: 0.0433s/iter; left time: 239.0850s\n",
      "\titers: 800, epoch: 4 | loss: 0.5597401\n",
      "\tspeed: 0.0433s/iter; left time: 234.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5966287 Vali Loss: 0.9814531 Test Loss: 1.2910458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5147487\n",
      "\tspeed: 0.1540s/iter; left time: 806.0056s\n",
      "\titers: 200, epoch: 5 | loss: 0.4905088\n",
      "\tspeed: 0.0432s/iter; left time: 222.0021s\n",
      "\titers: 300, epoch: 5 | loss: 0.5154892\n",
      "\tspeed: 0.0432s/iter; left time: 217.6247s\n",
      "\titers: 400, epoch: 5 | loss: 0.5248498\n",
      "\tspeed: 0.0432s/iter; left time: 213.3902s\n",
      "\titers: 500, epoch: 5 | loss: 0.4974828\n",
      "\tspeed: 0.0433s/iter; left time: 209.2038s\n",
      "\titers: 600, epoch: 5 | loss: 0.4696812\n",
      "\tspeed: 0.0433s/iter; left time: 204.7956s\n",
      "\titers: 700, epoch: 5 | loss: 0.4997624\n",
      "\tspeed: 0.0433s/iter; left time: 200.5115s\n",
      "\titers: 800, epoch: 5 | loss: 0.4531054\n",
      "\tspeed: 0.0432s/iter; left time: 196.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.4976955 Vali Loss: 1.0409889 Test Loss: 1.3053417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9804030060768127, rmse:0.9901530146598816, mae:0.6853036284446716, rse:0.7015628814697266\n",
      "Original data scale mse:35351660.0, rmse:5945.72607421875, mae:3821.09619140625, rse:0.29624462127685547\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9466599\n",
      "\tspeed: 0.0454s/iter; left time: 399.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.8727154\n",
      "\tspeed: 0.0434s/iter; left time: 377.3942s\n",
      "\titers: 300, epoch: 1 | loss: 0.9057765\n",
      "\tspeed: 0.0434s/iter; left time: 372.7011s\n",
      "\titers: 400, epoch: 1 | loss: 0.8797851\n",
      "\tspeed: 0.0435s/iter; left time: 369.3436s\n",
      "\titers: 500, epoch: 1 | loss: 0.8275533\n",
      "\tspeed: 0.0433s/iter; left time: 363.4032s\n",
      "\titers: 600, epoch: 1 | loss: 0.7401694\n",
      "\tspeed: 0.0438s/iter; left time: 363.5049s\n",
      "\titers: 700, epoch: 1 | loss: 0.7978014\n",
      "\tspeed: 0.0465s/iter; left time: 381.1200s\n",
      "\titers: 800, epoch: 1 | loss: 0.7577026\n",
      "\tspeed: 0.0434s/iter; left time: 351.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.18s\n",
      "Steps: 889 | Train Loss: 0.8278822 Vali Loss: 0.7998108 Test Loss: 0.9392518\n",
      "Validation loss decreased (inf --> 0.799811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8257199\n",
      "\tspeed: 0.1631s/iter; left time: 1288.6700s\n",
      "\titers: 200, epoch: 2 | loss: 0.7908405\n",
      "\tspeed: 0.0432s/iter; left time: 337.4041s\n",
      "\titers: 300, epoch: 2 | loss: 0.8114936\n",
      "\tspeed: 0.0433s/iter; left time: 333.1141s\n",
      "\titers: 400, epoch: 2 | loss: 0.7960544\n",
      "\tspeed: 0.0433s/iter; left time: 328.8684s\n",
      "\titers: 500, epoch: 2 | loss: 0.7977426\n",
      "\tspeed: 0.0433s/iter; left time: 324.4735s\n",
      "\titers: 600, epoch: 2 | loss: 0.7829188\n",
      "\tspeed: 0.0432s/iter; left time: 320.0653s\n",
      "\titers: 700, epoch: 2 | loss: 0.7445554\n",
      "\tspeed: 0.0432s/iter; left time: 315.8008s\n",
      "\titers: 800, epoch: 2 | loss: 0.7440019\n",
      "\tspeed: 0.0432s/iter; left time: 311.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.7802197 Vali Loss: 0.8078851 Test Loss: 0.9985030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6851830\n",
      "\tspeed: 0.1546s/iter; left time: 1084.0998s\n",
      "\titers: 200, epoch: 3 | loss: 0.7013032\n",
      "\tspeed: 0.0433s/iter; left time: 299.3369s\n",
      "\titers: 300, epoch: 3 | loss: 0.7688395\n",
      "\tspeed: 0.0433s/iter; left time: 294.7485s\n",
      "\titers: 400, epoch: 3 | loss: 0.7427030\n",
      "\tspeed: 0.0432s/iter; left time: 290.2659s\n",
      "\titers: 500, epoch: 3 | loss: 0.6877431\n",
      "\tspeed: 0.0432s/iter; left time: 285.7716s\n",
      "\titers: 600, epoch: 3 | loss: 0.7065533\n",
      "\tspeed: 0.0432s/iter; left time: 281.5004s\n",
      "\titers: 700, epoch: 3 | loss: 0.6642315\n",
      "\tspeed: 0.0433s/iter; left time: 277.3985s\n",
      "\titers: 800, epoch: 3 | loss: 0.6527606\n",
      "\tspeed: 0.0433s/iter; left time: 273.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.7020089 Vali Loss: 0.9253964 Test Loss: 1.1505303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6376268\n",
      "\tspeed: 0.1549s/iter; left time: 948.6309s\n",
      "\titers: 200, epoch: 4 | loss: 0.5873826\n",
      "\tspeed: 0.0433s/iter; left time: 260.5456s\n",
      "\titers: 300, epoch: 4 | loss: 0.5964963\n",
      "\tspeed: 0.0432s/iter; left time: 256.1165s\n",
      "\titers: 400, epoch: 4 | loss: 0.5676491\n",
      "\tspeed: 0.0432s/iter; left time: 251.8599s\n",
      "\titers: 500, epoch: 4 | loss: 0.5647410\n",
      "\tspeed: 0.0433s/iter; left time: 247.5781s\n",
      "\titers: 600, epoch: 4 | loss: 0.5496978\n",
      "\tspeed: 0.0433s/iter; left time: 243.2656s\n",
      "\titers: 700, epoch: 4 | loss: 0.6317477\n",
      "\tspeed: 0.0433s/iter; left time: 239.2751s\n",
      "\titers: 800, epoch: 4 | loss: 0.5474359\n",
      "\tspeed: 0.0433s/iter; left time: 234.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5977458 Vali Loss: 0.9744865 Test Loss: 1.2368258\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9392515420913696, rmse:0.9691498875617981, mae:0.6835147738456726, rse:0.68668133020401\n",
      "Original data scale mse:33994148.0, rmse:5830.4501953125, mae:3832.315185546875, rse:0.29050102829933167\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4911484\n",
      "\tspeed: 0.0693s/iter; left time: 611.9773s\n",
      "\titers: 200, epoch: 1 | loss: 0.5065615\n",
      "\tspeed: 0.0425s/iter; left time: 371.0347s\n",
      "\titers: 300, epoch: 1 | loss: 0.4340100\n",
      "\tspeed: 0.0425s/iter; left time: 366.7587s\n",
      "\titers: 400, epoch: 1 | loss: 0.4488462\n",
      "\tspeed: 0.0425s/iter; left time: 362.5609s\n",
      "\titers: 500, epoch: 1 | loss: 0.4275458\n",
      "\tspeed: 0.0424s/iter; left time: 357.7773s\n",
      "\titers: 600, epoch: 1 | loss: 0.4698621\n",
      "\tspeed: 0.0423s/iter; left time: 352.5370s\n",
      "\titers: 700, epoch: 1 | loss: 0.4225431\n",
      "\tspeed: 0.0423s/iter; left time: 348.5066s\n",
      "\titers: 800, epoch: 1 | loss: 0.4138886\n",
      "\tspeed: 0.0423s/iter; left time: 344.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 893 | Train Loss: 0.4471790 Vali Loss: 0.4661752 Test Loss: 0.4741735\n",
      "Validation loss decreased (inf --> 0.466175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775786\n",
      "\tspeed: 0.1549s/iter; left time: 1229.9370s\n",
      "\titers: 200, epoch: 2 | loss: 0.4439257\n",
      "\tspeed: 0.0423s/iter; left time: 331.6912s\n",
      "\titers: 300, epoch: 2 | loss: 0.3676892\n",
      "\tspeed: 0.0423s/iter; left time: 327.5157s\n",
      "\titers: 400, epoch: 2 | loss: 0.4086309\n",
      "\tspeed: 0.0423s/iter; left time: 323.1373s\n",
      "\titers: 500, epoch: 2 | loss: 0.3739947\n",
      "\tspeed: 0.0424s/iter; left time: 319.5687s\n",
      "\titers: 600, epoch: 2 | loss: 0.3817287\n",
      "\tspeed: 0.0425s/iter; left time: 316.4665s\n",
      "\titers: 700, epoch: 2 | loss: 0.3985335\n",
      "\tspeed: 0.0425s/iter; left time: 311.6215s\n",
      "\titers: 800, epoch: 2 | loss: 0.3476285\n",
      "\tspeed: 0.0424s/iter; left time: 306.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.3932738 Vali Loss: 0.4469037 Test Loss: 0.4600936\n",
      "Validation loss decreased (0.466175 --> 0.446904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3068054\n",
      "\tspeed: 0.2543s/iter; left time: 1791.3258s\n",
      "\titers: 200, epoch: 3 | loss: 0.3668438\n",
      "\tspeed: 0.0996s/iter; left time: 691.7961s\n",
      "\titers: 300, epoch: 3 | loss: 0.3455071\n",
      "\tspeed: 0.0997s/iter; left time: 682.3173s\n",
      "\titers: 400, epoch: 3 | loss: 0.3461210\n",
      "\tspeed: 0.1000s/iter; left time: 674.2198s\n",
      "\titers: 500, epoch: 3 | loss: 0.3217195\n",
      "\tspeed: 0.0996s/iter; left time: 661.8853s\n",
      "\titers: 600, epoch: 3 | loss: 0.3734902\n",
      "\tspeed: 0.0975s/iter; left time: 638.3809s\n",
      "\titers: 700, epoch: 3 | loss: 0.2914124\n",
      "\tspeed: 0.1000s/iter; left time: 644.7618s\n",
      "\titers: 800, epoch: 3 | loss: 0.3890799\n",
      "\tspeed: 0.0998s/iter; left time: 633.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.05s\n",
      "Steps: 893 | Train Loss: 0.3587247 Vali Loss: 0.4380572 Test Loss: 0.4524367\n",
      "Validation loss decreased (0.446904 --> 0.438057).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3552805\n",
      "\tspeed: 0.3507s/iter; left time: 2157.3631s\n",
      "\titers: 200, epoch: 4 | loss: 0.3344842\n",
      "\tspeed: 0.0996s/iter; left time: 602.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.3647326\n",
      "\tspeed: 0.1002s/iter; left time: 596.2035s\n",
      "\titers: 400, epoch: 4 | loss: 0.2998760\n",
      "\tspeed: 0.0997s/iter; left time: 583.4333s\n",
      "\titers: 500, epoch: 4 | loss: 0.4524735\n",
      "\tspeed: 0.0998s/iter; left time: 574.2098s\n",
      "\titers: 600, epoch: 4 | loss: 0.3286375\n",
      "\tspeed: 0.1001s/iter; left time: 565.7702s\n",
      "\titers: 700, epoch: 4 | loss: 0.3207008\n",
      "\tspeed: 0.0975s/iter; left time: 541.5647s\n",
      "\titers: 800, epoch: 4 | loss: 0.3865527\n",
      "\tspeed: 0.0997s/iter; left time: 543.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3505675 Vali Loss: 0.4404310 Test Loss: 0.4508197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3415059\n",
      "\tspeed: 0.3477s/iter; left time: 1828.5925s\n",
      "\titers: 200, epoch: 5 | loss: 0.2955045\n",
      "\tspeed: 0.0994s/iter; left time: 512.7961s\n",
      "\titers: 300, epoch: 5 | loss: 0.3343011\n",
      "\tspeed: 0.0965s/iter; left time: 488.2960s\n",
      "\titers: 400, epoch: 5 | loss: 0.3191603\n",
      "\tspeed: 0.1002s/iter; left time: 497.1236s\n",
      "\titers: 500, epoch: 5 | loss: 0.3369505\n",
      "\tspeed: 0.0998s/iter; left time: 484.7751s\n",
      "\titers: 600, epoch: 5 | loss: 0.3035013\n",
      "\tspeed: 0.1027s/iter; left time: 488.8667s\n",
      "\titers: 700, epoch: 5 | loss: 0.3314672\n",
      "\tspeed: 0.0997s/iter; left time: 464.6441s\n",
      "\titers: 800, epoch: 5 | loss: 0.3245445\n",
      "\tspeed: 0.0996s/iter; left time: 453.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.23s\n",
      "Steps: 893 | Train Loss: 0.3437869 Vali Loss: 0.4333304 Test Loss: 0.4505197\n",
      "Validation loss decreased (0.438057 --> 0.433330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2955053\n",
      "\tspeed: 0.3496s/iter; left time: 1526.2936s\n",
      "\titers: 200, epoch: 6 | loss: 0.3789532\n",
      "\tspeed: 0.0997s/iter; left time: 425.2423s\n",
      "\titers: 300, epoch: 6 | loss: 0.3201004\n",
      "\tspeed: 0.1000s/iter; left time: 416.7742s\n",
      "\titers: 400, epoch: 6 | loss: 0.3060965\n",
      "\tspeed: 0.0977s/iter; left time: 397.1223s\n",
      "\titers: 500, epoch: 6 | loss: 0.3340288\n",
      "\tspeed: 0.0996s/iter; left time: 395.1401s\n",
      "\titers: 600, epoch: 6 | loss: 0.3561740\n",
      "\tspeed: 0.1000s/iter; left time: 386.5593s\n",
      "\titers: 700, epoch: 6 | loss: 0.2889605\n",
      "\tspeed: 0.0997s/iter; left time: 375.4333s\n",
      "\titers: 800, epoch: 6 | loss: 0.3243141\n",
      "\tspeed: 0.0997s/iter; left time: 365.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3358514 Vali Loss: 0.4350837 Test Loss: 0.4501255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3363560\n",
      "\tspeed: 0.3447s/iter; left time: 1197.2968s\n",
      "\titers: 200, epoch: 7 | loss: 0.3300336\n",
      "\tspeed: 0.0995s/iter; left time: 335.5565s\n",
      "\titers: 300, epoch: 7 | loss: 0.3290423\n",
      "\tspeed: 0.0995s/iter; left time: 325.8258s\n",
      "\titers: 400, epoch: 7 | loss: 0.3301187\n",
      "\tspeed: 0.0999s/iter; left time: 316.8736s\n",
      "\titers: 500, epoch: 7 | loss: 0.3623188\n",
      "\tspeed: 0.0997s/iter; left time: 306.3446s\n",
      "\titers: 600, epoch: 7 | loss: 0.3117304\n",
      "\tspeed: 0.0979s/iter; left time: 291.1815s\n",
      "\titers: 700, epoch: 7 | loss: 0.3075892\n",
      "\tspeed: 0.0997s/iter; left time: 286.4121s\n",
      "\titers: 800, epoch: 7 | loss: 0.3116951\n",
      "\tspeed: 0.0997s/iter; left time: 276.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:29.06s\n",
      "Steps: 893 | Train Loss: 0.3296475 Vali Loss: 0.4394803 Test Loss: 0.4597104\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3222373\n",
      "\tspeed: 0.3475s/iter; left time: 896.4426s\n",
      "\titers: 200, epoch: 8 | loss: 0.3074499\n",
      "\tspeed: 0.0997s/iter; left time: 247.2852s\n",
      "\titers: 300, epoch: 8 | loss: 0.3007301\n",
      "\tspeed: 0.0997s/iter; left time: 237.2666s\n",
      "\titers: 400, epoch: 8 | loss: 0.3464734\n",
      "\tspeed: 0.1001s/iter; left time: 228.1169s\n",
      "\titers: 500, epoch: 8 | loss: 0.3576700\n",
      "\tspeed: 0.0996s/iter; left time: 217.1357s\n",
      "\titers: 600, epoch: 8 | loss: 0.2671410\n",
      "\tspeed: 0.0997s/iter; left time: 207.3670s\n",
      "\titers: 700, epoch: 8 | loss: 0.3065107\n",
      "\tspeed: 0.0980s/iter; left time: 193.9716s\n",
      "\titers: 800, epoch: 8 | loss: 0.3539655\n",
      "\tspeed: 0.0997s/iter; left time: 187.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.99s\n",
      "Steps: 893 | Train Loss: 0.3185648 Vali Loss: 0.4473014 Test Loss: 0.4629481\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.542383074760437, rmse:0.7364665865898132, mae:0.4505196213722229, rse:0.5201703310012817\n",
      "Original data scale mse:16739734.0, rmse:4091.422119140625, mae:2419.34033203125, rse:0.20343375205993652\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4961760\n",
      "\tspeed: 0.1013s/iter; left time: 894.6627s\n",
      "\titers: 200, epoch: 1 | loss: 0.4673467\n",
      "\tspeed: 0.0982s/iter; left time: 857.3946s\n",
      "\titers: 300, epoch: 1 | loss: 0.3913468\n",
      "\tspeed: 0.0998s/iter; left time: 861.2167s\n",
      "\titers: 400, epoch: 1 | loss: 0.3862548\n",
      "\tspeed: 0.0997s/iter; left time: 850.1341s\n",
      "\titers: 500, epoch: 1 | loss: 0.3760215\n",
      "\tspeed: 0.1002s/iter; left time: 844.6093s\n",
      "\titers: 600, epoch: 1 | loss: 0.3881062\n",
      "\tspeed: 0.0997s/iter; left time: 830.9371s\n",
      "\titers: 700, epoch: 1 | loss: 0.3617670\n",
      "\tspeed: 0.0996s/iter; left time: 819.7432s\n",
      "\titers: 800, epoch: 1 | loss: 0.3615622\n",
      "\tspeed: 0.0995s/iter; left time: 808.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:28.96s\n",
      "Steps: 893 | Train Loss: 0.4460977 Vali Loss: 0.4678970 Test Loss: 0.4768294\n",
      "Validation loss decreased (inf --> 0.467897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4298193\n",
      "\tspeed: 0.3487s/iter; left time: 2767.7632s\n",
      "\titers: 200, epoch: 2 | loss: 0.3945704\n",
      "\tspeed: 0.1001s/iter; left time: 784.2109s\n",
      "\titers: 300, epoch: 2 | loss: 0.3653846\n",
      "\tspeed: 0.0977s/iter; left time: 756.0032s\n",
      "\titers: 400, epoch: 2 | loss: 0.4323478\n",
      "\tspeed: 0.0997s/iter; left time: 761.7802s\n",
      "\titers: 500, epoch: 2 | loss: 0.3580473\n",
      "\tspeed: 0.1001s/iter; left time: 754.8115s\n",
      "\titers: 600, epoch: 2 | loss: 0.3739384\n",
      "\tspeed: 0.0997s/iter; left time: 741.8068s\n",
      "\titers: 700, epoch: 2 | loss: 0.3707134\n",
      "\tspeed: 0.0997s/iter; left time: 731.7379s\n",
      "\titers: 800, epoch: 2 | loss: 0.3879987\n",
      "\tspeed: 0.0997s/iter; left time: 721.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 893 | Train Loss: 0.3922306 Vali Loss: 0.4739162 Test Loss: 0.4904799\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3283895\n",
      "\tspeed: 0.3471s/iter; left time: 2445.3365s\n",
      "\titers: 200, epoch: 3 | loss: 0.3593989\n",
      "\tspeed: 0.1001s/iter; left time: 695.1505s\n",
      "\titers: 300, epoch: 3 | loss: 0.3461201\n",
      "\tspeed: 0.0997s/iter; left time: 682.3263s\n",
      "\titers: 400, epoch: 3 | loss: 0.3899336\n",
      "\tspeed: 0.0997s/iter; left time: 672.5761s\n",
      "\titers: 500, epoch: 3 | loss: 0.3038490\n",
      "\tspeed: 0.0979s/iter; left time: 650.7232s\n",
      "\titers: 600, epoch: 3 | loss: 0.3177424\n",
      "\tspeed: 0.0997s/iter; left time: 652.4112s\n",
      "\titers: 700, epoch: 3 | loss: 0.3442164\n",
      "\tspeed: 0.0997s/iter; left time: 642.5721s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645916\n",
      "\tspeed: 0.1001s/iter; left time: 635.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.11s\n",
      "Steps: 893 | Train Loss: 0.3600039 Vali Loss: 0.4441136 Test Loss: 0.4573037\n",
      "Validation loss decreased (0.467897 --> 0.444114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3785842\n",
      "\tspeed: 0.3505s/iter; left time: 2156.3456s\n",
      "\titers: 200, epoch: 4 | loss: 0.3646410\n",
      "\tspeed: 0.1003s/iter; left time: 606.8436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3598185\n",
      "\tspeed: 0.0995s/iter; left time: 592.2524s\n",
      "\titers: 400, epoch: 4 | loss: 0.3055528\n",
      "\tspeed: 0.0996s/iter; left time: 582.8728s\n",
      "\titers: 500, epoch: 4 | loss: 0.3440922\n",
      "\tspeed: 0.1002s/iter; left time: 576.2156s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483069\n",
      "\tspeed: 0.0980s/iter; left time: 553.6670s\n",
      "\titers: 700, epoch: 4 | loss: 0.3740851\n",
      "\tspeed: 0.0781s/iter; left time: 433.3801s\n",
      "\titers: 800, epoch: 4 | loss: 0.3176002\n",
      "\tspeed: 0.0833s/iter; left time: 453.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:23.55s\n",
      "Steps: 893 | Train Loss: 0.3523917 Vali Loss: 0.4382839 Test Loss: 0.4560694\n",
      "Validation loss decreased (0.444114 --> 0.438284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3475668\n",
      "\tspeed: 0.2750s/iter; left time: 1446.2601s\n",
      "\titers: 200, epoch: 5 | loss: 0.3251121\n",
      "\tspeed: 0.0736s/iter; left time: 379.6259s\n",
      "\titers: 300, epoch: 5 | loss: 0.3531427\n",
      "\tspeed: 0.0697s/iter; left time: 352.5928s\n",
      "\titers: 400, epoch: 5 | loss: 0.3877855\n",
      "\tspeed: 0.0691s/iter; left time: 342.7866s\n",
      "\titers: 500, epoch: 5 | loss: 0.4363698\n",
      "\tspeed: 0.0699s/iter; left time: 339.4271s\n",
      "\titers: 600, epoch: 5 | loss: 0.3527153\n",
      "\tspeed: 0.0691s/iter; left time: 328.6117s\n",
      "\titers: 700, epoch: 5 | loss: 0.3683708\n",
      "\tspeed: 0.0688s/iter; left time: 320.5714s\n",
      "\titers: 800, epoch: 5 | loss: 0.3201083\n",
      "\tspeed: 0.0631s/iter; left time: 287.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.33s\n",
      "Steps: 893 | Train Loss: 0.3443674 Vali Loss: 0.4326296 Test Loss: 0.4493239\n",
      "Validation loss decreased (0.438284 --> 0.432630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3875108\n",
      "\tspeed: 0.2185s/iter; left time: 954.0886s\n",
      "\titers: 200, epoch: 6 | loss: 0.2961913\n",
      "\tspeed: 0.0643s/iter; left time: 274.2214s\n",
      "\titers: 300, epoch: 6 | loss: 0.3305008\n",
      "\tspeed: 0.0586s/iter; left time: 244.2405s\n",
      "\titers: 400, epoch: 6 | loss: 0.3676060\n",
      "\tspeed: 0.0590s/iter; left time: 239.6983s\n",
      "\titers: 500, epoch: 6 | loss: 0.3054922\n",
      "\tspeed: 0.0635s/iter; left time: 251.9017s\n",
      "\titers: 600, epoch: 6 | loss: 0.3499708\n",
      "\tspeed: 0.0560s/iter; left time: 216.6187s\n",
      "\titers: 700, epoch: 6 | loss: 0.3658276\n",
      "\tspeed: 0.0678s/iter; left time: 255.4734s\n",
      "\titers: 800, epoch: 6 | loss: 0.3456498\n",
      "\tspeed: 0.0589s/iter; left time: 216.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.07s\n",
      "Steps: 893 | Train Loss: 0.3386246 Vali Loss: 0.4327755 Test Loss: 0.4507557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3751110\n",
      "\tspeed: 0.2167s/iter; left time: 752.5252s\n",
      "\titers: 200, epoch: 7 | loss: 0.3736641\n",
      "\tspeed: 0.0566s/iter; left time: 191.0273s\n",
      "\titers: 300, epoch: 7 | loss: 0.3364144\n",
      "\tspeed: 0.0547s/iter; left time: 178.9894s\n",
      "\titers: 400, epoch: 7 | loss: 0.3188649\n",
      "\tspeed: 0.0618s/iter; left time: 195.9655s\n",
      "\titers: 500, epoch: 7 | loss: 0.2985703\n",
      "\tspeed: 0.0598s/iter; left time: 183.7871s\n",
      "\titers: 600, epoch: 7 | loss: 0.3182776\n",
      "\tspeed: 0.0545s/iter; left time: 162.0567s\n",
      "\titers: 700, epoch: 7 | loss: 0.3210778\n",
      "\tspeed: 0.0543s/iter; left time: 155.9074s\n",
      "\titers: 800, epoch: 7 | loss: 0.3455326\n",
      "\tspeed: 0.0597s/iter; left time: 165.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.47s\n",
      "Steps: 893 | Train Loss: 0.3302290 Vali Loss: 0.4352394 Test Loss: 0.4564897\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3031308\n",
      "\tspeed: 0.1991s/iter; left time: 513.6828s\n",
      "\titers: 200, epoch: 8 | loss: 0.3194226\n",
      "\tspeed: 0.0547s/iter; left time: 135.5935s\n",
      "\titers: 300, epoch: 8 | loss: 0.2646621\n",
      "\tspeed: 0.0547s/iter; left time: 130.1115s\n",
      "\titers: 400, epoch: 8 | loss: 0.3403605\n",
      "\tspeed: 0.0547s/iter; left time: 124.6607s\n",
      "\titers: 500, epoch: 8 | loss: 0.2957830\n",
      "\tspeed: 0.0540s/iter; left time: 117.6638s\n",
      "\titers: 600, epoch: 8 | loss: 0.3299017\n",
      "\tspeed: 0.0539s/iter; left time: 112.1751s\n",
      "\titers: 700, epoch: 8 | loss: 0.3319207\n",
      "\tspeed: 0.0424s/iter; left time: 83.9013s\n",
      "\titers: 800, epoch: 8 | loss: 0.3285314\n",
      "\tspeed: 0.0425s/iter; left time: 79.9751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 893 | Train Loss: 0.3232820 Vali Loss: 0.4387058 Test Loss: 0.4518137\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5393510460853577, rmse:0.7344052195549011, mae:0.4493239223957062, rse:0.518714427947998\n",
      "Original data scale mse:16871196.0, rmse:4107.4560546875, mae:2425.1201171875, rse:0.20423100888729095\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6672421\n",
      "\tspeed: 0.1225s/iter; left time: 1079.0721s\n",
      "\titers: 200, epoch: 1 | loss: 0.5515631\n",
      "\tspeed: 0.1004s/iter; left time: 874.4951s\n",
      "\titers: 300, epoch: 1 | loss: 0.5762939\n",
      "\tspeed: 0.0997s/iter; left time: 858.4098s\n",
      "\titers: 400, epoch: 1 | loss: 0.5065603\n",
      "\tspeed: 0.0998s/iter; left time: 849.1282s\n",
      "\titers: 500, epoch: 1 | loss: 0.5610098\n",
      "\tspeed: 0.0997s/iter; left time: 838.9433s\n",
      "\titers: 600, epoch: 1 | loss: 0.5096467\n",
      "\tspeed: 0.0996s/iter; left time: 827.6667s\n",
      "\titers: 700, epoch: 1 | loss: 0.5499381\n",
      "\tspeed: 0.0981s/iter; left time: 805.2932s\n",
      "\titers: 800, epoch: 1 | loss: 0.5857596\n",
      "\tspeed: 0.1001s/iter; left time: 811.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.26s\n",
      "Steps: 891 | Train Loss: 0.5666141 Vali Loss: 0.6045604 Test Loss: 0.6403206\n",
      "Validation loss decreased (inf --> 0.604560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5640221\n",
      "\tspeed: 0.3492s/iter; left time: 2765.9513s\n",
      "\titers: 200, epoch: 2 | loss: 0.5088830\n",
      "\tspeed: 0.0982s/iter; left time: 768.1499s\n",
      "\titers: 300, epoch: 2 | loss: 0.4887963\n",
      "\tspeed: 0.0997s/iter; left time: 769.4972s\n",
      "\titers: 400, epoch: 2 | loss: 0.5271239\n",
      "\tspeed: 0.0999s/iter; left time: 760.9682s\n",
      "\titers: 500, epoch: 2 | loss: 0.4826321\n",
      "\tspeed: 0.0998s/iter; left time: 750.3560s\n",
      "\titers: 600, epoch: 2 | loss: 0.4500237\n",
      "\tspeed: 0.0998s/iter; left time: 740.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.4458811\n",
      "\tspeed: 0.1003s/iter; left time: 734.0238s\n",
      "\titers: 800, epoch: 2 | loss: 0.5414408\n",
      "\tspeed: 0.0981s/iter; left time: 708.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.78s\n",
      "Steps: 891 | Train Loss: 0.5187781 Vali Loss: 0.5858609 Test Loss: 0.6294323\n",
      "Validation loss decreased (0.604560 --> 0.585861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4665427\n",
      "\tspeed: 0.3484s/iter; left time: 2449.1963s\n",
      "\titers: 200, epoch: 3 | loss: 0.4825417\n",
      "\tspeed: 0.0998s/iter; left time: 691.3184s\n",
      "\titers: 300, epoch: 3 | loss: 0.5149940\n",
      "\tspeed: 0.0999s/iter; left time: 682.2108s\n",
      "\titers: 400, epoch: 3 | loss: 0.4779201\n",
      "\tspeed: 0.1001s/iter; left time: 673.8547s\n",
      "\titers: 500, epoch: 3 | loss: 0.4734988\n",
      "\tspeed: 0.0998s/iter; left time: 661.5925s\n",
      "\titers: 600, epoch: 3 | loss: 0.4606842\n",
      "\tspeed: 0.0999s/iter; left time: 652.2852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4830624\n",
      "\tspeed: 0.1002s/iter; left time: 644.2974s\n",
      "\titers: 800, epoch: 3 | loss: 0.4152540\n",
      "\tspeed: 0.0998s/iter; left time: 631.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.4818207 Vali Loss: 0.5982211 Test Loss: 0.6481169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5011472\n",
      "\tspeed: 0.3461s/iter; left time: 2124.6559s\n",
      "\titers: 200, epoch: 4 | loss: 0.5074872\n",
      "\tspeed: 0.0998s/iter; left time: 602.7188s\n",
      "\titers: 300, epoch: 4 | loss: 0.4955360\n",
      "\tspeed: 0.0998s/iter; left time: 592.6353s\n",
      "\titers: 400, epoch: 4 | loss: 0.4511050\n",
      "\tspeed: 0.1003s/iter; left time: 585.3277s\n",
      "\titers: 500, epoch: 4 | loss: 0.4521061\n",
      "\tspeed: 0.0963s/iter; left time: 552.4779s\n",
      "\titers: 600, epoch: 4 | loss: 0.4680182\n",
      "\tspeed: 0.0996s/iter; left time: 561.5179s\n",
      "\titers: 700, epoch: 4 | loss: 0.4725400\n",
      "\tspeed: 0.1002s/iter; left time: 554.8289s\n",
      "\titers: 800, epoch: 4 | loss: 0.4061299\n",
      "\tspeed: 0.0998s/iter; left time: 542.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.86s\n",
      "Steps: 891 | Train Loss: 0.4487891 Vali Loss: 0.6199368 Test Loss: 0.6803785\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4297377\n",
      "\tspeed: 0.3441s/iter; left time: 1805.6331s\n",
      "\titers: 200, epoch: 5 | loss: 0.4026465\n",
      "\tspeed: 0.1002s/iter; left time: 515.9557s\n",
      "\titers: 300, epoch: 5 | loss: 0.4717359\n",
      "\tspeed: 0.0999s/iter; left time: 504.1768s\n",
      "\titers: 400, epoch: 5 | loss: 0.3712812\n",
      "\tspeed: 0.0998s/iter; left time: 493.6633s\n",
      "\titers: 500, epoch: 5 | loss: 0.4022918\n",
      "\tspeed: 0.1002s/iter; left time: 485.7544s\n",
      "\titers: 600, epoch: 5 | loss: 0.3846109\n",
      "\tspeed: 0.0976s/iter; left time: 463.3442s\n",
      "\titers: 700, epoch: 5 | loss: 0.3668328\n",
      "\tspeed: 0.0998s/iter; left time: 463.7039s\n",
      "\titers: 800, epoch: 5 | loss: 0.3492153\n",
      "\tspeed: 0.1002s/iter; left time: 455.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.81s\n",
      "Steps: 891 | Train Loss: 0.4012262 Vali Loss: 0.6363432 Test Loss: 0.6880217\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8916634321212769, rmse:0.9442793130874634, mae:0.6294323801994324, rse:0.6687769889831543\n",
      "Original data scale mse:31304240.0, rmse:5595.01904296875, mae:3466.73583984375, rse:0.2786340117454529\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5821608\n",
      "\tspeed: 0.1011s/iter; left time: 890.8707s\n",
      "\titers: 200, epoch: 1 | loss: 0.5414001\n",
      "\tspeed: 0.0999s/iter; left time: 870.1064s\n",
      "\titers: 300, epoch: 1 | loss: 0.5977905\n",
      "\tspeed: 0.0999s/iter; left time: 860.0292s\n",
      "\titers: 400, epoch: 1 | loss: 0.6129014\n",
      "\tspeed: 0.1002s/iter; left time: 852.6214s\n",
      "\titers: 500, epoch: 1 | loss: 0.5201844\n",
      "\tspeed: 0.0999s/iter; left time: 840.4667s\n",
      "\titers: 600, epoch: 1 | loss: 0.5803166\n",
      "\tspeed: 0.0999s/iter; left time: 829.9148s\n",
      "\titers: 700, epoch: 1 | loss: 0.5274479\n",
      "\tspeed: 0.0981s/iter; left time: 805.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5249704\n",
      "\tspeed: 0.1000s/iter; left time: 810.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.5667487 Vali Loss: 0.6036084 Test Loss: 0.6384962\n",
      "Validation loss decreased (inf --> 0.603608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5650464\n",
      "\tspeed: 0.3508s/iter; left time: 2777.9605s\n",
      "\titers: 200, epoch: 2 | loss: 0.4880849\n",
      "\tspeed: 0.0999s/iter; left time: 781.2645s\n",
      "\titers: 300, epoch: 2 | loss: 0.5213675\n",
      "\tspeed: 0.0976s/iter; left time: 753.7105s\n",
      "\titers: 400, epoch: 2 | loss: 0.5095889\n",
      "\tspeed: 0.1003s/iter; left time: 764.0732s\n",
      "\titers: 500, epoch: 2 | loss: 0.4726025\n",
      "\tspeed: 0.0998s/iter; left time: 750.7598s\n",
      "\titers: 600, epoch: 2 | loss: 0.5014688\n",
      "\tspeed: 0.0999s/iter; left time: 741.1375s\n",
      "\titers: 700, epoch: 2 | loss: 0.5463427\n",
      "\tspeed: 0.0999s/iter; left time: 731.0628s\n",
      "\titers: 800, epoch: 2 | loss: 0.4964917\n",
      "\tspeed: 0.0983s/iter; left time: 709.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.5191443 Vali Loss: 0.5893764 Test Loss: 0.6355495\n",
      "Validation loss decreased (0.603608 --> 0.589376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5120730\n",
      "\tspeed: 0.3498s/iter; left time: 2458.6507s\n",
      "\titers: 200, epoch: 3 | loss: 0.4706349\n",
      "\tspeed: 0.1001s/iter; left time: 693.3674s\n",
      "\titers: 300, epoch: 3 | loss: 0.4448654\n",
      "\tspeed: 0.0998s/iter; left time: 681.6559s\n",
      "\titers: 400, epoch: 3 | loss: 0.4628130\n",
      "\tspeed: 0.0999s/iter; left time: 671.9505s\n",
      "\titers: 500, epoch: 3 | loss: 0.4449418\n",
      "\tspeed: 0.0983s/iter; left time: 651.6129s\n",
      "\titers: 600, epoch: 3 | loss: 0.4725779\n",
      "\tspeed: 0.0999s/iter; left time: 651.9273s\n",
      "\titers: 700, epoch: 3 | loss: 0.5287828\n",
      "\tspeed: 0.0997s/iter; left time: 640.6990s\n",
      "\titers: 800, epoch: 3 | loss: 0.4800147\n",
      "\tspeed: 0.1001s/iter; left time: 633.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.12s\n",
      "Steps: 891 | Train Loss: 0.4814646 Vali Loss: 0.5950368 Test Loss: 0.6511412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4533524\n",
      "\tspeed: 0.3469s/iter; left time: 2129.5220s\n",
      "\titers: 200, epoch: 4 | loss: 0.4304148\n",
      "\tspeed: 0.0999s/iter; left time: 603.3841s\n",
      "\titers: 300, epoch: 4 | loss: 0.4300361\n",
      "\tspeed: 0.0998s/iter; left time: 592.8193s\n",
      "\titers: 400, epoch: 4 | loss: 0.4440291\n",
      "\tspeed: 0.0998s/iter; left time: 582.4911s\n",
      "\titers: 500, epoch: 4 | loss: 0.4045419\n",
      "\tspeed: 0.0998s/iter; left time: 572.7650s\n",
      "\titers: 600, epoch: 4 | loss: 0.4626110\n",
      "\tspeed: 0.0982s/iter; left time: 553.7949s\n",
      "\titers: 700, epoch: 4 | loss: 0.4658494\n",
      "\tspeed: 0.0999s/iter; left time: 553.0796s\n",
      "\titers: 800, epoch: 4 | loss: 0.4166605\n",
      "\tspeed: 0.1000s/iter; left time: 543.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.4491993 Vali Loss: 0.6185856 Test Loss: 0.6720317\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4081205\n",
      "\tspeed: 0.3469s/iter; left time: 1820.3439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3865242\n",
      "\tspeed: 0.0979s/iter; left time: 503.9117s\n",
      "\titers: 300, epoch: 5 | loss: 0.4183852\n",
      "\tspeed: 0.0879s/iter; left time: 443.8502s\n",
      "\titers: 400, epoch: 5 | loss: 0.4128723\n",
      "\tspeed: 0.0851s/iter; left time: 420.8707s\n",
      "\titers: 500, epoch: 5 | loss: 0.3539628\n",
      "\tspeed: 0.0814s/iter; left time: 394.5072s\n",
      "\titers: 600, epoch: 5 | loss: 0.3663605\n",
      "\tspeed: 0.0782s/iter; left time: 371.3083s\n",
      "\titers: 700, epoch: 5 | loss: 0.3721410\n",
      "\tspeed: 0.0756s/iter; left time: 351.1780s\n",
      "\titers: 800, epoch: 5 | loss: 0.3518102\n",
      "\tspeed: 0.0759s/iter; left time: 345.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:14.69s\n",
      "Steps: 891 | Train Loss: 0.4004162 Vali Loss: 0.6410127 Test Loss: 0.6884735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.926580548286438, rmse:0.9625905156135559, mae:0.6355494260787964, rse:0.681745707988739\n",
      "Original data scale mse:32648818.0, rmse:5713.91455078125, mae:3491.83544921875, rse:0.28455501794815063\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6749020\n",
      "\tspeed: 0.0880s/iter; left time: 773.9963s\n",
      "\titers: 200, epoch: 1 | loss: 0.5854820\n",
      "\tspeed: 0.0643s/iter; left time: 558.6767s\n",
      "\titers: 300, epoch: 1 | loss: 0.5932214\n",
      "\tspeed: 0.0607s/iter; left time: 521.5064s\n",
      "\titers: 400, epoch: 1 | loss: 0.6503561\n",
      "\tspeed: 0.0638s/iter; left time: 541.9757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6313170\n",
      "\tspeed: 0.0652s/iter; left time: 547.1778s\n",
      "\titers: 600, epoch: 1 | loss: 0.5846669\n",
      "\tspeed: 0.0609s/iter; left time: 505.2470s\n",
      "\titers: 700, epoch: 1 | loss: 0.5666745\n",
      "\tspeed: 0.0584s/iter; left time: 478.5598s\n",
      "\titers: 800, epoch: 1 | loss: 0.5630711\n",
      "\tspeed: 0.0651s/iter; left time: 527.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.98s\n",
      "Steps: 889 | Train Loss: 0.5923140 Vali Loss: 0.6247001 Test Loss: 0.6689268\n",
      "Validation loss decreased (inf --> 0.624700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5999055\n",
      "\tspeed: 0.2301s/iter; left time: 1817.9884s\n",
      "\titers: 200, epoch: 2 | loss: 0.5163762\n",
      "\tspeed: 0.0640s/iter; left time: 499.1229s\n",
      "\titers: 300, epoch: 2 | loss: 0.5957887\n",
      "\tspeed: 0.0601s/iter; left time: 463.1147s\n",
      "\titers: 400, epoch: 2 | loss: 0.5381776\n",
      "\tspeed: 0.0599s/iter; left time: 455.1543s\n",
      "\titers: 500, epoch: 2 | loss: 0.5255415\n",
      "\tspeed: 0.0627s/iter; left time: 470.6591s\n",
      "\titers: 600, epoch: 2 | loss: 0.5293689\n",
      "\tspeed: 0.0553s/iter; left time: 409.0322s\n",
      "\titers: 700, epoch: 2 | loss: 0.4841101\n",
      "\tspeed: 0.0596s/iter; left time: 435.3629s\n",
      "\titers: 800, epoch: 2 | loss: 0.5456057\n",
      "\tspeed: 0.0638s/iter; left time: 459.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.23s\n",
      "Steps: 889 | Train Loss: 0.5422265 Vali Loss: 0.6108645 Test Loss: 0.6684534\n",
      "Validation loss decreased (0.624700 --> 0.610864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5128787\n",
      "\tspeed: 0.2132s/iter; left time: 1495.4042s\n",
      "\titers: 200, epoch: 3 | loss: 0.4480970\n",
      "\tspeed: 0.0630s/iter; left time: 435.8043s\n",
      "\titers: 300, epoch: 3 | loss: 0.4961124\n",
      "\tspeed: 0.0553s/iter; left time: 376.4363s\n",
      "\titers: 400, epoch: 3 | loss: 0.5564043\n",
      "\tspeed: 0.0554s/iter; left time: 372.0075s\n",
      "\titers: 500, epoch: 3 | loss: 0.5350204\n",
      "\tspeed: 0.0556s/iter; left time: 367.9148s\n",
      "\titers: 600, epoch: 3 | loss: 0.5114772\n",
      "\tspeed: 0.0555s/iter; left time: 361.6638s\n",
      "\titers: 700, epoch: 3 | loss: 0.4942974\n",
      "\tspeed: 0.0600s/iter; left time: 384.5499s\n",
      "\titers: 800, epoch: 3 | loss: 0.4492947\n",
      "\tspeed: 0.0602s/iter; left time: 380.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.59s\n",
      "Steps: 889 | Train Loss: 0.4943151 Vali Loss: 0.6295973 Test Loss: 0.7076582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4483882\n",
      "\tspeed: 0.1723s/iter; left time: 1055.3662s\n",
      "\titers: 200, epoch: 4 | loss: 0.4055574\n",
      "\tspeed: 0.0434s/iter; left time: 261.6143s\n",
      "\titers: 300, epoch: 4 | loss: 0.4998737\n",
      "\tspeed: 0.0940s/iter; left time: 557.0042s\n",
      "\titers: 400, epoch: 4 | loss: 0.4381592\n",
      "\tspeed: 0.0959s/iter; left time: 558.6168s\n",
      "\titers: 500, epoch: 4 | loss: 0.4398095\n",
      "\tspeed: 0.0963s/iter; left time: 551.1163s\n",
      "\titers: 600, epoch: 4 | loss: 0.3904050\n",
      "\tspeed: 0.0963s/iter; left time: 541.4066s\n",
      "\titers: 700, epoch: 4 | loss: 0.4184488\n",
      "\tspeed: 0.0959s/iter; left time: 529.4898s\n",
      "\titers: 800, epoch: 4 | loss: 0.4155434\n",
      "\tspeed: 0.0964s/iter; left time: 522.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.97s\n",
      "Steps: 889 | Train Loss: 0.4369344 Vali Loss: 0.6505283 Test Loss: 0.7536047\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3816183\n",
      "\tspeed: 0.3237s/iter; left time: 1694.4145s\n",
      "\titers: 200, epoch: 5 | loss: 0.3658687\n",
      "\tspeed: 0.0962s/iter; left time: 494.1775s\n",
      "\titers: 300, epoch: 5 | loss: 0.3781559\n",
      "\tspeed: 0.0963s/iter; left time: 484.9635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3842306\n",
      "\tspeed: 0.0962s/iter; left time: 474.7852s\n",
      "\titers: 500, epoch: 5 | loss: 0.3844637\n",
      "\tspeed: 0.0958s/iter; left time: 463.4083s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622078\n",
      "\tspeed: 0.0965s/iter; left time: 456.8915s\n",
      "\titers: 700, epoch: 5 | loss: 0.3801307\n",
      "\tspeed: 0.0945s/iter; left time: 438.1494s\n",
      "\titers: 800, epoch: 5 | loss: 0.3456769\n",
      "\tspeed: 0.0964s/iter; left time: 437.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.41s\n",
      "Steps: 889 | Train Loss: 0.3721608 Vali Loss: 0.6543319 Test Loss: 0.7557714\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9621178507804871, rmse:0.980876088142395, mae:0.6684539914131165, rse:0.694989800453186\n",
      "Original data scale mse:34872248.0, rmse:5905.27294921875, mae:3729.80712890625, rse:0.29422909021377563\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6934446\n",
      "\tspeed: 0.0987s/iter; left time: 867.5293s\n",
      "\titers: 200, epoch: 1 | loss: 0.6247063\n",
      "\tspeed: 0.0963s/iter; left time: 836.7673s\n",
      "\titers: 300, epoch: 1 | loss: 0.6612011\n",
      "\tspeed: 0.0945s/iter; left time: 811.4723s\n",
      "\titers: 400, epoch: 1 | loss: 0.6389622\n",
      "\tspeed: 0.0963s/iter; left time: 817.4475s\n",
      "\titers: 500, epoch: 1 | loss: 0.5934289\n",
      "\tspeed: 0.0961s/iter; left time: 806.6232s\n",
      "\titers: 600, epoch: 1 | loss: 0.5154261\n",
      "\tspeed: 0.0963s/iter; left time: 798.4704s\n",
      "\titers: 700, epoch: 1 | loss: 0.5651692\n",
      "\tspeed: 0.0960s/iter; left time: 786.1001s\n",
      "\titers: 800, epoch: 1 | loss: 0.5396094\n",
      "\tspeed: 0.0963s/iter; left time: 778.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5927589 Vali Loss: 0.6234155 Test Loss: 0.6664205\n",
      "Validation loss decreased (inf --> 0.623416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5715579\n",
      "\tspeed: 0.3282s/iter; left time: 2593.3084s\n",
      "\titers: 200, epoch: 2 | loss: 0.5660957\n",
      "\tspeed: 0.0961s/iter; left time: 750.0644s\n",
      "\titers: 300, epoch: 2 | loss: 0.5675597\n",
      "\tspeed: 0.0963s/iter; left time: 741.9776s\n",
      "\titers: 400, epoch: 2 | loss: 0.5479144\n",
      "\tspeed: 0.0963s/iter; left time: 732.1089s\n",
      "\titers: 500, epoch: 2 | loss: 0.5714894\n",
      "\tspeed: 0.0946s/iter; left time: 709.7225s\n",
      "\titers: 600, epoch: 2 | loss: 0.5486781\n",
      "\tspeed: 0.0963s/iter; left time: 712.5633s\n",
      "\titers: 700, epoch: 2 | loss: 0.5204014\n",
      "\tspeed: 0.0959s/iter; left time: 700.1509s\n",
      "\titers: 800, epoch: 2 | loss: 0.5183818\n",
      "\tspeed: 0.0963s/iter; left time: 693.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5440160 Vali Loss: 0.6201125 Test Loss: 0.6710535\n",
      "Validation loss decreased (0.623416 --> 0.620112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4829638\n",
      "\tspeed: 0.3295s/iter; left time: 2310.5892s\n",
      "\titers: 200, epoch: 3 | loss: 0.4810499\n",
      "\tspeed: 0.0944s/iter; left time: 652.7481s\n",
      "\titers: 300, epoch: 3 | loss: 0.5425767\n",
      "\tspeed: 0.0964s/iter; left time: 656.7294s\n",
      "\titers: 400, epoch: 3 | loss: 0.5283835\n",
      "\tspeed: 0.0963s/iter; left time: 646.5499s\n",
      "\titers: 500, epoch: 3 | loss: 0.4801555\n",
      "\tspeed: 0.0958s/iter; left time: 633.8055s\n",
      "\titers: 600, epoch: 3 | loss: 0.5072457\n",
      "\tspeed: 0.0961s/iter; left time: 625.8852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4781311\n",
      "\tspeed: 0.0963s/iter; left time: 617.3270s\n",
      "\titers: 800, epoch: 3 | loss: 0.4668347\n",
      "\tspeed: 0.0963s/iter; left time: 608.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.55s\n",
      "Steps: 889 | Train Loss: 0.4913807 Vali Loss: 0.6401752 Test Loss: 0.7129096\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4722865\n",
      "\tspeed: 0.3254s/iter; left time: 1993.0053s\n",
      "\titers: 200, epoch: 4 | loss: 0.4323826\n",
      "\tspeed: 0.0963s/iter; left time: 580.0950s\n",
      "\titers: 300, epoch: 4 | loss: 0.4230804\n",
      "\tspeed: 0.0964s/iter; left time: 571.0327s\n",
      "\titers: 400, epoch: 4 | loss: 0.4106955\n",
      "\tspeed: 0.0963s/iter; left time: 560.5630s\n",
      "\titers: 500, epoch: 4 | loss: 0.4227760\n",
      "\tspeed: 0.0944s/iter; left time: 540.4133s\n",
      "\titers: 600, epoch: 4 | loss: 0.3831848\n",
      "\tspeed: 0.0963s/iter; left time: 541.3955s\n",
      "\titers: 700, epoch: 4 | loss: 0.4679500\n",
      "\tspeed: 0.0961s/iter; left time: 530.7225s\n",
      "\titers: 800, epoch: 4 | loss: 0.4229302\n",
      "\tspeed: 0.0965s/iter; left time: 523.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:25.66s\n",
      "Steps: 889 | Train Loss: 0.4341105 Vali Loss: 0.6558956 Test Loss: 0.7309559\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4138470\n",
      "\tspeed: 0.3239s/iter; left time: 1695.8515s\n",
      "\titers: 200, epoch: 5 | loss: 0.3879161\n",
      "\tspeed: 0.0963s/iter; left time: 494.4180s\n",
      "\titers: 300, epoch: 5 | loss: 0.3631673\n",
      "\tspeed: 0.0963s/iter; left time: 485.1216s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704465\n",
      "\tspeed: 0.0963s/iter; left time: 475.4809s\n",
      "\titers: 500, epoch: 5 | loss: 0.3562725\n",
      "\tspeed: 0.0963s/iter; left time: 465.8318s\n",
      "\titers: 600, epoch: 5 | loss: 0.3766115\n",
      "\tspeed: 0.0963s/iter; left time: 455.9600s\n",
      "\titers: 700, epoch: 5 | loss: 0.3341760\n",
      "\tspeed: 0.0959s/iter; left time: 444.7203s\n",
      "\titers: 800, epoch: 5 | loss: 0.3604023\n",
      "\tspeed: 0.0946s/iter; left time: 429.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.62s\n",
      "Steps: 889 | Train Loss: 0.3729840 Vali Loss: 0.6521958 Test Loss: 0.7438802\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9993071556091309, rmse:0.9996535181999207, mae:0.6710531711578369, rse:0.7082943320274353\n",
      "Original data scale mse:35697720.0, rmse:5974.7568359375, mae:3709.144287109375, rse:0.29769107699394226\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.5202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5360  0.7321  0.4716  0.5171\n",
       "              2         24        0.5333  0.7303  0.4712  0.5158\n",
       "              1         96        0.8908  0.9438  0.6565  0.6685\n",
       "              2         96        0.9085  0.9531  0.6624  0.6750\n",
       "              1         168       0.9642  0.9819  0.6851  0.6957\n",
       "              2         168       0.9401  0.9696  0.6843  0.6870\n",
       "RMSE          1         24        0.5414  0.7358  0.4735  0.5197\n",
       "              2         24        0.5330  0.7301  0.4693  0.5156\n",
       "              1         96        0.8934  0.9452  0.6558  0.6694\n",
       "              2         96        0.8944  0.9457  0.6557  0.6698\n",
       "              1         168       0.9804  0.9902  0.6853  0.7016\n",
       "              2         168       0.9393  0.9691  0.6835  0.6867\n",
       "MAE           1         24        0.5424  0.7365  0.4505  0.5202\n",
       "              2         24        0.5394  0.7344  0.4493  0.5187\n",
       "              1         96        0.8917  0.9443  0.6294  0.6688\n",
       "              2         96        0.9266  0.9626  0.6355  0.6817\n",
       "              1         168       0.9621  0.9809  0.6685  0.6950\n",
       "              2         168       0.9993  0.9997  0.6711  0.7083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17142486.0</td>\n",
       "      <td>4140.3486</td>\n",
       "      <td>2565.9302</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17089198.0</td>\n",
       "      <td>4133.9082</td>\n",
       "      <td>2575.7898</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31524144.0</td>\n",
       "      <td>5614.6367</td>\n",
       "      <td>3636.7886</td>\n",
       "      <td>0.2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33323196.0</td>\n",
       "      <td>5772.6245</td>\n",
       "      <td>3707.9365</td>\n",
       "      <td>0.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34983416.0</td>\n",
       "      <td>5914.6782</td>\n",
       "      <td>3824.7483</td>\n",
       "      <td>0.2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34048708.0</td>\n",
       "      <td>5835.1270</td>\n",
       "      <td>3839.2070</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17373884.0</td>\n",
       "      <td>4168.1992</td>\n",
       "      <td>2577.1997</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17012618.0</td>\n",
       "      <td>4124.6357</td>\n",
       "      <td>2558.6548</td>\n",
       "      <td>0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31708800.0</td>\n",
       "      <td>5631.0566</td>\n",
       "      <td>3635.2244</td>\n",
       "      <td>0.2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32409162.0</td>\n",
       "      <td>5692.9043</td>\n",
       "      <td>3661.5996</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35351660.0</td>\n",
       "      <td>5945.7261</td>\n",
       "      <td>3821.0962</td>\n",
       "      <td>0.2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33994148.0</td>\n",
       "      <td>5830.4502</td>\n",
       "      <td>3832.3152</td>\n",
       "      <td>0.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16739734.0</td>\n",
       "      <td>4091.4221</td>\n",
       "      <td>2419.3403</td>\n",
       "      <td>0.2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16871196.0</td>\n",
       "      <td>4107.4561</td>\n",
       "      <td>2425.1201</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31304240.0</td>\n",
       "      <td>5595.0190</td>\n",
       "      <td>3466.7358</td>\n",
       "      <td>0.2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32648818.0</td>\n",
       "      <td>5713.9146</td>\n",
       "      <td>3491.8354</td>\n",
       "      <td>0.2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34872248.0</td>\n",
       "      <td>5905.2729</td>\n",
       "      <td>3729.8071</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35697720.0</td>\n",
       "      <td>5974.7568</td>\n",
       "      <td>3709.1443</td>\n",
       "      <td>0.2977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17142486.0  4140.3486  2565.9302  0.2059\n",
       "              2         24        17089198.0  4133.9082  2575.7898  0.2055\n",
       "              1         96        31524144.0  5614.6367  3636.7886  0.2796\n",
       "              2         96        33323196.0  5772.6245  3707.9365  0.2875\n",
       "              1         168       34983416.0  5914.6782  3824.7483  0.2947\n",
       "              2         168       34048708.0  5835.1270  3839.2070  0.2907\n",
       "RMSE          1         24        17373884.0  4168.1992  2577.1997  0.2073\n",
       "              2         24        17012618.0  4124.6357  2558.6548  0.2051\n",
       "              1         96        31708800.0  5631.0566  3635.2244  0.2804\n",
       "              2         96        32409162.0  5692.9043  3661.5996  0.2835\n",
       "              1         168       35351660.0  5945.7261  3821.0962  0.2962\n",
       "              2         168       33994148.0  5830.4502  3832.3152  0.2905\n",
       "MAE           1         24        16739734.0  4091.4221  2419.3403  0.2034\n",
       "              2         24        16871196.0  4107.4561  2425.1201  0.2042\n",
       "              1         96        31304240.0  5595.0190  3466.7358  0.2786\n",
       "              2         96        32648818.0  5713.9146  3491.8354  0.2846\n",
       "              1         168       34872248.0  5905.2729  3729.8071  0.2942\n",
       "              2         168       35697720.0  5974.7568  3709.1443  0.2977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.6941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5409  0.7354  0.4499  0.5194\n",
       "         MSE            0.5346  0.7312  0.4714  0.5164\n",
       "         RMSE           0.5372  0.7329  0.4714  0.5177\n",
       "96       MAE            0.9091  0.9534  0.6325  0.6753\n",
       "         MSE            0.8996  0.9485  0.6595  0.6718\n",
       "         RMSE           0.8939  0.9455  0.6558  0.6696\n",
       "168      MAE            0.9807  0.9903  0.6698  0.7016\n",
       "         MSE            0.9521  0.9758  0.6847  0.6914\n",
       "         RMSE           0.9598  0.9797  0.6844  0.6941"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16805465.0</td>\n",
       "      <td>4099.4391</td>\n",
       "      <td>2422.2302</td>\n",
       "      <td>0.2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17115842.0</td>\n",
       "      <td>4137.1284</td>\n",
       "      <td>2570.8600</td>\n",
       "      <td>0.2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17193251.0</td>\n",
       "      <td>4146.4175</td>\n",
       "      <td>2567.9272</td>\n",
       "      <td>0.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>31976529.0</td>\n",
       "      <td>5654.4668</td>\n",
       "      <td>3479.2856</td>\n",
       "      <td>0.2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>32423670.0</td>\n",
       "      <td>5693.6306</td>\n",
       "      <td>3672.3625</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32058981.0</td>\n",
       "      <td>5661.9805</td>\n",
       "      <td>3648.4120</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35284984.0</td>\n",
       "      <td>5940.0149</td>\n",
       "      <td>3719.4757</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34516062.0</td>\n",
       "      <td>5874.9026</td>\n",
       "      <td>3831.9777</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34672904.0</td>\n",
       "      <td>5888.0881</td>\n",
       "      <td>3826.7057</td>\n",
       "      <td>0.2934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16805465.0  4099.4391  2422.2302  0.2038\n",
       "         MSE            17115842.0  4137.1284  2570.8600  0.2057\n",
       "         RMSE           17193251.0  4146.4175  2567.9272  0.2062\n",
       "96       MAE            31976529.0  5654.4668  3479.2856  0.2816\n",
       "         MSE            32423670.0  5693.6306  3672.3625  0.2835\n",
       "         RMSE           32058981.0  5661.9805  3648.4120  0.2820\n",
       "168      MAE            35284984.0  5940.0149  3719.4757  0.2960\n",
       "         MSE            34516062.0  5874.9026  3831.9777  0.2927\n",
       "         RMSE           34672904.0  5888.0881  3826.7057  0.2934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_5_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
