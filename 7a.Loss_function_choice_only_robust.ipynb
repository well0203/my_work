{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Robust Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/robust\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5645647\n",
      "\tspeed: 0.0665s/iter; left time: 595.8050s\n",
      "\titers: 200, epoch: 1 | loss: 0.4373353\n",
      "\tspeed: 0.0404s/iter; left time: 358.1548s\n",
      "\titers: 300, epoch: 1 | loss: 0.3493574\n",
      "\tspeed: 0.0391s/iter; left time: 342.1404s\n",
      "\titers: 400, epoch: 1 | loss: 0.2721123\n",
      "\tspeed: 0.0354s/iter; left time: 306.3129s\n",
      "\titers: 500, epoch: 1 | loss: 0.2334988\n",
      "\tspeed: 0.0381s/iter; left time: 326.4242s\n",
      "\titers: 600, epoch: 1 | loss: 0.2227996\n",
      "\tspeed: 0.0325s/iter; left time: 274.9865s\n",
      "\titers: 700, epoch: 1 | loss: 0.3459783\n",
      "\tspeed: 0.0322s/iter; left time: 268.9289s\n",
      "\titers: 800, epoch: 1 | loss: 0.2465952\n",
      "\tspeed: 0.0332s/iter; left time: 274.1634s\n",
      "\titers: 900, epoch: 1 | loss: 0.1890533\n",
      "\tspeed: 0.0377s/iter; left time: 308.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.20s\n",
      "Steps: 906 | Train Loss: 0.3521562 Vali Loss: 0.2837784 Test Loss: 0.3351012\n",
      "Validation loss decreased (inf --> 0.283778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1369602\n",
      "\tspeed: 0.0999s/iter; left time: 805.0881s\n",
      "\titers: 200, epoch: 2 | loss: 0.2333409\n",
      "\tspeed: 0.0403s/iter; left time: 320.7781s\n",
      "\titers: 300, epoch: 2 | loss: 0.1687464\n",
      "\tspeed: 0.0403s/iter; left time: 316.9220s\n",
      "\titers: 400, epoch: 2 | loss: 0.2259671\n",
      "\tspeed: 0.0432s/iter; left time: 335.0799s\n",
      "\titers: 500, epoch: 2 | loss: 0.1321825\n",
      "\tspeed: 0.0398s/iter; left time: 305.0102s\n",
      "\titers: 600, epoch: 2 | loss: 0.1529523\n",
      "\tspeed: 0.0409s/iter; left time: 309.2151s\n",
      "\titers: 700, epoch: 2 | loss: 0.1427845\n",
      "\tspeed: 0.0404s/iter; left time: 300.9197s\n",
      "\titers: 800, epoch: 2 | loss: 0.2272940\n",
      "\tspeed: 0.0404s/iter; left time: 296.8068s\n",
      "\titers: 900, epoch: 2 | loss: 0.1502392\n",
      "\tspeed: 0.0405s/iter; left time: 293.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.04s\n",
      "Steps: 906 | Train Loss: 0.1839136 Vali Loss: 0.2242827 Test Loss: 0.2588198\n",
      "Validation loss decreased (0.283778 --> 0.224283).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1715890\n",
      "\tspeed: 0.0978s/iter; left time: 698.8574s\n",
      "\titers: 200, epoch: 3 | loss: 0.1321808\n",
      "\tspeed: 0.0400s/iter; left time: 281.6743s\n",
      "\titers: 300, epoch: 3 | loss: 0.1483532\n",
      "\tspeed: 0.0402s/iter; left time: 279.1535s\n",
      "\titers: 400, epoch: 3 | loss: 0.1454668\n",
      "\tspeed: 0.0404s/iter; left time: 276.8472s\n",
      "\titers: 500, epoch: 3 | loss: 0.1974567\n",
      "\tspeed: 0.0398s/iter; left time: 268.3864s\n",
      "\titers: 600, epoch: 3 | loss: 0.1696863\n",
      "\tspeed: 0.0408s/iter; left time: 270.9935s\n",
      "\titers: 700, epoch: 3 | loss: 0.1523357\n",
      "\tspeed: 0.0405s/iter; left time: 265.0208s\n",
      "\titers: 800, epoch: 3 | loss: 0.1443707\n",
      "\tspeed: 0.0410s/iter; left time: 264.6578s\n",
      "\titers: 900, epoch: 3 | loss: 0.1538004\n",
      "\tspeed: 0.0436s/iter; left time: 277.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.1533073 Vali Loss: 0.2284155 Test Loss: 0.2478931\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1093198\n",
      "\tspeed: 0.0950s/iter; left time: 593.1976s\n",
      "\titers: 200, epoch: 4 | loss: 0.1387891\n",
      "\tspeed: 0.0402s/iter; left time: 246.7946s\n",
      "\titers: 300, epoch: 4 | loss: 0.1146336\n",
      "\tspeed: 0.0405s/iter; left time: 244.6846s\n",
      "\titers: 400, epoch: 4 | loss: 0.1190760\n",
      "\tspeed: 0.0404s/iter; left time: 240.1403s\n",
      "\titers: 500, epoch: 4 | loss: 0.1434983\n",
      "\tspeed: 0.0403s/iter; left time: 235.5522s\n",
      "\titers: 600, epoch: 4 | loss: 0.1207120\n",
      "\tspeed: 0.0394s/iter; left time: 226.3982s\n",
      "\titers: 700, epoch: 4 | loss: 0.1220007\n",
      "\tspeed: 0.0388s/iter; left time: 218.8415s\n",
      "\titers: 800, epoch: 4 | loss: 0.1703660\n",
      "\tspeed: 0.0413s/iter; left time: 229.0255s\n",
      "\titers: 900, epoch: 4 | loss: 0.1145186\n",
      "\tspeed: 0.0411s/iter; left time: 223.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.61s\n",
      "Steps: 906 | Train Loss: 0.1316574 Vali Loss: 0.2245228 Test Loss: 0.2522752\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0990685\n",
      "\tspeed: 0.0830s/iter; left time: 443.0504s\n",
      "\titers: 200, epoch: 5 | loss: 0.0903148\n",
      "\tspeed: 0.0302s/iter; left time: 158.3494s\n",
      "\titers: 300, epoch: 5 | loss: 0.1039879\n",
      "\tspeed: 0.0304s/iter; left time: 156.1569s\n",
      "\titers: 400, epoch: 5 | loss: 0.1156793\n",
      "\tspeed: 0.0357s/iter; left time: 179.9279s\n",
      "\titers: 500, epoch: 5 | loss: 0.0939077\n",
      "\tspeed: 0.0406s/iter; left time: 200.4014s\n",
      "\titers: 600, epoch: 5 | loss: 0.1067051\n",
      "\tspeed: 0.0406s/iter; left time: 196.2075s\n",
      "\titers: 700, epoch: 5 | loss: 0.1100522\n",
      "\tspeed: 0.0404s/iter; left time: 191.3231s\n",
      "\titers: 800, epoch: 5 | loss: 0.1199708\n",
      "\tspeed: 0.0404s/iter; left time: 187.2705s\n",
      "\titers: 900, epoch: 5 | loss: 0.1084228\n",
      "\tspeed: 0.0406s/iter; left time: 184.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 906 | Train Loss: 0.1093506 Vali Loss: 0.2453700 Test Loss: 0.2733004\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.25892117619514465, rmse:0.5088430047035217, mae:0.35830968618392944, rse:0.49462392926216125\n",
      "Original data scale mse:20458642.0, rmse:4523.123046875, mae:3016.656982421875, rse:0.2248988002538681\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4966164\n",
      "\tspeed: 0.0423s/iter; left time: 379.2225s\n",
      "\titers: 200, epoch: 1 | loss: 0.3942728\n",
      "\tspeed: 0.0409s/iter; left time: 362.1130s\n",
      "\titers: 300, epoch: 1 | loss: 0.4101226\n",
      "\tspeed: 0.0405s/iter; left time: 355.0102s\n",
      "\titers: 400, epoch: 1 | loss: 0.3164099\n",
      "\tspeed: 0.0416s/iter; left time: 360.5283s\n",
      "\titers: 500, epoch: 1 | loss: 0.2853692\n",
      "\tspeed: 0.0406s/iter; left time: 347.2866s\n",
      "\titers: 600, epoch: 1 | loss: 0.2630173\n",
      "\tspeed: 0.0402s/iter; left time: 339.8587s\n",
      "\titers: 700, epoch: 1 | loss: 0.2321014\n",
      "\tspeed: 0.0402s/iter; left time: 336.4704s\n",
      "\titers: 800, epoch: 1 | loss: 0.2764530\n",
      "\tspeed: 0.0404s/iter; left time: 334.0555s\n",
      "\titers: 900, epoch: 1 | loss: 0.2417925\n",
      "\tspeed: 0.0408s/iter; left time: 333.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.06s\n",
      "Steps: 906 | Train Loss: 0.3609091 Vali Loss: 0.2814071 Test Loss: 0.3389556\n",
      "Validation loss decreased (inf --> 0.281407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2036290\n",
      "\tspeed: 0.1004s/iter; left time: 808.8777s\n",
      "\titers: 200, epoch: 2 | loss: 0.1889317\n",
      "\tspeed: 0.0404s/iter; left time: 321.4373s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521505\n",
      "\tspeed: 0.0405s/iter; left time: 318.1357s\n",
      "\titers: 400, epoch: 2 | loss: 0.1442502\n",
      "\tspeed: 0.0406s/iter; left time: 315.2211s\n",
      "\titers: 500, epoch: 2 | loss: 0.1653206\n",
      "\tspeed: 0.0426s/iter; left time: 325.9240s\n",
      "\titers: 600, epoch: 2 | loss: 0.1897358\n",
      "\tspeed: 0.0460s/iter; left time: 347.6526s\n",
      "\titers: 700, epoch: 2 | loss: 0.1712558\n",
      "\tspeed: 0.0434s/iter; left time: 323.8007s\n",
      "\titers: 800, epoch: 2 | loss: 0.1548272\n",
      "\tspeed: 0.0335s/iter; left time: 246.6527s\n",
      "\titers: 900, epoch: 2 | loss: 0.1804415\n",
      "\tspeed: 0.0372s/iter; left time: 270.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.00s\n",
      "Steps: 906 | Train Loss: 0.1869595 Vali Loss: 0.2361160 Test Loss: 0.2602846\n",
      "Validation loss decreased (0.281407 --> 0.236116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2022747\n",
      "\tspeed: 0.0977s/iter; left time: 698.2814s\n",
      "\titers: 200, epoch: 3 | loss: 0.1417277\n",
      "\tspeed: 0.0320s/iter; left time: 225.9084s\n",
      "\titers: 300, epoch: 3 | loss: 0.1230821\n",
      "\tspeed: 0.0309s/iter; left time: 215.0355s\n",
      "\titers: 400, epoch: 3 | loss: 0.1371556\n",
      "\tspeed: 0.0317s/iter; left time: 217.0210s\n",
      "\titers: 500, epoch: 3 | loss: 0.1450782\n",
      "\tspeed: 0.0369s/iter; left time: 248.9286s\n",
      "\titers: 600, epoch: 3 | loss: 0.1288812\n",
      "\tspeed: 0.0379s/iter; left time: 252.1479s\n",
      "\titers: 700, epoch: 3 | loss: 0.1775876\n",
      "\tspeed: 0.0329s/iter; left time: 215.1863s\n",
      "\titers: 800, epoch: 3 | loss: 0.1696465\n",
      "\tspeed: 0.0344s/iter; left time: 221.9881s\n",
      "\titers: 900, epoch: 3 | loss: 0.1122214\n",
      "\tspeed: 0.0380s/iter; left time: 240.9934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.80s\n",
      "Steps: 906 | Train Loss: 0.1547121 Vali Loss: 0.2188322 Test Loss: 0.2404817\n",
      "Validation loss decreased (0.236116 --> 0.218832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1234310\n",
      "\tspeed: 0.0977s/iter; left time: 609.6995s\n",
      "\titers: 200, epoch: 4 | loss: 0.1373686\n",
      "\tspeed: 0.0366s/iter; left time: 225.0563s\n",
      "\titers: 300, epoch: 4 | loss: 0.1926513\n",
      "\tspeed: 0.0375s/iter; left time: 226.8003s\n",
      "\titers: 400, epoch: 4 | loss: 0.1139159\n",
      "\tspeed: 0.0380s/iter; left time: 225.7806s\n",
      "\titers: 500, epoch: 4 | loss: 0.1539346\n",
      "\tspeed: 0.0373s/iter; left time: 217.9122s\n",
      "\titers: 600, epoch: 4 | loss: 0.1449407\n",
      "\tspeed: 0.0375s/iter; left time: 215.1549s\n",
      "\titers: 700, epoch: 4 | loss: 0.1607359\n",
      "\tspeed: 0.0386s/iter; left time: 218.0108s\n",
      "\titers: 800, epoch: 4 | loss: 0.0864749\n",
      "\tspeed: 0.0378s/iter; left time: 209.2507s\n",
      "\titers: 900, epoch: 4 | loss: 0.0848118\n",
      "\tspeed: 0.0370s/iter; left time: 201.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.25s\n",
      "Steps: 906 | Train Loss: 0.1330943 Vali Loss: 0.2275613 Test Loss: 0.2438716\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1344619\n",
      "\tspeed: 0.1005s/iter; left time: 536.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.0850486\n",
      "\tspeed: 0.0389s/iter; left time: 203.5588s\n",
      "\titers: 300, epoch: 5 | loss: 0.0993451\n",
      "\tspeed: 0.0395s/iter; left time: 202.7753s\n",
      "\titers: 400, epoch: 5 | loss: 0.1076651\n",
      "\tspeed: 0.0439s/iter; left time: 220.8951s\n",
      "\titers: 500, epoch: 5 | loss: 0.0834811\n",
      "\tspeed: 0.0425s/iter; left time: 209.7423s\n",
      "\titers: 600, epoch: 5 | loss: 0.1155935\n",
      "\tspeed: 0.0444s/iter; left time: 214.6402s\n",
      "\titers: 700, epoch: 5 | loss: 0.0924196\n",
      "\tspeed: 0.0408s/iter; left time: 193.2083s\n",
      "\titers: 800, epoch: 5 | loss: 0.1086210\n",
      "\tspeed: 0.0418s/iter; left time: 193.8174s\n",
      "\titers: 900, epoch: 5 | loss: 0.0984064\n",
      "\tspeed: 0.0412s/iter; left time: 187.1006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.1108767 Vali Loss: 0.2400857 Test Loss: 0.2565831\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821117\n",
      "\tspeed: 0.0995s/iter; left time: 441.0534s\n",
      "\titers: 200, epoch: 6 | loss: 0.1051194\n",
      "\tspeed: 0.0451s/iter; left time: 195.3229s\n",
      "\titers: 300, epoch: 6 | loss: 0.1453785\n",
      "\tspeed: 0.0439s/iter; left time: 185.8644s\n",
      "\titers: 400, epoch: 6 | loss: 0.0906615\n",
      "\tspeed: 0.0456s/iter; left time: 188.2250s\n",
      "\titers: 500, epoch: 6 | loss: 0.0889096\n",
      "\tspeed: 0.0415s/iter; left time: 167.4831s\n",
      "\titers: 600, epoch: 6 | loss: 0.0854225\n",
      "\tspeed: 0.0398s/iter; left time: 156.6141s\n",
      "\titers: 700, epoch: 6 | loss: 0.1034291\n",
      "\tspeed: 0.0431s/iter; left time: 164.9790s\n",
      "\titers: 800, epoch: 6 | loss: 0.0754498\n",
      "\tspeed: 0.0403s/iter; left time: 150.2563s\n",
      "\titers: 900, epoch: 6 | loss: 0.0861971\n",
      "\tspeed: 0.0407s/iter; left time: 147.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 906 | Train Loss: 0.0925012 Vali Loss: 0.2468222 Test Loss: 0.2661139\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23997162282466888, rmse:0.48986899852752686, mae:0.3382326066493988, rse:0.47618016600608826\n",
      "Original data scale mse:18265502.0, rmse:4273.81591796875, mae:2791.9541015625, rse:0.21250274777412415\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6546724\n",
      "\tspeed: 0.0762s/iter; left time: 681.6704s\n",
      "\titers: 200, epoch: 1 | loss: 0.5917277\n",
      "\tspeed: 0.0450s/iter; left time: 397.5332s\n",
      "\titers: 300, epoch: 1 | loss: 0.5455086\n",
      "\tspeed: 0.0462s/iter; left time: 404.1082s\n",
      "\titers: 400, epoch: 1 | loss: 0.4482757\n",
      "\tspeed: 0.0462s/iter; left time: 399.0896s\n",
      "\titers: 500, epoch: 1 | loss: 0.4275625\n",
      "\tspeed: 0.0449s/iter; left time: 383.7808s\n",
      "\titers: 600, epoch: 1 | loss: 0.3429817\n",
      "\tspeed: 0.0461s/iter; left time: 389.2570s\n",
      "\titers: 700, epoch: 1 | loss: 0.3445232\n",
      "\tspeed: 0.0466s/iter; left time: 388.9749s\n",
      "\titers: 800, epoch: 1 | loss: 0.3594815\n",
      "\tspeed: 0.0466s/iter; left time: 383.7271s\n",
      "\titers: 900, epoch: 1 | loss: 0.3681027\n",
      "\tspeed: 0.0465s/iter; left time: 378.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.54s\n",
      "Steps: 904 | Train Loss: 0.4762494 Vali Loss: 0.4285059 Test Loss: 0.5598444\n",
      "Validation loss decreased (inf --> 0.428506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2989585\n",
      "\tspeed: 0.1190s/iter; left time: 956.7349s\n",
      "\titers: 200, epoch: 2 | loss: 0.3341390\n",
      "\tspeed: 0.0460s/iter; left time: 364.9507s\n",
      "\titers: 300, epoch: 2 | loss: 0.3089204\n",
      "\tspeed: 0.0463s/iter; left time: 362.8152s\n",
      "\titers: 400, epoch: 2 | loss: 0.2703228\n",
      "\tspeed: 0.0464s/iter; left time: 358.9036s\n",
      "\titers: 500, epoch: 2 | loss: 0.2890018\n",
      "\tspeed: 0.0443s/iter; left time: 338.4020s\n",
      "\titers: 600, epoch: 2 | loss: 0.3287902\n",
      "\tspeed: 0.0464s/iter; left time: 350.0071s\n",
      "\titers: 700, epoch: 2 | loss: 0.2626685\n",
      "\tspeed: 0.0479s/iter; left time: 356.2692s\n",
      "\titers: 800, epoch: 2 | loss: 0.3108012\n",
      "\tspeed: 0.0495s/iter; left time: 362.8964s\n",
      "\titers: 900, epoch: 2 | loss: 0.2511025\n",
      "\tspeed: 0.0496s/iter; left time: 359.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.3040894 Vali Loss: 0.3595099 Test Loss: 0.4340324\n",
      "Validation loss decreased (0.428506 --> 0.359510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3092229\n",
      "\tspeed: 0.1213s/iter; left time: 864.9135s\n",
      "\titers: 200, epoch: 3 | loss: 0.2202515\n",
      "\tspeed: 0.0474s/iter; left time: 333.2600s\n",
      "\titers: 300, epoch: 3 | loss: 0.2092332\n",
      "\tspeed: 0.0475s/iter; left time: 329.3006s\n",
      "\titers: 400, epoch: 3 | loss: 0.2289536\n",
      "\tspeed: 0.0450s/iter; left time: 307.3094s\n",
      "\titers: 500, epoch: 3 | loss: 0.2403625\n",
      "\tspeed: 0.0468s/iter; left time: 314.8969s\n",
      "\titers: 600, epoch: 3 | loss: 0.2494952\n",
      "\tspeed: 0.0444s/iter; left time: 294.5056s\n",
      "\titers: 700, epoch: 3 | loss: 0.2256481\n",
      "\tspeed: 0.0466s/iter; left time: 304.6591s\n",
      "\titers: 800, epoch: 3 | loss: 0.2503496\n",
      "\tspeed: 0.0499s/iter; left time: 321.2960s\n",
      "\titers: 900, epoch: 3 | loss: 0.2428420\n",
      "\tspeed: 0.0471s/iter; left time: 298.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.2430000 Vali Loss: 0.3543893 Test Loss: 0.4415607\n",
      "Validation loss decreased (0.359510 --> 0.354389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1979982\n",
      "\tspeed: 0.1164s/iter; left time: 724.8426s\n",
      "\titers: 200, epoch: 4 | loss: 0.2111989\n",
      "\tspeed: 0.0435s/iter; left time: 266.4801s\n",
      "\titers: 300, epoch: 4 | loss: 0.1935357\n",
      "\tspeed: 0.0433s/iter; left time: 261.1182s\n",
      "\titers: 400, epoch: 4 | loss: 0.1566828\n",
      "\tspeed: 0.0433s/iter; left time: 256.5897s\n",
      "\titers: 500, epoch: 4 | loss: 0.2228490\n",
      "\tspeed: 0.0427s/iter; left time: 249.1554s\n",
      "\titers: 600, epoch: 4 | loss: 0.1653641\n",
      "\tspeed: 0.0442s/iter; left time: 253.1142s\n",
      "\titers: 700, epoch: 4 | loss: 0.2101256\n",
      "\tspeed: 0.0439s/iter; left time: 247.1517s\n",
      "\titers: 800, epoch: 4 | loss: 0.1827935\n",
      "\tspeed: 0.0430s/iter; left time: 237.9455s\n",
      "\titers: 900, epoch: 4 | loss: 0.2207310\n",
      "\tspeed: 0.0439s/iter; left time: 238.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.60s\n",
      "Steps: 904 | Train Loss: 0.2000465 Vali Loss: 0.3768986 Test Loss: 0.4664588\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1634137\n",
      "\tspeed: 0.1114s/iter; left time: 593.1064s\n",
      "\titers: 200, epoch: 5 | loss: 0.2103482\n",
      "\tspeed: 0.0460s/iter; left time: 240.4412s\n",
      "\titers: 300, epoch: 5 | loss: 0.1699097\n",
      "\tspeed: 0.0483s/iter; left time: 247.5357s\n",
      "\titers: 400, epoch: 5 | loss: 0.1680366\n",
      "\tspeed: 0.0467s/iter; left time: 234.5862s\n",
      "\titers: 500, epoch: 5 | loss: 0.1486269\n",
      "\tspeed: 0.0462s/iter; left time: 227.7463s\n",
      "\titers: 600, epoch: 5 | loss: 0.1546813\n",
      "\tspeed: 0.0426s/iter; left time: 205.6913s\n",
      "\titers: 700, epoch: 5 | loss: 0.1439729\n",
      "\tspeed: 0.0425s/iter; left time: 201.0203s\n",
      "\titers: 800, epoch: 5 | loss: 0.1317349\n",
      "\tspeed: 0.0439s/iter; left time: 202.8822s\n",
      "\titers: 900, epoch: 5 | loss: 0.1457338\n",
      "\tspeed: 0.0440s/iter; left time: 199.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.06s\n",
      "Steps: 904 | Train Loss: 0.1641401 Vali Loss: 0.3885486 Test Loss: 0.4919951\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1399367\n",
      "\tspeed: 0.1160s/iter; left time: 512.7463s\n",
      "\titers: 200, epoch: 6 | loss: 0.1144286\n",
      "\tspeed: 0.0407s/iter; left time: 175.9932s\n",
      "\titers: 300, epoch: 6 | loss: 0.1403850\n",
      "\tspeed: 0.0428s/iter; left time: 180.5859s\n",
      "\titers: 400, epoch: 6 | loss: 0.1323826\n",
      "\tspeed: 0.0413s/iter; left time: 170.1083s\n",
      "\titers: 500, epoch: 6 | loss: 0.1317175\n",
      "\tspeed: 0.0417s/iter; left time: 167.7451s\n",
      "\titers: 600, epoch: 6 | loss: 0.1453847\n",
      "\tspeed: 0.0415s/iter; left time: 162.6731s\n",
      "\titers: 700, epoch: 6 | loss: 0.1293670\n",
      "\tspeed: 0.0461s/iter; left time: 176.2985s\n",
      "\titers: 800, epoch: 6 | loss: 0.1634474\n",
      "\tspeed: 0.0474s/iter; left time: 176.4694s\n",
      "\titers: 900, epoch: 6 | loss: 0.1342661\n",
      "\tspeed: 0.0473s/iter; left time: 171.1382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 904 | Train Loss: 0.1395794 Vali Loss: 0.4038204 Test Loss: 0.5043370\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4419127106666565, rmse:0.6647651791572571, mae:0.4733096659183502, rse:0.646569013595581\n",
      "Original data scale mse:36498908.0, rmse:6041.4326171875, mae:3972.61376953125, rse:0.3008655309677124\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6162369\n",
      "\tspeed: 0.0452s/iter; left time: 403.9180s\n",
      "\titers: 200, epoch: 1 | loss: 0.5928781\n",
      "\tspeed: 0.0479s/iter; left time: 423.3046s\n",
      "\titers: 300, epoch: 1 | loss: 0.4926288\n",
      "\tspeed: 0.0481s/iter; left time: 420.5127s\n",
      "\titers: 400, epoch: 1 | loss: 0.4147618\n",
      "\tspeed: 0.0392s/iter; left time: 338.3812s\n",
      "\titers: 500, epoch: 1 | loss: 0.4681771\n",
      "\tspeed: 0.0377s/iter; left time: 322.2926s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539061\n",
      "\tspeed: 0.0476s/iter; left time: 401.6178s\n",
      "\titers: 700, epoch: 1 | loss: 0.3761141\n",
      "\tspeed: 0.0476s/iter; left time: 397.0902s\n",
      "\titers: 800, epoch: 1 | loss: 0.4220415\n",
      "\tspeed: 0.0475s/iter; left time: 391.3020s\n",
      "\titers: 900, epoch: 1 | loss: 0.3255250\n",
      "\tspeed: 0.0475s/iter; left time: 386.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 904 | Train Loss: 0.4757864 Vali Loss: 0.4285903 Test Loss: 0.5639002\n",
      "Validation loss decreased (inf --> 0.428590).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3665039\n",
      "\tspeed: 0.1175s/iter; left time: 944.4311s\n",
      "\titers: 200, epoch: 2 | loss: 0.3647703\n",
      "\tspeed: 0.0474s/iter; left time: 376.1827s\n",
      "\titers: 300, epoch: 2 | loss: 0.2680736\n",
      "\tspeed: 0.0472s/iter; left time: 369.7283s\n",
      "\titers: 400, epoch: 2 | loss: 0.2768405\n",
      "\tspeed: 0.0472s/iter; left time: 365.3940s\n",
      "\titers: 500, epoch: 2 | loss: 0.2867185\n",
      "\tspeed: 0.0472s/iter; left time: 360.4352s\n",
      "\titers: 600, epoch: 2 | loss: 0.2977949\n",
      "\tspeed: 0.0474s/iter; left time: 357.5699s\n",
      "\titers: 700, epoch: 2 | loss: 0.2797135\n",
      "\tspeed: 0.0474s/iter; left time: 352.3078s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295987\n",
      "\tspeed: 0.0473s/iter; left time: 347.0406s\n",
      "\titers: 900, epoch: 2 | loss: 0.2671846\n",
      "\tspeed: 0.0469s/iter; left time: 339.2475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.3036662 Vali Loss: 0.3695144 Test Loss: 0.4423220\n",
      "Validation loss decreased (0.428590 --> 0.369514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2837098\n",
      "\tspeed: 0.1173s/iter; left time: 836.5372s\n",
      "\titers: 200, epoch: 3 | loss: 0.2514321\n",
      "\tspeed: 0.0478s/iter; left time: 336.5144s\n",
      "\titers: 300, epoch: 3 | loss: 0.2103887\n",
      "\tspeed: 0.0429s/iter; left time: 297.6180s\n",
      "\titers: 400, epoch: 3 | loss: 0.2059026\n",
      "\tspeed: 0.0479s/iter; left time: 327.1647s\n",
      "\titers: 500, epoch: 3 | loss: 0.1989901\n",
      "\tspeed: 0.0478s/iter; left time: 321.6039s\n",
      "\titers: 600, epoch: 3 | loss: 0.2754957\n",
      "\tspeed: 0.0477s/iter; left time: 316.5512s\n",
      "\titers: 700, epoch: 3 | loss: 0.2409394\n",
      "\tspeed: 0.0478s/iter; left time: 312.2856s\n",
      "\titers: 800, epoch: 3 | loss: 0.2474875\n",
      "\tspeed: 0.0475s/iter; left time: 305.8016s\n",
      "\titers: 900, epoch: 3 | loss: 0.1864163\n",
      "\tspeed: 0.0478s/iter; left time: 302.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.2469032 Vali Loss: 0.3693818 Test Loss: 0.5008774\n",
      "Validation loss decreased (0.369514 --> 0.369382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1604201\n",
      "\tspeed: 0.1201s/iter; left time: 748.1303s\n",
      "\titers: 200, epoch: 4 | loss: 0.2122452\n",
      "\tspeed: 0.0480s/iter; left time: 294.2486s\n",
      "\titers: 300, epoch: 4 | loss: 0.2110735\n",
      "\tspeed: 0.0479s/iter; left time: 288.9838s\n",
      "\titers: 400, epoch: 4 | loss: 0.1941804\n",
      "\tspeed: 0.0480s/iter; left time: 284.6908s\n",
      "\titers: 500, epoch: 4 | loss: 0.2281753\n",
      "\tspeed: 0.0478s/iter; left time: 278.9157s\n",
      "\titers: 600, epoch: 4 | loss: 0.1882456\n",
      "\tspeed: 0.0478s/iter; left time: 273.9929s\n",
      "\titers: 700, epoch: 4 | loss: 0.2477907\n",
      "\tspeed: 0.0479s/iter; left time: 269.5466s\n",
      "\titers: 800, epoch: 4 | loss: 0.1979517\n",
      "\tspeed: 0.0480s/iter; left time: 265.4489s\n",
      "\titers: 900, epoch: 4 | loss: 0.1732447\n",
      "\tspeed: 0.0479s/iter; left time: 259.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.65s\n",
      "Steps: 904 | Train Loss: 0.2056369 Vali Loss: 0.3753512 Test Loss: 0.4872772\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1660488\n",
      "\tspeed: 0.1138s/iter; left time: 606.2151s\n",
      "\titers: 200, epoch: 5 | loss: 0.1781305\n",
      "\tspeed: 0.0479s/iter; left time: 250.0496s\n",
      "\titers: 300, epoch: 5 | loss: 0.1806497\n",
      "\tspeed: 0.0479s/iter; left time: 245.7192s\n",
      "\titers: 400, epoch: 5 | loss: 0.1743275\n",
      "\tspeed: 0.0478s/iter; left time: 240.3583s\n",
      "\titers: 500, epoch: 5 | loss: 0.1676579\n",
      "\tspeed: 0.0481s/iter; left time: 236.7245s\n",
      "\titers: 600, epoch: 5 | loss: 0.1889997\n",
      "\tspeed: 0.0480s/iter; left time: 231.4133s\n",
      "\titers: 700, epoch: 5 | loss: 0.1634367\n",
      "\tspeed: 0.0480s/iter; left time: 226.5826s\n",
      "\titers: 800, epoch: 5 | loss: 0.1637001\n",
      "\tspeed: 0.0478s/iter; left time: 221.0903s\n",
      "\titers: 900, epoch: 5 | loss: 0.1383694\n",
      "\tspeed: 0.0479s/iter; left time: 216.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.1678519 Vali Loss: 0.3705670 Test Loss: 0.4764751\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1255683\n",
      "\tspeed: 0.1140s/iter; left time: 504.0310s\n",
      "\titers: 200, epoch: 6 | loss: 0.1423870\n",
      "\tspeed: 0.0477s/iter; left time: 206.3230s\n",
      "\titers: 300, epoch: 6 | loss: 0.1751436\n",
      "\tspeed: 0.0477s/iter; left time: 201.4837s\n",
      "\titers: 400, epoch: 6 | loss: 0.1283779\n",
      "\tspeed: 0.0477s/iter; left time: 196.7157s\n",
      "\titers: 500, epoch: 6 | loss: 0.1471216\n",
      "\tspeed: 0.0478s/iter; left time: 192.2720s\n",
      "\titers: 600, epoch: 6 | loss: 0.1371356\n",
      "\tspeed: 0.0478s/iter; left time: 187.4798s\n",
      "\titers: 700, epoch: 6 | loss: 0.1250925\n",
      "\tspeed: 0.0473s/iter; left time: 180.8255s\n",
      "\titers: 800, epoch: 6 | loss: 0.1131927\n",
      "\tspeed: 0.0479s/iter; left time: 178.1336s\n",
      "\titers: 900, epoch: 6 | loss: 0.1198367\n",
      "\tspeed: 0.0465s/iter; left time: 168.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.1412776 Vali Loss: 0.3726344 Test Loss: 0.5208377\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.5002959370613098, rmse:0.707315981388092, mae:0.5115302801132202, rse:0.6879551410675049\n",
      "Original data scale mse:42418092.0, rmse:6512.91748046875, mae:4375.43310546875, rse:0.3243456184864044\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5661607\n",
      "\tspeed: 0.0834s/iter; left time: 744.4359s\n",
      "\titers: 200, epoch: 1 | loss: 0.5773467\n",
      "\tspeed: 0.0534s/iter; left time: 470.8143s\n",
      "\titers: 300, epoch: 1 | loss: 0.5367654\n",
      "\tspeed: 0.0534s/iter; left time: 466.0954s\n",
      "\titers: 400, epoch: 1 | loss: 0.5356638\n",
      "\tspeed: 0.0535s/iter; left time: 461.1928s\n",
      "\titers: 500, epoch: 1 | loss: 0.5021951\n",
      "\tspeed: 0.0537s/iter; left time: 457.5255s\n",
      "\titers: 600, epoch: 1 | loss: 0.5039054\n",
      "\tspeed: 0.0537s/iter; left time: 452.0268s\n",
      "\titers: 700, epoch: 1 | loss: 0.4795872\n",
      "\tspeed: 0.0537s/iter; left time: 447.0132s\n",
      "\titers: 800, epoch: 1 | loss: 0.4552305\n",
      "\tspeed: 0.0535s/iter; left time: 440.0517s\n",
      "\titers: 900, epoch: 1 | loss: 0.4847772\n",
      "\tspeed: 0.0536s/iter; left time: 435.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.01s\n",
      "Steps: 902 | Train Loss: 0.5303793 Vali Loss: 0.5360001 Test Loss: 0.7330878\n",
      "Validation loss decreased (inf --> 0.536000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4942363\n",
      "\tspeed: 0.1341s/iter; left time: 1075.5835s\n",
      "\titers: 200, epoch: 2 | loss: 0.4150608\n",
      "\tspeed: 0.0535s/iter; left time: 423.7173s\n",
      "\titers: 300, epoch: 2 | loss: 0.4309613\n",
      "\tspeed: 0.0537s/iter; left time: 419.6996s\n",
      "\titers: 400, epoch: 2 | loss: 0.3440691\n",
      "\tspeed: 0.0536s/iter; left time: 413.6222s\n",
      "\titers: 500, epoch: 2 | loss: 0.3228416\n",
      "\tspeed: 0.0535s/iter; left time: 407.7934s\n",
      "\titers: 600, epoch: 2 | loss: 0.2760397\n",
      "\tspeed: 0.0537s/iter; left time: 403.4280s\n",
      "\titers: 700, epoch: 2 | loss: 0.2734423\n",
      "\tspeed: 0.0536s/iter; left time: 397.8374s\n",
      "\titers: 800, epoch: 2 | loss: 0.3485744\n",
      "\tspeed: 0.0537s/iter; left time: 392.7331s\n",
      "\titers: 900, epoch: 2 | loss: 0.2771853\n",
      "\tspeed: 0.0533s/iter; left time: 384.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.3442728 Vali Loss: 0.3790651 Test Loss: 0.4672030\n",
      "Validation loss decreased (0.536000 --> 0.379065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2745140\n",
      "\tspeed: 0.1337s/iter; left time: 951.7490s\n",
      "\titers: 200, epoch: 3 | loss: 0.2703827\n",
      "\tspeed: 0.0536s/iter; left time: 376.1864s\n",
      "\titers: 300, epoch: 3 | loss: 0.2475511\n",
      "\tspeed: 0.0536s/iter; left time: 370.7523s\n",
      "\titers: 400, epoch: 3 | loss: 0.2924908\n",
      "\tspeed: 0.0538s/iter; left time: 366.7699s\n",
      "\titers: 500, epoch: 3 | loss: 0.2411224\n",
      "\tspeed: 0.0536s/iter; left time: 360.0040s\n",
      "\titers: 600, epoch: 3 | loss: 0.2614779\n",
      "\tspeed: 0.0537s/iter; left time: 355.1677s\n",
      "\titers: 700, epoch: 3 | loss: 0.2655052\n",
      "\tspeed: 0.0537s/iter; left time: 350.2530s\n",
      "\titers: 800, epoch: 3 | loss: 0.2397417\n",
      "\tspeed: 0.0537s/iter; left time: 344.5468s\n",
      "\titers: 900, epoch: 3 | loss: 0.2333572\n",
      "\tspeed: 0.0536s/iter; left time: 338.4147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.2522247 Vali Loss: 0.4058542 Test Loss: 0.4791397\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2076626\n",
      "\tspeed: 0.1290s/iter; left time: 801.9073s\n",
      "\titers: 200, epoch: 4 | loss: 0.1823039\n",
      "\tspeed: 0.0535s/iter; left time: 326.8779s\n",
      "\titers: 300, epoch: 4 | loss: 0.2445515\n",
      "\tspeed: 0.0535s/iter; left time: 321.6321s\n",
      "\titers: 400, epoch: 4 | loss: 0.2183089\n",
      "\tspeed: 0.0534s/iter; left time: 315.8086s\n",
      "\titers: 500, epoch: 4 | loss: 0.2147775\n",
      "\tspeed: 0.0537s/iter; left time: 312.3732s\n",
      "\titers: 600, epoch: 4 | loss: 0.1803208\n",
      "\tspeed: 0.0534s/iter; left time: 305.3755s\n",
      "\titers: 700, epoch: 4 | loss: 0.2064019\n",
      "\tspeed: 0.0535s/iter; left time: 300.5236s\n",
      "\titers: 800, epoch: 4 | loss: 0.2078039\n",
      "\tspeed: 0.0536s/iter; left time: 295.4519s\n",
      "\titers: 900, epoch: 4 | loss: 0.1913311\n",
      "\tspeed: 0.0536s/iter; left time: 290.4280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.2068389 Vali Loss: 0.4290836 Test Loss: 0.5045133\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2150669\n",
      "\tspeed: 0.1302s/iter; left time: 691.5577s\n",
      "\titers: 200, epoch: 5 | loss: 0.1831185\n",
      "\tspeed: 0.0544s/iter; left time: 283.6110s\n",
      "\titers: 300, epoch: 5 | loss: 0.1753126\n",
      "\tspeed: 0.0545s/iter; left time: 278.8622s\n",
      "\titers: 400, epoch: 5 | loss: 0.1991033\n",
      "\tspeed: 0.0537s/iter; left time: 269.3088s\n",
      "\titers: 500, epoch: 5 | loss: 0.1462441\n",
      "\tspeed: 0.0544s/iter; left time: 267.3069s\n",
      "\titers: 600, epoch: 5 | loss: 0.1777929\n",
      "\tspeed: 0.0533s/iter; left time: 256.7189s\n",
      "\titers: 700, epoch: 5 | loss: 0.1745093\n",
      "\tspeed: 0.0534s/iter; left time: 251.7675s\n",
      "\titers: 800, epoch: 5 | loss: 0.1517237\n",
      "\tspeed: 0.0535s/iter; left time: 246.9778s\n",
      "\titers: 900, epoch: 5 | loss: 0.1393686\n",
      "\tspeed: 0.0535s/iter; left time: 241.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.82s\n",
      "Steps: 902 | Train Loss: 0.1729458 Vali Loss: 0.4391145 Test Loss: 0.5485419\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4672527015209198, rmse:0.6835588216781616, mae:0.5047345757484436, rse:0.6628128290176392\n",
      "Original data scale mse:39235132.0, rmse:6263.79541015625, mae:4307.79296875, rse:0.3120923936367035\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7005892\n",
      "\tspeed: 0.0559s/iter; left time: 498.8072s\n",
      "\titers: 200, epoch: 1 | loss: 0.5440720\n",
      "\tspeed: 0.0540s/iter; left time: 475.9243s\n",
      "\titers: 300, epoch: 1 | loss: 0.4664656\n",
      "\tspeed: 0.0540s/iter; left time: 470.8347s\n",
      "\titers: 400, epoch: 1 | loss: 0.5177964\n",
      "\tspeed: 0.0538s/iter; left time: 464.0242s\n",
      "\titers: 500, epoch: 1 | loss: 0.4846527\n",
      "\tspeed: 0.0538s/iter; left time: 458.6007s\n",
      "\titers: 600, epoch: 1 | loss: 0.5070472\n",
      "\tspeed: 0.0543s/iter; left time: 457.4081s\n",
      "\titers: 700, epoch: 1 | loss: 0.5154229\n",
      "\tspeed: 0.0544s/iter; left time: 452.4743s\n",
      "\titers: 800, epoch: 1 | loss: 0.4440692\n",
      "\tspeed: 0.0541s/iter; left time: 444.4924s\n",
      "\titers: 900, epoch: 1 | loss: 0.4513678\n",
      "\tspeed: 0.0539s/iter; left time: 437.4451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.00s\n",
      "Steps: 902 | Train Loss: 0.5260653 Vali Loss: 0.5406291 Test Loss: 0.7387776\n",
      "Validation loss decreased (inf --> 0.540629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4946011\n",
      "\tspeed: 0.1333s/iter; left time: 1068.9107s\n",
      "\titers: 200, epoch: 2 | loss: 0.3835197\n",
      "\tspeed: 0.0538s/iter; left time: 425.6792s\n",
      "\titers: 300, epoch: 2 | loss: 0.4058985\n",
      "\tspeed: 0.0536s/iter; left time: 419.1813s\n",
      "\titers: 400, epoch: 2 | loss: 0.2835086\n",
      "\tspeed: 0.0535s/iter; left time: 412.9563s\n",
      "\titers: 500, epoch: 2 | loss: 0.3513405\n",
      "\tspeed: 0.0536s/iter; left time: 408.5779s\n",
      "\titers: 600, epoch: 2 | loss: 0.2929164\n",
      "\tspeed: 0.0536s/iter; left time: 402.6733s\n",
      "\titers: 700, epoch: 2 | loss: 0.3086975\n",
      "\tspeed: 0.0536s/iter; left time: 397.4702s\n",
      "\titers: 800, epoch: 2 | loss: 0.2758642\n",
      "\tspeed: 0.0537s/iter; left time: 392.7753s\n",
      "\titers: 900, epoch: 2 | loss: 0.2786883\n",
      "\tspeed: 0.0535s/iter; left time: 386.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.3549529 Vali Loss: 0.3977152 Test Loss: 0.4635265\n",
      "Validation loss decreased (0.540629 --> 0.397715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2768619\n",
      "\tspeed: 0.1347s/iter; left time: 958.7518s\n",
      "\titers: 200, epoch: 3 | loss: 0.2381207\n",
      "\tspeed: 0.0536s/iter; left time: 376.1993s\n",
      "\titers: 300, epoch: 3 | loss: 0.2398777\n",
      "\tspeed: 0.0535s/iter; left time: 370.0418s\n",
      "\titers: 400, epoch: 3 | loss: 0.2269317\n",
      "\tspeed: 0.0537s/iter; left time: 365.9528s\n",
      "\titers: 500, epoch: 3 | loss: 0.2643320\n",
      "\tspeed: 0.0536s/iter; left time: 359.8064s\n",
      "\titers: 600, epoch: 3 | loss: 0.2446325\n",
      "\tspeed: 0.0534s/iter; left time: 353.3040s\n",
      "\titers: 700, epoch: 3 | loss: 0.2594030\n",
      "\tspeed: 0.0534s/iter; left time: 348.2019s\n",
      "\titers: 800, epoch: 3 | loss: 0.2039291\n",
      "\tspeed: 0.0535s/iter; left time: 343.6192s\n",
      "\titers: 900, epoch: 3 | loss: 0.2343226\n",
      "\tspeed: 0.0536s/iter; left time: 338.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.2570016 Vali Loss: 0.4234625 Test Loss: 0.4815665\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1915036\n",
      "\tspeed: 0.1295s/iter; left time: 804.7385s\n",
      "\titers: 200, epoch: 4 | loss: 0.2288480\n",
      "\tspeed: 0.0538s/iter; left time: 329.1341s\n",
      "\titers: 300, epoch: 4 | loss: 0.2517293\n",
      "\tspeed: 0.0537s/iter; left time: 322.9278s\n",
      "\titers: 400, epoch: 4 | loss: 0.2164890\n",
      "\tspeed: 0.0537s/iter; left time: 317.7915s\n",
      "\titers: 500, epoch: 4 | loss: 0.2290688\n",
      "\tspeed: 0.0536s/iter; left time: 311.9111s\n",
      "\titers: 600, epoch: 4 | loss: 0.2107725\n",
      "\tspeed: 0.0536s/iter; left time: 306.3217s\n",
      "\titers: 700, epoch: 4 | loss: 0.2010569\n",
      "\tspeed: 0.0537s/iter; left time: 301.6399s\n",
      "\titers: 800, epoch: 4 | loss: 0.1858583\n",
      "\tspeed: 0.0535s/iter; left time: 294.7926s\n",
      "\titers: 900, epoch: 4 | loss: 0.1948081\n",
      "\tspeed: 0.0538s/iter; left time: 291.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.2112538 Vali Loss: 0.4369511 Test Loss: 0.5081213\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1695156\n",
      "\tspeed: 0.1295s/iter; left time: 687.8829s\n",
      "\titers: 200, epoch: 5 | loss: 0.1669810\n",
      "\tspeed: 0.0537s/iter; left time: 279.8404s\n",
      "\titers: 300, epoch: 5 | loss: 0.1833070\n",
      "\tspeed: 0.0537s/iter; left time: 274.5467s\n",
      "\titers: 400, epoch: 5 | loss: 0.1643036\n",
      "\tspeed: 0.0538s/iter; left time: 269.5751s\n",
      "\titers: 500, epoch: 5 | loss: 0.1790071\n",
      "\tspeed: 0.0535s/iter; left time: 262.9803s\n",
      "\titers: 600, epoch: 5 | loss: 0.1698678\n",
      "\tspeed: 0.0538s/iter; left time: 258.7818s\n",
      "\titers: 700, epoch: 5 | loss: 0.1591146\n",
      "\tspeed: 0.0538s/iter; left time: 253.6107s\n",
      "\titers: 800, epoch: 5 | loss: 0.1756431\n",
      "\tspeed: 0.0539s/iter; left time: 248.6112s\n",
      "\titers: 900, epoch: 5 | loss: 0.1827278\n",
      "\tspeed: 0.0534s/iter; left time: 240.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.1758139 Vali Loss: 0.4381305 Test Loss: 0.5416551\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4635637104511261, rmse:0.6808551549911499, mae:0.5041408538818359, rse:0.6601911783218384\n",
      "Original data scale mse:37890544.0, rmse:6155.52978515625, mae:4260.3515625, rse:0.3066980540752411\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7461114\n",
      "\tspeed: 0.0729s/iter; left time: 653.2421s\n",
      "\titers: 200, epoch: 1 | loss: 0.6529073\n",
      "\tspeed: 0.0452s/iter; left time: 400.7829s\n",
      "\titers: 300, epoch: 1 | loss: 0.5782019\n",
      "\tspeed: 0.0447s/iter; left time: 391.2271s\n",
      "\titers: 400, epoch: 1 | loss: 0.4998610\n",
      "\tspeed: 0.0417s/iter; left time: 361.1327s\n",
      "\titers: 500, epoch: 1 | loss: 0.4716066\n",
      "\tspeed: 0.0422s/iter; left time: 361.3435s\n",
      "\titers: 600, epoch: 1 | loss: 0.4612486\n",
      "\tspeed: 0.0420s/iter; left time: 355.2164s\n",
      "\titers: 700, epoch: 1 | loss: 0.5836230\n",
      "\tspeed: 0.0412s/iter; left time: 344.5760s\n",
      "\titers: 800, epoch: 1 | loss: 0.4892212\n",
      "\tspeed: 0.0417s/iter; left time: 344.8892s\n",
      "\titers: 900, epoch: 1 | loss: 0.4281857\n",
      "\tspeed: 0.0425s/iter; left time: 347.0908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.37s\n",
      "Steps: 906 | Train Loss: 0.5736664 Vali Loss: 0.2776520 Test Loss: 0.3264864\n",
      "Validation loss decreased (inf --> 0.277652).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3683157\n",
      "\tspeed: 0.0995s/iter; left time: 801.7695s\n",
      "\titers: 200, epoch: 2 | loss: 0.4829518\n",
      "\tspeed: 0.0422s/iter; left time: 336.0627s\n",
      "\titers: 300, epoch: 2 | loss: 0.4098303\n",
      "\tspeed: 0.0424s/iter; left time: 332.9070s\n",
      "\titers: 400, epoch: 2 | loss: 0.4821565\n",
      "\tspeed: 0.0421s/iter; left time: 326.3029s\n",
      "\titers: 500, epoch: 2 | loss: 0.3629837\n",
      "\tspeed: 0.0418s/iter; left time: 319.9717s\n",
      "\titers: 600, epoch: 2 | loss: 0.3894433\n",
      "\tspeed: 0.0424s/iter; left time: 320.2136s\n",
      "\titers: 700, epoch: 2 | loss: 0.3796617\n",
      "\tspeed: 0.0425s/iter; left time: 316.8922s\n",
      "\titers: 800, epoch: 2 | loss: 0.4837652\n",
      "\tspeed: 0.0423s/iter; left time: 311.0812s\n",
      "\titers: 900, epoch: 2 | loss: 0.3858483\n",
      "\tspeed: 0.0421s/iter; left time: 305.1908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 906 | Train Loss: 0.4253383 Vali Loss: 0.2241649 Test Loss: 0.2627058\n",
      "Validation loss decreased (0.277652 --> 0.224165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4184601\n",
      "\tspeed: 0.1024s/iter; left time: 731.9409s\n",
      "\titers: 200, epoch: 3 | loss: 0.3589702\n",
      "\tspeed: 0.0426s/iter; left time: 300.3382s\n",
      "\titers: 300, epoch: 3 | loss: 0.3864741\n",
      "\tspeed: 0.0422s/iter; left time: 293.3764s\n",
      "\titers: 400, epoch: 3 | loss: 0.3798923\n",
      "\tspeed: 0.0429s/iter; left time: 294.0842s\n",
      "\titers: 500, epoch: 3 | loss: 0.4409139\n",
      "\tspeed: 0.0431s/iter; left time: 290.7996s\n",
      "\titers: 600, epoch: 3 | loss: 0.4163352\n",
      "\tspeed: 0.0430s/iter; left time: 285.8029s\n",
      "\titers: 700, epoch: 3 | loss: 0.3735642\n",
      "\tspeed: 0.0424s/iter; left time: 277.7434s\n",
      "\titers: 800, epoch: 3 | loss: 0.3934213\n",
      "\tspeed: 0.0427s/iter; left time: 275.1484s\n",
      "\titers: 900, epoch: 3 | loss: 0.4092320\n",
      "\tspeed: 0.0420s/iter; left time: 266.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 906 | Train Loss: 0.3886658 Vali Loss: 0.2281934 Test Loss: 0.2456208\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3426898\n",
      "\tspeed: 0.0962s/iter; left time: 600.6490s\n",
      "\titers: 200, epoch: 4 | loss: 0.3767607\n",
      "\tspeed: 0.0420s/iter; left time: 258.0149s\n",
      "\titers: 300, epoch: 4 | loss: 0.3620969\n",
      "\tspeed: 0.0423s/iter; left time: 255.4610s\n",
      "\titers: 400, epoch: 4 | loss: 0.3348826\n",
      "\tspeed: 0.0417s/iter; left time: 247.7296s\n",
      "\titers: 500, epoch: 4 | loss: 0.3849360\n",
      "\tspeed: 0.0424s/iter; left time: 248.0058s\n",
      "\titers: 600, epoch: 4 | loss: 0.3511573\n",
      "\tspeed: 0.0416s/iter; left time: 238.9739s\n",
      "\titers: 700, epoch: 4 | loss: 0.3626874\n",
      "\tspeed: 0.0420s/iter; left time: 237.0702s\n",
      "\titers: 800, epoch: 4 | loss: 0.4081291\n",
      "\tspeed: 0.0416s/iter; left time: 230.4969s\n",
      "\titers: 900, epoch: 4 | loss: 0.3658917\n",
      "\tspeed: 0.0420s/iter; left time: 228.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.3597047 Vali Loss: 0.2268562 Test Loss: 0.2519057\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3171598\n",
      "\tspeed: 0.0956s/iter; left time: 509.9764s\n",
      "\titers: 200, epoch: 5 | loss: 0.3283252\n",
      "\tspeed: 0.0431s/iter; left time: 225.8955s\n",
      "\titers: 300, epoch: 5 | loss: 0.3180558\n",
      "\tspeed: 0.0424s/iter; left time: 217.6807s\n",
      "\titers: 400, epoch: 5 | loss: 0.3296632\n",
      "\tspeed: 0.0429s/iter; left time: 216.3145s\n",
      "\titers: 500, epoch: 5 | loss: 0.3155017\n",
      "\tspeed: 0.0431s/iter; left time: 212.6097s\n",
      "\titers: 600, epoch: 5 | loss: 0.3432666\n",
      "\tspeed: 0.0425s/iter; left time: 205.6570s\n",
      "\titers: 700, epoch: 5 | loss: 0.3247659\n",
      "\tspeed: 0.0426s/iter; left time: 201.6626s\n",
      "\titers: 800, epoch: 5 | loss: 0.3334618\n",
      "\tspeed: 0.0424s/iter; left time: 196.5720s\n",
      "\titers: 900, epoch: 5 | loss: 0.3186741\n",
      "\tspeed: 0.0427s/iter; left time: 193.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.86s\n",
      "Steps: 906 | Train Loss: 0.3285794 Vali Loss: 0.2464904 Test Loss: 0.2767749\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.26270100474357605, rmse:0.5125436782836914, mae:0.35968947410583496, rse:0.49822118878364563\n",
      "Original data scale mse:20469224.0, rmse:4524.29248046875, mae:3007.160888671875, rse:0.2249569594860077\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6982029\n",
      "\tspeed: 0.0435s/iter; left time: 389.9003s\n",
      "\titers: 200, epoch: 1 | loss: 0.6159171\n",
      "\tspeed: 0.0411s/iter; left time: 363.7823s\n",
      "\titers: 300, epoch: 1 | loss: 0.6252606\n",
      "\tspeed: 0.0415s/iter; left time: 363.8841s\n",
      "\titers: 400, epoch: 1 | loss: 0.5463977\n",
      "\tspeed: 0.0425s/iter; left time: 367.9656s\n",
      "\titers: 500, epoch: 1 | loss: 0.5218451\n",
      "\tspeed: 0.0424s/iter; left time: 362.9303s\n",
      "\titers: 600, epoch: 1 | loss: 0.5027246\n",
      "\tspeed: 0.0421s/iter; left time: 356.4968s\n",
      "\titers: 700, epoch: 1 | loss: 0.4774190\n",
      "\tspeed: 0.0418s/iter; left time: 349.7281s\n",
      "\titers: 800, epoch: 1 | loss: 0.5212248\n",
      "\tspeed: 0.0417s/iter; left time: 344.8048s\n",
      "\titers: 900, epoch: 1 | loss: 0.4854899\n",
      "\tspeed: 0.0416s/iter; left time: 339.2083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.5787885 Vali Loss: 0.2744367 Test Loss: 0.3292162\n",
      "Validation loss decreased (inf --> 0.274437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4447467\n",
      "\tspeed: 0.0983s/iter; left time: 792.1504s\n",
      "\titers: 200, epoch: 2 | loss: 0.4412494\n",
      "\tspeed: 0.0427s/iter; left time: 339.7156s\n",
      "\titers: 300, epoch: 2 | loss: 0.3834315\n",
      "\tspeed: 0.0420s/iter; left time: 330.0989s\n",
      "\titers: 400, epoch: 2 | loss: 0.3791665\n",
      "\tspeed: 0.0424s/iter; left time: 328.5550s\n",
      "\titers: 500, epoch: 2 | loss: 0.4030372\n",
      "\tspeed: 0.0422s/iter; left time: 323.1161s\n",
      "\titers: 600, epoch: 2 | loss: 0.4322845\n",
      "\tspeed: 0.0424s/iter; left time: 320.5036s\n",
      "\titers: 700, epoch: 2 | loss: 0.4121600\n",
      "\tspeed: 0.0423s/iter; left time: 315.6476s\n",
      "\titers: 800, epoch: 2 | loss: 0.3963506\n",
      "\tspeed: 0.0427s/iter; left time: 314.3304s\n",
      "\titers: 900, epoch: 2 | loss: 0.4162798\n",
      "\tspeed: 0.0423s/iter; left time: 306.7681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.4284949 Vali Loss: 0.2428965 Test Loss: 0.2610460\n",
      "Validation loss decreased (0.274437 --> 0.242897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4397380\n",
      "\tspeed: 0.1002s/iter; left time: 716.5522s\n",
      "\titers: 200, epoch: 3 | loss: 0.3714135\n",
      "\tspeed: 0.0424s/iter; left time: 298.8899s\n",
      "\titers: 300, epoch: 3 | loss: 0.3511816\n",
      "\tspeed: 0.0417s/iter; left time: 289.6677s\n",
      "\titers: 400, epoch: 3 | loss: 0.3657738\n",
      "\tspeed: 0.0420s/iter; left time: 287.4150s\n",
      "\titers: 500, epoch: 3 | loss: 0.3857349\n",
      "\tspeed: 0.0425s/iter; left time: 286.9333s\n",
      "\titers: 600, epoch: 3 | loss: 0.3564664\n",
      "\tspeed: 0.0426s/iter; left time: 282.9222s\n",
      "\titers: 700, epoch: 3 | loss: 0.4113604\n",
      "\tspeed: 0.0415s/iter; left time: 272.0022s\n",
      "\titers: 800, epoch: 3 | loss: 0.4029407\n",
      "\tspeed: 0.0423s/iter; left time: 272.6296s\n",
      "\titers: 900, epoch: 3 | loss: 0.3328545\n",
      "\tspeed: 0.0421s/iter; left time: 267.1321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.3896632 Vali Loss: 0.2230347 Test Loss: 0.2456640\n",
      "Validation loss decreased (0.242897 --> 0.223035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3423200\n",
      "\tspeed: 0.0989s/iter; left time: 617.3377s\n",
      "\titers: 200, epoch: 4 | loss: 0.3631905\n",
      "\tspeed: 0.0424s/iter; left time: 260.3886s\n",
      "\titers: 300, epoch: 4 | loss: 0.4438168\n",
      "\tspeed: 0.0424s/iter; left time: 256.2967s\n",
      "\titers: 400, epoch: 4 | loss: 0.3389303\n",
      "\tspeed: 0.0422s/iter; left time: 251.0473s\n",
      "\titers: 500, epoch: 4 | loss: 0.4199861\n",
      "\tspeed: 0.0427s/iter; left time: 249.6348s\n",
      "\titers: 600, epoch: 4 | loss: 0.3683004\n",
      "\tspeed: 0.0427s/iter; left time: 245.3397s\n",
      "\titers: 700, epoch: 4 | loss: 0.4172399\n",
      "\tspeed: 0.0427s/iter; left time: 241.1295s\n",
      "\titers: 800, epoch: 4 | loss: 0.2912661\n",
      "\tspeed: 0.0429s/iter; left time: 237.6079s\n",
      "\titers: 900, epoch: 4 | loss: 0.2848796\n",
      "\tspeed: 0.0423s/iter; left time: 230.4467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 906 | Train Loss: 0.3617161 Vali Loss: 0.2258493 Test Loss: 0.2433495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3664494\n",
      "\tspeed: 0.0955s/iter; left time: 509.5410s\n",
      "\titers: 200, epoch: 5 | loss: 0.3080376\n",
      "\tspeed: 0.0429s/iter; left time: 224.7448s\n",
      "\titers: 300, epoch: 5 | loss: 0.3119627\n",
      "\tspeed: 0.0430s/iter; left time: 221.1460s\n",
      "\titers: 400, epoch: 5 | loss: 0.3210239\n",
      "\tspeed: 0.0422s/iter; left time: 212.7514s\n",
      "\titers: 500, epoch: 5 | loss: 0.2903818\n",
      "\tspeed: 0.0426s/iter; left time: 210.5273s\n",
      "\titers: 600, epoch: 5 | loss: 0.3254892\n",
      "\tspeed: 0.0431s/iter; left time: 208.3971s\n",
      "\titers: 700, epoch: 5 | loss: 0.3048323\n",
      "\tspeed: 0.0432s/iter; left time: 204.4320s\n",
      "\titers: 800, epoch: 5 | loss: 0.3096336\n",
      "\tspeed: 0.0429s/iter; left time: 198.7381s\n",
      "\titers: 900, epoch: 5 | loss: 0.3121783\n",
      "\tspeed: 0.0426s/iter; left time: 193.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 906 | Train Loss: 0.3286614 Vali Loss: 0.2403434 Test Loss: 0.2644661\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2932463\n",
      "\tspeed: 0.0961s/iter; left time: 425.8249s\n",
      "\titers: 200, epoch: 6 | loss: 0.3175998\n",
      "\tspeed: 0.0421s/iter; left time: 182.2357s\n",
      "\titers: 300, epoch: 6 | loss: 0.3656258\n",
      "\tspeed: 0.0420s/iter; left time: 177.7870s\n",
      "\titers: 400, epoch: 6 | loss: 0.3123351\n",
      "\tspeed: 0.0429s/iter; left time: 177.0281s\n",
      "\titers: 500, epoch: 6 | loss: 0.2891043\n",
      "\tspeed: 0.0430s/iter; left time: 173.3351s\n",
      "\titers: 600, epoch: 6 | loss: 0.3142055\n",
      "\tspeed: 0.0422s/iter; left time: 165.9260s\n",
      "\titers: 700, epoch: 6 | loss: 0.2970073\n",
      "\tspeed: 0.0429s/iter; left time: 164.3137s\n",
      "\titers: 800, epoch: 6 | loss: 0.2884398\n",
      "\tspeed: 0.0426s/iter; left time: 158.9496s\n",
      "\titers: 900, epoch: 6 | loss: 0.2932458\n",
      "\tspeed: 0.0430s/iter; left time: 156.0366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 906 | Train Loss: 0.3011564 Vali Loss: 0.2485842 Test Loss: 0.2648035\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.24519793689250946, rmse:0.4951746463775635, mae:0.34172382950782776, rse:0.4813375771045685\n",
      "Original data scale mse:18739230.0, rmse:4328.88330078125, mae:2822.332763671875, rse:0.21524080634117126\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8064664\n",
      "\tspeed: 0.0802s/iter; left time: 717.3188s\n",
      "\titers: 200, epoch: 1 | loss: 0.7664227\n",
      "\tspeed: 0.0487s/iter; left time: 430.4098s\n",
      "\titers: 300, epoch: 1 | loss: 0.7341076\n",
      "\tspeed: 0.0501s/iter; left time: 437.7773s\n",
      "\titers: 400, epoch: 1 | loss: 0.6616915\n",
      "\tspeed: 0.0499s/iter; left time: 431.1638s\n",
      "\titers: 500, epoch: 1 | loss: 0.6488833\n",
      "\tspeed: 0.0482s/iter; left time: 411.2656s\n",
      "\titers: 600, epoch: 1 | loss: 0.5803346\n",
      "\tspeed: 0.0472s/iter; left time: 398.4665s\n",
      "\titers: 700, epoch: 1 | loss: 0.5828353\n",
      "\tspeed: 0.0468s/iter; left time: 390.5578s\n",
      "\titers: 800, epoch: 1 | loss: 0.5948309\n",
      "\tspeed: 0.0472s/iter; left time: 389.2518s\n",
      "\titers: 900, epoch: 1 | loss: 0.6047560\n",
      "\tspeed: 0.0471s/iter; left time: 383.3846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.45s\n",
      "Steps: 904 | Train Loss: 0.6821177 Vali Loss: 0.4251803 Test Loss: 0.5550168\n",
      "Validation loss decreased (inf --> 0.425180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5454522\n",
      "\tspeed: 0.1172s/iter; left time: 942.1691s\n",
      "\titers: 200, epoch: 2 | loss: 0.5770916\n",
      "\tspeed: 0.0477s/iter; left time: 378.3477s\n",
      "\titers: 300, epoch: 2 | loss: 0.5515141\n",
      "\tspeed: 0.0478s/iter; left time: 374.2195s\n",
      "\titers: 400, epoch: 2 | loss: 0.5206445\n",
      "\tspeed: 0.0478s/iter; left time: 370.0396s\n",
      "\titers: 500, epoch: 2 | loss: 0.5356205\n",
      "\tspeed: 0.0478s/iter; left time: 365.1989s\n",
      "\titers: 600, epoch: 2 | loss: 0.5716960\n",
      "\tspeed: 0.0478s/iter; left time: 360.2306s\n",
      "\titers: 700, epoch: 2 | loss: 0.5138907\n",
      "\tspeed: 0.0477s/iter; left time: 354.6510s\n",
      "\titers: 800, epoch: 2 | loss: 0.5554817\n",
      "\tspeed: 0.0477s/iter; left time: 349.9415s\n",
      "\titers: 900, epoch: 2 | loss: 0.4969156\n",
      "\tspeed: 0.0475s/iter; left time: 343.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.36s\n",
      "Steps: 904 | Train Loss: 0.5482871 Vali Loss: 0.3588398 Test Loss: 0.4320123\n",
      "Validation loss decreased (0.425180 --> 0.358840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5557590\n",
      "\tspeed: 0.1085s/iter; left time: 773.6815s\n",
      "\titers: 200, epoch: 3 | loss: 0.4666590\n",
      "\tspeed: 0.0354s/iter; left time: 248.8538s\n",
      "\titers: 300, epoch: 3 | loss: 0.4575912\n",
      "\tspeed: 0.0354s/iter; left time: 245.3698s\n",
      "\titers: 400, epoch: 3 | loss: 0.4686307\n",
      "\tspeed: 0.0354s/iter; left time: 241.8925s\n",
      "\titers: 500, epoch: 3 | loss: 0.4880049\n",
      "\tspeed: 0.0354s/iter; left time: 238.3754s\n",
      "\titers: 600, epoch: 3 | loss: 0.4762916\n",
      "\tspeed: 0.0354s/iter; left time: 234.7235s\n",
      "\titers: 700, epoch: 3 | loss: 0.4483458\n",
      "\tspeed: 0.0354s/iter; left time: 231.4640s\n",
      "\titers: 800, epoch: 3 | loss: 0.4853708\n",
      "\tspeed: 0.0354s/iter; left time: 227.7342s\n",
      "\titers: 900, epoch: 3 | loss: 0.4844504\n",
      "\tspeed: 0.0354s/iter; left time: 224.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.25s\n",
      "Steps: 904 | Train Loss: 0.4905927 Vali Loss: 0.3460696 Test Loss: 0.4395411\n",
      "Validation loss decreased (0.358840 --> 0.346070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4397926\n",
      "\tspeed: 0.1145s/iter; left time: 713.2366s\n",
      "\titers: 200, epoch: 4 | loss: 0.4575310\n",
      "\tspeed: 0.0474s/iter; left time: 290.4533s\n",
      "\titers: 300, epoch: 4 | loss: 0.4385205\n",
      "\tspeed: 0.0473s/iter; left time: 285.2149s\n",
      "\titers: 400, epoch: 4 | loss: 0.3930130\n",
      "\tspeed: 0.0473s/iter; left time: 280.5210s\n",
      "\titers: 500, epoch: 4 | loss: 0.4680209\n",
      "\tspeed: 0.0473s/iter; left time: 275.6596s\n",
      "\titers: 600, epoch: 4 | loss: 0.4003425\n",
      "\tspeed: 0.0472s/iter; left time: 270.2244s\n",
      "\titers: 700, epoch: 4 | loss: 0.4485963\n",
      "\tspeed: 0.0470s/iter; left time: 264.3728s\n",
      "\titers: 800, epoch: 4 | loss: 0.4115075\n",
      "\tspeed: 0.0471s/iter; left time: 260.6856s\n",
      "\titers: 900, epoch: 4 | loss: 0.4709758\n",
      "\tspeed: 0.0472s/iter; left time: 256.4659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.4433273 Vali Loss: 0.3830858 Test Loss: 0.4687644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4058290\n",
      "\tspeed: 0.1122s/iter; left time: 597.5045s\n",
      "\titers: 200, epoch: 5 | loss: 0.4450139\n",
      "\tspeed: 0.0476s/iter; left time: 248.4615s\n",
      "\titers: 300, epoch: 5 | loss: 0.4318683\n",
      "\tspeed: 0.0474s/iter; left time: 242.7717s\n",
      "\titers: 400, epoch: 5 | loss: 0.3999391\n",
      "\tspeed: 0.0475s/iter; left time: 238.5622s\n",
      "\titers: 500, epoch: 5 | loss: 0.3851315\n",
      "\tspeed: 0.0476s/iter; left time: 234.3907s\n",
      "\titers: 600, epoch: 5 | loss: 0.4026952\n",
      "\tspeed: 0.0476s/iter; left time: 229.6545s\n",
      "\titers: 700, epoch: 5 | loss: 0.3947259\n",
      "\tspeed: 0.0476s/iter; left time: 224.7579s\n",
      "\titers: 800, epoch: 5 | loss: 0.3597316\n",
      "\tspeed: 0.0476s/iter; left time: 219.9202s\n",
      "\titers: 900, epoch: 5 | loss: 0.3766596\n",
      "\tspeed: 0.0476s/iter; left time: 215.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.4016175 Vali Loss: 0.3793854 Test Loss: 0.4840747\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3668042\n",
      "\tspeed: 0.1124s/iter; left time: 496.9763s\n",
      "\titers: 200, epoch: 6 | loss: 0.3568165\n",
      "\tspeed: 0.0471s/iter; left time: 203.4176s\n",
      "\titers: 300, epoch: 6 | loss: 0.3732386\n",
      "\tspeed: 0.0473s/iter; left time: 199.4929s\n",
      "\titers: 400, epoch: 6 | loss: 0.3572828\n",
      "\tspeed: 0.0473s/iter; left time: 194.9045s\n",
      "\titers: 500, epoch: 6 | loss: 0.3612566\n",
      "\tspeed: 0.0473s/iter; left time: 190.0639s\n",
      "\titers: 600, epoch: 6 | loss: 0.3670929\n",
      "\tspeed: 0.0473s/iter; left time: 185.5566s\n",
      "\titers: 700, epoch: 6 | loss: 0.3390908\n",
      "\tspeed: 0.0473s/iter; left time: 180.7646s\n",
      "\titers: 800, epoch: 6 | loss: 0.3877013\n",
      "\tspeed: 0.0474s/iter; left time: 176.3508s\n",
      "\titers: 900, epoch: 6 | loss: 0.3606498\n",
      "\tspeed: 0.0473s/iter; left time: 171.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.3698651 Vali Loss: 0.3972877 Test Loss: 0.5082203\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4387984275817871, rmse:0.6624186038970947, mae:0.4693324565887451, rse:0.6442867517471313\n",
      "Original data scale mse:35833200.0, rmse:5986.083984375, mae:3917.44970703125, rse:0.29810911417007446\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7826722\n",
      "\tspeed: 0.0491s/iter; left time: 439.0545s\n",
      "\titers: 200, epoch: 1 | loss: 0.7669095\n",
      "\tspeed: 0.0476s/iter; left time: 420.5458s\n",
      "\titers: 300, epoch: 1 | loss: 0.6981553\n",
      "\tspeed: 0.0476s/iter; left time: 416.4479s\n",
      "\titers: 400, epoch: 1 | loss: 0.6360794\n",
      "\tspeed: 0.0476s/iter; left time: 410.9331s\n",
      "\titers: 500, epoch: 1 | loss: 0.6758806\n",
      "\tspeed: 0.0478s/iter; left time: 407.9704s\n",
      "\titers: 600, epoch: 1 | loss: 0.6679193\n",
      "\tspeed: 0.0478s/iter; left time: 403.3673s\n",
      "\titers: 700, epoch: 1 | loss: 0.6072015\n",
      "\tspeed: 0.0475s/iter; left time: 396.3501s\n",
      "\titers: 800, epoch: 1 | loss: 0.6476004\n",
      "\tspeed: 0.0476s/iter; left time: 392.4991s\n",
      "\titers: 900, epoch: 1 | loss: 0.5657718\n",
      "\tspeed: 0.0475s/iter; left time: 387.0963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.29s\n",
      "Steps: 904 | Train Loss: 0.6816599 Vali Loss: 0.4242748 Test Loss: 0.5577038\n",
      "Validation loss decreased (inf --> 0.424275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6051634\n",
      "\tspeed: 0.1178s/iter; left time: 946.4430s\n",
      "\titers: 200, epoch: 2 | loss: 0.6035539\n",
      "\tspeed: 0.0471s/iter; left time: 373.8651s\n",
      "\titers: 300, epoch: 2 | loss: 0.5138240\n",
      "\tspeed: 0.0473s/iter; left time: 370.3984s\n",
      "\titers: 400, epoch: 2 | loss: 0.5254555\n",
      "\tspeed: 0.0473s/iter; left time: 365.7251s\n",
      "\titers: 500, epoch: 2 | loss: 0.5307585\n",
      "\tspeed: 0.0472s/iter; left time: 360.1987s\n",
      "\titers: 600, epoch: 2 | loss: 0.5466508\n",
      "\tspeed: 0.0472s/iter; left time: 356.0068s\n",
      "\titers: 700, epoch: 2 | loss: 0.5277196\n",
      "\tspeed: 0.0472s/iter; left time: 350.7495s\n",
      "\titers: 800, epoch: 2 | loss: 0.5726936\n",
      "\tspeed: 0.0473s/iter; left time: 346.7067s\n",
      "\titers: 900, epoch: 2 | loss: 0.5164347\n",
      "\tspeed: 0.0472s/iter; left time: 341.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.5480284 Vali Loss: 0.3702663 Test Loss: 0.4406294\n",
      "Validation loss decreased (0.424275 --> 0.370266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5355127\n",
      "\tspeed: 0.1200s/iter; left time: 855.7171s\n",
      "\titers: 200, epoch: 3 | loss: 0.5054911\n",
      "\tspeed: 0.0479s/iter; left time: 336.7354s\n",
      "\titers: 300, epoch: 3 | loss: 0.4564782\n",
      "\tspeed: 0.0354s/iter; left time: 245.3342s\n",
      "\titers: 400, epoch: 3 | loss: 0.4572828\n",
      "\tspeed: 0.0354s/iter; left time: 242.1407s\n",
      "\titers: 500, epoch: 3 | loss: 0.4448029\n",
      "\tspeed: 0.0354s/iter; left time: 238.1931s\n",
      "\titers: 600, epoch: 3 | loss: 0.5135291\n",
      "\tspeed: 0.0353s/iter; left time: 234.3718s\n",
      "\titers: 700, epoch: 3 | loss: 0.4969874\n",
      "\tspeed: 0.0354s/iter; left time: 231.1370s\n",
      "\titers: 800, epoch: 3 | loss: 0.4942554\n",
      "\tspeed: 0.0354s/iter; left time: 227.6863s\n",
      "\titers: 900, epoch: 3 | loss: 0.4294151\n",
      "\tspeed: 0.0354s/iter; left time: 224.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.95s\n",
      "Steps: 904 | Train Loss: 0.4949856 Vali Loss: 0.3723978 Test Loss: 0.4794962\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4060275\n",
      "\tspeed: 0.1118s/iter; left time: 696.2451s\n",
      "\titers: 200, epoch: 4 | loss: 0.4581123\n",
      "\tspeed: 0.0472s/iter; left time: 288.9836s\n",
      "\titers: 300, epoch: 4 | loss: 0.4457313\n",
      "\tspeed: 0.0472s/iter; left time: 284.7329s\n",
      "\titers: 400, epoch: 4 | loss: 0.4425646\n",
      "\tspeed: 0.0471s/iter; left time: 279.2792s\n",
      "\titers: 500, epoch: 4 | loss: 0.4735631\n",
      "\tspeed: 0.0473s/iter; left time: 275.7013s\n",
      "\titers: 600, epoch: 4 | loss: 0.4367875\n",
      "\tspeed: 0.0470s/iter; left time: 269.0201s\n",
      "\titers: 700, epoch: 4 | loss: 0.4670251\n",
      "\tspeed: 0.0472s/iter; left time: 265.8329s\n",
      "\titers: 800, epoch: 4 | loss: 0.4425907\n",
      "\tspeed: 0.0472s/iter; left time: 260.8610s\n",
      "\titers: 900, epoch: 4 | loss: 0.4075777\n",
      "\tspeed: 0.0472s/iter; left time: 256.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 904 | Train Loss: 0.4485817 Vali Loss: 0.3547851 Test Loss: 0.4712861\n",
      "Validation loss decreased (0.370266 --> 0.354785).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3921745\n",
      "\tspeed: 0.1199s/iter; left time: 638.2794s\n",
      "\titers: 200, epoch: 5 | loss: 0.4282338\n",
      "\tspeed: 0.0472s/iter; left time: 246.7555s\n",
      "\titers: 300, epoch: 5 | loss: 0.4185658\n",
      "\tspeed: 0.0472s/iter; left time: 241.7247s\n",
      "\titers: 400, epoch: 5 | loss: 0.3942061\n",
      "\tspeed: 0.0470s/iter; left time: 236.3538s\n",
      "\titers: 500, epoch: 5 | loss: 0.4057429\n",
      "\tspeed: 0.0473s/iter; left time: 232.7615s\n",
      "\titers: 600, epoch: 5 | loss: 0.4259904\n",
      "\tspeed: 0.0468s/iter; left time: 225.7994s\n",
      "\titers: 700, epoch: 5 | loss: 0.3964215\n",
      "\tspeed: 0.0473s/iter; left time: 223.5740s\n",
      "\titers: 800, epoch: 5 | loss: 0.3993809\n",
      "\tspeed: 0.0474s/iter; left time: 219.0562s\n",
      "\titers: 900, epoch: 5 | loss: 0.3567997\n",
      "\tspeed: 0.0469s/iter; left time: 212.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.87s\n",
      "Steps: 904 | Train Loss: 0.4005559 Vali Loss: 0.3649893 Test Loss: 0.4830398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3387131\n",
      "\tspeed: 0.1124s/iter; left time: 496.8624s\n",
      "\titers: 200, epoch: 6 | loss: 0.3641458\n",
      "\tspeed: 0.0475s/iter; left time: 205.2727s\n",
      "\titers: 300, epoch: 6 | loss: 0.4022169\n",
      "\tspeed: 0.0475s/iter; left time: 200.6078s\n",
      "\titers: 400, epoch: 6 | loss: 0.3523118\n",
      "\tspeed: 0.0475s/iter; left time: 195.6034s\n",
      "\titers: 500, epoch: 6 | loss: 0.3746400\n",
      "\tspeed: 0.0474s/iter; left time: 190.7827s\n",
      "\titers: 600, epoch: 6 | loss: 0.3501792\n",
      "\tspeed: 0.0475s/iter; left time: 186.0868s\n",
      "\titers: 700, epoch: 6 | loss: 0.3256495\n",
      "\tspeed: 0.0388s/iter; left time: 148.2782s\n",
      "\titers: 800, epoch: 6 | loss: 0.3425799\n",
      "\tspeed: 0.0354s/iter; left time: 131.6598s\n",
      "\titers: 900, epoch: 6 | loss: 0.3267003\n",
      "\tspeed: 0.0354s/iter; left time: 128.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.77s\n",
      "Steps: 904 | Train Loss: 0.3663364 Vali Loss: 0.3792255 Test Loss: 0.5282541\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471676\n",
      "\tspeed: 0.1123s/iter; left time: 395.0729s\n",
      "\titers: 200, epoch: 7 | loss: 0.3320793\n",
      "\tspeed: 0.0478s/iter; left time: 163.2199s\n",
      "\titers: 300, epoch: 7 | loss: 0.3283722\n",
      "\tspeed: 0.0476s/iter; left time: 157.7901s\n",
      "\titers: 400, epoch: 7 | loss: 0.3186728\n",
      "\tspeed: 0.0477s/iter; left time: 153.3283s\n",
      "\titers: 500, epoch: 7 | loss: 0.3287959\n",
      "\tspeed: 0.0475s/iter; left time: 148.0350s\n",
      "\titers: 600, epoch: 7 | loss: 0.3218990\n",
      "\tspeed: 0.0476s/iter; left time: 143.7037s\n",
      "\titers: 700, epoch: 7 | loss: 0.3686137\n",
      "\tspeed: 0.0477s/iter; left time: 139.0567s\n",
      "\titers: 800, epoch: 7 | loss: 0.3285244\n",
      "\tspeed: 0.0477s/iter; left time: 134.3893s\n",
      "\titers: 900, epoch: 7 | loss: 0.3177367\n",
      "\tspeed: 0.0477s/iter; left time: 129.5875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.3364941 Vali Loss: 0.3665204 Test Loss: 0.5042919\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.471591055393219, rmse:0.6867249011993408, mae:0.48673340678215027, rse:0.667927622795105\n",
      "Original data scale mse:39601956.0, rmse:6293.00830078125, mae:4131.7314453125, rse:0.31339406967163086\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7501633\n",
      "\tspeed: 0.0825s/iter; left time: 735.6923s\n",
      "\titers: 200, epoch: 1 | loss: 0.7569238\n",
      "\tspeed: 0.0537s/iter; left time: 473.6315s\n",
      "\titers: 300, epoch: 1 | loss: 0.7307299\n",
      "\tspeed: 0.0537s/iter; left time: 468.7290s\n",
      "\titers: 400, epoch: 1 | loss: 0.7293500\n",
      "\tspeed: 0.0535s/iter; left time: 461.4926s\n",
      "\titers: 500, epoch: 1 | loss: 0.7057337\n",
      "\tspeed: 0.0534s/iter; left time: 454.6385s\n",
      "\titers: 600, epoch: 1 | loss: 0.7072594\n",
      "\tspeed: 0.0534s/iter; left time: 449.3014s\n",
      "\titers: 700, epoch: 1 | loss: 0.6900529\n",
      "\tspeed: 0.0534s/iter; left time: 444.2312s\n",
      "\titers: 800, epoch: 1 | loss: 0.6720834\n",
      "\tspeed: 0.0531s/iter; left time: 436.8159s\n",
      "\titers: 900, epoch: 1 | loss: 0.6936437\n",
      "\tspeed: 0.0531s/iter; left time: 431.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.92s\n",
      "Steps: 902 | Train Loss: 0.7238418 Vali Loss: 0.5320662 Test Loss: 0.7281205\n",
      "Validation loss decreased (inf --> 0.532066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7019882\n",
      "\tspeed: 0.1333s/iter; left time: 1069.1662s\n",
      "\titers: 200, epoch: 2 | loss: 0.6359353\n",
      "\tspeed: 0.0539s/iter; left time: 426.4663s\n",
      "\titers: 300, epoch: 2 | loss: 0.6494266\n",
      "\tspeed: 0.0536s/iter; left time: 419.1846s\n",
      "\titers: 400, epoch: 2 | loss: 0.5800546\n",
      "\tspeed: 0.0538s/iter; left time: 415.4109s\n",
      "\titers: 500, epoch: 2 | loss: 0.5660743\n",
      "\tspeed: 0.0537s/iter; left time: 409.1051s\n",
      "\titers: 600, epoch: 2 | loss: 0.5282308\n",
      "\tspeed: 0.0537s/iter; left time: 403.7605s\n",
      "\titers: 700, epoch: 2 | loss: 0.5169588\n",
      "\tspeed: 0.0536s/iter; left time: 397.5123s\n",
      "\titers: 800, epoch: 2 | loss: 0.5812657\n",
      "\tspeed: 0.0537s/iter; left time: 392.8220s\n",
      "\titers: 900, epoch: 2 | loss: 0.5165561\n",
      "\tspeed: 0.0535s/iter; left time: 386.4265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.5807301 Vali Loss: 0.3836309 Test Loss: 0.4612122\n",
      "Validation loss decreased (0.532066 --> 0.383631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5295238\n",
      "\tspeed: 0.1358s/iter; left time: 966.5868s\n",
      "\titers: 200, epoch: 3 | loss: 0.5225747\n",
      "\tspeed: 0.0544s/iter; left time: 381.9487s\n",
      "\titers: 300, epoch: 3 | loss: 0.5027869\n",
      "\tspeed: 0.0541s/iter; left time: 374.1713s\n",
      "\titers: 400, epoch: 3 | loss: 0.5515996\n",
      "\tspeed: 0.0538s/iter; left time: 366.5063s\n",
      "\titers: 500, epoch: 3 | loss: 0.5002297\n",
      "\tspeed: 0.0536s/iter; left time: 359.8260s\n",
      "\titers: 600, epoch: 3 | loss: 0.5084694\n",
      "\tspeed: 0.0537s/iter; left time: 355.0624s\n",
      "\titers: 700, epoch: 3 | loss: 0.5194324\n",
      "\tspeed: 0.0537s/iter; left time: 349.9077s\n",
      "\titers: 800, epoch: 3 | loss: 0.4972505\n",
      "\tspeed: 0.0537s/iter; left time: 344.5919s\n",
      "\titers: 900, epoch: 3 | loss: 0.4840217\n",
      "\tspeed: 0.0537s/iter; left time: 339.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.87s\n",
      "Steps: 902 | Train Loss: 0.4992432 Vali Loss: 0.3879341 Test Loss: 0.4769197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4472435\n",
      "\tspeed: 0.1301s/iter; left time: 808.5982s\n",
      "\titers: 200, epoch: 4 | loss: 0.4252438\n",
      "\tspeed: 0.0537s/iter; left time: 328.2038s\n",
      "\titers: 300, epoch: 4 | loss: 0.4829215\n",
      "\tspeed: 0.0536s/iter; left time: 322.5101s\n",
      "\titers: 400, epoch: 4 | loss: 0.4546541\n",
      "\tspeed: 0.0537s/iter; left time: 317.4775s\n",
      "\titers: 500, epoch: 4 | loss: 0.4641887\n",
      "\tspeed: 0.0539s/iter; left time: 313.4692s\n",
      "\titers: 600, epoch: 4 | loss: 0.4187097\n",
      "\tspeed: 0.0537s/iter; left time: 306.8215s\n",
      "\titers: 700, epoch: 4 | loss: 0.4351173\n",
      "\tspeed: 0.0536s/iter; left time: 301.0412s\n",
      "\titers: 800, epoch: 4 | loss: 0.4638724\n",
      "\tspeed: 0.0538s/iter; left time: 296.4928s\n",
      "\titers: 900, epoch: 4 | loss: 0.4366152\n",
      "\tspeed: 0.0537s/iter; left time: 290.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.4500228 Vali Loss: 0.4257467 Test Loss: 0.5126336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4453283\n",
      "\tspeed: 0.1306s/iter; left time: 693.9804s\n",
      "\titers: 200, epoch: 5 | loss: 0.4337400\n",
      "\tspeed: 0.0537s/iter; left time: 279.8776s\n",
      "\titers: 300, epoch: 5 | loss: 0.4144468\n",
      "\tspeed: 0.0538s/iter; left time: 275.0815s\n",
      "\titers: 400, epoch: 5 | loss: 0.4377461\n",
      "\tspeed: 0.0539s/iter; left time: 270.2999s\n",
      "\titers: 500, epoch: 5 | loss: 0.3671501\n",
      "\tspeed: 0.0537s/iter; left time: 263.9733s\n",
      "\titers: 600, epoch: 5 | loss: 0.3930199\n",
      "\tspeed: 0.0538s/iter; left time: 258.7675s\n",
      "\titers: 700, epoch: 5 | loss: 0.4070324\n",
      "\tspeed: 0.0537s/iter; left time: 253.2159s\n",
      "\titers: 800, epoch: 5 | loss: 0.3946013\n",
      "\tspeed: 0.0538s/iter; left time: 248.1880s\n",
      "\titers: 900, epoch: 5 | loss: 0.3659644\n",
      "\tspeed: 0.0538s/iter; left time: 242.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.4093621 Vali Loss: 0.4312938 Test Loss: 0.5392915\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4609777629375458, rmse:0.6789534091949463, mae:0.5002171397209167, rse:0.6583471894264221\n",
      "Original data scale mse:38069076.0, rmse:6170.01416015625, mae:4236.10498046875, rse:0.3074197471141815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8362218\n",
      "\tspeed: 0.0557s/iter; left time: 496.8167s\n",
      "\titers: 200, epoch: 1 | loss: 0.7356129\n",
      "\tspeed: 0.0539s/iter; left time: 475.4105s\n",
      "\titers: 300, epoch: 1 | loss: 0.6807122\n",
      "\tspeed: 0.0537s/iter; left time: 468.3342s\n",
      "\titers: 400, epoch: 1 | loss: 0.7171140\n",
      "\tspeed: 0.0538s/iter; left time: 463.6323s\n",
      "\titers: 500, epoch: 1 | loss: 0.6935529\n",
      "\tspeed: 0.0537s/iter; left time: 457.5074s\n",
      "\titers: 600, epoch: 1 | loss: 0.7096789\n",
      "\tspeed: 0.0541s/iter; left time: 455.4460s\n",
      "\titers: 700, epoch: 1 | loss: 0.7152407\n",
      "\tspeed: 0.0542s/iter; left time: 451.2115s\n",
      "\titers: 800, epoch: 1 | loss: 0.6635863\n",
      "\tspeed: 0.0541s/iter; left time: 445.0003s\n",
      "\titers: 900, epoch: 1 | loss: 0.6691676\n",
      "\tspeed: 0.0542s/iter; left time: 440.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.7214302 Vali Loss: 0.5380124 Test Loss: 0.7357840\n",
      "Validation loss decreased (inf --> 0.538012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6983247\n",
      "\tspeed: 0.1357s/iter; left time: 1088.3214s\n",
      "\titers: 200, epoch: 2 | loss: 0.6180595\n",
      "\tspeed: 0.0543s/iter; left time: 429.6240s\n",
      "\titers: 300, epoch: 2 | loss: 0.6322026\n",
      "\tspeed: 0.0544s/iter; left time: 425.4625s\n",
      "\titers: 400, epoch: 2 | loss: 0.5258986\n",
      "\tspeed: 0.0541s/iter; left time: 417.4338s\n",
      "\titers: 500, epoch: 2 | loss: 0.5912980\n",
      "\tspeed: 0.0540s/iter; left time: 411.6743s\n",
      "\titers: 600, epoch: 2 | loss: 0.5387182\n",
      "\tspeed: 0.0542s/iter; left time: 407.7321s\n",
      "\titers: 700, epoch: 2 | loss: 0.5565358\n",
      "\tspeed: 0.0543s/iter; left time: 402.6399s\n",
      "\titers: 800, epoch: 2 | loss: 0.5232177\n",
      "\tspeed: 0.0537s/iter; left time: 393.3298s\n",
      "\titers: 900, epoch: 2 | loss: 0.5223538\n",
      "\tspeed: 0.0537s/iter; left time: 387.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.08s\n",
      "Steps: 902 | Train Loss: 0.5906084 Vali Loss: 0.3991819 Test Loss: 0.4598295\n",
      "Validation loss decreased (0.538012 --> 0.399182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5225666\n",
      "\tspeed: 0.1351s/iter; left time: 961.8050s\n",
      "\titers: 200, epoch: 3 | loss: 0.4791816\n",
      "\tspeed: 0.0545s/iter; left time: 382.3426s\n",
      "\titers: 300, epoch: 3 | loss: 0.4841701\n",
      "\tspeed: 0.0541s/iter; left time: 374.0404s\n",
      "\titers: 400, epoch: 3 | loss: 0.4705889\n",
      "\tspeed: 0.0546s/iter; left time: 371.9224s\n",
      "\titers: 500, epoch: 3 | loss: 0.5152424\n",
      "\tspeed: 0.0540s/iter; left time: 362.7564s\n",
      "\titers: 600, epoch: 3 | loss: 0.5077010\n",
      "\tspeed: 0.0538s/iter; left time: 355.9449s\n",
      "\titers: 700, epoch: 3 | loss: 0.5025519\n",
      "\tspeed: 0.0534s/iter; left time: 348.2476s\n",
      "\titers: 800, epoch: 3 | loss: 0.4465362\n",
      "\tspeed: 0.0536s/iter; left time: 343.7727s\n",
      "\titers: 900, epoch: 3 | loss: 0.4787401\n",
      "\tspeed: 0.0535s/iter; left time: 338.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.93s\n",
      "Steps: 902 | Train Loss: 0.5040131 Vali Loss: 0.3924748 Test Loss: 0.4811535\n",
      "Validation loss decreased (0.399182 --> 0.392475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4340003\n",
      "\tspeed: 0.1335s/iter; left time: 829.8872s\n",
      "\titers: 200, epoch: 4 | loss: 0.4777999\n",
      "\tspeed: 0.0534s/iter; left time: 326.7195s\n",
      "\titers: 300, epoch: 4 | loss: 0.4901440\n",
      "\tspeed: 0.0536s/iter; left time: 322.3338s\n",
      "\titers: 400, epoch: 4 | loss: 0.4576968\n",
      "\tspeed: 0.0536s/iter; left time: 316.9316s\n",
      "\titers: 500, epoch: 4 | loss: 0.4644936\n",
      "\tspeed: 0.0536s/iter; left time: 311.6435s\n",
      "\titers: 600, epoch: 4 | loss: 0.4516342\n",
      "\tspeed: 0.0533s/iter; left time: 304.6272s\n",
      "\titers: 700, epoch: 4 | loss: 0.4495443\n",
      "\tspeed: 0.0535s/iter; left time: 300.4960s\n",
      "\titers: 800, epoch: 4 | loss: 0.4224161\n",
      "\tspeed: 0.0536s/iter; left time: 295.6912s\n",
      "\titers: 900, epoch: 4 | loss: 0.4253691\n",
      "\tspeed: 0.0536s/iter; left time: 290.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.51s\n",
      "Steps: 902 | Train Loss: 0.4550309 Vali Loss: 0.4289837 Test Loss: 0.5100748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4204411\n",
      "\tspeed: 0.1297s/iter; left time: 689.2079s\n",
      "\titers: 200, epoch: 5 | loss: 0.4049948\n",
      "\tspeed: 0.0534s/iter; left time: 278.2820s\n",
      "\titers: 300, epoch: 5 | loss: 0.4274650\n",
      "\tspeed: 0.0535s/iter; left time: 273.6162s\n",
      "\titers: 400, epoch: 5 | loss: 0.4168011\n",
      "\tspeed: 0.0538s/iter; left time: 269.7115s\n",
      "\titers: 500, epoch: 5 | loss: 0.4206059\n",
      "\tspeed: 0.0536s/iter; left time: 263.3751s\n",
      "\titers: 600, epoch: 5 | loss: 0.4025565\n",
      "\tspeed: 0.0537s/iter; left time: 258.3072s\n",
      "\titers: 700, epoch: 5 | loss: 0.3950890\n",
      "\tspeed: 0.0535s/iter; left time: 252.3747s\n",
      "\titers: 800, epoch: 5 | loss: 0.4090600\n",
      "\tspeed: 0.0536s/iter; left time: 247.4201s\n",
      "\titers: 900, epoch: 5 | loss: 0.4090587\n",
      "\tspeed: 0.0537s/iter; left time: 242.2657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.4136486 Vali Loss: 0.4345170 Test Loss: 0.5279194\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3809133\n",
      "\tspeed: 0.1299s/iter; left time: 573.1468s\n",
      "\titers: 200, epoch: 6 | loss: 0.3715863\n",
      "\tspeed: 0.0535s/iter; left time: 230.6196s\n",
      "\titers: 300, epoch: 6 | loss: 0.3729623\n",
      "\tspeed: 0.0536s/iter; left time: 225.6296s\n",
      "\titers: 400, epoch: 6 | loss: 0.3830902\n",
      "\tspeed: 0.0537s/iter; left time: 220.7359s\n",
      "\titers: 500, epoch: 6 | loss: 0.4015138\n",
      "\tspeed: 0.0536s/iter; left time: 215.1846s\n",
      "\titers: 600, epoch: 6 | loss: 0.3586400\n",
      "\tspeed: 0.0537s/iter; left time: 209.9872s\n",
      "\titers: 700, epoch: 6 | loss: 0.3749744\n",
      "\tspeed: 0.0536s/iter; left time: 204.2672s\n",
      "\titers: 800, epoch: 6 | loss: 0.3658184\n",
      "\tspeed: 0.0537s/iter; left time: 199.3586s\n",
      "\titers: 900, epoch: 6 | loss: 0.3755621\n",
      "\tspeed: 0.0537s/iter; left time: 193.9775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.3807046 Vali Loss: 0.4451516 Test Loss: 0.5592123\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4807005226612091, rmse:0.6933256983757019, mae:0.5033847689628601, rse:0.6722832322120667\n",
      "Original data scale mse:39885020.0, rmse:6315.458984375, mae:4252.66259765625, rse:0.3146664798259735\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5668260\n",
      "\tspeed: 0.0706s/iter; left time: 632.3595s\n",
      "\titers: 200, epoch: 1 | loss: 0.5016366\n",
      "\tspeed: 0.0420s/iter; left time: 372.4571s\n",
      "\titers: 300, epoch: 1 | loss: 0.4471771\n",
      "\tspeed: 0.0424s/iter; left time: 371.5963s\n",
      "\titers: 400, epoch: 1 | loss: 0.3983449\n",
      "\tspeed: 0.0415s/iter; left time: 359.2925s\n",
      "\titers: 500, epoch: 1 | loss: 0.3730129\n",
      "\tspeed: 0.0407s/iter; left time: 348.6474s\n",
      "\titers: 600, epoch: 1 | loss: 0.3658692\n",
      "\tspeed: 0.0415s/iter; left time: 351.0720s\n",
      "\titers: 700, epoch: 1 | loss: 0.4430440\n",
      "\tspeed: 0.0421s/iter; left time: 352.0726s\n",
      "\titers: 800, epoch: 1 | loss: 0.3778132\n",
      "\tspeed: 0.0418s/iter; left time: 345.1932s\n",
      "\titers: 900, epoch: 1 | loss: 0.3254126\n",
      "\tspeed: 0.0419s/iter; left time: 342.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.4427820 Vali Loss: 0.3982988 Test Loss: 0.4282602\n",
      "Validation loss decreased (inf --> 0.398299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2804739\n",
      "\tspeed: 0.0988s/iter; left time: 796.0292s\n",
      "\titers: 200, epoch: 2 | loss: 0.3377495\n",
      "\tspeed: 0.0414s/iter; left time: 329.6927s\n",
      "\titers: 300, epoch: 2 | loss: 0.2773281\n",
      "\tspeed: 0.0419s/iter; left time: 328.7367s\n",
      "\titers: 400, epoch: 2 | loss: 0.3087983\n",
      "\tspeed: 0.0409s/iter; left time: 317.3040s\n",
      "\titers: 500, epoch: 2 | loss: 0.2562788\n",
      "\tspeed: 0.0410s/iter; left time: 313.9234s\n",
      "\titers: 600, epoch: 2 | loss: 0.2656093\n",
      "\tspeed: 0.0412s/iter; left time: 311.3232s\n",
      "\titers: 700, epoch: 2 | loss: 0.2561977\n",
      "\tspeed: 0.0411s/iter; left time: 306.7177s\n",
      "\titers: 800, epoch: 2 | loss: 0.3150825\n",
      "\tspeed: 0.0412s/iter; left time: 303.1276s\n",
      "\titers: 900, epoch: 2 | loss: 0.2776596\n",
      "\tspeed: 0.0411s/iter; left time: 298.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.2973151 Vali Loss: 0.3205824 Test Loss: 0.3422310\n",
      "Validation loss decreased (0.398299 --> 0.320582).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2690117\n",
      "\tspeed: 0.0993s/iter; left time: 709.7462s\n",
      "\titers: 200, epoch: 3 | loss: 0.2384343\n",
      "\tspeed: 0.0405s/iter; left time: 285.2551s\n",
      "\titers: 300, epoch: 3 | loss: 0.2611229\n",
      "\tspeed: 0.0406s/iter; left time: 282.3370s\n",
      "\titers: 400, epoch: 3 | loss: 0.2572706\n",
      "\tspeed: 0.0410s/iter; left time: 280.9500s\n",
      "\titers: 500, epoch: 3 | loss: 0.3080456\n",
      "\tspeed: 0.0406s/iter; left time: 273.8350s\n",
      "\titers: 600, epoch: 3 | loss: 0.2688888\n",
      "\tspeed: 0.0408s/iter; left time: 271.4271s\n",
      "\titers: 700, epoch: 3 | loss: 0.2642769\n",
      "\tspeed: 0.0406s/iter; left time: 265.9083s\n",
      "\titers: 800, epoch: 3 | loss: 0.2454304\n",
      "\tspeed: 0.0408s/iter; left time: 263.3297s\n",
      "\titers: 900, epoch: 3 | loss: 0.2539083\n",
      "\tspeed: 0.0407s/iter; left time: 258.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.19s\n",
      "Steps: 906 | Train Loss: 0.2597370 Vali Loss: 0.3142181 Test Loss: 0.3285995\n",
      "Validation loss decreased (0.320582 --> 0.314218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2250671\n",
      "\tspeed: 0.0968s/iter; left time: 604.3000s\n",
      "\titers: 200, epoch: 4 | loss: 0.2457324\n",
      "\tspeed: 0.0408s/iter; left time: 250.4107s\n",
      "\titers: 300, epoch: 4 | loss: 0.2128700\n",
      "\tspeed: 0.0402s/iter; left time: 242.6676s\n",
      "\titers: 400, epoch: 4 | loss: 0.2110046\n",
      "\tspeed: 0.0408s/iter; left time: 242.3396s\n",
      "\titers: 500, epoch: 4 | loss: 0.2696874\n",
      "\tspeed: 0.0411s/iter; left time: 239.8895s\n",
      "\titers: 600, epoch: 4 | loss: 0.2251461\n",
      "\tspeed: 0.0385s/iter; left time: 221.3158s\n",
      "\titers: 700, epoch: 4 | loss: 0.2191906\n",
      "\tspeed: 0.0408s/iter; left time: 230.1066s\n",
      "\titers: 800, epoch: 4 | loss: 0.2617375\n",
      "\tspeed: 0.0410s/iter; left time: 227.4752s\n",
      "\titers: 900, epoch: 4 | loss: 0.2439935\n",
      "\tspeed: 0.0406s/iter; left time: 220.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.2418955 Vali Loss: 0.3180152 Test Loss: 0.3273972\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2380923\n",
      "\tspeed: 0.0951s/iter; left time: 507.4897s\n",
      "\titers: 200, epoch: 5 | loss: 0.2289899\n",
      "\tspeed: 0.0411s/iter; left time: 215.0195s\n",
      "\titers: 300, epoch: 5 | loss: 0.2038423\n",
      "\tspeed: 0.0412s/iter; left time: 211.5357s\n",
      "\titers: 400, epoch: 5 | loss: 0.2334992\n",
      "\tspeed: 0.0404s/iter; left time: 203.3877s\n",
      "\titers: 500, epoch: 5 | loss: 0.2128963\n",
      "\tspeed: 0.0406s/iter; left time: 200.6080s\n",
      "\titers: 600, epoch: 5 | loss: 0.2266824\n",
      "\tspeed: 0.0410s/iter; left time: 198.3568s\n",
      "\titers: 700, epoch: 5 | loss: 0.2089754\n",
      "\tspeed: 0.0409s/iter; left time: 193.5792s\n",
      "\titers: 800, epoch: 5 | loss: 0.2322671\n",
      "\tspeed: 0.0415s/iter; left time: 192.2096s\n",
      "\titers: 900, epoch: 5 | loss: 0.2445696\n",
      "\tspeed: 0.0406s/iter; left time: 184.4162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.38s\n",
      "Steps: 906 | Train Loss: 0.2234831 Vali Loss: 0.3125368 Test Loss: 0.3303335\n",
      "Validation loss decreased (0.314218 --> 0.312537).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2415015\n",
      "\tspeed: 0.0985s/iter; left time: 436.4454s\n",
      "\titers: 200, epoch: 6 | loss: 0.2221936\n",
      "\tspeed: 0.0408s/iter; left time: 176.8517s\n",
      "\titers: 300, epoch: 6 | loss: 0.2190171\n",
      "\tspeed: 0.0410s/iter; left time: 173.4680s\n",
      "\titers: 400, epoch: 6 | loss: 0.1934973\n",
      "\tspeed: 0.0415s/iter; left time: 171.3316s\n",
      "\titers: 500, epoch: 6 | loss: 0.2184666\n",
      "\tspeed: 0.0413s/iter; left time: 166.3530s\n",
      "\titers: 600, epoch: 6 | loss: 0.1856182\n",
      "\tspeed: 0.0408s/iter; left time: 160.2082s\n",
      "\titers: 700, epoch: 6 | loss: 0.2177500\n",
      "\tspeed: 0.0411s/iter; left time: 157.5764s\n",
      "\titers: 800, epoch: 6 | loss: 0.1806344\n",
      "\tspeed: 0.0399s/iter; left time: 148.9734s\n",
      "\titers: 900, epoch: 6 | loss: 0.1849925\n",
      "\tspeed: 0.0414s/iter; left time: 150.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.39s\n",
      "Steps: 906 | Train Loss: 0.2066747 Vali Loss: 0.3162780 Test Loss: 0.3311647\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1853101\n",
      "\tspeed: 0.0949s/iter; left time: 334.6788s\n",
      "\titers: 200, epoch: 7 | loss: 0.2129820\n",
      "\tspeed: 0.0417s/iter; left time: 142.7853s\n",
      "\titers: 300, epoch: 7 | loss: 0.2126344\n",
      "\tspeed: 0.0413s/iter; left time: 137.1671s\n",
      "\titers: 400, epoch: 7 | loss: 0.2076884\n",
      "\tspeed: 0.0412s/iter; left time: 132.7986s\n",
      "\titers: 500, epoch: 7 | loss: 0.1888626\n",
      "\tspeed: 0.0414s/iter; left time: 129.3626s\n",
      "\titers: 600, epoch: 7 | loss: 0.1700548\n",
      "\tspeed: 0.0411s/iter; left time: 124.1805s\n",
      "\titers: 700, epoch: 7 | loss: 0.1932032\n",
      "\tspeed: 0.0413s/iter; left time: 120.8929s\n",
      "\titers: 800, epoch: 7 | loss: 0.1791998\n",
      "\tspeed: 0.0412s/iter; left time: 116.5253s\n",
      "\titers: 900, epoch: 7 | loss: 0.1883053\n",
      "\tspeed: 0.0410s/iter; left time: 111.7766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.63s\n",
      "Steps: 906 | Train Loss: 0.1914722 Vali Loss: 0.3156435 Test Loss: 0.3311698\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2017332\n",
      "\tspeed: 0.0952s/iter; left time: 249.2589s\n",
      "\titers: 200, epoch: 8 | loss: 0.1626274\n",
      "\tspeed: 0.0417s/iter; left time: 105.0512s\n",
      "\titers: 300, epoch: 8 | loss: 0.1812320\n",
      "\tspeed: 0.0421s/iter; left time: 101.8968s\n",
      "\titers: 400, epoch: 8 | loss: 0.1838018\n",
      "\tspeed: 0.0415s/iter; left time: 96.1870s\n",
      "\titers: 500, epoch: 8 | loss: 0.1742301\n",
      "\tspeed: 0.0413s/iter; left time: 91.5576s\n",
      "\titers: 600, epoch: 8 | loss: 0.1731493\n",
      "\tspeed: 0.0417s/iter; left time: 88.3938s\n",
      "\titers: 700, epoch: 8 | loss: 0.1972015\n",
      "\tspeed: 0.0416s/iter; left time: 83.9809s\n",
      "\titers: 800, epoch: 8 | loss: 0.1981479\n",
      "\tspeed: 0.0411s/iter; left time: 78.9621s\n",
      "\titers: 900, epoch: 8 | loss: 0.1921657\n",
      "\tspeed: 0.0409s/iter; left time: 74.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.1776122 Vali Loss: 0.3201008 Test Loss: 0.3358350\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2680671215057373, rmse:0.5177519917488098, mae:0.3305746614933014, rse:0.5032839775085449\n",
      "Original data scale mse:20925334.0, rmse:4574.421875, mae:2752.579833984375, rse:0.2274494618177414\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5566037\n",
      "\tspeed: 0.0438s/iter; left time: 392.5990s\n",
      "\titers: 200, epoch: 1 | loss: 0.4855234\n",
      "\tspeed: 0.0411s/iter; left time: 363.9307s\n",
      "\titers: 300, epoch: 1 | loss: 0.4929893\n",
      "\tspeed: 0.0413s/iter; left time: 362.1254s\n",
      "\titers: 400, epoch: 1 | loss: 0.3975788\n",
      "\tspeed: 0.0412s/iter; left time: 357.1858s\n",
      "\titers: 500, epoch: 1 | loss: 0.4330063\n",
      "\tspeed: 0.0411s/iter; left time: 351.6737s\n",
      "\titers: 600, epoch: 1 | loss: 0.4184310\n",
      "\tspeed: 0.0414s/iter; left time: 350.0614s\n",
      "\titers: 700, epoch: 1 | loss: 0.3660325\n",
      "\tspeed: 0.0413s/iter; left time: 344.9100s\n",
      "\titers: 800, epoch: 1 | loss: 0.3101686\n",
      "\tspeed: 0.0415s/iter; left time: 342.8760s\n",
      "\titers: 900, epoch: 1 | loss: 0.3513955\n",
      "\tspeed: 0.0408s/iter; left time: 333.1889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.66s\n",
      "Steps: 906 | Train Loss: 0.4423631 Vali Loss: 0.3976679 Test Loss: 0.4292906\n",
      "Validation loss decreased (inf --> 0.397668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3478977\n",
      "\tspeed: 0.0986s/iter; left time: 794.1546s\n",
      "\titers: 200, epoch: 2 | loss: 0.2805927\n",
      "\tspeed: 0.0410s/iter; left time: 326.1892s\n",
      "\titers: 300, epoch: 2 | loss: 0.2551276\n",
      "\tspeed: 0.0409s/iter; left time: 321.4632s\n",
      "\titers: 400, epoch: 2 | loss: 0.3163478\n",
      "\tspeed: 0.0411s/iter; left time: 318.8201s\n",
      "\titers: 500, epoch: 2 | loss: 0.2456428\n",
      "\tspeed: 0.0412s/iter; left time: 315.1961s\n",
      "\titers: 600, epoch: 2 | loss: 0.2977647\n",
      "\tspeed: 0.0410s/iter; left time: 310.0350s\n",
      "\titers: 700, epoch: 2 | loss: 0.2762544\n",
      "\tspeed: 0.0411s/iter; left time: 306.6163s\n",
      "\titers: 800, epoch: 2 | loss: 0.2769859\n",
      "\tspeed: 0.0411s/iter; left time: 302.3655s\n",
      "\titers: 900, epoch: 2 | loss: 0.2938291\n",
      "\tspeed: 0.0412s/iter; left time: 298.8095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.49s\n",
      "Steps: 906 | Train Loss: 0.2961741 Vali Loss: 0.3188580 Test Loss: 0.3396104\n",
      "Validation loss decreased (0.397668 --> 0.318858).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2537711\n",
      "\tspeed: 0.0989s/iter; left time: 707.3695s\n",
      "\titers: 200, epoch: 3 | loss: 0.3213524\n",
      "\tspeed: 0.0412s/iter; left time: 290.5745s\n",
      "\titers: 300, epoch: 3 | loss: 0.2701304\n",
      "\tspeed: 0.0413s/iter; left time: 287.2167s\n",
      "\titers: 400, epoch: 3 | loss: 0.3002693\n",
      "\tspeed: 0.0415s/iter; left time: 284.4513s\n",
      "\titers: 500, epoch: 3 | loss: 0.2725642\n",
      "\tspeed: 0.0414s/iter; left time: 279.3967s\n",
      "\titers: 600, epoch: 3 | loss: 0.2312220\n",
      "\tspeed: 0.0413s/iter; left time: 274.7013s\n",
      "\titers: 700, epoch: 3 | loss: 0.2424035\n",
      "\tspeed: 0.0411s/iter; left time: 269.3769s\n",
      "\titers: 800, epoch: 3 | loss: 0.2456405\n",
      "\tspeed: 0.0420s/iter; left time: 270.7028s\n",
      "\titers: 900, epoch: 3 | loss: 0.2441261\n",
      "\tspeed: 0.0414s/iter; left time: 262.8582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.2592560 Vali Loss: 0.3163091 Test Loss: 0.3191819\n",
      "Validation loss decreased (0.318858 --> 0.316309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2610521\n",
      "\tspeed: 0.0991s/iter; left time: 618.4895s\n",
      "\titers: 200, epoch: 4 | loss: 0.2230835\n",
      "\tspeed: 0.0408s/iter; left time: 250.6327s\n",
      "\titers: 300, epoch: 4 | loss: 0.2567629\n",
      "\tspeed: 0.0415s/iter; left time: 250.8134s\n",
      "\titers: 400, epoch: 4 | loss: 0.2564912\n",
      "\tspeed: 0.0415s/iter; left time: 246.7440s\n",
      "\titers: 500, epoch: 4 | loss: 0.2714780\n",
      "\tspeed: 0.0414s/iter; left time: 242.0717s\n",
      "\titers: 600, epoch: 4 | loss: 0.2738412\n",
      "\tspeed: 0.0412s/iter; left time: 236.4260s\n",
      "\titers: 700, epoch: 4 | loss: 0.2382569\n",
      "\tspeed: 0.0413s/iter; left time: 232.8950s\n",
      "\titers: 800, epoch: 4 | loss: 0.2262008\n",
      "\tspeed: 0.0413s/iter; left time: 229.0016s\n",
      "\titers: 900, epoch: 4 | loss: 0.2340984\n",
      "\tspeed: 0.0414s/iter; left time: 225.4275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 906 | Train Loss: 0.2395558 Vali Loss: 0.3143098 Test Loss: 0.3239972\n",
      "Validation loss decreased (0.316309 --> 0.314310).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2121494\n",
      "\tspeed: 0.0985s/iter; left time: 525.5184s\n",
      "\titers: 200, epoch: 5 | loss: 0.2297910\n",
      "\tspeed: 0.0412s/iter; left time: 215.7144s\n",
      "\titers: 300, epoch: 5 | loss: 0.2057274\n",
      "\tspeed: 0.0415s/iter; left time: 213.0884s\n",
      "\titers: 400, epoch: 5 | loss: 0.2403576\n",
      "\tspeed: 0.0409s/iter; left time: 206.0549s\n",
      "\titers: 500, epoch: 5 | loss: 0.2741929\n",
      "\tspeed: 0.0411s/iter; left time: 202.8714s\n",
      "\titers: 600, epoch: 5 | loss: 0.2258921\n",
      "\tspeed: 0.0410s/iter; left time: 198.3803s\n",
      "\titers: 700, epoch: 5 | loss: 0.2325047\n",
      "\tspeed: 0.0413s/iter; left time: 195.7010s\n",
      "\titers: 800, epoch: 5 | loss: 0.2602603\n",
      "\tspeed: 0.0405s/iter; left time: 187.8126s\n",
      "\titers: 900, epoch: 5 | loss: 0.2216712\n",
      "\tspeed: 0.0414s/iter; left time: 187.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.55s\n",
      "Steps: 906 | Train Loss: 0.2190568 Vali Loss: 0.3184572 Test Loss: 0.3248944\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1876422\n",
      "\tspeed: 0.0950s/iter; left time: 420.9275s\n",
      "\titers: 200, epoch: 6 | loss: 0.2033045\n",
      "\tspeed: 0.0418s/iter; left time: 181.1851s\n",
      "\titers: 300, epoch: 6 | loss: 0.2030822\n",
      "\tspeed: 0.0421s/iter; left time: 178.3249s\n",
      "\titers: 400, epoch: 6 | loss: 0.2027894\n",
      "\tspeed: 0.0422s/iter; left time: 174.3821s\n",
      "\titers: 500, epoch: 6 | loss: 0.2005013\n",
      "\tspeed: 0.0425s/iter; left time: 171.1191s\n",
      "\titers: 600, epoch: 6 | loss: 0.1730578\n",
      "\tspeed: 0.0424s/iter; left time: 166.6613s\n",
      "\titers: 700, epoch: 6 | loss: 0.1952004\n",
      "\tspeed: 0.0422s/iter; left time: 161.8134s\n",
      "\titers: 800, epoch: 6 | loss: 0.1946093\n",
      "\tspeed: 0.0415s/iter; left time: 154.8508s\n",
      "\titers: 900, epoch: 6 | loss: 0.1947548\n",
      "\tspeed: 0.0425s/iter; left time: 154.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.2006993 Vali Loss: 0.3187766 Test Loss: 0.3294612\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2075318\n",
      "\tspeed: 0.0956s/iter; left time: 336.9367s\n",
      "\titers: 200, epoch: 7 | loss: 0.1894392\n",
      "\tspeed: 0.0411s/iter; left time: 140.8365s\n",
      "\titers: 300, epoch: 7 | loss: 0.2006222\n",
      "\tspeed: 0.0411s/iter; left time: 136.5702s\n",
      "\titers: 400, epoch: 7 | loss: 0.1985264\n",
      "\tspeed: 0.0411s/iter; left time: 132.6394s\n",
      "\titers: 500, epoch: 7 | loss: 0.1957365\n",
      "\tspeed: 0.0413s/iter; left time: 128.9065s\n",
      "\titers: 600, epoch: 7 | loss: 0.2047793\n",
      "\tspeed: 0.0416s/iter; left time: 125.9257s\n",
      "\titers: 700, epoch: 7 | loss: 0.1904843\n",
      "\tspeed: 0.0411s/iter; left time: 120.0979s\n",
      "\titers: 800, epoch: 7 | loss: 0.1808072\n",
      "\tspeed: 0.0408s/iter; left time: 115.2810s\n",
      "\titers: 900, epoch: 7 | loss: 0.1779598\n",
      "\tspeed: 0.0408s/iter; left time: 111.3081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.48s\n",
      "Steps: 906 | Train Loss: 0.1857852 Vali Loss: 0.3266283 Test Loss: 0.3319425\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2553166449069977, rmse:0.5052886605262756, mae:0.3241082429885864, rse:0.49116891622543335\n",
      "Original data scale mse:19889488.0, rmse:4459.76318359375, mae:2691.116943359375, rse:0.22174841165542603\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6115588\n",
      "\tspeed: 0.0797s/iter; left time: 712.2854s\n",
      "\titers: 200, epoch: 1 | loss: 0.5830034\n",
      "\tspeed: 0.0498s/iter; left time: 440.4276s\n",
      "\titers: 300, epoch: 1 | loss: 0.5585816\n",
      "\tspeed: 0.0502s/iter; left time: 439.0679s\n",
      "\titers: 400, epoch: 1 | loss: 0.5200341\n",
      "\tspeed: 0.0501s/iter; left time: 433.0990s\n",
      "\titers: 500, epoch: 1 | loss: 0.5049127\n",
      "\tspeed: 0.0490s/iter; left time: 418.2705s\n",
      "\titers: 600, epoch: 1 | loss: 0.4407553\n",
      "\tspeed: 0.0477s/iter; left time: 402.6346s\n",
      "\titers: 700, epoch: 1 | loss: 0.4462834\n",
      "\tspeed: 0.0476s/iter; left time: 397.2090s\n",
      "\titers: 800, epoch: 1 | loss: 0.4579721\n",
      "\tspeed: 0.0477s/iter; left time: 393.2951s\n",
      "\titers: 900, epoch: 1 | loss: 0.4630652\n",
      "\tspeed: 0.0477s/iter; left time: 387.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.89s\n",
      "Steps: 904 | Train Loss: 0.5222275 Vali Loss: 0.5014924 Test Loss: 0.5682946\n",
      "Validation loss decreased (inf --> 0.501492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4238201\n",
      "\tspeed: 0.1163s/iter; left time: 934.7350s\n",
      "\titers: 200, epoch: 2 | loss: 0.4197856\n",
      "\tspeed: 0.0478s/iter; left time: 379.6160s\n",
      "\titers: 300, epoch: 2 | loss: 0.4010336\n",
      "\tspeed: 0.0477s/iter; left time: 373.4727s\n",
      "\titers: 400, epoch: 2 | loss: 0.3804184\n",
      "\tspeed: 0.0476s/iter; left time: 368.6671s\n",
      "\titers: 500, epoch: 2 | loss: 0.3713737\n",
      "\tspeed: 0.0478s/iter; left time: 365.3334s\n",
      "\titers: 600, epoch: 2 | loss: 0.3904136\n",
      "\tspeed: 0.0478s/iter; left time: 360.5583s\n",
      "\titers: 700, epoch: 2 | loss: 0.3579198\n",
      "\tspeed: 0.0477s/iter; left time: 354.7340s\n",
      "\titers: 800, epoch: 2 | loss: 0.4012666\n",
      "\tspeed: 0.0477s/iter; left time: 349.7325s\n",
      "\titers: 900, epoch: 2 | loss: 0.3565502\n",
      "\tspeed: 0.0477s/iter; left time: 345.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.3944836 Vali Loss: 0.4238538 Test Loss: 0.4699799\n",
      "Validation loss decreased (0.501492 --> 0.423854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3834203\n",
      "\tspeed: 0.1183s/iter; left time: 844.1135s\n",
      "\titers: 200, epoch: 3 | loss: 0.3331022\n",
      "\tspeed: 0.0465s/iter; left time: 326.9839s\n",
      "\titers: 300, epoch: 3 | loss: 0.3204759\n",
      "\tspeed: 0.0475s/iter; left time: 329.4874s\n",
      "\titers: 400, epoch: 3 | loss: 0.3179659\n",
      "\tspeed: 0.0476s/iter; left time: 325.1116s\n",
      "\titers: 500, epoch: 3 | loss: 0.3535420\n",
      "\tspeed: 0.0476s/iter; left time: 320.3981s\n",
      "\titers: 600, epoch: 3 | loss: 0.3607985\n",
      "\tspeed: 0.0471s/iter; left time: 312.2394s\n",
      "\titers: 700, epoch: 3 | loss: 0.3019953\n",
      "\tspeed: 0.0478s/iter; left time: 312.4561s\n",
      "\titers: 800, epoch: 3 | loss: 0.3429635\n",
      "\tspeed: 0.0477s/iter; left time: 306.7711s\n",
      "\titers: 900, epoch: 3 | loss: 0.3431078\n",
      "\tspeed: 0.0474s/iter; left time: 300.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.3435943 Vali Loss: 0.4145606 Test Loss: 0.4659684\n",
      "Validation loss decreased (0.423854 --> 0.414561).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3050880\n",
      "\tspeed: 0.1148s/iter; left time: 715.1471s\n",
      "\titers: 200, epoch: 4 | loss: 0.3034989\n",
      "\tspeed: 0.0476s/iter; left time: 291.5346s\n",
      "\titers: 300, epoch: 4 | loss: 0.2979394\n",
      "\tspeed: 0.0475s/iter; left time: 286.6201s\n",
      "\titers: 400, epoch: 4 | loss: 0.2685758\n",
      "\tspeed: 0.0477s/iter; left time: 282.9583s\n",
      "\titers: 500, epoch: 4 | loss: 0.3442597\n",
      "\tspeed: 0.0477s/iter; left time: 278.2956s\n",
      "\titers: 600, epoch: 4 | loss: 0.2796071\n",
      "\tspeed: 0.0480s/iter; left time: 274.8312s\n",
      "\titers: 700, epoch: 4 | loss: 0.3278911\n",
      "\tspeed: 0.0479s/iter; left time: 269.5798s\n",
      "\titers: 800, epoch: 4 | loss: 0.2960745\n",
      "\tspeed: 0.0478s/iter; left time: 264.0864s\n",
      "\titers: 900, epoch: 4 | loss: 0.3270479\n",
      "\tspeed: 0.0477s/iter; left time: 259.1941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.36s\n",
      "Steps: 904 | Train Loss: 0.3128055 Vali Loss: 0.4168210 Test Loss: 0.4725619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2866268\n",
      "\tspeed: 0.1125s/iter; left time: 599.0107s\n",
      "\titers: 200, epoch: 5 | loss: 0.3179915\n",
      "\tspeed: 0.0478s/iter; left time: 249.5503s\n",
      "\titers: 300, epoch: 5 | loss: 0.2972972\n",
      "\tspeed: 0.0478s/iter; left time: 244.9077s\n",
      "\titers: 400, epoch: 5 | loss: 0.2920378\n",
      "\tspeed: 0.0477s/iter; left time: 239.7471s\n",
      "\titers: 500, epoch: 5 | loss: 0.2694999\n",
      "\tspeed: 0.0477s/iter; left time: 234.8159s\n",
      "\titers: 600, epoch: 5 | loss: 0.2672861\n",
      "\tspeed: 0.0477s/iter; left time: 230.1917s\n",
      "\titers: 700, epoch: 5 | loss: 0.2841391\n",
      "\tspeed: 0.0478s/iter; left time: 225.9362s\n",
      "\titers: 800, epoch: 5 | loss: 0.2562101\n",
      "\tspeed: 0.0477s/iter; left time: 220.7512s\n",
      "\titers: 900, epoch: 5 | loss: 0.2718032\n",
      "\tspeed: 0.0475s/iter; left time: 215.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.34s\n",
      "Steps: 904 | Train Loss: 0.2853150 Vali Loss: 0.4071884 Test Loss: 0.4732395\n",
      "Validation loss decreased (0.414561 --> 0.407188).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2535943\n",
      "\tspeed: 0.1151s/iter; left time: 508.7409s\n",
      "\titers: 200, epoch: 6 | loss: 0.2458549\n",
      "\tspeed: 0.0478s/iter; left time: 206.3470s\n",
      "\titers: 300, epoch: 6 | loss: 0.2757922\n",
      "\tspeed: 0.0476s/iter; left time: 201.1151s\n",
      "\titers: 400, epoch: 6 | loss: 0.2618496\n",
      "\tspeed: 0.0475s/iter; left time: 195.6966s\n",
      "\titers: 500, epoch: 6 | loss: 0.2467890\n",
      "\tspeed: 0.0475s/iter; left time: 191.0373s\n",
      "\titers: 600, epoch: 6 | loss: 0.2800977\n",
      "\tspeed: 0.0475s/iter; left time: 186.2829s\n",
      "\titers: 700, epoch: 6 | loss: 0.2484103\n",
      "\tspeed: 0.0475s/iter; left time: 181.6139s\n",
      "\titers: 800, epoch: 6 | loss: 0.2790080\n",
      "\tspeed: 0.0473s/iter; left time: 176.1074s\n",
      "\titers: 900, epoch: 6 | loss: 0.2538236\n",
      "\tspeed: 0.0474s/iter; left time: 171.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.2627822 Vali Loss: 0.4273484 Test Loss: 0.4729554\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2240744\n",
      "\tspeed: 0.1142s/iter; left time: 401.7001s\n",
      "\titers: 200, epoch: 7 | loss: 0.2229967\n",
      "\tspeed: 0.0485s/iter; left time: 165.6490s\n",
      "\titers: 300, epoch: 7 | loss: 0.2495193\n",
      "\tspeed: 0.0503s/iter; left time: 166.9682s\n",
      "\titers: 400, epoch: 7 | loss: 0.2350299\n",
      "\tspeed: 0.0481s/iter; left time: 154.5851s\n",
      "\titers: 500, epoch: 7 | loss: 0.2283342\n",
      "\tspeed: 0.0484s/iter; left time: 150.7682s\n",
      "\titers: 600, epoch: 7 | loss: 0.2313164\n",
      "\tspeed: 0.0504s/iter; left time: 152.0069s\n",
      "\titers: 700, epoch: 7 | loss: 0.2368815\n",
      "\tspeed: 0.0481s/iter; left time: 140.3163s\n",
      "\titers: 800, epoch: 7 | loss: 0.2292707\n",
      "\tspeed: 0.0477s/iter; left time: 134.3031s\n",
      "\titers: 900, epoch: 7 | loss: 0.2431902\n",
      "\tspeed: 0.0477s/iter; left time: 129.6621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.10s\n",
      "Steps: 904 | Train Loss: 0.2428129 Vali Loss: 0.4339893 Test Loss: 0.4815975\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2290939\n",
      "\tspeed: 0.1175s/iter; left time: 306.9440s\n",
      "\titers: 200, epoch: 8 | loss: 0.2398908\n",
      "\tspeed: 0.0493s/iter; left time: 123.8572s\n",
      "\titers: 300, epoch: 8 | loss: 0.2407383\n",
      "\tspeed: 0.0476s/iter; left time: 114.7567s\n",
      "\titers: 400, epoch: 8 | loss: 0.2275654\n",
      "\tspeed: 0.0474s/iter; left time: 109.5560s\n",
      "\titers: 500, epoch: 8 | loss: 0.2447397\n",
      "\tspeed: 0.0475s/iter; left time: 105.2197s\n",
      "\titers: 600, epoch: 8 | loss: 0.2316028\n",
      "\tspeed: 0.0477s/iter; left time: 100.8635s\n",
      "\titers: 700, epoch: 8 | loss: 0.2377874\n",
      "\tspeed: 0.0476s/iter; left time: 95.7187s\n",
      "\titers: 800, epoch: 8 | loss: 0.2231112\n",
      "\tspeed: 0.0475s/iter; left time: 90.8132s\n",
      "\titers: 900, epoch: 8 | loss: 0.2186633\n",
      "\tspeed: 0.0475s/iter; left time: 86.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.63s\n",
      "Steps: 904 | Train Loss: 0.2271254 Vali Loss: 0.4367002 Test Loss: 0.4786476\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.49115902185440063, rmse:0.7008273601531982, mae:0.47365128993988037, rse:0.6816441416740417\n",
      "Original data scale mse:40326344.0, rmse:6350.302734375, mae:3975.054931640625, rse:0.3162473440170288\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6034825\n",
      "\tspeed: 0.0502s/iter; left time: 449.1263s\n",
      "\titers: 200, epoch: 1 | loss: 0.5507028\n",
      "\tspeed: 0.0474s/iter; left time: 418.7115s\n",
      "\titers: 300, epoch: 1 | loss: 0.5007508\n",
      "\tspeed: 0.0473s/iter; left time: 413.3687s\n",
      "\titers: 400, epoch: 1 | loss: 0.4743139\n",
      "\tspeed: 0.0476s/iter; left time: 411.2996s\n",
      "\titers: 500, epoch: 1 | loss: 0.4567157\n",
      "\tspeed: 0.0487s/iter; left time: 415.6614s\n",
      "\titers: 600, epoch: 1 | loss: 0.4999577\n",
      "\tspeed: 0.0477s/iter; left time: 402.7384s\n",
      "\titers: 700, epoch: 1 | loss: 0.4845823\n",
      "\tspeed: 0.0488s/iter; left time: 406.7401s\n",
      "\titers: 800, epoch: 1 | loss: 0.4760923\n",
      "\tspeed: 0.0478s/iter; left time: 393.8507s\n",
      "\titers: 900, epoch: 1 | loss: 0.4509124\n",
      "\tspeed: 0.0477s/iter; left time: 387.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.58s\n",
      "Steps: 904 | Train Loss: 0.5182869 Vali Loss: 0.5017161 Test Loss: 0.5734323\n",
      "Validation loss decreased (inf --> 0.501716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3873321\n",
      "\tspeed: 0.1236s/iter; left time: 993.7370s\n",
      "\titers: 200, epoch: 2 | loss: 0.4113899\n",
      "\tspeed: 0.0478s/iter; left time: 378.9980s\n",
      "\titers: 300, epoch: 2 | loss: 0.3677758\n",
      "\tspeed: 0.0478s/iter; left time: 374.3053s\n",
      "\titers: 400, epoch: 2 | loss: 0.3784696\n",
      "\tspeed: 0.0476s/iter; left time: 368.5128s\n",
      "\titers: 500, epoch: 2 | loss: 0.3737342\n",
      "\tspeed: 0.0473s/iter; left time: 360.9292s\n",
      "\titers: 600, epoch: 2 | loss: 0.3858809\n",
      "\tspeed: 0.0476s/iter; left time: 358.9158s\n",
      "\titers: 700, epoch: 2 | loss: 0.3894660\n",
      "\tspeed: 0.0476s/iter; left time: 353.9038s\n",
      "\titers: 800, epoch: 2 | loss: 0.3639689\n",
      "\tspeed: 0.0475s/iter; left time: 348.2904s\n",
      "\titers: 900, epoch: 2 | loss: 0.3597989\n",
      "\tspeed: 0.0476s/iter; left time: 344.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.29s\n",
      "Steps: 904 | Train Loss: 0.3961964 Vali Loss: 0.4373525 Test Loss: 0.4658424\n",
      "Validation loss decreased (0.501716 --> 0.437353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3567201\n",
      "\tspeed: 0.1175s/iter; left time: 838.2160s\n",
      "\titers: 200, epoch: 3 | loss: 0.4051770\n",
      "\tspeed: 0.0480s/iter; left time: 337.6048s\n",
      "\titers: 300, epoch: 3 | loss: 0.3684655\n",
      "\tspeed: 0.0478s/iter; left time: 331.5409s\n",
      "\titers: 400, epoch: 3 | loss: 0.3487606\n",
      "\tspeed: 0.0478s/iter; left time: 326.4767s\n",
      "\titers: 500, epoch: 3 | loss: 0.3234715\n",
      "\tspeed: 0.0478s/iter; left time: 322.0905s\n",
      "\titers: 600, epoch: 3 | loss: 0.3506857\n",
      "\tspeed: 0.0479s/iter; left time: 317.9064s\n",
      "\titers: 700, epoch: 3 | loss: 0.3182862\n",
      "\tspeed: 0.0478s/iter; left time: 312.4605s\n",
      "\titers: 800, epoch: 3 | loss: 0.3413826\n",
      "\tspeed: 0.0478s/iter; left time: 307.6318s\n",
      "\titers: 900, epoch: 3 | loss: 0.3494556\n",
      "\tspeed: 0.0477s/iter; left time: 301.7996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 904 | Train Loss: 0.3447624 Vali Loss: 0.4335651 Test Loss: 0.4499207\n",
      "Validation loss decreased (0.437353 --> 0.433565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2904501\n",
      "\tspeed: 0.1185s/iter; left time: 738.3520s\n",
      "\titers: 200, epoch: 4 | loss: 0.3086890\n",
      "\tspeed: 0.0478s/iter; left time: 293.0076s\n",
      "\titers: 300, epoch: 4 | loss: 0.3202746\n",
      "\tspeed: 0.0480s/iter; left time: 289.3755s\n",
      "\titers: 400, epoch: 4 | loss: 0.2983309\n",
      "\tspeed: 0.0480s/iter; left time: 284.5372s\n",
      "\titers: 500, epoch: 4 | loss: 0.3225928\n",
      "\tspeed: 0.0478s/iter; left time: 278.4072s\n",
      "\titers: 600, epoch: 4 | loss: 0.3050541\n",
      "\tspeed: 0.0479s/iter; left time: 274.2229s\n",
      "\titers: 700, epoch: 4 | loss: 0.3180465\n",
      "\tspeed: 0.0477s/iter; left time: 268.3103s\n",
      "\titers: 800, epoch: 4 | loss: 0.2744825\n",
      "\tspeed: 0.0481s/iter; left time: 266.1402s\n",
      "\titers: 900, epoch: 4 | loss: 0.2725351\n",
      "\tspeed: 0.0479s/iter; left time: 260.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.53s\n",
      "Steps: 904 | Train Loss: 0.3125584 Vali Loss: 0.4253437 Test Loss: 0.4791566\n",
      "Validation loss decreased (0.433565 --> 0.425344).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2844376\n",
      "\tspeed: 0.1177s/iter; left time: 626.9919s\n",
      "\titers: 200, epoch: 5 | loss: 0.2873303\n",
      "\tspeed: 0.0470s/iter; left time: 245.8163s\n",
      "\titers: 300, epoch: 5 | loss: 0.2829492\n",
      "\tspeed: 0.0480s/iter; left time: 246.1455s\n",
      "\titers: 400, epoch: 5 | loss: 0.2643508\n",
      "\tspeed: 0.0478s/iter; left time: 240.2072s\n",
      "\titers: 500, epoch: 5 | loss: 0.2685104\n",
      "\tspeed: 0.0479s/iter; left time: 236.0348s\n",
      "\titers: 600, epoch: 5 | loss: 0.2810370\n",
      "\tspeed: 0.0480s/iter; left time: 231.5605s\n",
      "\titers: 700, epoch: 5 | loss: 0.2994999\n",
      "\tspeed: 0.0479s/iter; left time: 226.2039s\n",
      "\titers: 800, epoch: 5 | loss: 0.2662688\n",
      "\tspeed: 0.0479s/iter; left time: 221.3614s\n",
      "\titers: 900, epoch: 5 | loss: 0.2622414\n",
      "\tspeed: 0.0476s/iter; left time: 215.2954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.2855324 Vali Loss: 0.4168544 Test Loss: 0.4586405\n",
      "Validation loss decreased (0.425344 --> 0.416854).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2860955\n",
      "\tspeed: 0.1171s/iter; left time: 517.6671s\n",
      "\titers: 200, epoch: 6 | loss: 0.2661182\n",
      "\tspeed: 0.0504s/iter; left time: 217.9829s\n",
      "\titers: 300, epoch: 6 | loss: 0.2680987\n",
      "\tspeed: 0.0499s/iter; left time: 210.7430s\n",
      "\titers: 400, epoch: 6 | loss: 0.2909117\n",
      "\tspeed: 0.0504s/iter; left time: 207.5001s\n",
      "\titers: 500, epoch: 6 | loss: 0.2655762\n",
      "\tspeed: 0.0492s/iter; left time: 197.9556s\n",
      "\titers: 600, epoch: 6 | loss: 0.2552939\n",
      "\tspeed: 0.0480s/iter; left time: 188.2318s\n",
      "\titers: 700, epoch: 6 | loss: 0.2736236\n",
      "\tspeed: 0.0505s/iter; left time: 193.0812s\n",
      "\titers: 800, epoch: 6 | loss: 0.2536016\n",
      "\tspeed: 0.0504s/iter; left time: 187.6034s\n",
      "\titers: 900, epoch: 6 | loss: 0.2610558\n",
      "\tspeed: 0.0501s/iter; left time: 181.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.17s\n",
      "Steps: 904 | Train Loss: 0.2605563 Vali Loss: 0.4307886 Test Loss: 0.4689623\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2389380\n",
      "\tspeed: 0.1130s/iter; left time: 397.5951s\n",
      "\titers: 200, epoch: 7 | loss: 0.2423452\n",
      "\tspeed: 0.0475s/iter; left time: 162.3969s\n",
      "\titers: 300, epoch: 7 | loss: 0.2450469\n",
      "\tspeed: 0.0476s/iter; left time: 157.9749s\n",
      "\titers: 400, epoch: 7 | loss: 0.2339684\n",
      "\tspeed: 0.0469s/iter; left time: 150.9223s\n",
      "\titers: 500, epoch: 7 | loss: 0.2215564\n",
      "\tspeed: 0.0433s/iter; left time: 134.8236s\n",
      "\titers: 600, epoch: 7 | loss: 0.2500869\n",
      "\tspeed: 0.0354s/iter; left time: 106.6975s\n",
      "\titers: 700, epoch: 7 | loss: 0.2422784\n",
      "\tspeed: 0.0354s/iter; left time: 103.1211s\n",
      "\titers: 800, epoch: 7 | loss: 0.2440853\n",
      "\tspeed: 0.0353s/iter; left time: 99.5181s\n",
      "\titers: 900, epoch: 7 | loss: 0.2354862\n",
      "\tspeed: 0.0353s/iter; left time: 96.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.2408905 Vali Loss: 0.4327017 Test Loss: 0.4888551\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2328618\n",
      "\tspeed: 0.1119s/iter; left time: 292.3571s\n",
      "\titers: 200, epoch: 8 | loss: 0.2090433\n",
      "\tspeed: 0.0475s/iter; left time: 119.3137s\n",
      "\titers: 300, epoch: 8 | loss: 0.2129289\n",
      "\tspeed: 0.0473s/iter; left time: 114.1972s\n",
      "\titers: 400, epoch: 8 | loss: 0.2188863\n",
      "\tspeed: 0.0475s/iter; left time: 109.7770s\n",
      "\titers: 500, epoch: 8 | loss: 0.2201189\n",
      "\tspeed: 0.0474s/iter; left time: 104.8719s\n",
      "\titers: 600, epoch: 8 | loss: 0.2083899\n",
      "\tspeed: 0.0474s/iter; left time: 100.0564s\n",
      "\titers: 700, epoch: 8 | loss: 0.2089313\n",
      "\tspeed: 0.0476s/iter; left time: 95.7690s\n",
      "\titers: 800, epoch: 8 | loss: 0.2221401\n",
      "\tspeed: 0.0474s/iter; left time: 90.6682s\n",
      "\titers: 900, epoch: 8 | loss: 0.2166971\n",
      "\tspeed: 0.0476s/iter; left time: 86.2511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.2233746 Vali Loss: 0.4315720 Test Loss: 0.4907541\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.46618911623954773, rmse:0.6827804446220398, mae:0.458564430475235, rse:0.664091169834137\n",
      "Original data scale mse:37853992.0, rmse:6152.5595703125, mae:3816.9462890625, rse:0.3063996732234955\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5665159\n",
      "\tspeed: 0.0838s/iter; left time: 747.1695s\n",
      "\titers: 200, epoch: 1 | loss: 0.5884684\n",
      "\tspeed: 0.0539s/iter; left time: 475.4272s\n",
      "\titers: 300, epoch: 1 | loss: 0.5519950\n",
      "\tspeed: 0.0538s/iter; left time: 468.9913s\n",
      "\titers: 400, epoch: 1 | loss: 0.5502739\n",
      "\tspeed: 0.0537s/iter; left time: 463.1759s\n",
      "\titers: 500, epoch: 1 | loss: 0.5368783\n",
      "\tspeed: 0.0536s/iter; left time: 456.9799s\n",
      "\titers: 600, epoch: 1 | loss: 0.5454326\n",
      "\tspeed: 0.0536s/iter; left time: 451.1709s\n",
      "\titers: 700, epoch: 1 | loss: 0.5227320\n",
      "\tspeed: 0.0536s/iter; left time: 445.7072s\n",
      "\titers: 800, epoch: 1 | loss: 0.5035548\n",
      "\tspeed: 0.0538s/iter; left time: 442.3618s\n",
      "\titers: 900, epoch: 1 | loss: 0.5218879\n",
      "\tspeed: 0.0537s/iter; left time: 436.4146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.22s\n",
      "Steps: 902 | Train Loss: 0.5507321 Vali Loss: 0.5634081 Test Loss: 0.6531137\n",
      "Validation loss decreased (inf --> 0.563408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5101866\n",
      "\tspeed: 0.1340s/iter; left time: 1074.8517s\n",
      "\titers: 200, epoch: 2 | loss: 0.4751575\n",
      "\tspeed: 0.0538s/iter; left time: 425.8834s\n",
      "\titers: 300, epoch: 2 | loss: 0.4759747\n",
      "\tspeed: 0.0536s/iter; left time: 419.3303s\n",
      "\titers: 400, epoch: 2 | loss: 0.4305736\n",
      "\tspeed: 0.0534s/iter; left time: 412.5197s\n",
      "\titers: 500, epoch: 2 | loss: 0.4167421\n",
      "\tspeed: 0.0534s/iter; left time: 407.0465s\n",
      "\titers: 600, epoch: 2 | loss: 0.3776212\n",
      "\tspeed: 0.0537s/iter; left time: 403.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.3848957\n",
      "\tspeed: 0.0537s/iter; left time: 398.1465s\n",
      "\titers: 800, epoch: 2 | loss: 0.4178534\n",
      "\tspeed: 0.0536s/iter; left time: 392.1942s\n",
      "\titers: 900, epoch: 2 | loss: 0.3925001\n",
      "\tspeed: 0.0535s/iter; left time: 386.2945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.4299240 Vali Loss: 0.4529567 Test Loss: 0.5070729\n",
      "Validation loss decreased (0.563408 --> 0.452957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3886993\n",
      "\tspeed: 0.1351s/iter; left time: 961.2627s\n",
      "\titers: 200, epoch: 3 | loss: 0.3620102\n",
      "\tspeed: 0.0538s/iter; left time: 377.4551s\n",
      "\titers: 300, epoch: 3 | loss: 0.3674082\n",
      "\tspeed: 0.0537s/iter; left time: 371.2189s\n",
      "\titers: 400, epoch: 3 | loss: 0.3940060\n",
      "\tspeed: 0.0537s/iter; left time: 365.8347s\n",
      "\titers: 500, epoch: 3 | loss: 0.3436573\n",
      "\tspeed: 0.0537s/iter; left time: 360.4923s\n",
      "\titers: 600, epoch: 3 | loss: 0.3622456\n",
      "\tspeed: 0.0538s/iter; left time: 356.0556s\n",
      "\titers: 700, epoch: 3 | loss: 0.3702312\n",
      "\tspeed: 0.0535s/iter; left time: 348.9745s\n",
      "\titers: 800, epoch: 3 | loss: 0.3639712\n",
      "\tspeed: 0.0536s/iter; left time: 343.8868s\n",
      "\titers: 900, epoch: 3 | loss: 0.3532930\n",
      "\tspeed: 0.0538s/iter; left time: 339.5642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.3588001 Vali Loss: 0.4448532 Test Loss: 0.5038010\n",
      "Validation loss decreased (0.452957 --> 0.444853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3079253\n",
      "\tspeed: 0.1336s/iter; left time: 830.1163s\n",
      "\titers: 200, epoch: 4 | loss: 0.3025079\n",
      "\tspeed: 0.0537s/iter; left time: 328.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.3541246\n",
      "\tspeed: 0.0537s/iter; left time: 322.7246s\n",
      "\titers: 400, epoch: 4 | loss: 0.3398260\n",
      "\tspeed: 0.0536s/iter; left time: 317.1288s\n",
      "\titers: 500, epoch: 4 | loss: 0.3500948\n",
      "\tspeed: 0.0536s/iter; left time: 311.6731s\n",
      "\titers: 600, epoch: 4 | loss: 0.3118173\n",
      "\tspeed: 0.0538s/iter; left time: 307.3911s\n",
      "\titers: 700, epoch: 4 | loss: 0.3327943\n",
      "\tspeed: 0.0537s/iter; left time: 301.5044s\n",
      "\titers: 800, epoch: 4 | loss: 0.3290806\n",
      "\tspeed: 0.0536s/iter; left time: 295.6559s\n",
      "\titers: 900, epoch: 4 | loss: 0.3236909\n",
      "\tspeed: 0.0537s/iter; left time: 290.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.3237214 Vali Loss: 0.4423192 Test Loss: 0.5003442\n",
      "Validation loss decreased (0.444853 --> 0.442319).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3168175\n",
      "\tspeed: 0.1350s/iter; left time: 717.1128s\n",
      "\titers: 200, epoch: 5 | loss: 0.3164908\n",
      "\tspeed: 0.0538s/iter; left time: 280.3630s\n",
      "\titers: 300, epoch: 5 | loss: 0.2981934\n",
      "\tspeed: 0.0537s/iter; left time: 274.7287s\n",
      "\titers: 400, epoch: 5 | loss: 0.3222495\n",
      "\tspeed: 0.0537s/iter; left time: 269.0692s\n",
      "\titers: 500, epoch: 5 | loss: 0.2552517\n",
      "\tspeed: 0.0537s/iter; left time: 263.5994s\n",
      "\titers: 600, epoch: 5 | loss: 0.2978690\n",
      "\tspeed: 0.0538s/iter; left time: 259.0397s\n",
      "\titers: 700, epoch: 5 | loss: 0.2936289\n",
      "\tspeed: 0.0537s/iter; left time: 252.9585s\n",
      "\titers: 800, epoch: 5 | loss: 0.2867786\n",
      "\tspeed: 0.0536s/iter; left time: 247.4829s\n",
      "\titers: 900, epoch: 5 | loss: 0.2679510\n",
      "\tspeed: 0.0536s/iter; left time: 241.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.2953930 Vali Loss: 0.4466900 Test Loss: 0.5076823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2913139\n",
      "\tspeed: 0.1303s/iter; left time: 574.6056s\n",
      "\titers: 200, epoch: 6 | loss: 0.2818365\n",
      "\tspeed: 0.0536s/iter; left time: 230.8838s\n",
      "\titers: 300, epoch: 6 | loss: 0.2597834\n",
      "\tspeed: 0.0536s/iter; left time: 225.5147s\n",
      "\titers: 400, epoch: 6 | loss: 0.2885118\n",
      "\tspeed: 0.0536s/iter; left time: 220.3492s\n",
      "\titers: 500, epoch: 6 | loss: 0.2647938\n",
      "\tspeed: 0.0537s/iter; left time: 215.5103s\n",
      "\titers: 600, epoch: 6 | loss: 0.2637225\n",
      "\tspeed: 0.0537s/iter; left time: 209.8740s\n",
      "\titers: 700, epoch: 6 | loss: 0.2808955\n",
      "\tspeed: 0.0535s/iter; left time: 203.7058s\n",
      "\titers: 800, epoch: 6 | loss: 0.2594467\n",
      "\tspeed: 0.0536s/iter; left time: 198.9415s\n",
      "\titers: 900, epoch: 6 | loss: 0.2856370\n",
      "\tspeed: 0.0535s/iter; left time: 193.3219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.2722189 Vali Loss: 0.4587447 Test Loss: 0.5145693\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2384547\n",
      "\tspeed: 0.1302s/iter; left time: 457.0042s\n",
      "\titers: 200, epoch: 7 | loss: 0.2461951\n",
      "\tspeed: 0.0526s/iter; left time: 179.3746s\n",
      "\titers: 300, epoch: 7 | loss: 0.2451284\n",
      "\tspeed: 0.0536s/iter; left time: 177.4252s\n",
      "\titers: 400, epoch: 7 | loss: 0.2482292\n",
      "\tspeed: 0.0536s/iter; left time: 172.0546s\n",
      "\titers: 500, epoch: 7 | loss: 0.2463433\n",
      "\tspeed: 0.0536s/iter; left time: 166.7734s\n",
      "\titers: 600, epoch: 7 | loss: 0.2425788\n",
      "\tspeed: 0.0536s/iter; left time: 161.3664s\n",
      "\titers: 700, epoch: 7 | loss: 0.2472399\n",
      "\tspeed: 0.0537s/iter; left time: 156.1295s\n",
      "\titers: 800, epoch: 7 | loss: 0.2364642\n",
      "\tspeed: 0.0536s/iter; left time: 150.6007s\n",
      "\titers: 900, epoch: 7 | loss: 0.2476634\n",
      "\tspeed: 0.0536s/iter; left time: 145.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.2527197 Vali Loss: 0.4603270 Test Loss: 0.5185730\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5403303503990173, rmse:0.7350716590881348, mae:0.5003021359443665, rse:0.7127622365951538\n",
      "Original data scale mse:44810908.0, rmse:6694.09521484375, mae:4207.599609375, rse:0.3335319757461548\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5699619\n",
      "\tspeed: 0.0553s/iter; left time: 493.5435s\n",
      "\titers: 200, epoch: 1 | loss: 0.5475079\n",
      "\tspeed: 0.0537s/iter; left time: 473.9988s\n",
      "\titers: 300, epoch: 1 | loss: 0.5417031\n",
      "\tspeed: 0.0537s/iter; left time: 468.6000s\n",
      "\titers: 400, epoch: 1 | loss: 0.5082975\n",
      "\tspeed: 0.0532s/iter; left time: 458.2316s\n",
      "\titers: 500, epoch: 1 | loss: 0.5247245\n",
      "\tspeed: 0.0536s/iter; left time: 456.9518s\n",
      "\titers: 600, epoch: 1 | loss: 0.5380745\n",
      "\tspeed: 0.0537s/iter; left time: 452.2378s\n",
      "\titers: 700, epoch: 1 | loss: 0.5192104\n",
      "\tspeed: 0.0531s/iter; left time: 441.4557s\n",
      "\titers: 800, epoch: 1 | loss: 0.4973854\n",
      "\tspeed: 0.0536s/iter; left time: 440.6661s\n",
      "\titers: 900, epoch: 1 | loss: 0.5090938\n",
      "\tspeed: 0.0535s/iter; left time: 434.2922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.5505299 Vali Loss: 0.5693076 Test Loss: 0.6601585\n",
      "Validation loss decreased (inf --> 0.569308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4725834\n",
      "\tspeed: 0.1347s/iter; left time: 1080.2065s\n",
      "\titers: 200, epoch: 2 | loss: 0.5003747\n",
      "\tspeed: 0.0536s/iter; left time: 424.3304s\n",
      "\titers: 300, epoch: 2 | loss: 0.4856316\n",
      "\tspeed: 0.0536s/iter; left time: 419.4547s\n",
      "\titers: 400, epoch: 2 | loss: 0.4231773\n",
      "\tspeed: 0.0535s/iter; left time: 413.2790s\n",
      "\titers: 500, epoch: 2 | loss: 0.4233780\n",
      "\tspeed: 0.0536s/iter; left time: 408.5820s\n",
      "\titers: 600, epoch: 2 | loss: 0.4037501\n",
      "\tspeed: 0.0534s/iter; left time: 401.8683s\n",
      "\titers: 700, epoch: 2 | loss: 0.4091046\n",
      "\tspeed: 0.0536s/iter; left time: 397.8873s\n",
      "\titers: 800, epoch: 2 | loss: 0.3730760\n",
      "\tspeed: 0.0533s/iter; left time: 390.0606s\n",
      "\titers: 900, epoch: 2 | loss: 0.4009513\n",
      "\tspeed: 0.0536s/iter; left time: 386.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.4317535 Vali Loss: 0.4519477 Test Loss: 0.4982342\n",
      "Validation loss decreased (0.569308 --> 0.451948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3727932\n",
      "\tspeed: 0.1346s/iter; left time: 958.2392s\n",
      "\titers: 200, epoch: 3 | loss: 0.3425841\n",
      "\tspeed: 0.0535s/iter; left time: 375.6508s\n",
      "\titers: 300, epoch: 3 | loss: 0.3626783\n",
      "\tspeed: 0.0534s/iter; left time: 369.0600s\n",
      "\titers: 400, epoch: 3 | loss: 0.3433390\n",
      "\tspeed: 0.0536s/iter; left time: 365.1928s\n",
      "\titers: 500, epoch: 3 | loss: 0.3574099\n",
      "\tspeed: 0.0535s/iter; left time: 359.2338s\n",
      "\titers: 600, epoch: 3 | loss: 0.3801520\n",
      "\tspeed: 0.0533s/iter; left time: 352.9509s\n",
      "\titers: 700, epoch: 3 | loss: 0.3325544\n",
      "\tspeed: 0.0535s/iter; left time: 348.8115s\n",
      "\titers: 800, epoch: 3 | loss: 0.3610157\n",
      "\tspeed: 0.0534s/iter; left time: 342.4128s\n",
      "\titers: 900, epoch: 3 | loss: 0.3277501\n",
      "\tspeed: 0.0536s/iter; left time: 338.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.46s\n",
      "Steps: 902 | Train Loss: 0.3594171 Vali Loss: 0.4539334 Test Loss: 0.4856634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3178980\n",
      "\tspeed: 0.1310s/iter; left time: 813.9097s\n",
      "\titers: 200, epoch: 4 | loss: 0.3338085\n",
      "\tspeed: 0.0534s/iter; left time: 326.4811s\n",
      "\titers: 300, epoch: 4 | loss: 0.3219782\n",
      "\tspeed: 0.0535s/iter; left time: 321.6389s\n",
      "\titers: 400, epoch: 4 | loss: 0.3341945\n",
      "\tspeed: 0.0533s/iter; left time: 315.2018s\n",
      "\titers: 500, epoch: 4 | loss: 0.3553307\n",
      "\tspeed: 0.0536s/iter; left time: 311.4773s\n",
      "\titers: 600, epoch: 4 | loss: 0.2912029\n",
      "\tspeed: 0.0535s/iter; left time: 305.9248s\n",
      "\titers: 700, epoch: 4 | loss: 0.3311034\n",
      "\tspeed: 0.0535s/iter; left time: 300.5272s\n",
      "\titers: 800, epoch: 4 | loss: 0.3025007\n",
      "\tspeed: 0.0534s/iter; left time: 294.7086s\n",
      "\titers: 900, epoch: 4 | loss: 0.3260762\n",
      "\tspeed: 0.0535s/iter; left time: 289.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.3236151 Vali Loss: 0.4479893 Test Loss: 0.4924225\n",
      "Validation loss decreased (0.451948 --> 0.447989).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2995123\n",
      "\tspeed: 0.1370s/iter; left time: 727.7490s\n",
      "\titers: 200, epoch: 5 | loss: 0.2919329\n",
      "\tspeed: 0.0535s/iter; left time: 278.9356s\n",
      "\titers: 300, epoch: 5 | loss: 0.3060902\n",
      "\tspeed: 0.0534s/iter; left time: 273.2232s\n",
      "\titers: 400, epoch: 5 | loss: 0.2908042\n",
      "\tspeed: 0.0535s/iter; left time: 268.3196s\n",
      "\titers: 500, epoch: 5 | loss: 0.2746396\n",
      "\tspeed: 0.0536s/iter; left time: 263.4237s\n",
      "\titers: 600, epoch: 5 | loss: 0.3225055\n",
      "\tspeed: 0.0536s/iter; left time: 258.0525s\n",
      "\titers: 700, epoch: 5 | loss: 0.3016998\n",
      "\tspeed: 0.0535s/iter; left time: 252.3802s\n",
      "\titers: 800, epoch: 5 | loss: 0.2617193\n",
      "\tspeed: 0.0536s/iter; left time: 247.0927s\n",
      "\titers: 900, epoch: 5 | loss: 0.2697368\n",
      "\tspeed: 0.0531s/iter; left time: 239.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.2958051 Vali Loss: 0.4436080 Test Loss: 0.5030437\n",
      "Validation loss decreased (0.447989 --> 0.443608).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2939356\n",
      "\tspeed: 0.1338s/iter; left time: 590.3229s\n",
      "\titers: 200, epoch: 6 | loss: 0.2909550\n",
      "\tspeed: 0.0537s/iter; left time: 231.3267s\n",
      "\titers: 300, epoch: 6 | loss: 0.2864723\n",
      "\tspeed: 0.0536s/iter; left time: 225.6815s\n",
      "\titers: 400, epoch: 6 | loss: 0.2644904\n",
      "\tspeed: 0.0536s/iter; left time: 220.3287s\n",
      "\titers: 500, epoch: 6 | loss: 0.2466046\n",
      "\tspeed: 0.0536s/iter; left time: 215.0778s\n",
      "\titers: 600, epoch: 6 | loss: 0.2899375\n",
      "\tspeed: 0.0535s/iter; left time: 209.3229s\n",
      "\titers: 700, epoch: 6 | loss: 0.2669733\n",
      "\tspeed: 0.0537s/iter; left time: 204.7518s\n",
      "\titers: 800, epoch: 6 | loss: 0.2824681\n",
      "\tspeed: 0.0537s/iter; left time: 199.3660s\n",
      "\titers: 900, epoch: 6 | loss: 0.2672931\n",
      "\tspeed: 0.0536s/iter; left time: 193.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.2728003 Vali Loss: 0.4493155 Test Loss: 0.5087178\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2655763\n",
      "\tspeed: 0.1309s/iter; left time: 459.2576s\n",
      "\titers: 200, epoch: 7 | loss: 0.2581416\n",
      "\tspeed: 0.0538s/iter; left time: 183.4266s\n",
      "\titers: 300, epoch: 7 | loss: 0.2538862\n",
      "\tspeed: 0.0538s/iter; left time: 177.9046s\n",
      "\titers: 400, epoch: 7 | loss: 0.2699839\n",
      "\tspeed: 0.0537s/iter; left time: 172.4262s\n",
      "\titers: 500, epoch: 7 | loss: 0.2533457\n",
      "\tspeed: 0.0533s/iter; left time: 165.7140s\n",
      "\titers: 600, epoch: 7 | loss: 0.2446761\n",
      "\tspeed: 0.0534s/iter; left time: 160.6416s\n",
      "\titers: 700, epoch: 7 | loss: 0.2600569\n",
      "\tspeed: 0.0536s/iter; left time: 155.9984s\n",
      "\titers: 800, epoch: 7 | loss: 0.2456962\n",
      "\tspeed: 0.0535s/iter; left time: 150.2102s\n",
      "\titers: 900, epoch: 7 | loss: 0.2567835\n",
      "\tspeed: 0.0535s/iter; left time: 144.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.2515624 Vali Loss: 0.4564816 Test Loss: 0.5059831\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2437757\n",
      "\tspeed: 0.1312s/iter; left time: 342.0210s\n",
      "\titers: 200, epoch: 8 | loss: 0.2522405\n",
      "\tspeed: 0.0536s/iter; left time: 134.3220s\n",
      "\titers: 300, epoch: 8 | loss: 0.2425012\n",
      "\tspeed: 0.0533s/iter; left time: 128.3676s\n",
      "\titers: 400, epoch: 8 | loss: 0.2660030\n",
      "\tspeed: 0.0535s/iter; left time: 123.4884s\n",
      "\titers: 500, epoch: 8 | loss: 0.2334926\n",
      "\tspeed: 0.0535s/iter; left time: 118.1185s\n",
      "\titers: 600, epoch: 8 | loss: 0.2308565\n",
      "\tspeed: 0.0535s/iter; left time: 112.7324s\n",
      "\titers: 700, epoch: 8 | loss: 0.2352480\n",
      "\tspeed: 0.0534s/iter; left time: 107.2613s\n",
      "\titers: 800, epoch: 8 | loss: 0.2330101\n",
      "\tspeed: 0.0533s/iter; left time: 101.7147s\n",
      "\titers: 900, epoch: 8 | loss: 0.2594745\n",
      "\tspeed: 0.0532s/iter; left time: 96.1366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.2352301 Vali Loss: 0.4511191 Test Loss: 0.5154700\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5429455637931824, rmse:0.7368484139442444, mae:0.5033326745033264, rse:0.7144849896430969\n",
      "Original data scale mse:44440940.0, rmse:6666.40380859375, mae:4218.42333984375, rse:0.33215227723121643\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type robust \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.6628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2627</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.3597</td>\n",
       "      <td>0.4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.4813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.6443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.6679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4610</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4807</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2553</td>\n",
       "      <td>0.5053</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.6816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.6828</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.6641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.7128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.7145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2589  0.5088  0.3583  0.4946\n",
       "              2         24        0.2400  0.4899  0.3382  0.4762\n",
       "              1         96        0.4419  0.6648  0.4733  0.6466\n",
       "              2         96        0.5003  0.7073  0.5115  0.6880\n",
       "              1         168       0.4673  0.6836  0.5047  0.6628\n",
       "              2         168       0.4636  0.6809  0.5041  0.6602\n",
       "RMSE          1         24        0.2627  0.5125  0.3597  0.4982\n",
       "              2         24        0.2452  0.4952  0.3417  0.4813\n",
       "              1         96        0.4388  0.6624  0.4693  0.6443\n",
       "              2         96        0.4716  0.6867  0.4867  0.6679\n",
       "              1         168       0.4610  0.6790  0.5002  0.6583\n",
       "              2         168       0.4807  0.6933  0.5034  0.6723\n",
       "MAE           1         24        0.2681  0.5178  0.3306  0.5033\n",
       "              2         24        0.2553  0.5053  0.3241  0.4912\n",
       "              1         96        0.4912  0.7008  0.4737  0.6816\n",
       "              2         96        0.4662  0.6828  0.4586  0.6641\n",
       "              1         168       0.5403  0.7351  0.5003  0.7128\n",
       "              2         168       0.5429  0.7368  0.5033  0.7145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_robust.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_robust.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20458642.0</td>\n",
       "      <td>4523.1230</td>\n",
       "      <td>3016.6570</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18265502.0</td>\n",
       "      <td>4273.8159</td>\n",
       "      <td>2791.9541</td>\n",
       "      <td>0.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36498908.0</td>\n",
       "      <td>6041.4326</td>\n",
       "      <td>3972.6138</td>\n",
       "      <td>0.3009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>42418092.0</td>\n",
       "      <td>6512.9175</td>\n",
       "      <td>4375.4331</td>\n",
       "      <td>0.3243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39235132.0</td>\n",
       "      <td>6263.7954</td>\n",
       "      <td>4307.7930</td>\n",
       "      <td>0.3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37890544.0</td>\n",
       "      <td>6155.5298</td>\n",
       "      <td>4260.3516</td>\n",
       "      <td>0.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20469224.0</td>\n",
       "      <td>4524.2925</td>\n",
       "      <td>3007.1609</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18739230.0</td>\n",
       "      <td>4328.8833</td>\n",
       "      <td>2822.3328</td>\n",
       "      <td>0.2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35833200.0</td>\n",
       "      <td>5986.0840</td>\n",
       "      <td>3917.4497</td>\n",
       "      <td>0.2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>39601956.0</td>\n",
       "      <td>6293.0083</td>\n",
       "      <td>4131.7314</td>\n",
       "      <td>0.3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38069076.0</td>\n",
       "      <td>6170.0142</td>\n",
       "      <td>4236.1050</td>\n",
       "      <td>0.3074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39885020.0</td>\n",
       "      <td>6315.4590</td>\n",
       "      <td>4252.6626</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20925334.0</td>\n",
       "      <td>4574.4219</td>\n",
       "      <td>2752.5798</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19889488.0</td>\n",
       "      <td>4459.7632</td>\n",
       "      <td>2691.1169</td>\n",
       "      <td>0.2217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>40326344.0</td>\n",
       "      <td>6350.3027</td>\n",
       "      <td>3975.0549</td>\n",
       "      <td>0.3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37853992.0</td>\n",
       "      <td>6152.5596</td>\n",
       "      <td>3816.9463</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>44810908.0</td>\n",
       "      <td>6694.0952</td>\n",
       "      <td>4207.5996</td>\n",
       "      <td>0.3335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>44440940.0</td>\n",
       "      <td>6666.4038</td>\n",
       "      <td>4218.4233</td>\n",
       "      <td>0.3322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20458642.0  4523.1230  3016.6570  0.2249\n",
       "              2         24        18265502.0  4273.8159  2791.9541  0.2125\n",
       "              1         96        36498908.0  6041.4326  3972.6138  0.3009\n",
       "              2         96        42418092.0  6512.9175  4375.4331  0.3243\n",
       "              1         168       39235132.0  6263.7954  4307.7930  0.3121\n",
       "              2         168       37890544.0  6155.5298  4260.3516  0.3067\n",
       "RMSE          1         24        20469224.0  4524.2925  3007.1609  0.2250\n",
       "              2         24        18739230.0  4328.8833  2822.3328  0.2152\n",
       "              1         96        35833200.0  5986.0840  3917.4497  0.2981\n",
       "              2         96        39601956.0  6293.0083  4131.7314  0.3134\n",
       "              1         168       38069076.0  6170.0142  4236.1050  0.3074\n",
       "              2         168       39885020.0  6315.4590  4252.6626  0.3147\n",
       "MAE           1         24        20925334.0  4574.4219  2752.5798  0.2274\n",
       "              2         24        19889488.0  4459.7632  2691.1169  0.2217\n",
       "              1         96        40326344.0  6350.3027  3975.0549  0.3162\n",
       "              2         96        37853992.0  6152.5596  3816.9463  0.3064\n",
       "              1         168       44810908.0  6694.0952  4207.5996  0.3335\n",
       "              2         168       44440940.0  6666.4038  4218.4233  0.3322"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.4972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2494</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>0.4854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4787</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.4661</td>\n",
       "      <td>0.6729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4711</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>0.6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5416</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.7136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.6615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.6653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2617  0.5115  0.3273  0.4972\n",
       "         MSE            0.2494  0.4994  0.3483  0.4854\n",
       "         RMSE           0.2539  0.5039  0.3507  0.4898\n",
       "96       MAE            0.4787  0.6918  0.4661  0.6729\n",
       "         MSE            0.4711  0.6860  0.4924  0.6673\n",
       "         RMSE           0.4552  0.6746  0.4780  0.6561\n",
       "168      MAE            0.5416  0.7360  0.5018  0.7136\n",
       "         MSE            0.4654  0.6822  0.5044  0.6615\n",
       "         RMSE           0.4708  0.6861  0.5018  0.6653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>20407411.0</td>\n",
       "      <td>4517.0925</td>\n",
       "      <td>2721.8484</td>\n",
       "      <td>0.2246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19362072.0</td>\n",
       "      <td>4398.4695</td>\n",
       "      <td>2904.3055</td>\n",
       "      <td>0.2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19604227.0</td>\n",
       "      <td>4426.5879</td>\n",
       "      <td>2914.7468</td>\n",
       "      <td>0.2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39090168.0</td>\n",
       "      <td>6251.4312</td>\n",
       "      <td>3896.0006</td>\n",
       "      <td>0.3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39458500.0</td>\n",
       "      <td>6277.1750</td>\n",
       "      <td>4174.0234</td>\n",
       "      <td>0.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37717578.0</td>\n",
       "      <td>6139.5461</td>\n",
       "      <td>4024.5906</td>\n",
       "      <td>0.3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>44625924.0</td>\n",
       "      <td>6680.2495</td>\n",
       "      <td>4213.0115</td>\n",
       "      <td>0.3328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38562838.0</td>\n",
       "      <td>6209.6626</td>\n",
       "      <td>4284.0723</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38977048.0</td>\n",
       "      <td>6242.7366</td>\n",
       "      <td>4244.3838</td>\n",
       "      <td>0.3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            20407411.0  4517.0925  2721.8484  0.2246\n",
       "         MSE            19362072.0  4398.4695  2904.3055  0.2187\n",
       "         RMSE           19604227.0  4426.5879  2914.7468  0.2201\n",
       "96       MAE            39090168.0  6251.4312  3896.0006  0.3113\n",
       "         MSE            39458500.0  6277.1750  4174.0234  0.3126\n",
       "         RMSE           37717578.0  6139.5461  4024.5906  0.3058\n",
       "168      MAE            44625924.0  6680.2495  4213.0115  0.3328\n",
       "         MSE            38562838.0  6209.6626  4284.0723  0.3094\n",
       "         RMSE           38977048.0  6242.7366  4244.3838  0.3110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Robust Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2182888\n",
      "\tspeed: 0.0671s/iter; left time: 592.4143s\n",
      "\titers: 200, epoch: 1 | loss: 0.2483146\n",
      "\tspeed: 0.0423s/iter; left time: 369.5671s\n",
      "\titers: 300, epoch: 1 | loss: 0.1819766\n",
      "\tspeed: 0.0424s/iter; left time: 366.0528s\n",
      "\titers: 400, epoch: 1 | loss: 0.2401925\n",
      "\tspeed: 0.0423s/iter; left time: 361.0620s\n",
      "\titers: 500, epoch: 1 | loss: 0.2119175\n",
      "\tspeed: 0.0423s/iter; left time: 356.3942s\n",
      "\titers: 600, epoch: 1 | loss: 0.2411313\n",
      "\tspeed: 0.0423s/iter; left time: 352.5340s\n",
      "\titers: 700, epoch: 1 | loss: 0.2019983\n",
      "\tspeed: 0.0423s/iter; left time: 348.0317s\n",
      "\titers: 800, epoch: 1 | loss: 0.1758891\n",
      "\tspeed: 0.0423s/iter; left time: 343.6937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.2087825 Vali Loss: 0.2227851 Test Loss: 0.2488865\n",
      "Validation loss decreased (inf --> 0.222785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2542633\n",
      "\tspeed: 0.1523s/iter; left time: 1208.9493s\n",
      "\titers: 200, epoch: 2 | loss: 0.2285584\n",
      "\tspeed: 0.0420s/iter; left time: 328.9201s\n",
      "\titers: 300, epoch: 2 | loss: 0.1769358\n",
      "\tspeed: 0.0420s/iter; left time: 324.7187s\n",
      "\titers: 400, epoch: 2 | loss: 0.1626719\n",
      "\tspeed: 0.0420s/iter; left time: 320.5407s\n",
      "\titers: 500, epoch: 2 | loss: 0.1487459\n",
      "\tspeed: 0.0420s/iter; left time: 316.5330s\n",
      "\titers: 600, epoch: 2 | loss: 0.1563893\n",
      "\tspeed: 0.0420s/iter; left time: 312.4074s\n",
      "\titers: 700, epoch: 2 | loss: 0.2029024\n",
      "\tspeed: 0.0420s/iter; left time: 307.9137s\n",
      "\titers: 800, epoch: 2 | loss: 0.1471206\n",
      "\tspeed: 0.0420s/iter; left time: 303.6876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 893 | Train Loss: 0.1764989 Vali Loss: 0.2093719 Test Loss: 0.2462091\n",
      "Validation loss decreased (0.222785 --> 0.209372).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1130430\n",
      "\tspeed: 0.1520s/iter; left time: 1070.8532s\n",
      "\titers: 200, epoch: 3 | loss: 0.1681836\n",
      "\tspeed: 0.0422s/iter; left time: 293.2178s\n",
      "\titers: 300, epoch: 3 | loss: 0.1295601\n",
      "\tspeed: 0.0422s/iter; left time: 289.1402s\n",
      "\titers: 400, epoch: 3 | loss: 0.1543368\n",
      "\tspeed: 0.0422s/iter; left time: 284.8950s\n",
      "\titers: 500, epoch: 3 | loss: 0.1253413\n",
      "\tspeed: 0.0422s/iter; left time: 280.5928s\n",
      "\titers: 600, epoch: 3 | loss: 0.1647429\n",
      "\tspeed: 0.0422s/iter; left time: 276.4056s\n",
      "\titers: 700, epoch: 3 | loss: 0.0972432\n",
      "\tspeed: 0.0422s/iter; left time: 272.2859s\n",
      "\titers: 800, epoch: 3 | loss: 0.1882071\n",
      "\tspeed: 0.0422s/iter; left time: 268.0605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 893 | Train Loss: 0.1538710 Vali Loss: 0.2072558 Test Loss: 0.2366833\n",
      "Validation loss decreased (0.209372 --> 0.207256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1382889\n",
      "\tspeed: 0.1527s/iter; left time: 939.5439s\n",
      "\titers: 200, epoch: 4 | loss: 0.1295988\n",
      "\tspeed: 0.0423s/iter; left time: 255.9756s\n",
      "\titers: 300, epoch: 4 | loss: 0.1384621\n",
      "\tspeed: 0.0423s/iter; left time: 251.9077s\n",
      "\titers: 400, epoch: 4 | loss: 0.0996958\n",
      "\tspeed: 0.0424s/iter; left time: 247.9146s\n",
      "\titers: 500, epoch: 4 | loss: 0.1963269\n",
      "\tspeed: 0.0423s/iter; left time: 243.5882s\n",
      "\titers: 600, epoch: 4 | loss: 0.1216139\n",
      "\tspeed: 0.0423s/iter; left time: 239.3059s\n",
      "\titers: 700, epoch: 4 | loss: 0.1279448\n",
      "\tspeed: 0.0423s/iter; left time: 234.8436s\n",
      "\titers: 800, epoch: 4 | loss: 0.1715954\n",
      "\tspeed: 0.0423s/iter; left time: 230.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1435643 Vali Loss: 0.2129144 Test Loss: 0.2448330\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1146317\n",
      "\tspeed: 0.1519s/iter; left time: 798.9322s\n",
      "\titers: 200, epoch: 5 | loss: 0.0990961\n",
      "\tspeed: 0.0423s/iter; left time: 218.0007s\n",
      "\titers: 300, epoch: 5 | loss: 0.1344358\n",
      "\tspeed: 0.0423s/iter; left time: 213.8701s\n",
      "\titers: 400, epoch: 5 | loss: 0.1065817\n",
      "\tspeed: 0.0422s/iter; left time: 209.1114s\n",
      "\titers: 500, epoch: 5 | loss: 0.1366770\n",
      "\tspeed: 0.0420s/iter; left time: 203.8968s\n",
      "\titers: 600, epoch: 5 | loss: 0.0995290\n",
      "\tspeed: 0.0421s/iter; left time: 200.2429s\n",
      "\titers: 700, epoch: 5 | loss: 0.1291941\n",
      "\tspeed: 0.0423s/iter; left time: 196.9853s\n",
      "\titers: 800, epoch: 5 | loss: 0.1187898\n",
      "\tspeed: 0.0423s/iter; left time: 192.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.1356922 Vali Loss: 0.2070860 Test Loss: 0.2437721\n",
      "Validation loss decreased (0.207256 --> 0.207086).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052267\n",
      "\tspeed: 0.1527s/iter; left time: 666.5302s\n",
      "\titers: 200, epoch: 6 | loss: 0.1539435\n",
      "\tspeed: 0.0423s/iter; left time: 180.4593s\n",
      "\titers: 300, epoch: 6 | loss: 0.1016026\n",
      "\tspeed: 0.0423s/iter; left time: 176.1273s\n",
      "\titers: 400, epoch: 6 | loss: 0.0981144\n",
      "\tspeed: 0.0423s/iter; left time: 171.9055s\n",
      "\titers: 500, epoch: 6 | loss: 0.1160137\n",
      "\tspeed: 0.0423s/iter; left time: 167.7247s\n",
      "\titers: 600, epoch: 6 | loss: 0.1246929\n",
      "\tspeed: 0.0423s/iter; left time: 163.4481s\n",
      "\titers: 700, epoch: 6 | loss: 0.0993796\n",
      "\tspeed: 0.0423s/iter; left time: 159.2700s\n",
      "\titers: 800, epoch: 6 | loss: 0.1143529\n",
      "\tspeed: 0.0423s/iter; left time: 154.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 893 | Train Loss: 0.1223197 Vali Loss: 0.2111784 Test Loss: 0.2512260\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1277153\n",
      "\tspeed: 0.1510s/iter; left time: 524.3166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0998712\n",
      "\tspeed: 0.0423s/iter; left time: 142.6868s\n",
      "\titers: 300, epoch: 7 | loss: 0.1116811\n",
      "\tspeed: 0.0423s/iter; left time: 138.4256s\n",
      "\titers: 400, epoch: 7 | loss: 0.1238142\n",
      "\tspeed: 0.0422s/iter; left time: 134.0547s\n",
      "\titers: 500, epoch: 7 | loss: 0.1123730\n",
      "\tspeed: 0.0423s/iter; left time: 129.8465s\n",
      "\titers: 600, epoch: 7 | loss: 0.1097642\n",
      "\tspeed: 0.0423s/iter; left time: 125.7097s\n",
      "\titers: 700, epoch: 7 | loss: 0.0841276\n",
      "\tspeed: 0.0423s/iter; left time: 121.4399s\n",
      "\titers: 800, epoch: 7 | loss: 0.0980608\n",
      "\tspeed: 0.0423s/iter; left time: 117.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 893 | Train Loss: 0.1080896 Vali Loss: 0.2169513 Test Loss: 0.2719207\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982211\n",
      "\tspeed: 0.1511s/iter; left time: 389.7795s\n",
      "\titers: 200, epoch: 8 | loss: 0.0946582\n",
      "\tspeed: 0.0423s/iter; left time: 104.8453s\n",
      "\titers: 300, epoch: 8 | loss: 0.0831800\n",
      "\tspeed: 0.0423s/iter; left time: 100.5986s\n",
      "\titers: 400, epoch: 8 | loss: 0.1077355\n",
      "\tspeed: 0.0423s/iter; left time: 96.3900s\n",
      "\titers: 500, epoch: 8 | loss: 0.1004587\n",
      "\tspeed: 0.0423s/iter; left time: 92.1275s\n",
      "\titers: 600, epoch: 8 | loss: 0.0869073\n",
      "\tspeed: 0.0423s/iter; left time: 87.8975s\n",
      "\titers: 700, epoch: 8 | loss: 0.0918937\n",
      "\tspeed: 0.0423s/iter; left time: 83.7088s\n",
      "\titers: 800, epoch: 8 | loss: 0.1065189\n",
      "\tspeed: 0.0423s/iter; left time: 79.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 893 | Train Loss: 0.0947981 Vali Loss: 0.2311867 Test Loss: 0.2736874\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.24377213418483734, rmse:0.49373286962509155, mae:0.32709261775016785, rse:0.47993603348731995\n",
      "Original data scale mse:18229302.0, rmse:4269.57861328125, mae:2643.64306640625, rse:0.21229206025600433\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2206414\n",
      "\tspeed: 0.0443s/iter; left time: 391.6088s\n",
      "\titers: 200, epoch: 1 | loss: 0.2375478\n",
      "\tspeed: 0.0423s/iter; left time: 369.1894s\n",
      "\titers: 300, epoch: 1 | loss: 0.1452305\n",
      "\tspeed: 0.0423s/iter; left time: 364.9231s\n",
      "\titers: 400, epoch: 1 | loss: 0.1465522\n",
      "\tspeed: 0.0423s/iter; left time: 360.8159s\n",
      "\titers: 500, epoch: 1 | loss: 0.1584292\n",
      "\tspeed: 0.0423s/iter; left time: 356.3088s\n",
      "\titers: 600, epoch: 1 | loss: 0.1645278\n",
      "\tspeed: 0.0423s/iter; left time: 352.3695s\n",
      "\titers: 700, epoch: 1 | loss: 0.1320945\n",
      "\tspeed: 0.0423s/iter; left time: 348.0273s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485924\n",
      "\tspeed: 0.0423s/iter; left time: 344.0073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2064389 Vali Loss: 0.2237854 Test Loss: 0.2495932\n",
      "Validation loss decreased (inf --> 0.223785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1912019\n",
      "\tspeed: 0.1556s/iter; left time: 1234.7611s\n",
      "\titers: 200, epoch: 2 | loss: 0.1532453\n",
      "\tspeed: 0.0423s/iter; left time: 331.8465s\n",
      "\titers: 300, epoch: 2 | loss: 0.1540545\n",
      "\tspeed: 0.0424s/iter; left time: 327.7185s\n",
      "\titers: 400, epoch: 2 | loss: 0.1902761\n",
      "\tspeed: 0.0423s/iter; left time: 322.9039s\n",
      "\titers: 500, epoch: 2 | loss: 0.1828902\n",
      "\tspeed: 0.0423s/iter; left time: 318.9055s\n",
      "\titers: 600, epoch: 2 | loss: 0.1684876\n",
      "\tspeed: 0.0423s/iter; left time: 314.6219s\n",
      "\titers: 700, epoch: 2 | loss: 0.1584103\n",
      "\tspeed: 0.0423s/iter; left time: 310.2867s\n",
      "\titers: 800, epoch: 2 | loss: 0.1902631\n",
      "\tspeed: 0.0423s/iter; left time: 306.0857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.1782395 Vali Loss: 0.2117519 Test Loss: 0.2409998\n",
      "Validation loss decreased (0.223785 --> 0.211752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1524419\n",
      "\tspeed: 0.1535s/iter; left time: 1081.2843s\n",
      "\titers: 200, epoch: 3 | loss: 0.1627001\n",
      "\tspeed: 0.0423s/iter; left time: 293.7571s\n",
      "\titers: 300, epoch: 3 | loss: 0.1591595\n",
      "\tspeed: 0.0423s/iter; left time: 289.7706s\n",
      "\titers: 400, epoch: 3 | loss: 0.1622191\n",
      "\tspeed: 0.0423s/iter; left time: 285.3798s\n",
      "\titers: 500, epoch: 3 | loss: 0.1084869\n",
      "\tspeed: 0.0424s/iter; left time: 281.4775s\n",
      "\titers: 600, epoch: 3 | loss: 0.1607718\n",
      "\tspeed: 0.0423s/iter; left time: 276.6985s\n",
      "\titers: 700, epoch: 3 | loss: 0.1469914\n",
      "\tspeed: 0.0423s/iter; left time: 272.5152s\n",
      "\titers: 800, epoch: 3 | loss: 0.1555944\n",
      "\tspeed: 0.0423s/iter; left time: 268.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1535924 Vali Loss: 0.2054644 Test Loss: 0.2340896\n",
      "Validation loss decreased (0.211752 --> 0.205464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1761414\n",
      "\tspeed: 0.1529s/iter; left time: 940.8861s\n",
      "\titers: 200, epoch: 4 | loss: 0.1489290\n",
      "\tspeed: 0.0423s/iter; left time: 255.8050s\n",
      "\titers: 300, epoch: 4 | loss: 0.1410414\n",
      "\tspeed: 0.0422s/iter; left time: 251.3510s\n",
      "\titers: 400, epoch: 4 | loss: 0.1234727\n",
      "\tspeed: 0.0423s/iter; left time: 247.2712s\n",
      "\titers: 500, epoch: 4 | loss: 0.1392564\n",
      "\tspeed: 0.0423s/iter; left time: 243.1773s\n",
      "\titers: 600, epoch: 4 | loss: 0.1366114\n",
      "\tspeed: 0.0423s/iter; left time: 238.9896s\n",
      "\titers: 700, epoch: 4 | loss: 0.1602959\n",
      "\tspeed: 0.0423s/iter; left time: 234.6935s\n",
      "\titers: 800, epoch: 4 | loss: 0.1197448\n",
      "\tspeed: 0.0423s/iter; left time: 230.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.1465536 Vali Loss: 0.2101973 Test Loss: 0.2404596\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1367753\n",
      "\tspeed: 0.1511s/iter; left time: 794.8858s\n",
      "\titers: 200, epoch: 5 | loss: 0.1272282\n",
      "\tspeed: 0.0423s/iter; left time: 218.2070s\n",
      "\titers: 300, epoch: 5 | loss: 0.1496442\n",
      "\tspeed: 0.0423s/iter; left time: 214.1654s\n",
      "\titers: 400, epoch: 5 | loss: 0.1521624\n",
      "\tspeed: 0.0424s/iter; left time: 210.0168s\n",
      "\titers: 500, epoch: 5 | loss: 0.2145675\n",
      "\tspeed: 0.0423s/iter; left time: 205.7225s\n",
      "\titers: 600, epoch: 5 | loss: 0.1506090\n",
      "\tspeed: 0.0423s/iter; left time: 201.2500s\n",
      "\titers: 700, epoch: 5 | loss: 0.1555046\n",
      "\tspeed: 0.0423s/iter; left time: 197.0498s\n",
      "\titers: 800, epoch: 5 | loss: 0.1273113\n",
      "\tspeed: 0.0423s/iter; left time: 192.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.1361860 Vali Loss: 0.2075765 Test Loss: 0.2429294\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1674313\n",
      "\tspeed: 0.1531s/iter; left time: 668.3991s\n",
      "\titers: 200, epoch: 6 | loss: 0.1083477\n",
      "\tspeed: 0.0423s/iter; left time: 180.6613s\n",
      "\titers: 300, epoch: 6 | loss: 0.1070889\n",
      "\tspeed: 0.0423s/iter; left time: 176.3479s\n",
      "\titers: 400, epoch: 6 | loss: 0.1446198\n",
      "\tspeed: 0.0424s/iter; left time: 172.2337s\n",
      "\titers: 500, epoch: 6 | loss: 0.1063484\n",
      "\tspeed: 0.0423s/iter; left time: 167.9490s\n",
      "\titers: 600, epoch: 6 | loss: 0.1296085\n",
      "\tspeed: 0.0424s/iter; left time: 163.9010s\n",
      "\titers: 700, epoch: 6 | loss: 0.1381496\n",
      "\tspeed: 0.0425s/iter; left time: 159.9501s\n",
      "\titers: 800, epoch: 6 | loss: 0.1257187\n",
      "\tspeed: 0.0425s/iter; left time: 155.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.1262082 Vali Loss: 0.2218472 Test Loss: 0.2574605\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2340896874666214, rmse:0.4838281571865082, mae:0.3247095048427582, rse:0.4703080952167511\n",
      "Original data scale mse:17448062.0, rmse:4177.087890625, mae:2625.818359375, rse:0.20769323408603668\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4049923\n",
      "\tspeed: 0.0689s/iter; left time: 606.8800s\n",
      "\titers: 200, epoch: 1 | loss: 0.2957990\n",
      "\tspeed: 0.0428s/iter; left time: 372.7498s\n",
      "\titers: 300, epoch: 1 | loss: 0.3107244\n",
      "\tspeed: 0.0427s/iter; left time: 367.4864s\n",
      "\titers: 400, epoch: 1 | loss: 0.2609153\n",
      "\tspeed: 0.0427s/iter; left time: 363.3368s\n",
      "\titers: 500, epoch: 1 | loss: 0.3021559\n",
      "\tspeed: 0.0427s/iter; left time: 358.8438s\n",
      "\titers: 600, epoch: 1 | loss: 0.2765362\n",
      "\tspeed: 0.0427s/iter; left time: 354.6060s\n",
      "\titers: 700, epoch: 1 | loss: 0.3019718\n",
      "\tspeed: 0.0426s/iter; left time: 350.1938s\n",
      "\titers: 800, epoch: 1 | loss: 0.3384129\n",
      "\tspeed: 0.0427s/iter; left time: 346.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.3137484 Vali Loss: 0.3350134 Test Loss: 0.4042231\n",
      "Validation loss decreased (inf --> 0.335013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3234335\n",
      "\tspeed: 0.1540s/iter; left time: 1220.0525s\n",
      "\titers: 200, epoch: 2 | loss: 0.2690896\n",
      "\tspeed: 0.0427s/iter; left time: 333.8863s\n",
      "\titers: 300, epoch: 2 | loss: 0.2604612\n",
      "\tspeed: 0.0427s/iter; left time: 329.5562s\n",
      "\titers: 400, epoch: 2 | loss: 0.3257959\n",
      "\tspeed: 0.0427s/iter; left time: 325.2546s\n",
      "\titers: 500, epoch: 2 | loss: 0.2276038\n",
      "\tspeed: 0.0427s/iter; left time: 321.0410s\n",
      "\titers: 600, epoch: 2 | loss: 0.2075093\n",
      "\tspeed: 0.0427s/iter; left time: 316.9933s\n",
      "\titers: 700, epoch: 2 | loss: 0.2199426\n",
      "\tspeed: 0.0427s/iter; left time: 312.4776s\n",
      "\titers: 800, epoch: 2 | loss: 0.3054669\n",
      "\tspeed: 0.0427s/iter; left time: 307.9747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.2844034 Vali Loss: 0.3334920 Test Loss: 0.4056434\n",
      "Validation loss decreased (0.335013 --> 0.333492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2273551\n",
      "\tspeed: 0.1550s/iter; left time: 1089.2230s\n",
      "\titers: 200, epoch: 3 | loss: 0.2722374\n",
      "\tspeed: 0.0428s/iter; left time: 296.6875s\n",
      "\titers: 300, epoch: 3 | loss: 0.2850189\n",
      "\tspeed: 0.0428s/iter; left time: 292.4647s\n",
      "\titers: 400, epoch: 3 | loss: 0.2466170\n",
      "\tspeed: 0.0428s/iter; left time: 288.3025s\n",
      "\titers: 500, epoch: 3 | loss: 0.2558402\n",
      "\tspeed: 0.0429s/iter; left time: 284.1932s\n",
      "\titers: 600, epoch: 3 | loss: 0.2083510\n",
      "\tspeed: 0.0429s/iter; left time: 279.8767s\n",
      "\titers: 700, epoch: 3 | loss: 0.2529962\n",
      "\tspeed: 0.0428s/iter; left time: 275.1767s\n",
      "\titers: 800, epoch: 3 | loss: 0.2187040\n",
      "\tspeed: 0.0428s/iter; left time: 270.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 891 | Train Loss: 0.2485018 Vali Loss: 0.3550677 Test Loss: 0.4583389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2168615\n",
      "\tspeed: 0.1521s/iter; left time: 933.5163s\n",
      "\titers: 200, epoch: 4 | loss: 0.2235389\n",
      "\tspeed: 0.0426s/iter; left time: 257.3139s\n",
      "\titers: 300, epoch: 4 | loss: 0.2161325\n",
      "\tspeed: 0.0426s/iter; left time: 252.9119s\n",
      "\titers: 400, epoch: 4 | loss: 0.2032050\n",
      "\tspeed: 0.0426s/iter; left time: 248.5449s\n",
      "\titers: 500, epoch: 4 | loss: 0.1802410\n",
      "\tspeed: 0.0426s/iter; left time: 244.2919s\n",
      "\titers: 600, epoch: 4 | loss: 0.2107882\n",
      "\tspeed: 0.0426s/iter; left time: 240.0479s\n",
      "\titers: 700, epoch: 4 | loss: 0.1768880\n",
      "\tspeed: 0.0426s/iter; left time: 235.8910s\n",
      "\titers: 800, epoch: 4 | loss: 0.1494804\n",
      "\tspeed: 0.0426s/iter; left time: 231.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 891 | Train Loss: 0.1942186 Vali Loss: 0.3718321 Test Loss: 0.5154957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1428668\n",
      "\tspeed: 0.1512s/iter; left time: 793.4876s\n",
      "\titers: 200, epoch: 5 | loss: 0.1403580\n",
      "\tspeed: 0.0428s/iter; left time: 220.3215s\n",
      "\titers: 300, epoch: 5 | loss: 0.1688989\n",
      "\tspeed: 0.0428s/iter; left time: 216.2106s\n",
      "\titers: 400, epoch: 5 | loss: 0.1395124\n",
      "\tspeed: 0.0429s/iter; left time: 211.9929s\n",
      "\titers: 500, epoch: 5 | loss: 0.1450117\n",
      "\tspeed: 0.0428s/iter; left time: 207.6597s\n",
      "\titers: 600, epoch: 5 | loss: 0.1385178\n",
      "\tspeed: 0.0427s/iter; left time: 202.5236s\n",
      "\titers: 700, epoch: 5 | loss: 0.1198406\n",
      "\tspeed: 0.0427s/iter; left time: 198.4644s\n",
      "\titers: 800, epoch: 5 | loss: 0.1080823\n",
      "\tspeed: 0.0428s/iter; left time: 194.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.1442858 Vali Loss: 0.4074320 Test Loss: 0.5274310\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4056432843208313, rmse:0.636901319026947, mae:0.4532889127731323, rse:0.6194678544998169\n",
      "Original data scale mse:31905132.0, rmse:5648.462890625, mae:3713.9365234375, rse:0.28129544854164124\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2911865\n",
      "\tspeed: 0.0443s/iter; left time: 390.5713s\n",
      "\titers: 200, epoch: 1 | loss: 0.2554933\n",
      "\tspeed: 0.0427s/iter; left time: 371.6443s\n",
      "\titers: 300, epoch: 1 | loss: 0.3690168\n",
      "\tspeed: 0.0426s/iter; left time: 366.9870s\n",
      "\titers: 400, epoch: 1 | loss: 0.3681073\n",
      "\tspeed: 0.0426s/iter; left time: 362.8232s\n",
      "\titers: 500, epoch: 1 | loss: 0.2588452\n",
      "\tspeed: 0.0427s/iter; left time: 358.8153s\n",
      "\titers: 600, epoch: 1 | loss: 0.3433743\n",
      "\tspeed: 0.0426s/iter; left time: 354.0899s\n",
      "\titers: 700, epoch: 1 | loss: 0.2982317\n",
      "\tspeed: 0.0426s/iter; left time: 349.8697s\n",
      "\titers: 800, epoch: 1 | loss: 0.2857746\n",
      "\tspeed: 0.0426s/iter; left time: 345.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.3132502 Vali Loss: 0.3342929 Test Loss: 0.4064146\n",
      "Validation loss decreased (inf --> 0.334293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2956440\n",
      "\tspeed: 0.1539s/iter; left time: 1219.1017s\n",
      "\titers: 200, epoch: 2 | loss: 0.2711323\n",
      "\tspeed: 0.0427s/iter; left time: 333.9687s\n",
      "\titers: 300, epoch: 2 | loss: 0.2761405\n",
      "\tspeed: 0.0426s/iter; left time: 328.8849s\n",
      "\titers: 400, epoch: 2 | loss: 0.2718239\n",
      "\tspeed: 0.0426s/iter; left time: 324.6965s\n",
      "\titers: 500, epoch: 2 | loss: 0.2233150\n",
      "\tspeed: 0.0427s/iter; left time: 320.8067s\n",
      "\titers: 600, epoch: 2 | loss: 0.2687964\n",
      "\tspeed: 0.0426s/iter; left time: 316.2735s\n",
      "\titers: 700, epoch: 2 | loss: 0.3107231\n",
      "\tspeed: 0.0426s/iter; left time: 312.0622s\n",
      "\titers: 800, epoch: 2 | loss: 0.2536783\n",
      "\tspeed: 0.0426s/iter; left time: 307.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.2821826 Vali Loss: 0.3187537 Test Loss: 0.4230867\n",
      "Validation loss decreased (0.334293 --> 0.318754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2730467\n",
      "\tspeed: 0.1563s/iter; left time: 1098.3708s\n",
      "\titers: 200, epoch: 3 | loss: 0.2214015\n",
      "\tspeed: 0.0428s/iter; left time: 296.7806s\n",
      "\titers: 300, epoch: 3 | loss: 0.1991722\n",
      "\tspeed: 0.0427s/iter; left time: 291.8211s\n",
      "\titers: 400, epoch: 3 | loss: 0.2438296\n",
      "\tspeed: 0.0427s/iter; left time: 287.6403s\n",
      "\titers: 500, epoch: 3 | loss: 0.2184707\n",
      "\tspeed: 0.0427s/iter; left time: 283.0747s\n",
      "\titers: 600, epoch: 3 | loss: 0.2162259\n",
      "\tspeed: 0.0428s/iter; left time: 279.1217s\n",
      "\titers: 700, epoch: 3 | loss: 0.2521574\n",
      "\tspeed: 0.0428s/iter; left time: 274.8871s\n",
      "\titers: 800, epoch: 3 | loss: 0.2256935\n",
      "\tspeed: 0.0428s/iter; left time: 270.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.2377315 Vali Loss: 0.3662227 Test Loss: 0.4909471\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1883862\n",
      "\tspeed: 0.1519s/iter; left time: 932.5947s\n",
      "\titers: 200, epoch: 4 | loss: 0.1755034\n",
      "\tspeed: 0.0426s/iter; left time: 257.3751s\n",
      "\titers: 300, epoch: 4 | loss: 0.1892222\n",
      "\tspeed: 0.0426s/iter; left time: 253.1909s\n",
      "\titers: 400, epoch: 4 | loss: 0.1656071\n",
      "\tspeed: 0.0426s/iter; left time: 248.8671s\n",
      "\titers: 500, epoch: 4 | loss: 0.1632601\n",
      "\tspeed: 0.0427s/iter; left time: 244.8986s\n",
      "\titers: 600, epoch: 4 | loss: 0.1775828\n",
      "\tspeed: 0.0428s/iter; left time: 241.5719s\n",
      "\titers: 700, epoch: 4 | loss: 0.1985904\n",
      "\tspeed: 0.0428s/iter; left time: 236.9068s\n",
      "\titers: 800, epoch: 4 | loss: 0.1739397\n",
      "\tspeed: 0.0426s/iter; left time: 231.8410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.1840022 Vali Loss: 0.3693338 Test Loss: 0.5031531\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1468196\n",
      "\tspeed: 0.1509s/iter; left time: 791.7974s\n",
      "\titers: 200, epoch: 5 | loss: 0.1186915\n",
      "\tspeed: 0.0427s/iter; left time: 219.6282s\n",
      "\titers: 300, epoch: 5 | loss: 0.1432089\n",
      "\tspeed: 0.0427s/iter; left time: 215.4314s\n",
      "\titers: 400, epoch: 5 | loss: 0.1392983\n",
      "\tspeed: 0.0427s/iter; left time: 211.1448s\n",
      "\titers: 500, epoch: 5 | loss: 0.1237556\n",
      "\tspeed: 0.0427s/iter; left time: 206.9695s\n",
      "\titers: 600, epoch: 5 | loss: 0.1113769\n",
      "\tspeed: 0.0428s/iter; left time: 203.2917s\n",
      "\titers: 700, epoch: 5 | loss: 0.1409771\n",
      "\tspeed: 0.0428s/iter; left time: 199.0124s\n",
      "\titers: 800, epoch: 5 | loss: 0.1170147\n",
      "\tspeed: 0.0428s/iter; left time: 194.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.1372502 Vali Loss: 0.3961888 Test Loss: 0.5232928\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.42308685183525085, rmse:0.6504512429237366, mae:0.45941707491874695, rse:0.6326469779014587\n",
      "Original data scale mse:34005252.0, rmse:5831.40234375, mae:3790.419677734375, rse:0.29040592908859253\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4219725\n",
      "\tspeed: 0.0714s/iter; left time: 627.3441s\n",
      "\titers: 200, epoch: 1 | loss: 0.3213577\n",
      "\tspeed: 0.0432s/iter; left time: 375.7531s\n",
      "\titers: 300, epoch: 1 | loss: 0.3374341\n",
      "\tspeed: 0.0432s/iter; left time: 371.0781s\n",
      "\titers: 400, epoch: 1 | loss: 0.3923987\n",
      "\tspeed: 0.0432s/iter; left time: 366.9837s\n",
      "\titers: 500, epoch: 1 | loss: 0.3712656\n",
      "\tspeed: 0.0432s/iter; left time: 362.8432s\n",
      "\titers: 600, epoch: 1 | loss: 0.3270575\n",
      "\tspeed: 0.0432s/iter; left time: 358.4755s\n",
      "\titers: 700, epoch: 1 | loss: 0.3183230\n",
      "\tspeed: 0.0432s/iter; left time: 353.9584s\n",
      "\titers: 800, epoch: 1 | loss: 0.3355043\n",
      "\tspeed: 0.0432s/iter; left time: 349.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 889 | Train Loss: 0.3379270 Vali Loss: 0.3487453 Test Loss: 0.4337278\n",
      "Validation loss decreased (inf --> 0.348745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3505492\n",
      "\tspeed: 0.1562s/iter; left time: 1234.2560s\n",
      "\titers: 200, epoch: 2 | loss: 0.2815456\n",
      "\tspeed: 0.0432s/iter; left time: 337.3393s\n",
      "\titers: 300, epoch: 2 | loss: 0.3684201\n",
      "\tspeed: 0.0432s/iter; left time: 332.4921s\n",
      "\titers: 400, epoch: 2 | loss: 0.3003347\n",
      "\tspeed: 0.0432s/iter; left time: 328.2750s\n",
      "\titers: 500, epoch: 2 | loss: 0.2899017\n",
      "\tspeed: 0.0432s/iter; left time: 323.9465s\n",
      "\titers: 600, epoch: 2 | loss: 0.2943653\n",
      "\tspeed: 0.0431s/iter; left time: 319.2990s\n",
      "\titers: 700, epoch: 2 | loss: 0.2408169\n",
      "\tspeed: 0.0431s/iter; left time: 314.9757s\n",
      "\titers: 800, epoch: 2 | loss: 0.2967852\n",
      "\tspeed: 0.0432s/iter; left time: 311.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.3040860 Vali Loss: 0.3452318 Test Loss: 0.4300068\n",
      "Validation loss decreased (0.348745 --> 0.345232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2656941\n",
      "\tspeed: 0.1578s/iter; left time: 1106.8775s\n",
      "\titers: 200, epoch: 3 | loss: 0.2192199\n",
      "\tspeed: 0.0431s/iter; left time: 298.1325s\n",
      "\titers: 300, epoch: 3 | loss: 0.2572608\n",
      "\tspeed: 0.0431s/iter; left time: 293.7830s\n",
      "\titers: 400, epoch: 3 | loss: 0.2765799\n",
      "\tspeed: 0.0431s/iter; left time: 289.5822s\n",
      "\titers: 500, epoch: 3 | loss: 0.2829485\n",
      "\tspeed: 0.0432s/iter; left time: 285.8724s\n",
      "\titers: 600, epoch: 3 | loss: 0.2353772\n",
      "\tspeed: 0.0432s/iter; left time: 281.2424s\n",
      "\titers: 700, epoch: 3 | loss: 0.2344825\n",
      "\tspeed: 0.0431s/iter; left time: 276.4197s\n",
      "\titers: 800, epoch: 3 | loss: 0.2090407\n",
      "\tspeed: 0.0431s/iter; left time: 272.2415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 889 | Train Loss: 0.2437451 Vali Loss: 0.3876502 Test Loss: 0.5172561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1679521\n",
      "\tspeed: 0.1535s/iter; left time: 939.9233s\n",
      "\titers: 200, epoch: 4 | loss: 0.1774218\n",
      "\tspeed: 0.0433s/iter; left time: 260.7681s\n",
      "\titers: 300, epoch: 4 | loss: 0.2058694\n",
      "\tspeed: 0.0434s/iter; left time: 256.8529s\n",
      "\titers: 400, epoch: 4 | loss: 0.1830022\n",
      "\tspeed: 0.0434s/iter; left time: 252.5259s\n",
      "\titers: 500, epoch: 4 | loss: 0.1770386\n",
      "\tspeed: 0.0433s/iter; left time: 247.7507s\n",
      "\titers: 600, epoch: 4 | loss: 0.1469374\n",
      "\tspeed: 0.0434s/iter; left time: 244.0048s\n",
      "\titers: 700, epoch: 4 | loss: 0.1893812\n",
      "\tspeed: 0.0434s/iter; left time: 239.7172s\n",
      "\titers: 800, epoch: 4 | loss: 0.1701941\n",
      "\tspeed: 0.0433s/iter; left time: 234.6032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.1826646 Vali Loss: 0.3969426 Test Loss: 0.5706749\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1446595\n",
      "\tspeed: 0.1537s/iter; left time: 804.5972s\n",
      "\titers: 200, epoch: 5 | loss: 0.1312882\n",
      "\tspeed: 0.0432s/iter; left time: 222.0357s\n",
      "\titers: 300, epoch: 5 | loss: 0.1305957\n",
      "\tspeed: 0.0432s/iter; left time: 217.6116s\n",
      "\titers: 400, epoch: 5 | loss: 0.1302079\n",
      "\tspeed: 0.0432s/iter; left time: 213.2307s\n",
      "\titers: 500, epoch: 5 | loss: 0.1266844\n",
      "\tspeed: 0.0432s/iter; left time: 209.0294s\n",
      "\titers: 600, epoch: 5 | loss: 0.1237143\n",
      "\tspeed: 0.0432s/iter; left time: 204.7879s\n",
      "\titers: 700, epoch: 5 | loss: 0.1116356\n",
      "\tspeed: 0.0432s/iter; left time: 200.2983s\n",
      "\titers: 800, epoch: 5 | loss: 0.1180200\n",
      "\tspeed: 0.0433s/iter; left time: 196.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.1277201 Vali Loss: 0.4241887 Test Loss: 0.5817598\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.43000683188438416, rmse:0.6557490825653076, mae:0.4732247292995453, rse:0.6358470320701599\n",
      "Original data scale mse:34134564.0, rmse:5842.4794921875, mae:3888.266845703125, rse:0.2911003828048706\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4407575\n",
      "\tspeed: 0.0450s/iter; left time: 395.7944s\n",
      "\titers: 200, epoch: 1 | loss: 0.3782762\n",
      "\tspeed: 0.0432s/iter; left time: 375.4750s\n",
      "\titers: 300, epoch: 1 | loss: 0.4144816\n",
      "\tspeed: 0.0433s/iter; left time: 372.0573s\n",
      "\titers: 400, epoch: 1 | loss: 0.3776525\n",
      "\tspeed: 0.0433s/iter; left time: 367.7289s\n",
      "\titers: 500, epoch: 1 | loss: 0.3336774\n",
      "\tspeed: 0.0432s/iter; left time: 362.0939s\n",
      "\titers: 600, epoch: 1 | loss: 0.2712955\n",
      "\tspeed: 0.0432s/iter; left time: 357.9453s\n",
      "\titers: 700, epoch: 1 | loss: 0.3227006\n",
      "\tspeed: 0.0432s/iter; left time: 353.4853s\n",
      "\titers: 800, epoch: 1 | loss: 0.2782703\n",
      "\tspeed: 0.0432s/iter; left time: 349.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3393388 Vali Loss: 0.3470966 Test Loss: 0.4314443\n",
      "Validation loss decreased (inf --> 0.347097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3569445\n",
      "\tspeed: 0.1562s/iter; left time: 1234.3920s\n",
      "\titers: 200, epoch: 2 | loss: 0.3173552\n",
      "\tspeed: 0.0432s/iter; left time: 336.9127s\n",
      "\titers: 300, epoch: 2 | loss: 0.3198369\n",
      "\tspeed: 0.0432s/iter; left time: 332.5283s\n",
      "\titers: 400, epoch: 2 | loss: 0.2892367\n",
      "\tspeed: 0.0432s/iter; left time: 328.0513s\n",
      "\titers: 500, epoch: 2 | loss: 0.3043633\n",
      "\tspeed: 0.0432s/iter; left time: 323.7601s\n",
      "\titers: 600, epoch: 2 | loss: 0.3062617\n",
      "\tspeed: 0.0432s/iter; left time: 319.5736s\n",
      "\titers: 700, epoch: 2 | loss: 0.2757693\n",
      "\tspeed: 0.0432s/iter; left time: 315.2731s\n",
      "\titers: 800, epoch: 2 | loss: 0.2658074\n",
      "\tspeed: 0.0432s/iter; left time: 310.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.3037361 Vali Loss: 0.3466612 Test Loss: 0.4409137\n",
      "Validation loss decreased (0.347097 --> 0.346661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2411756\n",
      "\tspeed: 0.1595s/iter; left time: 1118.7216s\n",
      "\titers: 200, epoch: 3 | loss: 0.2372409\n",
      "\tspeed: 0.0432s/iter; left time: 298.6042s\n",
      "\titers: 300, epoch: 3 | loss: 0.3133474\n",
      "\tspeed: 0.0432s/iter; left time: 294.1087s\n",
      "\titers: 400, epoch: 3 | loss: 0.2907278\n",
      "\tspeed: 0.0432s/iter; left time: 289.8311s\n",
      "\titers: 500, epoch: 3 | loss: 0.2493317\n",
      "\tspeed: 0.0433s/iter; left time: 286.0561s\n",
      "\titers: 600, epoch: 3 | loss: 0.2681441\n",
      "\tspeed: 0.0432s/iter; left time: 281.1875s\n",
      "\titers: 700, epoch: 3 | loss: 0.2291876\n",
      "\tspeed: 0.0432s/iter; left time: 276.7867s\n",
      "\titers: 800, epoch: 3 | loss: 0.2249457\n",
      "\tspeed: 0.0432s/iter; left time: 272.7989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.2516279 Vali Loss: 0.3914679 Test Loss: 0.5096662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2386205\n",
      "\tspeed: 0.1524s/iter; left time: 933.3497s\n",
      "\titers: 200, epoch: 4 | loss: 0.1759195\n",
      "\tspeed: 0.0433s/iter; left time: 260.6938s\n",
      "\titers: 300, epoch: 4 | loss: 0.1840650\n",
      "\tspeed: 0.0432s/iter; left time: 255.9961s\n",
      "\titers: 400, epoch: 4 | loss: 0.1511063\n",
      "\tspeed: 0.0433s/iter; left time: 252.2814s\n",
      "\titers: 500, epoch: 4 | loss: 0.1705367\n",
      "\tspeed: 0.0433s/iter; left time: 247.6009s\n",
      "\titers: 600, epoch: 4 | loss: 0.1474632\n",
      "\tspeed: 0.0431s/iter; left time: 242.5532s\n",
      "\titers: 700, epoch: 4 | loss: 0.2182209\n",
      "\tspeed: 0.0431s/iter; left time: 238.2039s\n",
      "\titers: 800, epoch: 4 | loss: 0.1727867\n",
      "\tspeed: 0.0431s/iter; left time: 234.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.1821432 Vali Loss: 0.4079411 Test Loss: 0.5562986\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1476289\n",
      "\tspeed: 0.1528s/iter; left time: 799.8046s\n",
      "\titers: 200, epoch: 5 | loss: 0.1366095\n",
      "\tspeed: 0.0431s/iter; left time: 221.4838s\n",
      "\titers: 300, epoch: 5 | loss: 0.1219677\n",
      "\tspeed: 0.0431s/iter; left time: 217.1397s\n",
      "\titers: 400, epoch: 5 | loss: 0.1347326\n",
      "\tspeed: 0.0431s/iter; left time: 212.8904s\n",
      "\titers: 500, epoch: 5 | loss: 0.1075135\n",
      "\tspeed: 0.0431s/iter; left time: 208.5982s\n",
      "\titers: 600, epoch: 5 | loss: 0.1352350\n",
      "\tspeed: 0.0432s/iter; left time: 204.3307s\n",
      "\titers: 700, epoch: 5 | loss: 0.1199284\n",
      "\tspeed: 0.0431s/iter; left time: 199.8920s\n",
      "\titers: 800, epoch: 5 | loss: 0.1189027\n",
      "\tspeed: 0.0431s/iter; left time: 195.5191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.1323440 Vali Loss: 0.4090794 Test Loss: 0.5391755\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4409139156341553, rmse:0.6640135049819946, mae:0.4773784875869751, rse:0.6438606381416321\n",
      "Original data scale mse:35157356.0, rmse:5929.36376953125, mae:3919.80126953125, rse:0.29542940855026245\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4612264\n",
      "\tspeed: 0.0703s/iter; left time: 620.6735s\n",
      "\titers: 200, epoch: 1 | loss: 0.4931367\n",
      "\tspeed: 0.0424s/iter; left time: 369.9290s\n",
      "\titers: 300, epoch: 1 | loss: 0.4238130\n",
      "\tspeed: 0.0424s/iter; left time: 365.5662s\n",
      "\titers: 400, epoch: 1 | loss: 0.4851383\n",
      "\tspeed: 0.0424s/iter; left time: 361.3446s\n",
      "\titers: 500, epoch: 1 | loss: 0.4581392\n",
      "\tspeed: 0.0424s/iter; left time: 357.2157s\n",
      "\titers: 600, epoch: 1 | loss: 0.4889456\n",
      "\tspeed: 0.0424s/iter; left time: 352.9831s\n",
      "\titers: 700, epoch: 1 | loss: 0.4440142\n",
      "\tspeed: 0.0424s/iter; left time: 348.7187s\n",
      "\titers: 800, epoch: 1 | loss: 0.4172545\n",
      "\tspeed: 0.0424s/iter; left time: 344.6893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.4478988 Vali Loss: 0.2211551 Test Loss: 0.2469547\n",
      "Validation loss decreased (inf --> 0.221155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4969963\n",
      "\tspeed: 0.1545s/iter; left time: 1226.6377s\n",
      "\titers: 200, epoch: 2 | loss: 0.4799438\n",
      "\tspeed: 0.0427s/iter; left time: 334.3108s\n",
      "\titers: 300, epoch: 2 | loss: 0.4172078\n",
      "\tspeed: 0.0426s/iter; left time: 329.8421s\n",
      "\titers: 400, epoch: 2 | loss: 0.4173856\n",
      "\tspeed: 0.0426s/iter; left time: 325.6524s\n",
      "\titers: 500, epoch: 2 | loss: 0.3859967\n",
      "\tspeed: 0.0427s/iter; left time: 321.7328s\n",
      "\titers: 600, epoch: 2 | loss: 0.3960185\n",
      "\tspeed: 0.0426s/iter; left time: 316.6852s\n",
      "\titers: 700, epoch: 2 | loss: 0.4558703\n",
      "\tspeed: 0.0423s/iter; left time: 310.1533s\n",
      "\titers: 800, epoch: 2 | loss: 0.3944112\n",
      "\tspeed: 0.0422s/iter; left time: 305.2265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.4187160 Vali Loss: 0.2119642 Test Loss: 0.2481652\n",
      "Validation loss decreased (0.221155 --> 0.211964).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3558697\n",
      "\tspeed: 0.1531s/iter; left time: 1078.4734s\n",
      "\titers: 200, epoch: 3 | loss: 0.4031888\n",
      "\tspeed: 0.0424s/iter; left time: 294.2475s\n",
      "\titers: 300, epoch: 3 | loss: 0.3752215\n",
      "\tspeed: 0.0424s/iter; left time: 290.0653s\n",
      "\titers: 400, epoch: 3 | loss: 0.3727610\n",
      "\tspeed: 0.0426s/iter; left time: 287.1306s\n",
      "\titers: 500, epoch: 3 | loss: 0.3592518\n",
      "\tspeed: 0.0426s/iter; left time: 283.0151s\n",
      "\titers: 600, epoch: 3 | loss: 0.4104393\n",
      "\tspeed: 0.0426s/iter; left time: 278.7167s\n",
      "\titers: 700, epoch: 3 | loss: 0.3167129\n",
      "\tspeed: 0.0426s/iter; left time: 274.3454s\n",
      "\titers: 800, epoch: 3 | loss: 0.4401841\n",
      "\tspeed: 0.0426s/iter; left time: 270.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.3928169 Vali Loss: 0.2130078 Test Loss: 0.2390562\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3682080\n",
      "\tspeed: 0.1503s/iter; left time: 924.6140s\n",
      "\titers: 200, epoch: 4 | loss: 0.3599137\n",
      "\tspeed: 0.0424s/iter; left time: 256.7060s\n",
      "\titers: 300, epoch: 4 | loss: 0.4109510\n",
      "\tspeed: 0.0425s/iter; left time: 252.8530s\n",
      "\titers: 400, epoch: 4 | loss: 0.3691692\n",
      "\tspeed: 0.0423s/iter; left time: 247.7092s\n",
      "\titers: 500, epoch: 4 | loss: 0.4784911\n",
      "\tspeed: 0.0423s/iter; left time: 243.4482s\n",
      "\titers: 600, epoch: 4 | loss: 0.3593989\n",
      "\tspeed: 0.0423s/iter; left time: 239.1844s\n",
      "\titers: 700, epoch: 4 | loss: 0.3556636\n",
      "\tspeed: 0.0423s/iter; left time: 235.0332s\n",
      "\titers: 800, epoch: 4 | loss: 0.4085686\n",
      "\tspeed: 0.0423s/iter; left time: 230.5882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3901668 Vali Loss: 0.2179164 Test Loss: 0.2440517\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3726523\n",
      "\tspeed: 0.1512s/iter; left time: 795.3797s\n",
      "\titers: 200, epoch: 5 | loss: 0.3119459\n",
      "\tspeed: 0.0424s/iter; left time: 218.9842s\n",
      "\titers: 300, epoch: 5 | loss: 0.3757663\n",
      "\tspeed: 0.0425s/iter; left time: 214.8649s\n",
      "\titers: 400, epoch: 5 | loss: 0.3228470\n",
      "\tspeed: 0.0424s/iter; left time: 210.2669s\n",
      "\titers: 500, epoch: 5 | loss: 0.3623497\n",
      "\tspeed: 0.0424s/iter; left time: 206.2594s\n",
      "\titers: 600, epoch: 5 | loss: 0.3463914\n",
      "\tspeed: 0.0427s/iter; left time: 203.0576s\n",
      "\titers: 700, epoch: 5 | loss: 0.3652623\n",
      "\tspeed: 0.0426s/iter; left time: 198.6190s\n",
      "\titers: 800, epoch: 5 | loss: 0.3501074\n",
      "\tspeed: 0.0426s/iter; left time: 194.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3693833 Vali Loss: 0.2104208 Test Loss: 0.2432195\n",
      "Validation loss decreased (0.211964 --> 0.210421).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3216523\n",
      "\tspeed: 0.1531s/iter; left time: 668.5719s\n",
      "\titers: 200, epoch: 6 | loss: 0.3791971\n",
      "\tspeed: 0.0424s/iter; left time: 180.7690s\n",
      "\titers: 300, epoch: 6 | loss: 0.3138337\n",
      "\tspeed: 0.0424s/iter; left time: 176.5228s\n",
      "\titers: 400, epoch: 6 | loss: 0.3159437\n",
      "\tspeed: 0.0424s/iter; left time: 172.3101s\n",
      "\titers: 500, epoch: 6 | loss: 0.3236097\n",
      "\tspeed: 0.0424s/iter; left time: 168.0682s\n",
      "\titers: 600, epoch: 6 | loss: 0.3602601\n",
      "\tspeed: 0.0424s/iter; left time: 163.8196s\n",
      "\titers: 700, epoch: 6 | loss: 0.3172666\n",
      "\tspeed: 0.0424s/iter; left time: 159.5473s\n",
      "\titers: 800, epoch: 6 | loss: 0.3505700\n",
      "\tspeed: 0.0424s/iter; left time: 155.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3529901 Vali Loss: 0.2172078 Test Loss: 0.2523130\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3618367\n",
      "\tspeed: 0.1508s/iter; left time: 523.5932s\n",
      "\titers: 200, epoch: 7 | loss: 0.3543028\n",
      "\tspeed: 0.0425s/iter; left time: 143.2367s\n",
      "\titers: 300, epoch: 7 | loss: 0.3426455\n",
      "\tspeed: 0.0424s/iter; left time: 138.6854s\n",
      "\titers: 400, epoch: 7 | loss: 0.3477319\n",
      "\tspeed: 0.0423s/iter; left time: 134.2996s\n",
      "\titers: 500, epoch: 7 | loss: 0.3414739\n",
      "\tspeed: 0.0423s/iter; left time: 130.1410s\n",
      "\titers: 600, epoch: 7 | loss: 0.3208058\n",
      "\tspeed: 0.0424s/iter; left time: 125.9220s\n",
      "\titers: 700, epoch: 7 | loss: 0.2930879\n",
      "\tspeed: 0.0424s/iter; left time: 121.7094s\n",
      "\titers: 800, epoch: 7 | loss: 0.3072974\n",
      "\tspeed: 0.0423s/iter; left time: 117.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.3350942 Vali Loss: 0.2205501 Test Loss: 0.2730061\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3361881\n",
      "\tspeed: 0.1509s/iter; left time: 389.3314s\n",
      "\titers: 200, epoch: 8 | loss: 0.3133093\n",
      "\tspeed: 0.0424s/iter; left time: 105.1967s\n",
      "\titers: 300, epoch: 8 | loss: 0.2900985\n",
      "\tspeed: 0.0424s/iter; left time: 100.8443s\n",
      "\titers: 400, epoch: 8 | loss: 0.3482691\n",
      "\tspeed: 0.0424s/iter; left time: 96.6245s\n",
      "\titers: 500, epoch: 8 | loss: 0.3318945\n",
      "\tspeed: 0.0423s/iter; left time: 92.3116s\n",
      "\titers: 600, epoch: 8 | loss: 0.2822109\n",
      "\tspeed: 0.0423s/iter; left time: 88.0182s\n",
      "\titers: 700, epoch: 8 | loss: 0.3060897\n",
      "\tspeed: 0.0424s/iter; left time: 83.9099s\n",
      "\titers: 800, epoch: 8 | loss: 0.3357830\n",
      "\tspeed: 0.0424s/iter; left time: 79.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3131295 Vali Loss: 0.2335430 Test Loss: 0.2739078\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2432195246219635, rmse:0.49317291378974915, mae:0.32862284779548645, rse:0.4793917238712311\n",
      "Original data scale mse:18199538.0, rmse:4266.091796875, mae:2667.862060546875, rse:0.21211868524551392\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4627249\n",
      "\tspeed: 0.0441s/iter; left time: 389.0936s\n",
      "\titers: 200, epoch: 1 | loss: 0.4810070\n",
      "\tspeed: 0.0423s/iter; left time: 369.7337s\n",
      "\titers: 300, epoch: 1 | loss: 0.3775995\n",
      "\tspeed: 0.0424s/iter; left time: 365.6905s\n",
      "\titers: 400, epoch: 1 | loss: 0.3788279\n",
      "\tspeed: 0.0424s/iter; left time: 361.4481s\n",
      "\titers: 500, epoch: 1 | loss: 0.3954695\n",
      "\tspeed: 0.0424s/iter; left time: 357.2624s\n",
      "\titers: 600, epoch: 1 | loss: 0.4038344\n",
      "\tspeed: 0.0423s/iter; left time: 352.5639s\n",
      "\titers: 700, epoch: 1 | loss: 0.3603105\n",
      "\tspeed: 0.0423s/iter; left time: 348.5498s\n",
      "\titers: 800, epoch: 1 | loss: 0.3826021\n",
      "\tspeed: 0.0423s/iter; left time: 344.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.4462209 Vali Loss: 0.2220088 Test Loss: 0.2474589\n",
      "Validation loss decreased (inf --> 0.222009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4468117\n",
      "\tspeed: 0.1545s/iter; left time: 1226.0742s\n",
      "\titers: 200, epoch: 2 | loss: 0.3882646\n",
      "\tspeed: 0.0425s/iter; left time: 333.3921s\n",
      "\titers: 300, epoch: 2 | loss: 0.3921411\n",
      "\tspeed: 0.0425s/iter; left time: 328.5391s\n",
      "\titers: 400, epoch: 2 | loss: 0.4408219\n",
      "\tspeed: 0.0425s/iter; left time: 324.2496s\n",
      "\titers: 500, epoch: 2 | loss: 0.4288436\n",
      "\tspeed: 0.0425s/iter; left time: 320.1669s\n",
      "\titers: 600, epoch: 2 | loss: 0.4248250\n",
      "\tspeed: 0.0425s/iter; left time: 315.8468s\n",
      "\titers: 700, epoch: 2 | loss: 0.3980495\n",
      "\tspeed: 0.0425s/iter; left time: 311.7407s\n",
      "\titers: 800, epoch: 2 | loss: 0.4369488\n",
      "\tspeed: 0.0425s/iter; left time: 307.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.4213050 Vali Loss: 0.2097122 Test Loss: 0.2390324\n",
      "Validation loss decreased (0.222009 --> 0.209712).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4233243\n",
      "\tspeed: 0.1535s/iter; left time: 1081.4250s\n",
      "\titers: 200, epoch: 3 | loss: 0.4000756\n",
      "\tspeed: 0.0424s/iter; left time: 294.7136s\n",
      "\titers: 300, epoch: 3 | loss: 0.3975570\n",
      "\tspeed: 0.0426s/iter; left time: 291.6814s\n",
      "\titers: 400, epoch: 3 | loss: 0.4036248\n",
      "\tspeed: 0.0428s/iter; left time: 288.7328s\n",
      "\titers: 500, epoch: 3 | loss: 0.3283674\n",
      "\tspeed: 0.0428s/iter; left time: 284.5081s\n",
      "\titers: 600, epoch: 3 | loss: 0.3974990\n",
      "\tspeed: 0.0428s/iter; left time: 280.0580s\n",
      "\titers: 700, epoch: 3 | loss: 0.3839193\n",
      "\tspeed: 0.0428s/iter; left time: 275.5819s\n",
      "\titers: 800, epoch: 3 | loss: 0.4012060\n",
      "\tspeed: 0.0425s/iter; left time: 269.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 893 | Train Loss: 0.3911129 Vali Loss: 0.2123895 Test Loss: 0.2398590\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4230535\n",
      "\tspeed: 0.1529s/iter; left time: 940.3885s\n",
      "\titers: 200, epoch: 4 | loss: 0.3863612\n",
      "\tspeed: 0.0425s/iter; left time: 257.0466s\n",
      "\titers: 300, epoch: 4 | loss: 0.3751012\n",
      "\tspeed: 0.0425s/iter; left time: 253.0282s\n",
      "\titers: 400, epoch: 4 | loss: 0.3567015\n",
      "\tspeed: 0.0427s/iter; left time: 249.7753s\n",
      "\titers: 500, epoch: 4 | loss: 0.3692994\n",
      "\tspeed: 0.0425s/iter; left time: 244.2765s\n",
      "\titers: 600, epoch: 4 | loss: 0.3690723\n",
      "\tspeed: 0.0425s/iter; left time: 240.1361s\n",
      "\titers: 700, epoch: 4 | loss: 0.3942787\n",
      "\tspeed: 0.0425s/iter; left time: 235.7881s\n",
      "\titers: 800, epoch: 4 | loss: 0.3504765\n",
      "\tspeed: 0.0425s/iter; left time: 231.5134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3797200 Vali Loss: 0.2056763 Test Loss: 0.2373357\n",
      "Validation loss decreased (0.209712 --> 0.205676).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3825168\n",
      "\tspeed: 0.1554s/iter; left time: 817.1957s\n",
      "\titers: 200, epoch: 5 | loss: 0.3447078\n",
      "\tspeed: 0.0425s/iter; left time: 219.0883s\n",
      "\titers: 300, epoch: 5 | loss: 0.3645397\n",
      "\tspeed: 0.0426s/iter; left time: 215.2974s\n",
      "\titers: 400, epoch: 5 | loss: 0.4045370\n",
      "\tspeed: 0.0426s/iter; left time: 211.2526s\n",
      "\titers: 500, epoch: 5 | loss: 0.4360555\n",
      "\tspeed: 0.0426s/iter; left time: 206.9996s\n",
      "\titers: 600, epoch: 5 | loss: 0.3904092\n",
      "\tspeed: 0.0428s/iter; left time: 203.5662s\n",
      "\titers: 700, epoch: 5 | loss: 0.4079309\n",
      "\tspeed: 0.0428s/iter; left time: 199.1745s\n",
      "\titers: 800, epoch: 5 | loss: 0.3473741\n",
      "\tspeed: 0.0428s/iter; left time: 194.9087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 893 | Train Loss: 0.3669088 Vali Loss: 0.2076001 Test Loss: 0.2412341\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4358069\n",
      "\tspeed: 0.1538s/iter; left time: 671.6840s\n",
      "\titers: 200, epoch: 6 | loss: 0.3262861\n",
      "\tspeed: 0.0427s/iter; left time: 182.3221s\n",
      "\titers: 300, epoch: 6 | loss: 0.3337511\n",
      "\tspeed: 0.0427s/iter; left time: 177.8897s\n",
      "\titers: 400, epoch: 6 | loss: 0.3791381\n",
      "\tspeed: 0.0425s/iter; left time: 172.8758s\n",
      "\titers: 500, epoch: 6 | loss: 0.3326493\n",
      "\tspeed: 0.0425s/iter; left time: 168.4972s\n",
      "\titers: 600, epoch: 6 | loss: 0.3490874\n",
      "\tspeed: 0.0426s/iter; left time: 164.6048s\n",
      "\titers: 700, epoch: 6 | loss: 0.3610901\n",
      "\tspeed: 0.0426s/iter; left time: 160.2520s\n",
      "\titers: 800, epoch: 6 | loss: 0.3445083\n",
      "\tspeed: 0.0425s/iter; left time: 155.9353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.3520390 Vali Loss: 0.2155766 Test Loss: 0.2493458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3519499\n",
      "\tspeed: 0.1529s/iter; left time: 530.9237s\n",
      "\titers: 200, epoch: 7 | loss: 0.3816791\n",
      "\tspeed: 0.0425s/iter; left time: 143.5045s\n",
      "\titers: 300, epoch: 7 | loss: 0.3123848\n",
      "\tspeed: 0.0425s/iter; left time: 139.0378s\n",
      "\titers: 400, epoch: 7 | loss: 0.3204518\n",
      "\tspeed: 0.0425s/iter; left time: 134.8396s\n",
      "\titers: 500, epoch: 7 | loss: 0.2937274\n",
      "\tspeed: 0.0425s/iter; left time: 130.5625s\n",
      "\titers: 600, epoch: 7 | loss: 0.3157093\n",
      "\tspeed: 0.0425s/iter; left time: 126.3152s\n",
      "\titers: 700, epoch: 7 | loss: 0.3109202\n",
      "\tspeed: 0.0425s/iter; left time: 122.1029s\n",
      "\titers: 800, epoch: 7 | loss: 0.3189745\n",
      "\tspeed: 0.0425s/iter; left time: 117.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.3303891 Vali Loss: 0.2250563 Test Loss: 0.2799367\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23733577132225037, rmse:0.4871712028980255, mae:0.3286206126213074, rse:0.473557710647583\n",
      "Original data scale mse:17552708.0, rmse:4189.59521484375, mae:2641.27880859375, rse:0.20831511914730072\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6345074\n",
      "\tspeed: 0.0691s/iter; left time: 609.2619s\n",
      "\titers: 200, epoch: 1 | loss: 0.5412972\n",
      "\tspeed: 0.0428s/iter; left time: 372.5770s\n",
      "\titers: 300, epoch: 1 | loss: 0.5562449\n",
      "\tspeed: 0.0427s/iter; left time: 367.8249s\n",
      "\titers: 400, epoch: 1 | loss: 0.5097930\n",
      "\tspeed: 0.0427s/iter; left time: 363.5319s\n",
      "\titers: 500, epoch: 1 | loss: 0.5492460\n",
      "\tspeed: 0.0428s/iter; left time: 359.7909s\n",
      "\titers: 600, epoch: 1 | loss: 0.5247215\n",
      "\tspeed: 0.0428s/iter; left time: 355.9429s\n",
      "\titers: 700, epoch: 1 | loss: 0.5481805\n",
      "\tspeed: 0.0428s/iter; left time: 351.2185s\n",
      "\titers: 800, epoch: 1 | loss: 0.5801686\n",
      "\tspeed: 0.0428s/iter; left time: 346.7808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 891 | Train Loss: 0.5569856 Vali Loss: 0.3342626 Test Loss: 0.4036690\n",
      "Validation loss decreased (inf --> 0.334263).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5640212\n",
      "\tspeed: 0.1534s/iter; left time: 1214.6715s\n",
      "\titers: 200, epoch: 2 | loss: 0.5194572\n",
      "\tspeed: 0.0427s/iter; left time: 334.2129s\n",
      "\titers: 300, epoch: 2 | loss: 0.5155885\n",
      "\tspeed: 0.0428s/iter; left time: 330.3211s\n",
      "\titers: 400, epoch: 2 | loss: 0.5696425\n",
      "\tspeed: 0.0427s/iter; left time: 325.4819s\n",
      "\titers: 500, epoch: 2 | loss: 0.4769734\n",
      "\tspeed: 0.0428s/iter; left time: 321.5096s\n",
      "\titers: 600, epoch: 2 | loss: 0.4558331\n",
      "\tspeed: 0.0427s/iter; left time: 316.9321s\n",
      "\titers: 700, epoch: 2 | loss: 0.4634367\n",
      "\tspeed: 0.0428s/iter; left time: 313.0361s\n",
      "\titers: 800, epoch: 2 | loss: 0.5508001\n",
      "\tspeed: 0.0428s/iter; left time: 308.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.5325205 Vali Loss: 0.3381830 Test Loss: 0.4116932\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4698816\n",
      "\tspeed: 0.1519s/iter; left time: 1067.8639s\n",
      "\titers: 200, epoch: 3 | loss: 0.5208798\n",
      "\tspeed: 0.0428s/iter; left time: 296.4992s\n",
      "\titers: 300, epoch: 3 | loss: 0.5191745\n",
      "\tspeed: 0.0427s/iter; left time: 291.5807s\n",
      "\titers: 400, epoch: 3 | loss: 0.5005776\n",
      "\tspeed: 0.0427s/iter; left time: 287.1588s\n",
      "\titers: 500, epoch: 3 | loss: 0.5024170\n",
      "\tspeed: 0.0427s/iter; left time: 282.9332s\n",
      "\titers: 600, epoch: 3 | loss: 0.4613788\n",
      "\tspeed: 0.0427s/iter; left time: 278.5374s\n",
      "\titers: 700, epoch: 3 | loss: 0.5163460\n",
      "\tspeed: 0.0427s/iter; left time: 274.7261s\n",
      "\titers: 800, epoch: 3 | loss: 0.4546890\n",
      "\tspeed: 0.0427s/iter; left time: 270.1427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.4972181 Vali Loss: 0.3756260 Test Loss: 0.4761226\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4737630\n",
      "\tspeed: 0.1513s/iter; left time: 928.4065s\n",
      "\titers: 200, epoch: 4 | loss: 0.4687172\n",
      "\tspeed: 0.0427s/iter; left time: 257.9800s\n",
      "\titers: 300, epoch: 4 | loss: 0.4597653\n",
      "\tspeed: 0.0427s/iter; left time: 253.6618s\n",
      "\titers: 400, epoch: 4 | loss: 0.4724765\n",
      "\tspeed: 0.0427s/iter; left time: 249.3522s\n",
      "\titers: 500, epoch: 4 | loss: 0.4457217\n",
      "\tspeed: 0.0427s/iter; left time: 245.1885s\n",
      "\titers: 600, epoch: 4 | loss: 0.4597476\n",
      "\tspeed: 0.0427s/iter; left time: 240.6676s\n",
      "\titers: 700, epoch: 4 | loss: 0.4234651\n",
      "\tspeed: 0.0427s/iter; left time: 236.3710s\n",
      "\titers: 800, epoch: 4 | loss: 0.3789759\n",
      "\tspeed: 0.0427s/iter; left time: 232.1223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.4404088 Vali Loss: 0.3992287 Test Loss: 0.5203529\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4036690294742584, rmse:0.6353495121002197, mae:0.4568611979484558, rse:0.6179585456848145\n",
      "Original data scale mse:32573556.0, rmse:5707.32470703125, mae:3834.916748046875, rse:0.28422680497169495\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6040326\n",
      "\tspeed: 0.0445s/iter; left time: 392.1222s\n",
      "\titers: 200, epoch: 1 | loss: 0.4955250\n",
      "\tspeed: 0.0428s/iter; left time: 372.7255s\n",
      "\titers: 300, epoch: 1 | loss: 0.6056259\n",
      "\tspeed: 0.0427s/iter; left time: 367.3216s\n",
      "\titers: 400, epoch: 1 | loss: 0.5453749\n",
      "\tspeed: 0.0427s/iter; left time: 363.1428s\n",
      "\titers: 500, epoch: 1 | loss: 0.5231329\n",
      "\tspeed: 0.0427s/iter; left time: 358.9036s\n",
      "\titers: 600, epoch: 1 | loss: 0.4840289\n",
      "\tspeed: 0.0427s/iter; left time: 354.8231s\n",
      "\titers: 700, epoch: 1 | loss: 0.5079355\n",
      "\tspeed: 0.0427s/iter; left time: 350.3205s\n",
      "\titers: 800, epoch: 1 | loss: 0.4609497\n",
      "\tspeed: 0.0427s/iter; left time: 346.5687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.5556409 Vali Loss: 0.3335489 Test Loss: 0.4002578\n",
      "Validation loss decreased (inf --> 0.333549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5311090\n",
      "\tspeed: 0.1564s/iter; left time: 1238.9464s\n",
      "\titers: 200, epoch: 2 | loss: 0.4929393\n",
      "\tspeed: 0.0428s/iter; left time: 334.9083s\n",
      "\titers: 300, epoch: 2 | loss: 0.5975280\n",
      "\tspeed: 0.0428s/iter; left time: 330.4302s\n",
      "\titers: 400, epoch: 2 | loss: 0.5767192\n",
      "\tspeed: 0.0429s/iter; left time: 326.7495s\n",
      "\titers: 500, epoch: 2 | loss: 0.4910087\n",
      "\tspeed: 0.0429s/iter; left time: 322.8307s\n",
      "\titers: 600, epoch: 2 | loss: 0.5547670\n",
      "\tspeed: 0.0430s/iter; left time: 319.3152s\n",
      "\titers: 700, epoch: 2 | loss: 0.5132957\n",
      "\tspeed: 0.0429s/iter; left time: 314.2849s\n",
      "\titers: 800, epoch: 2 | loss: 0.5068620\n",
      "\tspeed: 0.0428s/iter; left time: 309.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.5305442 Vali Loss: 0.3430454 Test Loss: 0.4259739\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5168265\n",
      "\tspeed: 0.1549s/iter; left time: 1088.4429s\n",
      "\titers: 200, epoch: 3 | loss: 0.4956676\n",
      "\tspeed: 0.0430s/iter; left time: 297.6317s\n",
      "\titers: 300, epoch: 3 | loss: 0.5157908\n",
      "\tspeed: 0.0429s/iter; left time: 293.1327s\n",
      "\titers: 400, epoch: 3 | loss: 0.5067684\n",
      "\tspeed: 0.0429s/iter; left time: 288.8872s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548647\n",
      "\tspeed: 0.0429s/iter; left time: 284.6853s\n",
      "\titers: 600, epoch: 3 | loss: 0.4573902\n",
      "\tspeed: 0.0429s/iter; left time: 280.3237s\n",
      "\titers: 700, epoch: 3 | loss: 0.4979976\n",
      "\tspeed: 0.0429s/iter; left time: 275.8182s\n",
      "\titers: 800, epoch: 3 | loss: 0.4394158\n",
      "\tspeed: 0.0428s/iter; left time: 270.8534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 891 | Train Loss: 0.4911427 Vali Loss: 0.3692628 Test Loss: 0.4977124\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4704323\n",
      "\tspeed: 0.1544s/iter; left time: 947.4916s\n",
      "\titers: 200, epoch: 4 | loss: 0.4102717\n",
      "\tspeed: 0.0430s/iter; left time: 259.5974s\n",
      "\titers: 300, epoch: 4 | loss: 0.4254036\n",
      "\tspeed: 0.0429s/iter; left time: 254.9136s\n",
      "\titers: 400, epoch: 4 | loss: 0.4254311\n",
      "\tspeed: 0.0429s/iter; left time: 250.1880s\n",
      "\titers: 500, epoch: 4 | loss: 0.4057109\n",
      "\tspeed: 0.0429s/iter; left time: 246.3262s\n",
      "\titers: 600, epoch: 4 | loss: 0.4167624\n",
      "\tspeed: 0.0430s/iter; left time: 242.4912s\n",
      "\titers: 700, epoch: 4 | loss: 0.4556670\n",
      "\tspeed: 0.0430s/iter; left time: 238.1178s\n",
      "\titers: 800, epoch: 4 | loss: 0.4121064\n",
      "\tspeed: 0.0430s/iter; left time: 233.9707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.4327600 Vali Loss: 0.3784308 Test Loss: 0.5389258\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.40025779604911804, rmse:0.6326593160629272, mae:0.45186686515808105, rse:0.6153419613838196\n",
      "Original data scale mse:32110734.0, rmse:5666.63330078125, mae:3774.54248046875, rse:0.2822003662586212\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6487415\n",
      "\tspeed: 0.0704s/iter; left time: 618.9872s\n",
      "\titers: 200, epoch: 1 | loss: 0.5665378\n",
      "\tspeed: 0.0434s/iter; left time: 377.3207s\n",
      "\titers: 300, epoch: 1 | loss: 0.5798368\n",
      "\tspeed: 0.0434s/iter; left time: 372.8620s\n",
      "\titers: 400, epoch: 1 | loss: 0.6252718\n",
      "\tspeed: 0.0434s/iter; left time: 368.4850s\n",
      "\titers: 500, epoch: 1 | loss: 0.6081845\n",
      "\tspeed: 0.0434s/iter; left time: 364.1391s\n",
      "\titers: 600, epoch: 1 | loss: 0.5711913\n",
      "\tspeed: 0.0434s/iter; left time: 360.2027s\n",
      "\titers: 700, epoch: 1 | loss: 0.5641771\n",
      "\tspeed: 0.0434s/iter; left time: 355.6172s\n",
      "\titers: 800, epoch: 1 | loss: 0.5788223\n",
      "\tspeed: 0.0434s/iter; left time: 351.3518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.00s\n",
      "Steps: 889 | Train Loss: 0.5784869 Vali Loss: 0.3481130 Test Loss: 0.4330794\n",
      "Validation loss decreased (inf --> 0.348113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5929089\n",
      "\tspeed: 0.1593s/iter; left time: 1259.0297s\n",
      "\titers: 200, epoch: 2 | loss: 0.5337034\n",
      "\tspeed: 0.0432s/iter; left time: 337.2797s\n",
      "\titers: 300, epoch: 2 | loss: 0.6033278\n",
      "\tspeed: 0.0432s/iter; left time: 333.0272s\n",
      "\titers: 400, epoch: 2 | loss: 0.5481176\n",
      "\tspeed: 0.0432s/iter; left time: 328.6308s\n",
      "\titers: 500, epoch: 2 | loss: 0.5433515\n",
      "\tspeed: 0.0434s/iter; left time: 325.5672s\n",
      "\titers: 600, epoch: 2 | loss: 0.5433046\n",
      "\tspeed: 0.0434s/iter; left time: 321.0102s\n",
      "\titers: 700, epoch: 2 | loss: 0.5226781\n",
      "\tspeed: 0.0432s/iter; left time: 315.6562s\n",
      "\titers: 800, epoch: 2 | loss: 0.5602379\n",
      "\tspeed: 0.0432s/iter; left time: 311.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5536581 Vali Loss: 0.3503735 Test Loss: 0.4435634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5247940\n",
      "\tspeed: 0.1541s/iter; left time: 1080.6327s\n",
      "\titers: 200, epoch: 3 | loss: 0.4666578\n",
      "\tspeed: 0.0436s/iter; left time: 301.0711s\n",
      "\titers: 300, epoch: 3 | loss: 0.4915379\n",
      "\tspeed: 0.0436s/iter; left time: 297.1110s\n",
      "\titers: 400, epoch: 3 | loss: 0.5265747\n",
      "\tspeed: 0.0434s/iter; left time: 291.5574s\n",
      "\titers: 500, epoch: 3 | loss: 0.5261526\n",
      "\tspeed: 0.0435s/iter; left time: 287.8618s\n",
      "\titers: 600, epoch: 3 | loss: 0.4984049\n",
      "\tspeed: 0.0436s/iter; left time: 283.6791s\n",
      "\titers: 700, epoch: 3 | loss: 0.4938059\n",
      "\tspeed: 0.0435s/iter; left time: 278.9440s\n",
      "\titers: 800, epoch: 3 | loss: 0.4697720\n",
      "\tspeed: 0.0434s/iter; left time: 274.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 889 | Train Loss: 0.4933211 Vali Loss: 0.3897238 Test Loss: 0.5161418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4248726\n",
      "\tspeed: 0.1536s/iter; left time: 940.5743s\n",
      "\titers: 200, epoch: 4 | loss: 0.4227059\n",
      "\tspeed: 0.0434s/iter; left time: 261.4773s\n",
      "\titers: 300, epoch: 4 | loss: 0.4484168\n",
      "\tspeed: 0.0434s/iter; left time: 257.1222s\n",
      "\titers: 400, epoch: 4 | loss: 0.4374381\n",
      "\tspeed: 0.0433s/iter; left time: 252.3886s\n",
      "\titers: 500, epoch: 4 | loss: 0.4159889\n",
      "\tspeed: 0.0433s/iter; left time: 247.5729s\n",
      "\titers: 600, epoch: 4 | loss: 0.3730746\n",
      "\tspeed: 0.0433s/iter; left time: 243.4629s\n",
      "\titers: 700, epoch: 4 | loss: 0.4663849\n",
      "\tspeed: 0.0434s/iter; left time: 239.7770s\n",
      "\titers: 800, epoch: 4 | loss: 0.4110291\n",
      "\tspeed: 0.0434s/iter; left time: 235.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4278258 Vali Loss: 0.3949634 Test Loss: 0.5482817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.43307942152023315, rmse:0.6580876708030701, mae:0.4750068783760071, rse:0.6381146907806396\n",
      "Original data scale mse:35332576.0, rmse:5944.12109375, mae:3983.261962890625, rse:0.2961646616458893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5541797\n",
      "\tspeed: 0.0449s/iter; left time: 394.4930s\n",
      "\titers: 200, epoch: 1 | loss: 0.6447560\n",
      "\tspeed: 0.0433s/iter; left time: 376.7359s\n",
      "\titers: 300, epoch: 1 | loss: 0.6078178\n",
      "\tspeed: 0.0433s/iter; left time: 372.3166s\n",
      "\titers: 400, epoch: 1 | loss: 0.5680565\n",
      "\tspeed: 0.0433s/iter; left time: 367.9043s\n",
      "\titers: 500, epoch: 1 | loss: 0.5506138\n",
      "\tspeed: 0.0432s/iter; left time: 362.5799s\n",
      "\titers: 600, epoch: 1 | loss: 0.5916827\n",
      "\tspeed: 0.0433s/iter; left time: 358.9773s\n",
      "\titers: 700, epoch: 1 | loss: 0.5238413\n",
      "\tspeed: 0.0432s/iter; left time: 353.7496s\n",
      "\titers: 800, epoch: 1 | loss: 0.5558631\n",
      "\tspeed: 0.0431s/iter; left time: 349.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5795735 Vali Loss: 0.3490178 Test Loss: 0.4349462\n",
      "Validation loss decreased (inf --> 0.349018).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6458588\n",
      "\tspeed: 0.1573s/iter; left time: 1243.1764s\n",
      "\titers: 200, epoch: 2 | loss: 0.5979521\n",
      "\tspeed: 0.0433s/iter; left time: 337.6882s\n",
      "\titers: 300, epoch: 2 | loss: 0.6093858\n",
      "\tspeed: 0.0433s/iter; left time: 333.6957s\n",
      "\titers: 400, epoch: 2 | loss: 0.5543461\n",
      "\tspeed: 0.0433s/iter; left time: 329.3861s\n",
      "\titers: 500, epoch: 2 | loss: 0.5239897\n",
      "\tspeed: 0.0434s/iter; left time: 325.3004s\n",
      "\titers: 600, epoch: 2 | loss: 0.4797231\n",
      "\tspeed: 0.0433s/iter; left time: 320.8067s\n",
      "\titers: 700, epoch: 2 | loss: 0.5349596\n",
      "\tspeed: 0.0433s/iter; left time: 316.4395s\n",
      "\titers: 800, epoch: 2 | loss: 0.5079510\n",
      "\tspeed: 0.0433s/iter; left time: 312.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5485454 Vali Loss: 0.3758105 Test Loss: 0.4721995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5296508\n",
      "\tspeed: 0.1533s/iter; left time: 1075.1520s\n",
      "\titers: 200, epoch: 3 | loss: 0.5096095\n",
      "\tspeed: 0.0432s/iter; left time: 298.5468s\n",
      "\titers: 300, epoch: 3 | loss: 0.5181944\n",
      "\tspeed: 0.0432s/iter; left time: 294.2351s\n",
      "\titers: 400, epoch: 3 | loss: 0.5009753\n",
      "\tspeed: 0.0433s/iter; left time: 290.7663s\n",
      "\titers: 500, epoch: 3 | loss: 0.5160809\n",
      "\tspeed: 0.0433s/iter; left time: 286.5293s\n",
      "\titers: 600, epoch: 3 | loss: 0.4707217\n",
      "\tspeed: 0.0433s/iter; left time: 282.3188s\n",
      "\titers: 700, epoch: 3 | loss: 0.4547001\n",
      "\tspeed: 0.0434s/iter; left time: 278.0078s\n",
      "\titers: 800, epoch: 3 | loss: 0.4301299\n",
      "\tspeed: 0.0433s/iter; left time: 273.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4927791 Vali Loss: 0.3916558 Test Loss: 0.5282715\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4355078\n",
      "\tspeed: 0.1530s/iter; left time: 936.9614s\n",
      "\titers: 200, epoch: 4 | loss: 0.4094014\n",
      "\tspeed: 0.0435s/iter; left time: 261.9613s\n",
      "\titers: 300, epoch: 4 | loss: 0.4425901\n",
      "\tspeed: 0.0434s/iter; left time: 256.8307s\n",
      "\titers: 400, epoch: 4 | loss: 0.4454512\n",
      "\tspeed: 0.0434s/iter; left time: 252.5337s\n",
      "\titers: 500, epoch: 4 | loss: 0.3985242\n",
      "\tspeed: 0.0434s/iter; left time: 248.3329s\n",
      "\titers: 600, epoch: 4 | loss: 0.4066934\n",
      "\tspeed: 0.0433s/iter; left time: 243.7769s\n",
      "\titers: 700, epoch: 4 | loss: 0.4044339\n",
      "\tspeed: 0.0434s/iter; left time: 239.5480s\n",
      "\titers: 800, epoch: 4 | loss: 0.3898852\n",
      "\tspeed: 0.0434s/iter; left time: 235.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.76s\n",
      "Steps: 889 | Train Loss: 0.4138639 Vali Loss: 0.4066092 Test Loss: 0.5992306\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4349460303783417, rmse:0.6595043540000916, mae:0.4763880968093872, rse:0.6394883394241333\n",
      "Original data scale mse:35436588.0, rmse:5952.86376953125, mae:3990.803466796875, rse:0.29660025238990784\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3407999\n",
      "\tspeed: 0.0697s/iter; left time: 615.3187s\n",
      "\titers: 200, epoch: 1 | loss: 0.3598070\n",
      "\tspeed: 0.0421s/iter; left time: 367.7602s\n",
      "\titers: 300, epoch: 1 | loss: 0.3071695\n",
      "\tspeed: 0.0424s/iter; left time: 365.8797s\n",
      "\titers: 400, epoch: 1 | loss: 0.3217622\n",
      "\tspeed: 0.0424s/iter; left time: 361.3499s\n",
      "\titers: 500, epoch: 1 | loss: 0.3050108\n",
      "\tspeed: 0.0424s/iter; left time: 357.3816s\n",
      "\titers: 600, epoch: 1 | loss: 0.3329523\n",
      "\tspeed: 0.0424s/iter; left time: 352.8376s\n",
      "\titers: 700, epoch: 1 | loss: 0.2990830\n",
      "\tspeed: 0.0424s/iter; left time: 348.6590s\n",
      "\titers: 800, epoch: 1 | loss: 0.2877811\n",
      "\tspeed: 0.0423s/iter; left time: 344.3195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.3166869 Vali Loss: 0.3205190 Test Loss: 0.3306546\n",
      "Validation loss decreased (inf --> 0.320519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3504318\n",
      "\tspeed: 0.1525s/iter; left time: 1210.9338s\n",
      "\titers: 200, epoch: 2 | loss: 0.3321462\n",
      "\tspeed: 0.0424s/iter; left time: 332.2146s\n",
      "\titers: 300, epoch: 2 | loss: 0.2899115\n",
      "\tspeed: 0.0424s/iter; left time: 327.7598s\n",
      "\titers: 400, epoch: 2 | loss: 0.2918292\n",
      "\tspeed: 0.0424s/iter; left time: 323.6287s\n",
      "\titers: 500, epoch: 2 | loss: 0.2904305\n",
      "\tspeed: 0.0424s/iter; left time: 319.5672s\n",
      "\titers: 600, epoch: 2 | loss: 0.2945925\n",
      "\tspeed: 0.0424s/iter; left time: 315.1284s\n",
      "\titers: 700, epoch: 2 | loss: 0.2926659\n",
      "\tspeed: 0.0424s/iter; left time: 311.0399s\n",
      "\titers: 800, epoch: 2 | loss: 0.2831026\n",
      "\tspeed: 0.0424s/iter; left time: 306.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.2996101 Vali Loss: 0.3356258 Test Loss: 0.3559322\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2392561\n",
      "\tspeed: 0.1501s/iter; left time: 1057.6539s\n",
      "\titers: 200, epoch: 3 | loss: 0.2852877\n",
      "\tspeed: 0.0423s/iter; left time: 293.9754s\n",
      "\titers: 300, epoch: 3 | loss: 0.2525412\n",
      "\tspeed: 0.0424s/iter; left time: 290.3136s\n",
      "\titers: 400, epoch: 3 | loss: 0.2729546\n",
      "\tspeed: 0.0424s/iter; left time: 285.8616s\n",
      "\titers: 500, epoch: 3 | loss: 0.2617796\n",
      "\tspeed: 0.0424s/iter; left time: 281.7719s\n",
      "\titers: 600, epoch: 3 | loss: 0.2953496\n",
      "\tspeed: 0.0424s/iter; left time: 277.8198s\n",
      "\titers: 700, epoch: 3 | loss: 0.2387735\n",
      "\tspeed: 0.0426s/iter; left time: 274.3965s\n",
      "\titers: 800, epoch: 3 | loss: 0.2972452\n",
      "\tspeed: 0.0425s/iter; left time: 269.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.2766799 Vali Loss: 0.3361943 Test Loss: 0.3511512\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2737566\n",
      "\tspeed: 0.1508s/iter; left time: 927.5392s\n",
      "\titers: 200, epoch: 4 | loss: 0.2433610\n",
      "\tspeed: 0.0423s/iter; left time: 255.9719s\n",
      "\titers: 300, epoch: 4 | loss: 0.2543726\n",
      "\tspeed: 0.0423s/iter; left time: 251.6670s\n",
      "\titers: 400, epoch: 4 | loss: 0.2220378\n",
      "\tspeed: 0.0423s/iter; left time: 247.5232s\n",
      "\titers: 500, epoch: 4 | loss: 0.3129626\n",
      "\tspeed: 0.0424s/iter; left time: 243.9160s\n",
      "\titers: 600, epoch: 4 | loss: 0.2391707\n",
      "\tspeed: 0.0423s/iter; left time: 239.2810s\n",
      "\titers: 700, epoch: 4 | loss: 0.2357916\n",
      "\tspeed: 0.0423s/iter; left time: 234.9157s\n",
      "\titers: 800, epoch: 4 | loss: 0.2973626\n",
      "\tspeed: 0.0425s/iter; left time: 231.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2566382 Vali Loss: 0.3036595 Test Loss: 0.3120285\n",
      "Validation loss decreased (0.320519 --> 0.303660).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2369801\n",
      "\tspeed: 0.1533s/iter; left time: 806.3813s\n",
      "\titers: 200, epoch: 5 | loss: 0.2127407\n",
      "\tspeed: 0.0423s/iter; left time: 218.2689s\n",
      "\titers: 300, epoch: 5 | loss: 0.2476412\n",
      "\tspeed: 0.0424s/iter; left time: 214.2930s\n",
      "\titers: 400, epoch: 5 | loss: 0.2261378\n",
      "\tspeed: 0.0423s/iter; left time: 209.9362s\n",
      "\titers: 500, epoch: 5 | loss: 0.2450154\n",
      "\tspeed: 0.0423s/iter; left time: 205.6001s\n",
      "\titers: 600, epoch: 5 | loss: 0.2148946\n",
      "\tspeed: 0.0423s/iter; left time: 201.4148s\n",
      "\titers: 700, epoch: 5 | loss: 0.2560253\n",
      "\tspeed: 0.0423s/iter; left time: 197.2089s\n",
      "\titers: 800, epoch: 5 | loss: 0.2288969\n",
      "\tspeed: 0.0423s/iter; left time: 193.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.2457368 Vali Loss: 0.3050472 Test Loss: 0.3138959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2109427\n",
      "\tspeed: 0.1508s/iter; left time: 658.4415s\n",
      "\titers: 200, epoch: 6 | loss: 0.2650115\n",
      "\tspeed: 0.0423s/iter; left time: 180.4568s\n",
      "\titers: 300, epoch: 6 | loss: 0.2831419\n",
      "\tspeed: 0.0423s/iter; left time: 176.0496s\n",
      "\titers: 400, epoch: 6 | loss: 0.2267048\n",
      "\tspeed: 0.0423s/iter; left time: 171.9640s\n",
      "\titers: 500, epoch: 6 | loss: 0.2382194\n",
      "\tspeed: 0.0423s/iter; left time: 167.6327s\n",
      "\titers: 600, epoch: 6 | loss: 0.2519537\n",
      "\tspeed: 0.0423s/iter; left time: 163.5303s\n",
      "\titers: 700, epoch: 6 | loss: 0.2022270\n",
      "\tspeed: 0.0423s/iter; left time: 159.1781s\n",
      "\titers: 800, epoch: 6 | loss: 0.2319725\n",
      "\tspeed: 0.0423s/iter; left time: 155.0073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2408286 Vali Loss: 0.2955035 Test Loss: 0.3079064\n",
      "Validation loss decreased (0.303660 --> 0.295503).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2475756\n",
      "\tspeed: 0.1530s/iter; left time: 531.3682s\n",
      "\titers: 200, epoch: 7 | loss: 0.2347258\n",
      "\tspeed: 0.0423s/iter; left time: 142.8418s\n",
      "\titers: 300, epoch: 7 | loss: 0.2438284\n",
      "\tspeed: 0.0423s/iter; left time: 138.5680s\n",
      "\titers: 400, epoch: 7 | loss: 0.2352685\n",
      "\tspeed: 0.0423s/iter; left time: 134.2759s\n",
      "\titers: 500, epoch: 7 | loss: 0.2425852\n",
      "\tspeed: 0.0423s/iter; left time: 129.9323s\n",
      "\titers: 600, epoch: 7 | loss: 0.2188660\n",
      "\tspeed: 0.0423s/iter; left time: 125.6779s\n",
      "\titers: 700, epoch: 7 | loss: 0.2236696\n",
      "\tspeed: 0.0423s/iter; left time: 121.5110s\n",
      "\titers: 800, epoch: 7 | loss: 0.2287398\n",
      "\tspeed: 0.0424s/iter; left time: 117.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2348060 Vali Loss: 0.3015920 Test Loss: 0.3169947\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2366807\n",
      "\tspeed: 0.1505s/iter; left time: 388.2172s\n",
      "\titers: 200, epoch: 8 | loss: 0.2345567\n",
      "\tspeed: 0.0423s/iter; left time: 104.9477s\n",
      "\titers: 300, epoch: 8 | loss: 0.2331254\n",
      "\tspeed: 0.0424s/iter; left time: 100.8302s\n",
      "\titers: 400, epoch: 8 | loss: 0.2523240\n",
      "\tspeed: 0.0424s/iter; left time: 96.5976s\n",
      "\titers: 500, epoch: 8 | loss: 0.2475058\n",
      "\tspeed: 0.0424s/iter; left time: 92.3311s\n",
      "\titers: 600, epoch: 8 | loss: 0.1926418\n",
      "\tspeed: 0.0423s/iter; left time: 88.0733s\n",
      "\titers: 700, epoch: 8 | loss: 0.2304193\n",
      "\tspeed: 0.0423s/iter; left time: 83.7921s\n",
      "\titers: 800, epoch: 8 | loss: 0.2657511\n",
      "\tspeed: 0.0423s/iter; left time: 79.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 893 | Train Loss: 0.2285872 Vali Loss: 0.2974900 Test Loss: 0.3135431\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1835249\n",
      "\tspeed: 0.1505s/iter; left time: 253.8225s\n",
      "\titers: 200, epoch: 9 | loss: 0.2128022\n",
      "\tspeed: 0.0423s/iter; left time: 67.1860s\n",
      "\titers: 300, epoch: 9 | loss: 0.2322543\n",
      "\tspeed: 0.0423s/iter; left time: 62.9407s\n",
      "\titers: 400, epoch: 9 | loss: 0.2192557\n",
      "\tspeed: 0.0424s/iter; left time: 58.7532s\n",
      "\titers: 500, epoch: 9 | loss: 0.2268734\n",
      "\tspeed: 0.0423s/iter; left time: 54.4791s\n",
      "\titers: 600, epoch: 9 | loss: 0.2262852\n",
      "\tspeed: 0.0423s/iter; left time: 50.2410s\n",
      "\titers: 700, epoch: 9 | loss: 0.2455889\n",
      "\tspeed: 0.0423s/iter; left time: 45.9851s\n",
      "\titers: 800, epoch: 9 | loss: 0.2084319\n",
      "\tspeed: 0.0423s/iter; left time: 41.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 893 | Train Loss: 0.2212555 Vali Loss: 0.2979143 Test Loss: 0.3168210\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2377876341342926, rmse:0.4876347482204437, mae:0.3079063892364502, rse:0.47400835156440735\n",
      "Original data scale mse:17101788.0, rmse:4135.4306640625, mae:2451.934326171875, rse:0.20562195777893066\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3492706\n",
      "\tspeed: 0.0441s/iter; left time: 389.5203s\n",
      "\titers: 200, epoch: 1 | loss: 0.3223646\n",
      "\tspeed: 0.0423s/iter; left time: 369.4906s\n",
      "\titers: 300, epoch: 1 | loss: 0.2889603\n",
      "\tspeed: 0.0423s/iter; left time: 365.1428s\n",
      "\titers: 400, epoch: 1 | loss: 0.3188570\n",
      "\tspeed: 0.0423s/iter; left time: 360.7758s\n",
      "\titers: 500, epoch: 1 | loss: 0.2894336\n",
      "\tspeed: 0.0423s/iter; left time: 356.8956s\n",
      "\titers: 600, epoch: 1 | loss: 0.2879969\n",
      "\tspeed: 0.0423s/iter; left time: 352.6754s\n",
      "\titers: 700, epoch: 1 | loss: 0.2803269\n",
      "\tspeed: 0.0423s/iter; left time: 348.3860s\n",
      "\titers: 800, epoch: 1 | loss: 0.3026388\n",
      "\tspeed: 0.0423s/iter; left time: 344.3426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.3160063 Vali Loss: 0.3210048 Test Loss: 0.3320904\n",
      "Validation loss decreased (inf --> 0.321005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2829548\n",
      "\tspeed: 0.1547s/iter; left time: 1227.7542s\n",
      "\titers: 200, epoch: 2 | loss: 0.2896182\n",
      "\tspeed: 0.0426s/iter; left time: 334.2216s\n",
      "\titers: 300, epoch: 2 | loss: 0.3115814\n",
      "\tspeed: 0.0426s/iter; left time: 329.7647s\n",
      "\titers: 400, epoch: 2 | loss: 0.3041964\n",
      "\tspeed: 0.0425s/iter; left time: 324.9654s\n",
      "\titers: 500, epoch: 2 | loss: 0.2696025\n",
      "\tspeed: 0.0425s/iter; left time: 320.4307s\n",
      "\titers: 600, epoch: 2 | loss: 0.2711208\n",
      "\tspeed: 0.0425s/iter; left time: 316.1814s\n",
      "\titers: 700, epoch: 2 | loss: 0.2873453\n",
      "\tspeed: 0.0425s/iter; left time: 312.1943s\n",
      "\titers: 800, epoch: 2 | loss: 0.2799840\n",
      "\tspeed: 0.0425s/iter; left time: 307.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 893 | Train Loss: 0.2978686 Vali Loss: 0.3381143 Test Loss: 0.3496448\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2987165\n",
      "\tspeed: 0.1516s/iter; left time: 1067.9577s\n",
      "\titers: 200, epoch: 3 | loss: 0.2989759\n",
      "\tspeed: 0.0425s/iter; left time: 294.8670s\n",
      "\titers: 300, epoch: 3 | loss: 0.2987199\n",
      "\tspeed: 0.0424s/iter; left time: 290.1841s\n",
      "\titers: 400, epoch: 3 | loss: 0.2439609\n",
      "\tspeed: 0.0424s/iter; left time: 285.7858s\n",
      "\titers: 500, epoch: 3 | loss: 0.2935893\n",
      "\tspeed: 0.0424s/iter; left time: 281.7523s\n",
      "\titers: 600, epoch: 3 | loss: 0.2593340\n",
      "\tspeed: 0.0424s/iter; left time: 277.4921s\n",
      "\titers: 700, epoch: 3 | loss: 0.2762191\n",
      "\tspeed: 0.0424s/iter; left time: 273.0630s\n",
      "\titers: 800, epoch: 3 | loss: 0.2418674\n",
      "\tspeed: 0.0424s/iter; left time: 268.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.2761183 Vali Loss: 0.3319752 Test Loss: 0.3455724\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2644875\n",
      "\tspeed: 0.1527s/iter; left time: 939.1049s\n",
      "\titers: 200, epoch: 4 | loss: 0.2581673\n",
      "\tspeed: 0.0424s/iter; left time: 256.3613s\n",
      "\titers: 300, epoch: 4 | loss: 0.2791232\n",
      "\tspeed: 0.0423s/iter; left time: 252.0342s\n",
      "\titers: 400, epoch: 4 | loss: 0.2887608\n",
      "\tspeed: 0.0423s/iter; left time: 247.7439s\n",
      "\titers: 500, epoch: 4 | loss: 0.3367523\n",
      "\tspeed: 0.0423s/iter; left time: 243.5163s\n",
      "\titers: 600, epoch: 4 | loss: 0.2712596\n",
      "\tspeed: 0.0423s/iter; left time: 239.3620s\n",
      "\titers: 700, epoch: 4 | loss: 0.2736810\n",
      "\tspeed: 0.0424s/iter; left time: 235.2783s\n",
      "\titers: 800, epoch: 4 | loss: 0.2366427\n",
      "\tspeed: 0.0424s/iter; left time: 231.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2635901 Vali Loss: 0.2953023 Test Loss: 0.3092164\n",
      "Validation loss decreased (0.321005 --> 0.295302).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2878520\n",
      "\tspeed: 0.1544s/iter; left time: 812.0742s\n",
      "\titers: 200, epoch: 5 | loss: 0.2102588\n",
      "\tspeed: 0.0423s/iter; left time: 218.4423s\n",
      "\titers: 300, epoch: 5 | loss: 0.2345979\n",
      "\tspeed: 0.0424s/iter; left time: 214.5795s\n",
      "\titers: 400, epoch: 5 | loss: 0.2620084\n",
      "\tspeed: 0.0424s/iter; left time: 210.2182s\n",
      "\titers: 500, epoch: 5 | loss: 0.2468795\n",
      "\tspeed: 0.0424s/iter; left time: 205.9627s\n",
      "\titers: 600, epoch: 5 | loss: 0.2531159\n",
      "\tspeed: 0.0424s/iter; left time: 201.6793s\n",
      "\titers: 700, epoch: 5 | loss: 0.2624674\n",
      "\tspeed: 0.0424s/iter; left time: 197.4906s\n",
      "\titers: 800, epoch: 5 | loss: 0.2523279\n",
      "\tspeed: 0.0424s/iter; left time: 193.3633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2496463 Vali Loss: 0.2956663 Test Loss: 0.3079102\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2645135\n",
      "\tspeed: 0.1516s/iter; left time: 661.8346s\n",
      "\titers: 200, epoch: 6 | loss: 0.2888856\n",
      "\tspeed: 0.0424s/iter; left time: 180.8638s\n",
      "\titers: 300, epoch: 6 | loss: 0.2524284\n",
      "\tspeed: 0.0424s/iter; left time: 176.5309s\n",
      "\titers: 400, epoch: 6 | loss: 0.2396919\n",
      "\tspeed: 0.0424s/iter; left time: 172.2338s\n",
      "\titers: 500, epoch: 6 | loss: 0.2145966\n",
      "\tspeed: 0.0423s/iter; left time: 167.9257s\n",
      "\titers: 600, epoch: 6 | loss: 0.2417455\n",
      "\tspeed: 0.0423s/iter; left time: 163.6817s\n",
      "\titers: 700, epoch: 6 | loss: 0.2306209\n",
      "\tspeed: 0.0424s/iter; left time: 159.7886s\n",
      "\titers: 800, epoch: 6 | loss: 0.2561377\n",
      "\tspeed: 0.0424s/iter; left time: 155.2935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.2426151 Vali Loss: 0.2960870 Test Loss: 0.3072562\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2144406\n",
      "\tspeed: 0.1508s/iter; left time: 523.6642s\n",
      "\titers: 200, epoch: 7 | loss: 0.2333319\n",
      "\tspeed: 0.0423s/iter; left time: 142.8095s\n",
      "\titers: 300, epoch: 7 | loss: 0.1970526\n",
      "\tspeed: 0.0423s/iter; left time: 138.5929s\n",
      "\titers: 400, epoch: 7 | loss: 0.3026087\n",
      "\tspeed: 0.0424s/iter; left time: 134.4080s\n",
      "\titers: 500, epoch: 7 | loss: 0.2297455\n",
      "\tspeed: 0.0424s/iter; left time: 130.2529s\n",
      "\titers: 600, epoch: 7 | loss: 0.2446831\n",
      "\tspeed: 0.0424s/iter; left time: 125.9492s\n",
      "\titers: 700, epoch: 7 | loss: 0.2462345\n",
      "\tspeed: 0.0424s/iter; left time: 121.6947s\n",
      "\titers: 800, epoch: 7 | loss: 0.2369884\n",
      "\tspeed: 0.0424s/iter; left time: 117.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.2370268 Vali Loss: 0.2942532 Test Loss: 0.3022617\n",
      "Validation loss decreased (0.295302 --> 0.294253).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2856607\n",
      "\tspeed: 0.1538s/iter; left time: 396.7044s\n",
      "\titers: 200, epoch: 8 | loss: 0.2385260\n",
      "\tspeed: 0.0426s/iter; left time: 105.5903s\n",
      "\titers: 300, epoch: 8 | loss: 0.2134833\n",
      "\tspeed: 0.0426s/iter; left time: 101.3815s\n",
      "\titers: 400, epoch: 8 | loss: 0.2082520\n",
      "\tspeed: 0.0424s/iter; left time: 96.6366s\n",
      "\titers: 500, epoch: 8 | loss: 0.1990080\n",
      "\tspeed: 0.0424s/iter; left time: 92.4528s\n",
      "\titers: 600, epoch: 8 | loss: 0.2227144\n",
      "\tspeed: 0.0424s/iter; left time: 88.2767s\n",
      "\titers: 700, epoch: 8 | loss: 0.2333554\n",
      "\tspeed: 0.0424s/iter; left time: 83.9102s\n",
      "\titers: 800, epoch: 8 | loss: 0.2240583\n",
      "\tspeed: 0.0422s/iter; left time: 79.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.2323620 Vali Loss: 0.2965825 Test Loss: 0.3090989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2148220\n",
      "\tspeed: 0.1533s/iter; left time: 258.6684s\n",
      "\titers: 200, epoch: 9 | loss: 0.2325328\n",
      "\tspeed: 0.0425s/iter; left time: 67.4742s\n",
      "\titers: 300, epoch: 9 | loss: 0.2081405\n",
      "\tspeed: 0.0425s/iter; left time: 63.2401s\n",
      "\titers: 400, epoch: 9 | loss: 0.2322678\n",
      "\tspeed: 0.0425s/iter; left time: 59.0138s\n",
      "\titers: 500, epoch: 9 | loss: 0.2300684\n",
      "\tspeed: 0.0425s/iter; left time: 54.7037s\n",
      "\titers: 600, epoch: 9 | loss: 0.2085957\n",
      "\tspeed: 0.0425s/iter; left time: 50.4728s\n",
      "\titers: 700, epoch: 9 | loss: 0.2004253\n",
      "\tspeed: 0.0425s/iter; left time: 46.1802s\n",
      "\titers: 800, epoch: 9 | loss: 0.2524276\n",
      "\tspeed: 0.0425s/iter; left time: 41.9405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 893 | Train Loss: 0.2249389 Vali Loss: 0.2973551 Test Loss: 0.3165964\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2028467\n",
      "\tspeed: 0.1523s/iter; left time: 120.9030s\n",
      "\titers: 200, epoch: 10 | loss: 0.2189615\n",
      "\tspeed: 0.0425s/iter; left time: 29.4652s\n",
      "\titers: 300, epoch: 10 | loss: 0.2061844\n",
      "\tspeed: 0.0424s/iter; left time: 25.1700s\n",
      "\titers: 400, epoch: 10 | loss: 0.2266684\n",
      "\tspeed: 0.0424s/iter; left time: 20.9451s\n",
      "\titers: 500, epoch: 10 | loss: 0.2374375\n",
      "\tspeed: 0.0424s/iter; left time: 16.7075s\n",
      "\titers: 600, epoch: 10 | loss: 0.2025374\n",
      "\tspeed: 0.0424s/iter; left time: 12.4613s\n",
      "\titers: 700, epoch: 10 | loss: 0.2168925\n",
      "\tspeed: 0.0423s/iter; left time: 8.2123s\n",
      "\titers: 800, epoch: 10 | loss: 0.2289431\n",
      "\tspeed: 0.0423s/iter; left time: 3.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.2178133 Vali Loss: 0.2988171 Test Loss: 0.3171611\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23179012537002563, rmse:0.48144587874412537, mae:0.3022615611553192, rse:0.4679924249649048\n",
      "Original data scale mse:16840840.0, rmse:4103.75927734375, mae:2404.939697265625, rse:0.20404717326164246\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4684884\n",
      "\tspeed: 0.0704s/iter; left time: 620.1388s\n",
      "\titers: 200, epoch: 1 | loss: 0.3876328\n",
      "\tspeed: 0.0427s/iter; left time: 371.9052s\n",
      "\titers: 300, epoch: 1 | loss: 0.4045758\n",
      "\tspeed: 0.0427s/iter; left time: 367.7011s\n",
      "\titers: 400, epoch: 1 | loss: 0.3567076\n",
      "\tspeed: 0.0427s/iter; left time: 363.5386s\n",
      "\titers: 500, epoch: 1 | loss: 0.3886242\n",
      "\tspeed: 0.0428s/iter; left time: 359.6369s\n",
      "\titers: 600, epoch: 1 | loss: 0.3619347\n",
      "\tspeed: 0.0427s/iter; left time: 355.0105s\n",
      "\titers: 700, epoch: 1 | loss: 0.3875395\n",
      "\tspeed: 0.0427s/iter; left time: 350.8063s\n",
      "\titers: 800, epoch: 1 | loss: 0.4044845\n",
      "\tspeed: 0.0427s/iter; left time: 346.5733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.3969716 Vali Loss: 0.4126247 Test Loss: 0.4411414\n",
      "Validation loss decreased (inf --> 0.412625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3930952\n",
      "\tspeed: 0.1537s/iter; left time: 1217.6215s\n",
      "\titers: 200, epoch: 2 | loss: 0.3762832\n",
      "\tspeed: 0.0427s/iter; left time: 333.9568s\n",
      "\titers: 300, epoch: 2 | loss: 0.3693455\n",
      "\tspeed: 0.0427s/iter; left time: 329.6515s\n",
      "\titers: 400, epoch: 2 | loss: 0.4095068\n",
      "\tspeed: 0.0427s/iter; left time: 325.5429s\n",
      "\titers: 500, epoch: 2 | loss: 0.3498340\n",
      "\tspeed: 0.0427s/iter; left time: 321.2291s\n",
      "\titers: 600, epoch: 2 | loss: 0.3334362\n",
      "\tspeed: 0.0427s/iter; left time: 316.8363s\n",
      "\titers: 700, epoch: 2 | loss: 0.3262864\n",
      "\tspeed: 0.0427s/iter; left time: 312.4941s\n",
      "\titers: 800, epoch: 2 | loss: 0.3890919\n",
      "\tspeed: 0.0427s/iter; left time: 308.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.3827000 Vali Loss: 0.4105951 Test Loss: 0.4732466\n",
      "Validation loss decreased (0.412625 --> 0.410595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3412500\n",
      "\tspeed: 0.1530s/iter; left time: 1075.6923s\n",
      "\titers: 200, epoch: 3 | loss: 0.3567889\n",
      "\tspeed: 0.0427s/iter; left time: 296.2061s\n",
      "\titers: 300, epoch: 3 | loss: 0.3673129\n",
      "\tspeed: 0.0427s/iter; left time: 291.8884s\n",
      "\titers: 400, epoch: 3 | loss: 0.3337844\n",
      "\tspeed: 0.0427s/iter; left time: 287.5245s\n",
      "\titers: 500, epoch: 3 | loss: 0.3484310\n",
      "\tspeed: 0.0427s/iter; left time: 283.2105s\n",
      "\titers: 600, epoch: 3 | loss: 0.3459015\n",
      "\tspeed: 0.0427s/iter; left time: 279.0733s\n",
      "\titers: 700, epoch: 3 | loss: 0.3497356\n",
      "\tspeed: 0.0427s/iter; left time: 274.7621s\n",
      "\titers: 800, epoch: 3 | loss: 0.3012187\n",
      "\tspeed: 0.0428s/iter; left time: 270.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.3451515 Vali Loss: 0.4153292 Test Loss: 0.4852614\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3396926\n",
      "\tspeed: 0.1509s/iter; left time: 926.4915s\n",
      "\titers: 200, epoch: 4 | loss: 0.3588603\n",
      "\tspeed: 0.0427s/iter; left time: 258.0120s\n",
      "\titers: 300, epoch: 4 | loss: 0.3529438\n",
      "\tspeed: 0.0427s/iter; left time: 253.7474s\n",
      "\titers: 400, epoch: 4 | loss: 0.3635230\n",
      "\tspeed: 0.0427s/iter; left time: 249.4269s\n",
      "\titers: 500, epoch: 4 | loss: 0.3119981\n",
      "\tspeed: 0.0427s/iter; left time: 245.1838s\n",
      "\titers: 600, epoch: 4 | loss: 0.3348911\n",
      "\tspeed: 0.0427s/iter; left time: 240.8692s\n",
      "\titers: 700, epoch: 4 | loss: 0.3236400\n",
      "\tspeed: 0.0427s/iter; left time: 236.6809s\n",
      "\titers: 800, epoch: 4 | loss: 0.2864905\n",
      "\tspeed: 0.0427s/iter; left time: 232.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.3211430 Vali Loss: 0.4266058 Test Loss: 0.5030828\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2955221\n",
      "\tspeed: 0.1506s/iter; left time: 790.0143s\n",
      "\titers: 200, epoch: 5 | loss: 0.2874321\n",
      "\tspeed: 0.0429s/iter; left time: 220.9262s\n",
      "\titers: 300, epoch: 5 | loss: 0.3218697\n",
      "\tspeed: 0.0429s/iter; left time: 216.3066s\n",
      "\titers: 400, epoch: 5 | loss: 0.2892837\n",
      "\tspeed: 0.0428s/iter; left time: 211.8519s\n",
      "\titers: 500, epoch: 5 | loss: 0.2901415\n",
      "\tspeed: 0.0428s/iter; left time: 207.5334s\n",
      "\titers: 600, epoch: 5 | loss: 0.2946918\n",
      "\tspeed: 0.0428s/iter; left time: 203.2781s\n",
      "\titers: 700, epoch: 5 | loss: 0.2595286\n",
      "\tspeed: 0.0428s/iter; left time: 198.9766s\n",
      "\titers: 800, epoch: 5 | loss: 0.2591929\n",
      "\tspeed: 0.0427s/iter; left time: 194.3041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.2920518 Vali Loss: 0.4303524 Test Loss: 0.5138320\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.5228630304336548, rmse:0.7230926752090454, mae:0.47324660420417786, rse:0.7032999992370605\n",
      "Original data scale mse:37380588.0, rmse:6113.966796875, mae:3756.436767578125, rse:0.304477721452713\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4066630\n",
      "\tspeed: 0.0445s/iter; left time: 392.5133s\n",
      "\titers: 200, epoch: 1 | loss: 0.3719214\n",
      "\tspeed: 0.0427s/iter; left time: 371.8552s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187882\n",
      "\tspeed: 0.0427s/iter; left time: 367.6375s\n",
      "\titers: 400, epoch: 1 | loss: 0.4305293\n",
      "\tspeed: 0.0427s/iter; left time: 363.6047s\n",
      "\titers: 500, epoch: 1 | loss: 0.3620389\n",
      "\tspeed: 0.0427s/iter; left time: 359.1316s\n",
      "\titers: 600, epoch: 1 | loss: 0.4129305\n",
      "\tspeed: 0.0427s/iter; left time: 355.1640s\n",
      "\titers: 700, epoch: 1 | loss: 0.3711313\n",
      "\tspeed: 0.0427s/iter; left time: 350.8624s\n",
      "\titers: 800, epoch: 1 | loss: 0.3716925\n",
      "\tspeed: 0.0427s/iter; left time: 346.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.3972458 Vali Loss: 0.4115500 Test Loss: 0.4406545\n",
      "Validation loss decreased (inf --> 0.411550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4028302\n",
      "\tspeed: 0.1533s/iter; left time: 1214.2669s\n",
      "\titers: 200, epoch: 2 | loss: 0.3742743\n",
      "\tspeed: 0.0427s/iter; left time: 333.7863s\n",
      "\titers: 300, epoch: 2 | loss: 0.3932038\n",
      "\tspeed: 0.0427s/iter; left time: 329.5074s\n",
      "\titers: 400, epoch: 2 | loss: 0.3760182\n",
      "\tspeed: 0.0427s/iter; left time: 325.1327s\n",
      "\titers: 500, epoch: 2 | loss: 0.3723770\n",
      "\tspeed: 0.0427s/iter; left time: 321.0985s\n",
      "\titers: 600, epoch: 2 | loss: 0.3611200\n",
      "\tspeed: 0.0427s/iter; left time: 316.6957s\n",
      "\titers: 700, epoch: 2 | loss: 0.4004166\n",
      "\tspeed: 0.0427s/iter; left time: 312.3201s\n",
      "\titers: 800, epoch: 2 | loss: 0.3619330\n",
      "\tspeed: 0.0427s/iter; left time: 308.0910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.3844349 Vali Loss: 0.4448619 Test Loss: 0.4925394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3688284\n",
      "\tspeed: 0.1503s/iter; left time: 1056.3377s\n",
      "\titers: 200, epoch: 3 | loss: 0.3374178\n",
      "\tspeed: 0.0427s/iter; left time: 295.8017s\n",
      "\titers: 300, epoch: 3 | loss: 0.3261121\n",
      "\tspeed: 0.0427s/iter; left time: 291.5532s\n",
      "\titers: 400, epoch: 3 | loss: 0.3530890\n",
      "\tspeed: 0.0427s/iter; left time: 287.3141s\n",
      "\titers: 500, epoch: 3 | loss: 0.3203424\n",
      "\tspeed: 0.0427s/iter; left time: 283.2038s\n",
      "\titers: 600, epoch: 3 | loss: 0.3498648\n",
      "\tspeed: 0.0427s/iter; left time: 278.8635s\n",
      "\titers: 700, epoch: 3 | loss: 0.3799568\n",
      "\tspeed: 0.0427s/iter; left time: 274.5547s\n",
      "\titers: 800, epoch: 3 | loss: 0.3457251\n",
      "\tspeed: 0.0427s/iter; left time: 270.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.3539214 Vali Loss: 0.4222977 Test Loss: 0.4667308\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3712475\n",
      "\tspeed: 0.1524s/iter; left time: 935.4222s\n",
      "\titers: 200, epoch: 4 | loss: 0.3155898\n",
      "\tspeed: 0.0427s/iter; left time: 257.9800s\n",
      "\titers: 300, epoch: 4 | loss: 0.3220321\n",
      "\tspeed: 0.0426s/iter; left time: 253.2353s\n",
      "\titers: 400, epoch: 4 | loss: 0.3338384\n",
      "\tspeed: 0.0427s/iter; left time: 249.0726s\n",
      "\titers: 500, epoch: 4 | loss: 0.2876443\n",
      "\tspeed: 0.0427s/iter; left time: 245.1514s\n",
      "\titers: 600, epoch: 4 | loss: 0.3284000\n",
      "\tspeed: 0.0427s/iter; left time: 240.6321s\n",
      "\titers: 700, epoch: 4 | loss: 0.3487631\n",
      "\tspeed: 0.0427s/iter; left time: 236.4535s\n",
      "\titers: 800, epoch: 4 | loss: 0.3167527\n",
      "\tspeed: 0.0427s/iter; left time: 232.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.3331307 Vali Loss: 0.4358769 Test Loss: 0.4705009\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4096048176288605, rmse:0.6400037407875061, mae:0.44065436720848083, rse:0.6224853992462158\n",
      "Original data scale mse:32031288.0, rmse:5659.619140625, mae:3615.173583984375, rse:0.28185105323791504\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4762464\n",
      "\tspeed: 0.0698s/iter; left time: 613.1802s\n",
      "\titers: 200, epoch: 1 | loss: 0.4044638\n",
      "\tspeed: 0.0432s/iter; left time: 375.7523s\n",
      "\titers: 300, epoch: 1 | loss: 0.4141133\n",
      "\tspeed: 0.0432s/iter; left time: 371.4893s\n",
      "\titers: 400, epoch: 1 | loss: 0.4548874\n",
      "\tspeed: 0.0433s/iter; left time: 367.2673s\n",
      "\titers: 500, epoch: 1 | loss: 0.4367705\n",
      "\tspeed: 0.0433s/iter; left time: 363.7355s\n",
      "\titers: 600, epoch: 1 | loss: 0.4084821\n",
      "\tspeed: 0.0432s/iter; left time: 358.3047s\n",
      "\titers: 700, epoch: 1 | loss: 0.3975303\n",
      "\tspeed: 0.0432s/iter; left time: 353.7288s\n",
      "\titers: 800, epoch: 1 | loss: 0.3965552\n",
      "\tspeed: 0.0432s/iter; left time: 349.6155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.88s\n",
      "Steps: 889 | Train Loss: 0.4141807 Vali Loss: 0.4243684 Test Loss: 0.4601092\n",
      "Validation loss decreased (inf --> 0.424368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4300737\n",
      "\tspeed: 0.1577s/iter; left time: 1246.2801s\n",
      "\titers: 200, epoch: 2 | loss: 0.3933316\n",
      "\tspeed: 0.0432s/iter; left time: 337.3625s\n",
      "\titers: 300, epoch: 2 | loss: 0.4373253\n",
      "\tspeed: 0.0432s/iter; left time: 332.6225s\n",
      "\titers: 400, epoch: 2 | loss: 0.4031954\n",
      "\tspeed: 0.0432s/iter; left time: 328.4360s\n",
      "\titers: 500, epoch: 2 | loss: 0.3785727\n",
      "\tspeed: 0.0432s/iter; left time: 324.3987s\n",
      "\titers: 600, epoch: 2 | loss: 0.3911959\n",
      "\tspeed: 0.0432s/iter; left time: 319.7632s\n",
      "\titers: 700, epoch: 2 | loss: 0.3645288\n",
      "\tspeed: 0.0432s/iter; left time: 315.2958s\n",
      "\titers: 800, epoch: 2 | loss: 0.3864062\n",
      "\tspeed: 0.0432s/iter; left time: 311.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.3935670 Vali Loss: 0.4280627 Test Loss: 0.5137021\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3668686\n",
      "\tspeed: 0.1517s/iter; left time: 1063.9828s\n",
      "\titers: 200, epoch: 3 | loss: 0.3259976\n",
      "\tspeed: 0.0432s/iter; left time: 298.9398s\n",
      "\titers: 300, epoch: 3 | loss: 0.3444952\n",
      "\tspeed: 0.0432s/iter; left time: 294.5388s\n",
      "\titers: 400, epoch: 3 | loss: 0.3990349\n",
      "\tspeed: 0.0432s/iter; left time: 290.2631s\n",
      "\titers: 500, epoch: 3 | loss: 0.3777921\n",
      "\tspeed: 0.0432s/iter; left time: 285.8708s\n",
      "\titers: 600, epoch: 3 | loss: 0.3382579\n",
      "\tspeed: 0.0432s/iter; left time: 281.3408s\n",
      "\titers: 700, epoch: 3 | loss: 0.3370208\n",
      "\tspeed: 0.0432s/iter; left time: 277.3431s\n",
      "\titers: 800, epoch: 3 | loss: 0.3277113\n",
      "\tspeed: 0.0433s/iter; left time: 273.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3484925 Vali Loss: 0.4450209 Test Loss: 0.5042545\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3274429\n",
      "\tspeed: 0.1513s/iter; left time: 926.2675s\n",
      "\titers: 200, epoch: 4 | loss: 0.2927153\n",
      "\tspeed: 0.0432s/iter; left time: 260.0865s\n",
      "\titers: 300, epoch: 4 | loss: 0.3465253\n",
      "\tspeed: 0.0432s/iter; left time: 255.7508s\n",
      "\titers: 400, epoch: 4 | loss: 0.2953821\n",
      "\tspeed: 0.0432s/iter; left time: 251.4553s\n",
      "\titers: 500, epoch: 4 | loss: 0.3188933\n",
      "\tspeed: 0.0432s/iter; left time: 247.5413s\n",
      "\titers: 600, epoch: 4 | loss: 0.2916814\n",
      "\tspeed: 0.0432s/iter; left time: 242.8962s\n",
      "\titers: 700, epoch: 4 | loss: 0.3051240\n",
      "\tspeed: 0.0432s/iter; left time: 238.6241s\n",
      "\titers: 800, epoch: 4 | loss: 0.3008286\n",
      "\tspeed: 0.0432s/iter; left time: 234.3801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 889 | Train Loss: 0.3087744 Vali Loss: 0.4448800 Test Loss: 0.5246037\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.43595191836357117, rmse:0.6602665781974792, mae:0.460109144449234, rse:0.6402274370193481\n",
      "Original data scale mse:34436244.0, rmse:5868.240234375, mae:3779.667236328125, rse:0.29238390922546387\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4119244\n",
      "\tspeed: 0.0452s/iter; left time: 397.1317s\n",
      "\titers: 200, epoch: 1 | loss: 0.4654200\n",
      "\tspeed: 0.0432s/iter; left time: 375.3839s\n",
      "\titers: 300, epoch: 1 | loss: 0.4333512\n",
      "\tspeed: 0.0432s/iter; left time: 370.7699s\n",
      "\titers: 400, epoch: 1 | loss: 0.4041139\n",
      "\tspeed: 0.0432s/iter; left time: 366.6090s\n",
      "\titers: 500, epoch: 1 | loss: 0.3992240\n",
      "\tspeed: 0.0432s/iter; left time: 362.7811s\n",
      "\titers: 600, epoch: 1 | loss: 0.4176375\n",
      "\tspeed: 0.0432s/iter; left time: 358.2323s\n",
      "\titers: 700, epoch: 1 | loss: 0.3749172\n",
      "\tspeed: 0.0432s/iter; left time: 353.6500s\n",
      "\titers: 800, epoch: 1 | loss: 0.3851109\n",
      "\tspeed: 0.0432s/iter; left time: 349.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.4149217 Vali Loss: 0.4246492 Test Loss: 0.4598440\n",
      "Validation loss decreased (inf --> 0.424649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4789046\n",
      "\tspeed: 0.1550s/iter; left time: 1225.1736s\n",
      "\titers: 200, epoch: 2 | loss: 0.4431178\n",
      "\tspeed: 0.0432s/iter; left time: 336.7023s\n",
      "\titers: 300, epoch: 2 | loss: 0.4717377\n",
      "\tspeed: 0.0432s/iter; left time: 332.3623s\n",
      "\titers: 400, epoch: 2 | loss: 0.4151293\n",
      "\tspeed: 0.0432s/iter; left time: 328.2372s\n",
      "\titers: 500, epoch: 2 | loss: 0.3897159\n",
      "\tspeed: 0.0432s/iter; left time: 323.9363s\n",
      "\titers: 600, epoch: 2 | loss: 0.3489036\n",
      "\tspeed: 0.0432s/iter; left time: 319.5512s\n",
      "\titers: 700, epoch: 2 | loss: 0.3845072\n",
      "\tspeed: 0.0432s/iter; left time: 315.5498s\n",
      "\titers: 800, epoch: 2 | loss: 0.3695348\n",
      "\tspeed: 0.0432s/iter; left time: 311.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.4010219 Vali Loss: 0.4262091 Test Loss: 0.4661326\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3860887\n",
      "\tspeed: 0.1515s/iter; left time: 1062.6268s\n",
      "\titers: 200, epoch: 3 | loss: 0.3692849\n",
      "\tspeed: 0.0431s/iter; left time: 298.1589s\n",
      "\titers: 300, epoch: 3 | loss: 0.3794353\n",
      "\tspeed: 0.0432s/iter; left time: 294.1893s\n",
      "\titers: 400, epoch: 3 | loss: 0.3844395\n",
      "\tspeed: 0.0432s/iter; left time: 289.8401s\n",
      "\titers: 500, epoch: 3 | loss: 0.3778097\n",
      "\tspeed: 0.0433s/iter; left time: 286.0733s\n",
      "\titers: 600, epoch: 3 | loss: 0.3696763\n",
      "\tspeed: 0.0432s/iter; left time: 281.5654s\n",
      "\titers: 700, epoch: 3 | loss: 0.3511351\n",
      "\tspeed: 0.0432s/iter; left time: 277.1471s\n",
      "\titers: 800, epoch: 3 | loss: 0.3305629\n",
      "\tspeed: 0.0432s/iter; left time: 272.8776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.3650697 Vali Loss: 0.4287660 Test Loss: 0.4760078\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3313957\n",
      "\tspeed: 0.1522s/iter; left time: 931.7679s\n",
      "\titers: 200, epoch: 4 | loss: 0.3167084\n",
      "\tspeed: 0.0432s/iter; left time: 260.0871s\n",
      "\titers: 300, epoch: 4 | loss: 0.3513306\n",
      "\tspeed: 0.0432s/iter; left time: 255.8811s\n",
      "\titers: 400, epoch: 4 | loss: 0.3763891\n",
      "\tspeed: 0.0432s/iter; left time: 251.4039s\n",
      "\titers: 500, epoch: 4 | loss: 0.3395450\n",
      "\tspeed: 0.0432s/iter; left time: 247.1329s\n",
      "\titers: 600, epoch: 4 | loss: 0.3299132\n",
      "\tspeed: 0.0433s/iter; left time: 243.3341s\n",
      "\titers: 700, epoch: 4 | loss: 0.3232048\n",
      "\tspeed: 0.0432s/iter; left time: 238.6018s\n",
      "\titers: 800, epoch: 4 | loss: 0.3140013\n",
      "\tspeed: 0.0433s/iter; left time: 234.6607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3307437 Vali Loss: 0.4614118 Test Loss: 0.5043946\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.43597641587257385, rmse:0.6602851152420044, mae:0.4598439037799835, rse:0.6402454376220703\n",
      "Original data scale mse:34408188.0, rmse:5865.84912109375, mae:3774.69189453125, rse:0.29226478934288025\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type robust \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.4703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.6195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.6326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.6358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.4774</td>\n",
       "      <td>0.6439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.4794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.4736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.6327</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>0.6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.6381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.4764</td>\n",
       "      <td>0.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.4740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>0.6225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.6402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>0.6402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2438  0.4937  0.3271  0.4799\n",
       "              2         24        0.2341  0.4838  0.3247  0.4703\n",
       "              1         96        0.4056  0.6369  0.4533  0.6195\n",
       "              2         96        0.4231  0.6505  0.4594  0.6326\n",
       "              1         168       0.4300  0.6557  0.4732  0.6358\n",
       "              2         168       0.4409  0.6640  0.4774  0.6439\n",
       "RMSE          1         24        0.2432  0.4932  0.3286  0.4794\n",
       "              2         24        0.2373  0.4872  0.3286  0.4736\n",
       "              1         96        0.4037  0.6353  0.4569  0.6180\n",
       "              2         96        0.4003  0.6327  0.4519  0.6153\n",
       "              1         168       0.4331  0.6581  0.4750  0.6381\n",
       "              2         168       0.4349  0.6595  0.4764  0.6395\n",
       "MAE           1         24        0.2378  0.4876  0.3079  0.4740\n",
       "              2         24        0.2318  0.4814  0.3023  0.4680\n",
       "              1         96        0.5229  0.7231  0.4732  0.7033\n",
       "              2         96        0.4096  0.6400  0.4407  0.6225\n",
       "              1         168       0.4360  0.6603  0.4601  0.6402\n",
       "              2         168       0.4360  0.6603  0.4598  0.6402"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_robust.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_robust.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18229302.0</td>\n",
       "      <td>4269.5786</td>\n",
       "      <td>2643.6431</td>\n",
       "      <td>0.2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17448062.0</td>\n",
       "      <td>4177.0879</td>\n",
       "      <td>2625.8184</td>\n",
       "      <td>0.2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31905132.0</td>\n",
       "      <td>5648.4629</td>\n",
       "      <td>3713.9365</td>\n",
       "      <td>0.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34005252.0</td>\n",
       "      <td>5831.4023</td>\n",
       "      <td>3790.4197</td>\n",
       "      <td>0.2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34134564.0</td>\n",
       "      <td>5842.4795</td>\n",
       "      <td>3888.2668</td>\n",
       "      <td>0.2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35157356.0</td>\n",
       "      <td>5929.3638</td>\n",
       "      <td>3919.8013</td>\n",
       "      <td>0.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18199538.0</td>\n",
       "      <td>4266.0918</td>\n",
       "      <td>2667.8621</td>\n",
       "      <td>0.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17552708.0</td>\n",
       "      <td>4189.5952</td>\n",
       "      <td>2641.2788</td>\n",
       "      <td>0.2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32573556.0</td>\n",
       "      <td>5707.3247</td>\n",
       "      <td>3834.9167</td>\n",
       "      <td>0.2842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32110734.0</td>\n",
       "      <td>5666.6333</td>\n",
       "      <td>3774.5425</td>\n",
       "      <td>0.2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35332576.0</td>\n",
       "      <td>5944.1211</td>\n",
       "      <td>3983.2620</td>\n",
       "      <td>0.2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35436588.0</td>\n",
       "      <td>5952.8638</td>\n",
       "      <td>3990.8035</td>\n",
       "      <td>0.2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17101788.0</td>\n",
       "      <td>4135.4307</td>\n",
       "      <td>2451.9343</td>\n",
       "      <td>0.2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16840840.0</td>\n",
       "      <td>4103.7593</td>\n",
       "      <td>2404.9397</td>\n",
       "      <td>0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37380588.0</td>\n",
       "      <td>6113.9668</td>\n",
       "      <td>3756.4368</td>\n",
       "      <td>0.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32031288.0</td>\n",
       "      <td>5659.6191</td>\n",
       "      <td>3615.1736</td>\n",
       "      <td>0.2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34436244.0</td>\n",
       "      <td>5868.2402</td>\n",
       "      <td>3779.6672</td>\n",
       "      <td>0.2924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34408188.0</td>\n",
       "      <td>5865.8491</td>\n",
       "      <td>3774.6919</td>\n",
       "      <td>0.2923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18229302.0  4269.5786  2643.6431  0.2123\n",
       "              2         24        17448062.0  4177.0879  2625.8184  0.2077\n",
       "              1         96        31905132.0  5648.4629  3713.9365  0.2813\n",
       "              2         96        34005252.0  5831.4023  3790.4197  0.2904\n",
       "              1         168       34134564.0  5842.4795  3888.2668  0.2911\n",
       "              2         168       35157356.0  5929.3638  3919.8013  0.2954\n",
       "RMSE          1         24        18199538.0  4266.0918  2667.8621  0.2121\n",
       "              2         24        17552708.0  4189.5952  2641.2788  0.2083\n",
       "              1         96        32573556.0  5707.3247  3834.9167  0.2842\n",
       "              2         96        32110734.0  5666.6333  3774.5425  0.2822\n",
       "              1         168       35332576.0  5944.1211  3983.2620  0.2962\n",
       "              2         168       35436588.0  5952.8638  3990.8035  0.2966\n",
       "MAE           1         24        17101788.0  4135.4307  2451.9343  0.2056\n",
       "              2         24        16840840.0  4103.7593  2404.9397  0.2040\n",
       "              1         96        37380588.0  6113.9668  3756.4368  0.3045\n",
       "              2         96        32031288.0  5659.6191  3615.1736  0.2819\n",
       "              1         168       34436244.0  5868.2402  3779.6672  0.2924\n",
       "              2         168       34408188.0  5865.8491  3774.6919  0.2923"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>0.4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.6629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.6261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.6402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.6388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2348  0.4845  0.3051  0.4710\n",
       "         MSE            0.2389  0.4888  0.3259  0.4751\n",
       "         RMSE           0.2403  0.4902  0.3286  0.4765\n",
       "96       MAE            0.4662  0.6815  0.4570  0.6629\n",
       "         MSE            0.4144  0.6437  0.4564  0.6261\n",
       "         RMSE           0.4020  0.6340  0.4544  0.6167\n",
       "168      MAE            0.4360  0.6603  0.4600  0.6402\n",
       "         MSE            0.4355  0.6599  0.4753  0.6399\n",
       "         RMSE           0.4340  0.6588  0.4757  0.6388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16971314.0</td>\n",
       "      <td>4119.5950</td>\n",
       "      <td>2428.4370</td>\n",
       "      <td>0.2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17838682.0</td>\n",
       "      <td>4223.3333</td>\n",
       "      <td>2634.7307</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17876123.0</td>\n",
       "      <td>4227.8435</td>\n",
       "      <td>2654.5704</td>\n",
       "      <td>0.2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34705938.0</td>\n",
       "      <td>5886.7930</td>\n",
       "      <td>3685.8052</td>\n",
       "      <td>0.2932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>32955192.0</td>\n",
       "      <td>5739.9326</td>\n",
       "      <td>3752.1781</td>\n",
       "      <td>0.2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32342145.0</td>\n",
       "      <td>5686.9790</td>\n",
       "      <td>3804.7296</td>\n",
       "      <td>0.2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34422216.0</td>\n",
       "      <td>5867.0447</td>\n",
       "      <td>3777.1796</td>\n",
       "      <td>0.2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34645960.0</td>\n",
       "      <td>5885.9216</td>\n",
       "      <td>3904.0341</td>\n",
       "      <td>0.2933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35384582.0</td>\n",
       "      <td>5948.4924</td>\n",
       "      <td>3987.0327</td>\n",
       "      <td>0.2964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16971314.0  4119.5950  2428.4370  0.2048\n",
       "         MSE            17838682.0  4223.3333  2634.7307  0.2100\n",
       "         RMSE           17876123.0  4227.8435  2654.5704  0.2102\n",
       "96       MAE            34705938.0  5886.7930  3685.8052  0.2932\n",
       "         MSE            32955192.0  5739.9326  3752.1781  0.2859\n",
       "         RMSE           32342145.0  5686.9790  3804.7296  0.2832\n",
       "168      MAE            34422216.0  5867.0447  3777.1796  0.2923\n",
       "         MSE            34645960.0  5885.9216  3904.0341  0.2933\n",
       "         RMSE           35384582.0  5948.4924  3987.0327  0.2964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'robust_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Robust Scaler Informer IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/robust\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4625300\n",
      "\tspeed: 0.0721s/iter; left time: 646.2302s\n",
      "\titers: 200, epoch: 1 | loss: 0.3509545\n",
      "\tspeed: 0.0426s/iter; left time: 377.5256s\n",
      "\titers: 300, epoch: 1 | loss: 0.2405195\n",
      "\tspeed: 0.0422s/iter; left time: 369.8717s\n",
      "\titers: 400, epoch: 1 | loss: 0.2214437\n",
      "\tspeed: 0.0417s/iter; left time: 361.3671s\n",
      "\titers: 500, epoch: 1 | loss: 0.1680605\n",
      "\tspeed: 0.0416s/iter; left time: 356.0111s\n",
      "\titers: 600, epoch: 1 | loss: 0.1663851\n",
      "\tspeed: 0.0418s/iter; left time: 353.5010s\n",
      "\titers: 700, epoch: 1 | loss: 0.1372963\n",
      "\tspeed: 0.0422s/iter; left time: 352.5364s\n",
      "\titers: 800, epoch: 1 | loss: 0.1458827\n",
      "\tspeed: 0.0424s/iter; left time: 350.5665s\n",
      "\titers: 900, epoch: 1 | loss: 0.1841954\n",
      "\tspeed: 0.0452s/iter; left time: 368.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.22s\n",
      "Steps: 906 | Train Loss: 0.2600894 Vali Loss: 0.1366055 Test Loss: 0.1520595\n",
      "Validation loss decreased (inf --> 0.136605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1532973\n",
      "\tspeed: 0.1015s/iter; left time: 817.3042s\n",
      "\titers: 200, epoch: 2 | loss: 0.1260789\n",
      "\tspeed: 0.0428s/iter; left time: 340.6858s\n",
      "\titers: 300, epoch: 2 | loss: 0.1008584\n",
      "\tspeed: 0.0432s/iter; left time: 339.6580s\n",
      "\titers: 400, epoch: 2 | loss: 0.0796642\n",
      "\tspeed: 0.0429s/iter; left time: 332.6286s\n",
      "\titers: 500, epoch: 2 | loss: 0.1141303\n",
      "\tspeed: 0.0425s/iter; left time: 325.0501s\n",
      "\titers: 600, epoch: 2 | loss: 0.1037540\n",
      "\tspeed: 0.0422s/iter; left time: 318.9473s\n",
      "\titers: 700, epoch: 2 | loss: 0.1089663\n",
      "\tspeed: 0.0430s/iter; left time: 320.3766s\n",
      "\titers: 800, epoch: 2 | loss: 0.1039877\n",
      "\tspeed: 0.0428s/iter; left time: 314.6970s\n",
      "\titers: 900, epoch: 2 | loss: 0.1020551\n",
      "\tspeed: 0.0414s/iter; left time: 300.2244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 906 | Train Loss: 0.1054358 Vali Loss: 0.0893238 Test Loss: 0.1045632\n",
      "Validation loss decreased (0.136605 --> 0.089324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1023343\n",
      "\tspeed: 0.0991s/iter; left time: 708.4305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0731819\n",
      "\tspeed: 0.0418s/iter; left time: 294.4957s\n",
      "\titers: 300, epoch: 3 | loss: 0.0958075\n",
      "\tspeed: 0.0411s/iter; left time: 285.6417s\n",
      "\titers: 400, epoch: 3 | loss: 0.0770710\n",
      "\tspeed: 0.0418s/iter; left time: 286.3855s\n",
      "\titers: 500, epoch: 3 | loss: 0.1102199\n",
      "\tspeed: 0.0414s/iter; left time: 279.3725s\n",
      "\titers: 600, epoch: 3 | loss: 0.0913249\n",
      "\tspeed: 0.0422s/iter; left time: 280.8657s\n",
      "\titers: 700, epoch: 3 | loss: 0.0686877\n",
      "\tspeed: 0.0416s/iter; left time: 272.3437s\n",
      "\titers: 800, epoch: 3 | loss: 0.0790340\n",
      "\tspeed: 0.0419s/iter; left time: 270.3541s\n",
      "\titers: 900, epoch: 3 | loss: 0.0761617\n",
      "\tspeed: 0.0417s/iter; left time: 264.9784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 906 | Train Loss: 0.0858373 Vali Loss: 0.0872478 Test Loss: 0.1066528\n",
      "Validation loss decreased (0.089324 --> 0.087248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0815753\n",
      "\tspeed: 0.0988s/iter; left time: 616.5249s\n",
      "\titers: 200, epoch: 4 | loss: 0.0754646\n",
      "\tspeed: 0.0422s/iter; left time: 258.9453s\n",
      "\titers: 300, epoch: 4 | loss: 0.0764520\n",
      "\tspeed: 0.0422s/iter; left time: 254.7654s\n",
      "\titers: 400, epoch: 4 | loss: 0.0895106\n",
      "\tspeed: 0.0418s/iter; left time: 248.1376s\n",
      "\titers: 500, epoch: 4 | loss: 0.0601778\n",
      "\tspeed: 0.0425s/iter; left time: 248.4276s\n",
      "\titers: 600, epoch: 4 | loss: 0.1016150\n",
      "\tspeed: 0.0419s/iter; left time: 240.8332s\n",
      "\titers: 700, epoch: 4 | loss: 0.0842820\n",
      "\tspeed: 0.0418s/iter; left time: 236.0593s\n",
      "\titers: 800, epoch: 4 | loss: 0.0868589\n",
      "\tspeed: 0.0425s/iter; left time: 235.4316s\n",
      "\titers: 900, epoch: 4 | loss: 0.0967281\n",
      "\tspeed: 0.0419s/iter; left time: 228.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.0770693 Vali Loss: 0.0831974 Test Loss: 0.1002508\n",
      "Validation loss decreased (0.087248 --> 0.083197).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600150\n",
      "\tspeed: 0.0970s/iter; left time: 517.7904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0542572\n",
      "\tspeed: 0.0420s/iter; left time: 219.7320s\n",
      "\titers: 300, epoch: 5 | loss: 0.0645427\n",
      "\tspeed: 0.0422s/iter; left time: 216.6582s\n",
      "\titers: 400, epoch: 5 | loss: 0.0514126\n",
      "\tspeed: 0.0415s/iter; left time: 209.0129s\n",
      "\titers: 500, epoch: 5 | loss: 0.0702532\n",
      "\tspeed: 0.0416s/iter; left time: 205.4085s\n",
      "\titers: 600, epoch: 5 | loss: 0.0489614\n",
      "\tspeed: 0.0414s/iter; left time: 200.0782s\n",
      "\titers: 700, epoch: 5 | loss: 0.0924419\n",
      "\tspeed: 0.0419s/iter; left time: 198.2977s\n",
      "\titers: 800, epoch: 5 | loss: 0.0652864\n",
      "\tspeed: 0.0412s/iter; left time: 191.1621s\n",
      "\titers: 900, epoch: 5 | loss: 0.0642762\n",
      "\tspeed: 0.0417s/iter; left time: 189.1585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 906 | Train Loss: 0.0691553 Vali Loss: 0.0892626 Test Loss: 0.1061498\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608225\n",
      "\tspeed: 0.0948s/iter; left time: 419.9749s\n",
      "\titers: 200, epoch: 6 | loss: 0.0698372\n",
      "\tspeed: 0.0421s/iter; left time: 182.1997s\n",
      "\titers: 300, epoch: 6 | loss: 0.0788709\n",
      "\tspeed: 0.0424s/iter; left time: 179.3410s\n",
      "\titers: 400, epoch: 6 | loss: 0.0710383\n",
      "\tspeed: 0.0422s/iter; left time: 174.4703s\n",
      "\titers: 500, epoch: 6 | loss: 0.0734161\n",
      "\tspeed: 0.0425s/iter; left time: 171.2440s\n",
      "\titers: 600, epoch: 6 | loss: 0.0809034\n",
      "\tspeed: 0.0424s/iter; left time: 166.7563s\n",
      "\titers: 700, epoch: 6 | loss: 0.0680279\n",
      "\tspeed: 0.0426s/iter; left time: 163.2535s\n",
      "\titers: 800, epoch: 6 | loss: 0.0567202\n",
      "\tspeed: 0.0417s/iter; left time: 155.6090s\n",
      "\titers: 900, epoch: 6 | loss: 0.0692521\n",
      "\tspeed: 0.0427s/iter; left time: 155.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 906 | Train Loss: 0.0617734 Vali Loss: 0.0905120 Test Loss: 0.1105444\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0574806\n",
      "\tspeed: 0.0986s/iter; left time: 347.6475s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578606\n",
      "\tspeed: 0.0455s/iter; left time: 155.8857s\n",
      "\titers: 300, epoch: 7 | loss: 0.0457384\n",
      "\tspeed: 0.0438s/iter; left time: 145.5761s\n",
      "\titers: 400, epoch: 7 | loss: 0.0540566\n",
      "\tspeed: 0.0429s/iter; left time: 138.3762s\n",
      "\titers: 500, epoch: 7 | loss: 0.0499512\n",
      "\tspeed: 0.0426s/iter; left time: 133.2080s\n",
      "\titers: 600, epoch: 7 | loss: 0.0393287\n",
      "\tspeed: 0.0424s/iter; left time: 128.1868s\n",
      "\titers: 700, epoch: 7 | loss: 0.0459998\n",
      "\tspeed: 0.0445s/iter; left time: 130.1834s\n",
      "\titers: 800, epoch: 7 | loss: 0.0533252\n",
      "\tspeed: 0.0443s/iter; left time: 125.0492s\n",
      "\titers: 900, epoch: 7 | loss: 0.0566984\n",
      "\tspeed: 0.0426s/iter; left time: 116.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 906 | Train Loss: 0.0546729 Vali Loss: 0.0899979 Test Loss: 0.1061608\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10002385079860687, rmse:0.3162654638290405, mae:0.19335344433784485, rse:0.3993486762046814\n",
      "Original data scale mse:1696561.0, rmse:1302.52099609375, mae:857.1822509765625, rse:0.09153122454881668\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4168179\n",
      "\tspeed: 0.0482s/iter; left time: 431.5110s\n",
      "\titers: 200, epoch: 1 | loss: 0.2886696\n",
      "\tspeed: 0.0459s/iter; left time: 406.9410s\n",
      "\titers: 300, epoch: 1 | loss: 0.2403183\n",
      "\tspeed: 0.0447s/iter; left time: 391.2516s\n",
      "\titers: 400, epoch: 1 | loss: 0.1930146\n",
      "\tspeed: 0.0416s/iter; left time: 360.0591s\n",
      "\titers: 500, epoch: 1 | loss: 0.1608932\n",
      "\tspeed: 0.0419s/iter; left time: 358.3808s\n",
      "\titers: 600, epoch: 1 | loss: 0.1777097\n",
      "\tspeed: 0.0412s/iter; left time: 348.4035s\n",
      "\titers: 700, epoch: 1 | loss: 0.1669439\n",
      "\tspeed: 0.0414s/iter; left time: 346.2489s\n",
      "\titers: 800, epoch: 1 | loss: 0.1633795\n",
      "\tspeed: 0.0417s/iter; left time: 344.5251s\n",
      "\titers: 900, epoch: 1 | loss: 0.1446787\n",
      "\tspeed: 0.0417s/iter; left time: 339.9841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.13s\n",
      "Steps: 906 | Train Loss: 0.2495366 Vali Loss: 0.1316007 Test Loss: 0.1512348\n",
      "Validation loss decreased (inf --> 0.131601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1034280\n",
      "\tspeed: 0.1021s/iter; left time: 822.1082s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250904\n",
      "\tspeed: 0.0426s/iter; left time: 339.1439s\n",
      "\titers: 300, epoch: 2 | loss: 0.0913794\n",
      "\tspeed: 0.0421s/iter; left time: 330.8022s\n",
      "\titers: 400, epoch: 2 | loss: 0.1011957\n",
      "\tspeed: 0.0419s/iter; left time: 324.9645s\n",
      "\titers: 500, epoch: 2 | loss: 0.1224960\n",
      "\tspeed: 0.0427s/iter; left time: 327.1517s\n",
      "\titers: 600, epoch: 2 | loss: 0.0618044\n",
      "\tspeed: 0.0418s/iter; left time: 316.1671s\n",
      "\titers: 700, epoch: 2 | loss: 0.0826926\n",
      "\tspeed: 0.0422s/iter; left time: 314.3606s\n",
      "\titers: 800, epoch: 2 | loss: 0.0713667\n",
      "\tspeed: 0.0419s/iter; left time: 307.8078s\n",
      "\titers: 900, epoch: 2 | loss: 0.0813036\n",
      "\tspeed: 0.0423s/iter; left time: 306.6508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 906 | Train Loss: 0.1056956 Vali Loss: 0.0904077 Test Loss: 0.1066121\n",
      "Validation loss decreased (0.131601 --> 0.090408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0805268\n",
      "\tspeed: 0.1011s/iter; left time: 722.7247s\n",
      "\titers: 200, epoch: 3 | loss: 0.0777041\n",
      "\tspeed: 0.0411s/iter; left time: 289.7597s\n",
      "\titers: 300, epoch: 3 | loss: 0.1113748\n",
      "\tspeed: 0.0409s/iter; left time: 284.4654s\n",
      "\titers: 400, epoch: 3 | loss: 0.0737260\n",
      "\tspeed: 0.0410s/iter; left time: 281.0607s\n",
      "\titers: 500, epoch: 3 | loss: 0.0781929\n",
      "\tspeed: 0.0410s/iter; left time: 276.5056s\n",
      "\titers: 600, epoch: 3 | loss: 0.0720723\n",
      "\tspeed: 0.0417s/iter; left time: 277.0252s\n",
      "\titers: 700, epoch: 3 | loss: 0.0949330\n",
      "\tspeed: 0.0413s/iter; left time: 270.6018s\n",
      "\titers: 800, epoch: 3 | loss: 0.0955116\n",
      "\tspeed: 0.0411s/iter; left time: 264.9452s\n",
      "\titers: 900, epoch: 3 | loss: 0.0805945\n",
      "\tspeed: 0.0416s/iter; left time: 264.0420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.64s\n",
      "Steps: 906 | Train Loss: 0.0855026 Vali Loss: 0.0836945 Test Loss: 0.0981142\n",
      "Validation loss decreased (0.090408 --> 0.083695).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0895017\n",
      "\tspeed: 0.0994s/iter; left time: 620.5960s\n",
      "\titers: 200, epoch: 4 | loss: 0.0870529\n",
      "\tspeed: 0.0420s/iter; left time: 257.9520s\n",
      "\titers: 300, epoch: 4 | loss: 0.1146038\n",
      "\tspeed: 0.0423s/iter; left time: 255.4745s\n",
      "\titers: 400, epoch: 4 | loss: 0.0830920\n",
      "\tspeed: 0.0421s/iter; left time: 250.2070s\n",
      "\titers: 500, epoch: 4 | loss: 0.0829308\n",
      "\tspeed: 0.0420s/iter; left time: 245.5205s\n",
      "\titers: 600, epoch: 4 | loss: 0.0558912\n",
      "\tspeed: 0.0428s/iter; left time: 246.0520s\n",
      "\titers: 700, epoch: 4 | loss: 0.0529644\n",
      "\tspeed: 0.0427s/iter; left time: 240.8568s\n",
      "\titers: 800, epoch: 4 | loss: 0.0564321\n",
      "\tspeed: 0.0424s/iter; left time: 235.0833s\n",
      "\titers: 900, epoch: 4 | loss: 0.0643488\n",
      "\tspeed: 0.0423s/iter; left time: 230.0502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 906 | Train Loss: 0.0786023 Vali Loss: 0.0871105 Test Loss: 0.1037567\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767027\n",
      "\tspeed: 0.0967s/iter; left time: 515.8844s\n",
      "\titers: 200, epoch: 5 | loss: 0.1085476\n",
      "\tspeed: 0.0427s/iter; left time: 223.4023s\n",
      "\titers: 300, epoch: 5 | loss: 0.0677622\n",
      "\tspeed: 0.0424s/iter; left time: 217.7287s\n",
      "\titers: 400, epoch: 5 | loss: 0.0740710\n",
      "\tspeed: 0.0424s/iter; left time: 213.6862s\n",
      "\titers: 500, epoch: 5 | loss: 0.0827700\n",
      "\tspeed: 0.0418s/iter; left time: 206.3014s\n",
      "\titers: 600, epoch: 5 | loss: 0.0590484\n",
      "\tspeed: 0.0419s/iter; left time: 202.4878s\n",
      "\titers: 700, epoch: 5 | loss: 0.0672496\n",
      "\tspeed: 0.0415s/iter; left time: 196.6606s\n",
      "\titers: 800, epoch: 5 | loss: 0.0579648\n",
      "\tspeed: 0.0427s/iter; left time: 197.8927s\n",
      "\titers: 900, epoch: 5 | loss: 0.0681030\n",
      "\tspeed: 0.0418s/iter; left time: 189.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.0703172 Vali Loss: 0.0912882 Test Loss: 0.1049923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0739752\n",
      "\tspeed: 0.0995s/iter; left time: 440.8416s\n",
      "\titers: 200, epoch: 6 | loss: 0.0463412\n",
      "\tspeed: 0.0458s/iter; left time: 198.3777s\n",
      "\titers: 300, epoch: 6 | loss: 0.0616892\n",
      "\tspeed: 0.0460s/iter; left time: 194.4861s\n",
      "\titers: 400, epoch: 6 | loss: 0.0568204\n",
      "\tspeed: 0.0458s/iter; left time: 189.1229s\n",
      "\titers: 500, epoch: 6 | loss: 0.0625511\n",
      "\tspeed: 0.0459s/iter; left time: 185.0142s\n",
      "\titers: 600, epoch: 6 | loss: 0.0598992\n",
      "\tspeed: 0.0458s/iter; left time: 180.0717s\n",
      "\titers: 700, epoch: 6 | loss: 0.0622896\n",
      "\tspeed: 0.0431s/iter; left time: 164.9780s\n",
      "\titers: 800, epoch: 6 | loss: 0.0433253\n",
      "\tspeed: 0.0420s/iter; left time: 156.7730s\n",
      "\titers: 900, epoch: 6 | loss: 0.0558392\n",
      "\tspeed: 0.0416s/iter; left time: 150.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 906 | Train Loss: 0.0630982 Vali Loss: 0.0911216 Test Loss: 0.1052075\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.09819940477609634, rmse:0.3133678436279297, mae:0.19801004230976105, rse:0.39568981528282166\n",
      "Original data scale mse:1713331.125, rmse:1308.9427490234375, mae:885.3687133789062, rse:0.09198249876499176\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5045965\n",
      "\tspeed: 0.0799s/iter; left time: 714.4619s\n",
      "\titers: 200, epoch: 1 | loss: 0.4390484\n",
      "\tspeed: 0.0503s/iter; left time: 444.9529s\n",
      "\titers: 300, epoch: 1 | loss: 0.3437441\n",
      "\tspeed: 0.0486s/iter; left time: 425.0850s\n",
      "\titers: 400, epoch: 1 | loss: 0.3208438\n",
      "\tspeed: 0.0472s/iter; left time: 407.4240s\n",
      "\titers: 500, epoch: 1 | loss: 0.3070790\n",
      "\tspeed: 0.0470s/iter; left time: 401.7142s\n",
      "\titers: 600, epoch: 1 | loss: 0.2794358\n",
      "\tspeed: 0.0469s/iter; left time: 395.7681s\n",
      "\titers: 700, epoch: 1 | loss: 0.2686736\n",
      "\tspeed: 0.0469s/iter; left time: 390.8473s\n",
      "\titers: 800, epoch: 1 | loss: 0.2617631\n",
      "\tspeed: 0.0469s/iter; left time: 386.1759s\n",
      "\titers: 900, epoch: 1 | loss: 0.2700858\n",
      "\tspeed: 0.0495s/iter; left time: 403.2771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.26s\n",
      "Steps: 904 | Train Loss: 0.3468960 Vali Loss: 0.2351844 Test Loss: 0.2707231\n",
      "Validation loss decreased (inf --> 0.235184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2300241\n",
      "\tspeed: 0.1153s/iter; left time: 926.6494s\n",
      "\titers: 200, epoch: 2 | loss: 0.2220291\n",
      "\tspeed: 0.0475s/iter; left time: 376.9666s\n",
      "\titers: 300, epoch: 2 | loss: 0.1872774\n",
      "\tspeed: 0.0476s/iter; left time: 372.8818s\n",
      "\titers: 400, epoch: 2 | loss: 0.1779795\n",
      "\tspeed: 0.0474s/iter; left time: 366.7985s\n",
      "\titers: 500, epoch: 2 | loss: 0.1688535\n",
      "\tspeed: 0.0474s/iter; left time: 362.3098s\n",
      "\titers: 600, epoch: 2 | loss: 0.1828407\n",
      "\tspeed: 0.0476s/iter; left time: 358.6056s\n",
      "\titers: 700, epoch: 2 | loss: 0.1627705\n",
      "\tspeed: 0.0476s/iter; left time: 353.9687s\n",
      "\titers: 800, epoch: 2 | loss: 0.1611297\n",
      "\tspeed: 0.0475s/iter; left time: 348.2323s\n",
      "\titers: 900, epoch: 2 | loss: 0.1451629\n",
      "\tspeed: 0.0476s/iter; left time: 344.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.1849431 Vali Loss: 0.1534018 Test Loss: 0.1706837\n",
      "Validation loss decreased (0.235184 --> 0.153402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1613644\n",
      "\tspeed: 0.1162s/iter; left time: 828.7136s\n",
      "\titers: 200, epoch: 3 | loss: 0.1548926\n",
      "\tspeed: 0.0474s/iter; left time: 333.6597s\n",
      "\titers: 300, epoch: 3 | loss: 0.1574221\n",
      "\tspeed: 0.0478s/iter; left time: 331.3628s\n",
      "\titers: 400, epoch: 3 | loss: 0.1564433\n",
      "\tspeed: 0.0475s/iter; left time: 324.3579s\n",
      "\titers: 500, epoch: 3 | loss: 0.1398545\n",
      "\tspeed: 0.0478s/iter; left time: 322.0645s\n",
      "\titers: 600, epoch: 3 | loss: 0.1393510\n",
      "\tspeed: 0.0477s/iter; left time: 316.3891s\n",
      "\titers: 700, epoch: 3 | loss: 0.1322500\n",
      "\tspeed: 0.0476s/iter; left time: 311.1233s\n",
      "\titers: 800, epoch: 3 | loss: 0.1685270\n",
      "\tspeed: 0.0477s/iter; left time: 307.1098s\n",
      "\titers: 900, epoch: 3 | loss: 0.1617758\n",
      "\tspeed: 0.0477s/iter; left time: 302.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.1460258 Vali Loss: 0.1451110 Test Loss: 0.1648626\n",
      "Validation loss decreased (0.153402 --> 0.145111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1242825\n",
      "\tspeed: 0.1152s/iter; left time: 717.4326s\n",
      "\titers: 200, epoch: 4 | loss: 0.1335241\n",
      "\tspeed: 0.0472s/iter; left time: 289.3164s\n",
      "\titers: 300, epoch: 4 | loss: 0.1145575\n",
      "\tspeed: 0.0497s/iter; left time: 299.5475s\n",
      "\titers: 400, epoch: 4 | loss: 0.1492457\n",
      "\tspeed: 0.0505s/iter; left time: 299.3059s\n",
      "\titers: 500, epoch: 4 | loss: 0.1411823\n",
      "\tspeed: 0.0503s/iter; left time: 292.9530s\n",
      "\titers: 600, epoch: 4 | loss: 0.1362645\n",
      "\tspeed: 0.0503s/iter; left time: 287.8966s\n",
      "\titers: 700, epoch: 4 | loss: 0.1161992\n",
      "\tspeed: 0.0503s/iter; left time: 283.3188s\n",
      "\titers: 800, epoch: 4 | loss: 0.1321714\n",
      "\tspeed: 0.0485s/iter; left time: 268.0644s\n",
      "\titers: 900, epoch: 4 | loss: 0.1172668\n",
      "\tspeed: 0.0470s/iter; left time: 255.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.53s\n",
      "Steps: 904 | Train Loss: 0.1313648 Vali Loss: 0.1518364 Test Loss: 0.1867373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1045115\n",
      "\tspeed: 0.1114s/iter; left time: 593.2686s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071720\n",
      "\tspeed: 0.0472s/iter; left time: 246.5122s\n",
      "\titers: 300, epoch: 5 | loss: 0.1205560\n",
      "\tspeed: 0.0472s/iter; left time: 241.8979s\n",
      "\titers: 400, epoch: 5 | loss: 0.1421698\n",
      "\tspeed: 0.0472s/iter; left time: 237.2326s\n",
      "\titers: 500, epoch: 5 | loss: 0.1038092\n",
      "\tspeed: 0.0472s/iter; left time: 232.2796s\n",
      "\titers: 600, epoch: 5 | loss: 0.1141948\n",
      "\tspeed: 0.0473s/iter; left time: 228.1499s\n",
      "\titers: 700, epoch: 5 | loss: 0.1282563\n",
      "\tspeed: 0.0473s/iter; left time: 223.6481s\n",
      "\titers: 800, epoch: 5 | loss: 0.1173381\n",
      "\tspeed: 0.0475s/iter; left time: 219.7034s\n",
      "\titers: 900, epoch: 5 | loss: 0.1051606\n",
      "\tspeed: 0.0473s/iter; left time: 214.2197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.92s\n",
      "Steps: 904 | Train Loss: 0.1181595 Vali Loss: 0.1614592 Test Loss: 0.1828424\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839722\n",
      "\tspeed: 0.1119s/iter; left time: 494.8237s\n",
      "\titers: 200, epoch: 6 | loss: 0.1093515\n",
      "\tspeed: 0.0474s/iter; left time: 204.9572s\n",
      "\titers: 300, epoch: 6 | loss: 0.1092099\n",
      "\tspeed: 0.0475s/iter; left time: 200.5211s\n",
      "\titers: 400, epoch: 6 | loss: 0.1182218\n",
      "\tspeed: 0.0475s/iter; left time: 195.8688s\n",
      "\titers: 500, epoch: 6 | loss: 0.1052422\n",
      "\tspeed: 0.0436s/iter; left time: 175.1931s\n",
      "\titers: 600, epoch: 6 | loss: 0.0997554\n",
      "\tspeed: 0.0403s/iter; left time: 157.9230s\n",
      "\titers: 700, epoch: 6 | loss: 0.0752411\n",
      "\tspeed: 0.0431s/iter; left time: 164.8049s\n",
      "\titers: 800, epoch: 6 | loss: 0.1045671\n",
      "\tspeed: 0.0475s/iter; left time: 176.8885s\n",
      "\titers: 900, epoch: 6 | loss: 0.0971484\n",
      "\tspeed: 0.0474s/iter; left time: 171.5496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.60s\n",
      "Steps: 904 | Train Loss: 0.1055968 Vali Loss: 0.1675357 Test Loss: 0.1822582\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16490043699741364, rmse:0.40607935190200806, mae:0.26791679859161377, rse:0.5121438503265381\n",
      "Original data scale mse:3421302.0, rmse:1849.6761474609375, mae:1260.5140380859375, rse:0.13016927242279053\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4475376\n",
      "\tspeed: 0.0520s/iter; left time: 464.9204s\n",
      "\titers: 200, epoch: 1 | loss: 0.4170868\n",
      "\tspeed: 0.0503s/iter; left time: 445.1410s\n",
      "\titers: 300, epoch: 1 | loss: 0.3696011\n",
      "\tspeed: 0.0473s/iter; left time: 413.0678s\n",
      "\titers: 400, epoch: 1 | loss: 0.3156129\n",
      "\tspeed: 0.0472s/iter; left time: 407.5147s\n",
      "\titers: 500, epoch: 1 | loss: 0.3267281\n",
      "\tspeed: 0.0473s/iter; left time: 404.0254s\n",
      "\titers: 600, epoch: 1 | loss: 0.2518276\n",
      "\tspeed: 0.0475s/iter; left time: 401.1674s\n",
      "\titers: 700, epoch: 1 | loss: 0.2776158\n",
      "\tspeed: 0.0471s/iter; left time: 393.0135s\n",
      "\titers: 800, epoch: 1 | loss: 0.2633318\n",
      "\tspeed: 0.0471s/iter; left time: 388.1901s\n",
      "\titers: 900, epoch: 1 | loss: 0.2625957\n",
      "\tspeed: 0.0473s/iter; left time: 385.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.60s\n",
      "Steps: 904 | Train Loss: 0.3421745 Vali Loss: 0.2333531 Test Loss: 0.2728005\n",
      "Validation loss decreased (inf --> 0.233353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2594028\n",
      "\tspeed: 0.1171s/iter; left time: 941.1998s\n",
      "\titers: 200, epoch: 2 | loss: 0.2541784\n",
      "\tspeed: 0.0477s/iter; left time: 378.6054s\n",
      "\titers: 300, epoch: 2 | loss: 0.1773580\n",
      "\tspeed: 0.0478s/iter; left time: 374.6208s\n",
      "\titers: 400, epoch: 2 | loss: 0.1676601\n",
      "\tspeed: 0.0479s/iter; left time: 370.5879s\n",
      "\titers: 500, epoch: 2 | loss: 0.1602368\n",
      "\tspeed: 0.0477s/iter; left time: 364.1150s\n",
      "\titers: 600, epoch: 2 | loss: 0.1895377\n",
      "\tspeed: 0.0477s/iter; left time: 359.5270s\n",
      "\titers: 700, epoch: 2 | loss: 0.1559464\n",
      "\tspeed: 0.0477s/iter; left time: 354.7906s\n",
      "\titers: 800, epoch: 2 | loss: 0.1509054\n",
      "\tspeed: 0.0478s/iter; left time: 350.5780s\n",
      "\titers: 900, epoch: 2 | loss: 0.1405970\n",
      "\tspeed: 0.0478s/iter; left time: 345.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.39s\n",
      "Steps: 904 | Train Loss: 0.1825963 Vali Loss: 0.1495076 Test Loss: 0.1701031\n",
      "Validation loss decreased (0.233353 --> 0.149508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1443687\n",
      "\tspeed: 0.1170s/iter; left time: 834.7906s\n",
      "\titers: 200, epoch: 3 | loss: 0.1518792\n",
      "\tspeed: 0.0474s/iter; left time: 333.5571s\n",
      "\titers: 300, epoch: 3 | loss: 0.1543838\n",
      "\tspeed: 0.0475s/iter; left time: 329.3846s\n",
      "\titers: 400, epoch: 3 | loss: 0.1467329\n",
      "\tspeed: 0.0475s/iter; left time: 324.4534s\n",
      "\titers: 500, epoch: 3 | loss: 0.1330860\n",
      "\tspeed: 0.0475s/iter; left time: 319.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.1557555\n",
      "\tspeed: 0.0474s/iter; left time: 314.7347s\n",
      "\titers: 700, epoch: 3 | loss: 0.1508784\n",
      "\tspeed: 0.0473s/iter; left time: 308.8469s\n",
      "\titers: 800, epoch: 3 | loss: 0.1350839\n",
      "\tspeed: 0.0474s/iter; left time: 305.0759s\n",
      "\titers: 900, epoch: 3 | loss: 0.1113788\n",
      "\tspeed: 0.0474s/iter; left time: 300.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.1437586 Vali Loss: 0.1512932 Test Loss: 0.1674922\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1300042\n",
      "\tspeed: 0.1167s/iter; left time: 726.6414s\n",
      "\titers: 200, epoch: 4 | loss: 0.1244012\n",
      "\tspeed: 0.0504s/iter; left time: 308.7586s\n",
      "\titers: 300, epoch: 4 | loss: 0.1192255\n",
      "\tspeed: 0.0498s/iter; left time: 300.3810s\n",
      "\titers: 400, epoch: 4 | loss: 0.1346381\n",
      "\tspeed: 0.0502s/iter; left time: 297.4333s\n",
      "\titers: 500, epoch: 4 | loss: 0.1325753\n",
      "\tspeed: 0.0482s/iter; left time: 280.7504s\n",
      "\titers: 600, epoch: 4 | loss: 0.1362159\n",
      "\tspeed: 0.0475s/iter; left time: 272.3551s\n",
      "\titers: 700, epoch: 4 | loss: 0.1304613\n",
      "\tspeed: 0.0478s/iter; left time: 269.1685s\n",
      "\titers: 800, epoch: 4 | loss: 0.1154950\n",
      "\tspeed: 0.0482s/iter; left time: 266.3544s\n",
      "\titers: 900, epoch: 4 | loss: 0.1173018\n",
      "\tspeed: 0.0476s/iter; left time: 258.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.41s\n",
      "Steps: 904 | Train Loss: 0.1299172 Vali Loss: 0.1495079 Test Loss: 0.1671035\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1128451\n",
      "\tspeed: 0.1136s/iter; left time: 604.8635s\n",
      "\titers: 200, epoch: 5 | loss: 0.1181555\n",
      "\tspeed: 0.0479s/iter; left time: 250.0315s\n",
      "\titers: 300, epoch: 5 | loss: 0.1362707\n",
      "\tspeed: 0.0477s/iter; left time: 244.2189s\n",
      "\titers: 400, epoch: 5 | loss: 0.1163110\n",
      "\tspeed: 0.0477s/iter; left time: 239.7325s\n",
      "\titers: 500, epoch: 5 | loss: 0.1129930\n",
      "\tspeed: 0.0477s/iter; left time: 234.8635s\n",
      "\titers: 600, epoch: 5 | loss: 0.1037793\n",
      "\tspeed: 0.0491s/iter; left time: 237.0748s\n",
      "\titers: 700, epoch: 5 | loss: 0.1132942\n",
      "\tspeed: 0.0504s/iter; left time: 238.3661s\n",
      "\titers: 800, epoch: 5 | loss: 0.1099381\n",
      "\tspeed: 0.0502s/iter; left time: 232.2450s\n",
      "\titers: 900, epoch: 5 | loss: 0.0946565\n",
      "\tspeed: 0.0504s/iter; left time: 227.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.37s\n",
      "Steps: 904 | Train Loss: 0.1178938 Vali Loss: 0.1571686 Test Loss: 0.1803182\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.1699843406677246, rmse:0.41229158639907837, mae:0.2785334587097168, rse:0.5199787020683289\n",
      "Original data scale mse:3697298.25, rmse:1922.8359375, mae:1325.630615234375, rse:0.1353178173303604\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4966977\n",
      "\tspeed: 0.0815s/iter; left time: 726.8950s\n",
      "\titers: 200, epoch: 1 | loss: 0.4099219\n",
      "\tspeed: 0.0521s/iter; left time: 459.3734s\n",
      "\titers: 300, epoch: 1 | loss: 0.4381100\n",
      "\tspeed: 0.0529s/iter; left time: 461.3970s\n",
      "\titers: 400, epoch: 1 | loss: 0.3973788\n",
      "\tspeed: 0.0531s/iter; left time: 458.1676s\n",
      "\titers: 500, epoch: 1 | loss: 0.3753636\n",
      "\tspeed: 0.0527s/iter; left time: 449.0548s\n",
      "\titers: 600, epoch: 1 | loss: 0.3728669\n",
      "\tspeed: 0.0532s/iter; left time: 448.3544s\n",
      "\titers: 700, epoch: 1 | loss: 0.3483940\n",
      "\tspeed: 0.0530s/iter; left time: 440.7301s\n",
      "\titers: 800, epoch: 1 | loss: 0.3762171\n",
      "\tspeed: 0.0527s/iter; left time: 433.4911s\n",
      "\titers: 900, epoch: 1 | loss: 0.3350616\n",
      "\tspeed: 0.0530s/iter; left time: 430.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.33s\n",
      "Steps: 902 | Train Loss: 0.3986439 Vali Loss: 0.3218878 Test Loss: 0.3710622\n",
      "Validation loss decreased (inf --> 0.321888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3282322\n",
      "\tspeed: 0.1339s/iter; left time: 1073.8482s\n",
      "\titers: 200, epoch: 2 | loss: 0.2845210\n",
      "\tspeed: 0.0536s/iter; left time: 424.5442s\n",
      "\titers: 300, epoch: 2 | loss: 0.2315060\n",
      "\tspeed: 0.0534s/iter; left time: 417.2753s\n",
      "\titers: 400, epoch: 2 | loss: 0.2004031\n",
      "\tspeed: 0.0499s/iter; left time: 384.8871s\n",
      "\titers: 500, epoch: 2 | loss: 0.1822670\n",
      "\tspeed: 0.0426s/iter; left time: 324.5547s\n",
      "\titers: 600, epoch: 2 | loss: 0.2010734\n",
      "\tspeed: 0.0426s/iter; left time: 320.5012s\n",
      "\titers: 700, epoch: 2 | loss: 0.1537598\n",
      "\tspeed: 0.0426s/iter; left time: 316.1279s\n",
      "\titers: 800, epoch: 2 | loss: 0.1599696\n",
      "\tspeed: 0.0426s/iter; left time: 311.8362s\n",
      "\titers: 900, epoch: 2 | loss: 0.1636544\n",
      "\tspeed: 0.0426s/iter; left time: 307.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.62s\n",
      "Steps: 902 | Train Loss: 0.2208208 Vali Loss: 0.1734993 Test Loss: 0.2008001\n",
      "Validation loss decreased (0.321888 --> 0.173499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1543073\n",
      "\tspeed: 0.1343s/iter; left time: 956.0867s\n",
      "\titers: 200, epoch: 3 | loss: 0.1781035\n",
      "\tspeed: 0.0535s/iter; left time: 375.2786s\n",
      "\titers: 300, epoch: 3 | loss: 0.1746193\n",
      "\tspeed: 0.0536s/iter; left time: 370.9490s\n",
      "\titers: 400, epoch: 3 | loss: 0.1871681\n",
      "\tspeed: 0.0535s/iter; left time: 364.8387s\n",
      "\titers: 500, epoch: 3 | loss: 0.1751289\n",
      "\tspeed: 0.0533s/iter; left time: 358.3272s\n",
      "\titers: 600, epoch: 3 | loss: 0.1499453\n",
      "\tspeed: 0.0535s/iter; left time: 354.2278s\n",
      "\titers: 700, epoch: 3 | loss: 0.1454932\n",
      "\tspeed: 0.0535s/iter; left time: 348.8984s\n",
      "\titers: 800, epoch: 3 | loss: 0.1587827\n",
      "\tspeed: 0.0536s/iter; left time: 343.6442s\n",
      "\titers: 900, epoch: 3 | loss: 0.1564680\n",
      "\tspeed: 0.0533s/iter; left time: 336.6767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.1620454 Vali Loss: 0.1663911 Test Loss: 0.1857910\n",
      "Validation loss decreased (0.173499 --> 0.166391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1516684\n",
      "\tspeed: 0.1330s/iter; left time: 826.7187s\n",
      "\titers: 200, epoch: 4 | loss: 0.1399278\n",
      "\tspeed: 0.0536s/iter; left time: 327.9569s\n",
      "\titers: 300, epoch: 4 | loss: 0.1754512\n",
      "\tspeed: 0.0535s/iter; left time: 321.8352s\n",
      "\titers: 400, epoch: 4 | loss: 0.1406582\n",
      "\tspeed: 0.0533s/iter; left time: 314.9945s\n",
      "\titers: 500, epoch: 4 | loss: 0.1360245\n",
      "\tspeed: 0.0533s/iter; left time: 309.6627s\n",
      "\titers: 600, epoch: 4 | loss: 0.1327563\n",
      "\tspeed: 0.0530s/iter; left time: 303.0875s\n",
      "\titers: 700, epoch: 4 | loss: 0.1522301\n",
      "\tspeed: 0.0533s/iter; left time: 299.1300s\n",
      "\titers: 800, epoch: 4 | loss: 0.1508048\n",
      "\tspeed: 0.0535s/iter; left time: 295.0063s\n",
      "\titers: 900, epoch: 4 | loss: 0.1359401\n",
      "\tspeed: 0.0534s/iter; left time: 289.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.1436205 Vali Loss: 0.1616475 Test Loss: 0.1910362\n",
      "Validation loss decreased (0.166391 --> 0.161647).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1165406\n",
      "\tspeed: 0.1333s/iter; left time: 708.1248s\n",
      "\titers: 200, epoch: 5 | loss: 0.1227968\n",
      "\tspeed: 0.0537s/iter; left time: 279.8519s\n",
      "\titers: 300, epoch: 5 | loss: 0.1398759\n",
      "\tspeed: 0.0534s/iter; left time: 272.8818s\n",
      "\titers: 400, epoch: 5 | loss: 0.1302250\n",
      "\tspeed: 0.0538s/iter; left time: 269.4581s\n",
      "\titers: 500, epoch: 5 | loss: 0.1340078\n",
      "\tspeed: 0.0536s/iter; left time: 263.3397s\n",
      "\titers: 600, epoch: 5 | loss: 0.1324678\n",
      "\tspeed: 0.0536s/iter; left time: 257.9358s\n",
      "\titers: 700, epoch: 5 | loss: 0.1363588\n",
      "\tspeed: 0.0537s/iter; left time: 253.0217s\n",
      "\titers: 800, epoch: 5 | loss: 0.1203870\n",
      "\tspeed: 0.0536s/iter; left time: 247.3153s\n",
      "\titers: 900, epoch: 5 | loss: 0.1123812\n",
      "\tspeed: 0.0536s/iter; left time: 241.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.1272365 Vali Loss: 0.1729182 Test Loss: 0.1960722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1052577\n",
      "\tspeed: 0.1296s/iter; left time: 571.6242s\n",
      "\titers: 200, epoch: 6 | loss: 0.1154618\n",
      "\tspeed: 0.0535s/iter; left time: 230.7679s\n",
      "\titers: 300, epoch: 6 | loss: 0.1060943\n",
      "\tspeed: 0.0535s/iter; left time: 225.0888s\n",
      "\titers: 400, epoch: 6 | loss: 0.1166776\n",
      "\tspeed: 0.0531s/iter; left time: 218.4751s\n",
      "\titers: 500, epoch: 6 | loss: 0.1117797\n",
      "\tspeed: 0.0536s/iter; left time: 214.8774s\n",
      "\titers: 600, epoch: 6 | loss: 0.1012975\n",
      "\tspeed: 0.0535s/iter; left time: 209.2846s\n",
      "\titers: 700, epoch: 6 | loss: 0.1002825\n",
      "\tspeed: 0.0535s/iter; left time: 203.7766s\n",
      "\titers: 800, epoch: 6 | loss: 0.0949321\n",
      "\tspeed: 0.0530s/iter; left time: 196.6513s\n",
      "\titers: 900, epoch: 6 | loss: 0.1055358\n",
      "\tspeed: 0.0532s/iter; left time: 192.1221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.34s\n",
      "Steps: 902 | Train Loss: 0.1114315 Vali Loss: 0.1849274 Test Loss: 0.2154551\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1018671\n",
      "\tspeed: 0.1297s/iter; left time: 455.0034s\n",
      "\titers: 200, epoch: 7 | loss: 0.1101972\n",
      "\tspeed: 0.0533s/iter; left time: 181.6714s\n",
      "\titers: 300, epoch: 7 | loss: 0.0802369\n",
      "\tspeed: 0.0532s/iter; left time: 176.0020s\n",
      "\titers: 400, epoch: 7 | loss: 0.0953395\n",
      "\tspeed: 0.0533s/iter; left time: 171.1957s\n",
      "\titers: 500, epoch: 7 | loss: 0.1015822\n",
      "\tspeed: 0.0535s/iter; left time: 166.4659s\n",
      "\titers: 600, epoch: 7 | loss: 0.0980061\n",
      "\tspeed: 0.0531s/iter; left time: 159.8448s\n",
      "\titers: 700, epoch: 7 | loss: 0.0913025\n",
      "\tspeed: 0.0534s/iter; left time: 155.4228s\n",
      "\titers: 800, epoch: 7 | loss: 0.0808870\n",
      "\tspeed: 0.0533s/iter; left time: 149.7050s\n",
      "\titers: 900, epoch: 7 | loss: 0.0746090\n",
      "\tspeed: 0.0534s/iter; left time: 144.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.0969700 Vali Loss: 0.1899111 Test Loss: 0.2163351\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.19100810587406158, rmse:0.43704473972320557, mae:0.2906225919723511, rse:0.5505934953689575\n",
      "Original data scale mse:4675170.5, rmse:2162.21435546875, mae:1425.986083984375, rse:0.15230673551559448\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4542921\n",
      "\tspeed: 0.0565s/iter; left time: 504.3819s\n",
      "\titers: 200, epoch: 1 | loss: 0.4394370\n",
      "\tspeed: 0.0537s/iter; left time: 473.8614s\n",
      "\titers: 300, epoch: 1 | loss: 0.3722619\n",
      "\tspeed: 0.0537s/iter; left time: 467.9654s\n",
      "\titers: 400, epoch: 1 | loss: 0.3826541\n",
      "\tspeed: 0.0535s/iter; left time: 461.6214s\n",
      "\titers: 500, epoch: 1 | loss: 0.3788883\n",
      "\tspeed: 0.0536s/iter; left time: 456.9176s\n",
      "\titers: 600, epoch: 1 | loss: 0.3316003\n",
      "\tspeed: 0.0536s/iter; left time: 451.1635s\n",
      "\titers: 700, epoch: 1 | loss: 0.3430753\n",
      "\tspeed: 0.0537s/iter; left time: 446.9174s\n",
      "\titers: 800, epoch: 1 | loss: 0.3369034\n",
      "\tspeed: 0.0537s/iter; left time: 441.2478s\n",
      "\titers: 900, epoch: 1 | loss: 0.3387891\n",
      "\tspeed: 0.0534s/iter; left time: 433.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.3936864 Vali Loss: 0.3190689 Test Loss: 0.3769189\n",
      "Validation loss decreased (inf --> 0.319069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3121722\n",
      "\tspeed: 0.1314s/iter; left time: 1053.5448s\n",
      "\titers: 200, epoch: 2 | loss: 0.2628028\n",
      "\tspeed: 0.0525s/iter; left time: 415.8112s\n",
      "\titers: 300, epoch: 2 | loss: 0.2298339\n",
      "\tspeed: 0.0449s/iter; left time: 350.7182s\n",
      "\titers: 400, epoch: 2 | loss: 0.1916041\n",
      "\tspeed: 0.0426s/iter; left time: 328.9339s\n",
      "\titers: 500, epoch: 2 | loss: 0.2294622\n",
      "\tspeed: 0.0426s/iter; left time: 324.7520s\n",
      "\titers: 600, epoch: 2 | loss: 0.1571815\n",
      "\tspeed: 0.0426s/iter; left time: 320.4379s\n",
      "\titers: 700, epoch: 2 | loss: 0.1837410\n",
      "\tspeed: 0.0427s/iter; left time: 316.6783s\n",
      "\titers: 800, epoch: 2 | loss: 0.1569615\n",
      "\tspeed: 0.0426s/iter; left time: 312.0896s\n",
      "\titers: 900, epoch: 2 | loss: 0.1772609\n",
      "\tspeed: 0.0426s/iter; left time: 307.6540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 902 | Train Loss: 0.2187708 Vali Loss: 0.1668635 Test Loss: 0.1875922\n",
      "Validation loss decreased (0.319069 --> 0.166864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1912389\n",
      "\tspeed: 0.1350s/iter; left time: 960.9547s\n",
      "\titers: 200, epoch: 3 | loss: 0.1580966\n",
      "\tspeed: 0.0536s/iter; left time: 375.7838s\n",
      "\titers: 300, epoch: 3 | loss: 0.1571783\n",
      "\tspeed: 0.0534s/iter; left time: 369.1894s\n",
      "\titers: 400, epoch: 3 | loss: 0.1620918\n",
      "\tspeed: 0.0534s/iter; left time: 364.1162s\n",
      "\titers: 500, epoch: 3 | loss: 0.1507528\n",
      "\tspeed: 0.0536s/iter; left time: 359.9931s\n",
      "\titers: 600, epoch: 3 | loss: 0.1671983\n",
      "\tspeed: 0.0534s/iter; left time: 353.1086s\n",
      "\titers: 700, epoch: 3 | loss: 0.1423663\n",
      "\tspeed: 0.0532s/iter; left time: 346.8447s\n",
      "\titers: 800, epoch: 3 | loss: 0.1704713\n",
      "\tspeed: 0.0535s/iter; left time: 343.1298s\n",
      "\titers: 900, epoch: 3 | loss: 0.1696619\n",
      "\tspeed: 0.0534s/iter; left time: 337.6427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.49s\n",
      "Steps: 902 | Train Loss: 0.1618859 Vali Loss: 0.1633216 Test Loss: 0.1745463\n",
      "Validation loss decreased (0.166864 --> 0.163322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1582388\n",
      "\tspeed: 0.1328s/iter; left time: 825.2672s\n",
      "\titers: 200, epoch: 4 | loss: 0.1516810\n",
      "\tspeed: 0.0534s/iter; left time: 326.7718s\n",
      "\titers: 300, epoch: 4 | loss: 0.1378785\n",
      "\tspeed: 0.0531s/iter; left time: 319.6133s\n",
      "\titers: 400, epoch: 4 | loss: 0.1575182\n",
      "\tspeed: 0.0532s/iter; left time: 314.5776s\n",
      "\titers: 500, epoch: 4 | loss: 0.1490256\n",
      "\tspeed: 0.0522s/iter; left time: 303.3780s\n",
      "\titers: 600, epoch: 4 | loss: 0.1329670\n",
      "\tspeed: 0.0533s/iter; left time: 304.3511s\n",
      "\titers: 700, epoch: 4 | loss: 0.1389233\n",
      "\tspeed: 0.0534s/iter; left time: 300.0433s\n",
      "\titers: 800, epoch: 4 | loss: 0.1491598\n",
      "\tspeed: 0.0535s/iter; left time: 295.1766s\n",
      "\titers: 900, epoch: 4 | loss: 0.1340696\n",
      "\tspeed: 0.0535s/iter; left time: 289.6995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.22s\n",
      "Steps: 902 | Train Loss: 0.1444540 Vali Loss: 0.1620332 Test Loss: 0.1857745\n",
      "Validation loss decreased (0.163322 --> 0.162033).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1313165\n",
      "\tspeed: 0.1341s/iter; left time: 712.6462s\n",
      "\titers: 200, epoch: 5 | loss: 0.1233402\n",
      "\tspeed: 0.0534s/iter; left time: 278.2777s\n",
      "\titers: 300, epoch: 5 | loss: 0.1362630\n",
      "\tspeed: 0.0535s/iter; left time: 273.5586s\n",
      "\titers: 400, epoch: 5 | loss: 0.1411424\n",
      "\tspeed: 0.0533s/iter; left time: 267.1157s\n",
      "\titers: 500, epoch: 5 | loss: 0.1263086\n",
      "\tspeed: 0.0534s/iter; left time: 262.4771s\n",
      "\titers: 600, epoch: 5 | loss: 0.1267703\n",
      "\tspeed: 0.0532s/iter; left time: 256.0634s\n",
      "\titers: 700, epoch: 5 | loss: 0.1169034\n",
      "\tspeed: 0.0537s/iter; left time: 252.9753s\n",
      "\titers: 800, epoch: 5 | loss: 0.1271486\n",
      "\tspeed: 0.0530s/iter; left time: 244.4466s\n",
      "\titers: 900, epoch: 5 | loss: 0.1136018\n",
      "\tspeed: 0.0532s/iter; left time: 239.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.1284857 Vali Loss: 0.1680490 Test Loss: 0.1856285\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1368518\n",
      "\tspeed: 0.1299s/iter; left time: 573.0006s\n",
      "\titers: 200, epoch: 6 | loss: 0.1018151\n",
      "\tspeed: 0.0535s/iter; left time: 230.8313s\n",
      "\titers: 300, epoch: 6 | loss: 0.1177235\n",
      "\tspeed: 0.0533s/iter; left time: 224.3080s\n",
      "\titers: 400, epoch: 6 | loss: 0.1205800\n",
      "\tspeed: 0.0535s/iter; left time: 219.9936s\n",
      "\titers: 500, epoch: 6 | loss: 0.1277281\n",
      "\tspeed: 0.0535s/iter; left time: 214.6939s\n",
      "\titers: 600, epoch: 6 | loss: 0.1199198\n",
      "\tspeed: 0.0533s/iter; left time: 208.4946s\n",
      "\titers: 700, epoch: 6 | loss: 0.1167714\n",
      "\tspeed: 0.0534s/iter; left time: 203.4923s\n",
      "\titers: 800, epoch: 6 | loss: 0.1001362\n",
      "\tspeed: 0.0534s/iter; left time: 198.2642s\n",
      "\titers: 900, epoch: 6 | loss: 0.0938075\n",
      "\tspeed: 0.0533s/iter; left time: 192.4728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.1136454 Vali Loss: 0.1834338 Test Loss: 0.2057332\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056418\n",
      "\tspeed: 0.1301s/iter; left time: 456.6226s\n",
      "\titers: 200, epoch: 7 | loss: 0.1041363\n",
      "\tspeed: 0.0534s/iter; left time: 182.0073s\n",
      "\titers: 300, epoch: 7 | loss: 0.1026165\n",
      "\tspeed: 0.0536s/iter; left time: 177.2038s\n",
      "\titers: 400, epoch: 7 | loss: 0.1092902\n",
      "\tspeed: 0.0532s/iter; left time: 170.8495s\n",
      "\titers: 500, epoch: 7 | loss: 0.0900473\n",
      "\tspeed: 0.0533s/iter; left time: 165.7049s\n",
      "\titers: 600, epoch: 7 | loss: 0.0867380\n",
      "\tspeed: 0.0534s/iter; left time: 160.5340s\n",
      "\titers: 700, epoch: 7 | loss: 0.0969472\n",
      "\tspeed: 0.0534s/iter; left time: 155.2814s\n",
      "\titers: 800, epoch: 7 | loss: 0.0861391\n",
      "\tspeed: 0.0532s/iter; left time: 149.5787s\n",
      "\titers: 900, epoch: 7 | loss: 0.0882257\n",
      "\tspeed: 0.0531s/iter; left time: 143.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.0986794 Vali Loss: 0.1838279 Test Loss: 0.2055350\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.18572181463241577, rmse:0.43095454573631287, mae:0.2877998948097229, rse:0.5429210066795349\n",
      "Original data scale mse:4445287.0, rmse:2108.385009765625, mae:1414.09912109375, rse:0.148514986038208\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6713250\n",
      "\tspeed: 0.0711s/iter; left time: 636.8543s\n",
      "\titers: 200, epoch: 1 | loss: 0.5746155\n",
      "\tspeed: 0.0420s/iter; left time: 372.5324s\n",
      "\titers: 300, epoch: 1 | loss: 0.4691629\n",
      "\tspeed: 0.0416s/iter; left time: 364.2668s\n",
      "\titers: 400, epoch: 1 | loss: 0.4558076\n",
      "\tspeed: 0.0413s/iter; left time: 357.9231s\n",
      "\titers: 500, epoch: 1 | loss: 0.3989495\n",
      "\tspeed: 0.0413s/iter; left time: 353.5701s\n",
      "\titers: 600, epoch: 1 | loss: 0.3951532\n",
      "\tspeed: 0.0413s/iter; left time: 349.4303s\n",
      "\titers: 700, epoch: 1 | loss: 0.3611161\n",
      "\tspeed: 0.0413s/iter; left time: 345.2523s\n",
      "\titers: 800, epoch: 1 | loss: 0.3683667\n",
      "\tspeed: 0.0409s/iter; left time: 337.9324s\n",
      "\titers: 900, epoch: 1 | loss: 0.4177614\n",
      "\tspeed: 0.0415s/iter; left time: 338.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 906 | Train Loss: 0.4823299 Vali Loss: 0.1297127 Test Loss: 0.1445100\n",
      "Validation loss decreased (inf --> 0.129713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3774882\n",
      "\tspeed: 0.0981s/iter; left time: 790.1355s\n",
      "\titers: 200, epoch: 2 | loss: 0.3590513\n",
      "\tspeed: 0.0414s/iter; left time: 329.3928s\n",
      "\titers: 300, epoch: 2 | loss: 0.3128399\n",
      "\tspeed: 0.0411s/iter; left time: 322.8272s\n",
      "\titers: 400, epoch: 2 | loss: 0.2862418\n",
      "\tspeed: 0.0411s/iter; left time: 318.4109s\n",
      "\titers: 500, epoch: 2 | loss: 0.3366916\n",
      "\tspeed: 0.0411s/iter; left time: 314.9413s\n",
      "\titers: 600, epoch: 2 | loss: 0.3188420\n",
      "\tspeed: 0.0407s/iter; left time: 307.4296s\n",
      "\titers: 700, epoch: 2 | loss: 0.3298711\n",
      "\tspeed: 0.0410s/iter; left time: 305.3138s\n",
      "\titers: 800, epoch: 2 | loss: 0.3207609\n",
      "\tspeed: 0.0405s/iter; left time: 298.1130s\n",
      "\titers: 900, epoch: 2 | loss: 0.3203365\n",
      "\tspeed: 0.0407s/iter; left time: 295.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.39s\n",
      "Steps: 906 | Train Loss: 0.3200334 Vali Loss: 0.0892027 Test Loss: 0.1035133\n",
      "Validation loss decreased (0.129713 --> 0.089203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3195523\n",
      "\tspeed: 0.1027s/iter; left time: 734.1392s\n",
      "\titers: 200, epoch: 3 | loss: 0.2723418\n",
      "\tspeed: 0.0409s/iter; left time: 288.1735s\n",
      "\titers: 300, epoch: 3 | loss: 0.3066047\n",
      "\tspeed: 0.0411s/iter; left time: 285.3017s\n",
      "\titers: 400, epoch: 3 | loss: 0.2739902\n",
      "\tspeed: 0.0405s/iter; left time: 277.3353s\n",
      "\titers: 500, epoch: 3 | loss: 0.3328080\n",
      "\tspeed: 0.0408s/iter; left time: 275.2985s\n",
      "\titers: 600, epoch: 3 | loss: 0.3068560\n",
      "\tspeed: 0.0406s/iter; left time: 269.9660s\n",
      "\titers: 700, epoch: 3 | loss: 0.2571502\n",
      "\tspeed: 0.0405s/iter; left time: 265.3207s\n",
      "\titers: 800, epoch: 3 | loss: 0.2763128\n",
      "\tspeed: 0.0408s/iter; left time: 263.2531s\n",
      "\titers: 900, epoch: 3 | loss: 0.2732482\n",
      "\tspeed: 0.0406s/iter; left time: 257.9999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.2898511 Vali Loss: 0.0879231 Test Loss: 0.1062618\n",
      "Validation loss decreased (0.089203 --> 0.087923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2844734\n",
      "\tspeed: 0.0978s/iter; left time: 610.8170s\n",
      "\titers: 200, epoch: 4 | loss: 0.2732232\n",
      "\tspeed: 0.0409s/iter; left time: 250.9717s\n",
      "\titers: 300, epoch: 4 | loss: 0.2767519\n",
      "\tspeed: 0.0413s/iter; left time: 249.7548s\n",
      "\titers: 400, epoch: 4 | loss: 0.2922099\n",
      "\tspeed: 0.0407s/iter; left time: 241.9880s\n",
      "\titers: 500, epoch: 4 | loss: 0.2302153\n",
      "\tspeed: 0.0407s/iter; left time: 237.5323s\n",
      "\titers: 600, epoch: 4 | loss: 0.3151538\n",
      "\tspeed: 0.0408s/iter; left time: 234.1979s\n",
      "\titers: 700, epoch: 4 | loss: 0.2925580\n",
      "\tspeed: 0.0407s/iter; left time: 229.4470s\n",
      "\titers: 800, epoch: 4 | loss: 0.2975780\n",
      "\tspeed: 0.0404s/iter; left time: 224.0522s\n",
      "\titers: 900, epoch: 4 | loss: 0.3112267\n",
      "\tspeed: 0.0405s/iter; left time: 220.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.21s\n",
      "Steps: 906 | Train Loss: 0.2737008 Vali Loss: 0.0830865 Test Loss: 0.1014789\n",
      "Validation loss decreased (0.087923 --> 0.083086).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2465318\n",
      "\tspeed: 0.0979s/iter; left time: 522.3602s\n",
      "\titers: 200, epoch: 5 | loss: 0.2280588\n",
      "\tspeed: 0.0407s/iter; left time: 213.0662s\n",
      "\titers: 300, epoch: 5 | loss: 0.2604049\n",
      "\tspeed: 0.0407s/iter; left time: 209.0768s\n",
      "\titers: 400, epoch: 5 | loss: 0.2268636\n",
      "\tspeed: 0.0408s/iter; left time: 205.5341s\n",
      "\titers: 500, epoch: 5 | loss: 0.2929680\n",
      "\tspeed: 0.0414s/iter; left time: 204.2966s\n",
      "\titers: 600, epoch: 5 | loss: 0.2141552\n",
      "\tspeed: 0.0415s/iter; left time: 200.6759s\n",
      "\titers: 700, epoch: 5 | loss: 0.2961240\n",
      "\tspeed: 0.0415s/iter; left time: 196.5399s\n",
      "\titers: 800, epoch: 5 | loss: 0.2475485\n",
      "\tspeed: 0.0409s/iter; left time: 189.4521s\n",
      "\titers: 900, epoch: 5 | loss: 0.2456564\n",
      "\tspeed: 0.0408s/iter; left time: 185.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.45s\n",
      "Steps: 906 | Train Loss: 0.2595105 Vali Loss: 0.0909883 Test Loss: 0.1040540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2315773\n",
      "\tspeed: 0.1019s/iter; left time: 451.3820s\n",
      "\titers: 200, epoch: 6 | loss: 0.2623151\n",
      "\tspeed: 0.0459s/iter; left time: 198.6174s\n",
      "\titers: 300, epoch: 6 | loss: 0.2961919\n",
      "\tspeed: 0.0450s/iter; left time: 190.4095s\n",
      "\titers: 400, epoch: 6 | loss: 0.2524416\n",
      "\tspeed: 0.0420s/iter; left time: 173.5357s\n",
      "\titers: 500, epoch: 6 | loss: 0.2610012\n",
      "\tspeed: 0.0421s/iter; left time: 169.7330s\n",
      "\titers: 600, epoch: 6 | loss: 0.2793341\n",
      "\tspeed: 0.0424s/iter; left time: 166.8615s\n",
      "\titers: 700, epoch: 6 | loss: 0.2532963\n",
      "\tspeed: 0.0420s/iter; left time: 160.7202s\n",
      "\titers: 800, epoch: 6 | loss: 0.2478609\n",
      "\tspeed: 0.0410s/iter; left time: 153.0658s\n",
      "\titers: 900, epoch: 6 | loss: 0.2598470\n",
      "\tspeed: 0.0414s/iter; left time: 150.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.40s\n",
      "Steps: 906 | Train Loss: 0.2444963 Vali Loss: 0.0934578 Test Loss: 0.1112469\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2545051\n",
      "\tspeed: 0.0953s/iter; left time: 336.0677s\n",
      "\titers: 200, epoch: 7 | loss: 0.2206395\n",
      "\tspeed: 0.0405s/iter; left time: 138.7239s\n",
      "\titers: 300, epoch: 7 | loss: 0.2069458\n",
      "\tspeed: 0.0407s/iter; left time: 135.3046s\n",
      "\titers: 400, epoch: 7 | loss: 0.2269061\n",
      "\tspeed: 0.0409s/iter; left time: 131.8963s\n",
      "\titers: 500, epoch: 7 | loss: 0.2188151\n",
      "\tspeed: 0.0408s/iter; left time: 127.4390s\n",
      "\titers: 600, epoch: 7 | loss: 0.2116071\n",
      "\tspeed: 0.0410s/iter; left time: 124.1179s\n",
      "\titers: 700, epoch: 7 | loss: 0.2180890\n",
      "\tspeed: 0.0406s/iter; left time: 118.8846s\n",
      "\titers: 800, epoch: 7 | loss: 0.2350762\n",
      "\tspeed: 0.0409s/iter; left time: 115.5154s\n",
      "\titers: 900, epoch: 7 | loss: 0.2312025\n",
      "\tspeed: 0.0410s/iter; left time: 111.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.2293505 Vali Loss: 0.0911001 Test Loss: 0.1068099\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10121527314186096, rmse:0.31814348697662354, mae:0.1955755352973938, rse:0.4017200171947479\n",
      "Original data scale mse:1772951.375, rmse:1331.522216796875, mae:882.83447265625, rse:0.09356920421123505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6387104\n",
      "\tspeed: 0.0439s/iter; left time: 393.4884s\n",
      "\titers: 200, epoch: 1 | loss: 0.5202302\n",
      "\tspeed: 0.0415s/iter; left time: 368.0963s\n",
      "\titers: 300, epoch: 1 | loss: 0.4718112\n",
      "\tspeed: 0.0420s/iter; left time: 367.6984s\n",
      "\titers: 400, epoch: 1 | loss: 0.4226309\n",
      "\tspeed: 0.0420s/iter; left time: 363.4308s\n",
      "\titers: 500, epoch: 1 | loss: 0.3903136\n",
      "\tspeed: 0.0416s/iter; left time: 355.7931s\n",
      "\titers: 600, epoch: 1 | loss: 0.4099773\n",
      "\tspeed: 0.0422s/iter; left time: 356.7406s\n",
      "\titers: 700, epoch: 1 | loss: 0.3962696\n",
      "\tspeed: 0.0424s/iter; left time: 354.1770s\n",
      "\titers: 800, epoch: 1 | loss: 0.3976924\n",
      "\tspeed: 0.0423s/iter; left time: 349.1104s\n",
      "\titers: 900, epoch: 1 | loss: 0.3702214\n",
      "\tspeed: 0.0422s/iter; left time: 344.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 906 | Train Loss: 0.4750207 Vali Loss: 0.1252253 Test Loss: 0.1440151\n",
      "Validation loss decreased (inf --> 0.125225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3238702\n",
      "\tspeed: 0.0983s/iter; left time: 791.6843s\n",
      "\titers: 200, epoch: 2 | loss: 0.3565642\n",
      "\tspeed: 0.0413s/iter; left time: 328.3182s\n",
      "\titers: 300, epoch: 2 | loss: 0.2994523\n",
      "\tspeed: 0.0409s/iter; left time: 321.2571s\n",
      "\titers: 400, epoch: 2 | loss: 0.3117840\n",
      "\tspeed: 0.0405s/iter; left time: 314.3972s\n",
      "\titers: 500, epoch: 2 | loss: 0.3382605\n",
      "\tspeed: 0.0404s/iter; left time: 309.6441s\n",
      "\titers: 600, epoch: 2 | loss: 0.2482596\n",
      "\tspeed: 0.0406s/iter; left time: 306.7462s\n",
      "\titers: 700, epoch: 2 | loss: 0.2856577\n",
      "\tspeed: 0.0405s/iter; left time: 301.9089s\n",
      "\titers: 800, epoch: 2 | loss: 0.2650714\n",
      "\tspeed: 0.0404s/iter; left time: 296.7895s\n",
      "\titers: 900, epoch: 2 | loss: 0.2874792\n",
      "\tspeed: 0.0405s/iter; left time: 293.6864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.3208735 Vali Loss: 0.0921786 Test Loss: 0.1085492\n",
      "Validation loss decreased (0.125225 --> 0.092179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2825559\n",
      "\tspeed: 0.0984s/iter; left time: 703.3786s\n",
      "\titers: 200, epoch: 3 | loss: 0.2785680\n",
      "\tspeed: 0.0404s/iter; left time: 285.0572s\n",
      "\titers: 300, epoch: 3 | loss: 0.3291669\n",
      "\tspeed: 0.0408s/iter; left time: 283.6369s\n",
      "\titers: 400, epoch: 3 | loss: 0.2636746\n",
      "\tspeed: 0.0408s/iter; left time: 279.1684s\n",
      "\titers: 500, epoch: 3 | loss: 0.2784389\n",
      "\tspeed: 0.0408s/iter; left time: 275.5807s\n",
      "\titers: 600, epoch: 3 | loss: 0.2625436\n",
      "\tspeed: 0.0405s/iter; left time: 269.3736s\n",
      "\titers: 700, epoch: 3 | loss: 0.3021619\n",
      "\tspeed: 0.0407s/iter; left time: 266.4316s\n",
      "\titers: 800, epoch: 3 | loss: 0.3065397\n",
      "\tspeed: 0.0407s/iter; left time: 262.2978s\n",
      "\titers: 900, epoch: 3 | loss: 0.2815774\n",
      "\tspeed: 0.0405s/iter; left time: 257.4468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.14s\n",
      "Steps: 906 | Train Loss: 0.2897735 Vali Loss: 0.0840460 Test Loss: 0.0999372\n",
      "Validation loss decreased (0.092179 --> 0.084046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3026658\n",
      "\tspeed: 0.1015s/iter; left time: 633.4493s\n",
      "\titers: 200, epoch: 4 | loss: 0.2818322\n",
      "\tspeed: 0.0406s/iter; left time: 249.5643s\n",
      "\titers: 300, epoch: 4 | loss: 0.3274560\n",
      "\tspeed: 0.0403s/iter; left time: 243.8232s\n",
      "\titers: 400, epoch: 4 | loss: 0.2884991\n",
      "\tspeed: 0.0349s/iter; left time: 207.2581s\n",
      "\titers: 500, epoch: 4 | loss: 0.2975112\n",
      "\tspeed: 0.0403s/iter; left time: 235.4278s\n",
      "\titers: 600, epoch: 4 | loss: 0.2391492\n",
      "\tspeed: 0.0406s/iter; left time: 233.2116s\n",
      "\titers: 700, epoch: 4 | loss: 0.2316259\n",
      "\tspeed: 0.0406s/iter; left time: 229.2331s\n",
      "\titers: 800, epoch: 4 | loss: 0.2406767\n",
      "\tspeed: 0.0396s/iter; left time: 219.3908s\n",
      "\titers: 900, epoch: 4 | loss: 0.2454505\n",
      "\tspeed: 0.0406s/iter; left time: 221.2038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.37s\n",
      "Steps: 906 | Train Loss: 0.2776075 Vali Loss: 0.0879932 Test Loss: 0.1045437\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2722987\n",
      "\tspeed: 0.0953s/iter; left time: 508.4674s\n",
      "\titers: 200, epoch: 5 | loss: 0.3304349\n",
      "\tspeed: 0.0417s/iter; left time: 218.3732s\n",
      "\titers: 300, epoch: 5 | loss: 0.2579944\n",
      "\tspeed: 0.0421s/iter; left time: 216.4062s\n",
      "\titers: 400, epoch: 5 | loss: 0.2711307\n",
      "\tspeed: 0.0422s/iter; left time: 212.4489s\n",
      "\titers: 500, epoch: 5 | loss: 0.2844849\n",
      "\tspeed: 0.0416s/iter; left time: 205.5543s\n",
      "\titers: 600, epoch: 5 | loss: 0.2492066\n",
      "\tspeed: 0.0420s/iter; left time: 203.0845s\n",
      "\titers: 700, epoch: 5 | loss: 0.2619545\n",
      "\tspeed: 0.0410s/iter; left time: 194.2880s\n",
      "\titers: 800, epoch: 5 | loss: 0.2553905\n",
      "\tspeed: 0.0413s/iter; left time: 191.4817s\n",
      "\titers: 900, epoch: 5 | loss: 0.2662020\n",
      "\tspeed: 0.0411s/iter; left time: 186.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 906 | Train Loss: 0.2636664 Vali Loss: 0.0895833 Test Loss: 0.1048924\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2702800\n",
      "\tspeed: 0.0956s/iter; left time: 423.3911s\n",
      "\titers: 200, epoch: 6 | loss: 0.2116584\n",
      "\tspeed: 0.0415s/iter; left time: 179.5900s\n",
      "\titers: 300, epoch: 6 | loss: 0.2352795\n",
      "\tspeed: 0.0410s/iter; left time: 173.5184s\n",
      "\titers: 400, epoch: 6 | loss: 0.2390181\n",
      "\tspeed: 0.0409s/iter; left time: 168.7737s\n",
      "\titers: 500, epoch: 6 | loss: 0.2512813\n",
      "\tspeed: 0.0412s/iter; left time: 165.8862s\n",
      "\titers: 600, epoch: 6 | loss: 0.2593416\n",
      "\tspeed: 0.0408s/iter; left time: 160.3884s\n",
      "\titers: 700, epoch: 6 | loss: 0.2502033\n",
      "\tspeed: 0.0409s/iter; left time: 156.5038s\n",
      "\titers: 800, epoch: 6 | loss: 0.2122997\n",
      "\tspeed: 0.0411s/iter; left time: 153.3358s\n",
      "\titers: 900, epoch: 6 | loss: 0.2274542\n",
      "\tspeed: 0.0407s/iter; left time: 147.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.39s\n",
      "Steps: 906 | Train Loss: 0.2505443 Vali Loss: 0.0889714 Test Loss: 0.0995042\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.09998292475938797, rmse:0.31620076298713684, mae:0.1991349756717682, rse:0.3992669880390167\n",
      "Original data scale mse:1705655.875, rmse:1306.007568359375, mae:881.322265625, rse:0.09177622944116592\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7076046\n",
      "\tspeed: 0.0802s/iter; left time: 716.7557s\n",
      "\titers: 200, epoch: 1 | loss: 0.6578112\n",
      "\tspeed: 0.0504s/iter; left time: 445.4731s\n",
      "\titers: 300, epoch: 1 | loss: 0.5769344\n",
      "\tspeed: 0.0506s/iter; left time: 442.0016s\n",
      "\titers: 400, epoch: 1 | loss: 0.5587603\n",
      "\tspeed: 0.0506s/iter; left time: 437.0378s\n",
      "\titers: 500, epoch: 1 | loss: 0.5470400\n",
      "\tspeed: 0.0505s/iter; left time: 430.9606s\n",
      "\titers: 600, epoch: 1 | loss: 0.5232704\n",
      "\tspeed: 0.0504s/iter; left time: 425.4894s\n",
      "\titers: 700, epoch: 1 | loss: 0.5129842\n",
      "\tspeed: 0.0502s/iter; left time: 418.3993s\n",
      "\titers: 800, epoch: 1 | loss: 0.5082648\n",
      "\tspeed: 0.0471s/iter; left time: 387.7673s\n",
      "\titers: 900, epoch: 1 | loss: 0.5144677\n",
      "\tspeed: 0.0473s/iter; left time: 385.3660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.67s\n",
      "Steps: 904 | Train Loss: 0.5785226 Vali Loss: 0.2295883 Test Loss: 0.2638969\n",
      "Validation loss decreased (inf --> 0.229588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4732634\n",
      "\tspeed: 0.1167s/iter; left time: 938.1659s\n",
      "\titers: 200, epoch: 2 | loss: 0.4678551\n",
      "\tspeed: 0.0478s/iter; left time: 379.1766s\n",
      "\titers: 300, epoch: 2 | loss: 0.4294797\n",
      "\tspeed: 0.0476s/iter; left time: 372.7387s\n",
      "\titers: 400, epoch: 2 | loss: 0.4149728\n",
      "\tspeed: 0.0478s/iter; left time: 370.0574s\n",
      "\titers: 500, epoch: 2 | loss: 0.4075000\n",
      "\tspeed: 0.0476s/iter; left time: 363.6969s\n",
      "\titers: 600, epoch: 2 | loss: 0.4256922\n",
      "\tspeed: 0.0476s/iter; left time: 358.6389s\n",
      "\titers: 700, epoch: 2 | loss: 0.3983435\n",
      "\tspeed: 0.0476s/iter; left time: 354.0736s\n",
      "\titers: 800, epoch: 2 | loss: 0.3994232\n",
      "\tspeed: 0.0476s/iter; left time: 349.5357s\n",
      "\titers: 900, epoch: 2 | loss: 0.3774057\n",
      "\tspeed: 0.0476s/iter; left time: 344.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 904 | Train Loss: 0.4255902 Vali Loss: 0.1541461 Test Loss: 0.1693270\n",
      "Validation loss decreased (0.229588 --> 0.154146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3967619\n",
      "\tspeed: 0.1150s/iter; left time: 820.2421s\n",
      "\titers: 200, epoch: 3 | loss: 0.3920103\n",
      "\tspeed: 0.0474s/iter; left time: 333.5479s\n",
      "\titers: 300, epoch: 3 | loss: 0.3928330\n",
      "\tspeed: 0.0475s/iter; left time: 329.4105s\n",
      "\titers: 400, epoch: 3 | loss: 0.3925671\n",
      "\tspeed: 0.0474s/iter; left time: 323.8783s\n",
      "\titers: 500, epoch: 3 | loss: 0.3702200\n",
      "\tspeed: 0.0471s/iter; left time: 317.1831s\n",
      "\titers: 600, epoch: 3 | loss: 0.3681182\n",
      "\tspeed: 0.0472s/iter; left time: 312.9214s\n",
      "\titers: 700, epoch: 3 | loss: 0.3606570\n",
      "\tspeed: 0.0471s/iter; left time: 307.9082s\n",
      "\titers: 800, epoch: 3 | loss: 0.4051598\n",
      "\tspeed: 0.0476s/iter; left time: 306.2310s\n",
      "\titers: 900, epoch: 3 | loss: 0.4003642\n",
      "\tspeed: 0.0475s/iter; left time: 300.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.03s\n",
      "Steps: 904 | Train Loss: 0.3784842 Vali Loss: 0.1468547 Test Loss: 0.1658393\n",
      "Validation loss decreased (0.154146 --> 0.146855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3489684\n",
      "\tspeed: 0.1156s/iter; left time: 720.1678s\n",
      "\titers: 200, epoch: 4 | loss: 0.3631746\n",
      "\tspeed: 0.0470s/iter; left time: 288.1459s\n",
      "\titers: 300, epoch: 4 | loss: 0.3305521\n",
      "\tspeed: 0.0474s/iter; left time: 286.0212s\n",
      "\titers: 400, epoch: 4 | loss: 0.3837603\n",
      "\tspeed: 0.0474s/iter; left time: 281.2414s\n",
      "\titers: 500, epoch: 4 | loss: 0.3715574\n",
      "\tspeed: 0.0475s/iter; left time: 276.9851s\n",
      "\titers: 600, epoch: 4 | loss: 0.3740263\n",
      "\tspeed: 0.0477s/iter; left time: 273.2213s\n",
      "\titers: 700, epoch: 4 | loss: 0.3437344\n",
      "\tspeed: 0.0472s/iter; left time: 265.6247s\n",
      "\titers: 800, epoch: 4 | loss: 0.3518785\n",
      "\tspeed: 0.0473s/iter; left time: 261.4097s\n",
      "\titers: 900, epoch: 4 | loss: 0.3361613\n",
      "\tspeed: 0.0474s/iter; left time: 257.1632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.3586428 Vali Loss: 0.1560999 Test Loss: 0.1877114\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3248732\n",
      "\tspeed: 0.1131s/iter; left time: 602.5082s\n",
      "\titers: 200, epoch: 5 | loss: 0.3218637\n",
      "\tspeed: 0.0476s/iter; left time: 248.6593s\n",
      "\titers: 300, epoch: 5 | loss: 0.3424231\n",
      "\tspeed: 0.0476s/iter; left time: 244.0626s\n",
      "\titers: 400, epoch: 5 | loss: 0.3658382\n",
      "\tspeed: 0.0476s/iter; left time: 239.0712s\n",
      "\titers: 500, epoch: 5 | loss: 0.3252520\n",
      "\tspeed: 0.0476s/iter; left time: 234.3015s\n",
      "\titers: 600, epoch: 5 | loss: 0.3373571\n",
      "\tspeed: 0.0478s/iter; left time: 230.7813s\n",
      "\titers: 700, epoch: 5 | loss: 0.3443996\n",
      "\tspeed: 0.0477s/iter; left time: 225.3664s\n",
      "\titers: 800, epoch: 5 | loss: 0.3433782\n",
      "\tspeed: 0.0477s/iter; left time: 220.5594s\n",
      "\titers: 900, epoch: 5 | loss: 0.3306960\n",
      "\tspeed: 0.0474s/iter; left time: 214.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.3405212 Vali Loss: 0.1581815 Test Loss: 0.1783044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2823818\n",
      "\tspeed: 0.1144s/iter; left time: 505.9786s\n",
      "\titers: 200, epoch: 6 | loss: 0.3170049\n",
      "\tspeed: 0.0501s/iter; left time: 216.3365s\n",
      "\titers: 300, epoch: 6 | loss: 0.3333640\n",
      "\tspeed: 0.0499s/iter; left time: 210.6539s\n",
      "\titers: 400, epoch: 6 | loss: 0.3317137\n",
      "\tspeed: 0.0501s/iter; left time: 206.5240s\n",
      "\titers: 500, epoch: 6 | loss: 0.3278592\n",
      "\tspeed: 0.0500s/iter; left time: 201.1922s\n",
      "\titers: 600, epoch: 6 | loss: 0.3134820\n",
      "\tspeed: 0.0500s/iter; left time: 196.0346s\n",
      "\titers: 700, epoch: 6 | loss: 0.2773586\n",
      "\tspeed: 0.0501s/iter; left time: 191.3630s\n",
      "\titers: 800, epoch: 6 | loss: 0.3259693\n",
      "\tspeed: 0.0501s/iter; left time: 186.6063s\n",
      "\titers: 900, epoch: 6 | loss: 0.3263755\n",
      "\tspeed: 0.0502s/iter; left time: 181.8907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.42s\n",
      "Steps: 904 | Train Loss: 0.3207081 Vali Loss: 0.1650522 Test Loss: 0.1883738\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.1658245027065277, rmse:0.40721553564071655, mae:0.26516279578208923, rse:0.513576865196228\n",
      "Original data scale mse:3241397.75, rmse:1800.38818359375, mae:1225.7508544921875, rse:0.12670066952705383\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6672028\n",
      "\tspeed: 0.0493s/iter; left time: 440.9679s\n",
      "\titers: 200, epoch: 1 | loss: 0.6411328\n",
      "\tspeed: 0.0475s/iter; left time: 420.2654s\n",
      "\titers: 300, epoch: 1 | loss: 0.6009921\n",
      "\tspeed: 0.0476s/iter; left time: 416.4155s\n",
      "\titers: 400, epoch: 1 | loss: 0.5562096\n",
      "\tspeed: 0.0476s/iter; left time: 411.1776s\n",
      "\titers: 500, epoch: 1 | loss: 0.5659007\n",
      "\tspeed: 0.0478s/iter; left time: 407.8408s\n",
      "\titers: 600, epoch: 1 | loss: 0.4958803\n",
      "\tspeed: 0.0477s/iter; left time: 402.4228s\n",
      "\titers: 700, epoch: 1 | loss: 0.5227539\n",
      "\tspeed: 0.0476s/iter; left time: 396.9508s\n",
      "\titers: 800, epoch: 1 | loss: 0.5079434\n",
      "\tspeed: 0.0475s/iter; left time: 391.2304s\n",
      "\titers: 900, epoch: 1 | loss: 0.5088897\n",
      "\tspeed: 0.0476s/iter; left time: 387.3342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.5751543 Vali Loss: 0.2293541 Test Loss: 0.2676332\n",
      "Validation loss decreased (inf --> 0.229354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5067975\n",
      "\tspeed: 0.1159s/iter; left time: 931.2692s\n",
      "\titers: 200, epoch: 2 | loss: 0.5009702\n",
      "\tspeed: 0.0474s/iter; left time: 376.5013s\n",
      "\titers: 300, epoch: 2 | loss: 0.4146907\n",
      "\tspeed: 0.0471s/iter; left time: 369.2055s\n",
      "\titers: 400, epoch: 2 | loss: 0.4065040\n",
      "\tspeed: 0.0474s/iter; left time: 366.4733s\n",
      "\titers: 500, epoch: 2 | loss: 0.4014253\n",
      "\tspeed: 0.0474s/iter; left time: 362.2084s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311000\n",
      "\tspeed: 0.0476s/iter; left time: 358.6814s\n",
      "\titers: 700, epoch: 2 | loss: 0.3940893\n",
      "\tspeed: 0.0476s/iter; left time: 353.7970s\n",
      "\titers: 800, epoch: 2 | loss: 0.3867381\n",
      "\tspeed: 0.0474s/iter; left time: 347.4309s\n",
      "\titers: 900, epoch: 2 | loss: 0.3697745\n",
      "\tspeed: 0.0474s/iter; left time: 342.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.4226489 Vali Loss: 0.1488076 Test Loss: 0.1676236\n",
      "Validation loss decreased (0.229354 --> 0.148808).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3767413\n",
      "\tspeed: 0.1199s/iter; left time: 855.2428s\n",
      "\titers: 200, epoch: 3 | loss: 0.3853996\n",
      "\tspeed: 0.0502s/iter; left time: 353.2613s\n",
      "\titers: 300, epoch: 3 | loss: 0.3907964\n",
      "\tspeed: 0.0480s/iter; left time: 333.1190s\n",
      "\titers: 400, epoch: 3 | loss: 0.3817881\n",
      "\tspeed: 0.0479s/iter; left time: 327.1148s\n",
      "\titers: 500, epoch: 3 | loss: 0.3638865\n",
      "\tspeed: 0.0479s/iter; left time: 322.1902s\n",
      "\titers: 600, epoch: 3 | loss: 0.3909920\n",
      "\tspeed: 0.0477s/iter; left time: 316.3597s\n",
      "\titers: 700, epoch: 3 | loss: 0.3906323\n",
      "\tspeed: 0.0477s/iter; left time: 311.5878s\n",
      "\titers: 800, epoch: 3 | loss: 0.3639559\n",
      "\tspeed: 0.0476s/iter; left time: 306.4525s\n",
      "\titers: 900, epoch: 3 | loss: 0.3295690\n",
      "\tspeed: 0.0487s/iter; left time: 308.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.08s\n",
      "Steps: 904 | Train Loss: 0.3760676 Vali Loss: 0.1517964 Test Loss: 0.1692900\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3557675\n",
      "\tspeed: 0.1128s/iter; left time: 702.3462s\n",
      "\titers: 200, epoch: 4 | loss: 0.3477727\n",
      "\tspeed: 0.0476s/iter; left time: 291.7067s\n",
      "\titers: 300, epoch: 4 | loss: 0.3481817\n",
      "\tspeed: 0.0473s/iter; left time: 285.3461s\n",
      "\titers: 400, epoch: 4 | loss: 0.3668278\n",
      "\tspeed: 0.0475s/iter; left time: 281.8820s\n",
      "\titers: 500, epoch: 4 | loss: 0.3499805\n",
      "\tspeed: 0.0475s/iter; left time: 276.7011s\n",
      "\titers: 600, epoch: 4 | loss: 0.3646893\n",
      "\tspeed: 0.0474s/iter; left time: 271.6823s\n",
      "\titers: 700, epoch: 4 | loss: 0.3595571\n",
      "\tspeed: 0.0476s/iter; left time: 267.9632s\n",
      "\titers: 800, epoch: 4 | loss: 0.3383426\n",
      "\tspeed: 0.0476s/iter; left time: 263.0439s\n",
      "\titers: 900, epoch: 4 | loss: 0.3377383\n",
      "\tspeed: 0.0474s/iter; left time: 257.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.3568804 Vali Loss: 0.1482026 Test Loss: 0.1685868\n",
      "Validation loss decreased (0.148808 --> 0.148203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3419493\n",
      "\tspeed: 0.1156s/iter; left time: 615.3142s\n",
      "\titers: 200, epoch: 5 | loss: 0.3460248\n",
      "\tspeed: 0.0477s/iter; left time: 249.3727s\n",
      "\titers: 300, epoch: 5 | loss: 0.3735531\n",
      "\tspeed: 0.0478s/iter; left time: 244.7819s\n",
      "\titers: 400, epoch: 5 | loss: 0.3435251\n",
      "\tspeed: 0.0475s/iter; left time: 238.8335s\n",
      "\titers: 500, epoch: 5 | loss: 0.3315926\n",
      "\tspeed: 0.0478s/iter; left time: 235.4938s\n",
      "\titers: 600, epoch: 5 | loss: 0.3124721\n",
      "\tspeed: 0.0474s/iter; left time: 228.6926s\n",
      "\titers: 700, epoch: 5 | loss: 0.3316106\n",
      "\tspeed: 0.0477s/iter; left time: 225.4776s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173794\n",
      "\tspeed: 0.0477s/iter; left time: 220.8379s\n",
      "\titers: 900, epoch: 5 | loss: 0.3123973\n",
      "\tspeed: 0.0476s/iter; left time: 215.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.31s\n",
      "Steps: 904 | Train Loss: 0.3386473 Vali Loss: 0.1553063 Test Loss: 0.1836271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3127868\n",
      "\tspeed: 0.1126s/iter; left time: 497.7198s\n",
      "\titers: 200, epoch: 6 | loss: 0.3188365\n",
      "\tspeed: 0.0475s/iter; left time: 205.1790s\n",
      "\titers: 300, epoch: 6 | loss: 0.3285469\n",
      "\tspeed: 0.0475s/iter; left time: 200.6273s\n",
      "\titers: 400, epoch: 6 | loss: 0.3047352\n",
      "\tspeed: 0.0476s/iter; left time: 196.2882s\n",
      "\titers: 500, epoch: 6 | loss: 0.3122153\n",
      "\tspeed: 0.0477s/iter; left time: 191.7161s\n",
      "\titers: 600, epoch: 6 | loss: 0.3297661\n",
      "\tspeed: 0.0475s/iter; left time: 186.3747s\n",
      "\titers: 700, epoch: 6 | loss: 0.3428793\n",
      "\tspeed: 0.0478s/iter; left time: 182.5869s\n",
      "\titers: 800, epoch: 6 | loss: 0.3054907\n",
      "\tspeed: 0.0474s/iter; left time: 176.4158s\n",
      "\titers: 900, epoch: 6 | loss: 0.2888380\n",
      "\tspeed: 0.0474s/iter; left time: 171.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.21s\n",
      "Steps: 904 | Train Loss: 0.3165271 Vali Loss: 0.1582868 Test Loss: 0.1829295\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2851221\n",
      "\tspeed: 0.1140s/iter; left time: 400.9939s\n",
      "\titers: 200, epoch: 7 | loss: 0.2907151\n",
      "\tspeed: 0.0474s/iter; left time: 162.0832s\n",
      "\titers: 300, epoch: 7 | loss: 0.2974072\n",
      "\tspeed: 0.0478s/iter; left time: 158.5306s\n",
      "\titers: 400, epoch: 7 | loss: 0.2852646\n",
      "\tspeed: 0.0479s/iter; left time: 154.1008s\n",
      "\titers: 500, epoch: 7 | loss: 0.3227853\n",
      "\tspeed: 0.0476s/iter; left time: 148.3787s\n",
      "\titers: 600, epoch: 7 | loss: 0.2930651\n",
      "\tspeed: 0.0476s/iter; left time: 143.7180s\n",
      "\titers: 700, epoch: 7 | loss: 0.3022570\n",
      "\tspeed: 0.0475s/iter; left time: 138.4527s\n",
      "\titers: 800, epoch: 7 | loss: 0.2779420\n",
      "\tspeed: 0.0476s/iter; left time: 134.1450s\n",
      "\titers: 900, epoch: 7 | loss: 0.2702541\n",
      "\tspeed: 0.0476s/iter; left time: 129.2359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.2941211 Vali Loss: 0.1734410 Test Loss: 0.1993210\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16867855191230774, rmse:0.41070494055747986, mae:0.26371267437934875, rse:0.5179775953292847\n",
      "Original data scale mse:3074052.25, rmse:1753.2974853515625, mae:1195.16259765625, rse:0.12338671088218689\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7030319\n",
      "\tspeed: 0.0839s/iter; left time: 748.5235s\n",
      "\titers: 200, epoch: 1 | loss: 0.6379470\n",
      "\tspeed: 0.0540s/iter; left time: 476.5007s\n",
      "\titers: 300, epoch: 1 | loss: 0.6583493\n",
      "\tspeed: 0.0540s/iter; left time: 471.2133s\n",
      "\titers: 400, epoch: 1 | loss: 0.6269465\n",
      "\tspeed: 0.0535s/iter; left time: 461.3240s\n",
      "\titers: 500, epoch: 1 | loss: 0.6083505\n",
      "\tspeed: 0.0534s/iter; left time: 455.4200s\n",
      "\titers: 600, epoch: 1 | loss: 0.6066701\n",
      "\tspeed: 0.0535s/iter; left time: 450.2474s\n",
      "\titers: 700, epoch: 1 | loss: 0.5861924\n",
      "\tspeed: 0.0534s/iter; left time: 444.0215s\n",
      "\titers: 800, epoch: 1 | loss: 0.6097019\n",
      "\tspeed: 0.0532s/iter; left time: 437.7048s\n",
      "\titers: 900, epoch: 1 | loss: 0.5756783\n",
      "\tspeed: 0.0540s/iter; left time: 438.2281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.20s\n",
      "Steps: 902 | Train Loss: 0.6260541 Vali Loss: 0.3185092 Test Loss: 0.3676021\n",
      "Validation loss decreased (inf --> 0.318509).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5736175\n",
      "\tspeed: 0.1331s/iter; left time: 1067.3181s\n",
      "\titers: 200, epoch: 2 | loss: 0.5195261\n",
      "\tspeed: 0.0529s/iter; left time: 418.9155s\n",
      "\titers: 300, epoch: 2 | loss: 0.4741110\n",
      "\tspeed: 0.0533s/iter; left time: 416.6689s\n",
      "\titers: 400, epoch: 2 | loss: 0.4486416\n",
      "\tspeed: 0.0532s/iter; left time: 410.4720s\n",
      "\titers: 500, epoch: 2 | loss: 0.4234707\n",
      "\tspeed: 0.0535s/iter; left time: 407.7040s\n",
      "\titers: 600, epoch: 2 | loss: 0.4446415\n",
      "\tspeed: 0.0534s/iter; left time: 401.6814s\n",
      "\titers: 700, epoch: 2 | loss: 0.3860600\n",
      "\tspeed: 0.0536s/iter; left time: 397.3061s\n",
      "\titers: 800, epoch: 2 | loss: 0.3970504\n",
      "\tspeed: 0.0531s/iter; left time: 388.4043s\n",
      "\titers: 900, epoch: 2 | loss: 0.3983404\n",
      "\tspeed: 0.0533s/iter; left time: 384.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.34s\n",
      "Steps: 902 | Train Loss: 0.4623911 Vali Loss: 0.1713549 Test Loss: 0.2025613\n",
      "Validation loss decreased (0.318509 --> 0.171355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3905887\n",
      "\tspeed: 0.1376s/iter; left time: 979.6159s\n",
      "\titers: 200, epoch: 3 | loss: 0.4174222\n",
      "\tspeed: 0.0534s/iter; left time: 375.0495s\n",
      "\titers: 300, epoch: 3 | loss: 0.4136868\n",
      "\tspeed: 0.0532s/iter; left time: 368.1868s\n",
      "\titers: 400, epoch: 3 | loss: 0.4274124\n",
      "\tspeed: 0.0530s/iter; left time: 361.4051s\n",
      "\titers: 500, epoch: 3 | loss: 0.4152164\n",
      "\tspeed: 0.0533s/iter; left time: 357.9887s\n",
      "\titers: 600, epoch: 3 | loss: 0.3837762\n",
      "\tspeed: 0.0533s/iter; left time: 352.4076s\n",
      "\titers: 700, epoch: 3 | loss: 0.3787870\n",
      "\tspeed: 0.0532s/iter; left time: 346.8958s\n",
      "\titers: 800, epoch: 3 | loss: 0.3964634\n",
      "\tspeed: 0.0533s/iter; left time: 341.7249s\n",
      "\titers: 900, epoch: 3 | loss: 0.3896996\n",
      "\tspeed: 0.0533s/iter; left time: 336.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.3983761 Vali Loss: 0.1663148 Test Loss: 0.1848693\n",
      "Validation loss decreased (0.171355 --> 0.166315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3883315\n",
      "\tspeed: 0.1352s/iter; left time: 840.1276s\n",
      "\titers: 200, epoch: 4 | loss: 0.3728841\n",
      "\tspeed: 0.0538s/iter; left time: 328.9867s\n",
      "\titers: 300, epoch: 4 | loss: 0.4123284\n",
      "\tspeed: 0.0533s/iter; left time: 320.4594s\n",
      "\titers: 400, epoch: 4 | loss: 0.3718892\n",
      "\tspeed: 0.0534s/iter; left time: 316.1063s\n",
      "\titers: 500, epoch: 4 | loss: 0.3651274\n",
      "\tspeed: 0.0536s/iter; left time: 311.4453s\n",
      "\titers: 600, epoch: 4 | loss: 0.3572811\n",
      "\tspeed: 0.0533s/iter; left time: 304.6674s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860814\n",
      "\tspeed: 0.0534s/iter; left time: 300.0396s\n",
      "\titers: 800, epoch: 4 | loss: 0.3816961\n",
      "\tspeed: 0.0533s/iter; left time: 293.9776s\n",
      "\titers: 900, epoch: 4 | loss: 0.3650135\n",
      "\tspeed: 0.0532s/iter; left time: 288.2238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.3741104 Vali Loss: 0.1641398 Test Loss: 0.1942639\n",
      "Validation loss decreased (0.166315 --> 0.164140).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3342488\n",
      "\tspeed: 0.1323s/iter; left time: 702.9499s\n",
      "\titers: 200, epoch: 5 | loss: 0.3426462\n",
      "\tspeed: 0.0536s/iter; left time: 279.2700s\n",
      "\titers: 300, epoch: 5 | loss: 0.3665124\n",
      "\tspeed: 0.0535s/iter; left time: 273.3211s\n",
      "\titers: 400, epoch: 5 | loss: 0.3555437\n",
      "\tspeed: 0.0532s/iter; left time: 266.5344s\n",
      "\titers: 500, epoch: 5 | loss: 0.3538319\n",
      "\tspeed: 0.0535s/iter; left time: 262.9908s\n",
      "\titers: 600, epoch: 5 | loss: 0.3626565\n",
      "\tspeed: 0.0535s/iter; left time: 257.4855s\n",
      "\titers: 700, epoch: 5 | loss: 0.3609807\n",
      "\tspeed: 0.0536s/iter; left time: 252.4125s\n",
      "\titers: 800, epoch: 5 | loss: 0.3420316\n",
      "\tspeed: 0.0533s/iter; left time: 245.7224s\n",
      "\titers: 900, epoch: 5 | loss: 0.3177894\n",
      "\tspeed: 0.0535s/iter; left time: 241.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.3497111 Vali Loss: 0.1779226 Test Loss: 0.1954813\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3193985\n",
      "\tspeed: 0.1287s/iter; left time: 567.6670s\n",
      "\titers: 200, epoch: 6 | loss: 0.3323399\n",
      "\tspeed: 0.0530s/iter; left time: 228.6441s\n",
      "\titers: 300, epoch: 6 | loss: 0.3176599\n",
      "\tspeed: 0.0531s/iter; left time: 223.4800s\n",
      "\titers: 400, epoch: 6 | loss: 0.3318381\n",
      "\tspeed: 0.0526s/iter; left time: 216.2846s\n",
      "\titers: 500, epoch: 6 | loss: 0.3247978\n",
      "\tspeed: 0.0529s/iter; left time: 212.1795s\n",
      "\titers: 600, epoch: 6 | loss: 0.3188559\n",
      "\tspeed: 0.0525s/iter; left time: 205.2728s\n",
      "\titers: 700, epoch: 6 | loss: 0.3107843\n",
      "\tspeed: 0.0526s/iter; left time: 200.5402s\n",
      "\titers: 800, epoch: 6 | loss: 0.3002223\n",
      "\tspeed: 0.0529s/iter; left time: 196.2235s\n",
      "\titers: 900, epoch: 6 | loss: 0.3081976\n",
      "\tspeed: 0.0528s/iter; left time: 190.5044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.82s\n",
      "Steps: 902 | Train Loss: 0.3248961 Vali Loss: 0.1818803 Test Loss: 0.2120247\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3027043\n",
      "\tspeed: 0.1293s/iter; left time: 453.5444s\n",
      "\titers: 200, epoch: 7 | loss: 0.3187273\n",
      "\tspeed: 0.0535s/iter; left time: 182.5042s\n",
      "\titers: 300, epoch: 7 | loss: 0.2836799\n",
      "\tspeed: 0.0535s/iter; left time: 177.1857s\n",
      "\titers: 400, epoch: 7 | loss: 0.2965950\n",
      "\tspeed: 0.0535s/iter; left time: 171.8120s\n",
      "\titers: 500, epoch: 7 | loss: 0.3029802\n",
      "\tspeed: 0.0535s/iter; left time: 166.4681s\n",
      "\titers: 600, epoch: 7 | loss: 0.2989697\n",
      "\tspeed: 0.0536s/iter; left time: 161.2123s\n",
      "\titers: 700, epoch: 7 | loss: 0.2894181\n",
      "\tspeed: 0.0534s/iter; left time: 155.3672s\n",
      "\titers: 800, epoch: 7 | loss: 0.2712937\n",
      "\tspeed: 0.0534s/iter; left time: 149.8770s\n",
      "\titers: 900, epoch: 7 | loss: 0.2549787\n",
      "\tspeed: 0.0536s/iter; left time: 145.0834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.3009742 Vali Loss: 0.1985542 Test Loss: 0.2236999\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.1943083256483078, rmse:0.4408041834831238, mae:0.29183581471443176, rse:0.5553297400474548\n",
      "Original data scale mse:4601502.0, rmse:2145.111083984375, mae:1414.7354736328125, rse:0.1511019915342331\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6723502\n",
      "\tspeed: 0.0548s/iter; left time: 488.8549s\n",
      "\titers: 200, epoch: 1 | loss: 0.6609371\n",
      "\tspeed: 0.0533s/iter; left time: 470.0426s\n",
      "\titers: 300, epoch: 1 | loss: 0.6070185\n",
      "\tspeed: 0.0532s/iter; left time: 464.2008s\n",
      "\titers: 400, epoch: 1 | loss: 0.6146190\n",
      "\tspeed: 0.0533s/iter; left time: 459.4865s\n",
      "\titers: 500, epoch: 1 | loss: 0.6127619\n",
      "\tspeed: 0.0531s/iter; left time: 452.3338s\n",
      "\titers: 600, epoch: 1 | loss: 0.5725184\n",
      "\tspeed: 0.0528s/iter; left time: 444.2240s\n",
      "\titers: 700, epoch: 1 | loss: 0.5825441\n",
      "\tspeed: 0.0532s/iter; left time: 442.7166s\n",
      "\titers: 800, epoch: 1 | loss: 0.5778645\n",
      "\tspeed: 0.0535s/iter; left time: 439.8502s\n",
      "\titers: 900, epoch: 1 | loss: 0.5800887\n",
      "\tspeed: 0.0532s/iter; left time: 432.2504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.22s\n",
      "Steps: 902 | Train Loss: 0.6227781 Vali Loss: 0.3165659 Test Loss: 0.3747235\n",
      "Validation loss decreased (inf --> 0.316566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5546201\n",
      "\tspeed: 0.1338s/iter; left time: 1073.0040s\n",
      "\titers: 200, epoch: 2 | loss: 0.5001150\n",
      "\tspeed: 0.0533s/iter; left time: 422.0764s\n",
      "\titers: 300, epoch: 2 | loss: 0.4752352\n",
      "\tspeed: 0.0534s/iter; left time: 417.8601s\n",
      "\titers: 400, epoch: 2 | loss: 0.4362716\n",
      "\tspeed: 0.0535s/iter; left time: 412.9809s\n",
      "\titers: 500, epoch: 2 | loss: 0.4830326\n",
      "\tspeed: 0.0537s/iter; left time: 408.9044s\n",
      "\titers: 600, epoch: 2 | loss: 0.3963277\n",
      "\tspeed: 0.0534s/iter; left time: 401.7560s\n",
      "\titers: 700, epoch: 2 | loss: 0.4241565\n",
      "\tspeed: 0.0533s/iter; left time: 395.5212s\n",
      "\titers: 800, epoch: 2 | loss: 0.3883984\n",
      "\tspeed: 0.0533s/iter; left time: 390.2696s\n",
      "\titers: 900, epoch: 2 | loss: 0.4167257\n",
      "\tspeed: 0.0534s/iter; left time: 385.5856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.4604631 Vali Loss: 0.1654439 Test Loss: 0.1855372\n",
      "Validation loss decreased (0.316566 --> 0.165444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4327329\n",
      "\tspeed: 0.1337s/iter; left time: 951.7605s\n",
      "\titers: 200, epoch: 3 | loss: 0.3957958\n",
      "\tspeed: 0.0533s/iter; left time: 373.7281s\n",
      "\titers: 300, epoch: 3 | loss: 0.3918147\n",
      "\tspeed: 0.0532s/iter; left time: 368.3101s\n",
      "\titers: 400, epoch: 3 | loss: 0.3974347\n",
      "\tspeed: 0.0531s/iter; left time: 362.0889s\n",
      "\titers: 500, epoch: 3 | loss: 0.3861700\n",
      "\tspeed: 0.0535s/iter; left time: 359.3677s\n",
      "\titers: 600, epoch: 3 | loss: 0.4063203\n",
      "\tspeed: 0.0534s/iter; left time: 353.2609s\n",
      "\titers: 700, epoch: 3 | loss: 0.3755366\n",
      "\tspeed: 0.0533s/iter; left time: 347.3661s\n",
      "\titers: 800, epoch: 3 | loss: 0.4101175\n",
      "\tspeed: 0.0534s/iter; left time: 342.5668s\n",
      "\titers: 900, epoch: 3 | loss: 0.4065938\n",
      "\tspeed: 0.0534s/iter; left time: 337.2392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.3985641 Vali Loss: 0.1615396 Test Loss: 0.1741239\n",
      "Validation loss decreased (0.165444 --> 0.161540).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3973604\n",
      "\tspeed: 0.1328s/iter; left time: 825.4746s\n",
      "\titers: 200, epoch: 4 | loss: 0.3811136\n",
      "\tspeed: 0.0532s/iter; left time: 325.5959s\n",
      "\titers: 300, epoch: 4 | loss: 0.3667543\n",
      "\tspeed: 0.0532s/iter; left time: 320.0663s\n",
      "\titers: 400, epoch: 4 | loss: 0.3984342\n",
      "\tspeed: 0.0535s/iter; left time: 316.6181s\n",
      "\titers: 500, epoch: 4 | loss: 0.3825527\n",
      "\tspeed: 0.0536s/iter; left time: 311.6205s\n",
      "\titers: 600, epoch: 4 | loss: 0.3598682\n",
      "\tspeed: 0.0536s/iter; left time: 306.3476s\n",
      "\titers: 700, epoch: 4 | loss: 0.3688106\n",
      "\tspeed: 0.0533s/iter; left time: 299.5572s\n",
      "\titers: 800, epoch: 4 | loss: 0.3855335\n",
      "\tspeed: 0.0532s/iter; left time: 293.3586s\n",
      "\titers: 900, epoch: 4 | loss: 0.3541565\n",
      "\tspeed: 0.0529s/iter; left time: 286.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.3764152 Vali Loss: 0.1675763 Test Loss: 0.1879234\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3548161\n",
      "\tspeed: 0.1308s/iter; left time: 694.7941s\n",
      "\titers: 200, epoch: 5 | loss: 0.3561797\n",
      "\tspeed: 0.0534s/iter; left time: 278.5239s\n",
      "\titers: 300, epoch: 5 | loss: 0.3693134\n",
      "\tspeed: 0.0534s/iter; left time: 272.9339s\n",
      "\titers: 400, epoch: 5 | loss: 0.3632230\n",
      "\tspeed: 0.0535s/iter; left time: 268.0663s\n",
      "\titers: 500, epoch: 5 | loss: 0.3501744\n",
      "\tspeed: 0.0537s/iter; left time: 263.5916s\n",
      "\titers: 600, epoch: 5 | loss: 0.3605365\n",
      "\tspeed: 0.0535s/iter; left time: 257.2844s\n",
      "\titers: 700, epoch: 5 | loss: 0.3378835\n",
      "\tspeed: 0.0534s/iter; left time: 251.4644s\n",
      "\titers: 800, epoch: 5 | loss: 0.3507200\n",
      "\tspeed: 0.0536s/iter; left time: 247.2318s\n",
      "\titers: 900, epoch: 5 | loss: 0.3309479\n",
      "\tspeed: 0.0534s/iter; left time: 241.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.3533288 Vali Loss: 0.1728445 Test Loss: 0.1920822\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3452060\n",
      "\tspeed: 0.1312s/iter; left time: 578.5930s\n",
      "\titers: 200, epoch: 6 | loss: 0.3228913\n",
      "\tspeed: 0.0533s/iter; left time: 229.9566s\n",
      "\titers: 300, epoch: 6 | loss: 0.3375479\n",
      "\tspeed: 0.0532s/iter; left time: 224.2315s\n",
      "\titers: 400, epoch: 6 | loss: 0.3367357\n",
      "\tspeed: 0.0532s/iter; left time: 218.7645s\n",
      "\titers: 500, epoch: 6 | loss: 0.3427296\n",
      "\tspeed: 0.0534s/iter; left time: 214.1138s\n",
      "\titers: 600, epoch: 6 | loss: 0.3427576\n",
      "\tspeed: 0.0532s/iter; left time: 207.9529s\n",
      "\titers: 700, epoch: 6 | loss: 0.3230248\n",
      "\tspeed: 0.0533s/iter; left time: 202.9748s\n",
      "\titers: 800, epoch: 6 | loss: 0.3116249\n",
      "\tspeed: 0.0532s/iter; left time: 197.5769s\n",
      "\titers: 900, epoch: 6 | loss: 0.3034044\n",
      "\tspeed: 0.0533s/iter; left time: 192.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.28s\n",
      "Steps: 902 | Train Loss: 0.3296081 Vali Loss: 0.1894973 Test Loss: 0.2087091\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.1740160584449768, rmse:0.4171523153781891, mae:0.2821454405784607, rse:0.5255328416824341\n",
      "Original data scale mse:3916505.5, rmse:1979.0162353515625, mae:1351.43994140625, rse:0.13940225541591644\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5457722\n",
      "\tspeed: 0.0744s/iter; left time: 666.8877s\n",
      "\titers: 200, epoch: 1 | loss: 0.4619505\n",
      "\tspeed: 0.0447s/iter; left time: 395.7536s\n",
      "\titers: 300, epoch: 1 | loss: 0.3818028\n",
      "\tspeed: 0.0363s/iter; left time: 318.3249s\n",
      "\titers: 400, epoch: 1 | loss: 0.3662461\n",
      "\tspeed: 0.0380s/iter; left time: 329.2945s\n",
      "\titers: 500, epoch: 1 | loss: 0.3121561\n",
      "\tspeed: 0.0448s/iter; left time: 383.4400s\n",
      "\titers: 600, epoch: 1 | loss: 0.3036166\n",
      "\tspeed: 0.0449s/iter; left time: 380.0047s\n",
      "\titers: 700, epoch: 1 | loss: 0.2796393\n",
      "\tspeed: 0.0446s/iter; left time: 373.1687s\n",
      "\titers: 800, epoch: 1 | loss: 0.2928684\n",
      "\tspeed: 0.0448s/iter; left time: 369.8095s\n",
      "\titers: 900, epoch: 1 | loss: 0.3108425\n",
      "\tspeed: 0.0443s/iter; left time: 361.6804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.66s\n",
      "Steps: 906 | Train Loss: 0.3805347 Vali Loss: 0.2673029 Test Loss: 0.2819944\n",
      "Validation loss decreased (inf --> 0.267303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2744780\n",
      "\tspeed: 0.0986s/iter; left time: 794.4252s\n",
      "\titers: 200, epoch: 2 | loss: 0.2373412\n",
      "\tspeed: 0.0408s/iter; left time: 324.4975s\n",
      "\titers: 300, epoch: 2 | loss: 0.2131426\n",
      "\tspeed: 0.0407s/iter; left time: 319.8872s\n",
      "\titers: 400, epoch: 2 | loss: 0.1916635\n",
      "\tspeed: 0.0409s/iter; left time: 316.8684s\n",
      "\titers: 500, epoch: 2 | loss: 0.2201029\n",
      "\tspeed: 0.0408s/iter; left time: 312.1310s\n",
      "\titers: 600, epoch: 2 | loss: 0.2060806\n",
      "\tspeed: 0.0406s/iter; left time: 306.8481s\n",
      "\titers: 700, epoch: 2 | loss: 0.1968652\n",
      "\tspeed: 0.0413s/iter; left time: 307.7042s\n",
      "\titers: 800, epoch: 2 | loss: 0.1945976\n",
      "\tspeed: 0.0408s/iter; left time: 300.0182s\n",
      "\titers: 900, epoch: 2 | loss: 0.2025563\n",
      "\tspeed: 0.0410s/iter; left time: 297.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.27s\n",
      "Steps: 906 | Train Loss: 0.2138651 Vali Loss: 0.1810661 Test Loss: 0.1998956\n",
      "Validation loss decreased (0.267303 --> 0.181066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1849810\n",
      "\tspeed: 0.0985s/iter; left time: 703.8968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1683050\n",
      "\tspeed: 0.0408s/iter; left time: 287.5415s\n",
      "\titers: 300, epoch: 3 | loss: 0.1933122\n",
      "\tspeed: 0.0412s/iter; left time: 286.5381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1747953\n",
      "\tspeed: 0.0413s/iter; left time: 282.6948s\n",
      "\titers: 500, epoch: 3 | loss: 0.1968665\n",
      "\tspeed: 0.0410s/iter; left time: 277.0382s\n",
      "\titers: 600, epoch: 3 | loss: 0.1883342\n",
      "\tspeed: 0.0415s/iter; left time: 276.2210s\n",
      "\titers: 700, epoch: 3 | loss: 0.1661317\n",
      "\tspeed: 0.0410s/iter; left time: 268.8148s\n",
      "\titers: 800, epoch: 3 | loss: 0.1753330\n",
      "\tspeed: 0.0413s/iter; left time: 266.6649s\n",
      "\titers: 900, epoch: 3 | loss: 0.1612290\n",
      "\tspeed: 0.0409s/iter; left time: 259.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.1781615 Vali Loss: 0.1714392 Test Loss: 0.1930635\n",
      "Validation loss decreased (0.181066 --> 0.171439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1667491\n",
      "\tspeed: 0.0978s/iter; left time: 610.8551s\n",
      "\titers: 200, epoch: 4 | loss: 0.1568225\n",
      "\tspeed: 0.0401s/iter; left time: 246.6025s\n",
      "\titers: 300, epoch: 4 | loss: 0.1570158\n",
      "\tspeed: 0.0411s/iter; left time: 248.4502s\n",
      "\titers: 400, epoch: 4 | loss: 0.1697214\n",
      "\tspeed: 0.0412s/iter; left time: 245.1402s\n",
      "\titers: 500, epoch: 4 | loss: 0.1468529\n",
      "\tspeed: 0.0411s/iter; left time: 240.2270s\n",
      "\titers: 600, epoch: 4 | loss: 0.2020216\n",
      "\tspeed: 0.0410s/iter; left time: 235.4103s\n",
      "\titers: 700, epoch: 4 | loss: 0.1758019\n",
      "\tspeed: 0.0410s/iter; left time: 231.3828s\n",
      "\titers: 800, epoch: 4 | loss: 0.1742330\n",
      "\tspeed: 0.0409s/iter; left time: 226.6291s\n",
      "\titers: 900, epoch: 4 | loss: 0.1855033\n",
      "\tspeed: 0.0411s/iter; left time: 223.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.39s\n",
      "Steps: 906 | Train Loss: 0.1667347 Vali Loss: 0.1718393 Test Loss: 0.1885798\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1557937\n",
      "\tspeed: 0.0949s/iter; left time: 506.3479s\n",
      "\titers: 200, epoch: 5 | loss: 0.1380313\n",
      "\tspeed: 0.0410s/iter; left time: 214.4671s\n",
      "\titers: 300, epoch: 5 | loss: 0.1472689\n",
      "\tspeed: 0.0406s/iter; left time: 208.7242s\n",
      "\titers: 400, epoch: 5 | loss: 0.1500001\n",
      "\tspeed: 0.0407s/iter; left time: 204.9495s\n",
      "\titers: 500, epoch: 5 | loss: 0.1750159\n",
      "\tspeed: 0.0406s/iter; left time: 200.4821s\n",
      "\titers: 600, epoch: 5 | loss: 0.1361495\n",
      "\tspeed: 0.0405s/iter; left time: 195.9850s\n",
      "\titers: 700, epoch: 5 | loss: 0.1765044\n",
      "\tspeed: 0.0409s/iter; left time: 193.6395s\n",
      "\titers: 800, epoch: 5 | loss: 0.1426417\n",
      "\tspeed: 0.0413s/iter; left time: 191.5054s\n",
      "\titers: 900, epoch: 5 | loss: 0.1558857\n",
      "\tspeed: 0.0414s/iter; left time: 187.7925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.32s\n",
      "Steps: 906 | Train Loss: 0.1589783 Vali Loss: 0.1625855 Test Loss: 0.1826195\n",
      "Validation loss decreased (0.171439 --> 0.162585).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1450308\n",
      "\tspeed: 0.0975s/iter; left time: 431.8505s\n",
      "\titers: 200, epoch: 6 | loss: 0.1558551\n",
      "\tspeed: 0.0407s/iter; left time: 176.4633s\n",
      "\titers: 300, epoch: 6 | loss: 0.1792783\n",
      "\tspeed: 0.0409s/iter; left time: 173.2156s\n",
      "\titers: 400, epoch: 6 | loss: 0.1704415\n",
      "\tspeed: 0.0409s/iter; left time: 169.0471s\n",
      "\titers: 500, epoch: 6 | loss: 0.1573851\n",
      "\tspeed: 0.0415s/iter; left time: 167.3075s\n",
      "\titers: 600, epoch: 6 | loss: 0.1671356\n",
      "\tspeed: 0.0409s/iter; left time: 160.7905s\n",
      "\titers: 700, epoch: 6 | loss: 0.1638393\n",
      "\tspeed: 0.0408s/iter; left time: 156.2579s\n",
      "\titers: 800, epoch: 6 | loss: 0.1595617\n",
      "\tspeed: 0.0327s/iter; left time: 122.1136s\n",
      "\titers: 900, epoch: 6 | loss: 0.1701097\n",
      "\tspeed: 0.0283s/iter; left time: 102.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:35.16s\n",
      "Steps: 906 | Train Loss: 0.1515545 Vali Loss: 0.1674609 Test Loss: 0.1899537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1610046\n",
      "\tspeed: 0.0955s/iter; left time: 336.5264s\n",
      "\titers: 200, epoch: 7 | loss: 0.1198155\n",
      "\tspeed: 0.0409s/iter; left time: 139.9861s\n",
      "\titers: 300, epoch: 7 | loss: 0.1407748\n",
      "\tspeed: 0.0414s/iter; left time: 137.5900s\n",
      "\titers: 400, epoch: 7 | loss: 0.1454923\n",
      "\tspeed: 0.0412s/iter; left time: 132.7282s\n",
      "\titers: 500, epoch: 7 | loss: 0.1364675\n",
      "\tspeed: 0.0411s/iter; left time: 128.5014s\n",
      "\titers: 600, epoch: 7 | loss: 0.1231406\n",
      "\tspeed: 0.0411s/iter; left time: 124.3791s\n",
      "\titers: 700, epoch: 7 | loss: 0.1398096\n",
      "\tspeed: 0.0413s/iter; left time: 120.7101s\n",
      "\titers: 800, epoch: 7 | loss: 0.1630591\n",
      "\tspeed: 0.0412s/iter; left time: 116.3141s\n",
      "\titers: 900, epoch: 7 | loss: 0.1463931\n",
      "\tspeed: 0.0411s/iter; left time: 112.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.64s\n",
      "Steps: 906 | Train Loss: 0.1454282 Vali Loss: 0.1638277 Test Loss: 0.1816822\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1371342\n",
      "\tspeed: 0.0982s/iter; left time: 257.0689s\n",
      "\titers: 200, epoch: 8 | loss: 0.1308029\n",
      "\tspeed: 0.0406s/iter; left time: 102.3947s\n",
      "\titers: 300, epoch: 8 | loss: 0.1505614\n",
      "\tspeed: 0.0409s/iter; left time: 98.9800s\n",
      "\titers: 400, epoch: 8 | loss: 0.1294539\n",
      "\tspeed: 0.0413s/iter; left time: 95.7732s\n",
      "\titers: 500, epoch: 8 | loss: 0.1530150\n",
      "\tspeed: 0.0408s/iter; left time: 90.5320s\n",
      "\titers: 600, epoch: 8 | loss: 0.1423034\n",
      "\tspeed: 0.0413s/iter; left time: 87.5004s\n",
      "\titers: 700, epoch: 8 | loss: 0.1252410\n",
      "\tspeed: 0.0408s/iter; left time: 82.3644s\n",
      "\titers: 800, epoch: 8 | loss: 0.1201913\n",
      "\tspeed: 0.0411s/iter; left time: 78.9379s\n",
      "\titers: 900, epoch: 8 | loss: 0.1563341\n",
      "\tspeed: 0.0407s/iter; left time: 74.1012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.1401851 Vali Loss: 0.1655675 Test Loss: 0.1868510\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.09913782775402069, rmse:0.31486159563064575, mae:0.1829637587070465, rse:0.3975760042667389\n",
      "Original data scale mse:1536245.125, rmse:1239.45361328125, mae:781.243896484375, rse:0.08709932863712311\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4776601\n",
      "\tspeed: 0.0461s/iter; left time: 412.8404s\n",
      "\titers: 200, epoch: 1 | loss: 0.4439813\n",
      "\tspeed: 0.0434s/iter; left time: 384.2912s\n",
      "\titers: 300, epoch: 1 | loss: 0.3909110\n",
      "\tspeed: 0.0409s/iter; left time: 357.9452s\n",
      "\titers: 400, epoch: 1 | loss: 0.3461046\n",
      "\tspeed: 0.0413s/iter; left time: 357.8975s\n",
      "\titers: 500, epoch: 1 | loss: 0.3320941\n",
      "\tspeed: 0.0413s/iter; left time: 353.9767s\n",
      "\titers: 600, epoch: 1 | loss: 0.2909390\n",
      "\tspeed: 0.0412s/iter; left time: 348.3473s\n",
      "\titers: 700, epoch: 1 | loss: 0.2996924\n",
      "\tspeed: 0.0442s/iter; left time: 369.5877s\n",
      "\titers: 800, epoch: 1 | loss: 0.2653154\n",
      "\tspeed: 0.0450s/iter; left time: 371.7347s\n",
      "\titers: 900, epoch: 1 | loss: 0.2755414\n",
      "\tspeed: 0.0422s/iter; left time: 344.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 906 | Train Loss: 0.3752849 Vali Loss: 0.2672270 Test Loss: 0.2840111\n",
      "Validation loss decreased (inf --> 0.267227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2506149\n",
      "\tspeed: 0.0988s/iter; left time: 796.0010s\n",
      "\titers: 200, epoch: 2 | loss: 0.2350883\n",
      "\tspeed: 0.0415s/iter; left time: 330.3662s\n",
      "\titers: 300, epoch: 2 | loss: 0.2358949\n",
      "\tspeed: 0.0409s/iter; left time: 321.4743s\n",
      "\titers: 400, epoch: 2 | loss: 0.1885822\n",
      "\tspeed: 0.0409s/iter; left time: 316.8041s\n",
      "\titers: 500, epoch: 2 | loss: 0.2010925\n",
      "\tspeed: 0.0407s/iter; left time: 311.2328s\n",
      "\titers: 600, epoch: 2 | loss: 0.1833385\n",
      "\tspeed: 0.0407s/iter; left time: 307.1990s\n",
      "\titers: 700, epoch: 2 | loss: 0.1935309\n",
      "\tspeed: 0.0408s/iter; left time: 303.8843s\n",
      "\titers: 800, epoch: 2 | loss: 0.1903417\n",
      "\tspeed: 0.0411s/iter; left time: 302.1274s\n",
      "\titers: 900, epoch: 2 | loss: 0.1762984\n",
      "\tspeed: 0.0412s/iter; left time: 299.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.43s\n",
      "Steps: 906 | Train Loss: 0.2146217 Vali Loss: 0.1833718 Test Loss: 0.2010264\n",
      "Validation loss decreased (0.267227 --> 0.183372).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1991241\n",
      "\tspeed: 0.1004s/iter; left time: 718.0332s\n",
      "\titers: 200, epoch: 3 | loss: 0.1883680\n",
      "\tspeed: 0.0407s/iter; left time: 286.5865s\n",
      "\titers: 300, epoch: 3 | loss: 0.2205907\n",
      "\tspeed: 0.0407s/iter; left time: 282.9394s\n",
      "\titers: 400, epoch: 3 | loss: 0.1706741\n",
      "\tspeed: 0.0409s/iter; left time: 280.1142s\n",
      "\titers: 500, epoch: 3 | loss: 0.1849377\n",
      "\tspeed: 0.0409s/iter; left time: 276.2070s\n",
      "\titers: 600, epoch: 3 | loss: 0.1509293\n",
      "\tspeed: 0.0410s/iter; left time: 272.8778s\n",
      "\titers: 700, epoch: 3 | loss: 0.1512517\n",
      "\tspeed: 0.0408s/iter; left time: 267.4778s\n",
      "\titers: 800, epoch: 3 | loss: 0.1526526\n",
      "\tspeed: 0.0418s/iter; left time: 269.7099s\n",
      "\titers: 900, epoch: 3 | loss: 0.1587323\n",
      "\tspeed: 0.0411s/iter; left time: 260.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.43s\n",
      "Steps: 906 | Train Loss: 0.1776619 Vali Loss: 0.1771492 Test Loss: 0.1885832\n",
      "Validation loss decreased (0.183372 --> 0.177149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1701278\n",
      "\tspeed: 0.0984s/iter; left time: 614.3843s\n",
      "\titers: 200, epoch: 4 | loss: 0.2015077\n",
      "\tspeed: 0.0421s/iter; left time: 258.6759s\n",
      "\titers: 300, epoch: 4 | loss: 0.1763208\n",
      "\tspeed: 0.0413s/iter; left time: 249.6956s\n",
      "\titers: 400, epoch: 4 | loss: 0.1486210\n",
      "\tspeed: 0.0414s/iter; left time: 246.0193s\n",
      "\titers: 500, epoch: 4 | loss: 0.1765108\n",
      "\tspeed: 0.0412s/iter; left time: 240.6579s\n",
      "\titers: 600, epoch: 4 | loss: 0.1562960\n",
      "\tspeed: 0.0414s/iter; left time: 237.9090s\n",
      "\titers: 700, epoch: 4 | loss: 0.1685656\n",
      "\tspeed: 0.0414s/iter; left time: 233.7903s\n",
      "\titers: 800, epoch: 4 | loss: 0.1544240\n",
      "\tspeed: 0.0413s/iter; left time: 228.7849s\n",
      "\titers: 900, epoch: 4 | loss: 0.1616580\n",
      "\tspeed: 0.0409s/iter; left time: 222.8746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.1661116 Vali Loss: 0.1647085 Test Loss: 0.1840274\n",
      "Validation loss decreased (0.177149 --> 0.164708).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1714782\n",
      "\tspeed: 0.0981s/iter; left time: 523.6351s\n",
      "\titers: 200, epoch: 5 | loss: 0.1369216\n",
      "\tspeed: 0.0415s/iter; left time: 217.4533s\n",
      "\titers: 300, epoch: 5 | loss: 0.1575394\n",
      "\tspeed: 0.0412s/iter; left time: 211.8560s\n",
      "\titers: 400, epoch: 5 | loss: 0.1656790\n",
      "\tspeed: 0.0414s/iter; left time: 208.6095s\n",
      "\titers: 500, epoch: 5 | loss: 0.1608222\n",
      "\tspeed: 0.0422s/iter; left time: 208.0950s\n",
      "\titers: 600, epoch: 5 | loss: 0.1554044\n",
      "\tspeed: 0.0410s/iter; left time: 198.5533s\n",
      "\titers: 700, epoch: 5 | loss: 0.1500034\n",
      "\tspeed: 0.0411s/iter; left time: 194.9225s\n",
      "\titers: 800, epoch: 5 | loss: 0.1416839\n",
      "\tspeed: 0.0413s/iter; left time: 191.4694s\n",
      "\titers: 900, epoch: 5 | loss: 0.1522401\n",
      "\tspeed: 0.0413s/iter; left time: 187.2200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.76s\n",
      "Steps: 906 | Train Loss: 0.1595445 Vali Loss: 0.1665687 Test Loss: 0.1847638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1443708\n",
      "\tspeed: 0.0948s/iter; left time: 420.0415s\n",
      "\titers: 200, epoch: 6 | loss: 0.1567374\n",
      "\tspeed: 0.0416s/iter; left time: 180.2060s\n",
      "\titers: 300, epoch: 6 | loss: 0.1493996\n",
      "\tspeed: 0.0412s/iter; left time: 174.3654s\n",
      "\titers: 400, epoch: 6 | loss: 0.1430849\n",
      "\tspeed: 0.0413s/iter; left time: 170.7233s\n",
      "\titers: 500, epoch: 6 | loss: 0.1443629\n",
      "\tspeed: 0.0412s/iter; left time: 166.0309s\n",
      "\titers: 600, epoch: 6 | loss: 0.1465211\n",
      "\tspeed: 0.0409s/iter; left time: 160.9508s\n",
      "\titers: 700, epoch: 6 | loss: 0.1611205\n",
      "\tspeed: 0.0410s/iter; left time: 157.0484s\n",
      "\titers: 800, epoch: 6 | loss: 0.1412749\n",
      "\tspeed: 0.0405s/iter; left time: 151.1371s\n",
      "\titers: 900, epoch: 6 | loss: 0.1253723\n",
      "\tspeed: 0.0409s/iter; left time: 148.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.46s\n",
      "Steps: 906 | Train Loss: 0.1522222 Vali Loss: 0.1653213 Test Loss: 0.1843068\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1479426\n",
      "\tspeed: 0.0951s/iter; left time: 335.3703s\n",
      "\titers: 200, epoch: 7 | loss: 0.1245969\n",
      "\tspeed: 0.0415s/iter; left time: 142.1496s\n",
      "\titers: 300, epoch: 7 | loss: 0.1496309\n",
      "\tspeed: 0.0416s/iter; left time: 138.4134s\n",
      "\titers: 400, epoch: 7 | loss: 0.1311834\n",
      "\tspeed: 0.0418s/iter; left time: 134.6999s\n",
      "\titers: 500, epoch: 7 | loss: 0.1564162\n",
      "\tspeed: 0.0416s/iter; left time: 129.9491s\n",
      "\titers: 600, epoch: 7 | loss: 0.1434652\n",
      "\tspeed: 0.0412s/iter; left time: 124.7116s\n",
      "\titers: 700, epoch: 7 | loss: 0.1580399\n",
      "\tspeed: 0.0415s/iter; left time: 121.3790s\n",
      "\titers: 800, epoch: 7 | loss: 0.1317641\n",
      "\tspeed: 0.0410s/iter; left time: 115.9327s\n",
      "\titers: 900, epoch: 7 | loss: 0.1625302\n",
      "\tspeed: 0.0413s/iter; left time: 112.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1465913 Vali Loss: 0.1644109 Test Loss: 0.1782902\n",
      "Validation loss decreased (0.164708 --> 0.164411).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1670306\n",
      "\tspeed: 0.0976s/iter; left time: 255.6239s\n",
      "\titers: 200, epoch: 8 | loss: 0.1477174\n",
      "\tspeed: 0.0406s/iter; left time: 102.3562s\n",
      "\titers: 300, epoch: 8 | loss: 0.1230330\n",
      "\tspeed: 0.0409s/iter; left time: 98.9534s\n",
      "\titers: 400, epoch: 8 | loss: 0.1492897\n",
      "\tspeed: 0.0407s/iter; left time: 94.3518s\n",
      "\titers: 500, epoch: 8 | loss: 0.1254149\n",
      "\tspeed: 0.0406s/iter; left time: 90.1382s\n",
      "\titers: 600, epoch: 8 | loss: 0.1357246\n",
      "\tspeed: 0.0413s/iter; left time: 87.5731s\n",
      "\titers: 700, epoch: 8 | loss: 0.1226515\n",
      "\tspeed: 0.0410s/iter; left time: 82.8609s\n",
      "\titers: 800, epoch: 8 | loss: 0.1265222\n",
      "\tspeed: 0.0408s/iter; left time: 78.2217s\n",
      "\titers: 900, epoch: 8 | loss: 0.1466777\n",
      "\tspeed: 0.0411s/iter; left time: 74.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.1410861 Vali Loss: 0.1640912 Test Loss: 0.1874596\n",
      "Validation loss decreased (0.164411 --> 0.164091).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1428328\n",
      "\tspeed: 0.0984s/iter; left time: 168.4962s\n",
      "\titers: 200, epoch: 9 | loss: 0.1480935\n",
      "\tspeed: 0.0408s/iter; left time: 65.8877s\n",
      "\titers: 300, epoch: 9 | loss: 0.1487220\n",
      "\tspeed: 0.0409s/iter; left time: 61.8406s\n",
      "\titers: 400, epoch: 9 | loss: 0.1373631\n",
      "\tspeed: 0.0402s/iter; left time: 56.8076s\n",
      "\titers: 500, epoch: 9 | loss: 0.1378880\n",
      "\tspeed: 0.0408s/iter; left time: 53.5502s\n",
      "\titers: 600, epoch: 9 | loss: 0.1345500\n",
      "\tspeed: 0.0407s/iter; left time: 49.3720s\n",
      "\titers: 700, epoch: 9 | loss: 0.1397694\n",
      "\tspeed: 0.0408s/iter; left time: 45.4425s\n",
      "\titers: 800, epoch: 9 | loss: 0.1351453\n",
      "\tspeed: 0.0408s/iter; left time: 41.3072s\n",
      "\titers: 900, epoch: 9 | loss: 0.1375480\n",
      "\tspeed: 0.0408s/iter; left time: 37.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.23s\n",
      "Steps: 906 | Train Loss: 0.1350569 Vali Loss: 0.1672038 Test Loss: 0.1815512\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1340280\n",
      "\tspeed: 0.0949s/iter; left time: 76.6006s\n",
      "\titers: 200, epoch: 10 | loss: 0.1237886\n",
      "\tspeed: 0.0409s/iter; left time: 28.9508s\n",
      "\titers: 300, epoch: 10 | loss: 0.1060987\n",
      "\tspeed: 0.0411s/iter; left time: 24.9558s\n",
      "\titers: 400, epoch: 10 | loss: 0.1337412\n",
      "\tspeed: 0.0409s/iter; left time: 20.7277s\n",
      "\titers: 500, epoch: 10 | loss: 0.1200562\n",
      "\tspeed: 0.0408s/iter; left time: 16.5927s\n",
      "\titers: 600, epoch: 10 | loss: 0.1317466\n",
      "\tspeed: 0.0412s/iter; left time: 12.6409s\n",
      "\titers: 700, epoch: 10 | loss: 0.1188810\n",
      "\tspeed: 0.0407s/iter; left time: 8.4306s\n",
      "\titers: 800, epoch: 10 | loss: 0.1366085\n",
      "\tspeed: 0.0409s/iter; left time: 4.3756s\n",
      "\titers: 900, epoch: 10 | loss: 0.1230256\n",
      "\tspeed: 0.0407s/iter; left time: 0.2848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.1295959 Vali Loss: 0.1670163 Test Loss: 0.1832003\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10783817619085312, rmse:0.32838723063468933, mae:0.18776381015777588, rse:0.41465485095977783\n",
      "Original data scale mse:1982624.5, rmse:1408.0570068359375, mae:824.5411376953125, rse:0.09894748777151108\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5609224\n",
      "\tspeed: 0.0807s/iter; left time: 721.8443s\n",
      "\titers: 200, epoch: 1 | loss: 0.5243334\n",
      "\tspeed: 0.0499s/iter; left time: 441.0276s\n",
      "\titers: 300, epoch: 1 | loss: 0.4619636\n",
      "\tspeed: 0.0486s/iter; left time: 424.9568s\n",
      "\titers: 400, epoch: 1 | loss: 0.4469604\n",
      "\tspeed: 0.0472s/iter; left time: 408.0894s\n",
      "\titers: 500, epoch: 1 | loss: 0.4346926\n",
      "\tspeed: 0.0473s/iter; left time: 403.6345s\n",
      "\titers: 600, epoch: 1 | loss: 0.4109475\n",
      "\tspeed: 0.0471s/iter; left time: 397.6922s\n",
      "\titers: 700, epoch: 1 | loss: 0.4042616\n",
      "\tspeed: 0.0471s/iter; left time: 392.4713s\n",
      "\titers: 800, epoch: 1 | loss: 0.3887668\n",
      "\tspeed: 0.0489s/iter; left time: 403.2261s\n",
      "\titers: 900, epoch: 1 | loss: 0.3973931\n",
      "\tspeed: 0.0481s/iter; left time: 391.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.33s\n",
      "Steps: 904 | Train Loss: 0.4573110 Vali Loss: 0.3704648 Test Loss: 0.4015980\n",
      "Validation loss decreased (inf --> 0.370465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3526562\n",
      "\tspeed: 0.1174s/iter; left time: 943.8853s\n",
      "\titers: 200, epoch: 2 | loss: 0.3401772\n",
      "\tspeed: 0.0472s/iter; left time: 374.4983s\n",
      "\titers: 300, epoch: 2 | loss: 0.3025575\n",
      "\tspeed: 0.0472s/iter; left time: 370.1550s\n",
      "\titers: 400, epoch: 2 | loss: 0.2961200\n",
      "\tspeed: 0.0471s/iter; left time: 364.0647s\n",
      "\titers: 500, epoch: 2 | loss: 0.2845877\n",
      "\tspeed: 0.0470s/iter; left time: 359.0534s\n",
      "\titers: 600, epoch: 2 | loss: 0.2914656\n",
      "\tspeed: 0.0473s/iter; left time: 356.7556s\n",
      "\titers: 700, epoch: 2 | loss: 0.2735434\n",
      "\tspeed: 0.0473s/iter; left time: 351.9857s\n",
      "\titers: 800, epoch: 2 | loss: 0.2677212\n",
      "\tspeed: 0.0471s/iter; left time: 345.7804s\n",
      "\titers: 900, epoch: 2 | loss: 0.2493406\n",
      "\tspeed: 0.0469s/iter; left time: 339.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.87s\n",
      "Steps: 904 | Train Loss: 0.3005623 Vali Loss: 0.2569939 Test Loss: 0.2728545\n",
      "Validation loss decreased (0.370465 --> 0.256994).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2540559\n",
      "\tspeed: 0.1152s/iter; left time: 822.0176s\n",
      "\titers: 200, epoch: 3 | loss: 0.2587475\n",
      "\tspeed: 0.0470s/iter; left time: 330.6456s\n",
      "\titers: 300, epoch: 3 | loss: 0.2666639\n",
      "\tspeed: 0.0470s/iter; left time: 326.0529s\n",
      "\titers: 400, epoch: 3 | loss: 0.2591120\n",
      "\tspeed: 0.0470s/iter; left time: 321.0159s\n",
      "\titers: 500, epoch: 3 | loss: 0.2382762\n",
      "\tspeed: 0.0468s/iter; left time: 315.0162s\n",
      "\titers: 600, epoch: 3 | loss: 0.2448051\n",
      "\tspeed: 0.0464s/iter; left time: 307.8453s\n",
      "\titers: 700, epoch: 3 | loss: 0.2321104\n",
      "\tspeed: 0.0471s/iter; left time: 307.7846s\n",
      "\titers: 800, epoch: 3 | loss: 0.2661161\n",
      "\tspeed: 0.0469s/iter; left time: 301.4209s\n",
      "\titers: 900, epoch: 3 | loss: 0.2559404\n",
      "\tspeed: 0.0468s/iter; left time: 296.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.62s\n",
      "Steps: 904 | Train Loss: 0.2469540 Vali Loss: 0.2406677 Test Loss: 0.2586666\n",
      "Validation loss decreased (0.256994 --> 0.240668).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2228930\n",
      "\tspeed: 0.1147s/iter; left time: 714.3309s\n",
      "\titers: 200, epoch: 4 | loss: 0.2382651\n",
      "\tspeed: 0.0469s/iter; left time: 287.4373s\n",
      "\titers: 300, epoch: 4 | loss: 0.2213701\n",
      "\tspeed: 0.0470s/iter; left time: 283.5119s\n",
      "\titers: 400, epoch: 4 | loss: 0.2358070\n",
      "\tspeed: 0.0467s/iter; left time: 277.0446s\n",
      "\titers: 500, epoch: 4 | loss: 0.2334090\n",
      "\tspeed: 0.0465s/iter; left time: 271.2478s\n",
      "\titers: 600, epoch: 4 | loss: 0.2296933\n",
      "\tspeed: 0.0469s/iter; left time: 268.5268s\n",
      "\titers: 700, epoch: 4 | loss: 0.2192774\n",
      "\tspeed: 0.0470s/iter; left time: 264.7494s\n",
      "\titers: 800, epoch: 4 | loss: 0.2308961\n",
      "\tspeed: 0.0470s/iter; left time: 260.0620s\n",
      "\titers: 900, epoch: 4 | loss: 0.2068672\n",
      "\tspeed: 0.0470s/iter; left time: 255.0662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.62s\n",
      "Steps: 904 | Train Loss: 0.2287963 Vali Loss: 0.2351468 Test Loss: 0.2627827\n",
      "Validation loss decreased (0.240668 --> 0.235147).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1998413\n",
      "\tspeed: 0.1158s/iter; left time: 616.8073s\n",
      "\titers: 200, epoch: 5 | loss: 0.2193071\n",
      "\tspeed: 0.0471s/iter; left time: 245.9561s\n",
      "\titers: 300, epoch: 5 | loss: 0.2077117\n",
      "\tspeed: 0.0473s/iter; left time: 242.6683s\n",
      "\titers: 400, epoch: 5 | loss: 0.2434303\n",
      "\tspeed: 0.0472s/iter; left time: 236.9354s\n",
      "\titers: 500, epoch: 5 | loss: 0.2125362\n",
      "\tspeed: 0.0472s/iter; left time: 232.3533s\n",
      "\titers: 600, epoch: 5 | loss: 0.2191880\n",
      "\tspeed: 0.0471s/iter; left time: 227.2594s\n",
      "\titers: 700, epoch: 5 | loss: 0.2376513\n",
      "\tspeed: 0.0476s/iter; left time: 224.7071s\n",
      "\titers: 800, epoch: 5 | loss: 0.2253581\n",
      "\tspeed: 0.0471s/iter; left time: 217.8281s\n",
      "\titers: 900, epoch: 5 | loss: 0.1962350\n",
      "\tspeed: 0.0472s/iter; left time: 213.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.95s\n",
      "Steps: 904 | Train Loss: 0.2154299 Vali Loss: 0.2394691 Test Loss: 0.2566609\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1866974\n",
      "\tspeed: 0.1112s/iter; left time: 491.6012s\n",
      "\titers: 200, epoch: 6 | loss: 0.2211927\n",
      "\tspeed: 0.0469s/iter; left time: 202.8588s\n",
      "\titers: 300, epoch: 6 | loss: 0.2087145\n",
      "\tspeed: 0.0469s/iter; left time: 198.0450s\n",
      "\titers: 400, epoch: 6 | loss: 0.2200092\n",
      "\tspeed: 0.0468s/iter; left time: 193.0123s\n",
      "\titers: 500, epoch: 6 | loss: 0.2026272\n",
      "\tspeed: 0.0470s/iter; left time: 188.9387s\n",
      "\titers: 600, epoch: 6 | loss: 0.2080359\n",
      "\tspeed: 0.0471s/iter; left time: 184.6969s\n",
      "\titers: 700, epoch: 6 | loss: 0.1720245\n",
      "\tspeed: 0.0470s/iter; left time: 179.4810s\n",
      "\titers: 800, epoch: 6 | loss: 0.2128961\n",
      "\tspeed: 0.0468s/iter; left time: 174.2381s\n",
      "\titers: 900, epoch: 6 | loss: 0.2041475\n",
      "\tspeed: 0.0467s/iter; left time: 169.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.60s\n",
      "Steps: 904 | Train Loss: 0.2046925 Vali Loss: 0.2335692 Test Loss: 0.2630001\n",
      "Validation loss decreased (0.235147 --> 0.233569).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1906876\n",
      "\tspeed: 0.1167s/iter; left time: 410.2612s\n",
      "\titers: 200, epoch: 7 | loss: 0.1760302\n",
      "\tspeed: 0.0478s/iter; left time: 163.3774s\n",
      "\titers: 300, epoch: 7 | loss: 0.1980612\n",
      "\tspeed: 0.0484s/iter; left time: 160.6115s\n",
      "\titers: 400, epoch: 7 | loss: 0.1917071\n",
      "\tspeed: 0.0498s/iter; left time: 160.1522s\n",
      "\titers: 500, epoch: 7 | loss: 0.1776822\n",
      "\tspeed: 0.0498s/iter; left time: 155.3002s\n",
      "\titers: 600, epoch: 7 | loss: 0.2179713\n",
      "\tspeed: 0.0499s/iter; left time: 150.4242s\n",
      "\titers: 700, epoch: 7 | loss: 0.1928537\n",
      "\tspeed: 0.0502s/iter; left time: 146.5233s\n",
      "\titers: 800, epoch: 7 | loss: 0.1681959\n",
      "\tspeed: 0.0494s/iter; left time: 139.0894s\n",
      "\titers: 900, epoch: 7 | loss: 0.1982576\n",
      "\tspeed: 0.0460s/iter; left time: 125.0524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.41s\n",
      "Steps: 904 | Train Loss: 0.1930687 Vali Loss: 0.2379507 Test Loss: 0.2623207\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1884136\n",
      "\tspeed: 0.1142s/iter; left time: 298.3624s\n",
      "\titers: 200, epoch: 8 | loss: 0.1891558\n",
      "\tspeed: 0.0460s/iter; left time: 115.5783s\n",
      "\titers: 300, epoch: 8 | loss: 0.1987314\n",
      "\tspeed: 0.0472s/iter; left time: 113.9516s\n",
      "\titers: 400, epoch: 8 | loss: 0.1750718\n",
      "\tspeed: 0.0471s/iter; left time: 108.9153s\n",
      "\titers: 500, epoch: 8 | loss: 0.1834746\n",
      "\tspeed: 0.0471s/iter; left time: 104.1451s\n",
      "\titers: 600, epoch: 8 | loss: 0.1824766\n",
      "\tspeed: 0.0472s/iter; left time: 99.7576s\n",
      "\titers: 700, epoch: 8 | loss: 0.1741492\n",
      "\tspeed: 0.0472s/iter; left time: 95.0208s\n",
      "\titers: 800, epoch: 8 | loss: 0.1780686\n",
      "\tspeed: 0.0465s/iter; left time: 89.0106s\n",
      "\titers: 900, epoch: 8 | loss: 0.1818569\n",
      "\tspeed: 0.0469s/iter; left time: 85.0450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.63s\n",
      "Steps: 904 | Train Loss: 0.1835456 Vali Loss: 0.2421833 Test Loss: 0.2674352\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1895448\n",
      "\tspeed: 0.1133s/iter; left time: 193.6269s\n",
      "\titers: 200, epoch: 9 | loss: 0.1986769\n",
      "\tspeed: 0.0473s/iter; left time: 76.1230s\n",
      "\titers: 300, epoch: 9 | loss: 0.1697396\n",
      "\tspeed: 0.0470s/iter; left time: 70.8791s\n",
      "\titers: 400, epoch: 9 | loss: 0.1702705\n",
      "\tspeed: 0.0470s/iter; left time: 66.2886s\n",
      "\titers: 500, epoch: 9 | loss: 0.1700645\n",
      "\tspeed: 0.0469s/iter; left time: 61.4218s\n",
      "\titers: 600, epoch: 9 | loss: 0.1629677\n",
      "\tspeed: 0.0473s/iter; left time: 57.1464s\n",
      "\titers: 700, epoch: 9 | loss: 0.1640444\n",
      "\tspeed: 0.0469s/iter; left time: 51.9779s\n",
      "\titers: 800, epoch: 9 | loss: 0.1654269\n",
      "\tspeed: 0.0470s/iter; left time: 47.3798s\n",
      "\titers: 900, epoch: 9 | loss: 0.1891501\n",
      "\tspeed: 0.0475s/iter; left time: 43.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.83s\n",
      "Steps: 904 | Train Loss: 0.1746325 Vali Loss: 0.2436785 Test Loss: 0.2686452\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.19483530521392822, rmse:0.44140151143074036, mae:0.2628290355205536, rse:0.5566918849945068\n",
      "Original data scale mse:3251107.5, rmse:1803.082763671875, mae:1161.2264404296875, rse:0.12689030170440674\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5408066\n",
      "\tspeed: 0.0516s/iter; left time: 461.4843s\n",
      "\titers: 200, epoch: 1 | loss: 0.4969047\n",
      "\tspeed: 0.0498s/iter; left time: 440.2971s\n",
      "\titers: 300, epoch: 1 | loss: 0.4587035\n",
      "\tspeed: 0.0496s/iter; left time: 433.3118s\n",
      "\titers: 400, epoch: 1 | loss: 0.4662279\n",
      "\tspeed: 0.0497s/iter; left time: 429.2563s\n",
      "\titers: 500, epoch: 1 | loss: 0.4190004\n",
      "\tspeed: 0.0500s/iter; left time: 427.0476s\n",
      "\titers: 600, epoch: 1 | loss: 0.4151782\n",
      "\tspeed: 0.0500s/iter; left time: 421.6642s\n",
      "\titers: 700, epoch: 1 | loss: 0.4062589\n",
      "\tspeed: 0.0492s/iter; left time: 410.6811s\n",
      "\titers: 800, epoch: 1 | loss: 0.3966270\n",
      "\tspeed: 0.0467s/iter; left time: 385.0427s\n",
      "\titers: 900, epoch: 1 | loss: 0.3835855\n",
      "\tspeed: 0.0471s/iter; left time: 383.3067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.63s\n",
      "Steps: 904 | Train Loss: 0.4568406 Vali Loss: 0.3676046 Test Loss: 0.3981673\n",
      "Validation loss decreased (inf --> 0.367605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3467729\n",
      "\tspeed: 0.1163s/iter; left time: 934.4207s\n",
      "\titers: 200, epoch: 2 | loss: 0.3216526\n",
      "\tspeed: 0.0473s/iter; left time: 375.1793s\n",
      "\titers: 300, epoch: 2 | loss: 0.3120637\n",
      "\tspeed: 0.0473s/iter; left time: 370.8043s\n",
      "\titers: 400, epoch: 2 | loss: 0.2981583\n",
      "\tspeed: 0.0475s/iter; left time: 367.3445s\n",
      "\titers: 500, epoch: 2 | loss: 0.2839856\n",
      "\tspeed: 0.0474s/iter; left time: 362.0329s\n",
      "\titers: 600, epoch: 2 | loss: 0.2709781\n",
      "\tspeed: 0.0469s/iter; left time: 353.7034s\n",
      "\titers: 700, epoch: 2 | loss: 0.2700642\n",
      "\tspeed: 0.0468s/iter; left time: 347.8630s\n",
      "\titers: 800, epoch: 2 | loss: 0.2589352\n",
      "\tspeed: 0.0466s/iter; left time: 341.6855s\n",
      "\titers: 900, epoch: 2 | loss: 0.2295327\n",
      "\tspeed: 0.0470s/iter; left time: 340.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.77s\n",
      "Steps: 904 | Train Loss: 0.2983323 Vali Loss: 0.2517128 Test Loss: 0.2744485\n",
      "Validation loss decreased (0.367605 --> 0.251713).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2584858\n",
      "\tspeed: 0.1169s/iter; left time: 833.8333s\n",
      "\titers: 200, epoch: 3 | loss: 0.2443511\n",
      "\tspeed: 0.0469s/iter; left time: 330.1567s\n",
      "\titers: 300, epoch: 3 | loss: 0.2449764\n",
      "\tspeed: 0.0471s/iter; left time: 326.2539s\n",
      "\titers: 400, epoch: 3 | loss: 0.2443414\n",
      "\tspeed: 0.0471s/iter; left time: 321.9918s\n",
      "\titers: 500, epoch: 3 | loss: 0.2429548\n",
      "\tspeed: 0.0471s/iter; left time: 317.1408s\n",
      "\titers: 600, epoch: 3 | loss: 0.2538213\n",
      "\tspeed: 0.0493s/iter; left time: 327.2300s\n",
      "\titers: 700, epoch: 3 | loss: 0.2554872\n",
      "\tspeed: 0.0504s/iter; left time: 329.3079s\n",
      "\titers: 800, epoch: 3 | loss: 0.2518428\n",
      "\tspeed: 0.0503s/iter; left time: 323.5352s\n",
      "\titers: 900, epoch: 3 | loss: 0.2169301\n",
      "\tspeed: 0.0501s/iter; left time: 317.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.03s\n",
      "Steps: 904 | Train Loss: 0.2459033 Vali Loss: 0.2346435 Test Loss: 0.2624269\n",
      "Validation loss decreased (0.251713 --> 0.234643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2383796\n",
      "\tspeed: 0.1169s/iter; left time: 728.3092s\n",
      "\titers: 200, epoch: 4 | loss: 0.2254887\n",
      "\tspeed: 0.0470s/iter; left time: 287.8584s\n",
      "\titers: 300, epoch: 4 | loss: 0.2504866\n",
      "\tspeed: 0.0473s/iter; left time: 284.9244s\n",
      "\titers: 400, epoch: 4 | loss: 0.2294751\n",
      "\tspeed: 0.0471s/iter; left time: 279.0207s\n",
      "\titers: 500, epoch: 4 | loss: 0.2393156\n",
      "\tspeed: 0.0469s/iter; left time: 273.4581s\n",
      "\titers: 600, epoch: 4 | loss: 0.2135119\n",
      "\tspeed: 0.0469s/iter; left time: 268.8396s\n",
      "\titers: 700, epoch: 4 | loss: 0.2433015\n",
      "\tspeed: 0.0473s/iter; left time: 266.0163s\n",
      "\titers: 800, epoch: 4 | loss: 0.2229665\n",
      "\tspeed: 0.0471s/iter; left time: 260.2189s\n",
      "\titers: 900, epoch: 4 | loss: 0.2053911\n",
      "\tspeed: 0.0469s/iter; left time: 254.8192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.2304690 Vali Loss: 0.2361450 Test Loss: 0.2645998\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2325177\n",
      "\tspeed: 0.1149s/iter; left time: 611.8691s\n",
      "\titers: 200, epoch: 5 | loss: 0.1985134\n",
      "\tspeed: 0.0475s/iter; left time: 248.0737s\n",
      "\titers: 300, epoch: 5 | loss: 0.2265277\n",
      "\tspeed: 0.0474s/iter; left time: 242.9874s\n",
      "\titers: 400, epoch: 5 | loss: 0.2089091\n",
      "\tspeed: 0.0473s/iter; left time: 237.7510s\n",
      "\titers: 500, epoch: 5 | loss: 0.2146145\n",
      "\tspeed: 0.0471s/iter; left time: 231.8437s\n",
      "\titers: 600, epoch: 5 | loss: 0.1989035\n",
      "\tspeed: 0.0472s/iter; left time: 227.7578s\n",
      "\titers: 700, epoch: 5 | loss: 0.1927797\n",
      "\tspeed: 0.0487s/iter; left time: 230.1957s\n",
      "\titers: 800, epoch: 5 | loss: 0.2129710\n",
      "\tspeed: 0.0479s/iter; left time: 221.3371s\n",
      "\titers: 900, epoch: 5 | loss: 0.2192665\n",
      "\tspeed: 0.0472s/iter; left time: 213.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.2171487 Vali Loss: 0.2318016 Test Loss: 0.2570986\n",
      "Validation loss decreased (0.234643 --> 0.231802).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2084969\n",
      "\tspeed: 0.1167s/iter; left time: 515.7562s\n",
      "\titers: 200, epoch: 6 | loss: 0.1960920\n",
      "\tspeed: 0.0474s/iter; left time: 204.6015s\n",
      "\titers: 300, epoch: 6 | loss: 0.1975544\n",
      "\tspeed: 0.0472s/iter; left time: 199.1091s\n",
      "\titers: 400, epoch: 6 | loss: 0.2043416\n",
      "\tspeed: 0.0466s/iter; left time: 192.0208s\n",
      "\titers: 500, epoch: 6 | loss: 0.1878395\n",
      "\tspeed: 0.0476s/iter; left time: 191.2629s\n",
      "\titers: 600, epoch: 6 | loss: 0.1995321\n",
      "\tspeed: 0.0472s/iter; left time: 184.8964s\n",
      "\titers: 700, epoch: 6 | loss: 0.1923771\n",
      "\tspeed: 0.0473s/iter; left time: 180.9114s\n",
      "\titers: 800, epoch: 6 | loss: 0.1949241\n",
      "\tspeed: 0.0471s/iter; left time: 175.2477s\n",
      "\titers: 900, epoch: 6 | loss: 0.1903680\n",
      "\tspeed: 0.0474s/iter; left time: 171.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.91s\n",
      "Steps: 904 | Train Loss: 0.2058508 Vali Loss: 0.2401966 Test Loss: 0.2729353\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2076644\n",
      "\tspeed: 0.1128s/iter; left time: 396.8121s\n",
      "\titers: 200, epoch: 7 | loss: 0.2082104\n",
      "\tspeed: 0.0470s/iter; left time: 160.7667s\n",
      "\titers: 300, epoch: 7 | loss: 0.1862247\n",
      "\tspeed: 0.0471s/iter; left time: 156.1758s\n",
      "\titers: 400, epoch: 7 | loss: 0.1918603\n",
      "\tspeed: 0.0472s/iter; left time: 151.9866s\n",
      "\titers: 500, epoch: 7 | loss: 0.2082264\n",
      "\tspeed: 0.0472s/iter; left time: 147.0251s\n",
      "\titers: 600, epoch: 7 | loss: 0.1977967\n",
      "\tspeed: 0.0469s/iter; left time: 141.4618s\n",
      "\titers: 700, epoch: 7 | loss: 0.1790795\n",
      "\tspeed: 0.0470s/iter; left time: 137.0395s\n",
      "\titers: 800, epoch: 7 | loss: 0.1721518\n",
      "\tspeed: 0.0472s/iter; left time: 133.0916s\n",
      "\titers: 900, epoch: 7 | loss: 0.1934605\n",
      "\tspeed: 0.0469s/iter; left time: 127.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.82s\n",
      "Steps: 904 | Train Loss: 0.1956340 Vali Loss: 0.2346087 Test Loss: 0.2638255\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1697118\n",
      "\tspeed: 0.1109s/iter; left time: 289.6941s\n",
      "\titers: 200, epoch: 8 | loss: 0.1707996\n",
      "\tspeed: 0.0417s/iter; left time: 104.7575s\n",
      "\titers: 300, epoch: 8 | loss: 0.1900202\n",
      "\tspeed: 0.0490s/iter; left time: 118.3149s\n",
      "\titers: 400, epoch: 8 | loss: 0.1792226\n",
      "\tspeed: 0.0493s/iter; left time: 114.0551s\n",
      "\titers: 500, epoch: 8 | loss: 0.1682744\n",
      "\tspeed: 0.0495s/iter; left time: 109.4872s\n",
      "\titers: 600, epoch: 8 | loss: 0.1779657\n",
      "\tspeed: 0.0460s/iter; left time: 97.1204s\n",
      "\titers: 700, epoch: 8 | loss: 0.1766959\n",
      "\tspeed: 0.0470s/iter; left time: 94.5642s\n",
      "\titers: 800, epoch: 8 | loss: 0.1739851\n",
      "\tspeed: 0.0435s/iter; left time: 83.1857s\n",
      "\titers: 900, epoch: 8 | loss: 0.1696727\n",
      "\tspeed: 0.0441s/iter; left time: 80.0369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 904 | Train Loss: 0.1860251 Vali Loss: 0.2392129 Test Loss: 0.2659991\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.17835581302642822, rmse:0.42232194542884827, mae:0.25708287954330444, rse:0.5326288938522339\n",
      "Original data scale mse:2883676.75, rmse:1698.13916015625, mae:1115.929931640625, rse:0.11950498819351196\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5632496\n",
      "\tspeed: 0.0830s/iter; left time: 740.7944s\n",
      "\titers: 200, epoch: 1 | loss: 0.5157527\n",
      "\tspeed: 0.0533s/iter; left time: 470.5417s\n",
      "\titers: 300, epoch: 1 | loss: 0.5225931\n",
      "\tspeed: 0.0530s/iter; left time: 462.4681s\n",
      "\titers: 400, epoch: 1 | loss: 0.5064175\n",
      "\tspeed: 0.0534s/iter; left time: 460.7277s\n",
      "\titers: 500, epoch: 1 | loss: 0.4810719\n",
      "\tspeed: 0.0534s/iter; left time: 455.0067s\n",
      "\titers: 600, epoch: 1 | loss: 0.4809999\n",
      "\tspeed: 0.0533s/iter; left time: 448.5249s\n",
      "\titers: 700, epoch: 1 | loss: 0.4591694\n",
      "\tspeed: 0.0532s/iter; left time: 442.8845s\n",
      "\titers: 800, epoch: 1 | loss: 0.4808295\n",
      "\tspeed: 0.0530s/iter; left time: 435.8347s\n",
      "\titers: 900, epoch: 1 | loss: 0.4464947\n",
      "\tspeed: 0.0532s/iter; left time: 431.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.78s\n",
      "Steps: 902 | Train Loss: 0.4963819 Vali Loss: 0.4380530 Test Loss: 0.4737262\n",
      "Validation loss decreased (inf --> 0.438053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4330719\n",
      "\tspeed: 0.1220s/iter; left time: 978.1042s\n",
      "\titers: 200, epoch: 2 | loss: 0.3893396\n",
      "\tspeed: 0.0426s/iter; left time: 337.0944s\n",
      "\titers: 300, epoch: 2 | loss: 0.3565597\n",
      "\tspeed: 0.0425s/iter; left time: 332.3930s\n",
      "\titers: 400, epoch: 2 | loss: 0.3294356\n",
      "\tspeed: 0.0425s/iter; left time: 328.4396s\n",
      "\titers: 500, epoch: 2 | loss: 0.3018270\n",
      "\tspeed: 0.0426s/iter; left time: 324.2466s\n",
      "\titers: 600, epoch: 2 | loss: 0.3169613\n",
      "\tspeed: 0.0425s/iter; left time: 319.7372s\n",
      "\titers: 700, epoch: 2 | loss: 0.2771275\n",
      "\tspeed: 0.0426s/iter; left time: 315.6814s\n",
      "\titers: 800, epoch: 2 | loss: 0.2816032\n",
      "\tspeed: 0.0425s/iter; left time: 311.2600s\n",
      "\titers: 900, epoch: 2 | loss: 0.2748971\n",
      "\tspeed: 0.0425s/iter; left time: 307.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 902 | Train Loss: 0.3392451 Vali Loss: 0.2828687 Test Loss: 0.3127548\n",
      "Validation loss decreased (0.438053 --> 0.282869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2557863\n",
      "\tspeed: 0.1221s/iter; left time: 869.1969s\n",
      "\titers: 200, epoch: 3 | loss: 0.2850989\n",
      "\tspeed: 0.0426s/iter; left time: 298.7850s\n",
      "\titers: 300, epoch: 3 | loss: 0.2787260\n",
      "\tspeed: 0.0426s/iter; left time: 294.5779s\n",
      "\titers: 400, epoch: 3 | loss: 0.2852941\n",
      "\tspeed: 0.0426s/iter; left time: 290.3637s\n",
      "\titers: 500, epoch: 3 | loss: 0.2793160\n",
      "\tspeed: 0.0426s/iter; left time: 285.8982s\n",
      "\titers: 600, epoch: 3 | loss: 0.2520508\n",
      "\tspeed: 0.0426s/iter; left time: 281.7621s\n",
      "\titers: 700, epoch: 3 | loss: 0.2584607\n",
      "\tspeed: 0.0426s/iter; left time: 277.4774s\n",
      "\titers: 800, epoch: 3 | loss: 0.2498769\n",
      "\tspeed: 0.0426s/iter; left time: 273.3059s\n",
      "\titers: 900, epoch: 3 | loss: 0.2536239\n",
      "\tspeed: 0.0426s/iter; left time: 268.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 902 | Train Loss: 0.2655078 Vali Loss: 0.2571282 Test Loss: 0.2876839\n",
      "Validation loss decreased (0.282869 --> 0.257128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2511209\n",
      "\tspeed: 0.1313s/iter; left time: 816.2297s\n",
      "\titers: 200, epoch: 4 | loss: 0.2478851\n",
      "\tspeed: 0.0535s/iter; left time: 327.2596s\n",
      "\titers: 300, epoch: 4 | loss: 0.2678837\n",
      "\tspeed: 0.0532s/iter; left time: 320.0443s\n",
      "\titers: 400, epoch: 4 | loss: 0.2342361\n",
      "\tspeed: 0.0533s/iter; left time: 315.0167s\n",
      "\titers: 500, epoch: 4 | loss: 0.2349243\n",
      "\tspeed: 0.0532s/iter; left time: 309.6219s\n",
      "\titers: 600, epoch: 4 | loss: 0.2358436\n",
      "\tspeed: 0.0534s/iter; left time: 304.9643s\n",
      "\titers: 700, epoch: 4 | loss: 0.2612453\n",
      "\tspeed: 0.0533s/iter; left time: 299.5092s\n",
      "\titers: 800, epoch: 4 | loss: 0.2574546\n",
      "\tspeed: 0.0535s/iter; left time: 294.9436s\n",
      "\titers: 900, epoch: 4 | loss: 0.2365944\n",
      "\tspeed: 0.0533s/iter; left time: 288.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.32s\n",
      "Steps: 902 | Train Loss: 0.2442949 Vali Loss: 0.2538681 Test Loss: 0.2768912\n",
      "Validation loss decreased (0.257128 --> 0.253868).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2193953\n",
      "\tspeed: 0.1331s/iter; left time: 707.2679s\n",
      "\titers: 200, epoch: 5 | loss: 0.2179842\n",
      "\tspeed: 0.0534s/iter; left time: 278.2102s\n",
      "\titers: 300, epoch: 5 | loss: 0.2360814\n",
      "\tspeed: 0.0535s/iter; left time: 273.3457s\n",
      "\titers: 400, epoch: 5 | loss: 0.2377615\n",
      "\tspeed: 0.0530s/iter; left time: 265.9079s\n",
      "\titers: 500, epoch: 5 | loss: 0.2363496\n",
      "\tspeed: 0.0535s/iter; left time: 262.9627s\n",
      "\titers: 600, epoch: 5 | loss: 0.2460192\n",
      "\tspeed: 0.0533s/iter; left time: 256.4488s\n",
      "\titers: 700, epoch: 5 | loss: 0.2457788\n",
      "\tspeed: 0.0534s/iter; left time: 251.6651s\n",
      "\titers: 800, epoch: 5 | loss: 0.2220787\n",
      "\tspeed: 0.0536s/iter; left time: 247.4824s\n",
      "\titers: 900, epoch: 5 | loss: 0.2101454\n",
      "\tspeed: 0.0533s/iter; left time: 240.6346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.2286190 Vali Loss: 0.2507990 Test Loss: 0.2743211\n",
      "Validation loss decreased (0.253868 --> 0.250799).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2139448\n",
      "\tspeed: 0.1337s/iter; left time: 589.6982s\n",
      "\titers: 200, epoch: 6 | loss: 0.2156881\n",
      "\tspeed: 0.0547s/iter; left time: 235.8534s\n",
      "\titers: 300, epoch: 6 | loss: 0.1959274\n",
      "\tspeed: 0.0531s/iter; left time: 223.6519s\n",
      "\titers: 400, epoch: 6 | loss: 0.2159407\n",
      "\tspeed: 0.0534s/iter; left time: 219.4428s\n",
      "\titers: 500, epoch: 6 | loss: 0.2154929\n",
      "\tspeed: 0.0533s/iter; left time: 213.8546s\n",
      "\titers: 600, epoch: 6 | loss: 0.2082460\n",
      "\tspeed: 0.0533s/iter; left time: 208.4073s\n",
      "\titers: 700, epoch: 6 | loss: 0.2061070\n",
      "\tspeed: 0.0532s/iter; left time: 202.8335s\n",
      "\titers: 800, epoch: 6 | loss: 0.2044578\n",
      "\tspeed: 0.0528s/iter; left time: 195.8487s\n",
      "\titers: 900, epoch: 6 | loss: 0.2099167\n",
      "\tspeed: 0.0532s/iter; left time: 192.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.51s\n",
      "Steps: 902 | Train Loss: 0.2151362 Vali Loss: 0.2525556 Test Loss: 0.2818373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2145544\n",
      "\tspeed: 0.1316s/iter; left time: 461.9511s\n",
      "\titers: 200, epoch: 7 | loss: 0.2077160\n",
      "\tspeed: 0.0531s/iter; left time: 181.1511s\n",
      "\titers: 300, epoch: 7 | loss: 0.1872474\n",
      "\tspeed: 0.0535s/iter; left time: 177.0622s\n",
      "\titers: 400, epoch: 7 | loss: 0.2064607\n",
      "\tspeed: 0.0532s/iter; left time: 170.7752s\n",
      "\titers: 500, epoch: 7 | loss: 0.2029885\n",
      "\tspeed: 0.0533s/iter; left time: 165.8356s\n",
      "\titers: 600, epoch: 7 | loss: 0.2078575\n",
      "\tspeed: 0.0534s/iter; left time: 160.5704s\n",
      "\titers: 700, epoch: 7 | loss: 0.2009865\n",
      "\tspeed: 0.0535s/iter; left time: 155.5503s\n",
      "\titers: 800, epoch: 7 | loss: 0.1900662\n",
      "\tspeed: 0.0535s/iter; left time: 150.2426s\n",
      "\titers: 900, epoch: 7 | loss: 0.1870289\n",
      "\tspeed: 0.0536s/iter; left time: 145.1170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.2037051 Vali Loss: 0.2534152 Test Loss: 0.2857353\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1959792\n",
      "\tspeed: 0.1307s/iter; left time: 340.6820s\n",
      "\titers: 200, epoch: 8 | loss: 0.1916496\n",
      "\tspeed: 0.0534s/iter; left time: 133.8008s\n",
      "\titers: 300, epoch: 8 | loss: 0.2030609\n",
      "\tspeed: 0.0535s/iter; left time: 128.7537s\n",
      "\titers: 400, epoch: 8 | loss: 0.1842758\n",
      "\tspeed: 0.0534s/iter; left time: 123.1915s\n",
      "\titers: 500, epoch: 8 | loss: 0.2033385\n",
      "\tspeed: 0.0538s/iter; left time: 118.6975s\n",
      "\titers: 600, epoch: 8 | loss: 0.1765361\n",
      "\tspeed: 0.0541s/iter; left time: 113.9100s\n",
      "\titers: 700, epoch: 8 | loss: 0.1814290\n",
      "\tspeed: 0.0534s/iter; left time: 107.1938s\n",
      "\titers: 800, epoch: 8 | loss: 0.1856684\n",
      "\tspeed: 0.0537s/iter; left time: 102.3870s\n",
      "\titers: 900, epoch: 8 | loss: 0.1858994\n",
      "\tspeed: 0.0536s/iter; left time: 96.8201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1918486 Vali Loss: 0.2561021 Test Loss: 0.2780934\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.1986117660999298, rmse:0.445658802986145, mae:0.2743431031703949, rse:0.5614455938339233\n",
      "Original data scale mse:3670718.0, rmse:1915.9117431640625, mae:1241.1048583984375, rse:0.13495714962482452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5457351\n",
      "\tspeed: 0.0566s/iter; left time: 505.3249s\n",
      "\titers: 200, epoch: 1 | loss: 0.5282264\n",
      "\tspeed: 0.0546s/iter; left time: 481.6154s\n",
      "\titers: 300, epoch: 1 | loss: 0.5236274\n",
      "\tspeed: 0.0540s/iter; left time: 470.7641s\n",
      "\titers: 400, epoch: 1 | loss: 0.4873364\n",
      "\tspeed: 0.0532s/iter; left time: 458.7364s\n",
      "\titers: 500, epoch: 1 | loss: 0.5103250\n",
      "\tspeed: 0.0532s/iter; left time: 453.1004s\n",
      "\titers: 600, epoch: 1 | loss: 0.4482754\n",
      "\tspeed: 0.0537s/iter; left time: 452.2883s\n",
      "\titers: 700, epoch: 1 | loss: 0.4625291\n",
      "\tspeed: 0.0538s/iter; left time: 447.4308s\n",
      "\titers: 800, epoch: 1 | loss: 0.4470968\n",
      "\tspeed: 0.0533s/iter; left time: 438.2881s\n",
      "\titers: 900, epoch: 1 | loss: 0.4476103\n",
      "\tspeed: 0.0531s/iter; left time: 431.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.4975166 Vali Loss: 0.4339187 Test Loss: 0.4721376\n",
      "Validation loss decreased (inf --> 0.433919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4327614\n",
      "\tspeed: 0.1336s/iter; left time: 1071.3273s\n",
      "\titers: 200, epoch: 2 | loss: 0.3745706\n",
      "\tspeed: 0.0535s/iter; left time: 423.3517s\n",
      "\titers: 300, epoch: 2 | loss: 0.3375767\n",
      "\tspeed: 0.0535s/iter; left time: 418.0493s\n",
      "\titers: 400, epoch: 2 | loss: 0.3305673\n",
      "\tspeed: 0.0536s/iter; left time: 414.0333s\n",
      "\titers: 500, epoch: 2 | loss: 0.2993053\n",
      "\tspeed: 0.0535s/iter; left time: 407.4923s\n",
      "\titers: 600, epoch: 2 | loss: 0.3125845\n",
      "\tspeed: 0.0531s/iter; left time: 399.6328s\n",
      "\titers: 700, epoch: 2 | loss: 0.2725176\n",
      "\tspeed: 0.0533s/iter; left time: 395.4394s\n",
      "\titers: 800, epoch: 2 | loss: 0.3078899\n",
      "\tspeed: 0.0533s/iter; left time: 390.1788s\n",
      "\titers: 900, epoch: 2 | loss: 0.3088821\n",
      "\tspeed: 0.0536s/iter; left time: 387.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.3349405 Vali Loss: 0.2755053 Test Loss: 0.2961000\n",
      "Validation loss decreased (0.433919 --> 0.275505).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2862371\n",
      "\tspeed: 0.1381s/iter; left time: 982.9267s\n",
      "\titers: 200, epoch: 3 | loss: 0.2703195\n",
      "\tspeed: 0.0543s/iter; left time: 380.9892s\n",
      "\titers: 300, epoch: 3 | loss: 0.2668331\n",
      "\tspeed: 0.0543s/iter; left time: 375.2759s\n",
      "\titers: 400, epoch: 3 | loss: 0.2816649\n",
      "\tspeed: 0.0538s/iter; left time: 366.9804s\n",
      "\titers: 500, epoch: 3 | loss: 0.2603705\n",
      "\tspeed: 0.0533s/iter; left time: 357.9738s\n",
      "\titers: 600, epoch: 3 | loss: 0.2601631\n",
      "\tspeed: 0.0534s/iter; left time: 353.3462s\n",
      "\titers: 700, epoch: 3 | loss: 0.2542909\n",
      "\tspeed: 0.0535s/iter; left time: 348.5974s\n",
      "\titers: 800, epoch: 3 | loss: 0.2753270\n",
      "\tspeed: 0.0526s/iter; left time: 337.7030s\n",
      "\titers: 900, epoch: 3 | loss: 0.2467102\n",
      "\tspeed: 0.0533s/iter; left time: 336.5134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.2655737 Vali Loss: 0.2521651 Test Loss: 0.2810098\n",
      "Validation loss decreased (0.275505 --> 0.252165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2506363\n",
      "\tspeed: 0.1331s/iter; left time: 827.3443s\n",
      "\titers: 200, epoch: 4 | loss: 0.2414227\n",
      "\tspeed: 0.0532s/iter; left time: 325.5158s\n",
      "\titers: 300, epoch: 4 | loss: 0.2542776\n",
      "\tspeed: 0.0533s/iter; left time: 320.6653s\n",
      "\titers: 400, epoch: 4 | loss: 0.2567456\n",
      "\tspeed: 0.0533s/iter; left time: 315.5052s\n",
      "\titers: 500, epoch: 4 | loss: 0.2462144\n",
      "\tspeed: 0.0532s/iter; left time: 309.6437s\n",
      "\titers: 600, epoch: 4 | loss: 0.2383162\n",
      "\tspeed: 0.0532s/iter; left time: 304.2010s\n",
      "\titers: 700, epoch: 4 | loss: 0.2410191\n",
      "\tspeed: 0.0535s/iter; left time: 300.5779s\n",
      "\titers: 800, epoch: 4 | loss: 0.2308063\n",
      "\tspeed: 0.0533s/iter; left time: 293.7284s\n",
      "\titers: 900, epoch: 4 | loss: 0.2438544\n",
      "\tspeed: 0.0537s/iter; left time: 290.9130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.2451951 Vali Loss: 0.2500954 Test Loss: 0.2752612\n",
      "Validation loss decreased (0.252165 --> 0.250095).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2437989\n",
      "\tspeed: 0.1222s/iter; left time: 649.3465s\n",
      "\titers: 200, epoch: 5 | loss: 0.2259947\n",
      "\tspeed: 0.0426s/iter; left time: 221.9999s\n",
      "\titers: 300, epoch: 5 | loss: 0.2319941\n",
      "\tspeed: 0.0426s/iter; left time: 217.7861s\n",
      "\titers: 400, epoch: 5 | loss: 0.2390596\n",
      "\tspeed: 0.0426s/iter; left time: 213.3919s\n",
      "\titers: 500, epoch: 5 | loss: 0.2380520\n",
      "\tspeed: 0.0426s/iter; left time: 209.1694s\n",
      "\titers: 600, epoch: 5 | loss: 0.2440550\n",
      "\tspeed: 0.0426s/iter; left time: 204.8844s\n",
      "\titers: 700, epoch: 5 | loss: 0.2459286\n",
      "\tspeed: 0.0426s/iter; left time: 200.6821s\n",
      "\titers: 800, epoch: 5 | loss: 0.2140070\n",
      "\tspeed: 0.0426s/iter; left time: 196.4969s\n",
      "\titers: 900, epoch: 5 | loss: 0.2049489\n",
      "\tspeed: 0.0426s/iter; left time: 192.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 902 | Train Loss: 0.2310374 Vali Loss: 0.2522435 Test Loss: 0.2711625\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2384680\n",
      "\tspeed: 0.1290s/iter; left time: 569.0554s\n",
      "\titers: 200, epoch: 6 | loss: 0.2129129\n",
      "\tspeed: 0.0535s/iter; left time: 230.5736s\n",
      "\titers: 300, epoch: 6 | loss: 0.2252229\n",
      "\tspeed: 0.0533s/iter; left time: 224.3544s\n",
      "\titers: 400, epoch: 6 | loss: 0.2482168\n",
      "\tspeed: 0.0534s/iter; left time: 219.4611s\n",
      "\titers: 500, epoch: 6 | loss: 0.2043865\n",
      "\tspeed: 0.0533s/iter; left time: 213.9853s\n",
      "\titers: 600, epoch: 6 | loss: 0.2184150\n",
      "\tspeed: 0.0533s/iter; left time: 208.5547s\n",
      "\titers: 700, epoch: 6 | loss: 0.2206749\n",
      "\tspeed: 0.0539s/iter; left time: 205.3108s\n",
      "\titers: 800, epoch: 6 | loss: 0.2014902\n",
      "\tspeed: 0.0533s/iter; left time: 197.8232s\n",
      "\titers: 900, epoch: 6 | loss: 0.1992556\n",
      "\tspeed: 0.0532s/iter; left time: 192.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.2182060 Vali Loss: 0.2485982 Test Loss: 0.2788172\n",
      "Validation loss decreased (0.250095 --> 0.248598).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2268518\n",
      "\tspeed: 0.1321s/iter; left time: 463.4375s\n",
      "\titers: 200, epoch: 7 | loss: 0.1959685\n",
      "\tspeed: 0.0529s/iter; left time: 180.2719s\n",
      "\titers: 300, epoch: 7 | loss: 0.2199124\n",
      "\tspeed: 0.0533s/iter; left time: 176.2295s\n",
      "\titers: 400, epoch: 7 | loss: 0.2110029\n",
      "\tspeed: 0.0532s/iter; left time: 170.8075s\n",
      "\titers: 500, epoch: 7 | loss: 0.2112837\n",
      "\tspeed: 0.0536s/iter; left time: 166.5283s\n",
      "\titers: 600, epoch: 7 | loss: 0.2058442\n",
      "\tspeed: 0.0535s/iter; left time: 160.9561s\n",
      "\titers: 700, epoch: 7 | loss: 0.2065753\n",
      "\tspeed: 0.0531s/iter; left time: 154.4960s\n",
      "\titers: 800, epoch: 7 | loss: 0.1991162\n",
      "\tspeed: 0.0532s/iter; left time: 149.5157s\n",
      "\titers: 900, epoch: 7 | loss: 0.1958534\n",
      "\tspeed: 0.0534s/iter; left time: 144.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.29s\n",
      "Steps: 902 | Train Loss: 0.2060740 Vali Loss: 0.2488902 Test Loss: 0.2776476\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1959849\n",
      "\tspeed: 0.1291s/iter; left time: 336.6893s\n",
      "\titers: 200, epoch: 8 | loss: 0.1851822\n",
      "\tspeed: 0.0536s/iter; left time: 134.3725s\n",
      "\titers: 300, epoch: 8 | loss: 0.1907590\n",
      "\tspeed: 0.0534s/iter; left time: 128.5736s\n",
      "\titers: 400, epoch: 8 | loss: 0.1977106\n",
      "\tspeed: 0.0524s/iter; left time: 120.9297s\n",
      "\titers: 500, epoch: 8 | loss: 0.2159291\n",
      "\tspeed: 0.0533s/iter; left time: 117.6742s\n",
      "\titers: 600, epoch: 8 | loss: 0.1979827\n",
      "\tspeed: 0.0532s/iter; left time: 112.1569s\n",
      "\titers: 700, epoch: 8 | loss: 0.2029708\n",
      "\tspeed: 0.0534s/iter; left time: 107.2124s\n",
      "\titers: 800, epoch: 8 | loss: 0.1968417\n",
      "\tspeed: 0.0533s/iter; left time: 101.5509s\n",
      "\titers: 900, epoch: 8 | loss: 0.2011698\n",
      "\tspeed: 0.0531s/iter; left time: 95.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.21s\n",
      "Steps: 902 | Train Loss: 0.1949730 Vali Loss: 0.2532729 Test Loss: 0.2763503\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1993018\n",
      "\tspeed: 0.1292s/iter; left time: 220.3438s\n",
      "\titers: 200, epoch: 9 | loss: 0.1774716\n",
      "\tspeed: 0.0531s/iter; left time: 85.1862s\n",
      "\titers: 300, epoch: 9 | loss: 0.1944499\n",
      "\tspeed: 0.0533s/iter; left time: 80.1721s\n",
      "\titers: 400, epoch: 9 | loss: 0.2078677\n",
      "\tspeed: 0.0534s/iter; left time: 75.0381s\n",
      "\titers: 500, epoch: 9 | loss: 0.1839815\n",
      "\tspeed: 0.0529s/iter; left time: 69.0919s\n",
      "\titers: 600, epoch: 9 | loss: 0.1692742\n",
      "\tspeed: 0.0532s/iter; left time: 64.0768s\n",
      "\titers: 700, epoch: 9 | loss: 0.1779524\n",
      "\tspeed: 0.0531s/iter; left time: 58.6744s\n",
      "\titers: 800, epoch: 9 | loss: 0.1794150\n",
      "\tspeed: 0.0533s/iter; left time: 53.5607s\n",
      "\titers: 900, epoch: 9 | loss: 0.1874640\n",
      "\tspeed: 0.0532s/iter; left time: 48.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 902 | Train Loss: 0.1844025 Vali Loss: 0.2545887 Test Loss: 0.2794953\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.20644119381904602, rmse:0.4543580114841461, mae:0.27873149514198303, rse:0.5724049806594849\n",
      "Original data scale mse:4193679.75, rmse:2047.8475341796875, mae:1284.98291015625, rse:0.14425072073936462\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type robust \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.3993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.3957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.2679</td>\n",
       "      <td>0.5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.4123</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.4017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.3993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.5136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>0.5553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.4147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.5326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.5614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.2064</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.5724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.1000  0.3163  0.1934  0.3993\n",
       "              2         24        0.0982  0.3134  0.1980  0.3957\n",
       "              1         96        0.1649  0.4061  0.2679  0.5121\n",
       "              2         96        0.1700  0.4123  0.2785  0.5200\n",
       "              1         168       0.1910  0.4370  0.2906  0.5506\n",
       "              2         168       0.1857  0.4310  0.2878  0.5429\n",
       "RMSE          1         24        0.1012  0.3181  0.1956  0.4017\n",
       "              2         24        0.1000  0.3162  0.1991  0.3993\n",
       "              1         96        0.1658  0.4072  0.2652  0.5136\n",
       "              2         96        0.1687  0.4107  0.2637  0.5180\n",
       "              1         168       0.1943  0.4408  0.2918  0.5553\n",
       "              2         168       0.1740  0.4172  0.2821  0.5255\n",
       "MAE           1         24        0.0991  0.3149  0.1830  0.3976\n",
       "              2         24        0.1078  0.3284  0.1878  0.4147\n",
       "              1         96        0.1948  0.4414  0.2628  0.5567\n",
       "              2         96        0.1784  0.4223  0.2571  0.5326\n",
       "              1         168       0.1986  0.4457  0.2743  0.5614\n",
       "              2         168       0.2064  0.4544  0.2787  0.5724"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT_robust.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT_robust.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1696561.000</td>\n",
       "      <td>1302.5210</td>\n",
       "      <td>857.1823</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1713331.125</td>\n",
       "      <td>1308.9427</td>\n",
       "      <td>885.3687</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3421302.000</td>\n",
       "      <td>1849.6761</td>\n",
       "      <td>1260.5140</td>\n",
       "      <td>0.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3697298.250</td>\n",
       "      <td>1922.8359</td>\n",
       "      <td>1325.6306</td>\n",
       "      <td>0.1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4675170.500</td>\n",
       "      <td>2162.2144</td>\n",
       "      <td>1425.9861</td>\n",
       "      <td>0.1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4445287.000</td>\n",
       "      <td>2108.3850</td>\n",
       "      <td>1414.0991</td>\n",
       "      <td>0.1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1772951.375</td>\n",
       "      <td>1331.5222</td>\n",
       "      <td>882.8345</td>\n",
       "      <td>0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1705655.875</td>\n",
       "      <td>1306.0076</td>\n",
       "      <td>881.3223</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3241397.750</td>\n",
       "      <td>1800.3882</td>\n",
       "      <td>1225.7509</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3074052.250</td>\n",
       "      <td>1753.2975</td>\n",
       "      <td>1195.1626</td>\n",
       "      <td>0.1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4601502.000</td>\n",
       "      <td>2145.1111</td>\n",
       "      <td>1414.7355</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3916505.500</td>\n",
       "      <td>1979.0162</td>\n",
       "      <td>1351.4399</td>\n",
       "      <td>0.1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1536245.125</td>\n",
       "      <td>1239.4536</td>\n",
       "      <td>781.2439</td>\n",
       "      <td>0.0871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1982624.500</td>\n",
       "      <td>1408.0570</td>\n",
       "      <td>824.5411</td>\n",
       "      <td>0.0989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3251107.500</td>\n",
       "      <td>1803.0828</td>\n",
       "      <td>1161.2264</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2883676.750</td>\n",
       "      <td>1698.1392</td>\n",
       "      <td>1115.9299</td>\n",
       "      <td>0.1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3670718.000</td>\n",
       "      <td>1915.9117</td>\n",
       "      <td>1241.1049</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4193679.750</td>\n",
       "      <td>2047.8475</td>\n",
       "      <td>1284.9829</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1696561.000  1302.5210   857.1823  0.0915\n",
       "              2         24        1713331.125  1308.9427   885.3687  0.0920\n",
       "              1         96        3421302.000  1849.6761  1260.5140  0.1302\n",
       "              2         96        3697298.250  1922.8359  1325.6306  0.1353\n",
       "              1         168       4675170.500  2162.2144  1425.9861  0.1523\n",
       "              2         168       4445287.000  2108.3850  1414.0991  0.1485\n",
       "RMSE          1         24        1772951.375  1331.5222   882.8345  0.0936\n",
       "              2         24        1705655.875  1306.0076   881.3223  0.0918\n",
       "              1         96        3241397.750  1800.3882  1225.7509  0.1267\n",
       "              2         96        3074052.250  1753.2975  1195.1626  0.1234\n",
       "              1         168       4601502.000  2145.1111  1414.7355  0.1511\n",
       "              2         168       3916505.500  1979.0162  1351.4399  0.1394\n",
       "MAE           1         24        1536245.125  1239.4536   781.2439  0.0871\n",
       "              2         24        1982624.500  1408.0570   824.5411  0.0989\n",
       "              1         96        3251107.500  1803.0828  1161.2264  0.1269\n",
       "              2         96        2883676.750  1698.1392  1115.9299  0.1195\n",
       "              1         168       3670718.000  1915.9117  1241.1049  0.1350\n",
       "              2         168       4193679.750  2047.8475  1284.9829  0.1443"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.4061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.3975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.4319</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.5447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.4092</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.5161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.1884</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.5468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.5404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.1035  0.3216  0.1854  0.4061\n",
       "         MSE            0.0991  0.3148  0.1957  0.3975\n",
       "         RMSE           0.1006  0.3172  0.1974  0.4005\n",
       "96       MAE            0.1866  0.4319  0.2600  0.5447\n",
       "         MSE            0.1674  0.4092  0.2732  0.5161\n",
       "         RMSE           0.1673  0.4090  0.2644  0.5158\n",
       "168      MAE            0.2025  0.4500  0.2765  0.5669\n",
       "         MSE            0.1884  0.4340  0.2892  0.5468\n",
       "         RMSE           0.1842  0.4290  0.2870  0.5404"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.604755e+06</td>\n",
       "      <td>1266.7830</td>\n",
       "      <td>791.1026</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.669194e+06</td>\n",
       "      <td>1291.9119</td>\n",
       "      <td>844.1920</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.674064e+06</td>\n",
       "      <td>1293.7100</td>\n",
       "      <td>840.1658</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.198224e+06</td>\n",
       "      <td>1786.7822</td>\n",
       "      <td>1147.4320</td>\n",
       "      <td>0.1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.237661e+06</td>\n",
       "      <td>1799.3419</td>\n",
       "      <td>1226.9742</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.360102e+06</td>\n",
       "      <td>1833.0565</td>\n",
       "      <td>1241.0765</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.304869e+06</td>\n",
       "      <td>2074.7513</td>\n",
       "      <td>1328.4107</td>\n",
       "      <td>0.1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.318529e+06</td>\n",
       "      <td>2076.8229</td>\n",
       "      <td>1384.6658</td>\n",
       "      <td>0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.214063e+06</td>\n",
       "      <td>2051.1109</td>\n",
       "      <td>1365.7545</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.604755e+06  1266.7830   791.1026  0.0890\n",
       "         MSE            1.669194e+06  1291.9119   844.1920  0.0908\n",
       "         RMSE           1.674064e+06  1293.7100   840.1658  0.0909\n",
       "96       MAE            3.198224e+06  1786.7822  1147.4320  0.1257\n",
       "         MSE            3.237661e+06  1799.3419  1226.9742  0.1266\n",
       "         RMSE           3.360102e+06  1833.0565  1241.0765  0.1290\n",
       "168      MAE            4.304869e+06  2074.7513  1328.4107  0.1461\n",
       "         MSE            4.318529e+06  2076.8229  1384.6658  0.1463\n",
       "         RMSE           4.214063e+06  2051.1109  1365.7545  0.1445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Robust Scaler PatchTST IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1597213\n",
      "\tspeed: 0.0558s/iter; left time: 492.5701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1250994\n",
      "\tspeed: 0.0273s/iter; left time: 238.2858s\n",
      "\titers: 300, epoch: 1 | loss: 0.1183494\n",
      "\tspeed: 0.0273s/iter; left time: 235.5671s\n",
      "\titers: 400, epoch: 1 | loss: 0.1200371\n",
      "\tspeed: 0.0273s/iter; left time: 233.2924s\n",
      "\titers: 500, epoch: 1 | loss: 0.1212121\n",
      "\tspeed: 0.0273s/iter; left time: 230.5028s\n",
      "\titers: 600, epoch: 1 | loss: 0.1070887\n",
      "\tspeed: 0.0274s/iter; left time: 227.8723s\n",
      "\titers: 700, epoch: 1 | loss: 0.0849379\n",
      "\tspeed: 0.0271s/iter; left time: 222.6512s\n",
      "\titers: 800, epoch: 1 | loss: 0.0773466\n",
      "\tspeed: 0.0270s/iter; left time: 219.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.1211446 Vali Loss: 0.0934547 Test Loss: 0.1050258\n",
      "Validation loss decreased (inf --> 0.093455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1046875\n",
      "\tspeed: 0.1047s/iter; left time: 830.8083s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901086\n",
      "\tspeed: 0.0275s/iter; left time: 215.6004s\n",
      "\titers: 300, epoch: 2 | loss: 0.1446357\n",
      "\tspeed: 0.0275s/iter; left time: 212.6261s\n",
      "\titers: 400, epoch: 2 | loss: 0.0899448\n",
      "\tspeed: 0.0275s/iter; left time: 209.7327s\n",
      "\titers: 500, epoch: 2 | loss: 0.0817133\n",
      "\tspeed: 0.0274s/iter; left time: 206.6250s\n",
      "\titers: 600, epoch: 2 | loss: 0.0633355\n",
      "\tspeed: 0.0273s/iter; left time: 203.1792s\n",
      "\titers: 700, epoch: 2 | loss: 0.0923676\n",
      "\tspeed: 0.0271s/iter; left time: 198.9474s\n",
      "\titers: 800, epoch: 2 | loss: 0.0815537\n",
      "\tspeed: 0.0273s/iter; left time: 197.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.0962395 Vali Loss: 0.0925558 Test Loss: 0.1077783\n",
      "Validation loss decreased (0.093455 --> 0.092556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0773425\n",
      "\tspeed: 0.1040s/iter; left time: 732.8297s\n",
      "\titers: 200, epoch: 3 | loss: 0.0915096\n",
      "\tspeed: 0.0273s/iter; left time: 189.6466s\n",
      "\titers: 300, epoch: 3 | loss: 0.0683660\n",
      "\tspeed: 0.0273s/iter; left time: 187.0268s\n",
      "\titers: 400, epoch: 3 | loss: 0.0776493\n",
      "\tspeed: 0.0274s/iter; left time: 184.7337s\n",
      "\titers: 500, epoch: 3 | loss: 0.0619924\n",
      "\tspeed: 0.0273s/iter; left time: 181.3883s\n",
      "\titers: 600, epoch: 3 | loss: 0.0987970\n",
      "\tspeed: 0.0273s/iter; left time: 178.5865s\n",
      "\titers: 700, epoch: 3 | loss: 0.0687947\n",
      "\tspeed: 0.0272s/iter; left time: 175.5858s\n",
      "\titers: 800, epoch: 3 | loss: 0.1024149\n",
      "\tspeed: 0.0273s/iter; left time: 173.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0838130 Vali Loss: 0.0877197 Test Loss: 0.1003925\n",
      "Validation loss decreased (0.092556 --> 0.087720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0834958\n",
      "\tspeed: 0.1044s/iter; left time: 642.5343s\n",
      "\titers: 200, epoch: 4 | loss: 0.0677629\n",
      "\tspeed: 0.0273s/iter; left time: 165.3090s\n",
      "\titers: 300, epoch: 4 | loss: 0.0847111\n",
      "\tspeed: 0.0273s/iter; left time: 162.5221s\n",
      "\titers: 400, epoch: 4 | loss: 0.0682502\n",
      "\tspeed: 0.0273s/iter; left time: 159.8846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0699396\n",
      "\tspeed: 0.0273s/iter; left time: 157.0513s\n",
      "\titers: 600, epoch: 4 | loss: 0.0684388\n",
      "\tspeed: 0.0274s/iter; left time: 154.9139s\n",
      "\titers: 700, epoch: 4 | loss: 0.0847527\n",
      "\tspeed: 0.0276s/iter; left time: 153.0600s\n",
      "\titers: 800, epoch: 4 | loss: 0.0710470\n",
      "\tspeed: 0.0275s/iter; left time: 150.1256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0789999 Vali Loss: 0.0927059 Test Loss: 0.1073676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0954331\n",
      "\tspeed: 0.1021s/iter; left time: 536.8096s\n",
      "\titers: 200, epoch: 5 | loss: 0.0770963\n",
      "\tspeed: 0.0273s/iter; left time: 140.9965s\n",
      "\titers: 300, epoch: 5 | loss: 0.1005868\n",
      "\tspeed: 0.0273s/iter; left time: 138.2904s\n",
      "\titers: 400, epoch: 5 | loss: 0.1043643\n",
      "\tspeed: 0.0273s/iter; left time: 135.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.0563995\n",
      "\tspeed: 0.0274s/iter; left time: 133.0035s\n",
      "\titers: 600, epoch: 5 | loss: 0.0707918\n",
      "\tspeed: 0.0274s/iter; left time: 130.1662s\n",
      "\titers: 700, epoch: 5 | loss: 0.0635249\n",
      "\tspeed: 0.0273s/iter; left time: 127.0955s\n",
      "\titers: 800, epoch: 5 | loss: 0.0539855\n",
      "\tspeed: 0.0274s/iter; left time: 125.0388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 893 | Train Loss: 0.0734447 Vali Loss: 0.0907736 Test Loss: 0.1066975\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0660317\n",
      "\tspeed: 0.1019s/iter; left time: 444.9644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0766751\n",
      "\tspeed: 0.0273s/iter; left time: 116.4848s\n",
      "\titers: 300, epoch: 6 | loss: 0.0615512\n",
      "\tspeed: 0.0273s/iter; left time: 113.7106s\n",
      "\titers: 400, epoch: 6 | loss: 0.0642925\n",
      "\tspeed: 0.0273s/iter; left time: 111.0112s\n",
      "\titers: 500, epoch: 6 | loss: 0.0574973\n",
      "\tspeed: 0.0273s/iter; left time: 108.2978s\n",
      "\titers: 600, epoch: 6 | loss: 0.0665430\n",
      "\tspeed: 0.0272s/iter; left time: 105.2305s\n",
      "\titers: 700, epoch: 6 | loss: 0.0494402\n",
      "\tspeed: 0.0271s/iter; left time: 101.9135s\n",
      "\titers: 800, epoch: 6 | loss: 0.0583621\n",
      "\tspeed: 0.0271s/iter; left time: 99.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.0665612 Vali Loss: 0.0955620 Test Loss: 0.1079434\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10039250552654266, rmse:0.3168477714061737, mae:0.20459148287773132, rse:0.4000839293003082\n",
      "Original data scale mse:1888251.625, rmse:1374.13671875, mae:946.0014038085938, rse:0.09656382352113724\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1339864\n",
      "\tspeed: 0.0297s/iter; left time: 261.9882s\n",
      "\titers: 200, epoch: 1 | loss: 0.1683416\n",
      "\tspeed: 0.0271s/iter; left time: 236.5932s\n",
      "\titers: 300, epoch: 1 | loss: 0.0765521\n",
      "\tspeed: 0.0276s/iter; left time: 238.2730s\n",
      "\titers: 400, epoch: 1 | loss: 0.1050904\n",
      "\tspeed: 0.0275s/iter; left time: 234.8986s\n",
      "\titers: 500, epoch: 1 | loss: 0.1090557\n",
      "\tspeed: 0.0273s/iter; left time: 230.5845s\n",
      "\titers: 600, epoch: 1 | loss: 0.0982645\n",
      "\tspeed: 0.0272s/iter; left time: 226.3015s\n",
      "\titers: 700, epoch: 1 | loss: 0.0859872\n",
      "\tspeed: 0.0271s/iter; left time: 223.2849s\n",
      "\titers: 800, epoch: 1 | loss: 0.0723544\n",
      "\tspeed: 0.0271s/iter; left time: 220.6493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 893 | Train Loss: 0.1211111 Vali Loss: 0.0935115 Test Loss: 0.1044003\n",
      "Validation loss decreased (inf --> 0.093512).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0965336\n",
      "\tspeed: 0.1062s/iter; left time: 843.3594s\n",
      "\titers: 200, epoch: 2 | loss: 0.1351564\n",
      "\tspeed: 0.0274s/iter; left time: 215.0672s\n",
      "\titers: 300, epoch: 2 | loss: 0.1131656\n",
      "\tspeed: 0.0276s/iter; left time: 213.4877s\n",
      "\titers: 400, epoch: 2 | loss: 0.0873700\n",
      "\tspeed: 0.0277s/iter; left time: 211.2441s\n",
      "\titers: 500, epoch: 2 | loss: 0.1027931\n",
      "\tspeed: 0.0276s/iter; left time: 207.8834s\n",
      "\titers: 600, epoch: 2 | loss: 0.0780926\n",
      "\tspeed: 0.0276s/iter; left time: 205.4877s\n",
      "\titers: 700, epoch: 2 | loss: 0.0758585\n",
      "\tspeed: 0.0276s/iter; left time: 202.8268s\n",
      "\titers: 800, epoch: 2 | loss: 0.0954981\n",
      "\tspeed: 0.0276s/iter; left time: 200.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.89s\n",
      "Steps: 893 | Train Loss: 0.0958624 Vali Loss: 0.0892682 Test Loss: 0.1018598\n",
      "Validation loss decreased (0.093512 --> 0.089268).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0959135\n",
      "\tspeed: 0.1054s/iter; left time: 742.2531s\n",
      "\titers: 200, epoch: 3 | loss: 0.0702423\n",
      "\tspeed: 0.0273s/iter; left time: 189.7445s\n",
      "\titers: 300, epoch: 3 | loss: 0.0891603\n",
      "\tspeed: 0.0274s/iter; left time: 187.2643s\n",
      "\titers: 400, epoch: 3 | loss: 0.0826331\n",
      "\tspeed: 0.0274s/iter; left time: 184.6692s\n",
      "\titers: 500, epoch: 3 | loss: 0.0931666\n",
      "\tspeed: 0.0272s/iter; left time: 181.0080s\n",
      "\titers: 600, epoch: 3 | loss: 0.0824374\n",
      "\tspeed: 0.0274s/iter; left time: 179.4092s\n",
      "\titers: 700, epoch: 3 | loss: 0.0787437\n",
      "\tspeed: 0.0272s/iter; left time: 175.1706s\n",
      "\titers: 800, epoch: 3 | loss: 0.0775265\n",
      "\tspeed: 0.0272s/iter; left time: 172.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 893 | Train Loss: 0.0839665 Vali Loss: 0.0885877 Test Loss: 0.1019922\n",
      "Validation loss decreased (0.089268 --> 0.088588).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0641621\n",
      "\tspeed: 0.1041s/iter; left time: 640.2125s\n",
      "\titers: 200, epoch: 4 | loss: 0.0746479\n",
      "\tspeed: 0.0273s/iter; left time: 165.3898s\n",
      "\titers: 300, epoch: 4 | loss: 0.0773972\n",
      "\tspeed: 0.0274s/iter; left time: 162.7931s\n",
      "\titers: 400, epoch: 4 | loss: 0.0764374\n",
      "\tspeed: 0.0273s/iter; left time: 160.0135s\n",
      "\titers: 500, epoch: 4 | loss: 0.0831675\n",
      "\tspeed: 0.0273s/iter; left time: 157.1815s\n",
      "\titers: 600, epoch: 4 | loss: 0.1124018\n",
      "\tspeed: 0.0273s/iter; left time: 154.1611s\n",
      "\titers: 700, epoch: 4 | loss: 0.0546787\n",
      "\tspeed: 0.0273s/iter; left time: 151.7595s\n",
      "\titers: 800, epoch: 4 | loss: 0.0659995\n",
      "\tspeed: 0.0272s/iter; left time: 148.3600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 893 | Train Loss: 0.0788353 Vali Loss: 0.0922952 Test Loss: 0.1075878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0738197\n",
      "\tspeed: 0.1021s/iter; left time: 536.9791s\n",
      "\titers: 200, epoch: 5 | loss: 0.0668928\n",
      "\tspeed: 0.0275s/iter; left time: 141.8952s\n",
      "\titers: 300, epoch: 5 | loss: 0.0914367\n",
      "\tspeed: 0.0275s/iter; left time: 139.1052s\n",
      "\titers: 400, epoch: 5 | loss: 0.0611364\n",
      "\tspeed: 0.0276s/iter; left time: 136.9117s\n",
      "\titers: 500, epoch: 5 | loss: 0.0621461\n",
      "\tspeed: 0.0275s/iter; left time: 133.8370s\n",
      "\titers: 600, epoch: 5 | loss: 0.0681009\n",
      "\tspeed: 0.0276s/iter; left time: 131.5189s\n",
      "\titers: 700, epoch: 5 | loss: 0.0552011\n",
      "\tspeed: 0.0277s/iter; left time: 129.1429s\n",
      "\titers: 800, epoch: 5 | loss: 0.0698908\n",
      "\tspeed: 0.0277s/iter; left time: 126.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 893 | Train Loss: 0.0724410 Vali Loss: 0.0961375 Test Loss: 0.1087638\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741726\n",
      "\tspeed: 0.1031s/iter; left time: 449.9492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0750352\n",
      "\tspeed: 0.0275s/iter; left time: 117.4409s\n",
      "\titers: 300, epoch: 6 | loss: 0.0675339\n",
      "\tspeed: 0.0275s/iter; left time: 114.4693s\n",
      "\titers: 400, epoch: 6 | loss: 0.0656991\n",
      "\tspeed: 0.0277s/iter; left time: 112.8301s\n",
      "\titers: 500, epoch: 6 | loss: 0.0554043\n",
      "\tspeed: 0.0278s/iter; left time: 110.2912s\n",
      "\titers: 600, epoch: 6 | loss: 0.0549924\n",
      "\tspeed: 0.0274s/iter; left time: 105.7672s\n",
      "\titers: 700, epoch: 6 | loss: 0.0739159\n",
      "\tspeed: 0.0273s/iter; left time: 102.9502s\n",
      "\titers: 800, epoch: 6 | loss: 0.0735174\n",
      "\tspeed: 0.0273s/iter; left time: 99.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 893 | Train Loss: 0.0659135 Vali Loss: 0.0993308 Test Loss: 0.1134894\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.1019921824336052, rmse:0.31936216354370117, mae:0.2025916576385498, rse:0.4032588303089142\n",
      "Original data scale mse:1746225.75, rmse:1321.4483642578125, mae:910.2933959960938, rse:0.09286129474639893\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2341200\n",
      "\tspeed: 0.0548s/iter; left time: 482.6242s\n",
      "\titers: 200, epoch: 1 | loss: 0.1970873\n",
      "\tspeed: 0.0274s/iter; left time: 239.0961s\n",
      "\titers: 300, epoch: 1 | loss: 0.2034905\n",
      "\tspeed: 0.0275s/iter; left time: 236.6363s\n",
      "\titers: 400, epoch: 1 | loss: 0.1596092\n",
      "\tspeed: 0.0275s/iter; left time: 234.0873s\n",
      "\titers: 500, epoch: 1 | loss: 0.1583280\n",
      "\tspeed: 0.0276s/iter; left time: 232.3473s\n",
      "\titers: 600, epoch: 1 | loss: 0.1714234\n",
      "\tspeed: 0.0277s/iter; left time: 229.8866s\n",
      "\titers: 700, epoch: 1 | loss: 0.1465727\n",
      "\tspeed: 0.0277s/iter; left time: 227.1701s\n",
      "\titers: 800, epoch: 1 | loss: 0.1333285\n",
      "\tspeed: 0.0276s/iter; left time: 223.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.08s\n",
      "Steps: 891 | Train Loss: 0.1802173 Vali Loss: 0.1529222 Test Loss: 0.1648951\n",
      "Validation loss decreased (inf --> 0.152922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1804525\n",
      "\tspeed: 0.1053s/iter; left time: 833.7747s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079828\n",
      "\tspeed: 0.0278s/iter; left time: 217.1496s\n",
      "\titers: 300, epoch: 2 | loss: 0.1522308\n",
      "\tspeed: 0.0278s/iter; left time: 214.2933s\n",
      "\titers: 400, epoch: 2 | loss: 0.1599253\n",
      "\tspeed: 0.0276s/iter; left time: 210.5707s\n",
      "\titers: 500, epoch: 2 | loss: 0.1273285\n",
      "\tspeed: 0.0276s/iter; left time: 207.7726s\n",
      "\titers: 600, epoch: 2 | loss: 0.1360627\n",
      "\tspeed: 0.0276s/iter; left time: 204.6566s\n",
      "\titers: 700, epoch: 2 | loss: 0.1698801\n",
      "\tspeed: 0.0276s/iter; left time: 201.8235s\n",
      "\titers: 800, epoch: 2 | loss: 0.1596209\n",
      "\tspeed: 0.0276s/iter; left time: 199.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.1547196 Vali Loss: 0.1640207 Test Loss: 0.1781331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1363002\n",
      "\tspeed: 0.1021s/iter; left time: 717.8443s\n",
      "\titers: 200, epoch: 3 | loss: 0.1276009\n",
      "\tspeed: 0.0275s/iter; left time: 190.3155s\n",
      "\titers: 300, epoch: 3 | loss: 0.1163533\n",
      "\tspeed: 0.0276s/iter; left time: 188.3056s\n",
      "\titers: 400, epoch: 3 | loss: 0.1281459\n",
      "\tspeed: 0.0277s/iter; left time: 186.5779s\n",
      "\titers: 500, epoch: 3 | loss: 0.1434186\n",
      "\tspeed: 0.0277s/iter; left time: 183.4490s\n",
      "\titers: 600, epoch: 3 | loss: 0.1208209\n",
      "\tspeed: 0.0276s/iter; left time: 180.2164s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158978\n",
      "\tspeed: 0.0277s/iter; left time: 177.8465s\n",
      "\titers: 800, epoch: 3 | loss: 0.1010047\n",
      "\tspeed: 0.0276s/iter; left time: 174.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 891 | Train Loss: 0.1253278 Vali Loss: 0.1771536 Test Loss: 0.2131480\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1094053\n",
      "\tspeed: 0.1030s/iter; left time: 632.2779s\n",
      "\titers: 200, epoch: 4 | loss: 0.1334031\n",
      "\tspeed: 0.0277s/iter; left time: 167.5084s\n",
      "\titers: 300, epoch: 4 | loss: 0.1041441\n",
      "\tspeed: 0.0277s/iter; left time: 164.4997s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910065\n",
      "\tspeed: 0.0277s/iter; left time: 161.8497s\n",
      "\titers: 500, epoch: 4 | loss: 0.1087371\n",
      "\tspeed: 0.0279s/iter; left time: 160.2632s\n",
      "\titers: 600, epoch: 4 | loss: 0.0779595\n",
      "\tspeed: 0.0280s/iter; left time: 157.7706s\n",
      "\titers: 700, epoch: 4 | loss: 0.0946297\n",
      "\tspeed: 0.0279s/iter; left time: 154.4071s\n",
      "\titers: 800, epoch: 4 | loss: 0.0862142\n",
      "\tspeed: 0.0279s/iter; left time: 151.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.98s\n",
      "Steps: 891 | Train Loss: 0.0957572 Vali Loss: 0.1879341 Test Loss: 0.2464297\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16489508748054504, rmse:0.4060727655887604, mae:0.2669159173965454, rse:0.5121355652809143\n",
      "Original data scale mse:3313422.5, rmse:1820.2808837890625, mae:1241.3648681640625, rse:0.12810060381889343\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2024392\n",
      "\tspeed: 0.0300s/iter; left time: 264.5508s\n",
      "\titers: 200, epoch: 1 | loss: 0.1924519\n",
      "\tspeed: 0.0276s/iter; left time: 240.2264s\n",
      "\titers: 300, epoch: 1 | loss: 0.1595831\n",
      "\tspeed: 0.0276s/iter; left time: 237.8742s\n",
      "\titers: 400, epoch: 1 | loss: 0.1520529\n",
      "\tspeed: 0.0276s/iter; left time: 234.6889s\n",
      "\titers: 500, epoch: 1 | loss: 0.1643772\n",
      "\tspeed: 0.0276s/iter; left time: 232.2008s\n",
      "\titers: 600, epoch: 1 | loss: 0.1653766\n",
      "\tspeed: 0.0277s/iter; left time: 229.8641s\n",
      "\titers: 700, epoch: 1 | loss: 0.1410253\n",
      "\tspeed: 0.0276s/iter; left time: 226.6826s\n",
      "\titers: 800, epoch: 1 | loss: 0.1737520\n",
      "\tspeed: 0.0276s/iter; left time: 224.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.88s\n",
      "Steps: 891 | Train Loss: 0.1806344 Vali Loss: 0.1516944 Test Loss: 0.1639820\n",
      "Validation loss decreased (inf --> 0.151694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2045955\n",
      "\tspeed: 0.1057s/iter; left time: 837.0142s\n",
      "\titers: 200, epoch: 2 | loss: 0.1591339\n",
      "\tspeed: 0.0277s/iter; left time: 216.7717s\n",
      "\titers: 300, epoch: 2 | loss: 0.1382622\n",
      "\tspeed: 0.0276s/iter; left time: 212.8393s\n",
      "\titers: 400, epoch: 2 | loss: 0.1916264\n",
      "\tspeed: 0.0276s/iter; left time: 210.5969s\n",
      "\titers: 500, epoch: 2 | loss: 0.1185527\n",
      "\tspeed: 0.0277s/iter; left time: 208.0004s\n",
      "\titers: 600, epoch: 2 | loss: 0.1718521\n",
      "\tspeed: 0.0276s/iter; left time: 205.0915s\n",
      "\titers: 700, epoch: 2 | loss: 0.1378508\n",
      "\tspeed: 0.0276s/iter; left time: 202.3410s\n",
      "\titers: 800, epoch: 2 | loss: 0.1313460\n",
      "\tspeed: 0.0276s/iter; left time: 199.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.90s\n",
      "Steps: 891 | Train Loss: 0.1556489 Vali Loss: 0.1548333 Test Loss: 0.1734604\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1239161\n",
      "\tspeed: 0.1031s/iter; left time: 724.7299s\n",
      "\titers: 200, epoch: 3 | loss: 0.1217060\n",
      "\tspeed: 0.0276s/iter; left time: 191.1615s\n",
      "\titers: 300, epoch: 3 | loss: 0.1278841\n",
      "\tspeed: 0.0277s/iter; left time: 189.1104s\n",
      "\titers: 400, epoch: 3 | loss: 0.1313275\n",
      "\tspeed: 0.0278s/iter; left time: 186.8224s\n",
      "\titers: 500, epoch: 3 | loss: 0.1193142\n",
      "\tspeed: 0.0278s/iter; left time: 184.3036s\n",
      "\titers: 600, epoch: 3 | loss: 0.1566745\n",
      "\tspeed: 0.0277s/iter; left time: 180.9702s\n",
      "\titers: 700, epoch: 3 | loss: 0.1231076\n",
      "\tspeed: 0.0277s/iter; left time: 178.1335s\n",
      "\titers: 800, epoch: 3 | loss: 0.1096978\n",
      "\tspeed: 0.0278s/iter; left time: 175.7867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 891 | Train Loss: 0.1297728 Vali Loss: 0.1683650 Test Loss: 0.1926656\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1557647\n",
      "\tspeed: 0.1039s/iter; left time: 637.9265s\n",
      "\titers: 200, epoch: 4 | loss: 0.1141226\n",
      "\tspeed: 0.0276s/iter; left time: 166.9296s\n",
      "\titers: 300, epoch: 4 | loss: 0.1133354\n",
      "\tspeed: 0.0278s/iter; left time: 164.9302s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011626\n",
      "\tspeed: 0.0277s/iter; left time: 161.6079s\n",
      "\titers: 500, epoch: 4 | loss: 0.1022714\n",
      "\tspeed: 0.0275s/iter; left time: 158.0151s\n",
      "\titers: 600, epoch: 4 | loss: 0.1066604\n",
      "\tspeed: 0.0277s/iter; left time: 156.1449s\n",
      "\titers: 700, epoch: 4 | loss: 0.0906046\n",
      "\tspeed: 0.0278s/iter; left time: 153.7807s\n",
      "\titers: 800, epoch: 4 | loss: 0.1011764\n",
      "\tspeed: 0.0276s/iter; left time: 149.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.90s\n",
      "Steps: 891 | Train Loss: 0.1017535 Vali Loss: 0.1884820 Test Loss: 0.2062596\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16398201882839203, rmse:0.4049469232559204, mae:0.26584017276763916, rse:0.510715663433075\n",
      "Original data scale mse:3265158.75, rmse:1806.9749755859375, mae:1229.9158935546875, rse:0.12716421484947205\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2090630\n",
      "\tspeed: 0.0539s/iter; left time: 473.8504s\n",
      "\titers: 200, epoch: 1 | loss: 0.1629724\n",
      "\tspeed: 0.0282s/iter; left time: 245.0072s\n",
      "\titers: 300, epoch: 1 | loss: 0.1781568\n",
      "\tspeed: 0.0282s/iter; left time: 242.1577s\n",
      "\titers: 400, epoch: 1 | loss: 0.2323732\n",
      "\tspeed: 0.0282s/iter; left time: 239.6803s\n",
      "\titers: 500, epoch: 1 | loss: 0.2177277\n",
      "\tspeed: 0.0282s/iter; left time: 236.7400s\n",
      "\titers: 600, epoch: 1 | loss: 0.1886678\n",
      "\tspeed: 0.0282s/iter; left time: 233.7516s\n",
      "\titers: 700, epoch: 1 | loss: 0.1934050\n",
      "\tspeed: 0.0282s/iter; left time: 230.8829s\n",
      "\titers: 800, epoch: 1 | loss: 0.1709991\n",
      "\tspeed: 0.0282s/iter; left time: 228.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 889 | Train Loss: 0.1919119 Vali Loss: 0.1659669 Test Loss: 0.1744513\n",
      "Validation loss decreased (inf --> 0.165967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1880974\n",
      "\tspeed: 0.1097s/iter; left time: 867.1244s\n",
      "\titers: 200, epoch: 2 | loss: 0.1600982\n",
      "\tspeed: 0.0281s/iter; left time: 218.9840s\n",
      "\titers: 300, epoch: 2 | loss: 0.1921943\n",
      "\tspeed: 0.0281s/iter; left time: 216.3437s\n",
      "\titers: 400, epoch: 2 | loss: 0.1617059\n",
      "\tspeed: 0.0280s/iter; left time: 212.7282s\n",
      "\titers: 500, epoch: 2 | loss: 0.1528340\n",
      "\tspeed: 0.0280s/iter; left time: 210.2969s\n",
      "\titers: 600, epoch: 2 | loss: 0.1682263\n",
      "\tspeed: 0.0281s/iter; left time: 207.8753s\n",
      "\titers: 700, epoch: 2 | loss: 0.1455965\n",
      "\tspeed: 0.0280s/iter; left time: 204.5959s\n",
      "\titers: 800, epoch: 2 | loss: 0.1571157\n",
      "\tspeed: 0.0280s/iter; left time: 201.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.1635362 Vali Loss: 0.1820531 Test Loss: 0.2002112\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1339155\n",
      "\tspeed: 0.1031s/iter; left time: 723.2836s\n",
      "\titers: 200, epoch: 3 | loss: 0.1331342\n",
      "\tspeed: 0.0282s/iter; left time: 195.2575s\n",
      "\titers: 300, epoch: 3 | loss: 0.1374989\n",
      "\tspeed: 0.0283s/iter; left time: 192.6579s\n",
      "\titers: 400, epoch: 3 | loss: 0.1307534\n",
      "\tspeed: 0.0282s/iter; left time: 189.5262s\n",
      "\titers: 500, epoch: 3 | loss: 0.1050283\n",
      "\tspeed: 0.0282s/iter; left time: 186.8159s\n",
      "\titers: 600, epoch: 3 | loss: 0.1111476\n",
      "\tspeed: 0.0283s/iter; left time: 184.0684s\n",
      "\titers: 700, epoch: 3 | loss: 0.1086499\n",
      "\tspeed: 0.0282s/iter; left time: 180.8570s\n",
      "\titers: 800, epoch: 3 | loss: 0.1148870\n",
      "\tspeed: 0.0280s/iter; left time: 176.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.25s\n",
      "Steps: 889 | Train Loss: 0.1223599 Vali Loss: 0.1985043 Test Loss: 0.2259413\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0939422\n",
      "\tspeed: 0.1023s/iter; left time: 626.3026s\n",
      "\titers: 200, epoch: 4 | loss: 0.0970908\n",
      "\tspeed: 0.0281s/iter; left time: 169.0675s\n",
      "\titers: 300, epoch: 4 | loss: 0.1021712\n",
      "\tspeed: 0.0281s/iter; left time: 166.2941s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011734\n",
      "\tspeed: 0.0281s/iter; left time: 163.6321s\n",
      "\titers: 500, epoch: 4 | loss: 0.0782180\n",
      "\tspeed: 0.0283s/iter; left time: 161.7562s\n",
      "\titers: 600, epoch: 4 | loss: 0.0796969\n",
      "\tspeed: 0.0281s/iter; left time: 157.9940s\n",
      "\titers: 700, epoch: 4 | loss: 0.0868369\n",
      "\tspeed: 0.0281s/iter; left time: 154.9991s\n",
      "\titers: 800, epoch: 4 | loss: 0.0868512\n",
      "\tspeed: 0.0281s/iter; left time: 152.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 889 | Train Loss: 0.0903683 Vali Loss: 0.2081348 Test Loss: 0.2496003\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.17445136606693268, rmse:0.4176737666130066, mae:0.27865853905677795, rse:0.5261897444725037\n",
      "Original data scale mse:3830158.0, rmse:1957.0789794921875, mae:1328.46728515625, rse:0.13785697519779205\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2212362\n",
      "\tspeed: 0.0298s/iter; left time: 262.3765s\n",
      "\titers: 200, epoch: 1 | loss: 0.2341052\n",
      "\tspeed: 0.0280s/iter; left time: 243.5058s\n",
      "\titers: 300, epoch: 1 | loss: 0.1774727\n",
      "\tspeed: 0.0280s/iter; left time: 240.8109s\n",
      "\titers: 400, epoch: 1 | loss: 0.2074321\n",
      "\tspeed: 0.0280s/iter; left time: 237.9046s\n",
      "\titers: 500, epoch: 1 | loss: 0.1755013\n",
      "\tspeed: 0.0280s/iter; left time: 235.0646s\n",
      "\titers: 600, epoch: 1 | loss: 0.1708292\n",
      "\tspeed: 0.0280s/iter; left time: 232.3639s\n",
      "\titers: 700, epoch: 1 | loss: 0.1518244\n",
      "\tspeed: 0.0280s/iter; left time: 229.5485s\n",
      "\titers: 800, epoch: 1 | loss: 0.1631507\n",
      "\tspeed: 0.0280s/iter; left time: 226.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 889 | Train Loss: 0.1926922 Vali Loss: 0.1653686 Test Loss: 0.1746410\n",
      "Validation loss decreased (inf --> 0.165369).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2093762\n",
      "\tspeed: 0.1061s/iter; left time: 838.0620s\n",
      "\titers: 200, epoch: 2 | loss: 0.1853182\n",
      "\tspeed: 0.0281s/iter; left time: 219.2383s\n",
      "\titers: 300, epoch: 2 | loss: 0.2010320\n",
      "\tspeed: 0.0281s/iter; left time: 216.5992s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334858\n",
      "\tspeed: 0.0280s/iter; left time: 213.2210s\n",
      "\titers: 500, epoch: 2 | loss: 0.1634093\n",
      "\tspeed: 0.0281s/iter; left time: 210.4836s\n",
      "\titers: 600, epoch: 2 | loss: 0.1622410\n",
      "\tspeed: 0.0280s/iter; left time: 207.6036s\n",
      "\titers: 700, epoch: 2 | loss: 0.1410507\n",
      "\tspeed: 0.0280s/iter; left time: 204.3197s\n",
      "\titers: 800, epoch: 2 | loss: 0.1338744\n",
      "\tspeed: 0.0280s/iter; left time: 201.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.22s\n",
      "Steps: 889 | Train Loss: 0.1637408 Vali Loss: 0.1933918 Test Loss: 0.2250580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1410722\n",
      "\tspeed: 0.1042s/iter; left time: 730.6886s\n",
      "\titers: 200, epoch: 3 | loss: 0.1409790\n",
      "\tspeed: 0.0280s/iter; left time: 193.2313s\n",
      "\titers: 300, epoch: 3 | loss: 0.1267419\n",
      "\tspeed: 0.0279s/iter; left time: 190.4202s\n",
      "\titers: 400, epoch: 3 | loss: 0.1227864\n",
      "\tspeed: 0.0279s/iter; left time: 187.5435s\n",
      "\titers: 500, epoch: 3 | loss: 0.1205181\n",
      "\tspeed: 0.0280s/iter; left time: 184.8951s\n",
      "\titers: 600, epoch: 3 | loss: 0.1220575\n",
      "\tspeed: 0.0279s/iter; left time: 182.0035s\n",
      "\titers: 700, epoch: 3 | loss: 0.1206595\n",
      "\tspeed: 0.0280s/iter; left time: 179.4527s\n",
      "\titers: 800, epoch: 3 | loss: 0.1057200\n",
      "\tspeed: 0.0281s/iter; left time: 177.4679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.1192647 Vali Loss: 0.2108539 Test Loss: 0.2479705\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982499\n",
      "\tspeed: 0.1048s/iter; left time: 641.7769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0871327\n",
      "\tspeed: 0.0279s/iter; left time: 168.3529s\n",
      "\titers: 300, epoch: 4 | loss: 0.0898557\n",
      "\tspeed: 0.0279s/iter; left time: 165.5726s\n",
      "\titers: 400, epoch: 4 | loss: 0.0894240\n",
      "\tspeed: 0.0280s/iter; left time: 162.8379s\n",
      "\titers: 500, epoch: 4 | loss: 0.0880447\n",
      "\tspeed: 0.0280s/iter; left time: 160.1470s\n",
      "\titers: 600, epoch: 4 | loss: 0.0883829\n",
      "\tspeed: 0.0280s/iter; left time: 157.2740s\n",
      "\titers: 700, epoch: 4 | loss: 0.0837920\n",
      "\tspeed: 0.0280s/iter; left time: 154.4101s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751467\n",
      "\tspeed: 0.0280s/iter; left time: 151.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.08s\n",
      "Steps: 889 | Train Loss: 0.0838826 Vali Loss: 0.2037654 Test Loss: 0.2503187\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.1746409386396408, rmse:0.41790062189102173, mae:0.2786635160446167, rse:0.5264756083488464\n",
      "Original data scale mse:3708326.75, rmse:1925.70166015625, mae:1313.2982177734375, rse:0.1356467604637146\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3989910\n",
      "\tspeed: 0.0538s/iter; left time: 474.9631s\n",
      "\titers: 200, epoch: 1 | loss: 0.3480688\n",
      "\tspeed: 0.0272s/iter; left time: 237.2423s\n",
      "\titers: 300, epoch: 1 | loss: 0.3341171\n",
      "\tspeed: 0.0272s/iter; left time: 234.5411s\n",
      "\titers: 400, epoch: 1 | loss: 0.3403762\n",
      "\tspeed: 0.0272s/iter; left time: 231.8264s\n",
      "\titers: 500, epoch: 1 | loss: 0.3413131\n",
      "\tspeed: 0.0271s/iter; left time: 228.6878s\n",
      "\titers: 600, epoch: 1 | loss: 0.3260587\n",
      "\tspeed: 0.0272s/iter; left time: 226.3962s\n",
      "\titers: 700, epoch: 1 | loss: 0.2893950\n",
      "\tspeed: 0.0272s/iter; left time: 223.5139s\n",
      "\titers: 800, epoch: 1 | loss: 0.2756058\n",
      "\tspeed: 0.0271s/iter; left time: 220.4895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.3382208 Vali Loss: 0.0921124 Test Loss: 0.1037538\n",
      "Validation loss decreased (inf --> 0.092112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3231943\n",
      "\tspeed: 0.1035s/iter; left time: 821.8424s\n",
      "\titers: 200, epoch: 2 | loss: 0.2976673\n",
      "\tspeed: 0.0274s/iter; left time: 214.4205s\n",
      "\titers: 300, epoch: 2 | loss: 0.3821830\n",
      "\tspeed: 0.0274s/iter; left time: 212.0891s\n",
      "\titers: 400, epoch: 2 | loss: 0.2997683\n",
      "\tspeed: 0.0274s/iter; left time: 209.6539s\n",
      "\titers: 500, epoch: 2 | loss: 0.2880152\n",
      "\tspeed: 0.0275s/iter; left time: 207.1183s\n",
      "\titers: 600, epoch: 2 | loss: 0.2474743\n",
      "\tspeed: 0.0275s/iter; left time: 204.8700s\n",
      "\titers: 700, epoch: 2 | loss: 0.3062989\n",
      "\tspeed: 0.0273s/iter; left time: 200.3345s\n",
      "\titers: 800, epoch: 2 | loss: 0.2893554\n",
      "\tspeed: 0.0273s/iter; left time: 197.7592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.3101324 Vali Loss: 0.0985880 Test Loss: 0.1140383\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2816568\n",
      "\tspeed: 0.1021s/iter; left time: 719.5476s\n",
      "\titers: 200, epoch: 3 | loss: 0.2972019\n",
      "\tspeed: 0.0273s/iter; left time: 189.5375s\n",
      "\titers: 300, epoch: 3 | loss: 0.2629269\n",
      "\tspeed: 0.0274s/iter; left time: 187.3139s\n",
      "\titers: 400, epoch: 3 | loss: 0.2759361\n",
      "\tspeed: 0.0274s/iter; left time: 184.5789s\n",
      "\titers: 500, epoch: 3 | loss: 0.2483260\n",
      "\tspeed: 0.0274s/iter; left time: 181.9984s\n",
      "\titers: 600, epoch: 3 | loss: 0.3212468\n",
      "\tspeed: 0.0273s/iter; left time: 178.8504s\n",
      "\titers: 700, epoch: 3 | loss: 0.2653025\n",
      "\tspeed: 0.0274s/iter; left time: 176.3925s\n",
      "\titers: 800, epoch: 3 | loss: 0.3290220\n",
      "\tspeed: 0.0274s/iter; left time: 173.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 893 | Train Loss: 0.2893106 Vali Loss: 0.0905131 Test Loss: 0.1023722\n",
      "Validation loss decreased (0.092112 --> 0.090513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2842466\n",
      "\tspeed: 0.1041s/iter; left time: 640.5656s\n",
      "\titers: 200, epoch: 4 | loss: 0.2640494\n",
      "\tspeed: 0.0275s/iter; left time: 166.3822s\n",
      "\titers: 300, epoch: 4 | loss: 0.2899533\n",
      "\tspeed: 0.0275s/iter; left time: 163.8589s\n",
      "\titers: 400, epoch: 4 | loss: 0.2643963\n",
      "\tspeed: 0.0275s/iter; left time: 160.7070s\n",
      "\titers: 500, epoch: 4 | loss: 0.2563494\n",
      "\tspeed: 0.0275s/iter; left time: 158.1060s\n",
      "\titers: 600, epoch: 4 | loss: 0.2600521\n",
      "\tspeed: 0.0274s/iter; left time: 154.9710s\n",
      "\titers: 700, epoch: 4 | loss: 0.3017710\n",
      "\tspeed: 0.0273s/iter; left time: 151.6834s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761797\n",
      "\tspeed: 0.0274s/iter; left time: 149.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.2801430 Vali Loss: 0.0948413 Test Loss: 0.1073414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3035616\n",
      "\tspeed: 0.1015s/iter; left time: 534.0297s\n",
      "\titers: 200, epoch: 5 | loss: 0.2914004\n",
      "\tspeed: 0.0275s/iter; left time: 141.6851s\n",
      "\titers: 300, epoch: 5 | loss: 0.3216172\n",
      "\tspeed: 0.0273s/iter; left time: 138.1169s\n",
      "\titers: 400, epoch: 5 | loss: 0.3155159\n",
      "\tspeed: 0.0273s/iter; left time: 135.4904s\n",
      "\titers: 500, epoch: 5 | loss: 0.2312642\n",
      "\tspeed: 0.0274s/iter; left time: 133.0036s\n",
      "\titers: 600, epoch: 5 | loss: 0.2586295\n",
      "\tspeed: 0.0275s/iter; left time: 130.8077s\n",
      "\titers: 700, epoch: 5 | loss: 0.2488789\n",
      "\tspeed: 0.0274s/iter; left time: 127.8385s\n",
      "\titers: 800, epoch: 5 | loss: 0.2362315\n",
      "\tspeed: 0.0273s/iter; left time: 124.6366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 893 | Train Loss: 0.2723506 Vali Loss: 0.0912558 Test Loss: 0.1060832\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2608481\n",
      "\tspeed: 0.1021s/iter; left time: 445.9190s\n",
      "\titers: 200, epoch: 6 | loss: 0.2868155\n",
      "\tspeed: 0.0274s/iter; left time: 116.7329s\n",
      "\titers: 300, epoch: 6 | loss: 0.2376749\n",
      "\tspeed: 0.0275s/iter; left time: 114.3732s\n",
      "\titers: 400, epoch: 6 | loss: 0.2524871\n",
      "\tspeed: 0.0272s/iter; left time: 110.5974s\n",
      "\titers: 500, epoch: 6 | loss: 0.2314128\n",
      "\tspeed: 0.0273s/iter; left time: 108.0741s\n",
      "\titers: 600, epoch: 6 | loss: 0.2399177\n",
      "\tspeed: 0.0274s/iter; left time: 105.8641s\n",
      "\titers: 700, epoch: 6 | loss: 0.2095089\n",
      "\tspeed: 0.0274s/iter; left time: 103.3127s\n",
      "\titers: 800, epoch: 6 | loss: 0.2338229\n",
      "\tspeed: 0.0274s/iter; left time: 100.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.2577121 Vali Loss: 0.0938100 Test Loss: 0.1058958\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10237220674753189, rmse:0.31995657086372375, mae:0.20851056277751923, rse:0.4040094316005707\n",
      "Original data scale mse:2111207.75, rmse:1452.99951171875, mae:989.4656372070312, rse:0.10210570693016052\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3609038\n",
      "\tspeed: 0.0298s/iter; left time: 263.4686s\n",
      "\titers: 200, epoch: 1 | loss: 0.4020252\n",
      "\tspeed: 0.0276s/iter; left time: 241.2164s\n",
      "\titers: 300, epoch: 1 | loss: 0.2708032\n",
      "\tspeed: 0.0276s/iter; left time: 238.2193s\n",
      "\titers: 400, epoch: 1 | loss: 0.3174036\n",
      "\tspeed: 0.0275s/iter; left time: 234.8551s\n",
      "\titers: 500, epoch: 1 | loss: 0.3279735\n",
      "\tspeed: 0.0273s/iter; left time: 230.5855s\n",
      "\titers: 600, epoch: 1 | loss: 0.3083421\n",
      "\tspeed: 0.0274s/iter; left time: 228.2219s\n",
      "\titers: 700, epoch: 1 | loss: 0.2919141\n",
      "\tspeed: 0.0274s/iter; left time: 225.6053s\n",
      "\titers: 800, epoch: 1 | loss: 0.2666186\n",
      "\tspeed: 0.0274s/iter; left time: 223.1259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 893 | Train Loss: 0.3382880 Vali Loss: 0.0921155 Test Loss: 0.1030186\n",
      "Validation loss decreased (inf --> 0.092115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3134976\n",
      "\tspeed: 0.1049s/iter; left time: 832.5041s\n",
      "\titers: 200, epoch: 2 | loss: 0.3640731\n",
      "\tspeed: 0.0274s/iter; left time: 214.5407s\n",
      "\titers: 300, epoch: 2 | loss: 0.3400637\n",
      "\tspeed: 0.0276s/iter; left time: 213.5992s\n",
      "\titers: 400, epoch: 2 | loss: 0.3014559\n",
      "\tspeed: 0.0275s/iter; left time: 210.1612s\n",
      "\titers: 500, epoch: 2 | loss: 0.3211347\n",
      "\tspeed: 0.0274s/iter; left time: 206.5788s\n",
      "\titers: 600, epoch: 2 | loss: 0.2866733\n",
      "\tspeed: 0.0274s/iter; left time: 203.9501s\n",
      "\titers: 700, epoch: 2 | loss: 0.2770926\n",
      "\tspeed: 0.0274s/iter; left time: 200.7784s\n",
      "\titers: 800, epoch: 2 | loss: 0.3091931\n",
      "\tspeed: 0.0275s/iter; left time: 198.7824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 893 | Train Loss: 0.3096243 Vali Loss: 0.0894267 Test Loss: 0.1013852\n",
      "Validation loss decreased (0.092115 --> 0.089427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3128515\n",
      "\tspeed: 0.1063s/iter; left time: 748.8976s\n",
      "\titers: 200, epoch: 3 | loss: 0.2726294\n",
      "\tspeed: 0.0274s/iter; left time: 190.4956s\n",
      "\titers: 300, epoch: 3 | loss: 0.3007500\n",
      "\tspeed: 0.0274s/iter; left time: 187.6775s\n",
      "\titers: 400, epoch: 3 | loss: 0.2807919\n",
      "\tspeed: 0.0274s/iter; left time: 184.8122s\n",
      "\titers: 500, epoch: 3 | loss: 0.3051299\n",
      "\tspeed: 0.0274s/iter; left time: 182.0463s\n",
      "\titers: 600, epoch: 3 | loss: 0.2895802\n",
      "\tspeed: 0.0274s/iter; left time: 179.2751s\n",
      "\titers: 700, epoch: 3 | loss: 0.2763083\n",
      "\tspeed: 0.0274s/iter; left time: 176.5954s\n",
      "\titers: 800, epoch: 3 | loss: 0.2818125\n",
      "\tspeed: 0.0275s/iter; left time: 174.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.2887402 Vali Loss: 0.0895663 Test Loss: 0.1012410\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2516356\n",
      "\tspeed: 0.1028s/iter; left time: 632.7123s\n",
      "\titers: 200, epoch: 4 | loss: 0.2713962\n",
      "\tspeed: 0.0274s/iter; left time: 165.5862s\n",
      "\titers: 300, epoch: 4 | loss: 0.2800739\n",
      "\tspeed: 0.0276s/iter; left time: 164.5450s\n",
      "\titers: 400, epoch: 4 | loss: 0.2768391\n",
      "\tspeed: 0.0275s/iter; left time: 160.6783s\n",
      "\titers: 500, epoch: 4 | loss: 0.2972456\n",
      "\tspeed: 0.0274s/iter; left time: 157.6733s\n",
      "\titers: 600, epoch: 4 | loss: 0.3253022\n",
      "\tspeed: 0.0274s/iter; left time: 154.8141s\n",
      "\titers: 700, epoch: 4 | loss: 0.2505515\n",
      "\tspeed: 0.0274s/iter; left time: 151.8934s\n",
      "\titers: 800, epoch: 4 | loss: 0.2636257\n",
      "\tspeed: 0.0274s/iter; left time: 149.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.2806044 Vali Loss: 0.0931152 Test Loss: 0.1077828\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2501178\n",
      "\tspeed: 0.1028s/iter; left time: 540.3803s\n",
      "\titers: 200, epoch: 5 | loss: 0.2635645\n",
      "\tspeed: 0.0274s/iter; left time: 141.5400s\n",
      "\titers: 300, epoch: 5 | loss: 0.2938690\n",
      "\tspeed: 0.0275s/iter; left time: 139.1661s\n",
      "\titers: 400, epoch: 5 | loss: 0.2527859\n",
      "\tspeed: 0.0275s/iter; left time: 136.5754s\n",
      "\titers: 500, epoch: 5 | loss: 0.2520196\n",
      "\tspeed: 0.0275s/iter; left time: 133.4459s\n",
      "\titers: 600, epoch: 5 | loss: 0.2486941\n",
      "\tspeed: 0.0275s/iter; left time: 130.8605s\n",
      "\titers: 700, epoch: 5 | loss: 0.2252842\n",
      "\tspeed: 0.0275s/iter; left time: 128.2071s\n",
      "\titers: 800, epoch: 5 | loss: 0.2644553\n",
      "\tspeed: 0.0274s/iter; left time: 124.8602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.2674203 Vali Loss: 0.0933809 Test Loss: 0.1064256\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10138523578643799, rmse:0.3184104859828949, mae:0.21016791462898254, rse:0.4020571708679199\n",
      "Original data scale mse:2039680.5, rmse:1428.173828125, mae:989.9337158203125, rse:0.10036113858222961\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4806145\n",
      "\tspeed: 0.0557s/iter; left time: 490.6763s\n",
      "\titers: 200, epoch: 1 | loss: 0.4410127\n",
      "\tspeed: 0.0273s/iter; left time: 237.7891s\n",
      "\titers: 300, epoch: 1 | loss: 0.4491694\n",
      "\tspeed: 0.0273s/iter; left time: 235.2691s\n",
      "\titers: 400, epoch: 1 | loss: 0.3976703\n",
      "\tspeed: 0.0273s/iter; left time: 232.1958s\n",
      "\titers: 500, epoch: 1 | loss: 0.3961725\n",
      "\tspeed: 0.0274s/iter; left time: 230.6699s\n",
      "\titers: 600, epoch: 1 | loss: 0.4105466\n",
      "\tspeed: 0.0277s/iter; left time: 230.4010s\n",
      "\titers: 700, epoch: 1 | loss: 0.3813154\n",
      "\tspeed: 0.0277s/iter; left time: 227.5417s\n",
      "\titers: 800, epoch: 1 | loss: 0.3626679\n",
      "\tspeed: 0.0277s/iter; left time: 224.7624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.05s\n",
      "Steps: 891 | Train Loss: 0.4202391 Vali Loss: 0.1523135 Test Loss: 0.1646045\n",
      "Validation loss decreased (inf --> 0.152314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4255570\n",
      "\tspeed: 0.1043s/iter; left time: 826.1318s\n",
      "\titers: 200, epoch: 2 | loss: 0.3334434\n",
      "\tspeed: 0.0276s/iter; left time: 216.1412s\n",
      "\titers: 300, epoch: 2 | loss: 0.3896848\n",
      "\tspeed: 0.0276s/iter; left time: 213.3342s\n",
      "\titers: 400, epoch: 2 | loss: 0.4011560\n",
      "\tspeed: 0.0276s/iter; left time: 210.0959s\n",
      "\titers: 500, epoch: 2 | loss: 0.3594693\n",
      "\tspeed: 0.0275s/iter; left time: 206.6586s\n",
      "\titers: 600, epoch: 2 | loss: 0.3763236\n",
      "\tspeed: 0.0274s/iter; left time: 203.6418s\n",
      "\titers: 700, epoch: 2 | loss: 0.4101681\n",
      "\tspeed: 0.0276s/iter; left time: 201.9079s\n",
      "\titers: 800, epoch: 2 | loss: 0.3975696\n",
      "\tspeed: 0.0276s/iter; left time: 198.9925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.3931998 Vali Loss: 0.1666144 Test Loss: 0.1793017\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3716863\n",
      "\tspeed: 0.1010s/iter; left time: 710.1721s\n",
      "\titers: 200, epoch: 3 | loss: 0.3535139\n",
      "\tspeed: 0.0274s/iter; left time: 189.9001s\n",
      "\titers: 300, epoch: 3 | loss: 0.3395999\n",
      "\tspeed: 0.0274s/iter; left time: 187.2158s\n",
      "\titers: 400, epoch: 3 | loss: 0.3639786\n",
      "\tspeed: 0.0274s/iter; left time: 184.5890s\n",
      "\titers: 500, epoch: 3 | loss: 0.3644648\n",
      "\tspeed: 0.0275s/iter; left time: 182.0432s\n",
      "\titers: 600, epoch: 3 | loss: 0.3531541\n",
      "\tspeed: 0.0274s/iter; left time: 178.9824s\n",
      "\titers: 700, epoch: 3 | loss: 0.3434492\n",
      "\tspeed: 0.0274s/iter; left time: 176.2478s\n",
      "\titers: 800, epoch: 3 | loss: 0.3246901\n",
      "\tspeed: 0.0275s/iter; left time: 174.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 891 | Train Loss: 0.3535897 Vali Loss: 0.1936742 Test Loss: 0.2110268\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3438401\n",
      "\tspeed: 0.1010s/iter; left time: 620.0538s\n",
      "\titers: 200, epoch: 4 | loss: 0.3594979\n",
      "\tspeed: 0.0274s/iter; left time: 165.6722s\n",
      "\titers: 300, epoch: 4 | loss: 0.3176903\n",
      "\tspeed: 0.0274s/iter; left time: 162.8844s\n",
      "\titers: 400, epoch: 4 | loss: 0.3145906\n",
      "\tspeed: 0.0274s/iter; left time: 160.1458s\n",
      "\titers: 500, epoch: 4 | loss: 0.3398534\n",
      "\tspeed: 0.0275s/iter; left time: 157.8882s\n",
      "\titers: 600, epoch: 4 | loss: 0.2849299\n",
      "\tspeed: 0.0276s/iter; left time: 155.7035s\n",
      "\titers: 700, epoch: 4 | loss: 0.2994181\n",
      "\tspeed: 0.0276s/iter; left time: 152.8867s\n",
      "\titers: 800, epoch: 4 | loss: 0.2955664\n",
      "\tspeed: 0.0276s/iter; left time: 150.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.3091080 Vali Loss: 0.2019832 Test Loss: 0.2337380\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.1646045446395874, rmse:0.40571486949920654, mae:0.26583579182624817, rse:0.5116841197013855\n",
      "Original data scale mse:3247477.0, rmse:1802.0758056640625, mae:1229.265869140625, rse:0.1268194317817688\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4457387\n",
      "\tspeed: 0.0296s/iter; left time: 260.6780s\n",
      "\titers: 200, epoch: 1 | loss: 0.4364135\n",
      "\tspeed: 0.0277s/iter; left time: 241.3699s\n",
      "\titers: 300, epoch: 1 | loss: 0.3971988\n",
      "\tspeed: 0.0277s/iter; left time: 238.9333s\n",
      "\titers: 400, epoch: 1 | loss: 0.3871042\n",
      "\tspeed: 0.0277s/iter; left time: 235.8781s\n",
      "\titers: 500, epoch: 1 | loss: 0.4002297\n",
      "\tspeed: 0.0276s/iter; left time: 232.2060s\n",
      "\titers: 600, epoch: 1 | loss: 0.4037428\n",
      "\tspeed: 0.0276s/iter; left time: 229.4870s\n",
      "\titers: 700, epoch: 1 | loss: 0.3744934\n",
      "\tspeed: 0.0276s/iter; left time: 226.6037s\n",
      "\titers: 800, epoch: 1 | loss: 0.4144305\n",
      "\tspeed: 0.0276s/iter; left time: 223.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.4202448 Vali Loss: 0.1510423 Test Loss: 0.1635220\n",
      "Validation loss decreased (inf --> 0.151042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4511295\n",
      "\tspeed: 0.1043s/iter; left time: 825.8392s\n",
      "\titers: 200, epoch: 2 | loss: 0.3991274\n",
      "\tspeed: 0.0276s/iter; left time: 215.5018s\n",
      "\titers: 300, epoch: 2 | loss: 0.3755276\n",
      "\tspeed: 0.0276s/iter; left time: 212.9318s\n",
      "\titers: 400, epoch: 2 | loss: 0.4383247\n",
      "\tspeed: 0.0276s/iter; left time: 210.3580s\n",
      "\titers: 500, epoch: 2 | loss: 0.3478123\n",
      "\tspeed: 0.0276s/iter; left time: 207.7418s\n",
      "\titers: 600, epoch: 2 | loss: 0.4091602\n",
      "\tspeed: 0.0276s/iter; left time: 204.5299s\n",
      "\titers: 700, epoch: 2 | loss: 0.3707311\n",
      "\tspeed: 0.0275s/iter; left time: 200.9512s\n",
      "\titers: 800, epoch: 2 | loss: 0.3657139\n",
      "\tspeed: 0.0275s/iter; left time: 198.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.3946149 Vali Loss: 0.1550614 Test Loss: 0.1746269\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3485519\n",
      "\tspeed: 0.1018s/iter; left time: 715.5327s\n",
      "\titers: 200, epoch: 3 | loss: 0.3509437\n",
      "\tspeed: 0.0275s/iter; left time: 190.7126s\n",
      "\titers: 300, epoch: 3 | loss: 0.3502270\n",
      "\tspeed: 0.0275s/iter; left time: 187.4590s\n",
      "\titers: 400, epoch: 3 | loss: 0.3528855\n",
      "\tspeed: 0.0277s/iter; left time: 186.4666s\n",
      "\titers: 500, epoch: 3 | loss: 0.3492180\n",
      "\tspeed: 0.0276s/iter; left time: 183.1725s\n",
      "\titers: 600, epoch: 3 | loss: 0.3854982\n",
      "\tspeed: 0.0275s/iter; left time: 179.3189s\n",
      "\titers: 700, epoch: 3 | loss: 0.3498884\n",
      "\tspeed: 0.0275s/iter; left time: 176.5921s\n",
      "\titers: 800, epoch: 3 | loss: 0.3353539\n",
      "\tspeed: 0.0275s/iter; left time: 173.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 891 | Train Loss: 0.3601749 Vali Loss: 0.1636765 Test Loss: 0.1951172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3983988\n",
      "\tspeed: 0.1012s/iter; left time: 621.3178s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400000\n",
      "\tspeed: 0.0275s/iter; left time: 165.8692s\n",
      "\titers: 300, epoch: 4 | loss: 0.3318728\n",
      "\tspeed: 0.0275s/iter; left time: 163.0123s\n",
      "\titers: 400, epoch: 4 | loss: 0.3196463\n",
      "\tspeed: 0.0275s/iter; left time: 160.3281s\n",
      "\titers: 500, epoch: 4 | loss: 0.3169048\n",
      "\tspeed: 0.0275s/iter; left time: 157.5605s\n",
      "\titers: 600, epoch: 4 | loss: 0.3175818\n",
      "\tspeed: 0.0275s/iter; left time: 154.8999s\n",
      "\titers: 700, epoch: 4 | loss: 0.2933449\n",
      "\tspeed: 0.0275s/iter; left time: 152.2120s\n",
      "\titers: 800, epoch: 4 | loss: 0.2952097\n",
      "\tspeed: 0.0275s/iter; left time: 149.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 891 | Train Loss: 0.3179477 Vali Loss: 0.1791535 Test Loss: 0.2200200\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16352199018001556, rmse:0.4043785333633423, mae:0.26456624269485474, rse:0.5099987983703613\n",
      "Original data scale mse:3191100.75, rmse:1786.365234375, mae:1216.0294189453125, rse:0.12571381032466888\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4550535\n",
      "\tspeed: 0.0524s/iter; left time: 460.6666s\n",
      "\titers: 200, epoch: 1 | loss: 0.4021184\n",
      "\tspeed: 0.0283s/iter; left time: 246.0006s\n",
      "\titers: 300, epoch: 1 | loss: 0.4205815\n",
      "\tspeed: 0.0283s/iter; left time: 242.7769s\n",
      "\titers: 400, epoch: 1 | loss: 0.4796296\n",
      "\tspeed: 0.0282s/iter; left time: 239.6894s\n",
      "\titers: 500, epoch: 1 | loss: 0.4641162\n",
      "\tspeed: 0.0283s/iter; left time: 237.2901s\n",
      "\titers: 600, epoch: 1 | loss: 0.4318978\n",
      "\tspeed: 0.0282s/iter; left time: 233.8680s\n",
      "\titers: 700, epoch: 1 | loss: 0.4377279\n",
      "\tspeed: 0.0282s/iter; left time: 230.7564s\n",
      "\titers: 800, epoch: 1 | loss: 0.4123153\n",
      "\tspeed: 0.0281s/iter; left time: 227.6168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 889 | Train Loss: 0.4342031 Vali Loss: 0.1654518 Test Loss: 0.1739884\n",
      "Validation loss decreased (inf --> 0.165452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4327364\n",
      "\tspeed: 0.1051s/iter; left time: 830.7608s\n",
      "\titers: 200, epoch: 2 | loss: 0.3994458\n",
      "\tspeed: 0.0281s/iter; left time: 219.0151s\n",
      "\titers: 300, epoch: 2 | loss: 0.4411756\n",
      "\tspeed: 0.0281s/iter; left time: 216.2450s\n",
      "\titers: 400, epoch: 2 | loss: 0.4046885\n",
      "\tspeed: 0.0281s/iter; left time: 213.3276s\n",
      "\titers: 500, epoch: 2 | loss: 0.3930683\n",
      "\tspeed: 0.0281s/iter; left time: 210.5946s\n",
      "\titers: 600, epoch: 2 | loss: 0.4133877\n",
      "\tspeed: 0.0281s/iter; left time: 207.7367s\n",
      "\titers: 700, epoch: 2 | loss: 0.3823970\n",
      "\tspeed: 0.0281s/iter; left time: 204.9165s\n",
      "\titers: 800, epoch: 2 | loss: 0.4037084\n",
      "\tspeed: 0.0280s/iter; left time: 201.8619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 889 | Train Loss: 0.4043863 Vali Loss: 0.1834058 Test Loss: 0.2026916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3544116\n",
      "\tspeed: 0.1043s/iter; left time: 731.2546s\n",
      "\titers: 200, epoch: 3 | loss: 0.3664211\n",
      "\tspeed: 0.0282s/iter; left time: 195.2385s\n",
      "\titers: 300, epoch: 3 | loss: 0.3679662\n",
      "\tspeed: 0.0283s/iter; left time: 192.5977s\n",
      "\titers: 400, epoch: 3 | loss: 0.3632869\n",
      "\tspeed: 0.0282s/iter; left time: 188.9930s\n",
      "\titers: 500, epoch: 3 | loss: 0.3222180\n",
      "\tspeed: 0.0283s/iter; left time: 186.9175s\n",
      "\titers: 600, epoch: 3 | loss: 0.3301865\n",
      "\tspeed: 0.0281s/iter; left time: 183.3138s\n",
      "\titers: 700, epoch: 3 | loss: 0.3273660\n",
      "\tspeed: 0.0281s/iter; left time: 180.1776s\n",
      "\titers: 800, epoch: 3 | loss: 0.3483750\n",
      "\tspeed: 0.0281s/iter; left time: 177.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.25s\n",
      "Steps: 889 | Train Loss: 0.3518882 Vali Loss: 0.1911889 Test Loss: 0.2279174\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3143254\n",
      "\tspeed: 0.1032s/iter; left time: 631.8564s\n",
      "\titers: 200, epoch: 4 | loss: 0.3083077\n",
      "\tspeed: 0.0283s/iter; left time: 170.4112s\n",
      "\titers: 300, epoch: 4 | loss: 0.3249684\n",
      "\tspeed: 0.0283s/iter; left time: 167.4809s\n",
      "\titers: 400, epoch: 4 | loss: 0.3152758\n",
      "\tspeed: 0.0281s/iter; left time: 163.5840s\n",
      "\titers: 500, epoch: 4 | loss: 0.2851378\n",
      "\tspeed: 0.0282s/iter; left time: 161.5238s\n",
      "\titers: 600, epoch: 4 | loss: 0.2846509\n",
      "\tspeed: 0.0282s/iter; left time: 158.6276s\n",
      "\titers: 700, epoch: 4 | loss: 0.2939020\n",
      "\tspeed: 0.0281s/iter; left time: 155.2405s\n",
      "\titers: 800, epoch: 4 | loss: 0.2968993\n",
      "\tspeed: 0.0281s/iter; left time: 152.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 889 | Train Loss: 0.3019878 Vali Loss: 0.2049049 Test Loss: 0.2476811\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.17398840188980103, rmse:0.41711917519569397, mae:0.27738022804260254, rse:0.5254910588264465\n",
      "Original data scale mse:3762426.0, rmse:1939.6973876953125, mae:1316.056640625, rse:0.13663262128829956\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4678350\n",
      "\tspeed: 0.0300s/iter; left time: 264.1230s\n",
      "\titers: 200, epoch: 1 | loss: 0.4815196\n",
      "\tspeed: 0.0280s/iter; left time: 243.6881s\n",
      "\titers: 300, epoch: 1 | loss: 0.4190159\n",
      "\tspeed: 0.0280s/iter; left time: 240.8207s\n",
      "\titers: 400, epoch: 1 | loss: 0.4535054\n",
      "\tspeed: 0.0280s/iter; left time: 238.1486s\n",
      "\titers: 500, epoch: 1 | loss: 0.4164034\n",
      "\tspeed: 0.0280s/iter; left time: 235.1918s\n",
      "\titers: 600, epoch: 1 | loss: 0.4107657\n",
      "\tspeed: 0.0280s/iter; left time: 232.4681s\n",
      "\titers: 700, epoch: 1 | loss: 0.3869986\n",
      "\tspeed: 0.0280s/iter; left time: 229.7045s\n",
      "\titers: 800, epoch: 1 | loss: 0.4026855\n",
      "\tspeed: 0.0280s/iter; left time: 226.8998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 889 | Train Loss: 0.4350193 Vali Loss: 0.1647244 Test Loss: 0.1738069\n",
      "Validation loss decreased (inf --> 0.164724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4564470\n",
      "\tspeed: 0.1083s/iter; left time: 855.6244s\n",
      "\titers: 200, epoch: 2 | loss: 0.4311280\n",
      "\tspeed: 0.0282s/iter; left time: 219.7238s\n",
      "\titers: 300, epoch: 2 | loss: 0.4499467\n",
      "\tspeed: 0.0282s/iter; left time: 216.8994s\n",
      "\titers: 400, epoch: 2 | loss: 0.3637415\n",
      "\tspeed: 0.0281s/iter; left time: 213.9516s\n",
      "\titers: 500, epoch: 2 | loss: 0.4051772\n",
      "\tspeed: 0.0281s/iter; left time: 210.8816s\n",
      "\titers: 600, epoch: 2 | loss: 0.3998567\n",
      "\tspeed: 0.0281s/iter; left time: 207.7576s\n",
      "\titers: 700, epoch: 2 | loss: 0.3737804\n",
      "\tspeed: 0.0280s/iter; left time: 204.5434s\n",
      "\titers: 800, epoch: 2 | loss: 0.3618955\n",
      "\tspeed: 0.0280s/iter; left time: 201.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.4041765 Vali Loss: 0.1857733 Test Loss: 0.2240428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3693920\n",
      "\tspeed: 0.1042s/iter; left time: 730.8209s\n",
      "\titers: 200, epoch: 3 | loss: 0.3667064\n",
      "\tspeed: 0.0280s/iter; left time: 193.8471s\n",
      "\titers: 300, epoch: 3 | loss: 0.3666658\n",
      "\tspeed: 0.0280s/iter; left time: 191.0354s\n",
      "\titers: 400, epoch: 3 | loss: 0.3490892\n",
      "\tspeed: 0.0280s/iter; left time: 188.1940s\n",
      "\titers: 500, epoch: 3 | loss: 0.3506680\n",
      "\tspeed: 0.0281s/iter; left time: 185.5864s\n",
      "\titers: 600, epoch: 3 | loss: 0.3436027\n",
      "\tspeed: 0.0281s/iter; left time: 182.8255s\n",
      "\titers: 700, epoch: 3 | loss: 0.3386174\n",
      "\tspeed: 0.0281s/iter; left time: 179.9322s\n",
      "\titers: 800, epoch: 3 | loss: 0.3220275\n",
      "\tspeed: 0.0280s/iter; left time: 176.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 889 | Train Loss: 0.3445081 Vali Loss: 0.2274043 Test Loss: 0.2704502\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3136992\n",
      "\tspeed: 0.1033s/iter; left time: 632.3835s\n",
      "\titers: 200, epoch: 4 | loss: 0.3061055\n",
      "\tspeed: 0.0280s/iter; left time: 168.7364s\n",
      "\titers: 300, epoch: 4 | loss: 0.3151884\n",
      "\tspeed: 0.0280s/iter; left time: 165.9985s\n",
      "\titers: 400, epoch: 4 | loss: 0.3045795\n",
      "\tspeed: 0.0280s/iter; left time: 163.2459s\n",
      "\titers: 500, epoch: 4 | loss: 0.2912776\n",
      "\tspeed: 0.0281s/iter; left time: 160.6777s\n",
      "\titers: 600, epoch: 4 | loss: 0.3059667\n",
      "\tspeed: 0.0281s/iter; left time: 157.8792s\n",
      "\titers: 700, epoch: 4 | loss: 0.2799786\n",
      "\tspeed: 0.0281s/iter; left time: 155.1858s\n",
      "\titers: 800, epoch: 4 | loss: 0.2715220\n",
      "\tspeed: 0.0281s/iter; left time: 152.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 889 | Train Loss: 0.2906914 Vali Loss: 0.2089854 Test Loss: 0.2487408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.17380684614181519, rmse:0.41690146923065186, mae:0.2771608531475067, rse:0.525216817855835\n",
      "Original data scale mse:3631123.5, rmse:1905.5506591796875, mae:1299.105712890625, rse:0.13422732055187225\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2772144\n",
      "\tspeed: 0.0541s/iter; left time: 478.0420s\n",
      "\titers: 200, epoch: 1 | loss: 0.2475164\n",
      "\tspeed: 0.0272s/iter; left time: 237.2989s\n",
      "\titers: 300, epoch: 1 | loss: 0.2355023\n",
      "\tspeed: 0.0272s/iter; left time: 234.6778s\n",
      "\titers: 400, epoch: 1 | loss: 0.2272906\n",
      "\tspeed: 0.0272s/iter; left time: 232.1881s\n",
      "\titers: 500, epoch: 1 | loss: 0.2278984\n",
      "\tspeed: 0.0272s/iter; left time: 229.0243s\n",
      "\titers: 600, epoch: 1 | loss: 0.2126096\n",
      "\tspeed: 0.0272s/iter; left time: 226.4802s\n",
      "\titers: 700, epoch: 1 | loss: 0.1988434\n",
      "\tspeed: 0.0272s/iter; left time: 223.6141s\n",
      "\titers: 800, epoch: 1 | loss: 0.1842585\n",
      "\tspeed: 0.0272s/iter; left time: 221.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.2340502 Vali Loss: 0.1930947 Test Loss: 0.2015129\n",
      "Validation loss decreased (inf --> 0.193095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2264264\n",
      "\tspeed: 0.1031s/iter; left time: 818.3054s\n",
      "\titers: 200, epoch: 2 | loss: 0.2112633\n",
      "\tspeed: 0.0272s/iter; left time: 212.9865s\n",
      "\titers: 300, epoch: 2 | loss: 0.2698058\n",
      "\tspeed: 0.0271s/iter; left time: 210.0144s\n",
      "\titers: 400, epoch: 2 | loss: 0.2040202\n",
      "\tspeed: 0.0271s/iter; left time: 207.2263s\n",
      "\titers: 500, epoch: 2 | loss: 0.2111203\n",
      "\tspeed: 0.0271s/iter; left time: 204.5403s\n",
      "\titers: 600, epoch: 2 | loss: 0.1921387\n",
      "\tspeed: 0.0271s/iter; left time: 201.8032s\n",
      "\titers: 700, epoch: 2 | loss: 0.2121211\n",
      "\tspeed: 0.0271s/iter; left time: 199.1688s\n",
      "\titers: 800, epoch: 2 | loss: 0.2006321\n",
      "\tspeed: 0.0272s/iter; left time: 196.7281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.2181770 Vali Loss: 0.2227596 Test Loss: 0.2096923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1940939\n",
      "\tspeed: 0.1006s/iter; left time: 708.6033s\n",
      "\titers: 200, epoch: 3 | loss: 0.1842032\n",
      "\tspeed: 0.0273s/iter; left time: 189.3204s\n",
      "\titers: 300, epoch: 3 | loss: 0.1972996\n",
      "\tspeed: 0.0272s/iter; left time: 186.2610s\n",
      "\titers: 400, epoch: 3 | loss: 0.1995529\n",
      "\tspeed: 0.0272s/iter; left time: 183.7567s\n",
      "\titers: 500, epoch: 3 | loss: 0.1805160\n",
      "\tspeed: 0.0275s/iter; left time: 182.4353s\n",
      "\titers: 600, epoch: 3 | loss: 0.2008158\n",
      "\tspeed: 0.0272s/iter; left time: 178.0713s\n",
      "\titers: 700, epoch: 3 | loss: 0.1638671\n",
      "\tspeed: 0.0272s/iter; left time: 175.2215s\n",
      "\titers: 800, epoch: 3 | loss: 0.2240271\n",
      "\tspeed: 0.0272s/iter; left time: 172.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 893 | Train Loss: 0.1965025 Vali Loss: 0.2113444 Test Loss: 0.1891241\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1902553\n",
      "\tspeed: 0.1001s/iter; left time: 615.8209s\n",
      "\titers: 200, epoch: 4 | loss: 0.1771242\n",
      "\tspeed: 0.0272s/iter; left time: 164.3140s\n",
      "\titers: 300, epoch: 4 | loss: 0.1901796\n",
      "\tspeed: 0.0272s/iter; left time: 161.7596s\n",
      "\titers: 400, epoch: 4 | loss: 0.1678884\n",
      "\tspeed: 0.0272s/iter; left time: 159.0412s\n",
      "\titers: 500, epoch: 4 | loss: 0.1680799\n",
      "\tspeed: 0.0272s/iter; left time: 156.3752s\n",
      "\titers: 600, epoch: 4 | loss: 0.1558320\n",
      "\tspeed: 0.0272s/iter; left time: 153.5937s\n",
      "\titers: 700, epoch: 4 | loss: 0.1975853\n",
      "\tspeed: 0.0273s/iter; left time: 151.2956s\n",
      "\titers: 800, epoch: 4 | loss: 0.1909087\n",
      "\tspeed: 0.0271s/iter; left time: 147.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.44s\n",
      "Steps: 893 | Train Loss: 0.1870509 Vali Loss: 0.2575877 Test Loss: 0.1948483\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.10682186484336853, rmse:0.32683613896369934, mae:0.20151293277740479, rse:0.4126962721347809\n",
      "Original data scale mse:1802445.75, rmse:1342.552001953125, mae:882.4845581054688, rse:0.09434428811073303\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2903316\n",
      "\tspeed: 0.0290s/iter; left time: 256.0624s\n",
      "\titers: 200, epoch: 1 | loss: 0.2391727\n",
      "\tspeed: 0.0273s/iter; left time: 238.2490s\n",
      "\titers: 300, epoch: 1 | loss: 0.2628285\n",
      "\tspeed: 0.0273s/iter; left time: 235.5204s\n",
      "\titers: 400, epoch: 1 | loss: 0.2225724\n",
      "\tspeed: 0.0273s/iter; left time: 232.8638s\n",
      "\titers: 500, epoch: 1 | loss: 0.2047613\n",
      "\tspeed: 0.0273s/iter; left time: 230.3827s\n",
      "\titers: 600, epoch: 1 | loss: 0.2103523\n",
      "\tspeed: 0.0273s/iter; left time: 227.4446s\n",
      "\titers: 700, epoch: 1 | loss: 0.2010889\n",
      "\tspeed: 0.0273s/iter; left time: 224.5583s\n",
      "\titers: 800, epoch: 1 | loss: 0.2023016\n",
      "\tspeed: 0.0273s/iter; left time: 221.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 893 | Train Loss: 0.2363033 Vali Loss: 0.1945681 Test Loss: 0.2035963\n",
      "Validation loss decreased (inf --> 0.194568).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2460272\n",
      "\tspeed: 0.1042s/iter; left time: 827.3922s\n",
      "\titers: 200, epoch: 2 | loss: 0.2003957\n",
      "\tspeed: 0.0272s/iter; left time: 213.0871s\n",
      "\titers: 300, epoch: 2 | loss: 0.2269491\n",
      "\tspeed: 0.0272s/iter; left time: 210.5552s\n",
      "\titers: 400, epoch: 2 | loss: 0.2315074\n",
      "\tspeed: 0.0274s/iter; left time: 208.9846s\n",
      "\titers: 500, epoch: 2 | loss: 0.2197893\n",
      "\tspeed: 0.0273s/iter; left time: 205.4500s\n",
      "\titers: 600, epoch: 2 | loss: 0.1995071\n",
      "\tspeed: 0.0274s/iter; left time: 203.4937s\n",
      "\titers: 700, epoch: 2 | loss: 0.1902653\n",
      "\tspeed: 0.0273s/iter; left time: 200.4068s\n",
      "\titers: 800, epoch: 2 | loss: 0.2188397\n",
      "\tspeed: 0.0274s/iter; left time: 198.2419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.62s\n",
      "Steps: 893 | Train Loss: 0.2170928 Vali Loss: 0.2129313 Test Loss: 0.1963166\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1942241\n",
      "\tspeed: 0.1008s/iter; left time: 709.8744s\n",
      "\titers: 200, epoch: 3 | loss: 0.2110985\n",
      "\tspeed: 0.0271s/iter; left time: 188.4505s\n",
      "\titers: 300, epoch: 3 | loss: 0.1582796\n",
      "\tspeed: 0.0272s/iter; left time: 186.0013s\n",
      "\titers: 400, epoch: 3 | loss: 0.1779147\n",
      "\tspeed: 0.0272s/iter; left time: 183.3523s\n",
      "\titers: 500, epoch: 3 | loss: 0.1943081\n",
      "\tspeed: 0.0272s/iter; left time: 180.4831s\n",
      "\titers: 600, epoch: 3 | loss: 0.1656040\n",
      "\tspeed: 0.0272s/iter; left time: 177.8438s\n",
      "\titers: 700, epoch: 3 | loss: 0.1727342\n",
      "\tspeed: 0.0272s/iter; left time: 175.2643s\n",
      "\titers: 800, epoch: 3 | loss: 0.1648997\n",
      "\tspeed: 0.0272s/iter; left time: 172.4945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.45s\n",
      "Steps: 893 | Train Loss: 0.1913670 Vali Loss: 0.1845313 Test Loss: 0.1870741\n",
      "Validation loss decreased (0.194568 --> 0.184531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1604781\n",
      "\tspeed: 0.1041s/iter; left time: 640.3599s\n",
      "\titers: 200, epoch: 4 | loss: 0.2048772\n",
      "\tspeed: 0.0272s/iter; left time: 164.5514s\n",
      "\titers: 300, epoch: 4 | loss: 0.1891525\n",
      "\tspeed: 0.0272s/iter; left time: 161.7558s\n",
      "\titers: 400, epoch: 4 | loss: 0.1767827\n",
      "\tspeed: 0.0272s/iter; left time: 158.9703s\n",
      "\titers: 500, epoch: 4 | loss: 0.2109392\n",
      "\tspeed: 0.0272s/iter; left time: 156.4334s\n",
      "\titers: 600, epoch: 4 | loss: 0.1704210\n",
      "\tspeed: 0.0272s/iter; left time: 153.7519s\n",
      "\titers: 700, epoch: 4 | loss: 0.1621516\n",
      "\tspeed: 0.0272s/iter; left time: 151.1858s\n",
      "\titers: 800, epoch: 4 | loss: 0.1787823\n",
      "\tspeed: 0.0273s/iter; left time: 148.6377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.1807038 Vali Loss: 0.2036673 Test Loss: 0.1907268\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2015843\n",
      "\tspeed: 0.1008s/iter; left time: 529.9055s\n",
      "\titers: 200, epoch: 5 | loss: 0.1716271\n",
      "\tspeed: 0.0273s/iter; left time: 140.6595s\n",
      "\titers: 300, epoch: 5 | loss: 0.1764363\n",
      "\tspeed: 0.0273s/iter; left time: 138.2657s\n",
      "\titers: 400, epoch: 5 | loss: 0.1743835\n",
      "\tspeed: 0.0273s/iter; left time: 135.1742s\n",
      "\titers: 500, epoch: 5 | loss: 0.1826175\n",
      "\tspeed: 0.0274s/iter; left time: 132.9952s\n",
      "\titers: 600, epoch: 5 | loss: 0.1632469\n",
      "\tspeed: 0.0274s/iter; left time: 130.3078s\n",
      "\titers: 700, epoch: 5 | loss: 0.1755288\n",
      "\tspeed: 0.0273s/iter; left time: 127.4023s\n",
      "\titers: 800, epoch: 5 | loss: 0.1783555\n",
      "\tspeed: 0.0272s/iter; left time: 124.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.56s\n",
      "Steps: 893 | Train Loss: 0.1765098 Vali Loss: 0.1873488 Test Loss: 0.1856604\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1551464\n",
      "\tspeed: 0.1010s/iter; left time: 440.7549s\n",
      "\titers: 200, epoch: 6 | loss: 0.1562647\n",
      "\tspeed: 0.0273s/iter; left time: 116.4770s\n",
      "\titers: 300, epoch: 6 | loss: 0.1570591\n",
      "\tspeed: 0.0273s/iter; left time: 113.5520s\n",
      "\titers: 400, epoch: 6 | loss: 0.1616910\n",
      "\tspeed: 0.0273s/iter; left time: 110.9614s\n",
      "\titers: 500, epoch: 6 | loss: 0.1772716\n",
      "\tspeed: 0.0272s/iter; left time: 107.8020s\n",
      "\titers: 600, epoch: 6 | loss: 0.1845962\n",
      "\tspeed: 0.0272s/iter; left time: 105.0627s\n",
      "\titers: 700, epoch: 6 | loss: 0.1390236\n",
      "\tspeed: 0.0271s/iter; left time: 102.2262s\n",
      "\titers: 800, epoch: 6 | loss: 0.1598069\n",
      "\tspeed: 0.0272s/iter; left time: 99.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.1686121 Vali Loss: 0.1758340 Test Loss: 0.1838346\n",
      "Validation loss decreased (0.184531 --> 0.175834).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1601554\n",
      "\tspeed: 0.1039s/iter; left time: 360.7352s\n",
      "\titers: 200, epoch: 7 | loss: 0.1412529\n",
      "\tspeed: 0.0272s/iter; left time: 91.5916s\n",
      "\titers: 300, epoch: 7 | loss: 0.2031189\n",
      "\tspeed: 0.0271s/iter; left time: 88.8581s\n",
      "\titers: 400, epoch: 7 | loss: 0.1655057\n",
      "\tspeed: 0.0272s/iter; left time: 86.1635s\n",
      "\titers: 500, epoch: 7 | loss: 0.1521878\n",
      "\tspeed: 0.0272s/iter; left time: 83.4626s\n",
      "\titers: 600, epoch: 7 | loss: 0.1462952\n",
      "\tspeed: 0.0271s/iter; left time: 80.6856s\n",
      "\titers: 700, epoch: 7 | loss: 0.1368438\n",
      "\tspeed: 0.0271s/iter; left time: 77.9884s\n",
      "\titers: 800, epoch: 7 | loss: 0.1584302\n",
      "\tspeed: 0.0272s/iter; left time: 75.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 893 | Train Loss: 0.1658204 Vali Loss: 0.1871424 Test Loss: 0.1915115\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1638996\n",
      "\tspeed: 0.1004s/iter; left time: 258.9839s\n",
      "\titers: 200, epoch: 8 | loss: 0.1631495\n",
      "\tspeed: 0.0271s/iter; left time: 67.2977s\n",
      "\titers: 300, epoch: 8 | loss: 0.1616281\n",
      "\tspeed: 0.0271s/iter; left time: 64.5999s\n",
      "\titers: 400, epoch: 8 | loss: 0.1613719\n",
      "\tspeed: 0.0271s/iter; left time: 61.8600s\n",
      "\titers: 500, epoch: 8 | loss: 0.1562547\n",
      "\tspeed: 0.0271s/iter; left time: 59.1298s\n",
      "\titers: 600, epoch: 8 | loss: 0.1591557\n",
      "\tspeed: 0.0271s/iter; left time: 56.4058s\n",
      "\titers: 700, epoch: 8 | loss: 0.1430159\n",
      "\tspeed: 0.0271s/iter; left time: 53.7476s\n",
      "\titers: 800, epoch: 8 | loss: 0.1540750\n",
      "\tspeed: 0.0272s/iter; left time: 51.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.41s\n",
      "Steps: 893 | Train Loss: 0.1598968 Vali Loss: 0.1792915 Test Loss: 0.1951691\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1690300\n",
      "\tspeed: 0.1007s/iter; left time: 169.9410s\n",
      "\titers: 200, epoch: 9 | loss: 0.1429899\n",
      "\tspeed: 0.0273s/iter; left time: 43.2769s\n",
      "\titers: 300, epoch: 9 | loss: 0.1599445\n",
      "\tspeed: 0.0272s/iter; left time: 40.4007s\n",
      "\titers: 400, epoch: 9 | loss: 0.1658960\n",
      "\tspeed: 0.0272s/iter; left time: 37.7903s\n",
      "\titers: 500, epoch: 9 | loss: 0.1858020\n",
      "\tspeed: 0.0272s/iter; left time: 35.0698s\n",
      "\titers: 600, epoch: 9 | loss: 0.1413146\n",
      "\tspeed: 0.0273s/iter; left time: 32.4160s\n",
      "\titers: 700, epoch: 9 | loss: 0.1475893\n",
      "\tspeed: 0.0272s/iter; left time: 29.5432s\n",
      "\titers: 800, epoch: 9 | loss: 0.1766681\n",
      "\tspeed: 0.0272s/iter; left time: 26.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.1555115 Vali Loss: 0.1747558 Test Loss: 0.1856965\n",
      "Validation loss decreased (0.175834 --> 0.174756).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1707571\n",
      "\tspeed: 0.1036s/iter; left time: 82.2842s\n",
      "\titers: 200, epoch: 10 | loss: 0.1651157\n",
      "\tspeed: 0.0273s/iter; left time: 18.9380s\n",
      "\titers: 300, epoch: 10 | loss: 0.1455914\n",
      "\tspeed: 0.0273s/iter; left time: 16.2103s\n",
      "\titers: 400, epoch: 10 | loss: 0.1542371\n",
      "\tspeed: 0.0273s/iter; left time: 13.4930s\n",
      "\titers: 500, epoch: 10 | loss: 0.1631848\n",
      "\tspeed: 0.0273s/iter; left time: 10.7638s\n",
      "\titers: 600, epoch: 10 | loss: 0.1475690\n",
      "\tspeed: 0.0272s/iter; left time: 8.0113s\n",
      "\titers: 700, epoch: 10 | loss: 0.1742382\n",
      "\tspeed: 0.0272s/iter; left time: 5.2760s\n",
      "\titers: 800, epoch: 10 | loss: 0.1431437\n",
      "\tspeed: 0.0272s/iter; left time: 2.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.1517276 Vali Loss: 0.1719684 Test Loss: 0.1923187\n",
      "Validation loss decreased (0.174756 --> 0.171968).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.15008710324764252, rmse:0.3874107599258423, mae:0.1923186480998993, rse:0.4891839027404785\n",
      "Original data scale mse:1397562.75, rmse:1182.185546875, mae:716.2701416015625, rse:0.08307497203350067\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3354656\n",
      "\tspeed: 0.0554s/iter; left time: 487.8198s\n",
      "\titers: 200, epoch: 1 | loss: 0.3069719\n",
      "\tspeed: 0.0276s/iter; left time: 240.2099s\n",
      "\titers: 300, epoch: 1 | loss: 0.3119879\n",
      "\tspeed: 0.0276s/iter; left time: 237.9919s\n",
      "\titers: 400, epoch: 1 | loss: 0.2626441\n",
      "\tspeed: 0.0276s/iter; left time: 234.8232s\n",
      "\titers: 500, epoch: 1 | loss: 0.2645792\n",
      "\tspeed: 0.0276s/iter; left time: 232.3355s\n",
      "\titers: 600, epoch: 1 | loss: 0.2758307\n",
      "\tspeed: 0.0276s/iter; left time: 228.9850s\n",
      "\titers: 700, epoch: 1 | loss: 0.2530298\n",
      "\tspeed: 0.0276s/iter; left time: 226.4470s\n",
      "\titers: 800, epoch: 1 | loss: 0.2443783\n",
      "\tspeed: 0.0275s/iter; left time: 223.4520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.04s\n",
      "Steps: 891 | Train Loss: 0.2860997 Vali Loss: 0.2489570 Test Loss: 0.2600093\n",
      "Validation loss decreased (inf --> 0.248957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2721235\n",
      "\tspeed: 0.1094s/iter; left time: 866.4986s\n",
      "\titers: 200, epoch: 2 | loss: 0.2546379\n",
      "\tspeed: 0.0278s/iter; left time: 217.5152s\n",
      "\titers: 300, epoch: 2 | loss: 0.2754127\n",
      "\tspeed: 0.0278s/iter; left time: 214.8473s\n",
      "\titers: 400, epoch: 2 | loss: 0.2671065\n",
      "\tspeed: 0.0278s/iter; left time: 212.1802s\n",
      "\titers: 500, epoch: 2 | loss: 0.2445592\n",
      "\tspeed: 0.0278s/iter; left time: 209.1116s\n",
      "\titers: 600, epoch: 2 | loss: 0.2697321\n",
      "\tspeed: 0.0278s/iter; left time: 206.3207s\n",
      "\titers: 700, epoch: 2 | loss: 0.2891721\n",
      "\tspeed: 0.0278s/iter; left time: 203.8051s\n",
      "\titers: 800, epoch: 2 | loss: 0.2724285\n",
      "\tspeed: 0.0278s/iter; left time: 200.4035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.02s\n",
      "Steps: 891 | Train Loss: 0.2691066 Vali Loss: 0.3003735 Test Loss: 0.2601006\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2711836\n",
      "\tspeed: 0.1024s/iter; left time: 719.6709s\n",
      "\titers: 200, epoch: 3 | loss: 0.2332118\n",
      "\tspeed: 0.0277s/iter; left time: 191.8436s\n",
      "\titers: 300, epoch: 3 | loss: 0.2285972\n",
      "\tspeed: 0.0276s/iter; left time: 188.7889s\n",
      "\titers: 400, epoch: 3 | loss: 0.2308747\n",
      "\tspeed: 0.0276s/iter; left time: 186.0278s\n",
      "\titers: 500, epoch: 3 | loss: 0.2613144\n",
      "\tspeed: 0.0277s/iter; left time: 183.3181s\n",
      "\titers: 600, epoch: 3 | loss: 0.2351477\n",
      "\tspeed: 0.0277s/iter; left time: 180.6888s\n",
      "\titers: 700, epoch: 3 | loss: 0.2583102\n",
      "\tspeed: 0.0276s/iter; left time: 177.7320s\n",
      "\titers: 800, epoch: 3 | loss: 0.2158320\n",
      "\tspeed: 0.0277s/iter; left time: 175.1039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.2441824 Vali Loss: 0.2699709 Test Loss: 0.2541920\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2619168\n",
      "\tspeed: 0.1019s/iter; left time: 625.3125s\n",
      "\titers: 200, epoch: 4 | loss: 0.2518511\n",
      "\tspeed: 0.0276s/iter; left time: 166.7953s\n",
      "\titers: 300, epoch: 4 | loss: 0.2497801\n",
      "\tspeed: 0.0277s/iter; left time: 164.2363s\n",
      "\titers: 400, epoch: 4 | loss: 0.2563659\n",
      "\tspeed: 0.0277s/iter; left time: 161.7581s\n",
      "\titers: 500, epoch: 4 | loss: 0.2787930\n",
      "\tspeed: 0.0277s/iter; left time: 159.0092s\n",
      "\titers: 600, epoch: 4 | loss: 0.2311507\n",
      "\tspeed: 0.0277s/iter; left time: 155.9597s\n",
      "\titers: 700, epoch: 4 | loss: 0.2264641\n",
      "\tspeed: 0.0276s/iter; left time: 152.8709s\n",
      "\titers: 800, epoch: 4 | loss: 0.2160730\n",
      "\tspeed: 0.0277s/iter; left time: 150.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.2330040 Vali Loss: 0.2578333 Test Loss: 0.2667669\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.1686638742685318, rmse:0.41068708896636963, mae:0.2600093483924866, rse:0.5179550647735596\n",
      "Original data scale mse:3039094.5, rmse:1743.2999267578125, mae:1164.7308349609375, rse:0.12268313765525818\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3145234\n",
      "\tspeed: 0.0300s/iter; left time: 264.1847s\n",
      "\titers: 200, epoch: 1 | loss: 0.3028288\n",
      "\tspeed: 0.0277s/iter; left time: 241.1736s\n",
      "\titers: 300, epoch: 1 | loss: 0.2768580\n",
      "\tspeed: 0.0277s/iter; left time: 238.4263s\n",
      "\titers: 400, epoch: 1 | loss: 0.2640240\n",
      "\tspeed: 0.0277s/iter; left time: 235.5033s\n",
      "\titers: 500, epoch: 1 | loss: 0.2745113\n",
      "\tspeed: 0.0276s/iter; left time: 232.1401s\n",
      "\titers: 600, epoch: 1 | loss: 0.2687416\n",
      "\tspeed: 0.0277s/iter; left time: 229.9041s\n",
      "\titers: 700, epoch: 1 | loss: 0.2432872\n",
      "\tspeed: 0.0277s/iter; left time: 227.1500s\n",
      "\titers: 800, epoch: 1 | loss: 0.2711938\n",
      "\tspeed: 0.0277s/iter; left time: 224.4088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 891 | Train Loss: 0.2864623 Vali Loss: 0.2485841 Test Loss: 0.2601934\n",
      "Validation loss decreased (inf --> 0.248584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2977839\n",
      "\tspeed: 0.1053s/iter; left time: 834.1188s\n",
      "\titers: 200, epoch: 2 | loss: 0.2813226\n",
      "\tspeed: 0.0276s/iter; left time: 216.2184s\n",
      "\titers: 300, epoch: 2 | loss: 0.2627541\n",
      "\tspeed: 0.0277s/iter; left time: 213.5605s\n",
      "\titers: 400, epoch: 2 | loss: 0.3055850\n",
      "\tspeed: 0.0276s/iter; left time: 210.4343s\n",
      "\titers: 500, epoch: 2 | loss: 0.2443481\n",
      "\tspeed: 0.0277s/iter; left time: 208.2281s\n",
      "\titers: 600, epoch: 2 | loss: 0.2846391\n",
      "\tspeed: 0.0276s/iter; left time: 204.8406s\n",
      "\titers: 700, epoch: 2 | loss: 0.2434934\n",
      "\tspeed: 0.0277s/iter; left time: 202.5721s\n",
      "\titers: 800, epoch: 2 | loss: 0.2441979\n",
      "\tspeed: 0.0277s/iter; left time: 199.9039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.89s\n",
      "Steps: 891 | Train Loss: 0.2664769 Vali Loss: 0.2668871 Test Loss: 0.2658403\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2616486\n",
      "\tspeed: 0.1022s/iter; left time: 718.0143s\n",
      "\titers: 200, epoch: 3 | loss: 0.2386892\n",
      "\tspeed: 0.0277s/iter; left time: 191.8311s\n",
      "\titers: 300, epoch: 3 | loss: 0.2325476\n",
      "\tspeed: 0.0277s/iter; left time: 189.0619s\n",
      "\titers: 400, epoch: 3 | loss: 0.2380039\n",
      "\tspeed: 0.0277s/iter; left time: 186.3719s\n",
      "\titers: 500, epoch: 3 | loss: 0.2319053\n",
      "\tspeed: 0.0276s/iter; left time: 183.2277s\n",
      "\titers: 600, epoch: 3 | loss: 0.2567644\n",
      "\tspeed: 0.0277s/iter; left time: 180.6397s\n",
      "\titers: 700, epoch: 3 | loss: 0.2415968\n",
      "\tspeed: 0.0277s/iter; left time: 178.1514s\n",
      "\titers: 800, epoch: 3 | loss: 0.2250640\n",
      "\tspeed: 0.0277s/iter; left time: 175.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.2431886 Vali Loss: 0.2540849 Test Loss: 0.2577291\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2707479\n",
      "\tspeed: 0.1031s/iter; left time: 633.0998s\n",
      "\titers: 200, epoch: 4 | loss: 0.2530373\n",
      "\tspeed: 0.0276s/iter; left time: 166.8925s\n",
      "\titers: 300, epoch: 4 | loss: 0.2405092\n",
      "\tspeed: 0.0277s/iter; left time: 164.2396s\n",
      "\titers: 400, epoch: 4 | loss: 0.2568100\n",
      "\tspeed: 0.0276s/iter; left time: 161.1082s\n",
      "\titers: 500, epoch: 4 | loss: 0.2192773\n",
      "\tspeed: 0.0277s/iter; left time: 158.7389s\n",
      "\titers: 600, epoch: 4 | loss: 0.2281509\n",
      "\tspeed: 0.0276s/iter; left time: 155.4928s\n",
      "\titers: 700, epoch: 4 | loss: 0.2297659\n",
      "\tspeed: 0.0277s/iter; left time: 153.2679s\n",
      "\titers: 800, epoch: 4 | loss: 0.2559616\n",
      "\tspeed: 0.0277s/iter; left time: 150.6098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.89s\n",
      "Steps: 891 | Train Loss: 0.2363334 Vali Loss: 0.2650707 Test Loss: 0.2795453\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.16862164437770844, rmse:0.41063565015792847, mae:0.260193407535553, rse:0.517890214920044\n",
      "Original data scale mse:3028741.0, rmse:1740.327880859375, mae:1162.4697265625, rse:0.12247397750616074\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='robust', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3223890\n",
      "\tspeed: 0.0552s/iter; left time: 485.3466s\n",
      "\titers: 200, epoch: 1 | loss: 0.2809606\n",
      "\tspeed: 0.0282s/iter; left time: 244.9739s\n",
      "\titers: 300, epoch: 1 | loss: 0.2872838\n",
      "\tspeed: 0.0280s/iter; left time: 240.3770s\n",
      "\titers: 400, epoch: 1 | loss: 0.3180827\n",
      "\tspeed: 0.0280s/iter; left time: 237.4957s\n",
      "\titers: 500, epoch: 1 | loss: 0.3061780\n",
      "\tspeed: 0.0280s/iter; left time: 234.5382s\n",
      "\titers: 600, epoch: 1 | loss: 0.2868056\n",
      "\tspeed: 0.0280s/iter; left time: 232.3964s\n",
      "\titers: 700, epoch: 1 | loss: 0.2895761\n",
      "\tspeed: 0.0280s/iter; left time: 229.5519s\n",
      "\titers: 800, epoch: 1 | loss: 0.2692367\n",
      "\tspeed: 0.0280s/iter; left time: 226.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.2963385 Vali Loss: 0.2625978 Test Loss: 0.2725678\n",
      "Validation loss decreased (inf --> 0.262598).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3076510\n",
      "\tspeed: 0.1082s/iter; left time: 854.8839s\n",
      "\titers: 200, epoch: 2 | loss: 0.2820674\n",
      "\tspeed: 0.0281s/iter; left time: 219.4954s\n",
      "\titers: 300, epoch: 2 | loss: 0.2997876\n",
      "\tspeed: 0.0281s/iter; left time: 216.2880s\n",
      "\titers: 400, epoch: 2 | loss: 0.2806443\n",
      "\tspeed: 0.0279s/iter; left time: 212.3521s\n",
      "\titers: 500, epoch: 2 | loss: 0.2719420\n",
      "\tspeed: 0.0281s/iter; left time: 210.7596s\n",
      "\titers: 600, epoch: 2 | loss: 0.2711656\n",
      "\tspeed: 0.0281s/iter; left time: 208.1762s\n",
      "\titers: 700, epoch: 2 | loss: 0.2596438\n",
      "\tspeed: 0.0281s/iter; left time: 205.3606s\n",
      "\titers: 800, epoch: 2 | loss: 0.2756642\n",
      "\tspeed: 0.0282s/iter; left time: 202.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.22s\n",
      "Steps: 889 | Train Loss: 0.2775165 Vali Loss: 0.2705744 Test Loss: 0.2681555\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2577086\n",
      "\tspeed: 0.1030s/iter; left time: 722.1386s\n",
      "\titers: 200, epoch: 3 | loss: 0.2527416\n",
      "\tspeed: 0.0282s/iter; left time: 194.7112s\n",
      "\titers: 300, epoch: 3 | loss: 0.2637053\n",
      "\tspeed: 0.0283s/iter; left time: 192.7560s\n",
      "\titers: 400, epoch: 3 | loss: 0.2602287\n",
      "\tspeed: 0.0283s/iter; left time: 189.8289s\n",
      "\titers: 500, epoch: 3 | loss: 0.2299675\n",
      "\tspeed: 0.0281s/iter; left time: 186.0076s\n",
      "\titers: 600, epoch: 3 | loss: 0.2196577\n",
      "\tspeed: 0.0282s/iter; left time: 183.4662s\n",
      "\titers: 700, epoch: 3 | loss: 0.2399767\n",
      "\tspeed: 0.0280s/iter; left time: 179.6855s\n",
      "\titers: 800, epoch: 3 | loss: 0.2893007\n",
      "\tspeed: 0.0282s/iter; left time: 178.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 889 | Train Loss: 0.2505349 Vali Loss: 0.3348019 Test Loss: 0.3067805\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2356506\n",
      "\tspeed: 0.1028s/iter; left time: 629.3875s\n",
      "\titers: 200, epoch: 4 | loss: 0.2364836\n",
      "\tspeed: 0.0280s/iter; left time: 168.8943s\n",
      "\titers: 300, epoch: 4 | loss: 0.2408936\n",
      "\tspeed: 0.0280s/iter; left time: 166.1542s\n",
      "\titers: 400, epoch: 4 | loss: 0.2426249\n",
      "\tspeed: 0.0281s/iter; left time: 163.4435s\n",
      "\titers: 500, epoch: 4 | loss: 0.2182072\n",
      "\tspeed: 0.0281s/iter; left time: 160.6480s\n",
      "\titers: 600, epoch: 4 | loss: 0.2222353\n",
      "\tspeed: 0.0281s/iter; left time: 157.8592s\n",
      "\titers: 700, epoch: 4 | loss: 0.2550755\n",
      "\tspeed: 0.0280s/iter; left time: 154.8835s\n",
      "\titers: 800, epoch: 4 | loss: 0.2288322\n",
      "\tspeed: 0.0281s/iter; left time: 152.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.2387066 Vali Loss: 0.3053353 Test Loss: 0.2922479\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.17821213603019714, rmse:0.4221518039703369, mae:0.2725679576396942, rse:0.5318312048912048\n",
      "Original data scale mse:3552784.75, rmse:1884.8831787109375, mae:1258.2855224609375, rse:0.13277149200439453\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3296847\n",
      "\tspeed: 0.0301s/iter; left time: 264.3635s\n",
      "\titers: 200, epoch: 1 | loss: 0.3293105\n",
      "\tspeed: 0.0280s/iter; left time: 243.2877s\n",
      "\titers: 300, epoch: 1 | loss: 0.2815741\n",
      "\tspeed: 0.0281s/iter; left time: 241.1474s\n",
      "\titers: 400, epoch: 1 | loss: 0.2972320\n",
      "\tspeed: 0.0281s/iter; left time: 238.1908s\n",
      "\titers: 500, epoch: 1 | loss: 0.2813389\n",
      "\tspeed: 0.0281s/iter; left time: 235.5030s\n",
      "\titers: 600, epoch: 1 | loss: 0.2805541\n",
      "\tspeed: 0.0282s/iter; left time: 234.2167s\n",
      "\titers: 700, epoch: 1 | loss: 0.2684199\n",
      "\tspeed: 0.0281s/iter; left time: 230.0367s\n",
      "\titers: 800, epoch: 1 | loss: 0.2707690\n",
      "\tspeed: 0.0280s/iter; left time: 226.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.20s\n",
      "Steps: 889 | Train Loss: 0.2970601 Vali Loss: 0.2624180 Test Loss: 0.2727116\n",
      "Validation loss decreased (inf --> 0.262418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3206463\n",
      "\tspeed: 0.1062s/iter; left time: 839.4526s\n",
      "\titers: 200, epoch: 2 | loss: 0.2897732\n",
      "\tspeed: 0.0280s/iter; left time: 218.7131s\n",
      "\titers: 300, epoch: 2 | loss: 0.3186582\n",
      "\tspeed: 0.0280s/iter; left time: 215.9372s\n",
      "\titers: 400, epoch: 2 | loss: 0.2696510\n",
      "\tspeed: 0.0280s/iter; left time: 213.0265s\n",
      "\titers: 500, epoch: 2 | loss: 0.2730645\n",
      "\tspeed: 0.0280s/iter; left time: 210.3087s\n",
      "\titers: 600, epoch: 2 | loss: 0.2847755\n",
      "\tspeed: 0.0280s/iter; left time: 207.4211s\n",
      "\titers: 700, epoch: 2 | loss: 0.2543756\n",
      "\tspeed: 0.0280s/iter; left time: 204.6410s\n",
      "\titers: 800, epoch: 2 | loss: 0.2498963\n",
      "\tspeed: 0.0281s/iter; left time: 202.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.2788615 Vali Loss: 0.2963250 Test Loss: 0.2736378\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2599383\n",
      "\tspeed: 0.1043s/iter; left time: 731.2374s\n",
      "\titers: 200, epoch: 3 | loss: 0.2595088\n",
      "\tspeed: 0.0283s/iter; left time: 195.8361s\n",
      "\titers: 300, epoch: 3 | loss: 0.3014075\n",
      "\tspeed: 0.0282s/iter; left time: 191.9421s\n",
      "\titers: 400, epoch: 3 | loss: 0.2458985\n",
      "\tspeed: 0.0282s/iter; left time: 189.4694s\n",
      "\titers: 500, epoch: 3 | loss: 0.2549004\n",
      "\tspeed: 0.0281s/iter; left time: 186.0545s\n",
      "\titers: 600, epoch: 3 | loss: 0.2536776\n",
      "\tspeed: 0.0281s/iter; left time: 183.0760s\n",
      "\titers: 700, epoch: 3 | loss: 0.2389152\n",
      "\tspeed: 0.0282s/iter; left time: 180.8810s\n",
      "\titers: 800, epoch: 3 | loss: 0.2427696\n",
      "\tspeed: 0.0280s/iter; left time: 176.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.32s\n",
      "Steps: 889 | Train Loss: 0.2517867 Vali Loss: 0.2851760 Test Loss: 0.2754298\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2489079\n",
      "\tspeed: 0.1035s/iter; left time: 633.6283s\n",
      "\titers: 200, epoch: 4 | loss: 0.2422425\n",
      "\tspeed: 0.0279s/iter; left time: 168.1733s\n",
      "\titers: 300, epoch: 4 | loss: 0.2478787\n",
      "\tspeed: 0.0279s/iter; left time: 165.3300s\n",
      "\titers: 400, epoch: 4 | loss: 0.2366847\n",
      "\tspeed: 0.0279s/iter; left time: 162.7677s\n",
      "\titers: 500, epoch: 4 | loss: 0.2591833\n",
      "\tspeed: 0.0280s/iter; left time: 160.4847s\n",
      "\titers: 600, epoch: 4 | loss: 0.2471959\n",
      "\tspeed: 0.0280s/iter; left time: 157.5715s\n",
      "\titers: 700, epoch: 4 | loss: 0.2594621\n",
      "\tspeed: 0.0280s/iter; left time: 154.8835s\n",
      "\titers: 800, epoch: 4 | loss: 0.2246699\n",
      "\tspeed: 0.0280s/iter; left time: 151.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.11s\n",
      "Steps: 889 | Train Loss: 0.2389128 Vali Loss: 0.3068882 Test Loss: 0.3156111\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.1782127171754837, rmse:0.42215248942375183, mae:0.2727116048336029, rse:0.5318320989608765\n",
      "Original data scale mse:3531337.25, rmse:1879.185302734375, mae:1255.2706298828125, rse:0.13237012922763824\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type robust \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.4033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.5107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.5262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1746</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.5117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.4171</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.4169</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.4892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.1686</td>\n",
       "      <td>0.4106</td>\n",
       "      <td>0.2602</td>\n",
       "      <td>0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.1004  0.3168  0.2046  0.4001\n",
       "              2         24        0.1020  0.3194  0.2026  0.4033\n",
       "              1         96        0.1649  0.4061  0.2669  0.5121\n",
       "              2         96        0.1640  0.4049  0.2658  0.5107\n",
       "              1         168       0.1745  0.4177  0.2787  0.5262\n",
       "              2         168       0.1746  0.4179  0.2787  0.5265\n",
       "RMSE          1         24        0.1024  0.3200  0.2085  0.4040\n",
       "              2         24        0.1014  0.3184  0.2102  0.4021\n",
       "              1         96        0.1646  0.4057  0.2658  0.5117\n",
       "              2         96        0.1635  0.4044  0.2646  0.5100\n",
       "              1         168       0.1740  0.4171  0.2774  0.5255\n",
       "              2         168       0.1738  0.4169  0.2772  0.5252\n",
       "MAE           1         24        0.1068  0.3268  0.2015  0.4127\n",
       "              2         24        0.1501  0.3874  0.1923  0.4892\n",
       "              1         96        0.1687  0.4107  0.2600  0.5180\n",
       "              2         96        0.1686  0.4106  0.2602  0.5179\n",
       "              1         168       0.1782  0.4222  0.2726  0.5318\n",
       "              2         168       0.1782  0.4222  0.2727  0.5318"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT_robust.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT_robust.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1888251.625</td>\n",
       "      <td>1374.1367</td>\n",
       "      <td>946.0014</td>\n",
       "      <td>0.0966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1746225.750</td>\n",
       "      <td>1321.4484</td>\n",
       "      <td>910.2934</td>\n",
       "      <td>0.0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3313422.500</td>\n",
       "      <td>1820.2809</td>\n",
       "      <td>1241.3649</td>\n",
       "      <td>0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3265158.750</td>\n",
       "      <td>1806.9750</td>\n",
       "      <td>1229.9159</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3830158.000</td>\n",
       "      <td>1957.0790</td>\n",
       "      <td>1328.4673</td>\n",
       "      <td>0.1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3708326.750</td>\n",
       "      <td>1925.7017</td>\n",
       "      <td>1313.2982</td>\n",
       "      <td>0.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>2111207.750</td>\n",
       "      <td>1452.9995</td>\n",
       "      <td>989.4656</td>\n",
       "      <td>0.1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>2039680.500</td>\n",
       "      <td>1428.1738</td>\n",
       "      <td>989.9337</td>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3247477.000</td>\n",
       "      <td>1802.0758</td>\n",
       "      <td>1229.2659</td>\n",
       "      <td>0.1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3191100.750</td>\n",
       "      <td>1786.3652</td>\n",
       "      <td>1216.0294</td>\n",
       "      <td>0.1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3762426.000</td>\n",
       "      <td>1939.6974</td>\n",
       "      <td>1316.0566</td>\n",
       "      <td>0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3631123.500</td>\n",
       "      <td>1905.5507</td>\n",
       "      <td>1299.1057</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1802445.750</td>\n",
       "      <td>1342.5520</td>\n",
       "      <td>882.4846</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1397562.750</td>\n",
       "      <td>1182.1855</td>\n",
       "      <td>716.2701</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3039094.500</td>\n",
       "      <td>1743.2999</td>\n",
       "      <td>1164.7308</td>\n",
       "      <td>0.1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3028741.000</td>\n",
       "      <td>1740.3279</td>\n",
       "      <td>1162.4697</td>\n",
       "      <td>0.1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3552784.750</td>\n",
       "      <td>1884.8832</td>\n",
       "      <td>1258.2855</td>\n",
       "      <td>0.1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3531337.250</td>\n",
       "      <td>1879.1853</td>\n",
       "      <td>1255.2706</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1888251.625  1374.1367   946.0014  0.0966\n",
       "              2         24        1746225.750  1321.4484   910.2934  0.0929\n",
       "              1         96        3313422.500  1820.2809  1241.3649  0.1281\n",
       "              2         96        3265158.750  1806.9750  1229.9159  0.1272\n",
       "              1         168       3830158.000  1957.0790  1328.4673  0.1379\n",
       "              2         168       3708326.750  1925.7017  1313.2982  0.1356\n",
       "RMSE          1         24        2111207.750  1452.9995   989.4656  0.1021\n",
       "              2         24        2039680.500  1428.1738   989.9337  0.1004\n",
       "              1         96        3247477.000  1802.0758  1229.2659  0.1268\n",
       "              2         96        3191100.750  1786.3652  1216.0294  0.1257\n",
       "              1         168       3762426.000  1939.6974  1316.0566  0.1366\n",
       "              2         168       3631123.500  1905.5507  1299.1057  0.1342\n",
       "MAE           1         24        1802445.750  1342.5520   882.4846  0.0943\n",
       "              2         24        1397562.750  1182.1855   716.2701  0.0831\n",
       "              1         96        3039094.500  1743.2999  1164.7308  0.1227\n",
       "              2         96        3028741.000  1740.3279  1162.4697  0.1225\n",
       "              1         168       3552784.750  1884.8832  1258.2855  0.1328\n",
       "              2         168       3531337.250  1879.1853  1255.2706  0.1324"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.4017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>0.4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.1686</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>0.5114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.5108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.1285  0.3571  0.1969  0.4509\n",
       "         MSE            0.1012  0.3181  0.2036  0.4017\n",
       "         RMSE           0.1019  0.3192  0.2093  0.4030\n",
       "96       MAE            0.1686  0.4107  0.2601  0.5179\n",
       "         MSE            0.1644  0.4055  0.2664  0.5114\n",
       "         RMSE           0.1641  0.4050  0.2652  0.5108\n",
       "168      MAE            0.1782  0.4222  0.2726  0.5318\n",
       "         MSE            0.1745  0.4178  0.2787  0.5263\n",
       "         RMSE           0.1739  0.4170  0.2773  0.5254"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.600004e+06</td>\n",
       "      <td>1262.3688</td>\n",
       "      <td>799.3773</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.817239e+06</td>\n",
       "      <td>1347.7925</td>\n",
       "      <td>928.1474</td>\n",
       "      <td>0.0947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>2.075444e+06</td>\n",
       "      <td>1440.5867</td>\n",
       "      <td>989.6997</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.033918e+06</td>\n",
       "      <td>1741.8139</td>\n",
       "      <td>1163.6003</td>\n",
       "      <td>0.1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.289291e+06</td>\n",
       "      <td>1813.6279</td>\n",
       "      <td>1235.6404</td>\n",
       "      <td>0.1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.219289e+06</td>\n",
       "      <td>1794.2205</td>\n",
       "      <td>1222.6476</td>\n",
       "      <td>0.1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.542061e+06</td>\n",
       "      <td>1882.0342</td>\n",
       "      <td>1256.7781</td>\n",
       "      <td>0.1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.769242e+06</td>\n",
       "      <td>1941.3903</td>\n",
       "      <td>1320.8828</td>\n",
       "      <td>0.1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.696775e+06</td>\n",
       "      <td>1922.6240</td>\n",
       "      <td>1307.5812</td>\n",
       "      <td>0.1354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.600004e+06  1262.3688   799.3773  0.0887\n",
       "         MSE            1.817239e+06  1347.7925   928.1474  0.0947\n",
       "         RMSE           2.075444e+06  1440.5867   989.6997  0.1012\n",
       "96       MAE            3.033918e+06  1741.8139  1163.6003  0.1226\n",
       "         MSE            3.289291e+06  1813.6279  1235.6404  0.1276\n",
       "         RMSE           3.219289e+06  1794.2205  1222.6476  0.1263\n",
       "168      MAE            3.542061e+06  1882.0342  1256.7781  0.1326\n",
       "         MSE            3.769242e+06  1941.3903  1320.8828  0.1368\n",
       "         RMSE           3.696775e+06  1922.6240  1307.5812  0.1354"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at MAE loss pred_len=96  -> absolute is smaller and normalized is higher -> because our\n",
    "# features have different absolute scales, and in this way the feature with higher values dominate the loss\n",
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'robust_unscaled_IT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
