{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 336](#3-patchtst-336)\n",
    "- [4. PatchTST 512](#4-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with seq_len = 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.102024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.222776</td>\n",
       "      <td>0.151442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.053862</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>0.157675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.029237</td>\n",
       "      <td>0.170931</td>\n",
       "      <td>0.102782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.054016</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>0.143438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.180379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.013085</td>\n",
       "      <td>0.114375</td>\n",
       "      <td>0.065895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.090813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.161352</td>\n",
       "      <td>0.100413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.206759</td>\n",
       "      <td>0.136561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.056983</td>\n",
       "      <td>0.238688</td>\n",
       "      <td>0.164011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.254278</td>\n",
       "      <td>0.174006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.111931</td>\n",
       "      <td>0.064753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.091110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.151858</td>\n",
       "      <td>0.097850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             Informer                    \n",
       "Metrics                MSE      RMSE       MAE\n",
       "Country Pred_len                              \n",
       "DE      24        0.024532  0.156584  0.102024\n",
       "        96        0.049635  0.222776  0.151442\n",
       "        168       0.053862  0.232072  0.157675\n",
       "ES      24        0.029237  0.170931  0.102782\n",
       "        96        0.054016  0.232086  0.143438\n",
       "        168       0.081337  0.285179  0.180379\n",
       "FR      24        0.013085  0.114375  0.065895\n",
       "        96        0.022820  0.151050  0.090813\n",
       "        168       0.026034  0.161352  0.100413\n",
       "GB      24        0.042813  0.206759  0.136561\n",
       "        96        0.056983  0.238688  0.164011\n",
       "        168       0.064669  0.254278  0.174006\n",
       "IT      24        0.012534  0.111931  0.064753\n",
       "        96        0.022222  0.149071  0.091110\n",
       "        168       0.023064  0.151858  0.097850"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res= informer_results = []\n",
    "\n",
    "# DE 24\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.025699591264128685,\n",
    "    'RMSE': 0.16031092405319214,\n",
    "    'MAE': 0.10348266363143921,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.023365361616015434,\n",
    "    'RMSE': 0.15285731852054596,\n",
    "    'MAE': 0.10056539624929428,\n",
    "})\n",
    "\n",
    "# DE 96\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.04860777407884598,\n",
    "    'RMSE': 0.22047170996665955,\n",
    "    'MAE': 0.14964795112609863,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05066155269742012,\n",
    "    'RMSE': 0.22508122026920319,\n",
    "    'MAE': 0.1532352715730667,\n",
    "})\n",
    "\n",
    "# DE 168\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.054843734949827194,\n",
    "    'RMSE': 0.23418739438056946,\n",
    "    'MAE': 0.15871629118919373,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'DE',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05288044735789299,\n",
    "    'RMSE': 0.2299574911594391,\n",
    "    'MAE': 0.15663425624370575,\n",
    "})\n",
    "\n",
    "# GB 24\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.046120475977659225,\n",
    "    'RMSE': 0.2147567868232727,\n",
    "    'MAE': 0.1404818892478943,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.039505913853645325,\n",
    "    'RMSE': 0.19876094162464142,\n",
    "    'MAE': 0.13264088332653046,\n",
    "})\n",
    "\n",
    "# GB 96\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.05855736881494522,\n",
    "    'RMSE': 0.24198630452156067,\n",
    "    'MAE': 0.16477428376674652,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05540859326720238,\n",
    "    'RMSE': 0.235390305519104,\n",
    "    'MAE': 0.16324692964553833,\n",
    "})\n",
    "\n",
    "# GB 168\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.06292843818664551,\n",
    "    'RMSE': 0.250855416059494,\n",
    "    'MAE': 0.17068493366241455,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'GB',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.06641010195016861,\n",
    "    'RMSE': 0.257701575756073,\n",
    "    'MAE': 0.177326962351799,\n",
    "})\n",
    "\n",
    "# ES 24\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.027730144560337067,\n",
    "    'RMSE': 0.16652370989322662,\n",
    "    'MAE': 0.10189637541770935,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.03074352815747261,\n",
    "    'RMSE': 0.17533832788467407,\n",
    "    'MAE': 0.10366739332675934,\n",
    "})\n",
    "\n",
    "# ES 96\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.048280902206897736,\n",
    "    'RMSE': 0.21972915530204773,\n",
    "    'MAE': 0.13662198185920715,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.05975188687443733,\n",
    "    'RMSE': 0.24444198608398438,\n",
    "    'MAE': 0.1502540409564972,\n",
    "})\n",
    "\n",
    "# ES 168\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.07949484884738922,\n",
    "    'RMSE': 0.2819482982158661,\n",
    "    'MAE': 0.1783347725868225,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'ES',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.0831800326704979,\n",
    "    'RMSE': 0.2884095013141632,\n",
    "    'MAE': 0.18242256343364716,\n",
    "})\n",
    "\n",
    "# FR 24\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.012692660093307495,\n",
    "    'RMSE': 0.1126617044210434,\n",
    "    'MAE': 0.06498495489358902,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 24,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.013476599007844925,\n",
    "    'RMSE': 0.11608875542879105,\n",
    "    'MAE': 0.06680411100387573,\n",
    "})\n",
    "\n",
    "# FR 96\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.022180521860718727,\n",
    "    'RMSE': 0.14893126487731934,\n",
    "    'MAE': 0.09044930338859558,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 96,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.02346043847501278,\n",
    "    'RMSE': 0.15316800773143768,\n",
    "    'MAE': 0.09117613732814789,\n",
    "})\n",
    "\n",
    "# FR 168\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 1,\n",
    "    'MSE': 0.026063205674290657,\n",
    "    'RMSE': 0.16144102811813354,\n",
    "    'MAE': 0.10040990263223648,\n",
    "})\n",
    "informer_results.append({\n",
    "    'Country': 'FR',\n",
    "    'Pred_len': 168,\n",
    "    'Iteration': 2,\n",
    "    'MSE': 0.026005728170275688,\n",
    "    'RMSE': 0.16126291453838348,\n",
    "    'MAE': 0.10041678696870804})\n",
    "\n",
    "# IT 24\n",
    "informer_results.append({'Country': 'IT',\n",
    "  'Pred_len': 24,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.013071063905954361,\n",
    "  'RMSE': 0.11432875692844391,\n",
    "  'MAE': 0.06469322741031647})\n",
    "informer_results.append({'Country': 'IT',\n",
    "  'Pred_len': 24,\n",
    "  'Iteration': 2,\n",
    "  'MSE': 0.011997658759355545,\n",
    "  'RMSE': 0.10953382402658463,\n",
    "  'MAE': 0.06481219828128815})\n",
    "informer_results.append({'Country': 'IT',\n",
    "  'Pred_len': 96,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.022102830931544304,\n",
    "  'RMSE': 0.14867021143436432,\n",
    "  'MAE': 0.09126447886228561})\n",
    "informer_results.append({'Country': 'IT',\n",
    "  'Pred_len': 96,\n",
    "  'Iteration': 2,\n",
    "  'MSE': 0.022342106327414513,\n",
    "  'RMSE': 0.14947275817394257,\n",
    "  'MAE': 0.0909552201628685})\n",
    "informer_results.append(\n",
    " {'Country': 'IT',\n",
    "  'Pred_len': 168,\n",
    "  'Iteration': 1,\n",
    "  'MSE': 0.022543294355273247,\n",
    "  'RMSE': 0.15014424920082092,\n",
    "  'MAE': 0.09787493199110031})\n",
    "informer_results.append(\n",
    "    {'Country': 'IT',\n",
    "  'Pred_len': 168,\n",
    "  'Iteration': 2,\n",
    "  'MSE': 0.02358420379459858,\n",
    "  'RMSE': 0.1535715013742447,\n",
    "  'MAE': 0.0978248119354248})\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 168\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_Informer_custom_ftM_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2237253\n",
      "\tspeed: 0.1222s/iter; left time: 2196.6245s\n",
      "\titers: 200, epoch: 1 | loss: 0.2078324\n",
      "\tspeed: 0.0522s/iter; left time: 934.0596s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026997\n",
      "\tspeed: 0.0523s/iter; left time: 929.3324s\n",
      "\titers: 400, epoch: 1 | loss: 0.1845515\n",
      "\tspeed: 0.0521s/iter; left time: 921.7354s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_transformers\", 'informer_npy_168')\n",
    "os.rename(\"test_results\", \"informer_pics_168\")\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer_168.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 168\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1494096\n",
      "\tspeed: 0.0331s/iter; left time: 744.9698s\n",
      "\titers: 200, epoch: 1 | loss: 0.1323591\n",
      "\tspeed: 0.0147s/iter; left time: 328.7932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.1472841 Vali Loss: 0.1347737 Test Loss: 0.1428933\n",
      "Validation loss decreased (inf --> 0.134774).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0845640\n",
      "\tspeed: 0.0317s/iter; left time: 707.1836s\n",
      "\titers: 200, epoch: 2 | loss: 0.0840180\n",
      "\tspeed: 0.0150s/iter; left time: 332.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0913177 Vali Loss: 0.0952576 Test Loss: 0.0964126\n",
      "Validation loss decreased (0.134774 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0810556\n",
      "\tspeed: 0.0328s/iter; left time: 722.6901s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814877\n",
      "\tspeed: 0.0148s/iter; left time: 324.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0810284 Vali Loss: 0.0909402 Test Loss: 0.0929232\n",
      "Validation loss decreased (0.095258 --> 0.090940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0829395\n",
      "\tspeed: 0.0319s/iter; left time: 695.7021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0787051\n",
      "\tspeed: 0.0149s/iter; left time: 323.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0783240 Vali Loss: 0.0893383 Test Loss: 0.0917443\n",
      "Validation loss decreased (0.090940 --> 0.089338).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827021\n",
      "\tspeed: 0.0338s/iter; left time: 729.2611s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717351\n",
      "\tspeed: 0.0164s/iter; left time: 353.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0768973 Vali Loss: 0.0892281 Test Loss: 0.0911057\n",
      "Validation loss decreased (0.089338 --> 0.089228).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0709572\n",
      "\tspeed: 0.0362s/iter; left time: 772.7199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760926\n",
      "\tspeed: 0.0156s/iter; left time: 332.2332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0759201 Vali Loss: 0.0882277 Test Loss: 0.0904895\n",
      "Validation loss decreased (0.089228 --> 0.088228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0784024\n",
      "\tspeed: 0.0324s/iter; left time: 684.1842s\n",
      "\titers: 200, epoch: 7 | loss: 0.0754921\n",
      "\tspeed: 0.0147s/iter; left time: 308.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0752275 Vali Loss: 0.0879289 Test Loss: 0.0902016\n",
      "Validation loss decreased (0.088228 --> 0.087929).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0699481\n",
      "\tspeed: 0.0351s/iter; left time: 734.4453s\n",
      "\titers: 200, epoch: 8 | loss: 0.0718761\n",
      "\tspeed: 0.0194s/iter; left time: 403.5384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 226 | Train Loss: 0.0747946 Vali Loss: 0.0874789 Test Loss: 0.0901015\n",
      "Validation loss decreased (0.087929 --> 0.087479).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0716389\n",
      "\tspeed: 0.0366s/iter; left time: 756.9084s\n",
      "\titers: 200, epoch: 9 | loss: 0.0681881\n",
      "\tspeed: 0.0168s/iter; left time: 346.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0742107 Vali Loss: 0.0872496 Test Loss: 0.0898178\n",
      "Validation loss decreased (0.087479 --> 0.087250).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0767106\n",
      "\tspeed: 0.0373s/iter; left time: 762.6762s\n",
      "\titers: 200, epoch: 10 | loss: 0.0742374\n",
      "\tspeed: 0.0165s/iter; left time: 335.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0739115 Vali Loss: 0.0874932 Test Loss: 0.0897692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0768209\n",
      "\tspeed: 0.0303s/iter; left time: 613.9543s\n",
      "\titers: 200, epoch: 11 | loss: 0.0725960\n",
      "\tspeed: 0.0147s/iter; left time: 296.5618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0735395 Vali Loss: 0.0871070 Test Loss: 0.0896325\n",
      "Validation loss decreased (0.087250 --> 0.087107).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0729355\n",
      "\tspeed: 0.0305s/iter; left time: 609.9880s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778641\n",
      "\tspeed: 0.0168s/iter; left time: 334.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0733159 Vali Loss: 0.0867546 Test Loss: 0.0893783\n",
      "Validation loss decreased (0.087107 --> 0.086755).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0724195\n",
      "\tspeed: 0.0381s/iter; left time: 754.7910s\n",
      "\titers: 200, epoch: 13 | loss: 0.0691778\n",
      "\tspeed: 0.0212s/iter; left time: 417.5995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0731571 Vali Loss: 0.0866443 Test Loss: 0.0890993\n",
      "Validation loss decreased (0.086755 --> 0.086644).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0730425\n",
      "\tspeed: 0.0346s/iter; left time: 677.1500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0773089\n",
      "\tspeed: 0.0215s/iter; left time: 417.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0728669 Vali Loss: 0.0865124 Test Loss: 0.0889917\n",
      "Validation loss decreased (0.086644 --> 0.086512).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731445\n",
      "\tspeed: 0.0332s/iter; left time: 642.2836s\n",
      "\titers: 200, epoch: 15 | loss: 0.0727954\n",
      "\tspeed: 0.0147s/iter; left time: 282.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0726974 Vali Loss: 0.0864326 Test Loss: 0.0889845\n",
      "Validation loss decreased (0.086512 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736746\n",
      "\tspeed: 0.0366s/iter; left time: 698.8203s\n",
      "\titers: 200, epoch: 16 | loss: 0.0759136\n",
      "\tspeed: 0.0147s/iter; left time: 279.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0725172 Vali Loss: 0.0862788 Test Loss: 0.0887207\n",
      "Validation loss decreased (0.086433 --> 0.086279).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0719921\n",
      "\tspeed: 0.0363s/iter; left time: 685.1361s\n",
      "\titers: 200, epoch: 17 | loss: 0.0726950\n",
      "\tspeed: 0.0223s/iter; left time: 418.8842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0723900 Vali Loss: 0.0861436 Test Loss: 0.0887920\n",
      "Validation loss decreased (0.086279 --> 0.086144).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0689621\n",
      "\tspeed: 0.0343s/iter; left time: 639.8221s\n",
      "\titers: 200, epoch: 18 | loss: 0.0707179\n",
      "\tspeed: 0.0177s/iter; left time: 328.2012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0722318 Vali Loss: 0.0861794 Test Loss: 0.0886752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0785493\n",
      "\tspeed: 0.0353s/iter; left time: 651.0269s\n",
      "\titers: 200, epoch: 19 | loss: 0.0726154\n",
      "\tspeed: 0.0188s/iter; left time: 343.7562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0721604 Vali Loss: 0.0861406 Test Loss: 0.0886920\n",
      "Validation loss decreased (0.086144 --> 0.086141).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0758487\n",
      "\tspeed: 0.0340s/iter; left time: 619.1498s\n",
      "\titers: 200, epoch: 20 | loss: 0.0768337\n",
      "\tspeed: 0.0183s/iter; left time: 330.6882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0720731 Vali Loss: 0.0858387 Test Loss: 0.0885592\n",
      "Validation loss decreased (0.086141 --> 0.085839).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0714005\n",
      "\tspeed: 0.0359s/iter; left time: 645.3804s\n",
      "\titers: 200, epoch: 21 | loss: 0.0685546\n",
      "\tspeed: 0.0177s/iter; left time: 315.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0719999 Vali Loss: 0.0860083 Test Loss: 0.0886675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0693834\n",
      "\tspeed: 0.0356s/iter; left time: 632.1671s\n",
      "\titers: 200, epoch: 22 | loss: 0.0721585\n",
      "\tspeed: 0.0210s/iter; left time: 370.9165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0718582 Vali Loss: 0.0861149 Test Loss: 0.0887164\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0723435\n",
      "\tspeed: 0.0356s/iter; left time: 623.4974s\n",
      "\titers: 200, epoch: 23 | loss: 0.0708623\n",
      "\tspeed: 0.0192s/iter; left time: 334.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 226 | Train Loss: 0.0718138 Vali Loss: 0.0859426 Test Loss: 0.0885447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0673030\n",
      "\tspeed: 0.0337s/iter; left time: 583.4311s\n",
      "\titers: 200, epoch: 24 | loss: 0.0738681\n",
      "\tspeed: 0.0150s/iter; left time: 258.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0717829 Vali Loss: 0.0858032 Test Loss: 0.0884723\n",
      "Validation loss decreased (0.085839 --> 0.085803).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0704683\n",
      "\tspeed: 0.0400s/iter; left time: 683.7744s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714896\n",
      "\tspeed: 0.0186s/iter; left time: 315.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0717126 Vali Loss: 0.0859911 Test Loss: 0.0884950\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0681589\n",
      "\tspeed: 0.0359s/iter; left time: 604.9268s\n",
      "\titers: 200, epoch: 26 | loss: 0.0726249\n",
      "\tspeed: 0.0169s/iter; left time: 283.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0717103 Vali Loss: 0.0859508 Test Loss: 0.0884369\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0782910\n",
      "\tspeed: 0.0368s/iter; left time: 611.0635s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724409\n",
      "\tspeed: 0.0184s/iter; left time: 303.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0716138 Vali Loss: 0.0858983 Test Loss: 0.0884526\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0694560\n",
      "\tspeed: 0.0310s/iter; left time: 508.5377s\n",
      "\titers: 200, epoch: 28 | loss: 0.0677827\n",
      "\tspeed: 0.0149s/iter; left time: 242.8831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0715209 Vali Loss: 0.0858228 Test Loss: 0.0884682\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0740452\n",
      "\tspeed: 0.0342s/iter; left time: 553.5682s\n",
      "\titers: 200, epoch: 29 | loss: 0.0732080\n",
      "\tspeed: 0.0156s/iter; left time: 250.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0715645 Vali Loss: 0.0857859 Test Loss: 0.0884036\n",
      "Validation loss decreased (0.085803 --> 0.085786).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0713792\n",
      "\tspeed: 0.0326s/iter; left time: 519.2028s\n",
      "\titers: 200, epoch: 30 | loss: 0.0688472\n",
      "\tspeed: 0.0167s/iter; left time: 264.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0715175 Vali Loss: 0.0857581 Test Loss: 0.0884080\n",
      "Validation loss decreased (0.085786 --> 0.085758).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0746582\n",
      "\tspeed: 0.0346s/iter; left time: 544.3058s\n",
      "\titers: 200, epoch: 31 | loss: 0.0794997\n",
      "\tspeed: 0.0177s/iter; left time: 276.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0715177 Vali Loss: 0.0857334 Test Loss: 0.0884154\n",
      "Validation loss decreased (0.085758 --> 0.085733).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0719389\n",
      "\tspeed: 0.0366s/iter; left time: 567.0978s\n",
      "\titers: 200, epoch: 32 | loss: 0.0694298\n",
      "\tspeed: 0.0176s/iter; left time: 270.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0714295 Vali Loss: 0.0856955 Test Loss: 0.0884091\n",
      "Validation loss decreased (0.085733 --> 0.085696).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0731141\n",
      "\tspeed: 0.0374s/iter; left time: 570.6708s\n",
      "\titers: 200, epoch: 33 | loss: 0.0715551\n",
      "\tspeed: 0.0174s/iter; left time: 263.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0714486 Vali Loss: 0.0857436 Test Loss: 0.0884355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0685063\n",
      "\tspeed: 0.0328s/iter; left time: 492.9971s\n",
      "\titers: 200, epoch: 34 | loss: 0.0719461\n",
      "\tspeed: 0.0161s/iter; left time: 240.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0714117 Vali Loss: 0.0857003 Test Loss: 0.0883715\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0678761\n",
      "\tspeed: 0.0316s/iter; left time: 468.1568s\n",
      "\titers: 200, epoch: 35 | loss: 0.0704411\n",
      "\tspeed: 0.0148s/iter; left time: 217.1721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0714024 Vali Loss: 0.0857247 Test Loss: 0.0883413\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0765597\n",
      "\tspeed: 0.0361s/iter; left time: 527.0034s\n",
      "\titers: 200, epoch: 36 | loss: 0.0729911\n",
      "\tspeed: 0.0206s/iter; left time: 299.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 226 | Train Loss: 0.0713982 Vali Loss: 0.0857187 Test Loss: 0.0883920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0711310\n",
      "\tspeed: 0.0373s/iter; left time: 536.0037s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783857\n",
      "\tspeed: 0.0174s/iter; left time: 247.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0713893 Vali Loss: 0.0857170 Test Loss: 0.0883451\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0746590\n",
      "\tspeed: 0.0377s/iter; left time: 533.1887s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706815\n",
      "\tspeed: 0.0203s/iter; left time: 284.5018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 226 | Train Loss: 0.0713295 Vali Loss: 0.0857492 Test Loss: 0.0883414\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0762485\n",
      "\tspeed: 0.0415s/iter; left time: 578.0144s\n",
      "\titers: 200, epoch: 39 | loss: 0.0727055\n",
      "\tspeed: 0.0211s/iter; left time: 291.1379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 226 | Train Loss: 0.0713518 Vali Loss: 0.0857587 Test Loss: 0.0883479\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0698914\n",
      "\tspeed: 0.0356s/iter; left time: 487.4345s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677442\n",
      "\tspeed: 0.0159s/iter; left time: 216.2101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0713394 Vali Loss: 0.0856901 Test Loss: 0.0883288\n",
      "Validation loss decreased (0.085696 --> 0.085690).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0728084\n",
      "\tspeed: 0.0330s/iter; left time: 444.6270s\n",
      "\titers: 200, epoch: 41 | loss: 0.0761702\n",
      "\tspeed: 0.0179s/iter; left time: 239.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0713025 Vali Loss: 0.0855827 Test Loss: 0.0883383\n",
      "Validation loss decreased (0.085690 --> 0.085583).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0713209\n",
      "\tspeed: 0.0338s/iter; left time: 447.3594s\n",
      "\titers: 200, epoch: 42 | loss: 0.0679729\n",
      "\tspeed: 0.0182s/iter; left time: 238.8916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 226 | Train Loss: 0.0712892 Vali Loss: 0.0856312 Test Loss: 0.0883043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0712263\n",
      "\tspeed: 0.0329s/iter; left time: 427.8249s\n",
      "\titers: 200, epoch: 43 | loss: 0.0721410\n",
      "\tspeed: 0.0149s/iter; left time: 192.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0713039 Vali Loss: 0.0856211 Test Loss: 0.0883403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0702652\n",
      "\tspeed: 0.0383s/iter; left time: 489.9326s\n",
      "\titers: 200, epoch: 44 | loss: 0.0679031\n",
      "\tspeed: 0.0174s/iter; left time: 221.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0712658 Vali Loss: 0.0857103 Test Loss: 0.0883354\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0719044\n",
      "\tspeed: 0.0338s/iter; left time: 424.8848s\n",
      "\titers: 200, epoch: 45 | loss: 0.0728759\n",
      "\tspeed: 0.0153s/iter; left time: 190.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0712951 Vali Loss: 0.0857546 Test Loss: 0.0883350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0705679\n",
      "\tspeed: 0.0340s/iter; left time: 419.5287s\n",
      "\titers: 200, epoch: 46 | loss: 0.0715705\n",
      "\tspeed: 0.0180s/iter; left time: 219.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0713185 Vali Loss: 0.0855664 Test Loss: 0.0883432\n",
      "Validation loss decreased (0.085583 --> 0.085566).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0704627\n",
      "\tspeed: 0.0324s/iter; left time: 392.7287s\n",
      "\titers: 200, epoch: 47 | loss: 0.0729561\n",
      "\tspeed: 0.0157s/iter; left time: 189.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0712942 Vali Loss: 0.0856717 Test Loss: 0.0883280\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0682058\n",
      "\tspeed: 0.0331s/iter; left time: 392.8261s\n",
      "\titers: 200, epoch: 48 | loss: 0.0693166\n",
      "\tspeed: 0.0148s/iter; left time: 174.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0713058 Vali Loss: 0.0856410 Test Loss: 0.0883086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660363\n",
      "\tspeed: 0.0330s/iter; left time: 384.3493s\n",
      "\titers: 200, epoch: 49 | loss: 0.0697123\n",
      "\tspeed: 0.0171s/iter; left time: 197.6317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0712463 Vali Loss: 0.0855903 Test Loss: 0.0883189\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0686551\n",
      "\tspeed: 0.0378s/iter; left time: 431.8369s\n",
      "\titers: 200, epoch: 50 | loss: 0.0664038\n",
      "\tspeed: 0.0197s/iter; left time: 222.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0712557 Vali Loss: 0.0855734 Test Loss: 0.0883155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0744726\n",
      "\tspeed: 0.0354s/iter; left time: 397.0690s\n",
      "\titers: 200, epoch: 51 | loss: 0.0737909\n",
      "\tspeed: 0.0161s/iter; left time: 178.3100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0712689 Vali Loss: 0.0856441 Test Loss: 0.0883205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0756705\n",
      "\tspeed: 0.0318s/iter; left time: 348.8220s\n",
      "\titers: 200, epoch: 52 | loss: 0.0705133\n",
      "\tspeed: 0.0175s/iter; left time: 189.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0712694 Vali Loss: 0.0855412 Test Loss: 0.0883130\n",
      "Validation loss decreased (0.085566 --> 0.085541).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0720955\n",
      "\tspeed: 0.0342s/iter; left time: 367.8885s\n",
      "\titers: 200, epoch: 53 | loss: 0.0706849\n",
      "\tspeed: 0.0180s/iter; left time: 191.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.0712541 Vali Loss: 0.0856194 Test Loss: 0.0883148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0678672\n",
      "\tspeed: 0.0344s/iter; left time: 361.9226s\n",
      "\titers: 200, epoch: 54 | loss: 0.0734708\n",
      "\tspeed: 0.0161s/iter; left time: 167.7152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0712836 Vali Loss: 0.0856949 Test Loss: 0.0883241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0711872\n",
      "\tspeed: 0.0388s/iter; left time: 399.7837s\n",
      "\titers: 200, epoch: 55 | loss: 0.0728162\n",
      "\tspeed: 0.0148s/iter; left time: 150.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0712821 Vali Loss: 0.0857205 Test Loss: 0.0883147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0777686\n",
      "\tspeed: 0.0349s/iter; left time: 351.9102s\n",
      "\titers: 200, epoch: 56 | loss: 0.0725330\n",
      "\tspeed: 0.0160s/iter; left time: 159.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0712508 Vali Loss: 0.0856761 Test Loss: 0.0883089\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0710412\n",
      "\tspeed: 0.0361s/iter; left time: 355.3465s\n",
      "\titers: 200, epoch: 57 | loss: 0.0677898\n",
      "\tspeed: 0.0177s/iter; left time: 172.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0712242 Vali Loss: 0.0856294 Test Loss: 0.0883095\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0743255\n",
      "\tspeed: 0.0362s/iter; left time: 348.6598s\n",
      "\titers: 200, epoch: 58 | loss: 0.0715804\n",
      "\tspeed: 0.0191s/iter; left time: 181.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0712374 Vali Loss: 0.0856550 Test Loss: 0.0883076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0697248\n",
      "\tspeed: 0.0340s/iter; left time: 319.7715s\n",
      "\titers: 200, epoch: 59 | loss: 0.0690377\n",
      "\tspeed: 0.0154s/iter; left time: 143.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0712509 Vali Loss: 0.0857698 Test Loss: 0.0883156\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0771950\n",
      "\tspeed: 0.0342s/iter; left time: 313.7151s\n",
      "\titers: 200, epoch: 60 | loss: 0.0674402\n",
      "\tspeed: 0.0153s/iter; left time: 139.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0712430 Vali Loss: 0.0856275 Test Loss: 0.0883090\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0728195\n",
      "\tspeed: 0.0363s/iter; left time: 324.6634s\n",
      "\titers: 200, epoch: 61 | loss: 0.0771895\n",
      "\tspeed: 0.0157s/iter; left time: 138.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0712464 Vali Loss: 0.0856176 Test Loss: 0.0883221\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0706645\n",
      "\tspeed: 0.0355s/iter; left time: 309.0578s\n",
      "\titers: 200, epoch: 62 | loss: 0.0693574\n",
      "\tspeed: 0.0176s/iter; left time: 151.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0712369 Vali Loss: 0.0855623 Test Loss: 0.0883131\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021246246993541718, rmse:0.1457609236240387, mae:0.08831298351287842, rse:0.5144104957580566\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1518033\n",
      "\tspeed: 0.0192s/iter; left time: 431.8547s\n",
      "\titers: 200, epoch: 1 | loss: 0.1270512\n",
      "\tspeed: 0.0201s/iter; left time: 449.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.1498720 Vali Loss: 0.1357662 Test Loss: 0.1440873\n",
      "Validation loss decreased (inf --> 0.135766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853987\n",
      "\tspeed: 0.0352s/iter; left time: 784.5516s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901837\n",
      "\tspeed: 0.0148s/iter; left time: 328.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0911641 Vali Loss: 0.0949860 Test Loss: 0.0961873\n",
      "Validation loss decreased (0.135766 --> 0.094986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799221\n",
      "\tspeed: 0.0335s/iter; left time: 737.8098s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794998\n",
      "\tspeed: 0.0157s/iter; left time: 344.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 226 | Train Loss: 0.0814267 Vali Loss: 0.0915384 Test Loss: 0.0932980\n",
      "Validation loss decreased (0.094986 --> 0.091538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764318\n",
      "\tspeed: 0.0368s/iter; left time: 802.1689s\n",
      "\titers: 200, epoch: 4 | loss: 0.0785906\n",
      "\tspeed: 0.0218s/iter; left time: 474.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 226 | Train Loss: 0.0787459 Vali Loss: 0.0898482 Test Loss: 0.0917731\n",
      "Validation loss decreased (0.091538 --> 0.089848).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0741054\n",
      "\tspeed: 0.0383s/iter; left time: 826.3129s\n",
      "\titers: 200, epoch: 5 | loss: 0.0753271\n",
      "\tspeed: 0.0187s/iter; left time: 401.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0770410 Vali Loss: 0.0887867 Test Loss: 0.0908344\n",
      "Validation loss decreased (0.089848 --> 0.088787).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765578\n",
      "\tspeed: 0.0346s/iter; left time: 740.2349s\n",
      "\titers: 200, epoch: 6 | loss: 0.0733192\n",
      "\tspeed: 0.0162s/iter; left time: 344.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0760022 Vali Loss: 0.0880748 Test Loss: 0.0903927\n",
      "Validation loss decreased (0.088787 --> 0.088075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0709637\n",
      "\tspeed: 0.0361s/iter; left time: 763.8951s\n",
      "\titers: 200, epoch: 7 | loss: 0.0734636\n",
      "\tspeed: 0.0163s/iter; left time: 343.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0751434 Vali Loss: 0.0871895 Test Loss: 0.0901067\n",
      "Validation loss decreased (0.088075 --> 0.087190).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0773387\n",
      "\tspeed: 0.0366s/iter; left time: 764.6073s\n",
      "\titers: 200, epoch: 8 | loss: 0.0676913\n",
      "\tspeed: 0.0155s/iter; left time: 321.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0746788 Vali Loss: 0.0872169 Test Loss: 0.0898075\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0763129\n",
      "\tspeed: 0.0374s/iter; left time: 774.4037s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725481\n",
      "\tspeed: 0.0195s/iter; left time: 402.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 226 | Train Loss: 0.0741238 Vali Loss: 0.0871174 Test Loss: 0.0893675\n",
      "Validation loss decreased (0.087190 --> 0.087117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0748332\n",
      "\tspeed: 0.0366s/iter; left time: 750.1061s\n",
      "\titers: 200, epoch: 10 | loss: 0.0738588\n",
      "\tspeed: 0.0206s/iter; left time: 419.7334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0737441 Vali Loss: 0.0869346 Test Loss: 0.0891188\n",
      "Validation loss decreased (0.087117 --> 0.086935).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0711018\n",
      "\tspeed: 0.0379s/iter; left time: 767.1253s\n",
      "\titers: 200, epoch: 11 | loss: 0.0700966\n",
      "\tspeed: 0.0190s/iter; left time: 383.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0733540 Vali Loss: 0.0866789 Test Loss: 0.0892408\n",
      "Validation loss decreased (0.086935 --> 0.086679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0763421\n",
      "\tspeed: 0.0405s/iter; left time: 811.2465s\n",
      "\titers: 200, epoch: 12 | loss: 0.0745435\n",
      "\tspeed: 0.0196s/iter; left time: 390.4372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0731190 Vali Loss: 0.0863019 Test Loss: 0.0886837\n",
      "Validation loss decreased (0.086679 --> 0.086302).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0725760\n",
      "\tspeed: 0.0373s/iter; left time: 738.0649s\n",
      "\titers: 200, epoch: 13 | loss: 0.0694761\n",
      "\tspeed: 0.0202s/iter; left time: 396.9208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0728449 Vali Loss: 0.0860798 Test Loss: 0.0886771\n",
      "Validation loss decreased (0.086302 --> 0.086080).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0713402\n",
      "\tspeed: 0.0395s/iter; left time: 772.6691s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717091\n",
      "\tspeed: 0.0197s/iter; left time: 383.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0726764 Vali Loss: 0.0860854 Test Loss: 0.0887915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0696020\n",
      "\tspeed: 0.0379s/iter; left time: 732.7090s\n",
      "\titers: 200, epoch: 15 | loss: 0.0707006\n",
      "\tspeed: 0.0182s/iter; left time: 349.7996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0724796 Vali Loss: 0.0859697 Test Loss: 0.0885499\n",
      "Validation loss decreased (0.086080 --> 0.085970).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0702264\n",
      "\tspeed: 0.0326s/iter; left time: 623.5638s\n",
      "\titers: 200, epoch: 16 | loss: 0.0770680\n",
      "\tspeed: 0.0148s/iter; left time: 280.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0723478 Vali Loss: 0.0859928 Test Loss: 0.0885237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0693218\n",
      "\tspeed: 0.0366s/iter; left time: 690.8188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0685964\n",
      "\tspeed: 0.0195s/iter; left time: 366.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0721852 Vali Loss: 0.0858721 Test Loss: 0.0885176\n",
      "Validation loss decreased (0.085970 --> 0.085872).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0763035\n",
      "\tspeed: 0.0348s/iter; left time: 649.1754s\n",
      "\titers: 200, epoch: 18 | loss: 0.0726792\n",
      "\tspeed: 0.0228s/iter; left time: 422.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0720626 Vali Loss: 0.0858251 Test Loss: 0.0883971\n",
      "Validation loss decreased (0.085872 --> 0.085825).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737270\n",
      "\tspeed: 0.0377s/iter; left time: 694.0765s\n",
      "\titers: 200, epoch: 19 | loss: 0.0792900\n",
      "\tspeed: 0.0209s/iter; left time: 382.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0719951 Vali Loss: 0.0858679 Test Loss: 0.0884198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0684844\n",
      "\tspeed: 0.0388s/iter; left time: 707.1272s\n",
      "\titers: 200, epoch: 20 | loss: 0.0707226\n",
      "\tspeed: 0.0201s/iter; left time: 363.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0718766 Vali Loss: 0.0856740 Test Loss: 0.0883149\n",
      "Validation loss decreased (0.085825 --> 0.085674).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0758472\n",
      "\tspeed: 0.0385s/iter; left time: 691.6377s\n",
      "\titers: 200, epoch: 21 | loss: 0.0754508\n",
      "\tspeed: 0.0201s/iter; left time: 358.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0717989 Vali Loss: 0.0857483 Test Loss: 0.0882967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0715936\n",
      "\tspeed: 0.0376s/iter; left time: 667.4035s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681770\n",
      "\tspeed: 0.0188s/iter; left time: 332.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0716900 Vali Loss: 0.0857370 Test Loss: 0.0882843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729675\n",
      "\tspeed: 0.0385s/iter; left time: 675.1515s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740432\n",
      "\tspeed: 0.0212s/iter; left time: 369.5652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0716362 Vali Loss: 0.0854434 Test Loss: 0.0882942\n",
      "Validation loss decreased (0.085674 --> 0.085443).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0722094\n",
      "\tspeed: 0.0392s/iter; left time: 677.9869s\n",
      "\titers: 200, epoch: 24 | loss: 0.0706832\n",
      "\tspeed: 0.0174s/iter; left time: 300.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0715837 Vali Loss: 0.0857568 Test Loss: 0.0883134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0648718\n",
      "\tspeed: 0.0408s/iter; left time: 697.0089s\n",
      "\titers: 200, epoch: 25 | loss: 0.0725351\n",
      "\tspeed: 0.0172s/iter; left time: 292.1746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0714995 Vali Loss: 0.0852995 Test Loss: 0.0881621\n",
      "Validation loss decreased (0.085443 --> 0.085299).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812834\n",
      "\tspeed: 0.0387s/iter; left time: 651.7739s\n",
      "\titers: 200, epoch: 26 | loss: 0.0664594\n",
      "\tspeed: 0.0191s/iter; left time: 319.1942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0714836 Vali Loss: 0.0853780 Test Loss: 0.0881366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0742876\n",
      "\tspeed: 0.0400s/iter; left time: 665.4394s\n",
      "\titers: 200, epoch: 27 | loss: 0.0732438\n",
      "\tspeed: 0.0220s/iter; left time: 363.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 226 | Train Loss: 0.0714202 Vali Loss: 0.0854149 Test Loss: 0.0881234\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0714915\n",
      "\tspeed: 0.0348s/iter; left time: 570.5468s\n",
      "\titers: 200, epoch: 28 | loss: 0.0735736\n",
      "\tspeed: 0.0179s/iter; left time: 291.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0713732 Vali Loss: 0.0854846 Test Loss: 0.0881038\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0754490\n",
      "\tspeed: 0.0375s/iter; left time: 606.1918s\n",
      "\titers: 200, epoch: 29 | loss: 0.0688223\n",
      "\tspeed: 0.0199s/iter; left time: 319.9783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0714346 Vali Loss: 0.0855115 Test Loss: 0.0881206\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0691710\n",
      "\tspeed: 0.0383s/iter; left time: 610.5563s\n",
      "\titers: 200, epoch: 30 | loss: 0.0732817\n",
      "\tspeed: 0.0162s/iter; left time: 257.2781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0713558 Vali Loss: 0.0852352 Test Loss: 0.0881770\n",
      "Validation loss decreased (0.085299 --> 0.085235).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0723415\n",
      "\tspeed: 0.0368s/iter; left time: 578.3818s\n",
      "\titers: 200, epoch: 31 | loss: 0.0698793\n",
      "\tspeed: 0.0148s/iter; left time: 230.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0713109 Vali Loss: 0.0855413 Test Loss: 0.0881131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0731405\n",
      "\tspeed: 0.0358s/iter; left time: 555.4050s\n",
      "\titers: 200, epoch: 32 | loss: 0.0700180\n",
      "\tspeed: 0.0193s/iter; left time: 296.7149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0713076 Vali Loss: 0.0853621 Test Loss: 0.0880926\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0645976\n",
      "\tspeed: 0.0334s/iter; left time: 510.1503s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736442\n",
      "\tspeed: 0.0157s/iter; left time: 237.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0712606 Vali Loss: 0.0855004 Test Loss: 0.0881196\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0698599\n",
      "\tspeed: 0.0326s/iter; left time: 490.4366s\n",
      "\titers: 200, epoch: 34 | loss: 0.0672192\n",
      "\tspeed: 0.0148s/iter; left time: 220.8067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0712565 Vali Loss: 0.0854266 Test Loss: 0.0881393\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0714119\n",
      "\tspeed: 0.0380s/iter; left time: 562.3737s\n",
      "\titers: 200, epoch: 35 | loss: 0.0745585\n",
      "\tspeed: 0.0156s/iter; left time: 229.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0712457 Vali Loss: 0.0854704 Test Loss: 0.0881282\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0699492\n",
      "\tspeed: 0.0375s/iter; left time: 547.7401s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743586\n",
      "\tspeed: 0.0177s/iter; left time: 256.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 226 | Train Loss: 0.0712100 Vali Loss: 0.0852717 Test Loss: 0.0881152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0690385\n",
      "\tspeed: 0.0323s/iter; left time: 463.5959s\n",
      "\titers: 200, epoch: 37 | loss: 0.0691354\n",
      "\tspeed: 0.0149s/iter; left time: 212.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0712000 Vali Loss: 0.0853180 Test Loss: 0.0880658\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0746413\n",
      "\tspeed: 0.0389s/iter; left time: 549.4572s\n",
      "\titers: 200, epoch: 38 | loss: 0.0729299\n",
      "\tspeed: 0.0178s/iter; left time: 249.7368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0711829 Vali Loss: 0.0853320 Test Loss: 0.0880678\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0674538\n",
      "\tspeed: 0.0330s/iter; left time: 459.7032s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696075\n",
      "\tspeed: 0.0149s/iter; left time: 205.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0711302 Vali Loss: 0.0852830 Test Loss: 0.0880550\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0697548\n",
      "\tspeed: 0.0374s/iter; left time: 511.2212s\n",
      "\titers: 200, epoch: 40 | loss: 0.0723081\n",
      "\tspeed: 0.0164s/iter; left time: 222.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0711335 Vali Loss: 0.0852903 Test Loss: 0.0880491\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02114878036081791, rmse:0.1454261988401413, mae:0.08817699551582336, rse:0.5132291913032532\n",
      "Intermediate time for DE and pred_len 24: 00h:09m:10.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1546121\n",
      "\tspeed: 0.0416s/iter; left time: 932.4142s\n",
      "\titers: 200, epoch: 1 | loss: 0.1400235\n",
      "\tspeed: 0.0154s/iter; left time: 344.2735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.1571345 Vali Loss: 0.1484944 Test Loss: 0.1616077\n",
      "Validation loss decreased (inf --> 0.148494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1196035\n",
      "\tspeed: 0.0355s/iter; left time: 787.1608s\n",
      "\titers: 200, epoch: 2 | loss: 0.1128855\n",
      "\tspeed: 0.0196s/iter; left time: 433.6503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1181649 Vali Loss: 0.1238543 Test Loss: 0.1332652\n",
      "Validation loss decreased (0.148494 --> 0.123854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108415\n",
      "\tspeed: 0.0346s/iter; left time: 759.2518s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081765\n",
      "\tspeed: 0.0182s/iter; left time: 398.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1086654 Vali Loss: 0.1214263 Test Loss: 0.1309388\n",
      "Validation loss decreased (0.123854 --> 0.121426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058460\n",
      "\tspeed: 0.0362s/iter; left time: 787.2354s\n",
      "\titers: 200, epoch: 4 | loss: 0.1017606\n",
      "\tspeed: 0.0165s/iter; left time: 357.2158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.1063051 Vali Loss: 0.1204320 Test Loss: 0.1294891\n",
      "Validation loss decreased (0.121426 --> 0.120432).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1031780\n",
      "\tspeed: 0.0335s/iter; left time: 720.3490s\n",
      "\titers: 200, epoch: 5 | loss: 0.1077288\n",
      "\tspeed: 0.0182s/iter; left time: 388.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1049562 Vali Loss: 0.1202408 Test Loss: 0.1285590\n",
      "Validation loss decreased (0.120432 --> 0.120241).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1112841\n",
      "\tspeed: 0.0347s/iter; left time: 737.7303s\n",
      "\titers: 200, epoch: 6 | loss: 0.1057750\n",
      "\tspeed: 0.0166s/iter; left time: 351.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1040261 Vali Loss: 0.1198119 Test Loss: 0.1283519\n",
      "Validation loss decreased (0.120241 --> 0.119812).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015058\n",
      "\tspeed: 0.0369s/iter; left time: 777.0897s\n",
      "\titers: 200, epoch: 7 | loss: 0.1056823\n",
      "\tspeed: 0.0174s/iter; left time: 365.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1032991 Vali Loss: 0.1199166 Test Loss: 0.1284418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1041890\n",
      "\tspeed: 0.0343s/iter; left time: 714.1693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076229\n",
      "\tspeed: 0.0151s/iter; left time: 313.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 225 | Train Loss: 0.1027025 Vali Loss: 0.1198784 Test Loss: 0.1279660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1025044\n",
      "\tspeed: 0.0346s/iter; left time: 712.8094s\n",
      "\titers: 200, epoch: 9 | loss: 0.0994158\n",
      "\tspeed: 0.0150s/iter; left time: 307.2104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.1022336 Vali Loss: 0.1190886 Test Loss: 0.1272537\n",
      "Validation loss decreased (0.119812 --> 0.119089).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1005756\n",
      "\tspeed: 0.0383s/iter; left time: 781.2921s\n",
      "\titers: 200, epoch: 10 | loss: 0.1013288\n",
      "\tspeed: 0.0189s/iter; left time: 384.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.1017910 Vali Loss: 0.1191306 Test Loss: 0.1268866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1017002\n",
      "\tspeed: 0.0400s/iter; left time: 805.5786s\n",
      "\titers: 200, epoch: 11 | loss: 0.1038562\n",
      "\tspeed: 0.0225s/iter; left time: 451.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.1014321 Vali Loss: 0.1187267 Test Loss: 0.1270149\n",
      "Validation loss decreased (0.119089 --> 0.118727).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0990154\n",
      "\tspeed: 0.0380s/iter; left time: 756.3343s\n",
      "\titers: 200, epoch: 12 | loss: 0.1071175\n",
      "\tspeed: 0.0178s/iter; left time: 353.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1010969 Vali Loss: 0.1191120 Test Loss: 0.1271684\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1041970\n",
      "\tspeed: 0.0338s/iter; left time: 666.3408s\n",
      "\titers: 200, epoch: 13 | loss: 0.1016034\n",
      "\tspeed: 0.0164s/iter; left time: 322.0665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.1008338 Vali Loss: 0.1195352 Test Loss: 0.1274527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013781\n",
      "\tspeed: 0.0362s/iter; left time: 705.5291s\n",
      "\titers: 200, epoch: 14 | loss: 0.1037347\n",
      "\tspeed: 0.0171s/iter; left time: 330.4930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.1006502 Vali Loss: 0.1190295 Test Loss: 0.1268910\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0992426\n",
      "\tspeed: 0.0345s/iter; left time: 664.9427s\n",
      "\titers: 200, epoch: 15 | loss: 0.0969416\n",
      "\tspeed: 0.0149s/iter; left time: 286.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.1003572 Vali Loss: 0.1189620 Test Loss: 0.1268336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1013089\n",
      "\tspeed: 0.0349s/iter; left time: 664.2710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0990523\n",
      "\tspeed: 0.0203s/iter; left time: 383.4438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1001020 Vali Loss: 0.1187779 Test Loss: 0.1264221\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0997604\n",
      "\tspeed: 0.0361s/iter; left time: 678.8091s\n",
      "\titers: 200, epoch: 17 | loss: 0.1042790\n",
      "\tspeed: 0.0152s/iter; left time: 284.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1000534 Vali Loss: 0.1187418 Test Loss: 0.1266497\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1057856\n",
      "\tspeed: 0.0356s/iter; left time: 661.7073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0973422\n",
      "\tspeed: 0.0154s/iter; left time: 284.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0998120 Vali Loss: 0.1185887 Test Loss: 0.1265640\n",
      "Validation loss decreased (0.118727 --> 0.118589).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0994233\n",
      "\tspeed: 0.0348s/iter; left time: 639.0015s\n",
      "\titers: 200, epoch: 19 | loss: 0.0999866\n",
      "\tspeed: 0.0154s/iter; left time: 281.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0997114 Vali Loss: 0.1188520 Test Loss: 0.1263896\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0996900\n",
      "\tspeed: 0.0352s/iter; left time: 638.2583s\n",
      "\titers: 200, epoch: 20 | loss: 0.1031228\n",
      "\tspeed: 0.0178s/iter; left time: 320.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0995866 Vali Loss: 0.1189126 Test Loss: 0.1265392\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0999166\n",
      "\tspeed: 0.0333s/iter; left time: 595.9401s\n",
      "\titers: 200, epoch: 21 | loss: 0.0971584\n",
      "\tspeed: 0.0166s/iter; left time: 296.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0994200 Vali Loss: 0.1187942 Test Loss: 0.1265447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0989321\n",
      "\tspeed: 0.0332s/iter; left time: 587.4503s\n",
      "\titers: 200, epoch: 22 | loss: 0.1030317\n",
      "\tspeed: 0.0149s/iter; left time: 262.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0993532 Vali Loss: 0.1184512 Test Loss: 0.1264205\n",
      "Validation loss decreased (0.118589 --> 0.118451).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1053485\n",
      "\tspeed: 0.0363s/iter; left time: 633.2806s\n",
      "\titers: 200, epoch: 23 | loss: 0.0915438\n",
      "\tspeed: 0.0190s/iter; left time: 328.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0992047 Vali Loss: 0.1188719 Test Loss: 0.1264960\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1002571\n",
      "\tspeed: 0.0362s/iter; left time: 623.0431s\n",
      "\titers: 200, epoch: 24 | loss: 0.1038216\n",
      "\tspeed: 0.0164s/iter; left time: 280.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0991893 Vali Loss: 0.1185893 Test Loss: 0.1262891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0964289\n",
      "\tspeed: 0.0358s/iter; left time: 609.1420s\n",
      "\titers: 200, epoch: 25 | loss: 0.0961830\n",
      "\tspeed: 0.0160s/iter; left time: 270.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0990750 Vali Loss: 0.1187493 Test Loss: 0.1265117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1029489\n",
      "\tspeed: 0.0334s/iter; left time: 559.5250s\n",
      "\titers: 200, epoch: 26 | loss: 0.0984642\n",
      "\tspeed: 0.0149s/iter; left time: 249.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0990308 Vali Loss: 0.1184566 Test Loss: 0.1263237\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0963094\n",
      "\tspeed: 0.0343s/iter; left time: 568.2647s\n",
      "\titers: 200, epoch: 27 | loss: 0.0988014\n",
      "\tspeed: 0.0176s/iter; left time: 289.6134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0990124 Vali Loss: 0.1186175 Test Loss: 0.1265397\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0955154\n",
      "\tspeed: 0.0352s/iter; left time: 575.1701s\n",
      "\titers: 200, epoch: 28 | loss: 0.0994291\n",
      "\tspeed: 0.0150s/iter; left time: 243.4683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0988817 Vali Loss: 0.1186398 Test Loss: 0.1264903\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1008465\n",
      "\tspeed: 0.0376s/iter; left time: 605.1781s\n",
      "\titers: 200, epoch: 29 | loss: 0.0950760\n",
      "\tspeed: 0.0151s/iter; left time: 241.1719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0988331 Vali Loss: 0.1185322 Test Loss: 0.1264422\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0931816\n",
      "\tspeed: 0.0350s/iter; left time: 555.9447s\n",
      "\titers: 200, epoch: 30 | loss: 0.1001480\n",
      "\tspeed: 0.0149s/iter; left time: 234.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0989152 Vali Loss: 0.1184158 Test Loss: 0.1263546\n",
      "Validation loss decreased (0.118451 --> 0.118416).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0959047\n",
      "\tspeed: 0.0365s/iter; left time: 570.9919s\n",
      "\titers: 200, epoch: 31 | loss: 0.1010143\n",
      "\tspeed: 0.0189s/iter; left time: 293.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0988581 Vali Loss: 0.1183319 Test Loss: 0.1263200\n",
      "Validation loss decreased (0.118416 --> 0.118332).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0970245\n",
      "\tspeed: 0.0376s/iter; left time: 580.4557s\n",
      "\titers: 200, epoch: 32 | loss: 0.0988358\n",
      "\tspeed: 0.0166s/iter; left time: 254.0047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.0988036 Vali Loss: 0.1183956 Test Loss: 0.1264224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1012524\n",
      "\tspeed: 0.0394s/iter; left time: 599.4984s\n",
      "\titers: 200, epoch: 33 | loss: 0.0987937\n",
      "\tspeed: 0.0205s/iter; left time: 310.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0987398 Vali Loss: 0.1182987 Test Loss: 0.1263141\n",
      "Validation loss decreased (0.118332 --> 0.118299).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0985900\n",
      "\tspeed: 0.0374s/iter; left time: 560.4650s\n",
      "\titers: 200, epoch: 34 | loss: 0.0935382\n",
      "\tspeed: 0.0157s/iter; left time: 234.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0987068 Vali Loss: 0.1183450 Test Loss: 0.1263458\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0970084\n",
      "\tspeed: 0.0353s/iter; left time: 521.2234s\n",
      "\titers: 200, epoch: 35 | loss: 0.0927501\n",
      "\tspeed: 0.0208s/iter; left time: 304.0132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0986973 Vali Loss: 0.1186062 Test Loss: 0.1265274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0998640\n",
      "\tspeed: 0.0407s/iter; left time: 591.0085s\n",
      "\titers: 200, epoch: 36 | loss: 0.1007608\n",
      "\tspeed: 0.0220s/iter; left time: 317.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0986956 Vali Loss: 0.1184913 Test Loss: 0.1264177\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1017523\n",
      "\tspeed: 0.0404s/iter; left time: 577.5350s\n",
      "\titers: 200, epoch: 37 | loss: 0.0997659\n",
      "\tspeed: 0.0201s/iter; left time: 284.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.0985954 Vali Loss: 0.1184251 Test Loss: 0.1263238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0956129\n",
      "\tspeed: 0.0353s/iter; left time: 497.2797s\n",
      "\titers: 200, epoch: 38 | loss: 0.0992918\n",
      "\tspeed: 0.0156s/iter; left time: 217.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0986035 Vali Loss: 0.1185189 Test Loss: 0.1264063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0935376\n",
      "\tspeed: 0.0381s/iter; left time: 527.6382s\n",
      "\titers: 200, epoch: 39 | loss: 0.0947464\n",
      "\tspeed: 0.0203s/iter; left time: 278.7095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0986035 Vali Loss: 0.1185026 Test Loss: 0.1264198\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0979223\n",
      "\tspeed: 0.0352s/iter; left time: 479.1197s\n",
      "\titers: 200, epoch: 40 | loss: 0.0945299\n",
      "\tspeed: 0.0198s/iter; left time: 267.9891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0986283 Vali Loss: 0.1184659 Test Loss: 0.1264053\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0983004\n",
      "\tspeed: 0.0403s/iter; left time: 540.3695s\n",
      "\titers: 200, epoch: 41 | loss: 0.0979814\n",
      "\tspeed: 0.0201s/iter; left time: 267.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.0985964 Vali Loss: 0.1184100 Test Loss: 0.1263391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1028368\n",
      "\tspeed: 0.0382s/iter; left time: 502.9143s\n",
      "\titers: 200, epoch: 42 | loss: 0.0956750\n",
      "\tspeed: 0.0187s/iter; left time: 244.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0985760 Vali Loss: 0.1185045 Test Loss: 0.1263552\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0966641\n",
      "\tspeed: 0.0369s/iter; left time: 478.1689s\n",
      "\titers: 200, epoch: 43 | loss: 0.0967524\n",
      "\tspeed: 0.0153s/iter; left time: 197.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0985568 Vali Loss: 0.1185039 Test Loss: 0.1264004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03725607320666313, rmse:0.19301831722259521, mae:0.12631411850452423, rse:0.6835169196128845\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1594719\n",
      "\tspeed: 0.0203s/iter; left time: 454.8996s\n",
      "\titers: 200, epoch: 1 | loss: 0.1446275\n",
      "\tspeed: 0.0205s/iter; left time: 456.7100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1578681 Vali Loss: 0.1489479 Test Loss: 0.1620588\n",
      "Validation loss decreased (inf --> 0.148948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1165081\n",
      "\tspeed: 0.0368s/iter; left time: 815.4234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102197\n",
      "\tspeed: 0.0175s/iter; left time: 385.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1184436 Vali Loss: 0.1239039 Test Loss: 0.1334199\n",
      "Validation loss decreased (0.148948 --> 0.123904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1065054\n",
      "\tspeed: 0.0375s/iter; left time: 822.0836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0987603\n",
      "\tspeed: 0.0150s/iter; left time: 327.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.1088305 Vali Loss: 0.1219295 Test Loss: 0.1310768\n",
      "Validation loss decreased (0.123904 --> 0.121929).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1059293\n",
      "\tspeed: 0.0430s/iter; left time: 934.3116s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097753\n",
      "\tspeed: 0.0207s/iter; left time: 446.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.1064283 Vali Loss: 0.1208800 Test Loss: 0.1299682\n",
      "Validation loss decreased (0.121929 --> 0.120880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106490\n",
      "\tspeed: 0.0440s/iter; left time: 945.2451s\n",
      "\titers: 200, epoch: 5 | loss: 0.1115315\n",
      "\tspeed: 0.0198s/iter; left time: 423.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.1050829 Vali Loss: 0.1201282 Test Loss: 0.1288217\n",
      "Validation loss decreased (0.120880 --> 0.120128).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1070387\n",
      "\tspeed: 0.0368s/iter; left time: 783.4612s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977164\n",
      "\tspeed: 0.0164s/iter; left time: 346.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.1041735 Vali Loss: 0.1211485 Test Loss: 0.1292872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014085\n",
      "\tspeed: 0.0330s/iter; left time: 695.6314s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047801\n",
      "\tspeed: 0.0152s/iter; left time: 317.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1035143 Vali Loss: 0.1195752 Test Loss: 0.1277059\n",
      "Validation loss decreased (0.120128 --> 0.119575).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1013614\n",
      "\tspeed: 0.0390s/iter; left time: 811.3228s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080542\n",
      "\tspeed: 0.0195s/iter; left time: 405.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 225 | Train Loss: 0.1029324 Vali Loss: 0.1196418 Test Loss: 0.1277450\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1005211\n",
      "\tspeed: 0.0362s/iter; left time: 745.8069s\n",
      "\titers: 200, epoch: 9 | loss: 0.0996397\n",
      "\tspeed: 0.0171s/iter; left time: 349.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1024450 Vali Loss: 0.1194940 Test Loss: 0.1271717\n",
      "Validation loss decreased (0.119575 --> 0.119494).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033988\n",
      "\tspeed: 0.0405s/iter; left time: 825.6661s\n",
      "\titers: 200, epoch: 10 | loss: 0.1075299\n",
      "\tspeed: 0.0211s/iter; left time: 428.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.1019535 Vali Loss: 0.1189011 Test Loss: 0.1265846\n",
      "Validation loss decreased (0.119494 --> 0.118901).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1029874\n",
      "\tspeed: 0.0421s/iter; left time: 849.3110s\n",
      "\titers: 200, epoch: 11 | loss: 0.0994294\n",
      "\tspeed: 0.0199s/iter; left time: 398.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.1015970 Vali Loss: 0.1188431 Test Loss: 0.1266741\n",
      "Validation loss decreased (0.118901 --> 0.118843).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1002504\n",
      "\tspeed: 0.0386s/iter; left time: 769.3879s\n",
      "\titers: 200, epoch: 12 | loss: 0.0984752\n",
      "\tspeed: 0.0210s/iter; left time: 415.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1012771 Vali Loss: 0.1190146 Test Loss: 0.1266688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0951208\n",
      "\tspeed: 0.0397s/iter; left time: 781.4904s\n",
      "\titers: 200, epoch: 13 | loss: 0.1013440\n",
      "\tspeed: 0.0207s/iter; left time: 405.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1009379 Vali Loss: 0.1190206 Test Loss: 0.1263876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1019207\n",
      "\tspeed: 0.0394s/iter; left time: 767.8853s\n",
      "\titers: 200, epoch: 14 | loss: 0.1002271\n",
      "\tspeed: 0.0193s/iter; left time: 373.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1006495 Vali Loss: 0.1190553 Test Loss: 0.1264120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0994094\n",
      "\tspeed: 0.0393s/iter; left time: 756.3436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0971790\n",
      "\tspeed: 0.0179s/iter; left time: 342.5074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.1004595 Vali Loss: 0.1186343 Test Loss: 0.1265867\n",
      "Validation loss decreased (0.118843 --> 0.118634).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1021780\n",
      "\tspeed: 0.0393s/iter; left time: 747.8991s\n",
      "\titers: 200, epoch: 16 | loss: 0.1010583\n",
      "\tspeed: 0.0175s/iter; left time: 331.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.1002135 Vali Loss: 0.1187289 Test Loss: 0.1263449\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0969147\n",
      "\tspeed: 0.0383s/iter; left time: 720.5074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0948327\n",
      "\tspeed: 0.0190s/iter; left time: 354.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0999837 Vali Loss: 0.1188469 Test Loss: 0.1263028\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0999236\n",
      "\tspeed: 0.0408s/iter; left time: 757.3810s\n",
      "\titers: 200, epoch: 18 | loss: 0.1040796\n",
      "\tspeed: 0.0207s/iter; left time: 382.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0998135 Vali Loss: 0.1189184 Test Loss: 0.1264344\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1023207\n",
      "\tspeed: 0.0381s/iter; left time: 700.0582s\n",
      "\titers: 200, epoch: 19 | loss: 0.0959595\n",
      "\tspeed: 0.0178s/iter; left time: 324.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0996949 Vali Loss: 0.1189701 Test Loss: 0.1262245\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1043485\n",
      "\tspeed: 0.0417s/iter; left time: 756.0298s\n",
      "\titers: 200, epoch: 20 | loss: 0.1012136\n",
      "\tspeed: 0.0221s/iter; left time: 397.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0996269 Vali Loss: 0.1188949 Test Loss: 0.1261493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1007755\n",
      "\tspeed: 0.0402s/iter; left time: 719.6723s\n",
      "\titers: 200, epoch: 21 | loss: 0.0938013\n",
      "\tspeed: 0.0220s/iter; left time: 391.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0994555 Vali Loss: 0.1189866 Test Loss: 0.1263751\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0992515\n",
      "\tspeed: 0.0428s/iter; left time: 757.0956s\n",
      "\titers: 200, epoch: 22 | loss: 0.0981303\n",
      "\tspeed: 0.0226s/iter; left time: 396.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 225 | Train Loss: 0.0994021 Vali Loss: 0.1189413 Test Loss: 0.1262374\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1014347\n",
      "\tspeed: 0.0444s/iter; left time: 774.2949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0944737\n",
      "\tspeed: 0.0205s/iter; left time: 355.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 225 | Train Loss: 0.0993091 Vali Loss: 0.1188072 Test Loss: 0.1261979\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1021972\n",
      "\tspeed: 0.0403s/iter; left time: 693.4551s\n",
      "\titers: 200, epoch: 24 | loss: 0.0987332\n",
      "\tspeed: 0.0200s/iter; left time: 341.7360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0991928 Vali Loss: 0.1189013 Test Loss: 0.1264363\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1018750\n",
      "\tspeed: 0.0399s/iter; left time: 677.8940s\n",
      "\titers: 200, epoch: 25 | loss: 0.0972224\n",
      "\tspeed: 0.0192s/iter; left time: 323.9625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0991676 Vali Loss: 0.1189413 Test Loss: 0.1262479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03709335997700691, rmse:0.19259636104106903, mae:0.1265867054462433, rse:0.6820226311683655\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:29.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1597681\n",
      "\tspeed: 0.0421s/iter; left time: 943.7567s\n",
      "\titers: 200, epoch: 1 | loss: 0.1394441\n",
      "\tspeed: 0.0154s/iter; left time: 343.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1611064 Vali Loss: 0.1516039 Test Loss: 0.1655859\n",
      "Validation loss decreased (inf --> 0.151604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1293734\n",
      "\tspeed: 0.0379s/iter; left time: 840.5527s\n",
      "\titers: 200, epoch: 2 | loss: 0.1188756\n",
      "\tspeed: 0.0184s/iter; left time: 406.4267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1250985 Vali Loss: 0.1289203 Test Loss: 0.1402800\n",
      "Validation loss decreased (0.151604 --> 0.128920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1157258\n",
      "\tspeed: 0.0392s/iter; left time: 860.6975s\n",
      "\titers: 200, epoch: 3 | loss: 0.1150265\n",
      "\tspeed: 0.0159s/iter; left time: 347.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.1154583 Vali Loss: 0.1264038 Test Loss: 0.1374858\n",
      "Validation loss decreased (0.128920 --> 0.126404).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1165608\n",
      "\tspeed: 0.0366s/iter; left time: 794.8849s\n",
      "\titers: 200, epoch: 4 | loss: 0.1122621\n",
      "\tspeed: 0.0181s/iter; left time: 390.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1130506 Vali Loss: 0.1259780 Test Loss: 0.1365361\n",
      "Validation loss decreased (0.126404 --> 0.125978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1151247\n",
      "\tspeed: 0.0390s/iter; left time: 839.4699s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071975\n",
      "\tspeed: 0.0179s/iter; left time: 382.5318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1116234 Vali Loss: 0.1258907 Test Loss: 0.1366494\n",
      "Validation loss decreased (0.125978 --> 0.125891).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1089182\n",
      "\tspeed: 0.0355s/iter; left time: 756.0827s\n",
      "\titers: 200, epoch: 6 | loss: 0.1135221\n",
      "\tspeed: 0.0168s/iter; left time: 356.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.1107035 Vali Loss: 0.1255296 Test Loss: 0.1358035\n",
      "Validation loss decreased (0.125891 --> 0.125530).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1117654\n",
      "\tspeed: 0.0397s/iter; left time: 836.1848s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075306\n",
      "\tspeed: 0.0192s/iter; left time: 402.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1099964 Vali Loss: 0.1253670 Test Loss: 0.1351608\n",
      "Validation loss decreased (0.125530 --> 0.125367).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1033830\n",
      "\tspeed: 0.0366s/iter; left time: 762.8314s\n",
      "\titers: 200, epoch: 8 | loss: 0.1089234\n",
      "\tspeed: 0.0152s/iter; left time: 314.4212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.1094158 Vali Loss: 0.1254329 Test Loss: 0.1354677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1109020\n",
      "\tspeed: 0.0346s/iter; left time: 713.4664s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085580\n",
      "\tspeed: 0.0153s/iter; left time: 314.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1089027 Vali Loss: 0.1248833 Test Loss: 0.1352038\n",
      "Validation loss decreased (0.125367 --> 0.124883).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1067005\n",
      "\tspeed: 0.0356s/iter; left time: 725.6138s\n",
      "\titers: 200, epoch: 10 | loss: 0.1039695\n",
      "\tspeed: 0.0151s/iter; left time: 307.0943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1085350 Vali Loss: 0.1246719 Test Loss: 0.1349904\n",
      "Validation loss decreased (0.124883 --> 0.124672).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1060302\n",
      "\tspeed: 0.0401s/iter; left time: 807.2325s\n",
      "\titers: 200, epoch: 11 | loss: 0.1044329\n",
      "\tspeed: 0.0174s/iter; left time: 348.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.1080497 Vali Loss: 0.1248863 Test Loss: 0.1353544\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1098358\n",
      "\tspeed: 0.0364s/iter; left time: 724.6957s\n",
      "\titers: 200, epoch: 12 | loss: 0.1077055\n",
      "\tspeed: 0.0151s/iter; left time: 300.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1078033 Vali Loss: 0.1247643 Test Loss: 0.1351484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1063721\n",
      "\tspeed: 0.0377s/iter; left time: 743.4401s\n",
      "\titers: 200, epoch: 13 | loss: 0.1019878\n",
      "\tspeed: 0.0190s/iter; left time: 372.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1074929 Vali Loss: 0.1244314 Test Loss: 0.1348955\n",
      "Validation loss decreased (0.124672 --> 0.124431).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1112889\n",
      "\tspeed: 0.0405s/iter; left time: 788.4218s\n",
      "\titers: 200, epoch: 14 | loss: 0.1100490\n",
      "\tspeed: 0.0160s/iter; left time: 309.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.1072949 Vali Loss: 0.1246140 Test Loss: 0.1347168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1048008\n",
      "\tspeed: 0.0356s/iter; left time: 686.2853s\n",
      "\titers: 200, epoch: 15 | loss: 0.1065564\n",
      "\tspeed: 0.0168s/iter; left time: 321.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.1069529 Vali Loss: 0.1243602 Test Loss: 0.1350712\n",
      "Validation loss decreased (0.124431 --> 0.124360).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1137868\n",
      "\tspeed: 0.0366s/iter; left time: 696.4361s\n",
      "\titers: 200, epoch: 16 | loss: 0.1119398\n",
      "\tspeed: 0.0190s/iter; left time: 358.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.1068381 Vali Loss: 0.1244992 Test Loss: 0.1346245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1088810\n",
      "\tspeed: 0.0338s/iter; left time: 634.5856s\n",
      "\titers: 200, epoch: 17 | loss: 0.1117870\n",
      "\tspeed: 0.0153s/iter; left time: 286.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 225 | Train Loss: 0.1066407 Vali Loss: 0.1241617 Test Loss: 0.1347925\n",
      "Validation loss decreased (0.124360 --> 0.124162).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1037163\n",
      "\tspeed: 0.0382s/iter; left time: 710.1916s\n",
      "\titers: 200, epoch: 18 | loss: 0.1055945\n",
      "\tspeed: 0.0151s/iter; left time: 279.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1065037 Vali Loss: 0.1244145 Test Loss: 0.1348231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1053035\n",
      "\tspeed: 0.0340s/iter; left time: 624.7087s\n",
      "\titers: 200, epoch: 19 | loss: 0.1099117\n",
      "\tspeed: 0.0151s/iter; left time: 275.6109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.1063549 Vali Loss: 0.1242019 Test Loss: 0.1347113\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1073127\n",
      "\tspeed: 0.0361s/iter; left time: 654.6316s\n",
      "\titers: 200, epoch: 20 | loss: 0.1123709\n",
      "\tspeed: 0.0172s/iter; left time: 309.5763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.1063023 Vali Loss: 0.1241778 Test Loss: 0.1349964\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1037868\n",
      "\tspeed: 0.0403s/iter; left time: 721.5322s\n",
      "\titers: 200, epoch: 21 | loss: 0.1039041\n",
      "\tspeed: 0.0181s/iter; left time: 323.0807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.1061470 Vali Loss: 0.1238399 Test Loss: 0.1348939\n",
      "Validation loss decreased (0.124162 --> 0.123840).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1074208\n",
      "\tspeed: 0.0352s/iter; left time: 622.4051s\n",
      "\titers: 200, epoch: 22 | loss: 0.1065059\n",
      "\tspeed: 0.0153s/iter; left time: 268.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.1060402 Vali Loss: 0.1240012 Test Loss: 0.1350031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1067464\n",
      "\tspeed: 0.0396s/iter; left time: 690.8393s\n",
      "\titers: 200, epoch: 23 | loss: 0.0995105\n",
      "\tspeed: 0.0173s/iter; left time: 300.5072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.1059790 Vali Loss: 0.1240508 Test Loss: 0.1347556\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1051342\n",
      "\tspeed: 0.0373s/iter; left time: 643.2248s\n",
      "\titers: 200, epoch: 24 | loss: 0.1061060\n",
      "\tspeed: 0.0180s/iter; left time: 307.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.1058389 Vali Loss: 0.1241084 Test Loss: 0.1347512\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1040247\n",
      "\tspeed: 0.0346s/iter; left time: 587.8989s\n",
      "\titers: 200, epoch: 25 | loss: 0.1066597\n",
      "\tspeed: 0.0158s/iter; left time: 267.4184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.1057603 Vali Loss: 0.1238703 Test Loss: 0.1346270\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1043022\n",
      "\tspeed: 0.0344s/iter; left time: 576.4309s\n",
      "\titers: 200, epoch: 26 | loss: 0.1011586\n",
      "\tspeed: 0.0165s/iter; left time: 275.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 225 | Train Loss: 0.1057232 Vali Loss: 0.1242573 Test Loss: 0.1348052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1044532\n",
      "\tspeed: 0.0364s/iter; left time: 602.3999s\n",
      "\titers: 200, epoch: 27 | loss: 0.1077922\n",
      "\tspeed: 0.0170s/iter; left time: 279.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1056584 Vali Loss: 0.1239977 Test Loss: 0.1347191\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1062665\n",
      "\tspeed: 0.0378s/iter; left time: 617.5555s\n",
      "\titers: 200, epoch: 28 | loss: 0.1054133\n",
      "\tspeed: 0.0202s/iter; left time: 327.7679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 225 | Train Loss: 0.1055746 Vali Loss: 0.1241290 Test Loss: 0.1347836\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1068603\n",
      "\tspeed: 0.0393s/iter; left time: 633.2472s\n",
      "\titers: 200, epoch: 29 | loss: 0.1053896\n",
      "\tspeed: 0.0175s/iter; left time: 279.6740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1055822 Vali Loss: 0.1239924 Test Loss: 0.1348849\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1037724\n",
      "\tspeed: 0.0382s/iter; left time: 606.1204s\n",
      "\titers: 200, epoch: 30 | loss: 0.1117676\n",
      "\tspeed: 0.0187s/iter; left time: 294.8138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.1054864 Vali Loss: 0.1239919 Test Loss: 0.1348824\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1049670\n",
      "\tspeed: 0.0378s/iter; left time: 591.6000s\n",
      "\titers: 200, epoch: 31 | loss: 0.1072682\n",
      "\tspeed: 0.0175s/iter; left time: 271.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.1054962 Vali Loss: 0.1241026 Test Loss: 0.1347783\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04131152108311653, rmse:0.20325236022472382, mae:0.13489389419555664, rse:0.719936192035675\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1629653\n",
      "\tspeed: 0.0174s/iter; left time: 390.6402s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467177\n",
      "\tspeed: 0.0153s/iter; left time: 341.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.1603462 Vali Loss: 0.1508472 Test Loss: 0.1646355\n",
      "Validation loss decreased (inf --> 0.150847).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1300881\n",
      "\tspeed: 0.0398s/iter; left time: 881.5142s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143041\n",
      "\tspeed: 0.0183s/iter; left time: 403.2012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.1242376 Vali Loss: 0.1294085 Test Loss: 0.1407559\n",
      "Validation loss decreased (0.150847 --> 0.129408).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1186319\n",
      "\tspeed: 0.0381s/iter; left time: 836.7470s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203104\n",
      "\tspeed: 0.0162s/iter; left time: 354.0128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.1154474 Vali Loss: 0.1263371 Test Loss: 0.1371361\n",
      "Validation loss decreased (0.129408 --> 0.126337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1122255\n",
      "\tspeed: 0.0392s/iter; left time: 850.7349s\n",
      "\titers: 200, epoch: 4 | loss: 0.1088989\n",
      "\tspeed: 0.0171s/iter; left time: 369.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1131376 Vali Loss: 0.1253243 Test Loss: 0.1361789\n",
      "Validation loss decreased (0.126337 --> 0.125324).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1083760\n",
      "\tspeed: 0.0381s/iter; left time: 819.0103s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178844\n",
      "\tspeed: 0.0205s/iter; left time: 438.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.1117257 Vali Loss: 0.1248998 Test Loss: 0.1352501\n",
      "Validation loss decreased (0.125324 --> 0.124900).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1139530\n",
      "\tspeed: 0.0383s/iter; left time: 813.9864s\n",
      "\titers: 200, epoch: 6 | loss: 0.1064244\n",
      "\tspeed: 0.0166s/iter; left time: 351.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.1107475 Vali Loss: 0.1244106 Test Loss: 0.1347651\n",
      "Validation loss decreased (0.124900 --> 0.124411).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1151732\n",
      "\tspeed: 0.0393s/iter; left time: 826.2979s\n",
      "\titers: 200, epoch: 7 | loss: 0.1072712\n",
      "\tspeed: 0.0187s/iter; left time: 392.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1100969 Vali Loss: 0.1244932 Test Loss: 0.1351271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1128722\n",
      "\tspeed: 0.0398s/iter; left time: 829.2852s\n",
      "\titers: 200, epoch: 8 | loss: 0.1057848\n",
      "\tspeed: 0.0178s/iter; left time: 369.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.1094682 Vali Loss: 0.1239749 Test Loss: 0.1349620\n",
      "Validation loss decreased (0.124411 --> 0.123975).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1162132\n",
      "\tspeed: 0.0348s/iter; left time: 717.1068s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069723\n",
      "\tspeed: 0.0151s/iter; left time: 309.5633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1089953 Vali Loss: 0.1242746 Test Loss: 0.1343836\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1074245\n",
      "\tspeed: 0.0359s/iter; left time: 730.6829s\n",
      "\titers: 200, epoch: 10 | loss: 0.1146695\n",
      "\tspeed: 0.0169s/iter; left time: 342.2095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.1085315 Vali Loss: 0.1246715 Test Loss: 0.1342424\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1077108\n",
      "\tspeed: 0.0390s/iter; left time: 785.0145s\n",
      "\titers: 200, epoch: 11 | loss: 0.1067131\n",
      "\tspeed: 0.0204s/iter; left time: 408.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 225 | Train Loss: 0.1081504 Vali Loss: 0.1237239 Test Loss: 0.1338762\n",
      "Validation loss decreased (0.123975 --> 0.123724).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066032\n",
      "\tspeed: 0.0405s/iter; left time: 806.9693s\n",
      "\titers: 200, epoch: 12 | loss: 0.1069852\n",
      "\tspeed: 0.0188s/iter; left time: 372.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.1077525 Vali Loss: 0.1240567 Test Loss: 0.1340794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1074472\n",
      "\tspeed: 0.0397s/iter; left time: 781.6063s\n",
      "\titers: 200, epoch: 13 | loss: 0.1039106\n",
      "\tspeed: 0.0193s/iter; left time: 377.6317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.1074885 Vali Loss: 0.1241955 Test Loss: 0.1341534\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1025117\n",
      "\tspeed: 0.0398s/iter; left time: 774.9892s\n",
      "\titers: 200, epoch: 14 | loss: 0.1067264\n",
      "\tspeed: 0.0196s/iter; left time: 380.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1072166 Vali Loss: 0.1242939 Test Loss: 0.1342657\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1097217\n",
      "\tspeed: 0.0397s/iter; left time: 765.1856s\n",
      "\titers: 200, epoch: 15 | loss: 0.1035928\n",
      "\tspeed: 0.0197s/iter; left time: 376.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1069498 Vali Loss: 0.1239720 Test Loss: 0.1343582\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1067876\n",
      "\tspeed: 0.0413s/iter; left time: 786.6408s\n",
      "\titers: 200, epoch: 16 | loss: 0.1109241\n",
      "\tspeed: 0.0182s/iter; left time: 345.0859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.1067773 Vali Loss: 0.1238592 Test Loss: 0.1337989\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1054149\n",
      "\tspeed: 0.0402s/iter; left time: 756.4454s\n",
      "\titers: 200, epoch: 17 | loss: 0.1046284\n",
      "\tspeed: 0.0204s/iter; left time: 380.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.1066017 Vali Loss: 0.1241902 Test Loss: 0.1340709\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1064189\n",
      "\tspeed: 0.0413s/iter; left time: 766.7903s\n",
      "\titers: 200, epoch: 18 | loss: 0.1059560\n",
      "\tspeed: 0.0199s/iter; left time: 367.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1064438 Vali Loss: 0.1239474 Test Loss: 0.1339504\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1021350\n",
      "\tspeed: 0.0418s/iter; left time: 766.4911s\n",
      "\titers: 200, epoch: 19 | loss: 0.1146571\n",
      "\tspeed: 0.0191s/iter; left time: 348.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1062876 Vali Loss: 0.1241477 Test Loss: 0.1338608\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1086384\n",
      "\tspeed: 0.0393s/iter; left time: 712.8210s\n",
      "\titers: 200, epoch: 20 | loss: 0.1046049\n",
      "\tspeed: 0.0210s/iter; left time: 377.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.1061432 Vali Loss: 0.1240658 Test Loss: 0.1340669\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1032892\n",
      "\tspeed: 0.0414s/iter; left time: 741.2086s\n",
      "\titers: 200, epoch: 21 | loss: 0.1053182\n",
      "\tspeed: 0.0173s/iter; left time: 308.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.1060186 Vali Loss: 0.1244103 Test Loss: 0.1343777\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04032425582408905, rmse:0.20080900192260742, mae:0.13387621939182281, rse:0.7112816572189331\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:01.35s\n",
      "Intermediate time for DE: 00h:20m:42.10s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1348012\n",
      "\tspeed: 0.0432s/iter; left time: 971.5674s\n",
      "\titers: 200, epoch: 1 | loss: 0.1199800\n",
      "\tspeed: 0.0147s/iter; left time: 330.1381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.1358073 Vali Loss: 0.1256861 Test Loss: 0.1465730\n",
      "Validation loss decreased (inf --> 0.125686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0842726\n",
      "\tspeed: 0.0326s/iter; left time: 725.8451s\n",
      "\titers: 200, epoch: 2 | loss: 0.0801193\n",
      "\tspeed: 0.0165s/iter; left time: 366.0726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0878881 Vali Loss: 0.0922427 Test Loss: 0.1037492\n",
      "Validation loss decreased (0.125686 --> 0.092243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0849407\n",
      "\tspeed: 0.0333s/iter; left time: 735.1307s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829507\n",
      "\tspeed: 0.0208s/iter; left time: 455.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0802817 Vali Loss: 0.0916280 Test Loss: 0.1027605\n",
      "Validation loss decreased (0.092243 --> 0.091628).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0824983\n",
      "\tspeed: 0.0341s/iter; left time: 744.3155s\n",
      "\titers: 200, epoch: 4 | loss: 0.0778295\n",
      "\tspeed: 0.0148s/iter; left time: 322.3088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0787315 Vali Loss: 0.0912857 Test Loss: 0.1020525\n",
      "Validation loss decreased (0.091628 --> 0.091286).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0771139\n",
      "\tspeed: 0.0323s/iter; left time: 696.5428s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828588\n",
      "\tspeed: 0.0150s/iter; left time: 323.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0778978 Vali Loss: 0.0906263 Test Loss: 0.1016233\n",
      "Validation loss decreased (0.091286 --> 0.090626).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0730026\n",
      "\tspeed: 0.0334s/iter; left time: 714.6117s\n",
      "\titers: 200, epoch: 6 | loss: 0.0768275\n",
      "\tspeed: 0.0152s/iter; left time: 324.2262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0771877 Vali Loss: 0.0897547 Test Loss: 0.1013267\n",
      "Validation loss decreased (0.090626 --> 0.089755).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764931\n",
      "\tspeed: 0.0334s/iter; left time: 705.6211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729029\n",
      "\tspeed: 0.0151s/iter; left time: 317.9872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 226 | Train Loss: 0.0767380 Vali Loss: 0.0894999 Test Loss: 0.1012439\n",
      "Validation loss decreased (0.089755 --> 0.089500).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740525\n",
      "\tspeed: 0.0340s/iter; left time: 711.5861s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767735\n",
      "\tspeed: 0.0153s/iter; left time: 319.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0764164 Vali Loss: 0.0896466 Test Loss: 0.1009590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774673\n",
      "\tspeed: 0.0337s/iter; left time: 697.6230s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760660\n",
      "\tspeed: 0.0161s/iter; left time: 330.7182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 226 | Train Loss: 0.0760536 Vali Loss: 0.0890659 Test Loss: 0.1009193\n",
      "Validation loss decreased (0.089500 --> 0.089066).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0732044\n",
      "\tspeed: 0.0340s/iter; left time: 694.9415s\n",
      "\titers: 200, epoch: 10 | loss: 0.0767341\n",
      "\tspeed: 0.0172s/iter; left time: 349.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0757877 Vali Loss: 0.0891886 Test Loss: 0.1009441\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0825395\n",
      "\tspeed: 0.0343s/iter; left time: 694.4001s\n",
      "\titers: 200, epoch: 11 | loss: 0.0761485\n",
      "\tspeed: 0.0157s/iter; left time: 317.1140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0755504 Vali Loss: 0.0890318 Test Loss: 0.1007226\n",
      "Validation loss decreased (0.089066 --> 0.089032).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0742803\n",
      "\tspeed: 0.0315s/iter; left time: 629.9250s\n",
      "\titers: 200, epoch: 12 | loss: 0.0833599\n",
      "\tspeed: 0.0147s/iter; left time: 293.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 226 | Train Loss: 0.0753169 Vali Loss: 0.0888209 Test Loss: 0.1007950\n",
      "Validation loss decreased (0.089032 --> 0.088821).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688437\n",
      "\tspeed: 0.0332s/iter; left time: 656.0625s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757275\n",
      "\tspeed: 0.0163s/iter; left time: 321.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0752007 Vali Loss: 0.0886280 Test Loss: 0.1005576\n",
      "Validation loss decreased (0.088821 --> 0.088628).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754868\n",
      "\tspeed: 0.0337s/iter; left time: 658.6997s\n",
      "\titers: 200, epoch: 14 | loss: 0.0743996\n",
      "\tspeed: 0.0151s/iter; left time: 293.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0750082 Vali Loss: 0.0888044 Test Loss: 0.1005008\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0776850\n",
      "\tspeed: 0.0347s/iter; left time: 670.9982s\n",
      "\titers: 200, epoch: 15 | loss: 0.0746924\n",
      "\tspeed: 0.0162s/iter; left time: 310.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0748108 Vali Loss: 0.0884927 Test Loss: 0.1003191\n",
      "Validation loss decreased (0.088628 --> 0.088493).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0747475\n",
      "\tspeed: 0.0347s/iter; left time: 663.5982s\n",
      "\titers: 200, epoch: 16 | loss: 0.0749063\n",
      "\tspeed: 0.0154s/iter; left time: 292.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0747405 Vali Loss: 0.0885689 Test Loss: 0.1004213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733430\n",
      "\tspeed: 0.0335s/iter; left time: 632.4483s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734850\n",
      "\tspeed: 0.0151s/iter; left time: 284.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 226 | Train Loss: 0.0746306 Vali Loss: 0.0886222 Test Loss: 0.1004618\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729925\n",
      "\tspeed: 0.0397s/iter; left time: 740.4525s\n",
      "\titers: 200, epoch: 18 | loss: 0.0748200\n",
      "\tspeed: 0.0215s/iter; left time: 398.5138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 226 | Train Loss: 0.0745408 Vali Loss: 0.0885219 Test Loss: 0.1001322\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0740487\n",
      "\tspeed: 0.0393s/iter; left time: 724.6756s\n",
      "\titers: 200, epoch: 19 | loss: 0.0761470\n",
      "\tspeed: 0.0199s/iter; left time: 364.9858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 226 | Train Loss: 0.0743890 Vali Loss: 0.0884069 Test Loss: 0.1004253\n",
      "Validation loss decreased (0.088493 --> 0.088407).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0804507\n",
      "\tspeed: 0.0347s/iter; left time: 632.2010s\n",
      "\titers: 200, epoch: 20 | loss: 0.0757066\n",
      "\tspeed: 0.0176s/iter; left time: 318.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0743674 Vali Loss: 0.0885054 Test Loss: 0.1000969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0756700\n",
      "\tspeed: 0.0364s/iter; left time: 654.9323s\n",
      "\titers: 200, epoch: 21 | loss: 0.0785028\n",
      "\tspeed: 0.0168s/iter; left time: 301.1972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0743069 Vali Loss: 0.0886169 Test Loss: 0.1004365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0687134\n",
      "\tspeed: 0.0375s/iter; left time: 665.8023s\n",
      "\titers: 200, epoch: 22 | loss: 0.0773262\n",
      "\tspeed: 0.0215s/iter; left time: 378.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 226 | Train Loss: 0.0742749 Vali Loss: 0.0883453 Test Loss: 0.1002563\n",
      "Validation loss decreased (0.088407 --> 0.088345).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0707392\n",
      "\tspeed: 0.0365s/iter; left time: 639.1904s\n",
      "\titers: 200, epoch: 23 | loss: 0.0712351\n",
      "\tspeed: 0.0173s/iter; left time: 301.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 226 | Train Loss: 0.0741822 Vali Loss: 0.0882935 Test Loss: 0.1002856\n",
      "Validation loss decreased (0.088345 --> 0.088293).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0738477\n",
      "\tspeed: 0.0387s/iter; left time: 668.9220s\n",
      "\titers: 200, epoch: 24 | loss: 0.0728533\n",
      "\tspeed: 0.0195s/iter; left time: 335.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0740945 Vali Loss: 0.0883293 Test Loss: 0.1002986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0715703\n",
      "\tspeed: 0.0371s/iter; left time: 633.0545s\n",
      "\titers: 200, epoch: 25 | loss: 0.0675489\n",
      "\tspeed: 0.0195s/iter; left time: 331.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0740816 Vali Loss: 0.0881852 Test Loss: 0.1001899\n",
      "Validation loss decreased (0.088293 --> 0.088185).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0774840\n",
      "\tspeed: 0.0330s/iter; left time: 555.7904s\n",
      "\titers: 200, epoch: 26 | loss: 0.0691603\n",
      "\tspeed: 0.0156s/iter; left time: 260.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0740570 Vali Loss: 0.0882801 Test Loss: 0.1002105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0784263\n",
      "\tspeed: 0.0337s/iter; left time: 560.2220s\n",
      "\titers: 200, epoch: 27 | loss: 0.0770142\n",
      "\tspeed: 0.0158s/iter; left time: 261.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0740176 Vali Loss: 0.0882419 Test Loss: 0.1001402\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0708968\n",
      "\tspeed: 0.0385s/iter; left time: 630.6580s\n",
      "\titers: 200, epoch: 28 | loss: 0.0749423\n",
      "\tspeed: 0.0202s/iter; left time: 329.0441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0739662 Vali Loss: 0.0882251 Test Loss: 0.1001193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0744236\n",
      "\tspeed: 0.0379s/iter; left time: 613.4823s\n",
      "\titers: 200, epoch: 29 | loss: 0.0747024\n",
      "\tspeed: 0.0193s/iter; left time: 309.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0739222 Vali Loss: 0.0881882 Test Loss: 0.1000275\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0714746\n",
      "\tspeed: 0.0341s/iter; left time: 544.5706s\n",
      "\titers: 200, epoch: 30 | loss: 0.0766074\n",
      "\tspeed: 0.0169s/iter; left time: 268.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0739116 Vali Loss: 0.0882050 Test Loss: 0.1001214\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0727411\n",
      "\tspeed: 0.0325s/iter; left time: 510.4227s\n",
      "\titers: 200, epoch: 31 | loss: 0.0782608\n",
      "\tspeed: 0.0148s/iter; left time: 231.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0738956 Vali Loss: 0.0881337 Test Loss: 0.1001574\n",
      "Validation loss decreased (0.088185 --> 0.088134).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0693213\n",
      "\tspeed: 0.0345s/iter; left time: 535.1526s\n",
      "\titers: 200, epoch: 32 | loss: 0.0733726\n",
      "\tspeed: 0.0147s/iter; left time: 227.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0739038 Vali Loss: 0.0881182 Test Loss: 0.1001412\n",
      "Validation loss decreased (0.088134 --> 0.088118).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0727043\n",
      "\tspeed: 0.0332s/iter; left time: 507.4772s\n",
      "\titers: 200, epoch: 33 | loss: 0.0756064\n",
      "\tspeed: 0.0149s/iter; left time: 226.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0738486 Vali Loss: 0.0881378 Test Loss: 0.1001345\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697464\n",
      "\tspeed: 0.0327s/iter; left time: 491.7849s\n",
      "\titers: 200, epoch: 34 | loss: 0.0767846\n",
      "\tspeed: 0.0152s/iter; left time: 227.8124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0738271 Vali Loss: 0.0880433 Test Loss: 0.1000919\n",
      "Validation loss decreased (0.088118 --> 0.088043).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0740372\n",
      "\tspeed: 0.0324s/iter; left time: 480.5610s\n",
      "\titers: 200, epoch: 35 | loss: 0.0748931\n",
      "\tspeed: 0.0150s/iter; left time: 221.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0737723 Vali Loss: 0.0881123 Test Loss: 0.1001010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0736170\n",
      "\tspeed: 0.0352s/iter; left time: 514.2756s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743167\n",
      "\tspeed: 0.0152s/iter; left time: 220.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0738238 Vali Loss: 0.0880142 Test Loss: 0.1001303\n",
      "Validation loss decreased (0.088043 --> 0.088014).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0735850\n",
      "\tspeed: 0.0364s/iter; left time: 522.8827s\n",
      "\titers: 200, epoch: 37 | loss: 0.0743387\n",
      "\tspeed: 0.0150s/iter; left time: 214.1146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 226 | Train Loss: 0.0738114 Vali Loss: 0.0880951 Test Loss: 0.1000949\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0743272\n",
      "\tspeed: 0.0326s/iter; left time: 460.5040s\n",
      "\titers: 200, epoch: 38 | loss: 0.0732567\n",
      "\tspeed: 0.0148s/iter; left time: 207.7039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0737474 Vali Loss: 0.0880771 Test Loss: 0.1000663\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0693054\n",
      "\tspeed: 0.0360s/iter; left time: 500.4227s\n",
      "\titers: 200, epoch: 39 | loss: 0.0733643\n",
      "\tspeed: 0.0176s/iter; left time: 243.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0738039 Vali Loss: 0.0882132 Test Loss: 0.1000884\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0703399\n",
      "\tspeed: 0.0381s/iter; left time: 521.7610s\n",
      "\titers: 200, epoch: 40 | loss: 0.0768747\n",
      "\tspeed: 0.0187s/iter; left time: 254.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0737794 Vali Loss: 0.0880865 Test Loss: 0.1000977\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0724354\n",
      "\tspeed: 0.0356s/iter; left time: 479.7915s\n",
      "\titers: 200, epoch: 41 | loss: 0.0733097\n",
      "\tspeed: 0.0160s/iter; left time: 213.7762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0737165 Vali Loss: 0.0880635 Test Loss: 0.1001283\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0742350\n",
      "\tspeed: 0.0364s/iter; left time: 481.8759s\n",
      "\titers: 200, epoch: 42 | loss: 0.0694430\n",
      "\tspeed: 0.0147s/iter; left time: 192.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0737438 Vali Loss: 0.0880835 Test Loss: 0.1000885\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779440\n",
      "\tspeed: 0.0332s/iter; left time: 431.7426s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749396\n",
      "\tspeed: 0.0147s/iter; left time: 189.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0737518 Vali Loss: 0.0880366 Test Loss: 0.1000987\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0714604\n",
      "\tspeed: 0.0332s/iter; left time: 424.0469s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757622\n",
      "\tspeed: 0.0148s/iter; left time: 188.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 226 | Train Loss: 0.0737035 Vali Loss: 0.0881269 Test Loss: 0.1000961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0767419\n",
      "\tspeed: 0.0358s/iter; left time: 449.1202s\n",
      "\titers: 200, epoch: 45 | loss: 0.0718795\n",
      "\tspeed: 0.0192s/iter; left time: 239.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0737914 Vali Loss: 0.0881576 Test Loss: 0.1000799\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0765565\n",
      "\tspeed: 0.0342s/iter; left time: 422.1977s\n",
      "\titers: 200, epoch: 46 | loss: 0.0712216\n",
      "\tspeed: 0.0148s/iter; left time: 181.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 226 | Train Loss: 0.0736830 Vali Loss: 0.0880687 Test Loss: 0.1001025\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025458605960011482, rmse:0.1595575362443924, mae:0.1001303642988205, rse:0.5504282712936401\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1299379\n",
      "\tspeed: 0.0211s/iter; left time: 475.0637s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275410\n",
      "\tspeed: 0.0149s/iter; left time: 334.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.1308100 Vali Loss: 0.1222478 Test Loss: 0.1417705\n",
      "Validation loss decreased (inf --> 0.122248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0886318\n",
      "\tspeed: 0.0346s/iter; left time: 769.9040s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795489\n",
      "\tspeed: 0.0147s/iter; left time: 326.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0874953 Vali Loss: 0.0923675 Test Loss: 0.1036771\n",
      "Validation loss decreased (0.122248 --> 0.092367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0793882\n",
      "\tspeed: 0.0359s/iter; left time: 791.0130s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739622\n",
      "\tspeed: 0.0155s/iter; left time: 341.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0803336 Vali Loss: 0.0912035 Test Loss: 0.1025618\n",
      "Validation loss decreased (0.092367 --> 0.091204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770089\n",
      "\tspeed: 0.0349s/iter; left time: 762.1679s\n",
      "\titers: 200, epoch: 4 | loss: 0.0781828\n",
      "\tspeed: 0.0168s/iter; left time: 365.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0788796 Vali Loss: 0.0909087 Test Loss: 0.1021345\n",
      "Validation loss decreased (0.091204 --> 0.090909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0836506\n",
      "\tspeed: 0.0358s/iter; left time: 772.5072s\n",
      "\titers: 200, epoch: 5 | loss: 0.0713013\n",
      "\tspeed: 0.0164s/iter; left time: 351.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0779398 Vali Loss: 0.0901915 Test Loss: 0.1018874\n",
      "Validation loss decreased (0.090909 --> 0.090192).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814649\n",
      "\tspeed: 0.0365s/iter; left time: 779.4728s\n",
      "\titers: 200, epoch: 6 | loss: 0.0717318\n",
      "\tspeed: 0.0152s/iter; left time: 323.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0774009 Vali Loss: 0.0898792 Test Loss: 0.1014808\n",
      "Validation loss decreased (0.090192 --> 0.089879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731443\n",
      "\tspeed: 0.0381s/iter; left time: 806.6344s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849989\n",
      "\tspeed: 0.0211s/iter; left time: 445.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0768103 Vali Loss: 0.0896169 Test Loss: 0.1012145\n",
      "Validation loss decreased (0.089879 --> 0.089617).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767947\n",
      "\tspeed: 0.0367s/iter; left time: 766.7318s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805392\n",
      "\tspeed: 0.0162s/iter; left time: 337.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 226 | Train Loss: 0.0764402 Vali Loss: 0.0894719 Test Loss: 0.1012099\n",
      "Validation loss decreased (0.089617 --> 0.089472).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0757468\n",
      "\tspeed: 0.0379s/iter; left time: 783.9103s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773815\n",
      "\tspeed: 0.0207s/iter; left time: 425.5844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0761080 Vali Loss: 0.0896265 Test Loss: 0.1009124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0765713\n",
      "\tspeed: 0.0390s/iter; left time: 798.4415s\n",
      "\titers: 200, epoch: 10 | loss: 0.0686516\n",
      "\tspeed: 0.0203s/iter; left time: 414.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0758771 Vali Loss: 0.0890902 Test Loss: 0.1008138\n",
      "Validation loss decreased (0.089472 --> 0.089090).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0744935\n",
      "\tspeed: 0.0357s/iter; left time: 722.1835s\n",
      "\titers: 200, epoch: 11 | loss: 0.0698684\n",
      "\tspeed: 0.0150s/iter; left time: 302.8401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0755856 Vali Loss: 0.0890289 Test Loss: 0.1007839\n",
      "Validation loss decreased (0.089090 --> 0.089029).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0681625\n",
      "\tspeed: 0.0353s/iter; left time: 705.6890s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767795\n",
      "\tspeed: 0.0165s/iter; left time: 328.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0753697 Vali Loss: 0.0887901 Test Loss: 0.1009245\n",
      "Validation loss decreased (0.089029 --> 0.088790).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727203\n",
      "\tspeed: 0.0346s/iter; left time: 685.5272s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751047\n",
      "\tspeed: 0.0151s/iter; left time: 298.0573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0752134 Vali Loss: 0.0887878 Test Loss: 0.1005532\n",
      "Validation loss decreased (0.088790 --> 0.088788).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0849499\n",
      "\tspeed: 0.0327s/iter; left time: 640.0149s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722159\n",
      "\tspeed: 0.0147s/iter; left time: 286.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0749800 Vali Loss: 0.0888784 Test Loss: 0.1003572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731766\n",
      "\tspeed: 0.0316s/iter; left time: 611.8467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0795646\n",
      "\tspeed: 0.0148s/iter; left time: 285.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 226 | Train Loss: 0.0748853 Vali Loss: 0.0886995 Test Loss: 0.1003053\n",
      "Validation loss decreased (0.088788 --> 0.088700).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0797883\n",
      "\tspeed: 0.0378s/iter; left time: 722.9744s\n",
      "\titers: 200, epoch: 16 | loss: 0.0785311\n",
      "\tspeed: 0.0166s/iter; left time: 315.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0747140 Vali Loss: 0.0885486 Test Loss: 0.1003760\n",
      "Validation loss decreased (0.088700 --> 0.088549).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766100\n",
      "\tspeed: 0.0390s/iter; left time: 735.8959s\n",
      "\titers: 200, epoch: 17 | loss: 0.0713198\n",
      "\tspeed: 0.0155s/iter; left time: 290.4874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.0745887 Vali Loss: 0.0883946 Test Loss: 0.1003597\n",
      "Validation loss decreased (0.088549 --> 0.088395).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0718078\n",
      "\tspeed: 0.0355s/iter; left time: 661.6344s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747818\n",
      "\tspeed: 0.0149s/iter; left time: 277.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 226 | Train Loss: 0.0745034 Vali Loss: 0.0884246 Test Loss: 0.1004869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0739261\n",
      "\tspeed: 0.0328s/iter; left time: 604.6951s\n",
      "\titers: 200, epoch: 19 | loss: 0.0768519\n",
      "\tspeed: 0.0148s/iter; left time: 270.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 226 | Train Loss: 0.0743887 Vali Loss: 0.0882176 Test Loss: 0.1004880\n",
      "Validation loss decreased (0.088395 --> 0.088218).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0724575\n",
      "\tspeed: 0.0351s/iter; left time: 639.6548s\n",
      "\titers: 200, epoch: 20 | loss: 0.0703330\n",
      "\tspeed: 0.0179s/iter; left time: 323.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0742888 Vali Loss: 0.0882550 Test Loss: 0.1003058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0749832\n",
      "\tspeed: 0.0358s/iter; left time: 644.2972s\n",
      "\titers: 200, epoch: 21 | loss: 0.0722545\n",
      "\tspeed: 0.0168s/iter; left time: 300.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 226 | Train Loss: 0.0742666 Vali Loss: 0.0883987 Test Loss: 0.1002589\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0743824\n",
      "\tspeed: 0.0380s/iter; left time: 675.0969s\n",
      "\titers: 200, epoch: 22 | loss: 0.0727077\n",
      "\tspeed: 0.0164s/iter; left time: 288.8293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0741849 Vali Loss: 0.0884717 Test Loss: 0.1003307\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0725270\n",
      "\tspeed: 0.0364s/iter; left time: 638.3954s\n",
      "\titers: 200, epoch: 23 | loss: 0.0761230\n",
      "\tspeed: 0.0156s/iter; left time: 271.9287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0741284 Vali Loss: 0.0883142 Test Loss: 0.1002705\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0769574\n",
      "\tspeed: 0.0338s/iter; left time: 585.1179s\n",
      "\titers: 200, epoch: 24 | loss: 0.0711329\n",
      "\tspeed: 0.0149s/iter; left time: 255.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 226 | Train Loss: 0.0740526 Vali Loss: 0.0882026 Test Loss: 0.1002394\n",
      "Validation loss decreased (0.088218 --> 0.088203).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0785076\n",
      "\tspeed: 0.0363s/iter; left time: 619.5563s\n",
      "\titers: 200, epoch: 25 | loss: 0.0712431\n",
      "\tspeed: 0.0181s/iter; left time: 307.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0740483 Vali Loss: 0.0882465 Test Loss: 0.1003153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0716059\n",
      "\tspeed: 0.0335s/iter; left time: 564.3508s\n",
      "\titers: 200, epoch: 26 | loss: 0.0759152\n",
      "\tspeed: 0.0150s/iter; left time: 251.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0739681 Vali Loss: 0.0882726 Test Loss: 0.1000976\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0750724\n",
      "\tspeed: 0.0315s/iter; left time: 524.4293s\n",
      "\titers: 200, epoch: 27 | loss: 0.0754104\n",
      "\tspeed: 0.0148s/iter; left time: 243.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 226 | Train Loss: 0.0739455 Vali Loss: 0.0881110 Test Loss: 0.1002562\n",
      "Validation loss decreased (0.088203 --> 0.088111).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0758224\n",
      "\tspeed: 0.0345s/iter; left time: 565.3009s\n",
      "\titers: 200, epoch: 28 | loss: 0.0766049\n",
      "\tspeed: 0.0178s/iter; left time: 289.7150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0739173 Vali Loss: 0.0882354 Test Loss: 0.1001683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0708620\n",
      "\tspeed: 0.0402s/iter; left time: 649.9362s\n",
      "\titers: 200, epoch: 29 | loss: 0.0762078\n",
      "\tspeed: 0.0217s/iter; left time: 349.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 226 | Train Loss: 0.0739167 Vali Loss: 0.0882121 Test Loss: 0.1001651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0749271\n",
      "\tspeed: 0.0420s/iter; left time: 670.2582s\n",
      "\titers: 200, epoch: 30 | loss: 0.0734478\n",
      "\tspeed: 0.0223s/iter; left time: 353.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 226 | Train Loss: 0.0738925 Vali Loss: 0.0882489 Test Loss: 0.1001061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0736174\n",
      "\tspeed: 0.0342s/iter; left time: 537.5242s\n",
      "\titers: 200, epoch: 31 | loss: 0.0758822\n",
      "\tspeed: 0.0151s/iter; left time: 235.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0738126 Vali Loss: 0.0881726 Test Loss: 0.1001027\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0762339\n",
      "\tspeed: 0.0348s/iter; left time: 539.2509s\n",
      "\titers: 200, epoch: 32 | loss: 0.0719958\n",
      "\tspeed: 0.0150s/iter; left time: 231.2703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 226 | Train Loss: 0.0738045 Vali Loss: 0.0881914 Test Loss: 0.1000991\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0720251\n",
      "\tspeed: 0.0324s/iter; left time: 494.9373s\n",
      "\titers: 200, epoch: 33 | loss: 0.0768513\n",
      "\tspeed: 0.0149s/iter; left time: 225.9949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0738133 Vali Loss: 0.0880187 Test Loss: 0.1001144\n",
      "Validation loss decreased (0.088111 --> 0.088019).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0787433\n",
      "\tspeed: 0.0383s/iter; left time: 576.7804s\n",
      "\titers: 200, epoch: 34 | loss: 0.0745010\n",
      "\tspeed: 0.0196s/iter; left time: 293.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0737879 Vali Loss: 0.0880583 Test Loss: 0.1001430\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0743883\n",
      "\tspeed: 0.0329s/iter; left time: 488.0103s\n",
      "\titers: 200, epoch: 35 | loss: 0.0735667\n",
      "\tspeed: 0.0164s/iter; left time: 241.0911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0737276 Vali Loss: 0.0881054 Test Loss: 0.1001485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0694856\n",
      "\tspeed: 0.0350s/iter; left time: 509.9782s\n",
      "\titers: 200, epoch: 36 | loss: 0.0743685\n",
      "\tspeed: 0.0155s/iter; left time: 224.3093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0737488 Vali Loss: 0.0881350 Test Loss: 0.1001791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0712377\n",
      "\tspeed: 0.0356s/iter; left time: 510.7199s\n",
      "\titers: 200, epoch: 37 | loss: 0.0748500\n",
      "\tspeed: 0.0184s/iter; left time: 262.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0737391 Vali Loss: 0.0880918 Test Loss: 0.1001669\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0725543\n",
      "\tspeed: 0.0372s/iter; left time: 525.7316s\n",
      "\titers: 200, epoch: 38 | loss: 0.0687990\n",
      "\tspeed: 0.0157s/iter; left time: 220.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0737394 Vali Loss: 0.0881696 Test Loss: 0.1001650\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0725478\n",
      "\tspeed: 0.0346s/iter; left time: 480.8865s\n",
      "\titers: 200, epoch: 39 | loss: 0.0692375\n",
      "\tspeed: 0.0193s/iter; left time: 266.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0736793 Vali Loss: 0.0880255 Test Loss: 0.1001555\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0699850\n",
      "\tspeed: 0.0391s/iter; left time: 535.3959s\n",
      "\titers: 200, epoch: 40 | loss: 0.0763473\n",
      "\tspeed: 0.0185s/iter; left time: 251.8716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0736832 Vali Loss: 0.0882237 Test Loss: 0.1001549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0755943\n",
      "\tspeed: 0.0406s/iter; left time: 546.5201s\n",
      "\titers: 200, epoch: 41 | loss: 0.0742840\n",
      "\tspeed: 0.0224s/iter; left time: 299.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 226 | Train Loss: 0.0736210 Vali Loss: 0.0880303 Test Loss: 0.1001531\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0724656\n",
      "\tspeed: 0.0352s/iter; left time: 466.5144s\n",
      "\titers: 200, epoch: 42 | loss: 0.0697383\n",
      "\tspeed: 0.0166s/iter; left time: 218.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 226 | Train Loss: 0.0736599 Vali Loss: 0.0880839 Test Loss: 0.1001138\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0706227\n",
      "\tspeed: 0.0346s/iter; left time: 450.6407s\n",
      "\titers: 200, epoch: 43 | loss: 0.0782978\n",
      "\tspeed: 0.0196s/iter; left time: 252.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0736657 Vali Loss: 0.0880406 Test Loss: 0.1001322\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025257881730794907, rmse:0.1589272916316986, mae:0.10011441260576248, rse:0.5482540726661682\n",
      "Intermediate time for GB and pred_len 24: 00h:07m:55.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1432486\n",
      "\tspeed: 0.0433s/iter; left time: 969.2891s\n",
      "\titers: 200, epoch: 1 | loss: 0.1336714\n",
      "\tspeed: 0.0149s/iter; left time: 332.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.1440825 Vali Loss: 0.1380730 Test Loss: 0.1636122\n",
      "Validation loss decreased (inf --> 0.138073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1100838\n",
      "\tspeed: 0.0342s/iter; left time: 757.4684s\n",
      "\titers: 200, epoch: 2 | loss: 0.1123376\n",
      "\tspeed: 0.0150s/iter; left time: 330.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1121373 Vali Loss: 0.1199572 Test Loss: 0.1431091\n",
      "Validation loss decreased (0.138073 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1075862\n",
      "\tspeed: 0.0347s/iter; left time: 760.6842s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033198\n",
      "\tspeed: 0.0152s/iter; left time: 331.1744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.1063111 Vali Loss: 0.1183126 Test Loss: 0.1420789\n",
      "Validation loss decreased (0.119957 --> 0.118313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1024592\n",
      "\tspeed: 0.0350s/iter; left time: 760.0231s\n",
      "\titers: 200, epoch: 4 | loss: 0.1038170\n",
      "\tspeed: 0.0190s/iter; left time: 410.6695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.1047231 Vali Loss: 0.1184994 Test Loss: 0.1432469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1062332\n",
      "\tspeed: 0.0384s/iter; left time: 825.9961s\n",
      "\titers: 200, epoch: 5 | loss: 0.1022250\n",
      "\tspeed: 0.0228s/iter; left time: 488.7446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.1038286 Vali Loss: 0.1181398 Test Loss: 0.1429648\n",
      "Validation loss decreased (0.118313 --> 0.118140).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1065187\n",
      "\tspeed: 0.0390s/iter; left time: 829.3336s\n",
      "\titers: 200, epoch: 6 | loss: 0.1032488\n",
      "\tspeed: 0.0190s/iter; left time: 402.3874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.1031733 Vali Loss: 0.1179559 Test Loss: 0.1427092\n",
      "Validation loss decreased (0.118140 --> 0.117956).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0992134\n",
      "\tspeed: 0.0424s/iter; left time: 892.8995s\n",
      "\titers: 200, epoch: 7 | loss: 0.1032226\n",
      "\tspeed: 0.0194s/iter; left time: 406.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.1026534 Vali Loss: 0.1179666 Test Loss: 0.1436215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001497\n",
      "\tspeed: 0.0335s/iter; left time: 697.4606s\n",
      "\titers: 200, epoch: 8 | loss: 0.1063705\n",
      "\tspeed: 0.0153s/iter; left time: 316.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.64s\n",
      "Steps: 225 | Train Loss: 0.1021949 Vali Loss: 0.1178256 Test Loss: 0.1436705\n",
      "Validation loss decreased (0.117956 --> 0.117826).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1031673\n",
      "\tspeed: 0.0388s/iter; left time: 798.3675s\n",
      "\titers: 200, epoch: 9 | loss: 0.1014487\n",
      "\tspeed: 0.0200s/iter; left time: 409.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.1017360 Vali Loss: 0.1180316 Test Loss: 0.1442261\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1037467\n",
      "\tspeed: 0.0386s/iter; left time: 786.9086s\n",
      "\titers: 200, epoch: 10 | loss: 0.1027923\n",
      "\tspeed: 0.0177s/iter; left time: 358.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.1014511 Vali Loss: 0.1187993 Test Loss: 0.1454186\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0971863\n",
      "\tspeed: 0.0350s/iter; left time: 706.0033s\n",
      "\titers: 200, epoch: 11 | loss: 0.1066962\n",
      "\tspeed: 0.0170s/iter; left time: 341.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1011792 Vali Loss: 0.1179904 Test Loss: 0.1447006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0974395\n",
      "\tspeed: 0.0364s/iter; left time: 724.5687s\n",
      "\titers: 200, epoch: 12 | loss: 0.1026871\n",
      "\tspeed: 0.0169s/iter; left time: 335.6754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1009035 Vali Loss: 0.1181274 Test Loss: 0.1444180\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988215\n",
      "\tspeed: 0.0365s/iter; left time: 720.0462s\n",
      "\titers: 200, epoch: 13 | loss: 0.0990030\n",
      "\tspeed: 0.0156s/iter; left time: 304.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.1006301 Vali Loss: 0.1185747 Test Loss: 0.1452403\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1004764\n",
      "\tspeed: 0.0347s/iter; left time: 676.3641s\n",
      "\titers: 200, epoch: 14 | loss: 0.1026148\n",
      "\tspeed: 0.0189s/iter; left time: 365.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1004318 Vali Loss: 0.1184490 Test Loss: 0.1451024\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0977727\n",
      "\tspeed: 0.0344s/iter; left time: 661.6612s\n",
      "\titers: 200, epoch: 15 | loss: 0.0959741\n",
      "\tspeed: 0.0161s/iter; left time: 308.3490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1002692 Vali Loss: 0.1184843 Test Loss: 0.1451076\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0966277\n",
      "\tspeed: 0.0356s/iter; left time: 677.4609s\n",
      "\titers: 200, epoch: 16 | loss: 0.1025084\n",
      "\tspeed: 0.0174s/iter; left time: 328.6050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1000582 Vali Loss: 0.1184273 Test Loss: 0.1450801\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0983456\n",
      "\tspeed: 0.0350s/iter; left time: 657.3731s\n",
      "\titers: 200, epoch: 17 | loss: 0.0992725\n",
      "\tspeed: 0.0163s/iter; left time: 305.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0997954 Vali Loss: 0.1189902 Test Loss: 0.1460390\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034021\n",
      "\tspeed: 0.0345s/iter; left time: 641.1145s\n",
      "\titers: 200, epoch: 18 | loss: 0.0961946\n",
      "\tspeed: 0.0170s/iter; left time: 314.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0996697 Vali Loss: 0.1185702 Test Loss: 0.1454241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04502221569418907, rmse:0.2121843844652176, mae:0.1436704397201538, rse:0.7337632179260254\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1483310\n",
      "\tspeed: 0.0171s/iter; left time: 383.6728s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308554\n",
      "\tspeed: 0.0152s/iter; left time: 339.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.1445622 Vali Loss: 0.1381677 Test Loss: 0.1637920\n",
      "Validation loss decreased (inf --> 0.138168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1130186\n",
      "\tspeed: 0.0359s/iter; left time: 795.3798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083098\n",
      "\tspeed: 0.0169s/iter; left time: 372.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1122220 Vali Loss: 0.1197145 Test Loss: 0.1430694\n",
      "Validation loss decreased (0.138168 --> 0.119714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1004686\n",
      "\tspeed: 0.0382s/iter; left time: 839.2659s\n",
      "\titers: 200, epoch: 3 | loss: 0.1058460\n",
      "\tspeed: 0.0174s/iter; left time: 381.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1065320 Vali Loss: 0.1191321 Test Loss: 0.1431164\n",
      "Validation loss decreased (0.119714 --> 0.119132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1067420\n",
      "\tspeed: 0.0366s/iter; left time: 796.1413s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052855\n",
      "\tspeed: 0.0173s/iter; left time: 373.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.1051883 Vali Loss: 0.1185206 Test Loss: 0.1429021\n",
      "Validation loss decreased (0.119132 --> 0.118521).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1020963\n",
      "\tspeed: 0.0382s/iter; left time: 821.7015s\n",
      "\titers: 200, epoch: 5 | loss: 0.1061885\n",
      "\tspeed: 0.0175s/iter; left time: 373.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1042266 Vali Loss: 0.1179224 Test Loss: 0.1425153\n",
      "Validation loss decreased (0.118521 --> 0.117922).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1019426\n",
      "\tspeed: 0.0389s/iter; left time: 826.5984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987578\n",
      "\tspeed: 0.0173s/iter; left time: 365.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.1034838 Vali Loss: 0.1178515 Test Loss: 0.1430858\n",
      "Validation loss decreased (0.117922 --> 0.117851).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1048590\n",
      "\tspeed: 0.0416s/iter; left time: 876.0780s\n",
      "\titers: 200, epoch: 7 | loss: 0.1034662\n",
      "\tspeed: 0.0181s/iter; left time: 379.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.1028714 Vali Loss: 0.1178046 Test Loss: 0.1434703\n",
      "Validation loss decreased (0.117851 --> 0.117805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960290\n",
      "\tspeed: 0.0379s/iter; left time: 790.2719s\n",
      "\titers: 200, epoch: 8 | loss: 0.0993760\n",
      "\tspeed: 0.0191s/iter; left time: 395.6642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.1023618 Vali Loss: 0.1179817 Test Loss: 0.1439923\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982805\n",
      "\tspeed: 0.0392s/iter; left time: 806.9582s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009188\n",
      "\tspeed: 0.0190s/iter; left time: 390.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.1019138 Vali Loss: 0.1181148 Test Loss: 0.1445342\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027546\n",
      "\tspeed: 0.0385s/iter; left time: 785.1390s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985924\n",
      "\tspeed: 0.0171s/iter; left time: 345.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1015597 Vali Loss: 0.1182591 Test Loss: 0.1449339\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0938201\n",
      "\tspeed: 0.0379s/iter; left time: 763.8042s\n",
      "\titers: 200, epoch: 11 | loss: 0.1016373\n",
      "\tspeed: 0.0160s/iter; left time: 321.7632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1012948 Vali Loss: 0.1179792 Test Loss: 0.1446447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1054280\n",
      "\tspeed: 0.0389s/iter; left time: 775.5564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0961260\n",
      "\tspeed: 0.0179s/iter; left time: 355.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.1010108 Vali Loss: 0.1181633 Test Loss: 0.1451541\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1007230\n",
      "\tspeed: 0.0356s/iter; left time: 702.2664s\n",
      "\titers: 200, epoch: 13 | loss: 0.1053447\n",
      "\tspeed: 0.0166s/iter; left time: 325.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.1008488 Vali Loss: 0.1179375 Test Loss: 0.1453492\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0957747\n",
      "\tspeed: 0.0369s/iter; left time: 718.0869s\n",
      "\titers: 200, epoch: 14 | loss: 0.1026282\n",
      "\tspeed: 0.0170s/iter; left time: 329.2841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.1005955 Vali Loss: 0.1181584 Test Loss: 0.1455183\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1030927\n",
      "\tspeed: 0.0383s/iter; left time: 737.1703s\n",
      "\titers: 200, epoch: 15 | loss: 0.1035435\n",
      "\tspeed: 0.0158s/iter; left time: 303.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.1004362 Vali Loss: 0.1177396 Test Loss: 0.1446944\n",
      "Validation loss decreased (0.117805 --> 0.117740).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1024171\n",
      "\tspeed: 0.0353s/iter; left time: 671.1995s\n",
      "\titers: 200, epoch: 16 | loss: 0.1014723\n",
      "\tspeed: 0.0152s/iter; left time: 287.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.1002407 Vali Loss: 0.1181168 Test Loss: 0.1451479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0950730\n",
      "\tspeed: 0.0347s/iter; left time: 652.9884s\n",
      "\titers: 200, epoch: 17 | loss: 0.1007550\n",
      "\tspeed: 0.0180s/iter; left time: 337.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.1001653 Vali Loss: 0.1176875 Test Loss: 0.1446122\n",
      "Validation loss decreased (0.117740 --> 0.117687).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1016255\n",
      "\tspeed: 0.0367s/iter; left time: 682.6580s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003857\n",
      "\tspeed: 0.0153s/iter; left time: 281.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0999799 Vali Loss: 0.1176812 Test Loss: 0.1449458\n",
      "Validation loss decreased (0.117687 --> 0.117681).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0989775\n",
      "\tspeed: 0.0395s/iter; left time: 725.5833s\n",
      "\titers: 200, epoch: 19 | loss: 0.0949207\n",
      "\tspeed: 0.0160s/iter; left time: 292.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0998343 Vali Loss: 0.1181190 Test Loss: 0.1450148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1017841\n",
      "\tspeed: 0.0383s/iter; left time: 694.4167s\n",
      "\titers: 200, epoch: 20 | loss: 0.0993757\n",
      "\tspeed: 0.0170s/iter; left time: 306.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0997756 Vali Loss: 0.1178565 Test Loss: 0.1450385\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0974881\n",
      "\tspeed: 0.0428s/iter; left time: 765.9095s\n",
      "\titers: 200, epoch: 21 | loss: 0.1050698\n",
      "\tspeed: 0.0217s/iter; left time: 386.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0997030 Vali Loss: 0.1181531 Test Loss: 0.1456380\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0996484\n",
      "\tspeed: 0.0409s/iter; left time: 722.2175s\n",
      "\titers: 200, epoch: 22 | loss: 0.1009263\n",
      "\tspeed: 0.0186s/iter; left time: 326.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0995709 Vali Loss: 0.1181348 Test Loss: 0.1454638\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0936366\n",
      "\tspeed: 0.0403s/iter; left time: 703.4896s\n",
      "\titers: 200, epoch: 23 | loss: 0.1032682\n",
      "\tspeed: 0.0183s/iter; left time: 317.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0995458 Vali Loss: 0.1179884 Test Loss: 0.1451582\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0968743\n",
      "\tspeed: 0.0390s/iter; left time: 671.3012s\n",
      "\titers: 200, epoch: 24 | loss: 0.1019463\n",
      "\tspeed: 0.0163s/iter; left time: 279.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0994681 Vali Loss: 0.1181457 Test Loss: 0.1455523\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1061921\n",
      "\tspeed: 0.0398s/iter; left time: 677.3985s\n",
      "\titers: 200, epoch: 25 | loss: 0.0970668\n",
      "\tspeed: 0.0199s/iter; left time: 336.2067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0994505 Vali Loss: 0.1180443 Test Loss: 0.1453885\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1002892\n",
      "\tspeed: 0.0412s/iter; left time: 691.8628s\n",
      "\titers: 200, epoch: 26 | loss: 0.0993644\n",
      "\tspeed: 0.0192s/iter; left time: 320.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0993534 Vali Loss: 0.1181938 Test Loss: 0.1455262\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0944799\n",
      "\tspeed: 0.0407s/iter; left time: 673.0061s\n",
      "\titers: 200, epoch: 27 | loss: 0.0981926\n",
      "\tspeed: 0.0189s/iter; left time: 311.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0992863 Vali Loss: 0.1181367 Test Loss: 0.1452989\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0966076\n",
      "\tspeed: 0.0408s/iter; left time: 665.8369s\n",
      "\titers: 200, epoch: 28 | loss: 0.0948356\n",
      "\tspeed: 0.0220s/iter; left time: 356.5191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0992611 Vali Loss: 0.1181604 Test Loss: 0.1453564\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04601024091243744, rmse:0.21449998021125793, mae:0.1449458748102188, rse:0.7417708039283752\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:25.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1499535\n",
      "\tspeed: 0.0401s/iter; left time: 897.4073s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275760\n",
      "\tspeed: 0.0152s/iter; left time: 339.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1469418 Vali Loss: 0.1418786 Test Loss: 0.1676975\n",
      "Validation loss decreased (inf --> 0.141879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1141674\n",
      "\tspeed: 0.0351s/iter; left time: 778.8829s\n",
      "\titers: 200, epoch: 2 | loss: 0.1113455\n",
      "\tspeed: 0.0186s/iter; left time: 409.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.1173277 Vali Loss: 0.1255487 Test Loss: 0.1495915\n",
      "Validation loss decreased (0.141879 --> 0.125549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092727\n",
      "\tspeed: 0.0367s/iter; left time: 805.8922s\n",
      "\titers: 200, epoch: 3 | loss: 0.1134550\n",
      "\tspeed: 0.0179s/iter; left time: 390.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.1115658 Vali Loss: 0.1249689 Test Loss: 0.1503542\n",
      "Validation loss decreased (0.125549 --> 0.124969).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144803\n",
      "\tspeed: 0.0372s/iter; left time: 807.4042s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094217\n",
      "\tspeed: 0.0161s/iter; left time: 347.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.1099271 Vali Loss: 0.1243636 Test Loss: 0.1502110\n",
      "Validation loss decreased (0.124969 --> 0.124364).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1082388\n",
      "\tspeed: 0.0361s/iter; left time: 776.3311s\n",
      "\titers: 200, epoch: 5 | loss: 0.1077586\n",
      "\tspeed: 0.0164s/iter; left time: 351.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.1089903 Vali Loss: 0.1241797 Test Loss: 0.1502208\n",
      "Validation loss decreased (0.124364 --> 0.124180).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1081436\n",
      "\tspeed: 0.0350s/iter; left time: 744.8605s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119499\n",
      "\tspeed: 0.0157s/iter; left time: 332.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.1083248 Vali Loss: 0.1238742 Test Loss: 0.1504022\n",
      "Validation loss decreased (0.124180 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1111545\n",
      "\tspeed: 0.0391s/iter; left time: 822.6812s\n",
      "\titers: 200, epoch: 7 | loss: 0.1063496\n",
      "\tspeed: 0.0197s/iter; left time: 412.3867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.1078107 Vali Loss: 0.1247523 Test Loss: 0.1519305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016383\n",
      "\tspeed: 0.0358s/iter; left time: 746.1562s\n",
      "\titers: 200, epoch: 8 | loss: 0.1076421\n",
      "\tspeed: 0.0163s/iter; left time: 336.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.1074174 Vali Loss: 0.1238740 Test Loss: 0.1508317\n",
      "Validation loss decreased (0.123874 --> 0.123874).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1057409\n",
      "\tspeed: 0.0407s/iter; left time: 839.0853s\n",
      "\titers: 200, epoch: 9 | loss: 0.1076946\n",
      "\tspeed: 0.0168s/iter; left time: 343.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1070738 Vali Loss: 0.1239253 Test Loss: 0.1512166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1064644\n",
      "\tspeed: 0.0368s/iter; left time: 750.1468s\n",
      "\titers: 200, epoch: 10 | loss: 0.1061676\n",
      "\tspeed: 0.0233s/iter; left time: 472.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.1067472 Vali Loss: 0.1239237 Test Loss: 0.1517738\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1069961\n",
      "\tspeed: 0.0412s/iter; left time: 830.6942s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058313\n",
      "\tspeed: 0.0187s/iter; left time: 375.9255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1063631 Vali Loss: 0.1238796 Test Loss: 0.1516500\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1059460\n",
      "\tspeed: 0.0358s/iter; left time: 713.4968s\n",
      "\titers: 200, epoch: 12 | loss: 0.1064634\n",
      "\tspeed: 0.0157s/iter; left time: 311.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.1060945 Vali Loss: 0.1240394 Test Loss: 0.1517687\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1032645\n",
      "\tspeed: 0.0358s/iter; left time: 704.3413s\n",
      "\titers: 200, epoch: 13 | loss: 0.1023014\n",
      "\tspeed: 0.0198s/iter; left time: 387.3759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1058933 Vali Loss: 0.1241398 Test Loss: 0.1517029\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1068519\n",
      "\tspeed: 0.0363s/iter; left time: 706.8059s\n",
      "\titers: 200, epoch: 14 | loss: 0.1030616\n",
      "\tspeed: 0.0191s/iter; left time: 369.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.1056087 Vali Loss: 0.1243978 Test Loss: 0.1522958\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1037581\n",
      "\tspeed: 0.0354s/iter; left time: 680.9908s\n",
      "\titers: 200, epoch: 15 | loss: 0.1031120\n",
      "\tspeed: 0.0151s/iter; left time: 289.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.1054437 Vali Loss: 0.1244598 Test Loss: 0.1526321\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1081312\n",
      "\tspeed: 0.0348s/iter; left time: 661.3441s\n",
      "\titers: 200, epoch: 16 | loss: 0.1071312\n",
      "\tspeed: 0.0156s/iter; left time: 294.7698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 225 | Train Loss: 0.1052283 Vali Loss: 0.1243807 Test Loss: 0.1525210\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1078316\n",
      "\tspeed: 0.0349s/iter; left time: 656.4600s\n",
      "\titers: 200, epoch: 17 | loss: 0.1053726\n",
      "\tspeed: 0.0176s/iter; left time: 329.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.1050940 Vali Loss: 0.1245384 Test Loss: 0.1528213\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1060644\n",
      "\tspeed: 0.0423s/iter; left time: 786.3323s\n",
      "\titers: 200, epoch: 18 | loss: 0.1060730\n",
      "\tspeed: 0.0174s/iter; left time: 321.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.1049388 Vali Loss: 0.1245682 Test Loss: 0.1526806\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048577629029750824, rmse:0.22040332853794098, mae:0.1508316695690155, rse:0.7641699910163879\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1486480\n",
      "\tspeed: 0.0205s/iter; left time: 458.7998s\n",
      "\titers: 200, epoch: 1 | loss: 0.1346984\n",
      "\tspeed: 0.0177s/iter; left time: 394.6057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1462936 Vali Loss: 0.1413484 Test Loss: 0.1671238\n",
      "Validation loss decreased (inf --> 0.141348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1223506\n",
      "\tspeed: 0.0409s/iter; left time: 907.1932s\n",
      "\titers: 200, epoch: 2 | loss: 0.1111667\n",
      "\tspeed: 0.0190s/iter; left time: 419.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 225 | Train Loss: 0.1173274 Vali Loss: 0.1256820 Test Loss: 0.1498371\n",
      "Validation loss decreased (0.141348 --> 0.125682).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108388\n",
      "\tspeed: 0.0367s/iter; left time: 805.4347s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082366\n",
      "\tspeed: 0.0165s/iter; left time: 361.4048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.1116993 Vali Loss: 0.1249393 Test Loss: 0.1492249\n",
      "Validation loss decreased (0.125682 --> 0.124939).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090657\n",
      "\tspeed: 0.0378s/iter; left time: 820.9635s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095768\n",
      "\tspeed: 0.0192s/iter; left time: 415.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.1101767 Vali Loss: 0.1239666 Test Loss: 0.1496069\n",
      "Validation loss decreased (0.124939 --> 0.123967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1122283\n",
      "\tspeed: 0.0367s/iter; left time: 788.3670s\n",
      "\titers: 200, epoch: 5 | loss: 0.1103199\n",
      "\tspeed: 0.0160s/iter; left time: 343.1005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.1091507 Vali Loss: 0.1240546 Test Loss: 0.1494649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116899\n",
      "\tspeed: 0.0360s/iter; left time: 766.3005s\n",
      "\titers: 200, epoch: 6 | loss: 0.1087078\n",
      "\tspeed: 0.0194s/iter; left time: 410.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.1084126 Vali Loss: 0.1242108 Test Loss: 0.1503803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1052423\n",
      "\tspeed: 0.0364s/iter; left time: 766.0071s\n",
      "\titers: 200, epoch: 7 | loss: 0.1058420\n",
      "\tspeed: 0.0151s/iter; left time: 316.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.1078158 Vali Loss: 0.1241233 Test Loss: 0.1499704\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1088142\n",
      "\tspeed: 0.0420s/iter; left time: 874.5691s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080927\n",
      "\tspeed: 0.0239s/iter; left time: 494.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.1073037 Vali Loss: 0.1240906 Test Loss: 0.1502237\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1084523\n",
      "\tspeed: 0.0389s/iter; left time: 801.1094s\n",
      "\titers: 200, epoch: 9 | loss: 0.1062123\n",
      "\tspeed: 0.0177s/iter; left time: 363.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.1069074 Vali Loss: 0.1238233 Test Loss: 0.1508131\n",
      "Validation loss decreased (0.123967 --> 0.123823).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1033939\n",
      "\tspeed: 0.0372s/iter; left time: 758.7269s\n",
      "\titers: 200, epoch: 10 | loss: 0.1022663\n",
      "\tspeed: 0.0152s/iter; left time: 307.6453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1065447 Vali Loss: 0.1237250 Test Loss: 0.1507618\n",
      "Validation loss decreased (0.123823 --> 0.123725).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1049054\n",
      "\tspeed: 0.0390s/iter; left time: 786.1605s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089206\n",
      "\tspeed: 0.0157s/iter; left time: 314.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.1062916 Vali Loss: 0.1240461 Test Loss: 0.1506609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1051058\n",
      "\tspeed: 0.0399s/iter; left time: 796.0054s\n",
      "\titers: 200, epoch: 12 | loss: 0.1044658\n",
      "\tspeed: 0.0183s/iter; left time: 362.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.1060037 Vali Loss: 0.1238396 Test Loss: 0.1518371\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1060486\n",
      "\tspeed: 0.0357s/iter; left time: 703.7851s\n",
      "\titers: 200, epoch: 13 | loss: 0.1043409\n",
      "\tspeed: 0.0164s/iter; left time: 320.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.1057808 Vali Loss: 0.1241505 Test Loss: 0.1515134\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1095880\n",
      "\tspeed: 0.0367s/iter; left time: 713.9725s\n",
      "\titers: 200, epoch: 14 | loss: 0.1056166\n",
      "\tspeed: 0.0157s/iter; left time: 303.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.1055283 Vali Loss: 0.1239597 Test Loss: 0.1517490\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1075236\n",
      "\tspeed: 0.0366s/iter; left time: 705.3965s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062559\n",
      "\tspeed: 0.0166s/iter; left time: 318.1343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 225 | Train Loss: 0.1053117 Vali Loss: 0.1241924 Test Loss: 0.1519936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1069865\n",
      "\tspeed: 0.0389s/iter; left time: 740.6799s\n",
      "\titers: 200, epoch: 16 | loss: 0.1052222\n",
      "\tspeed: 0.0201s/iter; left time: 380.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.1051655 Vali Loss: 0.1241199 Test Loss: 0.1524266\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1054700\n",
      "\tspeed: 0.0390s/iter; left time: 732.6092s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039295\n",
      "\tspeed: 0.0177s/iter; left time: 330.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.1049739 Vali Loss: 0.1241205 Test Loss: 0.1521003\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1029889\n",
      "\tspeed: 0.0363s/iter; left time: 673.9203s\n",
      "\titers: 200, epoch: 18 | loss: 0.1077079\n",
      "\tspeed: 0.0168s/iter; left time: 309.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.1048550 Vali Loss: 0.1240906 Test Loss: 0.1522658\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1090901\n",
      "\tspeed: 0.0406s/iter; left time: 744.7466s\n",
      "\titers: 200, epoch: 19 | loss: 0.1001188\n",
      "\tspeed: 0.0177s/iter; left time: 323.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.1047448 Vali Loss: 0.1239998 Test Loss: 0.1522070\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1083529\n",
      "\tspeed: 0.0390s/iter; left time: 706.6121s\n",
      "\titers: 200, epoch: 20 | loss: 0.1003313\n",
      "\tspeed: 0.0151s/iter; left time: 272.4803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1046049 Vali Loss: 0.1242627 Test Loss: 0.1523417\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0486115999519825, rmse:0.22048038244247437, mae:0.15076184272766113, rse:0.7644371390342712\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:41.15s\n",
      "Intermediate time for GB: 00h:16m:02.70s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1451550\n",
      "\tspeed: 0.0395s/iter; left time: 888.7457s\n",
      "\titers: 200, epoch: 1 | loss: 0.1177439\n",
      "\tspeed: 0.0135s/iter; left time: 301.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.1467837 Vali Loss: 0.1082984 Test Loss: 0.1226880\n",
      "Validation loss decreased (inf --> 0.108298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765975\n",
      "\tspeed: 0.0305s/iter; left time: 680.4632s\n",
      "\titers: 200, epoch: 2 | loss: 0.0669800\n",
      "\tspeed: 0.0169s/iter; left time: 373.9560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0798699 Vali Loss: 0.0656852 Test Loss: 0.0723652\n",
      "Validation loss decreased (0.108298 --> 0.065685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679572\n",
      "\tspeed: 0.0377s/iter; left time: 830.4263s\n",
      "\titers: 200, epoch: 3 | loss: 0.0667502\n",
      "\tspeed: 0.0229s/iter; left time: 502.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 226 | Train Loss: 0.0679510 Vali Loss: 0.0617661 Test Loss: 0.0682334\n",
      "Validation loss decreased (0.065685 --> 0.061766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0635966\n",
      "\tspeed: 0.0350s/iter; left time: 763.2318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0613056\n",
      "\tspeed: 0.0183s/iter; left time: 397.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0647878 Vali Loss: 0.0594496 Test Loss: 0.0655302\n",
      "Validation loss decreased (0.061766 --> 0.059450).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0638050\n",
      "\tspeed: 0.0370s/iter; left time: 798.5349s\n",
      "\titers: 200, epoch: 5 | loss: 0.0621530\n",
      "\tspeed: 0.0200s/iter; left time: 429.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0625533 Vali Loss: 0.0581501 Test Loss: 0.0642101\n",
      "Validation loss decreased (0.059450 --> 0.058150).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599403\n",
      "\tspeed: 0.0373s/iter; left time: 797.2017s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587380\n",
      "\tspeed: 0.0200s/iter; left time: 426.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 226 | Train Loss: 0.0610643 Vali Loss: 0.0572503 Test Loss: 0.0633823\n",
      "Validation loss decreased (0.058150 --> 0.057250).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577566\n",
      "\tspeed: 0.0398s/iter; left time: 840.9181s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595189\n",
      "\tspeed: 0.0215s/iter; left time: 452.3899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 226 | Train Loss: 0.0599456 Vali Loss: 0.0565520 Test Loss: 0.0626068\n",
      "Validation loss decreased (0.057250 --> 0.056552).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583735\n",
      "\tspeed: 0.0344s/iter; left time: 719.6524s\n",
      "\titers: 200, epoch: 8 | loss: 0.0600804\n",
      "\tspeed: 0.0155s/iter; left time: 323.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0591601 Vali Loss: 0.0560919 Test Loss: 0.0620987\n",
      "Validation loss decreased (0.056552 --> 0.056092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0583554\n",
      "\tspeed: 0.0353s/iter; left time: 730.4459s\n",
      "\titers: 200, epoch: 9 | loss: 0.0625408\n",
      "\tspeed: 0.0158s/iter; left time: 324.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0584560 Vali Loss: 0.0557185 Test Loss: 0.0616777\n",
      "Validation loss decreased (0.056092 --> 0.055719).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586190\n",
      "\tspeed: 0.0380s/iter; left time: 778.4299s\n",
      "\titers: 200, epoch: 10 | loss: 0.0579860\n",
      "\tspeed: 0.0197s/iter; left time: 401.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 226 | Train Loss: 0.0579441 Vali Loss: 0.0553816 Test Loss: 0.0612375\n",
      "Validation loss decreased (0.055719 --> 0.055382).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0550162\n",
      "\tspeed: 0.0354s/iter; left time: 717.1668s\n",
      "\titers: 200, epoch: 11 | loss: 0.0574639\n",
      "\tspeed: 0.0172s/iter; left time: 346.2872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 226 | Train Loss: 0.0574571 Vali Loss: 0.0549510 Test Loss: 0.0610811\n",
      "Validation loss decreased (0.055382 --> 0.054951).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0580048\n",
      "\tspeed: 0.0352s/iter; left time: 703.7974s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585291\n",
      "\tspeed: 0.0173s/iter; left time: 345.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0570274 Vali Loss: 0.0547696 Test Loss: 0.0606912\n",
      "Validation loss decreased (0.054951 --> 0.054770).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0554573\n",
      "\tspeed: 0.0340s/iter; left time: 673.3766s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591582\n",
      "\tspeed: 0.0172s/iter; left time: 337.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0566880 Vali Loss: 0.0546194 Test Loss: 0.0605852\n",
      "Validation loss decreased (0.054770 --> 0.054619).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0542542\n",
      "\tspeed: 0.0369s/iter; left time: 721.0404s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572352\n",
      "\tspeed: 0.0199s/iter; left time: 386.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 226 | Train Loss: 0.0564119 Vali Loss: 0.0544218 Test Loss: 0.0603917\n",
      "Validation loss decreased (0.054619 --> 0.054422).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0540660\n",
      "\tspeed: 0.0353s/iter; left time: 681.8516s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574466\n",
      "\tspeed: 0.0172s/iter; left time: 330.8605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0561427 Vali Loss: 0.0542233 Test Loss: 0.0602162\n",
      "Validation loss decreased (0.054422 --> 0.054223).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569734\n",
      "\tspeed: 0.0354s/iter; left time: 676.9982s\n",
      "\titers: 200, epoch: 16 | loss: 0.0520816\n",
      "\tspeed: 0.0170s/iter; left time: 322.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0559051 Vali Loss: 0.0542752 Test Loss: 0.0600648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0512955\n",
      "\tspeed: 0.0350s/iter; left time: 661.3820s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539228\n",
      "\tspeed: 0.0192s/iter; left time: 361.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0556844 Vali Loss: 0.0540120 Test Loss: 0.0600547\n",
      "Validation loss decreased (0.054223 --> 0.054012).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0542477\n",
      "\tspeed: 0.0356s/iter; left time: 663.8737s\n",
      "\titers: 200, epoch: 18 | loss: 0.0539086\n",
      "\tspeed: 0.0175s/iter; left time: 324.7138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0555654 Vali Loss: 0.0539356 Test Loss: 0.0599224\n",
      "Validation loss decreased (0.054012 --> 0.053936).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0571002\n",
      "\tspeed: 0.0365s/iter; left time: 673.3697s\n",
      "\titers: 200, epoch: 19 | loss: 0.0550000\n",
      "\tspeed: 0.0195s/iter; left time: 357.1438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0553925 Vali Loss: 0.0537290 Test Loss: 0.0598146\n",
      "Validation loss decreased (0.053936 --> 0.053729).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542098\n",
      "\tspeed: 0.0336s/iter; left time: 612.3132s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565600\n",
      "\tspeed: 0.0149s/iter; left time: 269.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0552582 Vali Loss: 0.0536194 Test Loss: 0.0596348\n",
      "Validation loss decreased (0.053729 --> 0.053619).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0570835\n",
      "\tspeed: 0.0300s/iter; left time: 538.8699s\n",
      "\titers: 200, epoch: 21 | loss: 0.0525154\n",
      "\tspeed: 0.0174s/iter; left time: 310.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0551466 Vali Loss: 0.0537754 Test Loss: 0.0597416\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0550864\n",
      "\tspeed: 0.0319s/iter; left time: 566.1580s\n",
      "\titers: 200, epoch: 22 | loss: 0.0529542\n",
      "\tspeed: 0.0151s/iter; left time: 266.4800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0550331 Vali Loss: 0.0535485 Test Loss: 0.0595939\n",
      "Validation loss decreased (0.053619 --> 0.053548).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570377\n",
      "\tspeed: 0.0327s/iter; left time: 573.6363s\n",
      "\titers: 200, epoch: 23 | loss: 0.0554462\n",
      "\tspeed: 0.0192s/iter; left time: 334.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0549571 Vali Loss: 0.0536868 Test Loss: 0.0597135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0528872\n",
      "\tspeed: 0.0315s/iter; left time: 544.7078s\n",
      "\titers: 200, epoch: 24 | loss: 0.0580698\n",
      "\tspeed: 0.0167s/iter; left time: 287.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0548983 Vali Loss: 0.0533693 Test Loss: 0.0593940\n",
      "Validation loss decreased (0.053548 --> 0.053369).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0536186\n",
      "\tspeed: 0.0309s/iter; left time: 527.9620s\n",
      "\titers: 200, epoch: 25 | loss: 0.0545483\n",
      "\tspeed: 0.0130s/iter; left time: 220.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0548395 Vali Loss: 0.0534591 Test Loss: 0.0594047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0536943\n",
      "\tspeed: 0.0284s/iter; left time: 479.1360s\n",
      "\titers: 200, epoch: 26 | loss: 0.0547102\n",
      "\tspeed: 0.0137s/iter; left time: 228.9919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0547063 Vali Loss: 0.0533696 Test Loss: 0.0594442\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0586530\n",
      "\tspeed: 0.0287s/iter; left time: 477.2321s\n",
      "\titers: 200, epoch: 27 | loss: 0.0519660\n",
      "\tspeed: 0.0136s/iter; left time: 224.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0546750 Vali Loss: 0.0533953 Test Loss: 0.0594027\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0549270\n",
      "\tspeed: 0.0294s/iter; left time: 481.3725s\n",
      "\titers: 200, epoch: 28 | loss: 0.0517543\n",
      "\tspeed: 0.0135s/iter; left time: 219.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0546615 Vali Loss: 0.0533006 Test Loss: 0.0593567\n",
      "Validation loss decreased (0.053369 --> 0.053301).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0557347\n",
      "\tspeed: 0.0290s/iter; left time: 468.2238s\n",
      "\titers: 200, epoch: 29 | loss: 0.0538403\n",
      "\tspeed: 0.0129s/iter; left time: 207.9327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0546012 Vali Loss: 0.0533369 Test Loss: 0.0592920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0516878\n",
      "\tspeed: 0.0296s/iter; left time: 471.9321s\n",
      "\titers: 200, epoch: 30 | loss: 0.0524874\n",
      "\tspeed: 0.0136s/iter; left time: 215.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 226 | Train Loss: 0.0545499 Vali Loss: 0.0533188 Test Loss: 0.0593219\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0556062\n",
      "\tspeed: 0.0303s/iter; left time: 475.7911s\n",
      "\titers: 200, epoch: 31 | loss: 0.0533224\n",
      "\tspeed: 0.0139s/iter; left time: 216.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0545046 Vali Loss: 0.0533411 Test Loss: 0.0593881\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0547356\n",
      "\tspeed: 0.0282s/iter; left time: 437.0103s\n",
      "\titers: 200, epoch: 32 | loss: 0.0559356\n",
      "\tspeed: 0.0142s/iter; left time: 218.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0544690 Vali Loss: 0.0532426 Test Loss: 0.0593208\n",
      "Validation loss decreased (0.053301 --> 0.053243).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0555151\n",
      "\tspeed: 0.0287s/iter; left time: 438.1923s\n",
      "\titers: 200, epoch: 33 | loss: 0.0566518\n",
      "\tspeed: 0.0133s/iter; left time: 202.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0544179 Vali Loss: 0.0533163 Test Loss: 0.0592986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0558582\n",
      "\tspeed: 0.0281s/iter; left time: 422.6046s\n",
      "\titers: 200, epoch: 34 | loss: 0.0547988\n",
      "\tspeed: 0.0132s/iter; left time: 197.2114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0544022 Vali Loss: 0.0532038 Test Loss: 0.0591519\n",
      "Validation loss decreased (0.053243 --> 0.053204).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0563478\n",
      "\tspeed: 0.0299s/iter; left time: 442.8674s\n",
      "\titers: 200, epoch: 35 | loss: 0.0556942\n",
      "\tspeed: 0.0118s/iter; left time: 173.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0543788 Vali Loss: 0.0532233 Test Loss: 0.0592055\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0515261\n",
      "\tspeed: 0.0282s/iter; left time: 411.0176s\n",
      "\titers: 200, epoch: 36 | loss: 0.0552400\n",
      "\tspeed: 0.0135s/iter; left time: 195.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0543355 Vali Loss: 0.0531696 Test Loss: 0.0591507\n",
      "Validation loss decreased (0.053204 --> 0.053170).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0567131\n",
      "\tspeed: 0.0290s/iter; left time: 417.2604s\n",
      "\titers: 200, epoch: 37 | loss: 0.0568572\n",
      "\tspeed: 0.0153s/iter; left time: 218.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0543303 Vali Loss: 0.0532427 Test Loss: 0.0592053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0516365\n",
      "\tspeed: 0.0281s/iter; left time: 397.9304s\n",
      "\titers: 200, epoch: 38 | loss: 0.0545847\n",
      "\tspeed: 0.0114s/iter; left time: 160.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0543382 Vali Loss: 0.0532185 Test Loss: 0.0591625\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0540008\n",
      "\tspeed: 0.0277s/iter; left time: 385.6329s\n",
      "\titers: 200, epoch: 39 | loss: 0.0528272\n",
      "\tspeed: 0.0118s/iter; left time: 162.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0542832 Vali Loss: 0.0531784 Test Loss: 0.0591502\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0516087\n",
      "\tspeed: 0.0261s/iter; left time: 357.7612s\n",
      "\titers: 200, epoch: 40 | loss: 0.0524877\n",
      "\tspeed: 0.0117s/iter; left time: 159.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0542918 Vali Loss: 0.0532291 Test Loss: 0.0591576\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0586451\n",
      "\tspeed: 0.0272s/iter; left time: 365.4904s\n",
      "\titers: 200, epoch: 41 | loss: 0.0575853\n",
      "\tspeed: 0.0117s/iter; left time: 156.9834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0542267 Vali Loss: 0.0530851 Test Loss: 0.0592127\n",
      "Validation loss decreased (0.053170 --> 0.053085).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0498054\n",
      "\tspeed: 0.0326s/iter; left time: 431.2476s\n",
      "\titers: 200, epoch: 42 | loss: 0.0552870\n",
      "\tspeed: 0.0123s/iter; left time: 161.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0543146 Vali Loss: 0.0531483 Test Loss: 0.0591471\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0503690\n",
      "\tspeed: 0.0294s/iter; left time: 382.3126s\n",
      "\titers: 200, epoch: 43 | loss: 0.0562914\n",
      "\tspeed: 0.0128s/iter; left time: 165.7275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0542930 Vali Loss: 0.0531643 Test Loss: 0.0592036\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0539966\n",
      "\tspeed: 0.0299s/iter; left time: 382.5697s\n",
      "\titers: 200, epoch: 44 | loss: 0.0501583\n",
      "\tspeed: 0.0130s/iter; left time: 164.5872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0542000 Vali Loss: 0.0531088 Test Loss: 0.0590504\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0574259\n",
      "\tspeed: 0.0273s/iter; left time: 342.4563s\n",
      "\titers: 200, epoch: 45 | loss: 0.0551004\n",
      "\tspeed: 0.0111s/iter; left time: 138.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0542018 Vali Loss: 0.0531857 Test Loss: 0.0591267\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0549353\n",
      "\tspeed: 0.0265s/iter; left time: 326.4648s\n",
      "\titers: 200, epoch: 46 | loss: 0.0492027\n",
      "\tspeed: 0.0126s/iter; left time: 153.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0542488 Vali Loss: 0.0531209 Test Loss: 0.0592010\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0555106\n",
      "\tspeed: 0.0269s/iter; left time: 325.1362s\n",
      "\titers: 200, epoch: 47 | loss: 0.0540510\n",
      "\tspeed: 0.0113s/iter; left time: 136.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0542097 Vali Loss: 0.0531165 Test Loss: 0.0591204\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0553315\n",
      "\tspeed: 0.0270s/iter; left time: 320.2321s\n",
      "\titers: 200, epoch: 48 | loss: 0.0546300\n",
      "\tspeed: 0.0114s/iter; left time: 134.4081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541788 Vali Loss: 0.0531417 Test Loss: 0.0590926\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549805\n",
      "\tspeed: 0.0267s/iter; left time: 310.7206s\n",
      "\titers: 200, epoch: 49 | loss: 0.0557395\n",
      "\tspeed: 0.0112s/iter; left time: 128.9113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541946 Vali Loss: 0.0531759 Test Loss: 0.0591419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0542814\n",
      "\tspeed: 0.0268s/iter; left time: 306.4461s\n",
      "\titers: 200, epoch: 50 | loss: 0.0558326\n",
      "\tspeed: 0.0137s/iter; left time: 155.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0541970 Vali Loss: 0.0531588 Test Loss: 0.0592191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0540405\n",
      "\tspeed: 0.0286s/iter; left time: 319.9939s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547026\n",
      "\tspeed: 0.0130s/iter; left time: 144.2814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0541853 Vali Loss: 0.0531794 Test Loss: 0.0590807\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009818107821047306, rmse:0.09908636659383774, mae:0.05921265855431557, rse:0.29159918427467346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1507255\n",
      "\tspeed: 0.0146s/iter; left time: 327.6570s\n",
      "\titers: 200, epoch: 1 | loss: 0.1207082\n",
      "\tspeed: 0.0143s/iter; left time: 319.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.1465289 Vali Loss: 0.1071480 Test Loss: 0.1212301\n",
      "Validation loss decreased (inf --> 0.107148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0785520\n",
      "\tspeed: 0.0280s/iter; left time: 622.9595s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688930\n",
      "\tspeed: 0.0117s/iter; left time: 259.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0799033 Vali Loss: 0.0661498 Test Loss: 0.0729442\n",
      "Validation loss decreased (0.107148 --> 0.066150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0675750\n",
      "\tspeed: 0.0298s/iter; left time: 657.1261s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637515\n",
      "\tspeed: 0.0114s/iter; left time: 249.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0680635 Vali Loss: 0.0614426 Test Loss: 0.0683460\n",
      "Validation loss decreased (0.066150 --> 0.061443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0669186\n",
      "\tspeed: 0.0290s/iter; left time: 633.9092s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643349\n",
      "\tspeed: 0.0131s/iter; left time: 283.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0648668 Vali Loss: 0.0593724 Test Loss: 0.0657995\n",
      "Validation loss decreased (0.061443 --> 0.059372).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610497\n",
      "\tspeed: 0.0305s/iter; left time: 658.0443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619393\n",
      "\tspeed: 0.0118s/iter; left time: 254.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0626716 Vali Loss: 0.0577798 Test Loss: 0.0641355\n",
      "Validation loss decreased (0.059372 --> 0.057780).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614329\n",
      "\tspeed: 0.0273s/iter; left time: 582.4532s\n",
      "\titers: 200, epoch: 6 | loss: 0.0615167\n",
      "\tspeed: 0.0124s/iter; left time: 263.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0611074 Vali Loss: 0.0574545 Test Loss: 0.0633995\n",
      "Validation loss decreased (0.057780 --> 0.057454).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597643\n",
      "\tspeed: 0.0283s/iter; left time: 599.3577s\n",
      "\titers: 200, epoch: 7 | loss: 0.0607079\n",
      "\tspeed: 0.0116s/iter; left time: 244.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0599273 Vali Loss: 0.0563146 Test Loss: 0.0625127\n",
      "Validation loss decreased (0.057454 --> 0.056315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0574845\n",
      "\tspeed: 0.0285s/iter; left time: 596.6742s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590476\n",
      "\tspeed: 0.0120s/iter; left time: 250.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0590586 Vali Loss: 0.0560240 Test Loss: 0.0619528\n",
      "Validation loss decreased (0.056315 --> 0.056024).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0639373\n",
      "\tspeed: 0.0279s/iter; left time: 576.6687s\n",
      "\titers: 200, epoch: 9 | loss: 0.0527270\n",
      "\tspeed: 0.0118s/iter; left time: 242.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0583976 Vali Loss: 0.0554776 Test Loss: 0.0613036\n",
      "Validation loss decreased (0.056024 --> 0.055478).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0565735\n",
      "\tspeed: 0.0287s/iter; left time: 587.6593s\n",
      "\titers: 200, epoch: 10 | loss: 0.0558760\n",
      "\tspeed: 0.0118s/iter; left time: 240.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0577687 Vali Loss: 0.0552871 Test Loss: 0.0610560\n",
      "Validation loss decreased (0.055478 --> 0.055287).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0571113\n",
      "\tspeed: 0.0293s/iter; left time: 592.0521s\n",
      "\titers: 200, epoch: 11 | loss: 0.0566703\n",
      "\tspeed: 0.0118s/iter; left time: 237.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0573187 Vali Loss: 0.0547834 Test Loss: 0.0607028\n",
      "Validation loss decreased (0.055287 --> 0.054783).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586570\n",
      "\tspeed: 0.0273s/iter; left time: 547.2207s\n",
      "\titers: 200, epoch: 12 | loss: 0.0570341\n",
      "\tspeed: 0.0119s/iter; left time: 236.3911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0569485 Vali Loss: 0.0544821 Test Loss: 0.0604087\n",
      "Validation loss decreased (0.054783 --> 0.054482).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0555787\n",
      "\tspeed: 0.0303s/iter; left time: 599.0129s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562803\n",
      "\tspeed: 0.0129s/iter; left time: 253.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0566200 Vali Loss: 0.0545550 Test Loss: 0.0603720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0575179\n",
      "\tspeed: 0.0300s/iter; left time: 587.0186s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569978\n",
      "\tspeed: 0.0119s/iter; left time: 231.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 226 | Train Loss: 0.0562737 Vali Loss: 0.0543751 Test Loss: 0.0601368\n",
      "Validation loss decreased (0.054482 --> 0.054375).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0523732\n",
      "\tspeed: 0.0262s/iter; left time: 507.0347s\n",
      "\titers: 200, epoch: 15 | loss: 0.0562500\n",
      "\tspeed: 0.0124s/iter; left time: 239.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0560525 Vali Loss: 0.0540945 Test Loss: 0.0599775\n",
      "Validation loss decreased (0.054375 --> 0.054095).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0528089\n",
      "\tspeed: 0.0271s/iter; left time: 517.4916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597127\n",
      "\tspeed: 0.0117s/iter; left time: 222.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0558022 Vali Loss: 0.0539221 Test Loss: 0.0597435\n",
      "Validation loss decreased (0.054095 --> 0.053922).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0559879\n",
      "\tspeed: 0.0289s/iter; left time: 545.5689s\n",
      "\titers: 200, epoch: 17 | loss: 0.0581747\n",
      "\tspeed: 0.0117s/iter; left time: 218.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0556188 Vali Loss: 0.0539700 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0555314\n",
      "\tspeed: 0.0261s/iter; left time: 486.7138s\n",
      "\titers: 200, epoch: 18 | loss: 0.0544397\n",
      "\tspeed: 0.0110s/iter; left time: 203.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 226 | Train Loss: 0.0554477 Vali Loss: 0.0536921 Test Loss: 0.0595935\n",
      "Validation loss decreased (0.053922 --> 0.053692).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0524647\n",
      "\tspeed: 0.0272s/iter; left time: 501.1017s\n",
      "\titers: 200, epoch: 19 | loss: 0.0516993\n",
      "\tspeed: 0.0121s/iter; left time: 221.9829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0553181 Vali Loss: 0.0537883 Test Loss: 0.0596126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0527550\n",
      "\tspeed: 0.0291s/iter; left time: 529.7238s\n",
      "\titers: 200, epoch: 20 | loss: 0.0565373\n",
      "\tspeed: 0.0142s/iter; left time: 257.1261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0551740 Vali Loss: 0.0537758 Test Loss: 0.0596166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569603\n",
      "\tspeed: 0.0264s/iter; left time: 474.5772s\n",
      "\titers: 200, epoch: 21 | loss: 0.0545343\n",
      "\tspeed: 0.0118s/iter; left time: 210.3655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 226 | Train Loss: 0.0550889 Vali Loss: 0.0533999 Test Loss: 0.0594185\n",
      "Validation loss decreased (0.053692 --> 0.053400).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0562903\n",
      "\tspeed: 0.0269s/iter; left time: 477.0942s\n",
      "\titers: 200, epoch: 22 | loss: 0.0577873\n",
      "\tspeed: 0.0137s/iter; left time: 241.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0549383 Vali Loss: 0.0534308 Test Loss: 0.0593246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0538595\n",
      "\tspeed: 0.0284s/iter; left time: 498.1272s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566281\n",
      "\tspeed: 0.0130s/iter; left time: 226.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 226 | Train Loss: 0.0548749 Vali Loss: 0.0534087 Test Loss: 0.0593133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0507098\n",
      "\tspeed: 0.0292s/iter; left time: 504.9074s\n",
      "\titers: 200, epoch: 24 | loss: 0.0538428\n",
      "\tspeed: 0.0121s/iter; left time: 207.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0548080 Vali Loss: 0.0533418 Test Loss: 0.0593664\n",
      "Validation loss decreased (0.053400 --> 0.053342).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0554929\n",
      "\tspeed: 0.0276s/iter; left time: 471.6608s\n",
      "\titers: 200, epoch: 25 | loss: 0.0567786\n",
      "\tspeed: 0.0115s/iter; left time: 195.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0546885 Vali Loss: 0.0534237 Test Loss: 0.0594419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548124\n",
      "\tspeed: 0.0265s/iter; left time: 446.6148s\n",
      "\titers: 200, epoch: 26 | loss: 0.0535798\n",
      "\tspeed: 0.0110s/iter; left time: 183.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.68s\n",
      "Steps: 226 | Train Loss: 0.0546452 Vali Loss: 0.0533526 Test Loss: 0.0591975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0557830\n",
      "\tspeed: 0.0274s/iter; left time: 455.9417s\n",
      "\titers: 200, epoch: 27 | loss: 0.0586098\n",
      "\tspeed: 0.0135s/iter; left time: 222.7970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0545553 Vali Loss: 0.0533763 Test Loss: 0.0592641\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0546051\n",
      "\tspeed: 0.0277s/iter; left time: 454.7507s\n",
      "\titers: 200, epoch: 28 | loss: 0.0558206\n",
      "\tspeed: 0.0126s/iter; left time: 204.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0545318 Vali Loss: 0.0532169 Test Loss: 0.0592011\n",
      "Validation loss decreased (0.053342 --> 0.053217).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0563632\n",
      "\tspeed: 0.0271s/iter; left time: 438.6456s\n",
      "\titers: 200, epoch: 29 | loss: 0.0581273\n",
      "\tspeed: 0.0125s/iter; left time: 200.6389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0544601 Vali Loss: 0.0531060 Test Loss: 0.0591692\n",
      "Validation loss decreased (0.053217 --> 0.053106).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0574518\n",
      "\tspeed: 0.0266s/iter; left time: 424.1283s\n",
      "\titers: 200, epoch: 30 | loss: 0.0555285\n",
      "\tspeed: 0.0108s/iter; left time: 171.7217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0544499 Vali Loss: 0.0530576 Test Loss: 0.0590920\n",
      "Validation loss decreased (0.053106 --> 0.053058).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0510666\n",
      "\tspeed: 0.0274s/iter; left time: 431.2590s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540474\n",
      "\tspeed: 0.0111s/iter; left time: 173.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0544246 Vali Loss: 0.0533034 Test Loss: 0.0591211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0568054\n",
      "\tspeed: 0.0268s/iter; left time: 416.0011s\n",
      "\titers: 200, epoch: 32 | loss: 0.0557136\n",
      "\tspeed: 0.0116s/iter; left time: 178.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0543331 Vali Loss: 0.0531352 Test Loss: 0.0590774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0552513\n",
      "\tspeed: 0.0290s/iter; left time: 443.3887s\n",
      "\titers: 200, epoch: 33 | loss: 0.0547300\n",
      "\tspeed: 0.0120s/iter; left time: 181.6856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0543432 Vali Loss: 0.0531316 Test Loss: 0.0590895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0512971\n",
      "\tspeed: 0.0261s/iter; left time: 392.2131s\n",
      "\titers: 200, epoch: 34 | loss: 0.0529503\n",
      "\tspeed: 0.0118s/iter; left time: 176.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 226 | Train Loss: 0.0543068 Vali Loss: 0.0530512 Test Loss: 0.0591309\n",
      "Validation loss decreased (0.053058 --> 0.053051).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0559119\n",
      "\tspeed: 0.0271s/iter; left time: 401.2238s\n",
      "\titers: 200, epoch: 35 | loss: 0.0545416\n",
      "\tspeed: 0.0123s/iter; left time: 180.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0542706 Vali Loss: 0.0530420 Test Loss: 0.0589782\n",
      "Validation loss decreased (0.053051 --> 0.053042).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0561696\n",
      "\tspeed: 0.0283s/iter; left time: 412.9282s\n",
      "\titers: 200, epoch: 36 | loss: 0.0561849\n",
      "\tspeed: 0.0117s/iter; left time: 169.7662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0542947 Vali Loss: 0.0530133 Test Loss: 0.0590346\n",
      "Validation loss decreased (0.053042 --> 0.053013).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0509262\n",
      "\tspeed: 0.0275s/iter; left time: 394.9990s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508690\n",
      "\tspeed: 0.0119s/iter; left time: 169.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0541840 Vali Loss: 0.0531005 Test Loss: 0.0591013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0554777\n",
      "\tspeed: 0.0279s/iter; left time: 394.2060s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548198\n",
      "\tspeed: 0.0120s/iter; left time: 169.1098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0542373 Vali Loss: 0.0530459 Test Loss: 0.0589842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0525637\n",
      "\tspeed: 0.0294s/iter; left time: 408.4744s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543035\n",
      "\tspeed: 0.0164s/iter; left time: 226.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 226 | Train Loss: 0.0542141 Vali Loss: 0.0530863 Test Loss: 0.0589925\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0504019\n",
      "\tspeed: 0.0292s/iter; left time: 399.6585s\n",
      "\titers: 200, epoch: 40 | loss: 0.0561855\n",
      "\tspeed: 0.0114s/iter; left time: 154.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 226 | Train Loss: 0.0542050 Vali Loss: 0.0530611 Test Loss: 0.0590304\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0555407\n",
      "\tspeed: 0.0284s/iter; left time: 382.3314s\n",
      "\titers: 200, epoch: 41 | loss: 0.0573847\n",
      "\tspeed: 0.0121s/iter; left time: 161.0054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0541970 Vali Loss: 0.0529732 Test Loss: 0.0589725\n",
      "Validation loss decreased (0.053013 --> 0.052973).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0557087\n",
      "\tspeed: 0.0262s/iter; left time: 347.2037s\n",
      "\titers: 200, epoch: 42 | loss: 0.0507394\n",
      "\tspeed: 0.0107s/iter; left time: 140.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 226 | Train Loss: 0.0542100 Vali Loss: 0.0530530 Test Loss: 0.0589480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0532187\n",
      "\tspeed: 0.0280s/iter; left time: 364.2858s\n",
      "\titers: 200, epoch: 43 | loss: 0.0522638\n",
      "\tspeed: 0.0114s/iter; left time: 146.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0541853 Vali Loss: 0.0530456 Test Loss: 0.0589709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0523888\n",
      "\tspeed: 0.0294s/iter; left time: 376.4591s\n",
      "\titers: 200, epoch: 44 | loss: 0.0555471\n",
      "\tspeed: 0.0114s/iter; left time: 145.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0541429 Vali Loss: 0.0530979 Test Loss: 0.0590576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0518244\n",
      "\tspeed: 0.0268s/iter; left time: 336.3404s\n",
      "\titers: 200, epoch: 45 | loss: 0.0573724\n",
      "\tspeed: 0.0110s/iter; left time: 137.2029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541446 Vali Loss: 0.0530079 Test Loss: 0.0589412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0536192\n",
      "\tspeed: 0.0274s/iter; left time: 338.2583s\n",
      "\titers: 200, epoch: 46 | loss: 0.0520935\n",
      "\tspeed: 0.0119s/iter; left time: 146.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0541448 Vali Loss: 0.0530503 Test Loss: 0.0589884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0567641\n",
      "\tspeed: 0.0258s/iter; left time: 312.7587s\n",
      "\titers: 200, epoch: 47 | loss: 0.0499426\n",
      "\tspeed: 0.0110s/iter; left time: 132.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 226 | Train Loss: 0.0541792 Vali Loss: 0.0529625 Test Loss: 0.0589573\n",
      "Validation loss decreased (0.052973 --> 0.052963).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0543365\n",
      "\tspeed: 0.0311s/iter; left time: 369.0471s\n",
      "\titers: 200, epoch: 48 | loss: 0.0528470\n",
      "\tspeed: 0.0118s/iter; left time: 139.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0540931 Vali Loss: 0.0529664 Test Loss: 0.0589474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0498530\n",
      "\tspeed: 0.0266s/iter; left time: 309.8380s\n",
      "\titers: 200, epoch: 49 | loss: 0.0562437\n",
      "\tspeed: 0.0115s/iter; left time: 133.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0541368 Vali Loss: 0.0529739 Test Loss: 0.0589651\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0547175\n",
      "\tspeed: 0.0263s/iter; left time: 300.8490s\n",
      "\titers: 200, epoch: 50 | loss: 0.0537487\n",
      "\tspeed: 0.0108s/iter; left time: 122.8662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 226 | Train Loss: 0.0540701 Vali Loss: 0.0530535 Test Loss: 0.0589779\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0549713\n",
      "\tspeed: 0.0263s/iter; left time: 294.7595s\n",
      "\titers: 200, epoch: 51 | loss: 0.0546206\n",
      "\tspeed: 0.0119s/iter; left time: 131.8535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541515 Vali Loss: 0.0530221 Test Loss: 0.0589595\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0527683\n",
      "\tspeed: 0.0266s/iter; left time: 292.3650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0574221\n",
      "\tspeed: 0.0120s/iter; left time: 130.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0541668 Vali Loss: 0.0530018 Test Loss: 0.0589725\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0534396\n",
      "\tspeed: 0.0290s/iter; left time: 311.5190s\n",
      "\titers: 200, epoch: 53 | loss: 0.0520115\n",
      "\tspeed: 0.0114s/iter; left time: 121.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0540821 Vali Loss: 0.0530134 Test Loss: 0.0589416\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0542039\n",
      "\tspeed: 0.0269s/iter; left time: 283.4755s\n",
      "\titers: 200, epoch: 54 | loss: 0.0522672\n",
      "\tspeed: 0.0119s/iter; left time: 124.2941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0541188 Vali Loss: 0.0530085 Test Loss: 0.0589848\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0503511\n",
      "\tspeed: 0.0266s/iter; left time: 274.0105s\n",
      "\titers: 200, epoch: 55 | loss: 0.0528312\n",
      "\tspeed: 0.0115s/iter; left time: 117.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0540319 Vali Loss: 0.0529898 Test Loss: 0.0589086\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0524455\n",
      "\tspeed: 0.0277s/iter; left time: 278.7486s\n",
      "\titers: 200, epoch: 56 | loss: 0.0551980\n",
      "\tspeed: 0.0115s/iter; left time: 114.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0541053 Vali Loss: 0.0529852 Test Loss: 0.0588668\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0554461\n",
      "\tspeed: 0.0263s/iter; left time: 259.1786s\n",
      "\titers: 200, epoch: 57 | loss: 0.0511636\n",
      "\tspeed: 0.0109s/iter; left time: 106.5654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 226 | Train Loss: 0.0540857 Vali Loss: 0.0530011 Test Loss: 0.0590005\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009839903563261032, rmse:0.09919628500938416, mae:0.058957286179065704, rse:0.2919226884841919\n",
      "Intermediate time for ES and pred_len 24: 00h:07m:56.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1514326\n",
      "\tspeed: 0.0397s/iter; left time: 889.9418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1340956\n",
      "\tspeed: 0.0111s/iter; left time: 247.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.1534535 Vali Loss: 0.1192981 Test Loss: 0.1362016\n",
      "Validation loss decreased (inf --> 0.119298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0992987\n",
      "\tspeed: 0.0289s/iter; left time: 640.6691s\n",
      "\titers: 200, epoch: 2 | loss: 0.0911604\n",
      "\tspeed: 0.0132s/iter; left time: 291.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0996113 Vali Loss: 0.0870584 Test Loss: 0.0990485\n",
      "Validation loss decreased (0.119298 --> 0.087058).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860890\n",
      "\tspeed: 0.0287s/iter; left time: 630.2518s\n",
      "\titers: 200, epoch: 3 | loss: 0.0849074\n",
      "\tspeed: 0.0134s/iter; left time: 292.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0886737 Vali Loss: 0.0814001 Test Loss: 0.0934050\n",
      "Validation loss decreased (0.087058 --> 0.081400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801919\n",
      "\tspeed: 0.0299s/iter; left time: 649.1137s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829801\n",
      "\tspeed: 0.0112s/iter; left time: 241.7950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0853538 Vali Loss: 0.0797981 Test Loss: 0.0914087\n",
      "Validation loss decreased (0.081400 --> 0.079798).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849047\n",
      "\tspeed: 0.0306s/iter; left time: 657.2593s\n",
      "\titers: 200, epoch: 5 | loss: 0.0815262\n",
      "\tspeed: 0.0136s/iter; left time: 291.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0834915 Vali Loss: 0.0786919 Test Loss: 0.0897241\n",
      "Validation loss decreased (0.079798 --> 0.078692).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793926\n",
      "\tspeed: 0.0287s/iter; left time: 611.6769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0799922\n",
      "\tspeed: 0.0113s/iter; left time: 238.2779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0820761 Vali Loss: 0.0781931 Test Loss: 0.0889015\n",
      "Validation loss decreased (0.078692 --> 0.078193).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787506\n",
      "\tspeed: 0.0286s/iter; left time: 601.3436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0792138\n",
      "\tspeed: 0.0109s/iter; left time: 228.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0810654 Vali Loss: 0.0774327 Test Loss: 0.0880531\n",
      "Validation loss decreased (0.078193 --> 0.077433).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0786066\n",
      "\tspeed: 0.0290s/iter; left time: 604.3271s\n",
      "\titers: 200, epoch: 8 | loss: 0.0784651\n",
      "\tspeed: 0.0110s/iter; left time: 228.6810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0803040 Vali Loss: 0.0773680 Test Loss: 0.0878483\n",
      "Validation loss decreased (0.077433 --> 0.077368).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0771229\n",
      "\tspeed: 0.0279s/iter; left time: 575.3227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0784607\n",
      "\tspeed: 0.0111s/iter; left time: 228.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 225 | Train Loss: 0.0797460 Vali Loss: 0.0767728 Test Loss: 0.0873519\n",
      "Validation loss decreased (0.077368 --> 0.076773).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769961\n",
      "\tspeed: 0.0305s/iter; left time: 622.3057s\n",
      "\titers: 200, epoch: 10 | loss: 0.0839497\n",
      "\tspeed: 0.0112s/iter; left time: 227.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0792595 Vali Loss: 0.0770860 Test Loss: 0.0873690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784799\n",
      "\tspeed: 0.0265s/iter; left time: 533.1242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0806227\n",
      "\tspeed: 0.0124s/iter; left time: 248.0597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 225 | Train Loss: 0.0788540 Vali Loss: 0.0766369 Test Loss: 0.0871308\n",
      "Validation loss decreased (0.076773 --> 0.076637).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758444\n",
      "\tspeed: 0.0291s/iter; left time: 580.7146s\n",
      "\titers: 200, epoch: 12 | loss: 0.0784750\n",
      "\tspeed: 0.0133s/iter; left time: 262.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0784713 Vali Loss: 0.0762269 Test Loss: 0.0869149\n",
      "Validation loss decreased (0.076637 --> 0.076227).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0733879\n",
      "\tspeed: 0.0281s/iter; left time: 553.2530s\n",
      "\titers: 200, epoch: 13 | loss: 0.0769888\n",
      "\tspeed: 0.0111s/iter; left time: 218.1576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 225 | Train Loss: 0.0781977 Vali Loss: 0.0762897 Test Loss: 0.0870662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810686\n",
      "\tspeed: 0.0264s/iter; left time: 514.1753s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0113s/iter; left time: 219.2021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 225 | Train Loss: 0.0779459 Vali Loss: 0.0761060 Test Loss: 0.0869318\n",
      "Validation loss decreased (0.076227 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0744233\n",
      "\tspeed: 0.0289s/iter; left time: 555.8119s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829216\n",
      "\tspeed: 0.0138s/iter; left time: 264.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0777016 Vali Loss: 0.0759125 Test Loss: 0.0868220\n",
      "Validation loss decreased (0.076106 --> 0.075912).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0767097\n",
      "\tspeed: 0.0306s/iter; left time: 581.5039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0796856\n",
      "\tspeed: 0.0144s/iter; left time: 271.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0774920 Vali Loss: 0.0758455 Test Loss: 0.0867436\n",
      "Validation loss decreased (0.075912 --> 0.075846).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0774719\n",
      "\tspeed: 0.0277s/iter; left time: 521.3130s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752526\n",
      "\tspeed: 0.0130s/iter; left time: 243.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.0773374 Vali Loss: 0.0755446 Test Loss: 0.0865177\n",
      "Validation loss decreased (0.075846 --> 0.075545).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765253\n",
      "\tspeed: 0.0286s/iter; left time: 530.7867s\n",
      "\titers: 200, epoch: 18 | loss: 0.0765767\n",
      "\tspeed: 0.0122s/iter; left time: 225.3476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0771752 Vali Loss: 0.0757170 Test Loss: 0.0865492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0783547\n",
      "\tspeed: 0.0282s/iter; left time: 518.1567s\n",
      "\titers: 200, epoch: 19 | loss: 0.0767365\n",
      "\tspeed: 0.0143s/iter; left time: 261.0149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.0769659 Vali Loss: 0.0754213 Test Loss: 0.0863692\n",
      "Validation loss decreased (0.075545 --> 0.075421).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0790408\n",
      "\tspeed: 0.0282s/iter; left time: 510.8319s\n",
      "\titers: 200, epoch: 20 | loss: 0.0773466\n",
      "\tspeed: 0.0128s/iter; left time: 231.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0768425 Vali Loss: 0.0754664 Test Loss: 0.0864002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0753531\n",
      "\tspeed: 0.0301s/iter; left time: 539.1700s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731350\n",
      "\tspeed: 0.0137s/iter; left time: 243.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0766955 Vali Loss: 0.0754862 Test Loss: 0.0863862\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0779898\n",
      "\tspeed: 0.0269s/iter; left time: 475.8422s\n",
      "\titers: 200, epoch: 22 | loss: 0.0825680\n",
      "\tspeed: 0.0122s/iter; left time: 214.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0766248 Vali Loss: 0.0755235 Test Loss: 0.0864362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0791111\n",
      "\tspeed: 0.0267s/iter; left time: 465.7960s\n",
      "\titers: 200, epoch: 23 | loss: 0.0759331\n",
      "\tspeed: 0.0114s/iter; left time: 197.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0765473 Vali Loss: 0.0753228 Test Loss: 0.0863299\n",
      "Validation loss decreased (0.075421 --> 0.075323).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761495\n",
      "\tspeed: 0.0284s/iter; left time: 488.6902s\n",
      "\titers: 200, epoch: 24 | loss: 0.0738292\n",
      "\tspeed: 0.0112s/iter; left time: 190.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0765094 Vali Loss: 0.0753156 Test Loss: 0.0862079\n",
      "Validation loss decreased (0.075323 --> 0.075316).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0779993\n",
      "\tspeed: 0.0305s/iter; left time: 519.3030s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782428\n",
      "\tspeed: 0.0151s/iter; left time: 255.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0763938 Vali Loss: 0.0753543 Test Loss: 0.0861947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0742307\n",
      "\tspeed: 0.0315s/iter; left time: 528.8139s\n",
      "\titers: 200, epoch: 26 | loss: 0.0757918\n",
      "\tspeed: 0.0134s/iter; left time: 223.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0762774 Vali Loss: 0.0752724 Test Loss: 0.0862290\n",
      "Validation loss decreased (0.075316 --> 0.075272).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0783321\n",
      "\tspeed: 0.0281s/iter; left time: 465.0481s\n",
      "\titers: 200, epoch: 27 | loss: 0.0757260\n",
      "\tspeed: 0.0135s/iter; left time: 222.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0762253 Vali Loss: 0.0752488 Test Loss: 0.0862783\n",
      "Validation loss decreased (0.075272 --> 0.075249).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0790930\n",
      "\tspeed: 0.0276s/iter; left time: 450.5264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0729679\n",
      "\tspeed: 0.0121s/iter; left time: 195.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0761534 Vali Loss: 0.0751565 Test Loss: 0.0862070\n",
      "Validation loss decreased (0.075249 --> 0.075156).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0786199\n",
      "\tspeed: 0.0269s/iter; left time: 432.6455s\n",
      "\titers: 200, epoch: 29 | loss: 0.0761598\n",
      "\tspeed: 0.0112s/iter; left time: 179.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 225 | Train Loss: 0.0761940 Vali Loss: 0.0751621 Test Loss: 0.0861756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0733554\n",
      "\tspeed: 0.0295s/iter; left time: 467.9329s\n",
      "\titers: 200, epoch: 30 | loss: 0.0730510\n",
      "\tspeed: 0.0106s/iter; left time: 167.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0761272 Vali Loss: 0.0751793 Test Loss: 0.0861981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0754577\n",
      "\tspeed: 0.0268s/iter; left time: 419.6410s\n",
      "\titers: 200, epoch: 31 | loss: 0.0763041\n",
      "\tspeed: 0.0118s/iter; left time: 183.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0761112 Vali Loss: 0.0752193 Test Loss: 0.0862073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0753690\n",
      "\tspeed: 0.0270s/iter; left time: 417.0290s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749692\n",
      "\tspeed: 0.0145s/iter; left time: 222.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0760013 Vali Loss: 0.0751270 Test Loss: 0.0861752\n",
      "Validation loss decreased (0.075156 --> 0.075127).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0775594\n",
      "\tspeed: 0.0288s/iter; left time: 437.4118s\n",
      "\titers: 200, epoch: 33 | loss: 0.0772318\n",
      "\tspeed: 0.0126s/iter; left time: 189.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0760387 Vali Loss: 0.0752166 Test Loss: 0.0862664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0794576\n",
      "\tspeed: 0.0310s/iter; left time: 464.7791s\n",
      "\titers: 200, epoch: 34 | loss: 0.0768538\n",
      "\tspeed: 0.0135s/iter; left time: 200.1176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0760135 Vali Loss: 0.0751128 Test Loss: 0.0860821\n",
      "Validation loss decreased (0.075127 --> 0.075113).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735802\n",
      "\tspeed: 0.0271s/iter; left time: 400.3334s\n",
      "\titers: 200, epoch: 35 | loss: 0.0766621\n",
      "\tspeed: 0.0134s/iter; left time: 196.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0760044 Vali Loss: 0.0751563 Test Loss: 0.0862373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0772841\n",
      "\tspeed: 0.0301s/iter; left time: 436.7725s\n",
      "\titers: 200, epoch: 36 | loss: 0.0781624\n",
      "\tspeed: 0.0126s/iter; left time: 182.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0759210 Vali Loss: 0.0752047 Test Loss: 0.0861904\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786459\n",
      "\tspeed: 0.0323s/iter; left time: 462.1864s\n",
      "\titers: 200, epoch: 37 | loss: 0.0782112\n",
      "\tspeed: 0.0140s/iter; left time: 199.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0759412 Vali Loss: 0.0751507 Test Loss: 0.0861724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0764863\n",
      "\tspeed: 0.0285s/iter; left time: 400.6951s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763690\n",
      "\tspeed: 0.0114s/iter; left time: 159.7223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 225 | Train Loss: 0.0758886 Vali Loss: 0.0750675 Test Loss: 0.0861431\n",
      "Validation loss decreased (0.075113 --> 0.075067).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0746387\n",
      "\tspeed: 0.0303s/iter; left time: 420.2301s\n",
      "\titers: 200, epoch: 39 | loss: 0.0787861\n",
      "\tspeed: 0.0153s/iter; left time: 210.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0758228 Vali Loss: 0.0751216 Test Loss: 0.0861156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0776882\n",
      "\tspeed: 0.0279s/iter; left time: 380.6277s\n",
      "\titers: 200, epoch: 40 | loss: 0.0786385\n",
      "\tspeed: 0.0113s/iter; left time: 152.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0759235 Vali Loss: 0.0751186 Test Loss: 0.0860987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0728601\n",
      "\tspeed: 0.0277s/iter; left time: 371.5797s\n",
      "\titers: 200, epoch: 41 | loss: 0.0760473\n",
      "\tspeed: 0.0117s/iter; left time: 155.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0759023 Vali Loss: 0.0751263 Test Loss: 0.0861959\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0754796\n",
      "\tspeed: 0.0293s/iter; left time: 385.9538s\n",
      "\titers: 200, epoch: 42 | loss: 0.0757237\n",
      "\tspeed: 0.0123s/iter; left time: 160.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0758651 Vali Loss: 0.0751259 Test Loss: 0.0861585\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0747819\n",
      "\tspeed: 0.0280s/iter; left time: 362.8419s\n",
      "\titers: 200, epoch: 43 | loss: 0.0768324\n",
      "\tspeed: 0.0109s/iter; left time: 139.8543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 225 | Train Loss: 0.0758420 Vali Loss: 0.0750790 Test Loss: 0.0861122\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0760698\n",
      "\tspeed: 0.0267s/iter; left time: 339.2354s\n",
      "\titers: 200, epoch: 44 | loss: 0.0753583\n",
      "\tspeed: 0.0144s/iter; left time: 181.2118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0758371 Vali Loss: 0.0751272 Test Loss: 0.0861907\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0728124\n",
      "\tspeed: 0.0275s/iter; left time: 344.0722s\n",
      "\titers: 200, epoch: 45 | loss: 0.0740116\n",
      "\tspeed: 0.0145s/iter; left time: 180.2584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 225 | Train Loss: 0.0758549 Vali Loss: 0.0751464 Test Loss: 0.0861597\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0761023\n",
      "\tspeed: 0.0271s/iter; left time: 333.1433s\n",
      "\titers: 200, epoch: 46 | loss: 0.0756330\n",
      "\tspeed: 0.0132s/iter; left time: 160.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0758372 Vali Loss: 0.0751317 Test Loss: 0.0862101\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0762448\n",
      "\tspeed: 0.0301s/iter; left time: 362.6132s\n",
      "\titers: 200, epoch: 47 | loss: 0.0742020\n",
      "\tspeed: 0.0126s/iter; left time: 151.0476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 225 | Train Loss: 0.0758265 Vali Loss: 0.0751139 Test Loss: 0.0861376\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784523\n",
      "\tspeed: 0.0285s/iter; left time: 337.1899s\n",
      "\titers: 200, epoch: 48 | loss: 0.0720111\n",
      "\tspeed: 0.0114s/iter; left time: 133.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 225 | Train Loss: 0.0757754 Vali Loss: 0.0750921 Test Loss: 0.0861033\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019112445414066315, rmse:0.1382477730512619, mae:0.08614306151866913, rse:0.4061303436756134\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1577033\n",
      "\tspeed: 0.0132s/iter; left time: 295.0442s\n",
      "\titers: 200, epoch: 1 | loss: 0.1350389\n",
      "\tspeed: 0.0130s/iter; left time: 290.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.1574104 Vali Loss: 0.1217240 Test Loss: 0.1391744\n",
      "Validation loss decreased (inf --> 0.121724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0954664\n",
      "\tspeed: 0.0301s/iter; left time: 668.4554s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901520\n",
      "\tspeed: 0.0124s/iter; left time: 272.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0996074 Vali Loss: 0.0869710 Test Loss: 0.0990641\n",
      "Validation loss decreased (0.121724 --> 0.086971).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872138\n",
      "\tspeed: 0.0288s/iter; left time: 633.0436s\n",
      "\titers: 200, epoch: 3 | loss: 0.0905658\n",
      "\tspeed: 0.0122s/iter; left time: 267.1381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0889019 Vali Loss: 0.0821534 Test Loss: 0.0939969\n",
      "Validation loss decreased (0.086971 --> 0.082153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868627\n",
      "\tspeed: 0.0313s/iter; left time: 680.1948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0845538\n",
      "\tspeed: 0.0119s/iter; left time: 256.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0855274 Vali Loss: 0.0803953 Test Loss: 0.0916625\n",
      "Validation loss decreased (0.082153 --> 0.080395).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0849042\n",
      "\tspeed: 0.0300s/iter; left time: 644.3792s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862014\n",
      "\tspeed: 0.0120s/iter; left time: 257.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 225 | Train Loss: 0.0836403 Vali Loss: 0.0792225 Test Loss: 0.0900389\n",
      "Validation loss decreased (0.080395 --> 0.079222).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834529\n",
      "\tspeed: 0.0287s/iter; left time: 609.7094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0859380\n",
      "\tspeed: 0.0122s/iter; left time: 257.3358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 225 | Train Loss: 0.0823096 Vali Loss: 0.0782612 Test Loss: 0.0890277\n",
      "Validation loss decreased (0.079222 --> 0.078261).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0838038\n",
      "\tspeed: 0.0294s/iter; left time: 618.4004s\n",
      "\titers: 200, epoch: 7 | loss: 0.0800350\n",
      "\tspeed: 0.0121s/iter; left time: 253.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0814003 Vali Loss: 0.0777358 Test Loss: 0.0884875\n",
      "Validation loss decreased (0.078261 --> 0.077736).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803438\n",
      "\tspeed: 0.0281s/iter; left time: 585.6875s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797413\n",
      "\tspeed: 0.0114s/iter; left time: 236.6889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0805841 Vali Loss: 0.0774105 Test Loss: 0.0880362\n",
      "Validation loss decreased (0.077736 --> 0.077410).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0753549\n",
      "\tspeed: 0.0284s/iter; left time: 584.4948s\n",
      "\titers: 200, epoch: 9 | loss: 0.0840414\n",
      "\tspeed: 0.0139s/iter; left time: 285.0079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 225 | Train Loss: 0.0800004 Vali Loss: 0.0773046 Test Loss: 0.0879727\n",
      "Validation loss decreased (0.077410 --> 0.077305).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788011\n",
      "\tspeed: 0.0319s/iter; left time: 650.2066s\n",
      "\titers: 200, epoch: 10 | loss: 0.0813491\n",
      "\tspeed: 0.0128s/iter; left time: 259.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0794434 Vali Loss: 0.0767787 Test Loss: 0.0874287\n",
      "Validation loss decreased (0.077305 --> 0.076779).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0806336\n",
      "\tspeed: 0.0278s/iter; left time: 560.6176s\n",
      "\titers: 200, epoch: 11 | loss: 0.0811494\n",
      "\tspeed: 0.0159s/iter; left time: 318.1278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0790037 Vali Loss: 0.0766619 Test Loss: 0.0873398\n",
      "Validation loss decreased (0.076779 --> 0.076662).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0747868\n",
      "\tspeed: 0.0323s/iter; left time: 643.0898s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767990\n",
      "\tspeed: 0.0126s/iter; left time: 250.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0786772 Vali Loss: 0.0761316 Test Loss: 0.0871168\n",
      "Validation loss decreased (0.076662 --> 0.076132).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763483\n",
      "\tspeed: 0.0292s/iter; left time: 575.5384s\n",
      "\titers: 200, epoch: 13 | loss: 0.0806691\n",
      "\tspeed: 0.0119s/iter; left time: 232.6534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 225 | Train Loss: 0.0784107 Vali Loss: 0.0759851 Test Loss: 0.0868440\n",
      "Validation loss decreased (0.076132 --> 0.075985).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810251\n",
      "\tspeed: 0.0280s/iter; left time: 545.8384s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781442\n",
      "\tspeed: 0.0144s/iter; left time: 279.8245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0781160 Vali Loss: 0.0762808 Test Loss: 0.0871939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0731684\n",
      "\tspeed: 0.0293s/iter; left time: 563.2923s\n",
      "\titers: 200, epoch: 15 | loss: 0.0800549\n",
      "\tspeed: 0.0114s/iter; left time: 217.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0779006 Vali Loss: 0.0761531 Test Loss: 0.0868299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0808244\n",
      "\tspeed: 0.0282s/iter; left time: 535.8622s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744877\n",
      "\tspeed: 0.0121s/iter; left time: 229.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0776603 Vali Loss: 0.0759935 Test Loss: 0.0866621\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0797293\n",
      "\tspeed: 0.0351s/iter; left time: 660.5789s\n",
      "\titers: 200, epoch: 17 | loss: 0.0745371\n",
      "\tspeed: 0.0166s/iter; left time: 310.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 225 | Train Loss: 0.0774855 Vali Loss: 0.0758769 Test Loss: 0.0865073\n",
      "Validation loss decreased (0.075985 --> 0.075877).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0825204\n",
      "\tspeed: 0.0306s/iter; left time: 567.7591s\n",
      "\titers: 200, epoch: 18 | loss: 0.0759405\n",
      "\tspeed: 0.0110s/iter; left time: 203.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 225 | Train Loss: 0.0773324 Vali Loss: 0.0759104 Test Loss: 0.0866722\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0751155\n",
      "\tspeed: 0.0279s/iter; left time: 511.4307s\n",
      "\titers: 200, epoch: 19 | loss: 0.0759723\n",
      "\tspeed: 0.0126s/iter; left time: 229.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0771947 Vali Loss: 0.0758913 Test Loss: 0.0865089\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0770257\n",
      "\tspeed: 0.0271s/iter; left time: 490.9193s\n",
      "\titers: 200, epoch: 20 | loss: 0.0793783\n",
      "\tspeed: 0.0117s/iter; left time: 211.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 225 | Train Loss: 0.0770421 Vali Loss: 0.0759149 Test Loss: 0.0864828\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0808547\n",
      "\tspeed: 0.0325s/iter; left time: 581.6474s\n",
      "\titers: 200, epoch: 21 | loss: 0.0746658\n",
      "\tspeed: 0.0117s/iter; left time: 207.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0769642 Vali Loss: 0.0755270 Test Loss: 0.0862854\n",
      "Validation loss decreased (0.075877 --> 0.075527).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0799318\n",
      "\tspeed: 0.0300s/iter; left time: 529.7660s\n",
      "\titers: 200, epoch: 22 | loss: 0.0795009\n",
      "\tspeed: 0.0121s/iter; left time: 212.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0769058 Vali Loss: 0.0755863 Test Loss: 0.0861169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0806981\n",
      "\tspeed: 0.0276s/iter; left time: 481.9471s\n",
      "\titers: 200, epoch: 23 | loss: 0.0776285\n",
      "\tspeed: 0.0116s/iter; left time: 201.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 225 | Train Loss: 0.0767392 Vali Loss: 0.0755869 Test Loss: 0.0862814\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0757655\n",
      "\tspeed: 0.0292s/iter; left time: 503.2249s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774275\n",
      "\tspeed: 0.0116s/iter; left time: 198.3893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0766776 Vali Loss: 0.0756844 Test Loss: 0.0863970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0719616\n",
      "\tspeed: 0.0294s/iter; left time: 500.1217s\n",
      "\titers: 200, epoch: 25 | loss: 0.0789211\n",
      "\tspeed: 0.0115s/iter; left time: 193.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.0766260 Vali Loss: 0.0756459 Test Loss: 0.0862978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0750893\n",
      "\tspeed: 0.0280s/iter; left time: 469.5322s\n",
      "\titers: 200, epoch: 26 | loss: 0.0768932\n",
      "\tspeed: 0.0116s/iter; left time: 193.4952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 225 | Train Loss: 0.0765750 Vali Loss: 0.0754100 Test Loss: 0.0859953\n",
      "Validation loss decreased (0.075527 --> 0.075410).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0803022\n",
      "\tspeed: 0.0282s/iter; left time: 466.6631s\n",
      "\titers: 200, epoch: 27 | loss: 0.0765712\n",
      "\tspeed: 0.0122s/iter; left time: 201.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0764555 Vali Loss: 0.0756538 Test Loss: 0.0862654\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0799393\n",
      "\tspeed: 0.0319s/iter; left time: 520.0467s\n",
      "\titers: 200, epoch: 28 | loss: 0.0732785\n",
      "\tspeed: 0.0129s/iter; left time: 209.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0764959 Vali Loss: 0.0755844 Test Loss: 0.0862349\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0759135\n",
      "\tspeed: 0.0282s/iter; left time: 454.3806s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728304\n",
      "\tspeed: 0.0118s/iter; left time: 188.9390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 225 | Train Loss: 0.0763770 Vali Loss: 0.0755688 Test Loss: 0.0862012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0758216\n",
      "\tspeed: 0.0286s/iter; left time: 453.5418s\n",
      "\titers: 200, epoch: 30 | loss: 0.0788435\n",
      "\tspeed: 0.0122s/iter; left time: 193.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 225 | Train Loss: 0.0763523 Vali Loss: 0.0754775 Test Loss: 0.0861182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0740229\n",
      "\tspeed: 0.0326s/iter; left time: 509.6023s\n",
      "\titers: 200, epoch: 31 | loss: 0.0750465\n",
      "\tspeed: 0.0121s/iter; left time: 188.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0762969 Vali Loss: 0.0754892 Test Loss: 0.0860911\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0735503\n",
      "\tspeed: 0.0292s/iter; left time: 450.2291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0753440\n",
      "\tspeed: 0.0115s/iter; left time: 176.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 225 | Train Loss: 0.0762555 Vali Loss: 0.0753743 Test Loss: 0.0860091\n",
      "Validation loss decreased (0.075410 --> 0.075374).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0745924\n",
      "\tspeed: 0.0290s/iter; left time: 441.1284s\n",
      "\titers: 200, epoch: 33 | loss: 0.0805365\n",
      "\tspeed: 0.0129s/iter; left time: 195.3121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0762440 Vali Loss: 0.0754154 Test Loss: 0.0860034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0734176\n",
      "\tspeed: 0.0289s/iter; left time: 432.1467s\n",
      "\titers: 200, epoch: 34 | loss: 0.0756994\n",
      "\tspeed: 0.0121s/iter; left time: 180.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 225 | Train Loss: 0.0761795 Vali Loss: 0.0754332 Test Loss: 0.0861153\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0789745\n",
      "\tspeed: 0.0296s/iter; left time: 436.9366s\n",
      "\titers: 200, epoch: 35 | loss: 0.0763532\n",
      "\tspeed: 0.0154s/iter; left time: 225.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0761926 Vali Loss: 0.0754571 Test Loss: 0.0860438\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0762898\n",
      "\tspeed: 0.0288s/iter; left time: 418.2761s\n",
      "\titers: 200, epoch: 36 | loss: 0.0747354\n",
      "\tspeed: 0.0123s/iter; left time: 177.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 225 | Train Loss: 0.0761171 Vali Loss: 0.0755036 Test Loss: 0.0860654\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0761736\n",
      "\tspeed: 0.0277s/iter; left time: 396.2141s\n",
      "\titers: 200, epoch: 37 | loss: 0.0747050\n",
      "\tspeed: 0.0137s/iter; left time: 194.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 225 | Train Loss: 0.0761568 Vali Loss: 0.0753613 Test Loss: 0.0860309\n",
      "Validation loss decreased (0.075374 --> 0.075361).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0727366\n",
      "\tspeed: 0.0293s/iter; left time: 412.1367s\n",
      "\titers: 200, epoch: 38 | loss: 0.0777595\n",
      "\tspeed: 0.0129s/iter; left time: 180.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0761321 Vali Loss: 0.0753521 Test Loss: 0.0860522\n",
      "Validation loss decreased (0.075361 --> 0.075352).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0778039\n",
      "\tspeed: 0.0298s/iter; left time: 413.1627s\n",
      "\titers: 200, epoch: 39 | loss: 0.0722151\n",
      "\tspeed: 0.0128s/iter; left time: 176.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0760934 Vali Loss: 0.0754370 Test Loss: 0.0860848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0743089\n",
      "\tspeed: 0.0336s/iter; left time: 458.4894s\n",
      "\titers: 200, epoch: 40 | loss: 0.0775397\n",
      "\tspeed: 0.0140s/iter; left time: 188.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0760195 Vali Loss: 0.0753774 Test Loss: 0.0860355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0738335\n",
      "\tspeed: 0.0334s/iter; left time: 447.5114s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781013\n",
      "\tspeed: 0.0166s/iter; left time: 220.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0760308 Vali Loss: 0.0753938 Test Loss: 0.0860646\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0752735\n",
      "\tspeed: 0.0323s/iter; left time: 426.0101s\n",
      "\titers: 200, epoch: 42 | loss: 0.0769139\n",
      "\tspeed: 0.0115s/iter; left time: 150.9601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0760375 Vali Loss: 0.0753885 Test Loss: 0.0860948\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0789014\n",
      "\tspeed: 0.0278s/iter; left time: 359.7525s\n",
      "\titers: 200, epoch: 43 | loss: 0.0771543\n",
      "\tspeed: 0.0110s/iter; left time: 141.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 225 | Train Loss: 0.0760886 Vali Loss: 0.0754264 Test Loss: 0.0860126\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0794128\n",
      "\tspeed: 0.0305s/iter; left time: 388.6699s\n",
      "\titers: 200, epoch: 44 | loss: 0.0747860\n",
      "\tspeed: 0.0124s/iter; left time: 156.6997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 225 | Train Loss: 0.0760847 Vali Loss: 0.0753687 Test Loss: 0.0860298\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0770456\n",
      "\tspeed: 0.0286s/iter; left time: 357.1021s\n",
      "\titers: 200, epoch: 45 | loss: 0.0763281\n",
      "\tspeed: 0.0129s/iter; left time: 160.1738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 225 | Train Loss: 0.0760148 Vali Loss: 0.0753657 Test Loss: 0.0860127\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0800752\n",
      "\tspeed: 0.0316s/iter; left time: 387.8871s\n",
      "\titers: 200, epoch: 46 | loss: 0.0794832\n",
      "\tspeed: 0.0119s/iter; left time: 144.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 225 | Train Loss: 0.0760315 Vali Loss: 0.0753694 Test Loss: 0.0860104\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0796557\n",
      "\tspeed: 0.0317s/iter; left time: 382.5726s\n",
      "\titers: 200, epoch: 47 | loss: 0.0767693\n",
      "\tspeed: 0.0136s/iter; left time: 161.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0760123 Vali Loss: 0.0753986 Test Loss: 0.0860624\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0745895\n",
      "\tspeed: 0.0291s/iter; left time: 343.7544s\n",
      "\titers: 200, epoch: 48 | loss: 0.0807312\n",
      "\tspeed: 0.0126s/iter; left time: 147.4480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0760364 Vali Loss: 0.0753589 Test Loss: 0.0860535\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019077060744166374, rmse:0.13811972737312317, mae:0.08605219423770905, rse:0.4057542085647583\n",
      "Intermediate time for ES and pred_len 96: 00h:06m:52.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1568499\n",
      "\tspeed: 0.0381s/iter; left time: 853.6006s\n",
      "\titers: 200, epoch: 1 | loss: 0.1316590\n",
      "\tspeed: 0.0128s/iter; left time: 285.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.1573622 Vali Loss: 0.1235502 Test Loss: 0.1400854\n",
      "Validation loss decreased (inf --> 0.123550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1035424\n",
      "\tspeed: 0.0314s/iter; left time: 696.2753s\n",
      "\titers: 200, epoch: 2 | loss: 0.1005864\n",
      "\tspeed: 0.0122s/iter; left time: 270.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 225 | Train Loss: 0.1043460 Vali Loss: 0.0933807 Test Loss: 0.1052763\n",
      "Validation loss decreased (0.123550 --> 0.093381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0921834\n",
      "\tspeed: 0.0291s/iter; left time: 638.4836s\n",
      "\titers: 200, epoch: 3 | loss: 0.0943769\n",
      "\tspeed: 0.0138s/iter; left time: 301.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 225 | Train Loss: 0.0942344 Vali Loss: 0.0873603 Test Loss: 0.0990985\n",
      "Validation loss decreased (0.093381 --> 0.087360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907277\n",
      "\tspeed: 0.0332s/iter; left time: 720.7441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888133\n",
      "\tspeed: 0.0141s/iter; left time: 304.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0908532 Vali Loss: 0.0852744 Test Loss: 0.0964538\n",
      "Validation loss decreased (0.087360 --> 0.085274).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867176\n",
      "\tspeed: 0.0328s/iter; left time: 706.0179s\n",
      "\titers: 200, epoch: 5 | loss: 0.0870261\n",
      "\tspeed: 0.0137s/iter; left time: 293.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0889696 Vali Loss: 0.0843731 Test Loss: 0.0953252\n",
      "Validation loss decreased (0.085274 --> 0.084373).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0842111\n",
      "\tspeed: 0.0327s/iter; left time: 696.3192s\n",
      "\titers: 200, epoch: 6 | loss: 0.0886363\n",
      "\tspeed: 0.0137s/iter; left time: 289.3246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0875895 Vali Loss: 0.0837014 Test Loss: 0.0944848\n",
      "Validation loss decreased (0.084373 --> 0.083701).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0892857\n",
      "\tspeed: 0.0325s/iter; left time: 683.8164s\n",
      "\titers: 200, epoch: 7 | loss: 0.0852607\n",
      "\tspeed: 0.0141s/iter; left time: 296.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0865385 Vali Loss: 0.0830057 Test Loss: 0.0939623\n",
      "Validation loss decreased (0.083701 --> 0.083006).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0876576\n",
      "\tspeed: 0.0328s/iter; left time: 683.0705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0875875\n",
      "\tspeed: 0.0139s/iter; left time: 288.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0857704 Vali Loss: 0.0828423 Test Loss: 0.0935337\n",
      "Validation loss decreased (0.083006 --> 0.082842).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0869338\n",
      "\tspeed: 0.0333s/iter; left time: 686.7570s\n",
      "\titers: 200, epoch: 9 | loss: 0.0878397\n",
      "\tspeed: 0.0133s/iter; left time: 272.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0851366 Vali Loss: 0.0828146 Test Loss: 0.0935755\n",
      "Validation loss decreased (0.082842 --> 0.082815).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832062\n",
      "\tspeed: 0.0298s/iter; left time: 608.1331s\n",
      "\titers: 200, epoch: 10 | loss: 0.0817573\n",
      "\tspeed: 0.0143s/iter; left time: 289.2983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0846364 Vali Loss: 0.0826662 Test Loss: 0.0931646\n",
      "Validation loss decreased (0.082815 --> 0.082666).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0856273\n",
      "\tspeed: 0.0316s/iter; left time: 637.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0868291\n",
      "\tspeed: 0.0145s/iter; left time: 290.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0842443 Vali Loss: 0.0824437 Test Loss: 0.0931207\n",
      "Validation loss decreased (0.082666 --> 0.082444).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0871971\n",
      "\tspeed: 0.0311s/iter; left time: 620.3054s\n",
      "\titers: 200, epoch: 12 | loss: 0.0862963\n",
      "\tspeed: 0.0144s/iter; left time: 285.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0839270 Vali Loss: 0.0820603 Test Loss: 0.0927688\n",
      "Validation loss decreased (0.082444 --> 0.082060).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0827589\n",
      "\tspeed: 0.0322s/iter; left time: 633.7782s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821555\n",
      "\tspeed: 0.0140s/iter; left time: 275.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0836436 Vali Loss: 0.0825373 Test Loss: 0.0930180\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0816468\n",
      "\tspeed: 0.0305s/iter; left time: 594.9166s\n",
      "\titers: 200, epoch: 14 | loss: 0.0777866\n",
      "\tspeed: 0.0142s/iter; left time: 274.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 225 | Train Loss: 0.0833672 Vali Loss: 0.0822728 Test Loss: 0.0929308\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0817904\n",
      "\tspeed: 0.0316s/iter; left time: 608.8828s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814839\n",
      "\tspeed: 0.0151s/iter; left time: 289.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0831294 Vali Loss: 0.0823914 Test Loss: 0.0927944\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0831645\n",
      "\tspeed: 0.0281s/iter; left time: 534.4025s\n",
      "\titers: 200, epoch: 16 | loss: 0.0814912\n",
      "\tspeed: 0.0125s/iter; left time: 236.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0829364 Vali Loss: 0.0822596 Test Loss: 0.0928918\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0829945\n",
      "\tspeed: 0.0293s/iter; left time: 551.2159s\n",
      "\titers: 200, epoch: 17 | loss: 0.0866629\n",
      "\tspeed: 0.0124s/iter; left time: 231.6541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 225 | Train Loss: 0.0827697 Vali Loss: 0.0822756 Test Loss: 0.0927913\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0808619\n",
      "\tspeed: 0.0289s/iter; left time: 536.1474s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827853\n",
      "\tspeed: 0.0123s/iter; left time: 226.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 225 | Train Loss: 0.0825893 Vali Loss: 0.0821652 Test Loss: 0.0926397\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0829511\n",
      "\tspeed: 0.0302s/iter; left time: 554.6400s\n",
      "\titers: 200, epoch: 19 | loss: 0.0840674\n",
      "\tspeed: 0.0144s/iter; left time: 263.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0824541 Vali Loss: 0.0822779 Test Loss: 0.0930222\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0822663\n",
      "\tspeed: 0.0309s/iter; left time: 559.9971s\n",
      "\titers: 200, epoch: 20 | loss: 0.0844956\n",
      "\tspeed: 0.0139s/iter; left time: 249.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0823565 Vali Loss: 0.0822376 Test Loss: 0.0928995\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0786321\n",
      "\tspeed: 0.0304s/iter; left time: 543.4276s\n",
      "\titers: 200, epoch: 21 | loss: 0.0809851\n",
      "\tspeed: 0.0137s/iter; left time: 244.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0822532 Vali Loss: 0.0821607 Test Loss: 0.0927439\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0797071\n",
      "\tspeed: 0.0305s/iter; left time: 538.3366s\n",
      "\titers: 200, epoch: 22 | loss: 0.0842925\n",
      "\tspeed: 0.0144s/iter; left time: 252.2247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0821002 Vali Loss: 0.0822368 Test Loss: 0.0929710\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021398216485977173, rmse:0.14628128707408905, mae:0.09276880323886871, rse:0.42976129055023193\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1665550\n",
      "\tspeed: 0.0171s/iter; left time: 383.3097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1342119\n",
      "\tspeed: 0.0155s/iter; left time: 345.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.59s\n",
      "Steps: 225 | Train Loss: 0.1595942 Vali Loss: 0.1252286 Test Loss: 0.1425784\n",
      "Validation loss decreased (inf --> 0.125229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1071426\n",
      "\tspeed: 0.0318s/iter; left time: 705.9752s\n",
      "\titers: 200, epoch: 2 | loss: 0.0988839\n",
      "\tspeed: 0.0144s/iter; left time: 316.7955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.1038184 Vali Loss: 0.0923388 Test Loss: 0.1043468\n",
      "Validation loss decreased (0.125229 --> 0.092339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954366\n",
      "\tspeed: 0.0328s/iter; left time: 720.6446s\n",
      "\titers: 200, epoch: 3 | loss: 0.0929098\n",
      "\tspeed: 0.0141s/iter; left time: 307.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0936030 Vali Loss: 0.0874168 Test Loss: 0.0985869\n",
      "Validation loss decreased (0.092339 --> 0.087417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919800\n",
      "\tspeed: 0.0328s/iter; left time: 712.6136s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923115\n",
      "\tspeed: 0.0140s/iter; left time: 302.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0906089 Vali Loss: 0.0856613 Test Loss: 0.0964879\n",
      "Validation loss decreased (0.087417 --> 0.085661).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887270\n",
      "\tspeed: 0.0319s/iter; left time: 686.2710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917832\n",
      "\tspeed: 0.0149s/iter; left time: 319.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0887391 Vali Loss: 0.0848867 Test Loss: 0.0954072\n",
      "Validation loss decreased (0.085661 --> 0.084887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0873320\n",
      "\tspeed: 0.0322s/iter; left time: 685.0572s\n",
      "\titers: 200, epoch: 6 | loss: 0.0866217\n",
      "\tspeed: 0.0141s/iter; left time: 298.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0875130 Vali Loss: 0.0838974 Test Loss: 0.0948258\n",
      "Validation loss decreased (0.084887 --> 0.083897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0856005\n",
      "\tspeed: 0.0316s/iter; left time: 665.8393s\n",
      "\titers: 200, epoch: 7 | loss: 0.0889447\n",
      "\tspeed: 0.0143s/iter; left time: 299.9235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0866496 Vali Loss: 0.0836268 Test Loss: 0.0943554\n",
      "Validation loss decreased (0.083897 --> 0.083627).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0852821\n",
      "\tspeed: 0.0336s/iter; left time: 698.7176s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845993\n",
      "\tspeed: 0.0161s/iter; left time: 333.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0859998 Vali Loss: 0.0833807 Test Loss: 0.0940453\n",
      "Validation loss decreased (0.083627 --> 0.083381).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0903444\n",
      "\tspeed: 0.0305s/iter; left time: 628.0585s\n",
      "\titers: 200, epoch: 9 | loss: 0.0831527\n",
      "\tspeed: 0.0122s/iter; left time: 249.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 225 | Train Loss: 0.0854311 Vali Loss: 0.0835337 Test Loss: 0.0938182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0861049\n",
      "\tspeed: 0.0310s/iter; left time: 631.4107s\n",
      "\titers: 200, epoch: 10 | loss: 0.0856074\n",
      "\tspeed: 0.0130s/iter; left time: 264.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 225 | Train Loss: 0.0849855 Vali Loss: 0.0832467 Test Loss: 0.0936491\n",
      "Validation loss decreased (0.083381 --> 0.083247).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0823327\n",
      "\tspeed: 0.0299s/iter; left time: 603.0824s\n",
      "\titers: 200, epoch: 11 | loss: 0.0823785\n",
      "\tspeed: 0.0136s/iter; left time: 272.2093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 225 | Train Loss: 0.0845717 Vali Loss: 0.0834375 Test Loss: 0.0938023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0852507\n",
      "\tspeed: 0.0306s/iter; left time: 610.6626s\n",
      "\titers: 200, epoch: 12 | loss: 0.0844938\n",
      "\tspeed: 0.0131s/iter; left time: 260.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0841896 Vali Loss: 0.0829765 Test Loss: 0.0932096\n",
      "Validation loss decreased (0.083247 --> 0.082976).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0808426\n",
      "\tspeed: 0.0333s/iter; left time: 656.3417s\n",
      "\titers: 200, epoch: 13 | loss: 0.0806663\n",
      "\tspeed: 0.0167s/iter; left time: 327.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0839008 Vali Loss: 0.0827313 Test Loss: 0.0932784\n",
      "Validation loss decreased (0.082976 --> 0.082731).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0810001\n",
      "\tspeed: 0.0325s/iter; left time: 632.8474s\n",
      "\titers: 200, epoch: 14 | loss: 0.0829864\n",
      "\tspeed: 0.0134s/iter; left time: 259.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0836157 Vali Loss: 0.0822975 Test Loss: 0.0925756\n",
      "Validation loss decreased (0.082731 --> 0.082298).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0856069\n",
      "\tspeed: 0.0336s/iter; left time: 646.3278s\n",
      "\titers: 200, epoch: 15 | loss: 0.0858787\n",
      "\tspeed: 0.0138s/iter; left time: 264.6898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0833859 Vali Loss: 0.0826017 Test Loss: 0.0927973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0810837\n",
      "\tspeed: 0.0321s/iter; left time: 610.0693s\n",
      "\titers: 200, epoch: 16 | loss: 0.0873101\n",
      "\tspeed: 0.0139s/iter; left time: 262.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0832361 Vali Loss: 0.0825363 Test Loss: 0.0927583\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0846607\n",
      "\tspeed: 0.0319s/iter; left time: 598.8119s\n",
      "\titers: 200, epoch: 17 | loss: 0.0821061\n",
      "\tspeed: 0.0150s/iter; left time: 281.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.65s\n",
      "Steps: 225 | Train Loss: 0.0830506 Vali Loss: 0.0828263 Test Loss: 0.0932079\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0788185\n",
      "\tspeed: 0.0334s/iter; left time: 620.2452s\n",
      "\titers: 200, epoch: 18 | loss: 0.0828428\n",
      "\tspeed: 0.0138s/iter; left time: 255.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 225 | Train Loss: 0.0828306 Vali Loss: 0.0825819 Test Loss: 0.0928293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0817331\n",
      "\tspeed: 0.0304s/iter; left time: 558.5909s\n",
      "\titers: 200, epoch: 19 | loss: 0.0834585\n",
      "\tspeed: 0.0134s/iter; left time: 245.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0827299 Vali Loss: 0.0825543 Test Loss: 0.0930653\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0806477\n",
      "\tspeed: 0.0298s/iter; left time: 540.3614s\n",
      "\titers: 200, epoch: 20 | loss: 0.0841569\n",
      "\tspeed: 0.0147s/iter; left time: 264.0877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0826318 Vali Loss: 0.0825693 Test Loss: 0.0926642\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0823159\n",
      "\tspeed: 0.0311s/iter; left time: 556.3385s\n",
      "\titers: 200, epoch: 21 | loss: 0.0850630\n",
      "\tspeed: 0.0157s/iter; left time: 280.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0824663 Vali Loss: 0.0825424 Test Loss: 0.0927273\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0775800\n",
      "\tspeed: 0.0318s/iter; left time: 562.2015s\n",
      "\titers: 200, epoch: 22 | loss: 0.0822026\n",
      "\tspeed: 0.0134s/iter; left time: 235.9942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 225 | Train Loss: 0.0823799 Vali Loss: 0.0825105 Test Loss: 0.0927264\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0850594\n",
      "\tspeed: 0.0313s/iter; left time: 545.4146s\n",
      "\titers: 200, epoch: 23 | loss: 0.0854007\n",
      "\tspeed: 0.0148s/iter; left time: 257.1360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0822438 Vali Loss: 0.0825739 Test Loss: 0.0928915\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0819938\n",
      "\tspeed: 0.0318s/iter; left time: 548.4068s\n",
      "\titers: 200, epoch: 24 | loss: 0.0815709\n",
      "\tspeed: 0.0136s/iter; left time: 232.0669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0821720 Vali Loss: 0.0823585 Test Loss: 0.0925500\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02151847630739212, rmse:0.14669176936149597, mae:0.09257563203573227, rse:0.43096721172332764\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:42.31s\n",
      "Intermediate time for ES: 00h:18m:31.27s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1076997\n",
      "\tspeed: 0.0366s/iter; left time: 822.6094s\n",
      "\titers: 200, epoch: 1 | loss: 0.0844932\n",
      "\tspeed: 0.0120s/iter; left time: 267.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.1071305 Vali Loss: 0.0901043 Test Loss: 0.0994532\n",
      "Validation loss decreased (inf --> 0.090104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561477\n",
      "\tspeed: 0.0277s/iter; left time: 615.9330s\n",
      "\titers: 200, epoch: 2 | loss: 0.0513192\n",
      "\tspeed: 0.0130s/iter; left time: 287.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0585561 Vali Loss: 0.0592476 Test Loss: 0.0617865\n",
      "Validation loss decreased (0.090104 --> 0.059248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513508\n",
      "\tspeed: 0.0291s/iter; left time: 642.1081s\n",
      "\titers: 200, epoch: 3 | loss: 0.0479516\n",
      "\tspeed: 0.0128s/iter; left time: 281.1625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0507629 Vali Loss: 0.0568690 Test Loss: 0.0597648\n",
      "Validation loss decreased (0.059248 --> 0.056869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0521114\n",
      "\tspeed: 0.0289s/iter; left time: 631.1283s\n",
      "\titers: 200, epoch: 4 | loss: 0.0502443\n",
      "\tspeed: 0.0111s/iter; left time: 240.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0488265 Vali Loss: 0.0553084 Test Loss: 0.0585132\n",
      "Validation loss decreased (0.056869 --> 0.055308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0463736\n",
      "\tspeed: 0.0269s/iter; left time: 582.0012s\n",
      "\titers: 200, epoch: 5 | loss: 0.0434525\n",
      "\tspeed: 0.0115s/iter; left time: 247.6833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0475343 Vali Loss: 0.0543128 Test Loss: 0.0578031\n",
      "Validation loss decreased (0.055308 --> 0.054313).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460580\n",
      "\tspeed: 0.0264s/iter; left time: 563.7507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0450222\n",
      "\tspeed: 0.0112s/iter; left time: 238.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0466277 Vali Loss: 0.0534805 Test Loss: 0.0573687\n",
      "Validation loss decreased (0.054313 --> 0.053480).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0470545\n",
      "\tspeed: 0.0273s/iter; left time: 577.0121s\n",
      "\titers: 200, epoch: 7 | loss: 0.0459243\n",
      "\tspeed: 0.0134s/iter; left time: 282.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0458450 Vali Loss: 0.0528845 Test Loss: 0.0568669\n",
      "Validation loss decreased (0.053480 --> 0.052884).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0449147\n",
      "\tspeed: 0.0286s/iter; left time: 598.4418s\n",
      "\titers: 200, epoch: 8 | loss: 0.0446093\n",
      "\tspeed: 0.0121s/iter; left time: 252.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0452563 Vali Loss: 0.0526112 Test Loss: 0.0566168\n",
      "Validation loss decreased (0.052884 --> 0.052611).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0432319\n",
      "\tspeed: 0.0289s/iter; left time: 597.5363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445187\n",
      "\tspeed: 0.0134s/iter; left time: 276.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0447915 Vali Loss: 0.0519764 Test Loss: 0.0564366\n",
      "Validation loss decreased (0.052611 --> 0.051976).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0441739\n",
      "\tspeed: 0.0284s/iter; left time: 581.9944s\n",
      "\titers: 200, epoch: 10 | loss: 0.0453514\n",
      "\tspeed: 0.0111s/iter; left time: 225.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0443843 Vali Loss: 0.0517694 Test Loss: 0.0559094\n",
      "Validation loss decreased (0.051976 --> 0.051769).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0440916\n",
      "\tspeed: 0.0287s/iter; left time: 580.5034s\n",
      "\titers: 200, epoch: 11 | loss: 0.0410351\n",
      "\tspeed: 0.0130s/iter; left time: 261.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 226 | Train Loss: 0.0440559 Vali Loss: 0.0514138 Test Loss: 0.0556246\n",
      "Validation loss decreased (0.051769 --> 0.051414).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0477772\n",
      "\tspeed: 0.0277s/iter; left time: 554.8615s\n",
      "\titers: 200, epoch: 12 | loss: 0.0450721\n",
      "\tspeed: 0.0112s/iter; left time: 222.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0437628 Vali Loss: 0.0512534 Test Loss: 0.0554950\n",
      "Validation loss decreased (0.051414 --> 0.051253).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0407731\n",
      "\tspeed: 0.0260s/iter; left time: 514.7758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0449747\n",
      "\tspeed: 0.0109s/iter; left time: 215.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 226 | Train Loss: 0.0434858 Vali Loss: 0.0510212 Test Loss: 0.0552484\n",
      "Validation loss decreased (0.051253 --> 0.051021).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0429213\n",
      "\tspeed: 0.0290s/iter; left time: 566.4141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441765\n",
      "\tspeed: 0.0119s/iter; left time: 231.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0432644 Vali Loss: 0.0510122 Test Loss: 0.0552304\n",
      "Validation loss decreased (0.051021 --> 0.051012).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0418309\n",
      "\tspeed: 0.0284s/iter; left time: 549.5122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0407279\n",
      "\tspeed: 0.0119s/iter; left time: 229.4668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0430998 Vali Loss: 0.0508352 Test Loss: 0.0550930\n",
      "Validation loss decreased (0.051012 --> 0.050835).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0448649\n",
      "\tspeed: 0.0265s/iter; left time: 506.1767s\n",
      "\titers: 200, epoch: 16 | loss: 0.0415453\n",
      "\tspeed: 0.0116s/iter; left time: 220.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0428707 Vali Loss: 0.0507972 Test Loss: 0.0549450\n",
      "Validation loss decreased (0.050835 --> 0.050797).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0412447\n",
      "\tspeed: 0.0284s/iter; left time: 536.5456s\n",
      "\titers: 200, epoch: 17 | loss: 0.0421428\n",
      "\tspeed: 0.0124s/iter; left time: 233.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0427756 Vali Loss: 0.0509308 Test Loss: 0.0550025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0438714\n",
      "\tspeed: 0.0317s/iter; left time: 591.5384s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411248\n",
      "\tspeed: 0.0116s/iter; left time: 214.6642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.26s\n",
      "Steps: 226 | Train Loss: 0.0427111 Vali Loss: 0.0506774 Test Loss: 0.0549089\n",
      "Validation loss decreased (0.050797 --> 0.050677).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0438699\n",
      "\tspeed: 0.0279s/iter; left time: 514.4521s\n",
      "\titers: 200, epoch: 19 | loss: 0.0439883\n",
      "\tspeed: 0.0120s/iter; left time: 219.2189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0425621 Vali Loss: 0.0504781 Test Loss: 0.0547615\n",
      "Validation loss decreased (0.050677 --> 0.050478).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443324\n",
      "\tspeed: 0.0284s/iter; left time: 517.3331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0498845\n",
      "\tspeed: 0.0132s/iter; left time: 238.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0424116 Vali Loss: 0.0505399 Test Loss: 0.0547433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0421793\n",
      "\tspeed: 0.0311s/iter; left time: 559.8406s\n",
      "\titers: 200, epoch: 21 | loss: 0.0429938\n",
      "\tspeed: 0.0119s/iter; left time: 212.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0423381 Vali Loss: 0.0505695 Test Loss: 0.0546886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0414619\n",
      "\tspeed: 0.0274s/iter; left time: 486.8265s\n",
      "\titers: 200, epoch: 22 | loss: 0.0428697\n",
      "\tspeed: 0.0109s/iter; left time: 193.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0423087 Vali Loss: 0.0504615 Test Loss: 0.0547043\n",
      "Validation loss decreased (0.050478 --> 0.050462).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0432623\n",
      "\tspeed: 0.0273s/iter; left time: 478.8892s\n",
      "\titers: 200, epoch: 23 | loss: 0.0416626\n",
      "\tspeed: 0.0132s/iter; left time: 230.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0422408 Vali Loss: 0.0504132 Test Loss: 0.0545935\n",
      "Validation loss decreased (0.050462 --> 0.050413).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0429033\n",
      "\tspeed: 0.0276s/iter; left time: 478.1290s\n",
      "\titers: 200, epoch: 24 | loss: 0.0424754\n",
      "\tspeed: 0.0126s/iter; left time: 216.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0422113 Vali Loss: 0.0503552 Test Loss: 0.0545690\n",
      "Validation loss decreased (0.050413 --> 0.050355).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0423113\n",
      "\tspeed: 0.0304s/iter; left time: 518.4762s\n",
      "\titers: 200, epoch: 25 | loss: 0.0433888\n",
      "\tspeed: 0.0114s/iter; left time: 193.2392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0421563 Vali Loss: 0.0502765 Test Loss: 0.0544758\n",
      "Validation loss decreased (0.050355 --> 0.050276).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0431847\n",
      "\tspeed: 0.0268s/iter; left time: 451.9787s\n",
      "\titers: 200, epoch: 26 | loss: 0.0440871\n",
      "\tspeed: 0.0124s/iter; left time: 208.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0420852 Vali Loss: 0.0502675 Test Loss: 0.0544903\n",
      "Validation loss decreased (0.050276 --> 0.050267).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0451052\n",
      "\tspeed: 0.0275s/iter; left time: 457.9538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0414471\n",
      "\tspeed: 0.0127s/iter; left time: 209.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0420029 Vali Loss: 0.0502640 Test Loss: 0.0544903\n",
      "Validation loss decreased (0.050267 --> 0.050264).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0410312\n",
      "\tspeed: 0.0275s/iter; left time: 451.0224s\n",
      "\titers: 200, epoch: 28 | loss: 0.0397029\n",
      "\tspeed: 0.0112s/iter; left time: 181.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0420169 Vali Loss: 0.0502905 Test Loss: 0.0544227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0439552\n",
      "\tspeed: 0.0268s/iter; left time: 434.0147s\n",
      "\titers: 200, epoch: 29 | loss: 0.0436785\n",
      "\tspeed: 0.0121s/iter; left time: 194.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0420040 Vali Loss: 0.0502262 Test Loss: 0.0544775\n",
      "Validation loss decreased (0.050264 --> 0.050226).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0386494\n",
      "\tspeed: 0.0273s/iter; left time: 435.8998s\n",
      "\titers: 200, epoch: 30 | loss: 0.0414599\n",
      "\tspeed: 0.0114s/iter; left time: 180.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0419425 Vali Loss: 0.0501913 Test Loss: 0.0544087\n",
      "Validation loss decreased (0.050226 --> 0.050191).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0415383\n",
      "\tspeed: 0.0284s/iter; left time: 446.9521s\n",
      "\titers: 200, epoch: 31 | loss: 0.0454751\n",
      "\tspeed: 0.0122s/iter; left time: 190.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0419474 Vali Loss: 0.0501453 Test Loss: 0.0544220\n",
      "Validation loss decreased (0.050191 --> 0.050145).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0417625\n",
      "\tspeed: 0.0254s/iter; left time: 393.5596s\n",
      "\titers: 200, epoch: 32 | loss: 0.0423680\n",
      "\tspeed: 0.0114s/iter; left time: 175.3526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 226 | Train Loss: 0.0418900 Vali Loss: 0.0501593 Test Loss: 0.0543905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0450227\n",
      "\tspeed: 0.0287s/iter; left time: 438.5214s\n",
      "\titers: 200, epoch: 33 | loss: 0.0442311\n",
      "\tspeed: 0.0111s/iter; left time: 168.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0418550 Vali Loss: 0.0501616 Test Loss: 0.0544021\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0403130\n",
      "\tspeed: 0.0265s/iter; left time: 398.1377s\n",
      "\titers: 200, epoch: 34 | loss: 0.0437343\n",
      "\tspeed: 0.0123s/iter; left time: 184.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0418723 Vali Loss: 0.0501117 Test Loss: 0.0543684\n",
      "Validation loss decreased (0.050145 --> 0.050112).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0398785\n",
      "\tspeed: 0.0289s/iter; left time: 428.2609s\n",
      "\titers: 200, epoch: 35 | loss: 0.0417303\n",
      "\tspeed: 0.0115s/iter; left time: 169.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0418444 Vali Loss: 0.0501631 Test Loss: 0.0543461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0433487\n",
      "\tspeed: 0.0281s/iter; left time: 409.7674s\n",
      "\titers: 200, epoch: 36 | loss: 0.0434720\n",
      "\tspeed: 0.0119s/iter; left time: 172.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0417718 Vali Loss: 0.0501187 Test Loss: 0.0543627\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0401681\n",
      "\tspeed: 0.0268s/iter; left time: 385.0938s\n",
      "\titers: 200, epoch: 37 | loss: 0.0441142\n",
      "\tspeed: 0.0115s/iter; left time: 164.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 226 | Train Loss: 0.0417959 Vali Loss: 0.0501724 Test Loss: 0.0543492\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0411178\n",
      "\tspeed: 0.0272s/iter; left time: 384.8570s\n",
      "\titers: 200, epoch: 38 | loss: 0.0432949\n",
      "\tspeed: 0.0118s/iter; left time: 164.9964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0417960 Vali Loss: 0.0501164 Test Loss: 0.0543611\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0413207\n",
      "\tspeed: 0.0268s/iter; left time: 373.2222s\n",
      "\titers: 200, epoch: 39 | loss: 0.0395798\n",
      "\tspeed: 0.0134s/iter; left time: 185.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0417862 Vali Loss: 0.0501370 Test Loss: 0.0543230\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0393236\n",
      "\tspeed: 0.0276s/iter; left time: 378.2623s\n",
      "\titers: 200, epoch: 40 | loss: 0.0432977\n",
      "\tspeed: 0.0140s/iter; left time: 190.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0417697 Vali Loss: 0.0501129 Test Loss: 0.0543245\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0413589\n",
      "\tspeed: 0.0276s/iter; left time: 371.8289s\n",
      "\titers: 200, epoch: 41 | loss: 0.0408612\n",
      "\tspeed: 0.0118s/iter; left time: 157.1315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0417722 Vali Loss: 0.0501124 Test Loss: 0.0543231\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0411079\n",
      "\tspeed: 0.0275s/iter; left time: 364.1753s\n",
      "\titers: 200, epoch: 42 | loss: 0.0426689\n",
      "\tspeed: 0.0134s/iter; left time: 175.4101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0417917 Vali Loss: 0.0500473 Test Loss: 0.0543122\n",
      "Validation loss decreased (0.050112 --> 0.050047).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0426921\n",
      "\tspeed: 0.0298s/iter; left time: 387.4994s\n",
      "\titers: 200, epoch: 43 | loss: 0.0417973\n",
      "\tspeed: 0.0127s/iter; left time: 164.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0417330 Vali Loss: 0.0501269 Test Loss: 0.0543233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0460333\n",
      "\tspeed: 0.0263s/iter; left time: 336.7133s\n",
      "\titers: 200, epoch: 44 | loss: 0.0428604\n",
      "\tspeed: 0.0118s/iter; left time: 149.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0417183 Vali Loss: 0.0500891 Test Loss: 0.0543393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0413917\n",
      "\tspeed: 0.0278s/iter; left time: 349.1030s\n",
      "\titers: 200, epoch: 45 | loss: 0.0451330\n",
      "\tspeed: 0.0121s/iter; left time: 150.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0417131 Vali Loss: 0.0501954 Test Loss: 0.0542969\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0412224\n",
      "\tspeed: 0.0257s/iter; left time: 317.2667s\n",
      "\titers: 200, epoch: 46 | loss: 0.0388272\n",
      "\tspeed: 0.0122s/iter; left time: 149.6360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 226 | Train Loss: 0.0417154 Vali Loss: 0.0500848 Test Loss: 0.0543053\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0411421\n",
      "\tspeed: 0.0256s/iter; left time: 309.2963s\n",
      "\titers: 200, epoch: 47 | loss: 0.0433625\n",
      "\tspeed: 0.0123s/iter; left time: 147.1452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0416896 Vali Loss: 0.0500637 Test Loss: 0.0543185\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0429682\n",
      "\tspeed: 0.0280s/iter; left time: 332.5864s\n",
      "\titers: 200, epoch: 48 | loss: 0.0388278\n",
      "\tspeed: 0.0115s/iter; left time: 135.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0417241 Vali Loss: 0.0501448 Test Loss: 0.0543115\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0408700\n",
      "\tspeed: 0.0274s/iter; left time: 318.8413s\n",
      "\titers: 200, epoch: 49 | loss: 0.0415598\n",
      "\tspeed: 0.0126s/iter; left time: 145.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0417560 Vali Loss: 0.0500766 Test Loss: 0.0543064\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0433627\n",
      "\tspeed: 0.0270s/iter; left time: 307.9947s\n",
      "\titers: 200, epoch: 50 | loss: 0.0431110\n",
      "\tspeed: 0.0123s/iter; left time: 139.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 226 | Train Loss: 0.0417134 Vali Loss: 0.0501223 Test Loss: 0.0543024\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0428324\n",
      "\tspeed: 0.0267s/iter; left time: 298.6868s\n",
      "\titers: 200, epoch: 51 | loss: 0.0426559\n",
      "\tspeed: 0.0122s/iter; left time: 134.8948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0417224 Vali Loss: 0.0500905 Test Loss: 0.0542994\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0420346\n",
      "\tspeed: 0.0272s/iter; left time: 298.8920s\n",
      "\titers: 200, epoch: 52 | loss: 0.0446948\n",
      "\tspeed: 0.0113s/iter; left time: 122.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 226 | Train Loss: 0.0417438 Vali Loss: 0.0500549 Test Loss: 0.0543111\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009950376115739346, rmse:0.09975156933069229, mae:0.05431215465068817, rse:0.3848387897014618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1132520\n",
      "\tspeed: 0.0132s/iter; left time: 297.2207s\n",
      "\titers: 200, epoch: 1 | loss: 0.0936352\n",
      "\tspeed: 0.0115s/iter; left time: 257.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.1100713 Vali Loss: 0.0928013 Test Loss: 0.1021270\n",
      "Validation loss decreased (inf --> 0.092801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0561683\n",
      "\tspeed: 0.0279s/iter; left time: 621.7909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0500469\n",
      "\tspeed: 0.0119s/iter; left time: 263.9628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0584609 Vali Loss: 0.0593945 Test Loss: 0.0617017\n",
      "Validation loss decreased (0.092801 --> 0.059395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0524821\n",
      "\tspeed: 0.0300s/iter; left time: 661.1010s\n",
      "\titers: 200, epoch: 3 | loss: 0.0518600\n",
      "\tspeed: 0.0117s/iter; left time: 257.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0507010 Vali Loss: 0.0567825 Test Loss: 0.0595066\n",
      "Validation loss decreased (0.059395 --> 0.056782).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0513417\n",
      "\tspeed: 0.0290s/iter; left time: 632.3452s\n",
      "\titers: 200, epoch: 4 | loss: 0.0476954\n",
      "\tspeed: 0.0115s/iter; left time: 250.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0487247 Vali Loss: 0.0548968 Test Loss: 0.0583465\n",
      "Validation loss decreased (0.056782 --> 0.054897).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0463436\n",
      "\tspeed: 0.0274s/iter; left time: 591.8462s\n",
      "\titers: 200, epoch: 5 | loss: 0.0457454\n",
      "\tspeed: 0.0131s/iter; left time: 280.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0475371 Vali Loss: 0.0540130 Test Loss: 0.0578556\n",
      "Validation loss decreased (0.054897 --> 0.054013).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0482146\n",
      "\tspeed: 0.0287s/iter; left time: 613.4564s\n",
      "\titers: 200, epoch: 6 | loss: 0.0426126\n",
      "\tspeed: 0.0118s/iter; left time: 249.9885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 226 | Train Loss: 0.0466017 Vali Loss: 0.0535288 Test Loss: 0.0573014\n",
      "Validation loss decreased (0.054013 --> 0.053529).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0471374\n",
      "\tspeed: 0.0281s/iter; left time: 594.3587s\n",
      "\titers: 200, epoch: 7 | loss: 0.0462750\n",
      "\tspeed: 0.0129s/iter; left time: 271.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0458805 Vali Loss: 0.0530002 Test Loss: 0.0569769\n",
      "Validation loss decreased (0.053529 --> 0.053000).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0432870\n",
      "\tspeed: 0.0327s/iter; left time: 683.8869s\n",
      "\titers: 200, epoch: 8 | loss: 0.0464771\n",
      "\tspeed: 0.0157s/iter; left time: 327.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0453083 Vali Loss: 0.0525476 Test Loss: 0.0566880\n",
      "Validation loss decreased (0.053000 --> 0.052548).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0439847\n",
      "\tspeed: 0.0334s/iter; left time: 690.6590s\n",
      "\titers: 200, epoch: 9 | loss: 0.0429174\n",
      "\tspeed: 0.0119s/iter; left time: 244.4898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0448298 Vali Loss: 0.0522136 Test Loss: 0.0562477\n",
      "Validation loss decreased (0.052548 --> 0.052214).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0473599\n",
      "\tspeed: 0.0308s/iter; left time: 629.5455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0475908\n",
      "\tspeed: 0.0141s/iter; left time: 288.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0443794 Vali Loss: 0.0519422 Test Loss: 0.0561186\n",
      "Validation loss decreased (0.052214 --> 0.051942).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0444583\n",
      "\tspeed: 0.0281s/iter; left time: 567.8487s\n",
      "\titers: 200, epoch: 11 | loss: 0.0427089\n",
      "\tspeed: 0.0138s/iter; left time: 277.9358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0440518 Vali Loss: 0.0515362 Test Loss: 0.0558749\n",
      "Validation loss decreased (0.051942 --> 0.051536).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0448553\n",
      "\tspeed: 0.0275s/iter; left time: 550.6003s\n",
      "\titers: 200, epoch: 12 | loss: 0.0447962\n",
      "\tspeed: 0.0109s/iter; left time: 217.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0438076 Vali Loss: 0.0513053 Test Loss: 0.0556109\n",
      "Validation loss decreased (0.051536 --> 0.051305).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434728\n",
      "\tspeed: 0.0278s/iter; left time: 550.7100s\n",
      "\titers: 200, epoch: 13 | loss: 0.0442762\n",
      "\tspeed: 0.0111s/iter; left time: 219.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0434890 Vali Loss: 0.0513953 Test Loss: 0.0555171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0443075\n",
      "\tspeed: 0.0261s/iter; left time: 509.9389s\n",
      "\titers: 200, epoch: 14 | loss: 0.0430610\n",
      "\tspeed: 0.0115s/iter; left time: 224.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 226 | Train Loss: 0.0432744 Vali Loss: 0.0510744 Test Loss: 0.0554607\n",
      "Validation loss decreased (0.051305 --> 0.051074).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0478131\n",
      "\tspeed: 0.0278s/iter; left time: 538.2221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0429646\n",
      "\tspeed: 0.0122s/iter; left time: 235.0548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0430683 Vali Loss: 0.0510316 Test Loss: 0.0552032\n",
      "Validation loss decreased (0.051074 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0433127\n",
      "\tspeed: 0.0278s/iter; left time: 530.7388s\n",
      "\titers: 200, epoch: 16 | loss: 0.0383054\n",
      "\tspeed: 0.0116s/iter; left time: 220.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 226 | Train Loss: 0.0430262 Vali Loss: 0.0509267 Test Loss: 0.0551992\n",
      "Validation loss decreased (0.051032 --> 0.050927).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0434445\n",
      "\tspeed: 0.0290s/iter; left time: 547.1359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0434979\n",
      "\tspeed: 0.0119s/iter; left time: 223.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0427973 Vali Loss: 0.0510822 Test Loss: 0.0551089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0394827\n",
      "\tspeed: 0.0273s/iter; left time: 509.1593s\n",
      "\titers: 200, epoch: 18 | loss: 0.0379569\n",
      "\tspeed: 0.0114s/iter; left time: 211.1277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0426730 Vali Loss: 0.0507940 Test Loss: 0.0550116\n",
      "Validation loss decreased (0.050927 --> 0.050794).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458686\n",
      "\tspeed: 0.0291s/iter; left time: 536.9927s\n",
      "\titers: 200, epoch: 19 | loss: 0.0403266\n",
      "\tspeed: 0.0116s/iter; left time: 212.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 226 | Train Loss: 0.0425948 Vali Loss: 0.0506898 Test Loss: 0.0550069\n",
      "Validation loss decreased (0.050794 --> 0.050690).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0466481\n",
      "\tspeed: 0.0285s/iter; left time: 518.3718s\n",
      "\titers: 200, epoch: 20 | loss: 0.0429751\n",
      "\tspeed: 0.0122s/iter; left time: 220.2748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0425307 Vali Loss: 0.0506668 Test Loss: 0.0549237\n",
      "Validation loss decreased (0.050690 --> 0.050667).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0463741\n",
      "\tspeed: 0.0276s/iter; left time: 496.2116s\n",
      "\titers: 200, epoch: 21 | loss: 0.0434584\n",
      "\tspeed: 0.0125s/iter; left time: 223.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 226 | Train Loss: 0.0424368 Vali Loss: 0.0507159 Test Loss: 0.0549146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0432137\n",
      "\tspeed: 0.0270s/iter; left time: 478.9800s\n",
      "\titers: 200, epoch: 22 | loss: 0.0440204\n",
      "\tspeed: 0.0135s/iter; left time: 239.1491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0423375 Vali Loss: 0.0507138 Test Loss: 0.0549455\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0391456\n",
      "\tspeed: 0.0269s/iter; left time: 471.1515s\n",
      "\titers: 200, epoch: 23 | loss: 0.0456504\n",
      "\tspeed: 0.0127s/iter; left time: 221.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0423303 Vali Loss: 0.0505761 Test Loss: 0.0547516\n",
      "Validation loss decreased (0.050667 --> 0.050576).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0495292\n",
      "\tspeed: 0.0277s/iter; left time: 479.3011s\n",
      "\titers: 200, epoch: 24 | loss: 0.0441425\n",
      "\tspeed: 0.0131s/iter; left time: 225.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0422179 Vali Loss: 0.0504646 Test Loss: 0.0548036\n",
      "Validation loss decreased (0.050576 --> 0.050465).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0434198\n",
      "\tspeed: 0.0265s/iter; left time: 453.2344s\n",
      "\titers: 200, epoch: 25 | loss: 0.0399199\n",
      "\tspeed: 0.0117s/iter; left time: 198.7763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0421116 Vali Loss: 0.0505635 Test Loss: 0.0547086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0391855\n",
      "\tspeed: 0.0289s/iter; left time: 486.2451s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404929\n",
      "\tspeed: 0.0113s/iter; left time: 189.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 226 | Train Loss: 0.0420860 Vali Loss: 0.0504334 Test Loss: 0.0546581\n",
      "Validation loss decreased (0.050465 --> 0.050433).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0421239\n",
      "\tspeed: 0.0288s/iter; left time: 479.4316s\n",
      "\titers: 200, epoch: 27 | loss: 0.0430600\n",
      "\tspeed: 0.0117s/iter; left time: 193.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0420590 Vali Loss: 0.0504060 Test Loss: 0.0546327\n",
      "Validation loss decreased (0.050433 --> 0.050406).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0418076\n",
      "\tspeed: 0.0262s/iter; left time: 429.7771s\n",
      "\titers: 200, epoch: 28 | loss: 0.0465923\n",
      "\tspeed: 0.0110s/iter; left time: 179.8877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 226 | Train Loss: 0.0420133 Vali Loss: 0.0503824 Test Loss: 0.0546185\n",
      "Validation loss decreased (0.050406 --> 0.050382).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0430298\n",
      "\tspeed: 0.0268s/iter; left time: 433.2265s\n",
      "\titers: 200, epoch: 29 | loss: 0.0435396\n",
      "\tspeed: 0.0116s/iter; left time: 187.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 226 | Train Loss: 0.0419836 Vali Loss: 0.0504460 Test Loss: 0.0546655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0395162\n",
      "\tspeed: 0.0268s/iter; left time: 427.9269s\n",
      "\titers: 200, epoch: 30 | loss: 0.0399079\n",
      "\tspeed: 0.0130s/iter; left time: 205.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0419524 Vali Loss: 0.0503811 Test Loss: 0.0545891\n",
      "Validation loss decreased (0.050382 --> 0.050381).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0434384\n",
      "\tspeed: 0.0285s/iter; left time: 447.4180s\n",
      "\titers: 200, epoch: 31 | loss: 0.0422784\n",
      "\tspeed: 0.0114s/iter; left time: 177.7662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 226 | Train Loss: 0.0419383 Vali Loss: 0.0504887 Test Loss: 0.0545525\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0440265\n",
      "\tspeed: 0.0284s/iter; left time: 440.6071s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421281\n",
      "\tspeed: 0.0110s/iter; left time: 169.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418608 Vali Loss: 0.0503399 Test Loss: 0.0545567\n",
      "Validation loss decreased (0.050381 --> 0.050340).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0409427\n",
      "\tspeed: 0.0294s/iter; left time: 449.6261s\n",
      "\titers: 200, epoch: 33 | loss: 0.0411612\n",
      "\tspeed: 0.0126s/iter; left time: 191.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 226 | Train Loss: 0.0419174 Vali Loss: 0.0503196 Test Loss: 0.0545303\n",
      "Validation loss decreased (0.050340 --> 0.050320).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0402150\n",
      "\tspeed: 0.0267s/iter; left time: 401.9880s\n",
      "\titers: 200, epoch: 34 | loss: 0.0400097\n",
      "\tspeed: 0.0131s/iter; left time: 195.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0418580 Vali Loss: 0.0503860 Test Loss: 0.0545335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0419727\n",
      "\tspeed: 0.0287s/iter; left time: 424.6724s\n",
      "\titers: 200, epoch: 35 | loss: 0.0405766\n",
      "\tspeed: 0.0123s/iter; left time: 180.5289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418350 Vali Loss: 0.0503724 Test Loss: 0.0545397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0433877\n",
      "\tspeed: 0.0278s/iter; left time: 405.8178s\n",
      "\titers: 200, epoch: 36 | loss: 0.0435869\n",
      "\tspeed: 0.0116s/iter; left time: 168.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 226 | Train Loss: 0.0417693 Vali Loss: 0.0502802 Test Loss: 0.0544944\n",
      "Validation loss decreased (0.050320 --> 0.050280).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0458055\n",
      "\tspeed: 0.0283s/iter; left time: 405.9492s\n",
      "\titers: 200, epoch: 37 | loss: 0.0446754\n",
      "\tspeed: 0.0119s/iter; left time: 169.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 226 | Train Loss: 0.0418336 Vali Loss: 0.0503019 Test Loss: 0.0545030\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0411173\n",
      "\tspeed: 0.0282s/iter; left time: 398.5139s\n",
      "\titers: 200, epoch: 38 | loss: 0.0411220\n",
      "\tspeed: 0.0133s/iter; left time: 186.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0418050 Vali Loss: 0.0503602 Test Loss: 0.0544847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0413137\n",
      "\tspeed: 0.0278s/iter; left time: 387.2038s\n",
      "\titers: 200, epoch: 39 | loss: 0.0416295\n",
      "\tspeed: 0.0125s/iter; left time: 172.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0417889 Vali Loss: 0.0503047 Test Loss: 0.0544787\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0432878\n",
      "\tspeed: 0.0281s/iter; left time: 384.8453s\n",
      "\titers: 200, epoch: 40 | loss: 0.0432607\n",
      "\tspeed: 0.0111s/iter; left time: 150.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 226 | Train Loss: 0.0417856 Vali Loss: 0.0502169 Test Loss: 0.0544858\n",
      "Validation loss decreased (0.050280 --> 0.050217).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0388566\n",
      "\tspeed: 0.0297s/iter; left time: 399.2168s\n",
      "\titers: 200, epoch: 41 | loss: 0.0415661\n",
      "\tspeed: 0.0135s/iter; left time: 180.3718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.28s\n",
      "Steps: 226 | Train Loss: 0.0417968 Vali Loss: 0.0503313 Test Loss: 0.0544953\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0421035\n",
      "\tspeed: 0.0279s/iter; left time: 368.7326s\n",
      "\titers: 200, epoch: 42 | loss: 0.0378885\n",
      "\tspeed: 0.0117s/iter; left time: 154.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0417965 Vali Loss: 0.0501956 Test Loss: 0.0544790\n",
      "Validation loss decreased (0.050217 --> 0.050196).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0376006\n",
      "\tspeed: 0.0267s/iter; left time: 347.5844s\n",
      "\titers: 200, epoch: 43 | loss: 0.0401736\n",
      "\tspeed: 0.0114s/iter; left time: 146.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.69s\n",
      "Steps: 226 | Train Loss: 0.0417676 Vali Loss: 0.0502214 Test Loss: 0.0544823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0423001\n",
      "\tspeed: 0.0292s/iter; left time: 372.6998s\n",
      "\titers: 200, epoch: 44 | loss: 0.0432456\n",
      "\tspeed: 0.0123s/iter; left time: 155.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 226 | Train Loss: 0.0417521 Vali Loss: 0.0502241 Test Loss: 0.0544708\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0473008\n",
      "\tspeed: 0.0268s/iter; left time: 336.7709s\n",
      "\titers: 200, epoch: 45 | loss: 0.0419766\n",
      "\tspeed: 0.0125s/iter; left time: 155.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 226 | Train Loss: 0.0417417 Vali Loss: 0.0502226 Test Loss: 0.0544550\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0400830\n",
      "\tspeed: 0.0257s/iter; left time: 316.9914s\n",
      "\titers: 200, epoch: 46 | loss: 0.0410218\n",
      "\tspeed: 0.0109s/iter; left time: 132.8488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.68s\n",
      "Steps: 226 | Train Loss: 0.0417677 Vali Loss: 0.0502597 Test Loss: 0.0544538\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0393896\n",
      "\tspeed: 0.0263s/iter; left time: 318.7374s\n",
      "\titers: 200, epoch: 47 | loss: 0.0409002\n",
      "\tspeed: 0.0120s/iter; left time: 144.0154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 226 | Train Loss: 0.0417359 Vali Loss: 0.0502057 Test Loss: 0.0544625\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0393750\n",
      "\tspeed: 0.0262s/iter; left time: 311.5134s\n",
      "\titers: 200, epoch: 48 | loss: 0.0431451\n",
      "\tspeed: 0.0119s/iter; left time: 140.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 226 | Train Loss: 0.0417638 Vali Loss: 0.0502611 Test Loss: 0.0544590\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0408053\n",
      "\tspeed: 0.0261s/iter; left time: 303.7718s\n",
      "\titers: 200, epoch: 49 | loss: 0.0423045\n",
      "\tspeed: 0.0117s/iter; left time: 135.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 226 | Train Loss: 0.0417316 Vali Loss: 0.0502708 Test Loss: 0.0544587\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0426644\n",
      "\tspeed: 0.0275s/iter; left time: 313.6911s\n",
      "\titers: 200, epoch: 50 | loss: 0.0394742\n",
      "\tspeed: 0.0124s/iter; left time: 140.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0417384 Vali Loss: 0.0502756 Test Loss: 0.0544553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0417658\n",
      "\tspeed: 0.0281s/iter; left time: 315.2885s\n",
      "\titers: 200, epoch: 51 | loss: 0.0443871\n",
      "\tspeed: 0.0110s/iter; left time: 121.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 226 | Train Loss: 0.0417456 Vali Loss: 0.0502617 Test Loss: 0.0544569\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0391585\n",
      "\tspeed: 0.0267s/iter; left time: 293.0616s\n",
      "\titers: 200, epoch: 52 | loss: 0.0424905\n",
      "\tspeed: 0.0127s/iter; left time: 138.5199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0417283 Vali Loss: 0.0502521 Test Loss: 0.0544676\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009985145181417465, rmse:0.099925696849823, mae:0.05447903648018837, rse:0.3855105936527252\n",
      "Intermediate time for FR and pred_len 24: 00h:07m:07.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1123679\n",
      "\tspeed: 0.0368s/iter; left time: 823.6254s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958893\n",
      "\tspeed: 0.0191s/iter; left time: 424.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.1128916 Vali Loss: 0.0989846 Test Loss: 0.1113308\n",
      "Validation loss decreased (inf --> 0.098985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745022\n",
      "\tspeed: 0.0299s/iter; left time: 663.2570s\n",
      "\titers: 200, epoch: 2 | loss: 0.0712615\n",
      "\tspeed: 0.0155s/iter; left time: 343.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0742915 Vali Loss: 0.0767684 Test Loss: 0.0858899\n",
      "Validation loss decreased (0.098985 --> 0.076768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0659868\n",
      "\tspeed: 0.0292s/iter; left time: 640.4535s\n",
      "\titers: 200, epoch: 3 | loss: 0.0683075\n",
      "\tspeed: 0.0142s/iter; left time: 309.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 225 | Train Loss: 0.0667917 Vali Loss: 0.0733530 Test Loss: 0.0831187\n",
      "Validation loss decreased (0.076768 --> 0.073353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611087\n",
      "\tspeed: 0.0294s/iter; left time: 639.5643s\n",
      "\titers: 200, epoch: 4 | loss: 0.0628312\n",
      "\tspeed: 0.0154s/iter; left time: 333.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.0646899 Vali Loss: 0.0722058 Test Loss: 0.0819560\n",
      "Validation loss decreased (0.073353 --> 0.072206).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643648\n",
      "\tspeed: 0.0304s/iter; left time: 653.2929s\n",
      "\titers: 200, epoch: 5 | loss: 0.0637357\n",
      "\tspeed: 0.0140s/iter; left time: 300.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 225 | Train Loss: 0.0635126 Vali Loss: 0.0712091 Test Loss: 0.0811195\n",
      "Validation loss decreased (0.072206 --> 0.071209).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619154\n",
      "\tspeed: 0.0295s/iter; left time: 627.6468s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602226\n",
      "\tspeed: 0.0145s/iter; left time: 306.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.44s\n",
      "Steps: 225 | Train Loss: 0.0626181 Vali Loss: 0.0708816 Test Loss: 0.0805953\n",
      "Validation loss decreased (0.071209 --> 0.070882).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0573235\n",
      "\tspeed: 0.0315s/iter; left time: 662.3238s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595317\n",
      "\tspeed: 0.0144s/iter; left time: 301.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 225 | Train Loss: 0.0619120 Vali Loss: 0.0703958 Test Loss: 0.0801718\n",
      "Validation loss decreased (0.070882 --> 0.070396).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658628\n",
      "\tspeed: 0.0313s/iter; left time: 652.1954s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633189\n",
      "\tspeed: 0.0138s/iter; left time: 286.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0613964 Vali Loss: 0.0702106 Test Loss: 0.0801473\n",
      "Validation loss decreased (0.070396 --> 0.070211).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600250\n",
      "\tspeed: 0.0294s/iter; left time: 605.1540s\n",
      "\titers: 200, epoch: 9 | loss: 0.0614435\n",
      "\tspeed: 0.0146s/iter; left time: 298.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0609292 Vali Loss: 0.0699040 Test Loss: 0.0799337\n",
      "Validation loss decreased (0.070211 --> 0.069904).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612160\n",
      "\tspeed: 0.0299s/iter; left time: 610.1638s\n",
      "\titers: 200, epoch: 10 | loss: 0.0641046\n",
      "\tspeed: 0.0140s/iter; left time: 284.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0605648 Vali Loss: 0.0696879 Test Loss: 0.0796519\n",
      "Validation loss decreased (0.069904 --> 0.069688).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595196\n",
      "\tspeed: 0.0293s/iter; left time: 591.3284s\n",
      "\titers: 200, epoch: 11 | loss: 0.0624229\n",
      "\tspeed: 0.0135s/iter; left time: 270.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0602561 Vali Loss: 0.0694851 Test Loss: 0.0793414\n",
      "Validation loss decreased (0.069688 --> 0.069485).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0597834\n",
      "\tspeed: 0.0298s/iter; left time: 593.3318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628897\n",
      "\tspeed: 0.0145s/iter; left time: 286.8973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.0599916 Vali Loss: 0.0693257 Test Loss: 0.0792334\n",
      "Validation loss decreased (0.069485 --> 0.069326).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0558545\n",
      "\tspeed: 0.0301s/iter; left time: 592.0259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0633420\n",
      "\tspeed: 0.0146s/iter; left time: 286.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0597048 Vali Loss: 0.0692271 Test Loss: 0.0793881\n",
      "Validation loss decreased (0.069326 --> 0.069227).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0623547\n",
      "\tspeed: 0.0304s/iter; left time: 591.3906s\n",
      "\titers: 200, epoch: 14 | loss: 0.0607159\n",
      "\tspeed: 0.0148s/iter; left time: 286.5679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0595040 Vali Loss: 0.0691486 Test Loss: 0.0791799\n",
      "Validation loss decreased (0.069227 --> 0.069149).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574526\n",
      "\tspeed: 0.0282s/iter; left time: 542.7165s\n",
      "\titers: 200, epoch: 15 | loss: 0.0585850\n",
      "\tspeed: 0.0125s/iter; left time: 239.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 225 | Train Loss: 0.0592926 Vali Loss: 0.0690939 Test Loss: 0.0789895\n",
      "Validation loss decreased (0.069149 --> 0.069094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0594159\n",
      "\tspeed: 0.0278s/iter; left time: 528.4335s\n",
      "\titers: 200, epoch: 16 | loss: 0.0593273\n",
      "\tspeed: 0.0131s/iter; left time: 247.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 225 | Train Loss: 0.0591808 Vali Loss: 0.0690333 Test Loss: 0.0789739\n",
      "Validation loss decreased (0.069094 --> 0.069033).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0589404\n",
      "\tspeed: 0.0312s/iter; left time: 586.7048s\n",
      "\titers: 200, epoch: 17 | loss: 0.0600491\n",
      "\tspeed: 0.0145s/iter; left time: 271.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0589729 Vali Loss: 0.0689332 Test Loss: 0.0788983\n",
      "Validation loss decreased (0.069033 --> 0.068933).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0599934\n",
      "\tspeed: 0.0300s/iter; left time: 556.4016s\n",
      "\titers: 200, epoch: 18 | loss: 0.0601626\n",
      "\tspeed: 0.0142s/iter; left time: 262.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0588744 Vali Loss: 0.0689585 Test Loss: 0.0789438\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0574171\n",
      "\tspeed: 0.0301s/iter; left time: 552.2804s\n",
      "\titers: 200, epoch: 19 | loss: 0.0597989\n",
      "\tspeed: 0.0142s/iter; left time: 259.8038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0587569 Vali Loss: 0.0688923 Test Loss: 0.0789166\n",
      "Validation loss decreased (0.068933 --> 0.068892).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0599075\n",
      "\tspeed: 0.0318s/iter; left time: 576.1903s\n",
      "\titers: 200, epoch: 20 | loss: 0.0607334\n",
      "\tspeed: 0.0144s/iter; left time: 260.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 225 | Train Loss: 0.0586495 Vali Loss: 0.0688203 Test Loss: 0.0789143\n",
      "Validation loss decreased (0.068892 --> 0.068820).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0559591\n",
      "\tspeed: 0.0300s/iter; left time: 537.8844s\n",
      "\titers: 200, epoch: 21 | loss: 0.0560985\n",
      "\tspeed: 0.0136s/iter; left time: 242.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 225 | Train Loss: 0.0585981 Vali Loss: 0.0689306 Test Loss: 0.0788465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0595138\n",
      "\tspeed: 0.0290s/iter; left time: 512.5853s\n",
      "\titers: 200, epoch: 22 | loss: 0.0625688\n",
      "\tspeed: 0.0151s/iter; left time: 265.3506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.0584874 Vali Loss: 0.0688657 Test Loss: 0.0787652\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0635147\n",
      "\tspeed: 0.0295s/iter; left time: 515.2432s\n",
      "\titers: 200, epoch: 23 | loss: 0.0556708\n",
      "\tspeed: 0.0137s/iter; left time: 237.6141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0584421 Vali Loss: 0.0688052 Test Loss: 0.0788075\n",
      "Validation loss decreased (0.068820 --> 0.068805).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0591203\n",
      "\tspeed: 0.0308s/iter; left time: 530.1169s\n",
      "\titers: 200, epoch: 24 | loss: 0.0588287\n",
      "\tspeed: 0.0145s/iter; left time: 247.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 225 | Train Loss: 0.0583241 Vali Loss: 0.0688512 Test Loss: 0.0787713\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0583268\n",
      "\tspeed: 0.0289s/iter; left time: 491.5857s\n",
      "\titers: 200, epoch: 25 | loss: 0.0582507\n",
      "\tspeed: 0.0149s/iter; left time: 252.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0583419 Vali Loss: 0.0687748 Test Loss: 0.0787924\n",
      "Validation loss decreased (0.068805 --> 0.068775).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0603914\n",
      "\tspeed: 0.0310s/iter; left time: 519.6890s\n",
      "\titers: 200, epoch: 26 | loss: 0.0552229\n",
      "\tspeed: 0.0158s/iter; left time: 263.1600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 225 | Train Loss: 0.0582278 Vali Loss: 0.0688510 Test Loss: 0.0787250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0577940\n",
      "\tspeed: 0.0299s/iter; left time: 495.3489s\n",
      "\titers: 200, epoch: 27 | loss: 0.0601696\n",
      "\tspeed: 0.0150s/iter; left time: 246.5478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0582012 Vali Loss: 0.0688192 Test Loss: 0.0786948\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578605\n",
      "\tspeed: 0.0294s/iter; left time: 480.7478s\n",
      "\titers: 200, epoch: 28 | loss: 0.0600844\n",
      "\tspeed: 0.0147s/iter; left time: 238.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0581673 Vali Loss: 0.0688492 Test Loss: 0.0787168\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0583453\n",
      "\tspeed: 0.0299s/iter; left time: 480.8207s\n",
      "\titers: 200, epoch: 29 | loss: 0.0567716\n",
      "\tspeed: 0.0155s/iter; left time: 247.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0581208 Vali Loss: 0.0688215 Test Loss: 0.0787646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0565776\n",
      "\tspeed: 0.0270s/iter; left time: 428.6058s\n",
      "\titers: 200, epoch: 30 | loss: 0.0572355\n",
      "\tspeed: 0.0122s/iter; left time: 191.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 225 | Train Loss: 0.0581081 Vali Loss: 0.0688053 Test Loss: 0.0787088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0574476\n",
      "\tspeed: 0.0281s/iter; left time: 439.2139s\n",
      "\titers: 200, epoch: 31 | loss: 0.0602526\n",
      "\tspeed: 0.0118s/iter; left time: 183.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0580495 Vali Loss: 0.0688045 Test Loss: 0.0786794\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0563497\n",
      "\tspeed: 0.0262s/iter; left time: 404.6826s\n",
      "\titers: 200, epoch: 32 | loss: 0.0547948\n",
      "\tspeed: 0.0159s/iter; left time: 243.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0580019 Vali Loss: 0.0688197 Test Loss: 0.0786736\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0594476\n",
      "\tspeed: 0.0313s/iter; left time: 475.3239s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562596\n",
      "\tspeed: 0.0155s/iter; left time: 233.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0580157 Vali Loss: 0.0687966 Test Loss: 0.0787213\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0581558\n",
      "\tspeed: 0.0301s/iter; left time: 450.2101s\n",
      "\titers: 200, epoch: 34 | loss: 0.0557810\n",
      "\tspeed: 0.0138s/iter; left time: 205.9344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 225 | Train Loss: 0.0579935 Vali Loss: 0.0687963 Test Loss: 0.0786681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0563106\n",
      "\tspeed: 0.0292s/iter; left time: 430.2525s\n",
      "\titers: 200, epoch: 35 | loss: 0.0524707\n",
      "\tspeed: 0.0144s/iter; left time: 211.2295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0579753 Vali Loss: 0.0687898 Test Loss: 0.0786819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0190742090344429, rmse:0.13810941576957703, mae:0.07879239320755005, rse:0.5342438817024231\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1166308\n",
      "\tspeed: 0.0159s/iter; left time: 355.2066s\n",
      "\titers: 200, epoch: 1 | loss: 0.0994046\n",
      "\tspeed: 0.0146s/iter; left time: 326.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 225 | Train Loss: 0.1117094 Vali Loss: 0.0984777 Test Loss: 0.1107020\n",
      "Validation loss decreased (inf --> 0.098478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0687049\n",
      "\tspeed: 0.0310s/iter; left time: 688.1168s\n",
      "\titers: 200, epoch: 2 | loss: 0.0646807\n",
      "\tspeed: 0.0152s/iter; left time: 334.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0741771 Vali Loss: 0.0772416 Test Loss: 0.0861534\n",
      "Validation loss decreased (0.098478 --> 0.077242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0712700\n",
      "\tspeed: 0.0307s/iter; left time: 674.4700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663007\n",
      "\tspeed: 0.0142s/iter; left time: 310.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0670107 Vali Loss: 0.0735325 Test Loss: 0.0832724\n",
      "Validation loss decreased (0.077242 --> 0.073533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0639523\n",
      "\tspeed: 0.0304s/iter; left time: 660.3264s\n",
      "\titers: 200, epoch: 4 | loss: 0.0674347\n",
      "\tspeed: 0.0146s/iter; left time: 315.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0648524 Vali Loss: 0.0721268 Test Loss: 0.0823177\n",
      "Validation loss decreased (0.073533 --> 0.072127).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0598700\n",
      "\tspeed: 0.0316s/iter; left time: 680.2964s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624903\n",
      "\tspeed: 0.0137s/iter; left time: 292.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.0635970 Vali Loss: 0.0713102 Test Loss: 0.0813186\n",
      "Validation loss decreased (0.072127 --> 0.071310).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572047\n",
      "\tspeed: 0.0304s/iter; left time: 647.7199s\n",
      "\titers: 200, epoch: 6 | loss: 0.0654277\n",
      "\tspeed: 0.0137s/iter; left time: 290.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0626289 Vali Loss: 0.0707619 Test Loss: 0.0812851\n",
      "Validation loss decreased (0.071310 --> 0.070762).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0640521\n",
      "\tspeed: 0.0322s/iter; left time: 677.7879s\n",
      "\titers: 200, epoch: 7 | loss: 0.0631458\n",
      "\tspeed: 0.0140s/iter; left time: 292.7822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.55s\n",
      "Steps: 225 | Train Loss: 0.0619283 Vali Loss: 0.0702095 Test Loss: 0.0806952\n",
      "Validation loss decreased (0.070762 --> 0.070209).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0586155\n",
      "\tspeed: 0.0303s/iter; left time: 630.4248s\n",
      "\titers: 200, epoch: 8 | loss: 0.0610592\n",
      "\tspeed: 0.0125s/iter; left time: 259.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.22s\n",
      "Steps: 225 | Train Loss: 0.0613886 Vali Loss: 0.0699927 Test Loss: 0.0804892\n",
      "Validation loss decreased (0.070209 --> 0.069993).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0590662\n",
      "\tspeed: 0.0295s/iter; left time: 607.9826s\n",
      "\titers: 200, epoch: 9 | loss: 0.0599735\n",
      "\tspeed: 0.0135s/iter; left time: 276.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 225 | Train Loss: 0.0609320 Vali Loss: 0.0695000 Test Loss: 0.0799430\n",
      "Validation loss decreased (0.069993 --> 0.069500).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586988\n",
      "\tspeed: 0.0293s/iter; left time: 597.5257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605690\n",
      "\tspeed: 0.0121s/iter; left time: 245.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 225 | Train Loss: 0.0605663 Vali Loss: 0.0694764 Test Loss: 0.0797163\n",
      "Validation loss decreased (0.069500 --> 0.069476).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579402\n",
      "\tspeed: 0.0278s/iter; left time: 560.6244s\n",
      "\titers: 200, epoch: 11 | loss: 0.0572975\n",
      "\tspeed: 0.0127s/iter; left time: 254.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0602539 Vali Loss: 0.0695163 Test Loss: 0.0795091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0620443\n",
      "\tspeed: 0.0278s/iter; left time: 554.5792s\n",
      "\titers: 200, epoch: 12 | loss: 0.0597114\n",
      "\tspeed: 0.0126s/iter; left time: 249.0868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 225 | Train Loss: 0.0599766 Vali Loss: 0.0692275 Test Loss: 0.0796349\n",
      "Validation loss decreased (0.069476 --> 0.069227).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0643581\n",
      "\tspeed: 0.0307s/iter; left time: 604.3868s\n",
      "\titers: 200, epoch: 13 | loss: 0.0598506\n",
      "\tspeed: 0.0127s/iter; left time: 249.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 225 | Train Loss: 0.0596898 Vali Loss: 0.0689855 Test Loss: 0.0796881\n",
      "Validation loss decreased (0.069227 --> 0.068986).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0596512\n",
      "\tspeed: 0.0287s/iter; left time: 558.9535s\n",
      "\titers: 200, epoch: 14 | loss: 0.0564288\n",
      "\tspeed: 0.0193s/iter; left time: 374.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0595472 Vali Loss: 0.0690365 Test Loss: 0.0794910\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0556980\n",
      "\tspeed: 0.0384s/iter; left time: 739.9536s\n",
      "\titers: 200, epoch: 15 | loss: 0.0596696\n",
      "\tspeed: 0.0159s/iter; left time: 303.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0593626 Vali Loss: 0.0688358 Test Loss: 0.0795370\n",
      "Validation loss decreased (0.068986 --> 0.068836).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0549609\n",
      "\tspeed: 0.0346s/iter; left time: 658.5274s\n",
      "\titers: 200, epoch: 16 | loss: 0.0632015\n",
      "\tspeed: 0.0176s/iter; left time: 333.0713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0592233 Vali Loss: 0.0688676 Test Loss: 0.0792973\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562952\n",
      "\tspeed: 0.0360s/iter; left time: 676.4448s\n",
      "\titers: 200, epoch: 17 | loss: 0.0567398\n",
      "\tspeed: 0.0190s/iter; left time: 355.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0590819 Vali Loss: 0.0688663 Test Loss: 0.0794996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0627169\n",
      "\tspeed: 0.0368s/iter; left time: 683.1355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0635834\n",
      "\tspeed: 0.0186s/iter; left time: 343.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0588690 Vali Loss: 0.0687865 Test Loss: 0.0791472\n",
      "Validation loss decreased (0.068836 --> 0.068786).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0616352\n",
      "\tspeed: 0.0353s/iter; left time: 648.4132s\n",
      "\titers: 200, epoch: 19 | loss: 0.0590960\n",
      "\tspeed: 0.0164s/iter; left time: 298.7639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0588683 Vali Loss: 0.0687898 Test Loss: 0.0792912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0610490\n",
      "\tspeed: 0.0321s/iter; left time: 582.4944s\n",
      "\titers: 200, epoch: 20 | loss: 0.0584898\n",
      "\tspeed: 0.0136s/iter; left time: 245.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 225 | Train Loss: 0.0587853 Vali Loss: 0.0687302 Test Loss: 0.0791306\n",
      "Validation loss decreased (0.068786 --> 0.068730).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0583889\n",
      "\tspeed: 0.0369s/iter; left time: 661.3062s\n",
      "\titers: 200, epoch: 21 | loss: 0.0628211\n",
      "\tspeed: 0.0122s/iter; left time: 217.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 225 | Train Loss: 0.0586868 Vali Loss: 0.0687014 Test Loss: 0.0791981\n",
      "Validation loss decreased (0.068730 --> 0.068701).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0587090\n",
      "\tspeed: 0.0343s/iter; left time: 605.6964s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551478\n",
      "\tspeed: 0.0176s/iter; left time: 309.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0585566 Vali Loss: 0.0686361 Test Loss: 0.0792414\n",
      "Validation loss decreased (0.068701 --> 0.068636).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0580032\n",
      "\tspeed: 0.0365s/iter; left time: 636.1141s\n",
      "\titers: 200, epoch: 23 | loss: 0.0596124\n",
      "\tspeed: 0.0216s/iter; left time: 375.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0585786 Vali Loss: 0.0686573 Test Loss: 0.0791250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0593962\n",
      "\tspeed: 0.0341s/iter; left time: 586.5833s\n",
      "\titers: 200, epoch: 24 | loss: 0.0610090\n",
      "\tspeed: 0.0186s/iter; left time: 317.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0584186 Vali Loss: 0.0686477 Test Loss: 0.0791397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0564482\n",
      "\tspeed: 0.0344s/iter; left time: 584.3063s\n",
      "\titers: 200, epoch: 25 | loss: 0.0560195\n",
      "\tspeed: 0.0201s/iter; left time: 339.9757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0583797 Vali Loss: 0.0685837 Test Loss: 0.0791009\n",
      "Validation loss decreased (0.068636 --> 0.068584).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0605035\n",
      "\tspeed: 0.0330s/iter; left time: 553.4683s\n",
      "\titers: 200, epoch: 26 | loss: 0.0577445\n",
      "\tspeed: 0.0185s/iter; left time: 308.7116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0583410 Vali Loss: 0.0685910 Test Loss: 0.0791649\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0584437\n",
      "\tspeed: 0.0342s/iter; left time: 565.2720s\n",
      "\titers: 200, epoch: 27 | loss: 0.0561151\n",
      "\tspeed: 0.0183s/iter; left time: 300.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0582971 Vali Loss: 0.0685541 Test Loss: 0.0791507\n",
      "Validation loss decreased (0.068584 --> 0.068554).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0558530\n",
      "\tspeed: 0.0352s/iter; left time: 573.8647s\n",
      "\titers: 200, epoch: 28 | loss: 0.0564394\n",
      "\tspeed: 0.0171s/iter; left time: 277.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0582924 Vali Loss: 0.0686031 Test Loss: 0.0790981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0609890\n",
      "\tspeed: 0.0321s/iter; left time: 516.7603s\n",
      "\titers: 200, epoch: 29 | loss: 0.0533565\n",
      "\tspeed: 0.0162s/iter; left time: 259.1166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0582134 Vali Loss: 0.0685947 Test Loss: 0.0790453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0584938\n",
      "\tspeed: 0.0349s/iter; left time: 553.8667s\n",
      "\titers: 200, epoch: 30 | loss: 0.0573765\n",
      "\tspeed: 0.0175s/iter; left time: 276.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0582150 Vali Loss: 0.0685356 Test Loss: 0.0789865\n",
      "Validation loss decreased (0.068554 --> 0.068536).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0600751\n",
      "\tspeed: 0.0314s/iter; left time: 490.7125s\n",
      "\titers: 200, epoch: 31 | loss: 0.0535122\n",
      "\tspeed: 0.0156s/iter; left time: 242.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.42s\n",
      "Steps: 225 | Train Loss: 0.0581959 Vali Loss: 0.0685362 Test Loss: 0.0790093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0585135\n",
      "\tspeed: 0.0328s/iter; left time: 506.1256s\n",
      "\titers: 200, epoch: 32 | loss: 0.0575287\n",
      "\tspeed: 0.0189s/iter; left time: 289.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0581202 Vali Loss: 0.0685129 Test Loss: 0.0790591\n",
      "Validation loss decreased (0.068536 --> 0.068513).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0580706\n",
      "\tspeed: 0.0356s/iter; left time: 541.7282s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604630\n",
      "\tspeed: 0.0184s/iter; left time: 278.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0581116 Vali Loss: 0.0685235 Test Loss: 0.0790510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0582404\n",
      "\tspeed: 0.0341s/iter; left time: 511.3092s\n",
      "\titers: 200, epoch: 34 | loss: 0.0577914\n",
      "\tspeed: 0.0210s/iter; left time: 312.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0580539 Vali Loss: 0.0685138 Test Loss: 0.0790187\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0584563\n",
      "\tspeed: 0.0364s/iter; left time: 536.4841s\n",
      "\titers: 200, epoch: 35 | loss: 0.0595547\n",
      "\tspeed: 0.0155s/iter; left time: 227.8006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0580781 Vali Loss: 0.0685244 Test Loss: 0.0790781\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0601649\n",
      "\tspeed: 0.0338s/iter; left time: 491.5926s\n",
      "\titers: 200, epoch: 36 | loss: 0.0602529\n",
      "\tspeed: 0.0210s/iter; left time: 303.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0580418 Vali Loss: 0.0685017 Test Loss: 0.0790352\n",
      "Validation loss decreased (0.068513 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0571623\n",
      "\tspeed: 0.0419s/iter; left time: 598.8166s\n",
      "\titers: 200, epoch: 37 | loss: 0.0578815\n",
      "\tspeed: 0.0212s/iter; left time: 300.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 225 | Train Loss: 0.0580344 Vali Loss: 0.0685067 Test Loss: 0.0790283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0573594\n",
      "\tspeed: 0.0360s/iter; left time: 507.2722s\n",
      "\titers: 200, epoch: 38 | loss: 0.0590343\n",
      "\tspeed: 0.0158s/iter; left time: 221.1354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0580271 Vali Loss: 0.0685113 Test Loss: 0.0789837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0553383\n",
      "\tspeed: 0.0376s/iter; left time: 520.1840s\n",
      "\titers: 200, epoch: 39 | loss: 0.0529877\n",
      "\tspeed: 0.0152s/iter; left time: 208.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0580175 Vali Loss: 0.0685062 Test Loss: 0.0790252\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0592485\n",
      "\tspeed: 0.0342s/iter; left time: 465.9658s\n",
      "\titers: 200, epoch: 40 | loss: 0.0586444\n",
      "\tspeed: 0.0172s/iter; left time: 232.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 225 | Train Loss: 0.0579980 Vali Loss: 0.0684937 Test Loss: 0.0790323\n",
      "Validation loss decreased (0.068502 --> 0.068494).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0628458\n",
      "\tspeed: 0.0370s/iter; left time: 495.8552s\n",
      "\titers: 200, epoch: 41 | loss: 0.0581595\n",
      "\tspeed: 0.0167s/iter; left time: 222.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579853 Vali Loss: 0.0684993 Test Loss: 0.0790148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0597324\n",
      "\tspeed: 0.0307s/iter; left time: 404.9280s\n",
      "\titers: 200, epoch: 42 | loss: 0.0543683\n",
      "\tspeed: 0.0181s/iter; left time: 236.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0580027 Vali Loss: 0.0685095 Test Loss: 0.0790117\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0602942\n",
      "\tspeed: 0.0344s/iter; left time: 445.4938s\n",
      "\titers: 200, epoch: 43 | loss: 0.0588281\n",
      "\tspeed: 0.0170s/iter; left time: 218.3892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0579897 Vali Loss: 0.0685076 Test Loss: 0.0789774\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0577775\n",
      "\tspeed: 0.0354s/iter; left time: 450.6939s\n",
      "\titers: 200, epoch: 44 | loss: 0.0578619\n",
      "\tspeed: 0.0146s/iter; left time: 184.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0579762 Vali Loss: 0.0685071 Test Loss: 0.0790132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0587692\n",
      "\tspeed: 0.0285s/iter; left time: 356.2176s\n",
      "\titers: 200, epoch: 45 | loss: 0.0575636\n",
      "\tspeed: 0.0171s/iter; left time: 211.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.58s\n",
      "Steps: 225 | Train Loss: 0.0579338 Vali Loss: 0.0685000 Test Loss: 0.0790003\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0571148\n",
      "\tspeed: 0.0347s/iter; left time: 426.0458s\n",
      "\titers: 200, epoch: 46 | loss: 0.0616274\n",
      "\tspeed: 0.0154s/iter; left time: 187.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 225 | Train Loss: 0.0580003 Vali Loss: 0.0684827 Test Loss: 0.0790229\n",
      "Validation loss decreased (0.068494 --> 0.068483).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0560301\n",
      "\tspeed: 0.0333s/iter; left time: 401.3574s\n",
      "\titers: 200, epoch: 47 | loss: 0.0598776\n",
      "\tspeed: 0.0145s/iter; left time: 173.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0579353 Vali Loss: 0.0684818 Test Loss: 0.0790140\n",
      "Validation loss decreased (0.068483 --> 0.068482).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0621192\n",
      "\tspeed: 0.0364s/iter; left time: 431.0097s\n",
      "\titers: 200, epoch: 48 | loss: 0.0558696\n",
      "\tspeed: 0.0180s/iter; left time: 211.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579430 Vali Loss: 0.0684988 Test Loss: 0.0790144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549243\n",
      "\tspeed: 0.0354s/iter; left time: 411.1534s\n",
      "\titers: 200, epoch: 49 | loss: 0.0607253\n",
      "\tspeed: 0.0200s/iter; left time: 230.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0579465 Vali Loss: 0.0684958 Test Loss: 0.0789943\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0580601\n",
      "\tspeed: 0.0360s/iter; left time: 409.2362s\n",
      "\titers: 200, epoch: 50 | loss: 0.0604288\n",
      "\tspeed: 0.0216s/iter; left time: 243.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 225 | Train Loss: 0.0578998 Vali Loss: 0.0684910 Test Loss: 0.0790050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0581676\n",
      "\tspeed: 0.0343s/iter; left time: 382.0332s\n",
      "\titers: 200, epoch: 51 | loss: 0.0585575\n",
      "\tspeed: 0.0185s/iter; left time: 204.3241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 225 | Train Loss: 0.0579432 Vali Loss: 0.0684809 Test Loss: 0.0790085\n",
      "Validation loss decreased (0.068482 --> 0.068481).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0603360\n",
      "\tspeed: 0.0393s/iter; left time: 429.5871s\n",
      "\titers: 200, epoch: 52 | loss: 0.0584841\n",
      "\tspeed: 0.0237s/iter; left time: 256.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0579319 Vali Loss: 0.0684904 Test Loss: 0.0789994\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0585743\n",
      "\tspeed: 0.0372s/iter; left time: 397.6573s\n",
      "\titers: 200, epoch: 53 | loss: 0.0588034\n",
      "\tspeed: 0.0192s/iter; left time: 203.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0579132 Vali Loss: 0.0684941 Test Loss: 0.0790057\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0557282\n",
      "\tspeed: 0.0357s/iter; left time: 373.8456s\n",
      "\titers: 200, epoch: 54 | loss: 0.0613860\n",
      "\tspeed: 0.0172s/iter; left time: 178.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0579653 Vali Loss: 0.0685006 Test Loss: 0.0789996\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0585939\n",
      "\tspeed: 0.0368s/iter; left time: 376.8087s\n",
      "\titers: 200, epoch: 55 | loss: 0.0651440\n",
      "\tspeed: 0.0153s/iter; left time: 154.9025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0579389 Vali Loss: 0.0684873 Test Loss: 0.0790061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0619266\n",
      "\tspeed: 0.0351s/iter; left time: 351.5120s\n",
      "\titers: 200, epoch: 56 | loss: 0.0551651\n",
      "\tspeed: 0.0203s/iter; left time: 201.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0579282 Vali Loss: 0.0684934 Test Loss: 0.0789854\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0585389\n",
      "\tspeed: 0.0339s/iter; left time: 332.6475s\n",
      "\titers: 200, epoch: 57 | loss: 0.0609670\n",
      "\tspeed: 0.0187s/iter; left time: 181.5152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0579366 Vali Loss: 0.0684922 Test Loss: 0.0789980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598860\n",
      "\tspeed: 0.0352s/iter; left time: 337.3262s\n",
      "\titers: 200, epoch: 58 | loss: 0.0599037\n",
      "\tspeed: 0.0192s/iter; left time: 182.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0579010 Vali Loss: 0.0684900 Test Loss: 0.0789935\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599850\n",
      "\tspeed: 0.0360s/iter; left time: 336.9727s\n",
      "\titers: 200, epoch: 59 | loss: 0.0567161\n",
      "\tspeed: 0.0183s/iter; left time: 169.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0579170 Vali Loss: 0.0685022 Test Loss: 0.0789889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0599660\n",
      "\tspeed: 0.0346s/iter; left time: 316.1463s\n",
      "\titers: 200, epoch: 60 | loss: 0.0574773\n",
      "\tspeed: 0.0191s/iter; left time: 172.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0579000 Vali Loss: 0.0684907 Test Loss: 0.0789931\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0555947\n",
      "\tspeed: 0.0367s/iter; left time: 326.8183s\n",
      "\titers: 200, epoch: 61 | loss: 0.0567072\n",
      "\tspeed: 0.0197s/iter; left time: 173.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.0579001 Vali Loss: 0.0684961 Test Loss: 0.0790021\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019269950687885284, rmse:0.1388162523508072, mae:0.07900849729776382, rse:0.5369781255722046\n",
      "Intermediate time for FR and pred_len 96: 00h:07m:56.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1178433\n",
      "\tspeed: 0.0442s/iter; left time: 990.4424s\n",
      "\titers: 200, epoch: 1 | loss: 0.0979904\n",
      "\tspeed: 0.0151s/iter; left time: 335.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.1161686 Vali Loss: 0.1026122 Test Loss: 0.1144287\n",
      "Validation loss decreased (inf --> 0.102612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0802685\n",
      "\tspeed: 0.0318s/iter; left time: 705.8233s\n",
      "\titers: 200, epoch: 2 | loss: 0.0758796\n",
      "\tspeed: 0.0206s/iter; left time: 453.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0786359 Vali Loss: 0.0817531 Test Loss: 0.0914209\n",
      "Validation loss decreased (0.102612 --> 0.081753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686616\n",
      "\tspeed: 0.0396s/iter; left time: 869.3379s\n",
      "\titers: 200, epoch: 3 | loss: 0.0681255\n",
      "\tspeed: 0.0236s/iter; left time: 515.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 225 | Train Loss: 0.0712700 Vali Loss: 0.0772329 Test Loss: 0.0881135\n",
      "Validation loss decreased (0.081753 --> 0.077233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0735443\n",
      "\tspeed: 0.0391s/iter; left time: 848.8578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703870\n",
      "\tspeed: 0.0260s/iter; left time: 561.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0689783 Vali Loss: 0.0761214 Test Loss: 0.0871739\n",
      "Validation loss decreased (0.077233 --> 0.076121).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0685207\n",
      "\tspeed: 0.0397s/iter; left time: 854.0756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0634067\n",
      "\tspeed: 0.0196s/iter; left time: 418.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0678461 Vali Loss: 0.0758394 Test Loss: 0.0865922\n",
      "Validation loss decreased (0.076121 --> 0.075839).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0663654\n",
      "\tspeed: 0.0347s/iter; left time: 737.2492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0719434\n",
      "\tspeed: 0.0148s/iter; left time: 313.6845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0670404 Vali Loss: 0.0752677 Test Loss: 0.0862171\n",
      "Validation loss decreased (0.075839 --> 0.075268).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0663606\n",
      "\tspeed: 0.0406s/iter; left time: 854.5411s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665885\n",
      "\tspeed: 0.0240s/iter; left time: 503.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0664133 Vali Loss: 0.0750782 Test Loss: 0.0859377\n",
      "Validation loss decreased (0.075268 --> 0.075078).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0610192\n",
      "\tspeed: 0.0403s/iter; left time: 838.8842s\n",
      "\titers: 200, epoch: 8 | loss: 0.0643330\n",
      "\tspeed: 0.0140s/iter; left time: 291.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0659399 Vali Loss: 0.0749717 Test Loss: 0.0858859\n",
      "Validation loss decreased (0.075078 --> 0.074972).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0677186\n",
      "\tspeed: 0.0362s/iter; left time: 746.3905s\n",
      "\titers: 200, epoch: 9 | loss: 0.0667564\n",
      "\tspeed: 0.0157s/iter; left time: 321.6059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0655065 Vali Loss: 0.0745897 Test Loss: 0.0855368\n",
      "Validation loss decreased (0.074972 --> 0.074590).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0658022\n",
      "\tspeed: 0.0340s/iter; left time: 693.1290s\n",
      "\titers: 200, epoch: 10 | loss: 0.0643987\n",
      "\tspeed: 0.0175s/iter; left time: 354.2846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0651897 Vali Loss: 0.0747029 Test Loss: 0.0855107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0664462\n",
      "\tspeed: 0.0326s/iter; left time: 657.3021s\n",
      "\titers: 200, epoch: 11 | loss: 0.0612322\n",
      "\tspeed: 0.0131s/iter; left time: 261.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 225 | Train Loss: 0.0649022 Vali Loss: 0.0745873 Test Loss: 0.0857235\n",
      "Validation loss decreased (0.074590 --> 0.074587).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0639878\n",
      "\tspeed: 0.0313s/iter; left time: 623.6526s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650366\n",
      "\tspeed: 0.0104s/iter; left time: 206.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 225 | Train Loss: 0.0645888 Vali Loss: 0.0743928 Test Loss: 0.0858431\n",
      "Validation loss decreased (0.074587 --> 0.074393).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0629034\n",
      "\tspeed: 0.0336s/iter; left time: 662.0700s\n",
      "\titers: 200, epoch: 13 | loss: 0.0618235\n",
      "\tspeed: 0.0180s/iter; left time: 352.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0643678 Vali Loss: 0.0744177 Test Loss: 0.0855179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0662641\n",
      "\tspeed: 0.0380s/iter; left time: 739.7201s\n",
      "\titers: 200, epoch: 14 | loss: 0.0653053\n",
      "\tspeed: 0.0193s/iter; left time: 374.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0641760 Vali Loss: 0.0742883 Test Loss: 0.0857224\n",
      "Validation loss decreased (0.074393 --> 0.074288).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0616458\n",
      "\tspeed: 0.0398s/iter; left time: 766.2188s\n",
      "\titers: 200, epoch: 15 | loss: 0.0615292\n",
      "\tspeed: 0.0170s/iter; left time: 325.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0639647 Vali Loss: 0.0742747 Test Loss: 0.0858672\n",
      "Validation loss decreased (0.074288 --> 0.074275).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0649231\n",
      "\tspeed: 0.0355s/iter; left time: 674.5108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0664912\n",
      "\tspeed: 0.0218s/iter; left time: 412.6628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0638754 Vali Loss: 0.0742751 Test Loss: 0.0856137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0634356\n",
      "\tspeed: 0.0361s/iter; left time: 678.0320s\n",
      "\titers: 200, epoch: 17 | loss: 0.0662411\n",
      "\tspeed: 0.0165s/iter; left time: 308.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 225 | Train Loss: 0.0636968 Vali Loss: 0.0742034 Test Loss: 0.0857146\n",
      "Validation loss decreased (0.074275 --> 0.074203).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0625355\n",
      "\tspeed: 0.0384s/iter; left time: 714.0764s\n",
      "\titers: 200, epoch: 18 | loss: 0.0631167\n",
      "\tspeed: 0.0179s/iter; left time: 329.8468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0635564 Vali Loss: 0.0741951 Test Loss: 0.0855760\n",
      "Validation loss decreased (0.074203 --> 0.074195).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0636816\n",
      "\tspeed: 0.0388s/iter; left time: 711.9540s\n",
      "\titers: 200, epoch: 19 | loss: 0.0653322\n",
      "\tspeed: 0.0224s/iter; left time: 408.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0634603 Vali Loss: 0.0741919 Test Loss: 0.0857492\n",
      "Validation loss decreased (0.074195 --> 0.074192).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0619669\n",
      "\tspeed: 0.0425s/iter; left time: 770.9257s\n",
      "\titers: 200, epoch: 20 | loss: 0.0645041\n",
      "\tspeed: 0.0190s/iter; left time: 342.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0633220 Vali Loss: 0.0740985 Test Loss: 0.0858055\n",
      "Validation loss decreased (0.074192 --> 0.074098).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0634483\n",
      "\tspeed: 0.0358s/iter; left time: 640.4021s\n",
      "\titers: 200, epoch: 21 | loss: 0.0661550\n",
      "\tspeed: 0.0158s/iter; left time: 280.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0632298 Vali Loss: 0.0740741 Test Loss: 0.0856835\n",
      "Validation loss decreased (0.074098 --> 0.074074).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0665884\n",
      "\tspeed: 0.0412s/iter; left time: 727.7174s\n",
      "\titers: 200, epoch: 22 | loss: 0.0624136\n",
      "\tspeed: 0.0192s/iter; left time: 337.2748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0631625 Vali Loss: 0.0741992 Test Loss: 0.0855839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0592897\n",
      "\tspeed: 0.0360s/iter; left time: 628.8964s\n",
      "\titers: 200, epoch: 23 | loss: 0.0609877\n",
      "\tspeed: 0.0190s/iter; left time: 329.3686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 225 | Train Loss: 0.0630976 Vali Loss: 0.0740889 Test Loss: 0.0858281\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0619836\n",
      "\tspeed: 0.0388s/iter; left time: 667.9136s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606376\n",
      "\tspeed: 0.0196s/iter; left time: 334.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0630359 Vali Loss: 0.0742436 Test Loss: 0.0856210\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0620375\n",
      "\tspeed: 0.0345s/iter; left time: 587.0172s\n",
      "\titers: 200, epoch: 25 | loss: 0.0610093\n",
      "\tspeed: 0.0175s/iter; left time: 295.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0629425 Vali Loss: 0.0740689 Test Loss: 0.0856918\n",
      "Validation loss decreased (0.074074 --> 0.074069).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0623213\n",
      "\tspeed: 0.0420s/iter; left time: 704.5601s\n",
      "\titers: 200, epoch: 26 | loss: 0.0607373\n",
      "\tspeed: 0.0224s/iter; left time: 373.9348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 225 | Train Loss: 0.0629212 Vali Loss: 0.0741398 Test Loss: 0.0855965\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0599672\n",
      "\tspeed: 0.0363s/iter; left time: 600.5544s\n",
      "\titers: 200, epoch: 27 | loss: 0.0638771\n",
      "\tspeed: 0.0233s/iter; left time: 382.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0628768 Vali Loss: 0.0741251 Test Loss: 0.0856418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0645678\n",
      "\tspeed: 0.0372s/iter; left time: 607.0370s\n",
      "\titers: 200, epoch: 28 | loss: 0.0622639\n",
      "\tspeed: 0.0179s/iter; left time: 290.0750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0628522 Vali Loss: 0.0740774 Test Loss: 0.0857350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0643791\n",
      "\tspeed: 0.0335s/iter; left time: 539.3548s\n",
      "\titers: 200, epoch: 29 | loss: 0.0624117\n",
      "\tspeed: 0.0174s/iter; left time: 278.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0628074 Vali Loss: 0.0740491 Test Loss: 0.0857703\n",
      "Validation loss decreased (0.074069 --> 0.074049).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0639029\n",
      "\tspeed: 0.0334s/iter; left time: 530.8416s\n",
      "\titers: 200, epoch: 30 | loss: 0.0644022\n",
      "\tspeed: 0.0198s/iter; left time: 312.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0627769 Vali Loss: 0.0741052 Test Loss: 0.0856595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0654455\n",
      "\tspeed: 0.0327s/iter; left time: 511.9813s\n",
      "\titers: 200, epoch: 31 | loss: 0.0616240\n",
      "\tspeed: 0.0176s/iter; left time: 273.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0627635 Vali Loss: 0.0741205 Test Loss: 0.0856111\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611650\n",
      "\tspeed: 0.0301s/iter; left time: 465.0414s\n",
      "\titers: 200, epoch: 32 | loss: 0.0649987\n",
      "\tspeed: 0.0101s/iter; left time: 154.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.54s\n",
      "Steps: 225 | Train Loss: 0.0627000 Vali Loss: 0.0740636 Test Loss: 0.0857006\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0597707\n",
      "\tspeed: 0.0298s/iter; left time: 453.2348s\n",
      "\titers: 200, epoch: 33 | loss: 0.0641938\n",
      "\tspeed: 0.0153s/iter; left time: 231.4744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0627276 Vali Loss: 0.0741174 Test Loss: 0.0856934\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0659970\n",
      "\tspeed: 0.0363s/iter; left time: 542.8981s\n",
      "\titers: 200, epoch: 34 | loss: 0.0607483\n",
      "\tspeed: 0.0221s/iter; left time: 329.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0626968 Vali Loss: 0.0741465 Test Loss: 0.0856483\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0599526\n",
      "\tspeed: 0.0340s/iter; left time: 501.6005s\n",
      "\titers: 200, epoch: 35 | loss: 0.0630129\n",
      "\tspeed: 0.0152s/iter; left time: 222.7658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0626719 Vali Loss: 0.0740543 Test Loss: 0.0856168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0640251\n",
      "\tspeed: 0.0362s/iter; left time: 525.7571s\n",
      "\titers: 200, epoch: 36 | loss: 0.0665271\n",
      "\tspeed: 0.0182s/iter; left time: 262.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0626520 Vali Loss: 0.0740346 Test Loss: 0.0856374\n",
      "Validation loss decreased (0.074049 --> 0.074035).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0650771\n",
      "\tspeed: 0.0383s/iter; left time: 547.4149s\n",
      "\titers: 200, epoch: 37 | loss: 0.0620096\n",
      "\tspeed: 0.0125s/iter; left time: 176.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 225 | Train Loss: 0.0626566 Vali Loss: 0.0740899 Test Loss: 0.0856191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0620774\n",
      "\tspeed: 0.0358s/iter; left time: 503.2467s\n",
      "\titers: 200, epoch: 38 | loss: 0.0605291\n",
      "\tspeed: 0.0227s/iter; left time: 317.3686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0626232 Vali Loss: 0.0740508 Test Loss: 0.0856860\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0638552\n",
      "\tspeed: 0.0358s/iter; left time: 496.2853s\n",
      "\titers: 200, epoch: 39 | loss: 0.0609560\n",
      "\tspeed: 0.0127s/iter; left time: 174.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 225 | Train Loss: 0.0626238 Vali Loss: 0.0741312 Test Loss: 0.0856796\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0629077\n",
      "\tspeed: 0.0332s/iter; left time: 452.9871s\n",
      "\titers: 200, epoch: 40 | loss: 0.0619635\n",
      "\tspeed: 0.0172s/iter; left time: 232.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0625679 Vali Loss: 0.0740890 Test Loss: 0.0856143\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0585513\n",
      "\tspeed: 0.0334s/iter; left time: 447.2526s\n",
      "\titers: 200, epoch: 41 | loss: 0.0619032\n",
      "\tspeed: 0.0175s/iter; left time: 232.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0625734 Vali Loss: 0.0740964 Test Loss: 0.0856672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0622944\n",
      "\tspeed: 0.0330s/iter; left time: 434.3602s\n",
      "\titers: 200, epoch: 42 | loss: 0.0620603\n",
      "\tspeed: 0.0116s/iter; left time: 152.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 225 | Train Loss: 0.0625519 Vali Loss: 0.0740899 Test Loss: 0.0856896\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0636618\n",
      "\tspeed: 0.0339s/iter; left time: 439.3911s\n",
      "\titers: 200, epoch: 43 | loss: 0.0662818\n",
      "\tspeed: 0.0193s/iter; left time: 247.6156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0625558 Vali Loss: 0.0740881 Test Loss: 0.0856588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0609411\n",
      "\tspeed: 0.0347s/iter; left time: 442.1387s\n",
      "\titers: 200, epoch: 44 | loss: 0.0611548\n",
      "\tspeed: 0.0181s/iter; left time: 228.6233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0625591 Vali Loss: 0.0740926 Test Loss: 0.0856833\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0599050\n",
      "\tspeed: 0.0359s/iter; left time: 448.8544s\n",
      "\titers: 200, epoch: 45 | loss: 0.0615746\n",
      "\tspeed: 0.0186s/iter; left time: 230.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0625465 Vali Loss: 0.0740532 Test Loss: 0.0857476\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0656682\n",
      "\tspeed: 0.0346s/iter; left time: 425.1519s\n",
      "\titers: 200, epoch: 46 | loss: 0.0665195\n",
      "\tspeed: 0.0171s/iter; left time: 208.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0625344 Vali Loss: 0.0740709 Test Loss: 0.0856607\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021044865250587463, rmse:0.1450684815645218, mae:0.08563748002052307, rse:0.5618639588356018\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1210394\n",
      "\tspeed: 0.0218s/iter; left time: 489.1919s\n",
      "\titers: 200, epoch: 1 | loss: 0.1047875\n",
      "\tspeed: 0.0180s/iter; left time: 401.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.1171486 Vali Loss: 0.1032319 Test Loss: 0.1152084\n",
      "Validation loss decreased (inf --> 0.103232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0764794\n",
      "\tspeed: 0.0339s/iter; left time: 751.2943s\n",
      "\titers: 200, epoch: 2 | loss: 0.0732857\n",
      "\tspeed: 0.0101s/iter; left time: 224.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0785486 Vali Loss: 0.0815163 Test Loss: 0.0911878\n",
      "Validation loss decreased (0.103232 --> 0.081516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0692481\n",
      "\tspeed: 0.0352s/iter; left time: 773.6957s\n",
      "\titers: 200, epoch: 3 | loss: 0.0701355\n",
      "\tspeed: 0.0158s/iter; left time: 344.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0712442 Vali Loss: 0.0773953 Test Loss: 0.0882910\n",
      "Validation loss decreased (0.081516 --> 0.077395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0653713\n",
      "\tspeed: 0.0373s/iter; left time: 809.7535s\n",
      "\titers: 200, epoch: 4 | loss: 0.0740804\n",
      "\tspeed: 0.0200s/iter; left time: 432.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0692651 Vali Loss: 0.0763515 Test Loss: 0.0871971\n",
      "Validation loss decreased (0.077395 --> 0.076352).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0681931\n",
      "\tspeed: 0.0284s/iter; left time: 609.5723s\n",
      "\titers: 200, epoch: 5 | loss: 0.0681475\n",
      "\tspeed: 0.0171s/iter; left time: 365.1300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.51s\n",
      "Steps: 225 | Train Loss: 0.0681561 Vali Loss: 0.0757714 Test Loss: 0.0865808\n",
      "Validation loss decreased (0.076352 --> 0.075771).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646403\n",
      "\tspeed: 0.0391s/iter; left time: 831.2309s\n",
      "\titers: 200, epoch: 6 | loss: 0.0670295\n",
      "\tspeed: 0.0180s/iter; left time: 381.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0673313 Vali Loss: 0.0754521 Test Loss: 0.0862572\n",
      "Validation loss decreased (0.075771 --> 0.075452).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0610189\n",
      "\tspeed: 0.0350s/iter; left time: 737.7563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0690645\n",
      "\tspeed: 0.0175s/iter; left time: 366.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0667259 Vali Loss: 0.0749807 Test Loss: 0.0862407\n",
      "Validation loss decreased (0.075452 --> 0.074981).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0644768\n",
      "\tspeed: 0.0379s/iter; left time: 788.9388s\n",
      "\titers: 200, epoch: 8 | loss: 0.0653624\n",
      "\tspeed: 0.0185s/iter; left time: 382.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0662581 Vali Loss: 0.0748040 Test Loss: 0.0859648\n",
      "Validation loss decreased (0.074981 --> 0.074804).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657071\n",
      "\tspeed: 0.0377s/iter; left time: 777.6188s\n",
      "\titers: 200, epoch: 9 | loss: 0.0655997\n",
      "\tspeed: 0.0181s/iter; left time: 370.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0658779 Vali Loss: 0.0746631 Test Loss: 0.0856976\n",
      "Validation loss decreased (0.074804 --> 0.074663).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0684024\n",
      "\tspeed: 0.0375s/iter; left time: 764.8521s\n",
      "\titers: 200, epoch: 10 | loss: 0.0660051\n",
      "\tspeed: 0.0208s/iter; left time: 422.6620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0655724 Vali Loss: 0.0745846 Test Loss: 0.0858406\n",
      "Validation loss decreased (0.074663 --> 0.074585).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0623031\n",
      "\tspeed: 0.0423s/iter; left time: 851.5952s\n",
      "\titers: 200, epoch: 11 | loss: 0.0676518\n",
      "\tspeed: 0.0215s/iter; left time: 431.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0652500 Vali Loss: 0.0747508 Test Loss: 0.0857698\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0664428\n",
      "\tspeed: 0.0370s/iter; left time: 737.4653s\n",
      "\titers: 200, epoch: 12 | loss: 0.0653762\n",
      "\tspeed: 0.0151s/iter; left time: 299.8820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0650192 Vali Loss: 0.0744734 Test Loss: 0.0855734\n",
      "Validation loss decreased (0.074585 --> 0.074473).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646388\n",
      "\tspeed: 0.0372s/iter; left time: 732.2521s\n",
      "\titers: 200, epoch: 13 | loss: 0.0651568\n",
      "\tspeed: 0.0187s/iter; left time: 365.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 225 | Train Loss: 0.0647588 Vali Loss: 0.0744340 Test Loss: 0.0853351\n",
      "Validation loss decreased (0.074473 --> 0.074434).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0667653\n",
      "\tspeed: 0.0349s/iter; left time: 679.3370s\n",
      "\titers: 200, epoch: 14 | loss: 0.0626236\n",
      "\tspeed: 0.0170s/iter; left time: 328.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0645367 Vali Loss: 0.0741993 Test Loss: 0.0855686\n",
      "Validation loss decreased (0.074434 --> 0.074199).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0680252\n",
      "\tspeed: 0.0361s/iter; left time: 695.7682s\n",
      "\titers: 200, epoch: 15 | loss: 0.0593005\n",
      "\tspeed: 0.0169s/iter; left time: 323.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0643566 Vali Loss: 0.0741186 Test Loss: 0.0857946\n",
      "Validation loss decreased (0.074199 --> 0.074119).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0614194\n",
      "\tspeed: 0.0366s/iter; left time: 697.0894s\n",
      "\titers: 200, epoch: 16 | loss: 0.0623373\n",
      "\tspeed: 0.0210s/iter; left time: 397.6584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0642088 Vali Loss: 0.0741625 Test Loss: 0.0854788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0665994\n",
      "\tspeed: 0.0375s/iter; left time: 705.5601s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648475\n",
      "\tspeed: 0.0137s/iter; left time: 256.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0640424 Vali Loss: 0.0741478 Test Loss: 0.0855078\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0663047\n",
      "\tspeed: 0.0415s/iter; left time: 770.2559s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661211\n",
      "\tspeed: 0.0182s/iter; left time: 335.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 225 | Train Loss: 0.0639167 Vali Loss: 0.0740825 Test Loss: 0.0855979\n",
      "Validation loss decreased (0.074119 --> 0.074082).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0629823\n",
      "\tspeed: 0.0371s/iter; left time: 680.3404s\n",
      "\titers: 200, epoch: 19 | loss: 0.0630848\n",
      "\tspeed: 0.0190s/iter; left time: 346.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0637715 Vali Loss: 0.0740956 Test Loss: 0.0853726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0632227\n",
      "\tspeed: 0.0390s/iter; left time: 707.3950s\n",
      "\titers: 200, epoch: 20 | loss: 0.0624366\n",
      "\tspeed: 0.0219s/iter; left time: 394.8818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0637345 Vali Loss: 0.0740992 Test Loss: 0.0856143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0620175\n",
      "\tspeed: 0.0429s/iter; left time: 768.7946s\n",
      "\titers: 200, epoch: 21 | loss: 0.0622662\n",
      "\tspeed: 0.0251s/iter; left time: 446.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0636170 Vali Loss: 0.0739984 Test Loss: 0.0854581\n",
      "Validation loss decreased (0.074082 --> 0.073998).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0642883\n",
      "\tspeed: 0.0401s/iter; left time: 709.4577s\n",
      "\titers: 200, epoch: 22 | loss: 0.0624295\n",
      "\tspeed: 0.0192s/iter; left time: 338.0463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0635554 Vali Loss: 0.0738083 Test Loss: 0.0854759\n",
      "Validation loss decreased (0.073998 --> 0.073808).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0619837\n",
      "\tspeed: 0.0440s/iter; left time: 767.9425s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606846\n",
      "\tspeed: 0.0231s/iter; left time: 401.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0634304 Vali Loss: 0.0739375 Test Loss: 0.0856123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0621821\n",
      "\tspeed: 0.0305s/iter; left time: 525.0064s\n",
      "\titers: 200, epoch: 24 | loss: 0.0660644\n",
      "\tspeed: 0.0144s/iter; left time: 246.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0633682 Vali Loss: 0.0739710 Test Loss: 0.0856309\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0619161\n",
      "\tspeed: 0.0325s/iter; left time: 552.7801s\n",
      "\titers: 200, epoch: 25 | loss: 0.0685211\n",
      "\tspeed: 0.0234s/iter; left time: 395.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 225 | Train Loss: 0.0633131 Vali Loss: 0.0738985 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0625157\n",
      "\tspeed: 0.0427s/iter; left time: 716.5477s\n",
      "\titers: 200, epoch: 26 | loss: 0.0681692\n",
      "\tspeed: 0.0162s/iter; left time: 270.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0632651 Vali Loss: 0.0739015 Test Loss: 0.0856150\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0608956\n",
      "\tspeed: 0.0388s/iter; left time: 642.5381s\n",
      "\titers: 200, epoch: 27 | loss: 0.0656074\n",
      "\tspeed: 0.0127s/iter; left time: 208.9528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 225 | Train Loss: 0.0632046 Vali Loss: 0.0739431 Test Loss: 0.0855818\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0641362\n",
      "\tspeed: 0.0339s/iter; left time: 554.2001s\n",
      "\titers: 200, epoch: 28 | loss: 0.0657411\n",
      "\tspeed: 0.0199s/iter; left time: 322.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0631599 Vali Loss: 0.0738821 Test Loss: 0.0856754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0651714\n",
      "\tspeed: 0.0356s/iter; left time: 573.7399s\n",
      "\titers: 200, epoch: 29 | loss: 0.0617112\n",
      "\tspeed: 0.0231s/iter; left time: 368.9746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0631507 Vali Loss: 0.0738765 Test Loss: 0.0856216\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0614604\n",
      "\tspeed: 0.0370s/iter; left time: 587.6082s\n",
      "\titers: 200, epoch: 30 | loss: 0.0620838\n",
      "\tspeed: 0.0102s/iter; left time: 161.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0630906 Vali Loss: 0.0737731 Test Loss: 0.0855447\n",
      "Validation loss decreased (0.073808 --> 0.073773).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0615081\n",
      "\tspeed: 0.0341s/iter; left time: 534.3254s\n",
      "\titers: 200, epoch: 31 | loss: 0.0636241\n",
      "\tspeed: 0.0191s/iter; left time: 297.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0630592 Vali Loss: 0.0738371 Test Loss: 0.0856570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0609704\n",
      "\tspeed: 0.0391s/iter; left time: 603.8718s\n",
      "\titers: 200, epoch: 32 | loss: 0.0635759\n",
      "\tspeed: 0.0171s/iter; left time: 261.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0630527 Vali Loss: 0.0738693 Test Loss: 0.0855334\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0646972\n",
      "\tspeed: 0.0420s/iter; left time: 637.8868s\n",
      "\titers: 200, epoch: 33 | loss: 0.0630995\n",
      "\tspeed: 0.0148s/iter; left time: 222.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0630115 Vali Loss: 0.0738945 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0654340\n",
      "\tspeed: 0.0340s/iter; left time: 509.1516s\n",
      "\titers: 200, epoch: 34 | loss: 0.0624656\n",
      "\tspeed: 0.0128s/iter; left time: 191.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 225 | Train Loss: 0.0630298 Vali Loss: 0.0738741 Test Loss: 0.0855332\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0638330\n",
      "\tspeed: 0.0341s/iter; left time: 502.8451s\n",
      "\titers: 200, epoch: 35 | loss: 0.0668810\n",
      "\tspeed: 0.0212s/iter; left time: 311.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0629951 Vali Loss: 0.0739457 Test Loss: 0.0855343\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0623147\n",
      "\tspeed: 0.0343s/iter; left time: 498.7837s\n",
      "\titers: 200, epoch: 36 | loss: 0.0608723\n",
      "\tspeed: 0.0205s/iter; left time: 296.2423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.0629881 Vali Loss: 0.0737848 Test Loss: 0.0855618\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0630879\n",
      "\tspeed: 0.0392s/iter; left time: 559.9751s\n",
      "\titers: 200, epoch: 37 | loss: 0.0650850\n",
      "\tspeed: 0.0183s/iter; left time: 260.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0629607 Vali Loss: 0.0738439 Test Loss: 0.0855667\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0633509\n",
      "\tspeed: 0.0409s/iter; left time: 575.3754s\n",
      "\titers: 200, epoch: 38 | loss: 0.0605446\n",
      "\tspeed: 0.0228s/iter; left time: 319.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0629436 Vali Loss: 0.0738411 Test Loss: 0.0855348\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0598986\n",
      "\tspeed: 0.0325s/iter; left time: 450.1978s\n",
      "\titers: 200, epoch: 39 | loss: 0.0613178\n",
      "\tspeed: 0.0182s/iter; left time: 250.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0628666 Vali Loss: 0.0738966 Test Loss: 0.0854778\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0665396\n",
      "\tspeed: 0.0381s/iter; left time: 518.5626s\n",
      "\titers: 200, epoch: 40 | loss: 0.0625084\n",
      "\tspeed: 0.0184s/iter; left time: 248.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0628995 Vali Loss: 0.0738050 Test Loss: 0.0855525\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021028192713856697, rmse:0.14501100778579712, mae:0.08554467558860779, rse:0.5616413950920105\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:01.02s\n",
      "Intermediate time for FR: 00h:23m:05.21s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1593821\n",
      "\tspeed: 0.0385s/iter; left time: 866.1848s\n",
      "\titers: 200, epoch: 1 | loss: 0.1234813\n",
      "\tspeed: 0.0164s/iter; left time: 367.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.1570896 Vali Loss: 0.1092966 Test Loss: 0.1122958\n",
      "Validation loss decreased (inf --> 0.109297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0768305\n",
      "\tspeed: 0.0344s/iter; left time: 767.1176s\n",
      "\titers: 200, epoch: 2 | loss: 0.0711576\n",
      "\tspeed: 0.0164s/iter; left time: 364.3583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.02s\n",
      "Steps: 226 | Train Loss: 0.0823309 Vali Loss: 0.0656439 Test Loss: 0.0675110\n",
      "Validation loss decreased (0.109297 --> 0.065644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0701625\n",
      "\tspeed: 0.0344s/iter; left time: 758.6147s\n",
      "\titers: 200, epoch: 3 | loss: 0.0677254\n",
      "\tspeed: 0.0169s/iter; left time: 371.2511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0685028 Vali Loss: 0.0616079 Test Loss: 0.0640182\n",
      "Validation loss decreased (0.065644 --> 0.061608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659868\n",
      "\tspeed: 0.0351s/iter; left time: 766.3866s\n",
      "\titers: 200, epoch: 4 | loss: 0.0607433\n",
      "\tspeed: 0.0153s/iter; left time: 332.6987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 226 | Train Loss: 0.0651398 Vali Loss: 0.0595158 Test Loss: 0.0618037\n",
      "Validation loss decreased (0.061608 --> 0.059516).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0652476\n",
      "\tspeed: 0.0306s/iter; left time: 659.8101s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612183\n",
      "\tspeed: 0.0190s/iter; left time: 408.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0629467 Vali Loss: 0.0581176 Test Loss: 0.0603192\n",
      "Validation loss decreased (0.059516 --> 0.058118).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0603484\n",
      "\tspeed: 0.0346s/iter; left time: 738.6505s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601482\n",
      "\tspeed: 0.0182s/iter; left time: 386.2320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 226 | Train Loss: 0.0615746 Vali Loss: 0.0571964 Test Loss: 0.0595768\n",
      "Validation loss decreased (0.058118 --> 0.057196).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648735\n",
      "\tspeed: 0.0350s/iter; left time: 740.6096s\n",
      "\titers: 200, epoch: 7 | loss: 0.0578561\n",
      "\tspeed: 0.0161s/iter; left time: 339.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0606378 Vali Loss: 0.0574239 Test Loss: 0.0596774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0606239\n",
      "\tspeed: 0.0338s/iter; left time: 706.0522s\n",
      "\titers: 200, epoch: 8 | loss: 0.0619788\n",
      "\tspeed: 0.0189s/iter; left time: 393.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0599561 Vali Loss: 0.0565249 Test Loss: 0.0588886\n",
      "Validation loss decreased (0.057196 --> 0.056525).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0612155\n",
      "\tspeed: 0.0348s/iter; left time: 719.4713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0603437\n",
      "\tspeed: 0.0223s/iter; left time: 458.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0592684 Vali Loss: 0.0561483 Test Loss: 0.0586221\n",
      "Validation loss decreased (0.056525 --> 0.056148).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0569037\n",
      "\tspeed: 0.0322s/iter; left time: 658.4225s\n",
      "\titers: 200, epoch: 10 | loss: 0.0605587\n",
      "\tspeed: 0.0154s/iter; left time: 313.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0588348 Vali Loss: 0.0559605 Test Loss: 0.0583189\n",
      "Validation loss decreased (0.056148 --> 0.055961).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0575559\n",
      "\tspeed: 0.0350s/iter; left time: 709.0042s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598319\n",
      "\tspeed: 0.0183s/iter; left time: 368.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0583838 Vali Loss: 0.0558892 Test Loss: 0.0580843\n",
      "Validation loss decreased (0.055961 --> 0.055889).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0626877\n",
      "\tspeed: 0.0348s/iter; left time: 697.1967s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601823\n",
      "\tspeed: 0.0203s/iter; left time: 403.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0580430 Vali Loss: 0.0554932 Test Loss: 0.0579933\n",
      "Validation loss decreased (0.055889 --> 0.055493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0553428\n",
      "\tspeed: 0.0341s/iter; left time: 674.9824s\n",
      "\titers: 200, epoch: 13 | loss: 0.0518866\n",
      "\tspeed: 0.0216s/iter; left time: 425.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 226 | Train Loss: 0.0577669 Vali Loss: 0.0554023 Test Loss: 0.0577424\n",
      "Validation loss decreased (0.055493 --> 0.055402).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0606736\n",
      "\tspeed: 0.0393s/iter; left time: 768.9665s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573600\n",
      "\tspeed: 0.0219s/iter; left time: 426.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 226 | Train Loss: 0.0575232 Vali Loss: 0.0553580 Test Loss: 0.0577659\n",
      "Validation loss decreased (0.055402 --> 0.055358).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0550222\n",
      "\tspeed: 0.0346s/iter; left time: 668.2236s\n",
      "\titers: 200, epoch: 15 | loss: 0.0600982\n",
      "\tspeed: 0.0158s/iter; left time: 304.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 226 | Train Loss: 0.0572379 Vali Loss: 0.0551939 Test Loss: 0.0576582\n",
      "Validation loss decreased (0.055358 --> 0.055194).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0585859\n",
      "\tspeed: 0.0326s/iter; left time: 623.2261s\n",
      "\titers: 200, epoch: 16 | loss: 0.0548897\n",
      "\tspeed: 0.0212s/iter; left time: 403.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 226 | Train Loss: 0.0570594 Vali Loss: 0.0551680 Test Loss: 0.0576045\n",
      "Validation loss decreased (0.055194 --> 0.055168).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0570717\n",
      "\tspeed: 0.0328s/iter; left time: 619.0840s\n",
      "\titers: 200, epoch: 17 | loss: 0.0575829\n",
      "\tspeed: 0.0171s/iter; left time: 321.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0569856 Vali Loss: 0.0549979 Test Loss: 0.0573956\n",
      "Validation loss decreased (0.055168 --> 0.054998).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0575156\n",
      "\tspeed: 0.0299s/iter; left time: 556.9840s\n",
      "\titers: 200, epoch: 18 | loss: 0.0545770\n",
      "\tspeed: 0.0154s/iter; left time: 285.1953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0567499 Vali Loss: 0.0549638 Test Loss: 0.0573878\n",
      "Validation loss decreased (0.054998 --> 0.054964).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0576251\n",
      "\tspeed: 0.0311s/iter; left time: 573.1316s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538437\n",
      "\tspeed: 0.0170s/iter; left time: 311.3687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0566140 Vali Loss: 0.0548153 Test Loss: 0.0572582\n",
      "Validation loss decreased (0.054964 --> 0.054815).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549435\n",
      "\tspeed: 0.0370s/iter; left time: 674.0809s\n",
      "\titers: 200, epoch: 20 | loss: 0.0604172\n",
      "\tspeed: 0.0197s/iter; left time: 357.5049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.68s\n",
      "Steps: 226 | Train Loss: 0.0564828 Vali Loss: 0.0547100 Test Loss: 0.0570773\n",
      "Validation loss decreased (0.054815 --> 0.054710).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0577941\n",
      "\tspeed: 0.0342s/iter; left time: 614.9415s\n",
      "\titers: 200, epoch: 21 | loss: 0.0589544\n",
      "\tspeed: 0.0195s/iter; left time: 347.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 226 | Train Loss: 0.0563989 Vali Loss: 0.0548747 Test Loss: 0.0571588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0532447\n",
      "\tspeed: 0.0364s/iter; left time: 646.6842s\n",
      "\titers: 200, epoch: 22 | loss: 0.0579227\n",
      "\tspeed: 0.0174s/iter; left time: 307.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0563174 Vali Loss: 0.0547841 Test Loss: 0.0570779\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529711\n",
      "\tspeed: 0.0317s/iter; left time: 556.5155s\n",
      "\titers: 200, epoch: 23 | loss: 0.0534307\n",
      "\tspeed: 0.0172s/iter; left time: 299.5708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0561656 Vali Loss: 0.0546956 Test Loss: 0.0570976\n",
      "Validation loss decreased (0.054710 --> 0.054696).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0533154\n",
      "\tspeed: 0.0320s/iter; left time: 553.2430s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565265\n",
      "\tspeed: 0.0173s/iter; left time: 297.2476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0560654 Vali Loss: 0.0544975 Test Loss: 0.0569965\n",
      "Validation loss decreased (0.054696 --> 0.054497).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0553172\n",
      "\tspeed: 0.0346s/iter; left time: 590.9189s\n",
      "\titers: 200, epoch: 25 | loss: 0.0583547\n",
      "\tspeed: 0.0168s/iter; left time: 284.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0560763 Vali Loss: 0.0545897 Test Loss: 0.0569591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0532063\n",
      "\tspeed: 0.0335s/iter; left time: 564.5653s\n",
      "\titers: 200, epoch: 26 | loss: 0.0599777\n",
      "\tspeed: 0.0202s/iter; left time: 338.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 226 | Train Loss: 0.0559622 Vali Loss: 0.0546010 Test Loss: 0.0569279\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0548969\n",
      "\tspeed: 0.0322s/iter; left time: 535.6900s\n",
      "\titers: 200, epoch: 27 | loss: 0.0585928\n",
      "\tspeed: 0.0160s/iter; left time: 264.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0559206 Vali Loss: 0.0545490 Test Loss: 0.0569308\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0570990\n",
      "\tspeed: 0.0350s/iter; left time: 573.2734s\n",
      "\titers: 200, epoch: 28 | loss: 0.0536195\n",
      "\tspeed: 0.0202s/iter; left time: 328.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0558758 Vali Loss: 0.0544448 Test Loss: 0.0568816\n",
      "Validation loss decreased (0.054497 --> 0.054445).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0576614\n",
      "\tspeed: 0.0360s/iter; left time: 582.2564s\n",
      "\titers: 200, epoch: 29 | loss: 0.0557368\n",
      "\tspeed: 0.0193s/iter; left time: 310.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 226 | Train Loss: 0.0558452 Vali Loss: 0.0543916 Test Loss: 0.0567876\n",
      "Validation loss decreased (0.054445 --> 0.054392).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537613\n",
      "\tspeed: 0.0356s/iter; left time: 568.2374s\n",
      "\titers: 200, epoch: 30 | loss: 0.0583726\n",
      "\tspeed: 0.0197s/iter; left time: 312.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 226 | Train Loss: 0.0557715 Vali Loss: 0.0544268 Test Loss: 0.0568058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0558028\n",
      "\tspeed: 0.0337s/iter; left time: 529.2667s\n",
      "\titers: 200, epoch: 31 | loss: 0.0578166\n",
      "\tspeed: 0.0179s/iter; left time: 278.8404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 226 | Train Loss: 0.0557194 Vali Loss: 0.0544070 Test Loss: 0.0568181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0546350\n",
      "\tspeed: 0.0384s/iter; left time: 595.2493s\n",
      "\titers: 200, epoch: 32 | loss: 0.0560995\n",
      "\tspeed: 0.0170s/iter; left time: 261.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 226 | Train Loss: 0.0556565 Vali Loss: 0.0543337 Test Loss: 0.0567663\n",
      "Validation loss decreased (0.054392 --> 0.054334).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553093\n",
      "\tspeed: 0.0340s/iter; left time: 518.8935s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544334\n",
      "\tspeed: 0.0158s/iter; left time: 239.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0557085 Vali Loss: 0.0544495 Test Loss: 0.0567643\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0517952\n",
      "\tspeed: 0.0335s/iter; left time: 503.3773s\n",
      "\titers: 200, epoch: 34 | loss: 0.0577175\n",
      "\tspeed: 0.0186s/iter; left time: 277.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0556033 Vali Loss: 0.0542944 Test Loss: 0.0567092\n",
      "Validation loss decreased (0.054334 --> 0.054294).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0554626\n",
      "\tspeed: 0.0333s/iter; left time: 493.7844s\n",
      "\titers: 200, epoch: 35 | loss: 0.0574955\n",
      "\tspeed: 0.0172s/iter; left time: 252.4543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0556600 Vali Loss: 0.0544349 Test Loss: 0.0567912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0561451\n",
      "\tspeed: 0.0317s/iter; left time: 462.0321s\n",
      "\titers: 200, epoch: 36 | loss: 0.0557724\n",
      "\tspeed: 0.0182s/iter; left time: 263.9853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0555661 Vali Loss: 0.0543601 Test Loss: 0.0567166\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0554360\n",
      "\tspeed: 0.0333s/iter; left time: 478.6523s\n",
      "\titers: 200, epoch: 37 | loss: 0.0573009\n",
      "\tspeed: 0.0201s/iter; left time: 286.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 226 | Train Loss: 0.0556243 Vali Loss: 0.0543863 Test Loss: 0.0567281\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0536021\n",
      "\tspeed: 0.0335s/iter; left time: 474.1719s\n",
      "\titers: 200, epoch: 38 | loss: 0.0571662\n",
      "\tspeed: 0.0178s/iter; left time: 250.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0555641 Vali Loss: 0.0543375 Test Loss: 0.0567224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0549302\n",
      "\tspeed: 0.0352s/iter; left time: 489.1106s\n",
      "\titers: 200, epoch: 39 | loss: 0.0537636\n",
      "\tspeed: 0.0171s/iter; left time: 236.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0555776 Vali Loss: 0.0542915 Test Loss: 0.0567141\n",
      "Validation loss decreased (0.054294 --> 0.054291).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0591478\n",
      "\tspeed: 0.0335s/iter; left time: 458.8138s\n",
      "\titers: 200, epoch: 40 | loss: 0.0551421\n",
      "\tspeed: 0.0189s/iter; left time: 256.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0555408 Vali Loss: 0.0542786 Test Loss: 0.0566839\n",
      "Validation loss decreased (0.054291 --> 0.054279).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0548276\n",
      "\tspeed: 0.0344s/iter; left time: 462.9470s\n",
      "\titers: 200, epoch: 41 | loss: 0.0597277\n",
      "\tspeed: 0.0158s/iter; left time: 211.6258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0555752 Vali Loss: 0.0542433 Test Loss: 0.0566768\n",
      "Validation loss decreased (0.054279 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0533049\n",
      "\tspeed: 0.0370s/iter; left time: 489.7141s\n",
      "\titers: 200, epoch: 42 | loss: 0.0562531\n",
      "\tspeed: 0.0172s/iter; left time: 225.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0555230 Vali Loss: 0.0542666 Test Loss: 0.0566782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0556623\n",
      "\tspeed: 0.0317s/iter; left time: 412.4533s\n",
      "\titers: 200, epoch: 43 | loss: 0.0522621\n",
      "\tspeed: 0.0143s/iter; left time: 184.1355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0555398 Vali Loss: 0.0542849 Test Loss: 0.0567014\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0547930\n",
      "\tspeed: 0.0364s/iter; left time: 465.2045s\n",
      "\titers: 200, epoch: 44 | loss: 0.0556331\n",
      "\tspeed: 0.0173s/iter; left time: 220.0462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 226 | Train Loss: 0.0555342 Vali Loss: 0.0542565 Test Loss: 0.0566445\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0550974\n",
      "\tspeed: 0.0316s/iter; left time: 396.7160s\n",
      "\titers: 200, epoch: 45 | loss: 0.0577911\n",
      "\tspeed: 0.0199s/iter; left time: 248.0192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 226 | Train Loss: 0.0554842 Vali Loss: 0.0542433 Test Loss: 0.0566635\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0575353\n",
      "\tspeed: 0.0373s/iter; left time: 460.4084s\n",
      "\titers: 200, epoch: 46 | loss: 0.0522142\n",
      "\tspeed: 0.0186s/iter; left time: 226.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 226 | Train Loss: 0.0554918 Vali Loss: 0.0542934 Test Loss: 0.0567038\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0574253\n",
      "\tspeed: 0.0366s/iter; left time: 442.6720s\n",
      "\titers: 200, epoch: 47 | loss: 0.0566233\n",
      "\tspeed: 0.0188s/iter; left time: 225.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.72s\n",
      "Steps: 226 | Train Loss: 0.0554435 Vali Loss: 0.0542549 Test Loss: 0.0566532\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0553350\n",
      "\tspeed: 0.0327s/iter; left time: 388.8370s\n",
      "\titers: 200, epoch: 48 | loss: 0.0556369\n",
      "\tspeed: 0.0110s/iter; left time: 129.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0554421 Vali Loss: 0.0542326 Test Loss: 0.0566230\n",
      "Validation loss decreased (0.054243 --> 0.054233).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0547879\n",
      "\tspeed: 0.0266s/iter; left time: 309.4427s\n",
      "\titers: 200, epoch: 49 | loss: 0.0571191\n",
      "\tspeed: 0.0154s/iter; left time: 178.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.45s\n",
      "Steps: 226 | Train Loss: 0.0554875 Vali Loss: 0.0542973 Test Loss: 0.0566744\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0545607\n",
      "\tspeed: 0.0302s/iter; left time: 345.2076s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601258\n",
      "\tspeed: 0.0158s/iter; left time: 179.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0554540 Vali Loss: 0.0543102 Test Loss: 0.0566505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0563313\n",
      "\tspeed: 0.0290s/iter; left time: 325.0505s\n",
      "\titers: 200, epoch: 51 | loss: 0.0548222\n",
      "\tspeed: 0.0199s/iter; left time: 221.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0554719 Vali Loss: 0.0542533 Test Loss: 0.0566383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0545011\n",
      "\tspeed: 0.0325s/iter; left time: 356.8565s\n",
      "\titers: 200, epoch: 52 | loss: 0.0588692\n",
      "\tspeed: 0.0156s/iter; left time: 169.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 226 | Train Loss: 0.0554400 Vali Loss: 0.0542348 Test Loss: 0.0566454\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0573895\n",
      "\tspeed: 0.0347s/iter; left time: 373.1242s\n",
      "\titers: 200, epoch: 53 | loss: 0.0557008\n",
      "\tspeed: 0.0129s/iter; left time: 137.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0554208 Vali Loss: 0.0542583 Test Loss: 0.0566513\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0584419\n",
      "\tspeed: 0.0320s/iter; left time: 336.7609s\n",
      "\titers: 200, epoch: 54 | loss: 0.0557770\n",
      "\tspeed: 0.0162s/iter; left time: 169.1376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0554332 Vali Loss: 0.0543062 Test Loss: 0.0566685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0592031\n",
      "\tspeed: 0.0389s/iter; left time: 400.3010s\n",
      "\titers: 200, epoch: 55 | loss: 0.0580452\n",
      "\tspeed: 0.0206s/iter; left time: 210.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 226 | Train Loss: 0.0554006 Vali Loss: 0.0542188 Test Loss: 0.0566485\n",
      "Validation loss decreased (0.054233 --> 0.054219).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0557944\n",
      "\tspeed: 0.0409s/iter; left time: 411.7455s\n",
      "\titers: 200, epoch: 56 | loss: 0.0575436\n",
      "\tspeed: 0.0207s/iter; left time: 206.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0554949 Vali Loss: 0.0542535 Test Loss: 0.0566425\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0552367\n",
      "\tspeed: 0.0414s/iter; left time: 407.1292s\n",
      "\titers: 200, epoch: 57 | loss: 0.0526632\n",
      "\tspeed: 0.0241s/iter; left time: 235.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 226 | Train Loss: 0.0554752 Vali Loss: 0.0542661 Test Loss: 0.0566391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0547907\n",
      "\tspeed: 0.0400s/iter; left time: 384.9602s\n",
      "\titers: 200, epoch: 58 | loss: 0.0545247\n",
      "\tspeed: 0.0207s/iter; left time: 196.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0554905 Vali Loss: 0.0541866 Test Loss: 0.0566272\n",
      "Validation loss decreased (0.054219 --> 0.054187).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0552047\n",
      "\tspeed: 0.0409s/iter; left time: 384.3971s\n",
      "\titers: 200, epoch: 59 | loss: 0.0546905\n",
      "\tspeed: 0.0208s/iter; left time: 193.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554464 Vali Loss: 0.0542363 Test Loss: 0.0566469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0582271\n",
      "\tspeed: 0.0398s/iter; left time: 365.0822s\n",
      "\titers: 200, epoch: 60 | loss: 0.0584647\n",
      "\tspeed: 0.0210s/iter; left time: 190.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0553746 Vali Loss: 0.0542754 Test Loss: 0.0566607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0538022\n",
      "\tspeed: 0.0400s/iter; left time: 357.9140s\n",
      "\titers: 200, epoch: 61 | loss: 0.0595238\n",
      "\tspeed: 0.0210s/iter; left time: 185.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0554177 Vali Loss: 0.0542619 Test Loss: 0.0566389\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0548657\n",
      "\tspeed: 0.0397s/iter; left time: 345.9753s\n",
      "\titers: 200, epoch: 62 | loss: 0.0552229\n",
      "\tspeed: 0.0208s/iter; left time: 179.1133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0553776 Vali Loss: 0.0542065 Test Loss: 0.0566425\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0586561\n",
      "\tspeed: 0.0395s/iter; left time: 335.5264s\n",
      "\titers: 200, epoch: 63 | loss: 0.0528608\n",
      "\tspeed: 0.0208s/iter; left time: 174.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0554656 Vali Loss: 0.0543084 Test Loss: 0.0566508\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0573308\n",
      "\tspeed: 0.0396s/iter; left time: 327.3391s\n",
      "\titers: 200, epoch: 64 | loss: 0.0524875\n",
      "\tspeed: 0.0207s/iter; left time: 168.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0554920 Vali Loss: 0.0543357 Test Loss: 0.0566719\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0554935\n",
      "\tspeed: 0.0400s/iter; left time: 321.1642s\n",
      "\titers: 200, epoch: 65 | loss: 0.0556387\n",
      "\tspeed: 0.0209s/iter; left time: 166.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554536 Vali Loss: 0.0542445 Test Loss: 0.0566510\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0557238\n",
      "\tspeed: 0.0407s/iter; left time: 317.9882s\n",
      "\titers: 200, epoch: 66 | loss: 0.0578800\n",
      "\tspeed: 0.0207s/iter; left time: 159.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0554466 Vali Loss: 0.0542907 Test Loss: 0.0566411\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0559544\n",
      "\tspeed: 0.0414s/iter; left time: 314.2850s\n",
      "\titers: 200, epoch: 67 | loss: 0.0554192\n",
      "\tspeed: 0.0211s/iter; left time: 158.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0554506 Vali Loss: 0.0542586 Test Loss: 0.0566385\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0526508\n",
      "\tspeed: 0.0402s/iter; left time: 295.5240s\n",
      "\titers: 200, epoch: 68 | loss: 0.0582800\n",
      "\tspeed: 0.0209s/iter; left time: 151.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0554338 Vali Loss: 0.0542876 Test Loss: 0.0566296\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010013620369136333, rmse:0.10006807744503021, mae:0.05662719905376434, rse:0.3781079947948456\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1573607\n",
      "\tspeed: 0.0223s/iter; left time: 501.1747s\n",
      "\titers: 200, epoch: 1 | loss: 0.1300314\n",
      "\tspeed: 0.0211s/iter; left time: 473.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.1577573 Vali Loss: 0.1105426 Test Loss: 0.1145439\n",
      "Validation loss decreased (inf --> 0.110543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0793203\n",
      "\tspeed: 0.0412s/iter; left time: 917.2832s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723160\n",
      "\tspeed: 0.0207s/iter; left time: 458.9329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0822697 Vali Loss: 0.0660343 Test Loss: 0.0675971\n",
      "Validation loss decreased (0.110543 --> 0.066034).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0746850\n",
      "\tspeed: 0.0424s/iter; left time: 935.3700s\n",
      "\titers: 200, epoch: 3 | loss: 0.0648276\n",
      "\tspeed: 0.0207s/iter; left time: 455.0452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 226 | Train Loss: 0.0688575 Vali Loss: 0.0622213 Test Loss: 0.0644347\n",
      "Validation loss decreased (0.066034 --> 0.062221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676612\n",
      "\tspeed: 0.0410s/iter; left time: 893.8046s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647271\n",
      "\tspeed: 0.0206s/iter; left time: 448.5015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0654854 Vali Loss: 0.0597844 Test Loss: 0.0622531\n",
      "Validation loss decreased (0.062221 --> 0.059784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0643532\n",
      "\tspeed: 0.0410s/iter; left time: 885.2005s\n",
      "\titers: 200, epoch: 5 | loss: 0.0649878\n",
      "\tspeed: 0.0208s/iter; left time: 447.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0632192 Vali Loss: 0.0583535 Test Loss: 0.0607662\n",
      "Validation loss decreased (0.059784 --> 0.058354).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0636768\n",
      "\tspeed: 0.0413s/iter; left time: 883.6520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0600426\n",
      "\tspeed: 0.0208s/iter; left time: 442.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0617498 Vali Loss: 0.0575012 Test Loss: 0.0599200\n",
      "Validation loss decreased (0.058354 --> 0.057501).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585431\n",
      "\tspeed: 0.0420s/iter; left time: 887.2518s\n",
      "\titers: 200, epoch: 7 | loss: 0.0626427\n",
      "\tspeed: 0.0207s/iter; left time: 435.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0607552 Vali Loss: 0.0570765 Test Loss: 0.0593813\n",
      "Validation loss decreased (0.057501 --> 0.057077).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0621818\n",
      "\tspeed: 0.0453s/iter; left time: 947.4440s\n",
      "\titers: 200, epoch: 8 | loss: 0.0585240\n",
      "\tspeed: 0.0223s/iter; left time: 463.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 226 | Train Loss: 0.0598608 Vali Loss: 0.0566811 Test Loss: 0.0587871\n",
      "Validation loss decreased (0.057077 --> 0.056681).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0634323\n",
      "\tspeed: 0.0434s/iter; left time: 898.4721s\n",
      "\titers: 200, epoch: 9 | loss: 0.0529604\n",
      "\tspeed: 0.0216s/iter; left time: 445.1481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 226 | Train Loss: 0.0592861 Vali Loss: 0.0563962 Test Loss: 0.0584393\n",
      "Validation loss decreased (0.056681 --> 0.056396).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0588704\n",
      "\tspeed: 0.0410s/iter; left time: 840.1156s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591631\n",
      "\tspeed: 0.0207s/iter; left time: 421.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0588297 Vali Loss: 0.0560655 Test Loss: 0.0582095\n",
      "Validation loss decreased (0.056396 --> 0.056065).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0584188\n",
      "\tspeed: 0.0406s/iter; left time: 822.6313s\n",
      "\titers: 200, epoch: 11 | loss: 0.0559009\n",
      "\tspeed: 0.0206s/iter; left time: 415.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0584830 Vali Loss: 0.0559946 Test Loss: 0.0581161\n",
      "Validation loss decreased (0.056065 --> 0.055995).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601121\n",
      "\tspeed: 0.0408s/iter; left time: 817.4414s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607920\n",
      "\tspeed: 0.0208s/iter; left time: 413.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0580687 Vali Loss: 0.0558722 Test Loss: 0.0578477\n",
      "Validation loss decreased (0.055995 --> 0.055872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0583283\n",
      "\tspeed: 0.0406s/iter; left time: 803.1971s\n",
      "\titers: 200, epoch: 13 | loss: 0.0573606\n",
      "\tspeed: 0.0206s/iter; left time: 405.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0577804 Vali Loss: 0.0556091 Test Loss: 0.0576085\n",
      "Validation loss decreased (0.055872 --> 0.055609).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0578804\n",
      "\tspeed: 0.0409s/iter; left time: 799.8185s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590153\n",
      "\tspeed: 0.0207s/iter; left time: 403.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0575066 Vali Loss: 0.0554821 Test Loss: 0.0575015\n",
      "Validation loss decreased (0.055609 --> 0.055482).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571506\n",
      "\tspeed: 0.0403s/iter; left time: 778.3618s\n",
      "\titers: 200, epoch: 15 | loss: 0.0561143\n",
      "\tspeed: 0.0206s/iter; left time: 397.1777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0572847 Vali Loss: 0.0552979 Test Loss: 0.0573816\n",
      "Validation loss decreased (0.055482 --> 0.055298).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0606932\n",
      "\tspeed: 0.0411s/iter; left time: 785.0597s\n",
      "\titers: 200, epoch: 16 | loss: 0.0601799\n",
      "\tspeed: 0.0209s/iter; left time: 397.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0570542 Vali Loss: 0.0552463 Test Loss: 0.0573230\n",
      "Validation loss decreased (0.055298 --> 0.055246).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562132\n",
      "\tspeed: 0.0421s/iter; left time: 795.8917s\n",
      "\titers: 200, epoch: 17 | loss: 0.0517945\n",
      "\tspeed: 0.0207s/iter; left time: 388.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0569558 Vali Loss: 0.0551512 Test Loss: 0.0572169\n",
      "Validation loss decreased (0.055246 --> 0.055151).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549782\n",
      "\tspeed: 0.0406s/iter; left time: 757.9198s\n",
      "\titers: 200, epoch: 18 | loss: 0.0557214\n",
      "\tspeed: 0.0207s/iter; left time: 383.2907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0567689 Vali Loss: 0.0550626 Test Loss: 0.0571761\n",
      "Validation loss decreased (0.055151 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578548\n",
      "\tspeed: 0.0408s/iter; left time: 751.9434s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540285\n",
      "\tspeed: 0.0207s/iter; left time: 380.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0566034 Vali Loss: 0.0548398 Test Loss: 0.0571010\n",
      "Validation loss decreased (0.055063 --> 0.054840).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0574559\n",
      "\tspeed: 0.0437s/iter; left time: 796.3183s\n",
      "\titers: 200, epoch: 20 | loss: 0.0562656\n",
      "\tspeed: 0.0207s/iter; left time: 374.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0564844 Vali Loss: 0.0550186 Test Loss: 0.0571432\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0561579\n",
      "\tspeed: 0.0405s/iter; left time: 728.9998s\n",
      "\titers: 200, epoch: 21 | loss: 0.0594371\n",
      "\tspeed: 0.0207s/iter; left time: 369.8702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0563916 Vali Loss: 0.0548216 Test Loss: 0.0570241\n",
      "Validation loss decreased (0.054840 --> 0.054822).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0581695\n",
      "\tspeed: 0.0408s/iter; left time: 725.0918s\n",
      "\titers: 200, epoch: 22 | loss: 0.0569547\n",
      "\tspeed: 0.0208s/iter; left time: 367.2073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0561927 Vali Loss: 0.0548563 Test Loss: 0.0569162\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0582812\n",
      "\tspeed: 0.0404s/iter; left time: 708.2660s\n",
      "\titers: 200, epoch: 23 | loss: 0.0591026\n",
      "\tspeed: 0.0206s/iter; left time: 359.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0562241 Vali Loss: 0.0548312 Test Loss: 0.0568969\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0575212\n",
      "\tspeed: 0.0405s/iter; left time: 701.1362s\n",
      "\titers: 200, epoch: 24 | loss: 0.0577626\n",
      "\tspeed: 0.0208s/iter; left time: 357.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0560995 Vali Loss: 0.0546449 Test Loss: 0.0568261\n",
      "Validation loss decreased (0.054822 --> 0.054645).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0569925\n",
      "\tspeed: 0.0414s/iter; left time: 707.1271s\n",
      "\titers: 200, epoch: 25 | loss: 0.0539485\n",
      "\tspeed: 0.0208s/iter; left time: 352.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 226 | Train Loss: 0.0560700 Vali Loss: 0.0546967 Test Loss: 0.0567787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0563161\n",
      "\tspeed: 0.0406s/iter; left time: 684.3640s\n",
      "\titers: 200, epoch: 26 | loss: 0.0521550\n",
      "\tspeed: 0.0212s/iter; left time: 354.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0559894 Vali Loss: 0.0546580 Test Loss: 0.0567892\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0538891\n",
      "\tspeed: 0.0410s/iter; left time: 682.0252s\n",
      "\titers: 200, epoch: 27 | loss: 0.0539563\n",
      "\tspeed: 0.0207s/iter; left time: 342.8657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0559241 Vali Loss: 0.0546632 Test Loss: 0.0567738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0540387\n",
      "\tspeed: 0.0402s/iter; left time: 659.2702s\n",
      "\titers: 200, epoch: 28 | loss: 0.0539434\n",
      "\tspeed: 0.0207s/iter; left time: 338.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0559196 Vali Loss: 0.0546260 Test Loss: 0.0567322\n",
      "Validation loss decreased (0.054645 --> 0.054626).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0551787\n",
      "\tspeed: 0.0415s/iter; left time: 670.8148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0559215\n",
      "\tspeed: 0.0208s/iter; left time: 334.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0558759 Vali Loss: 0.0545475 Test Loss: 0.0567204\n",
      "Validation loss decreased (0.054626 --> 0.054548).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0539703\n",
      "\tspeed: 0.0407s/iter; left time: 649.3731s\n",
      "\titers: 200, epoch: 30 | loss: 0.0529386\n",
      "\tspeed: 0.0220s/iter; left time: 348.6622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 226 | Train Loss: 0.0558195 Vali Loss: 0.0545579 Test Loss: 0.0566725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0549525\n",
      "\tspeed: 0.0403s/iter; left time: 633.1932s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581255\n",
      "\tspeed: 0.0210s/iter; left time: 327.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 226 | Train Loss: 0.0557404 Vali Loss: 0.0544842 Test Loss: 0.0566326\n",
      "Validation loss decreased (0.054548 --> 0.054484).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0531414\n",
      "\tspeed: 0.0407s/iter; left time: 629.8803s\n",
      "\titers: 200, epoch: 32 | loss: 0.0568882\n",
      "\tspeed: 0.0208s/iter; left time: 320.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0557324 Vali Loss: 0.0545144 Test Loss: 0.0566872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0525673\n",
      "\tspeed: 0.0407s/iter; left time: 620.7663s\n",
      "\titers: 200, epoch: 33 | loss: 0.0552366\n",
      "\tspeed: 0.0208s/iter; left time: 314.8116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 226 | Train Loss: 0.0557313 Vali Loss: 0.0545479 Test Loss: 0.0566107\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0545913\n",
      "\tspeed: 0.0407s/iter; left time: 612.7376s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527151\n",
      "\tspeed: 0.0214s/iter; left time: 320.3710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0556540 Vali Loss: 0.0545217 Test Loss: 0.0565855\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0528577\n",
      "\tspeed: 0.0404s/iter; left time: 598.0508s\n",
      "\titers: 200, epoch: 35 | loss: 0.0565141\n",
      "\tspeed: 0.0222s/iter; left time: 326.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 226 | Train Loss: 0.0556809 Vali Loss: 0.0545160 Test Loss: 0.0565746\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0542427\n",
      "\tspeed: 0.0414s/iter; left time: 603.8443s\n",
      "\titers: 200, epoch: 36 | loss: 0.0564523\n",
      "\tspeed: 0.0208s/iter; left time: 301.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0556686 Vali Loss: 0.0544228 Test Loss: 0.0565843\n",
      "Validation loss decreased (0.054484 --> 0.054423).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0549694\n",
      "\tspeed: 0.0408s/iter; left time: 586.3012s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558352\n",
      "\tspeed: 0.0208s/iter; left time: 296.1056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 226 | Train Loss: 0.0556525 Vali Loss: 0.0544250 Test Loss: 0.0566035\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0556710\n",
      "\tspeed: 0.0408s/iter; left time: 576.6104s\n",
      "\titers: 200, epoch: 38 | loss: 0.0572953\n",
      "\tspeed: 0.0212s/iter; left time: 297.9368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 226 | Train Loss: 0.0556188 Vali Loss: 0.0544323 Test Loss: 0.0565958\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0535805\n",
      "\tspeed: 0.0412s/iter; left time: 572.9118s\n",
      "\titers: 200, epoch: 39 | loss: 0.0622349\n",
      "\tspeed: 0.0208s/iter; left time: 287.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 226 | Train Loss: 0.0556048 Vali Loss: 0.0544680 Test Loss: 0.0565738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0561483\n",
      "\tspeed: 0.0412s/iter; left time: 564.3674s\n",
      "\titers: 200, epoch: 40 | loss: 0.0531933\n",
      "\tspeed: 0.0207s/iter; left time: 281.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 226 | Train Loss: 0.0555662 Vali Loss: 0.0544984 Test Loss: 0.0565711\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0561239\n",
      "\tspeed: 0.0408s/iter; left time: 549.7383s\n",
      "\titers: 200, epoch: 41 | loss: 0.0517765\n",
      "\tspeed: 0.0217s/iter; left time: 289.5929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 226 | Train Loss: 0.0555728 Vali Loss: 0.0543907 Test Loss: 0.0565282\n",
      "Validation loss decreased (0.054423 --> 0.054391).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0523082\n",
      "\tspeed: 0.0408s/iter; left time: 540.0180s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538820\n",
      "\tspeed: 0.0208s/iter; left time: 272.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 226 | Train Loss: 0.0555350 Vali Loss: 0.0544950 Test Loss: 0.0565574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0518777\n",
      "\tspeed: 0.0401s/iter; left time: 521.5896s\n",
      "\titers: 200, epoch: 43 | loss: 0.0526231\n",
      "\tspeed: 0.0207s/iter; left time: 267.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0555422 Vali Loss: 0.0543530 Test Loss: 0.0565322\n",
      "Validation loss decreased (0.054391 --> 0.054353).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0558865\n",
      "\tspeed: 0.0432s/iter; left time: 552.5992s\n",
      "\titers: 200, epoch: 44 | loss: 0.0584679\n",
      "\tspeed: 0.0217s/iter; left time: 275.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 226 | Train Loss: 0.0555280 Vali Loss: 0.0543507 Test Loss: 0.0565503\n",
      "Validation loss decreased (0.054353 --> 0.054351).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0574074\n",
      "\tspeed: 0.0420s/iter; left time: 528.0008s\n",
      "\titers: 200, epoch: 45 | loss: 0.0555215\n",
      "\tspeed: 0.0212s/iter; left time: 264.6747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 226 | Train Loss: 0.0555235 Vali Loss: 0.0544811 Test Loss: 0.0565407\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0546385\n",
      "\tspeed: 0.0412s/iter; left time: 508.5139s\n",
      "\titers: 200, epoch: 46 | loss: 0.0590151\n",
      "\tspeed: 0.0210s/iter; left time: 256.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0555281 Vali Loss: 0.0544902 Test Loss: 0.0565665\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0578885\n",
      "\tspeed: 0.0403s/iter; left time: 487.7635s\n",
      "\titers: 200, epoch: 47 | loss: 0.0509819\n",
      "\tspeed: 0.0207s/iter; left time: 248.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0555610 Vali Loss: 0.0544188 Test Loss: 0.0565211\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0543291\n",
      "\tspeed: 0.0414s/iter; left time: 491.3178s\n",
      "\titers: 200, epoch: 48 | loss: 0.0562213\n",
      "\tspeed: 0.0212s/iter; left time: 249.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 226 | Train Loss: 0.0555136 Vali Loss: 0.0544448 Test Loss: 0.0565119\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0515884\n",
      "\tspeed: 0.0400s/iter; left time: 466.3707s\n",
      "\titers: 200, epoch: 49 | loss: 0.0570134\n",
      "\tspeed: 0.0207s/iter; left time: 239.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0555256 Vali Loss: 0.0544299 Test Loss: 0.0565411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0553536\n",
      "\tspeed: 0.0418s/iter; left time: 477.6535s\n",
      "\titers: 200, epoch: 50 | loss: 0.0554720\n",
      "\tspeed: 0.0207s/iter; left time: 234.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0554629 Vali Loss: 0.0543953 Test Loss: 0.0565168\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0514704\n",
      "\tspeed: 0.0408s/iter; left time: 456.4795s\n",
      "\titers: 200, epoch: 51 | loss: 0.0539592\n",
      "\tspeed: 0.0208s/iter; left time: 230.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0554583 Vali Loss: 0.0544391 Test Loss: 0.0565219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0580358\n",
      "\tspeed: 0.0400s/iter; left time: 439.3845s\n",
      "\titers: 200, epoch: 52 | loss: 0.0561351\n",
      "\tspeed: 0.0208s/iter; left time: 225.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0555748 Vali Loss: 0.0544157 Test Loss: 0.0565323\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0542540\n",
      "\tspeed: 0.0416s/iter; left time: 447.1590s\n",
      "\titers: 200, epoch: 53 | loss: 0.0574763\n",
      "\tspeed: 0.0211s/iter; left time: 224.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0554894 Vali Loss: 0.0544404 Test Loss: 0.0565196\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0552687\n",
      "\tspeed: 0.0401s/iter; left time: 422.0096s\n",
      "\titers: 200, epoch: 54 | loss: 0.0548174\n",
      "\tspeed: 0.0211s/iter; left time: 219.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0555267 Vali Loss: 0.0543990 Test Loss: 0.0565228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009993644431233406, rmse:0.09996821731328964, mae:0.05655033513903618, rse:0.37773069739341736\n",
      "Intermediate time for IT and pred_len 24: 00h:11m:50.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1669092\n",
      "\tspeed: 0.0452s/iter; left time: 1012.5820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1401041\n",
      "\tspeed: 0.0207s/iter; left time: 461.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.1638128 Vali Loss: 0.1188383 Test Loss: 0.1233246\n",
      "Validation loss decreased (inf --> 0.118838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1033055\n",
      "\tspeed: 0.0424s/iter; left time: 941.3287s\n",
      "\titers: 200, epoch: 2 | loss: 0.0938538\n",
      "\tspeed: 0.0208s/iter; left time: 459.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.1024199 Vali Loss: 0.0843555 Test Loss: 0.0881399\n",
      "Validation loss decreased (0.118838 --> 0.084356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874186\n",
      "\tspeed: 0.0430s/iter; left time: 944.8962s\n",
      "\titers: 200, epoch: 3 | loss: 0.0862540\n",
      "\tspeed: 0.0210s/iter; left time: 459.1061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0883068 Vali Loss: 0.0805757 Test Loss: 0.0844691\n",
      "Validation loss decreased (0.084356 --> 0.080576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0822606\n",
      "\tspeed: 0.0446s/iter; left time: 970.0285s\n",
      "\titers: 200, epoch: 4 | loss: 0.0853445\n",
      "\tspeed: 0.0209s/iter; left time: 451.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0851258 Vali Loss: 0.0790129 Test Loss: 0.0829461\n",
      "Validation loss decreased (0.080576 --> 0.079013).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0794841\n",
      "\tspeed: 0.0420s/iter; left time: 904.0994s\n",
      "\titers: 200, epoch: 5 | loss: 0.0796301\n",
      "\tspeed: 0.0208s/iter; left time: 445.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0833385 Vali Loss: 0.0780248 Test Loss: 0.0820323\n",
      "Validation loss decreased (0.079013 --> 0.078025).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0790213\n",
      "\tspeed: 0.0420s/iter; left time: 892.9639s\n",
      "\titers: 200, epoch: 6 | loss: 0.0824916\n",
      "\tspeed: 0.0209s/iter; left time: 443.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0820430 Vali Loss: 0.0773483 Test Loss: 0.0812382\n",
      "Validation loss decreased (0.078025 --> 0.077348).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770506\n",
      "\tspeed: 0.0432s/iter; left time: 910.1604s\n",
      "\titers: 200, epoch: 7 | loss: 0.0813279\n",
      "\tspeed: 0.0207s/iter; left time: 433.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0810946 Vali Loss: 0.0771037 Test Loss: 0.0812631\n",
      "Validation loss decreased (0.077348 --> 0.077104).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0820660\n",
      "\tspeed: 0.0430s/iter; left time: 895.8289s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803185\n",
      "\tspeed: 0.0206s/iter; left time: 427.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0803903 Vali Loss: 0.0763726 Test Loss: 0.0802872\n",
      "Validation loss decreased (0.077104 --> 0.076373).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0789092\n",
      "\tspeed: 0.0433s/iter; left time: 891.1467s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763635\n",
      "\tspeed: 0.0208s/iter; left time: 425.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0797350 Vali Loss: 0.0760175 Test Loss: 0.0801024\n",
      "Validation loss decreased (0.076373 --> 0.076018).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0757352\n",
      "\tspeed: 0.0423s/iter; left time: 862.3985s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821360\n",
      "\tspeed: 0.0207s/iter; left time: 419.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0792618 Vali Loss: 0.0760024 Test Loss: 0.0800756\n",
      "Validation loss decreased (0.076018 --> 0.076002).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0765340\n",
      "\tspeed: 0.0424s/iter; left time: 854.6667s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766016\n",
      "\tspeed: 0.0208s/iter; left time: 417.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0788864 Vali Loss: 0.0757054 Test Loss: 0.0797140\n",
      "Validation loss decreased (0.076002 --> 0.075705).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787157\n",
      "\tspeed: 0.0427s/iter; left time: 850.0699s\n",
      "\titers: 200, epoch: 12 | loss: 0.0781840\n",
      "\tspeed: 0.0208s/iter; left time: 412.6570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0785617 Vali Loss: 0.0754555 Test Loss: 0.0794976\n",
      "Validation loss decreased (0.075705 --> 0.075456).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0803629\n",
      "\tspeed: 0.0424s/iter; left time: 835.8411s\n",
      "\titers: 200, epoch: 13 | loss: 0.0813732\n",
      "\tspeed: 0.0208s/iter; left time: 407.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0782243 Vali Loss: 0.0753873 Test Loss: 0.0795178\n",
      "Validation loss decreased (0.075456 --> 0.075387).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0805302\n",
      "\tspeed: 0.0426s/iter; left time: 830.4879s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788860\n",
      "\tspeed: 0.0208s/iter; left time: 403.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0779015 Vali Loss: 0.0751808 Test Loss: 0.0794455\n",
      "Validation loss decreased (0.075387 --> 0.075181).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0773549\n",
      "\tspeed: 0.0425s/iter; left time: 817.5567s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791559\n",
      "\tspeed: 0.0227s/iter; left time: 434.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0777317 Vali Loss: 0.0751953 Test Loss: 0.0795967\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785272\n",
      "\tspeed: 0.0422s/iter; left time: 802.9055s\n",
      "\titers: 200, epoch: 16 | loss: 0.0769728\n",
      "\tspeed: 0.0209s/iter; left time: 394.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0774655 Vali Loss: 0.0749888 Test Loss: 0.0792939\n",
      "Validation loss decreased (0.075181 --> 0.074989).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0769738\n",
      "\tspeed: 0.0438s/iter; left time: 824.3760s\n",
      "\titers: 200, epoch: 17 | loss: 0.0778376\n",
      "\tspeed: 0.0213s/iter; left time: 398.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0772400 Vali Loss: 0.0750678 Test Loss: 0.0794692\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0805343\n",
      "\tspeed: 0.0424s/iter; left time: 787.8991s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752611\n",
      "\tspeed: 0.0207s/iter; left time: 383.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0770767 Vali Loss: 0.0748767 Test Loss: 0.0791836\n",
      "Validation loss decreased (0.074989 --> 0.074877).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779965\n",
      "\tspeed: 0.0429s/iter; left time: 787.0227s\n",
      "\titers: 200, epoch: 19 | loss: 0.0749951\n",
      "\tspeed: 0.0209s/iter; left time: 380.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0769474 Vali Loss: 0.0746936 Test Loss: 0.0789684\n",
      "Validation loss decreased (0.074877 --> 0.074694).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0736500\n",
      "\tspeed: 0.0420s/iter; left time: 762.0740s\n",
      "\titers: 200, epoch: 20 | loss: 0.0772865\n",
      "\tspeed: 0.0207s/iter; left time: 373.4359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0767863 Vali Loss: 0.0748690 Test Loss: 0.0791829\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0763280\n",
      "\tspeed: 0.0422s/iter; left time: 755.2023s\n",
      "\titers: 200, epoch: 21 | loss: 0.0714772\n",
      "\tspeed: 0.0208s/iter; left time: 370.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0766963 Vali Loss: 0.0748559 Test Loss: 0.0792080\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0795258\n",
      "\tspeed: 0.0434s/iter; left time: 766.9435s\n",
      "\titers: 200, epoch: 22 | loss: 0.0783744\n",
      "\tspeed: 0.0208s/iter; left time: 365.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0765899 Vali Loss: 0.0747872 Test Loss: 0.0790109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0773060\n",
      "\tspeed: 0.0423s/iter; left time: 738.0832s\n",
      "\titers: 200, epoch: 23 | loss: 0.0768325\n",
      "\tspeed: 0.0213s/iter; left time: 368.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0765073 Vali Loss: 0.0747645 Test Loss: 0.0790767\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0763985\n",
      "\tspeed: 0.0426s/iter; left time: 733.1196s\n",
      "\titers: 200, epoch: 24 | loss: 0.0742462\n",
      "\tspeed: 0.0208s/iter; left time: 355.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0763747 Vali Loss: 0.0746120 Test Loss: 0.0790180\n",
      "Validation loss decreased (0.074694 --> 0.074612).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0758858\n",
      "\tspeed: 0.0437s/iter; left time: 742.7844s\n",
      "\titers: 200, epoch: 25 | loss: 0.0799969\n",
      "\tspeed: 0.0208s/iter; left time: 351.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0762890 Vali Loss: 0.0746417 Test Loss: 0.0790498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0812193\n",
      "\tspeed: 0.0425s/iter; left time: 713.7002s\n",
      "\titers: 200, epoch: 26 | loss: 0.0759417\n",
      "\tspeed: 0.0208s/iter; left time: 346.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0762690 Vali Loss: 0.0745990 Test Loss: 0.0788645\n",
      "Validation loss decreased (0.074612 --> 0.074599).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0765115\n",
      "\tspeed: 0.0425s/iter; left time: 703.0682s\n",
      "\titers: 200, epoch: 27 | loss: 0.0747217\n",
      "\tspeed: 0.0208s/iter; left time: 342.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0761361 Vali Loss: 0.0745715 Test Loss: 0.0788600\n",
      "Validation loss decreased (0.074599 --> 0.074571).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0780237\n",
      "\tspeed: 0.0427s/iter; left time: 696.8410s\n",
      "\titers: 200, epoch: 28 | loss: 0.0751070\n",
      "\tspeed: 0.0209s/iter; left time: 338.5861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0761311 Vali Loss: 0.0746733 Test Loss: 0.0790727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0780154\n",
      "\tspeed: 0.0419s/iter; left time: 673.9280s\n",
      "\titers: 200, epoch: 29 | loss: 0.0717261\n",
      "\tspeed: 0.0208s/iter; left time: 333.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0760820 Vali Loss: 0.0745423 Test Loss: 0.0788420\n",
      "Validation loss decreased (0.074571 --> 0.074542).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0772073\n",
      "\tspeed: 0.0436s/iter; left time: 691.9070s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782413\n",
      "\tspeed: 0.0209s/iter; left time: 329.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0759955 Vali Loss: 0.0745012 Test Loss: 0.0788583\n",
      "Validation loss decreased (0.074542 --> 0.074501).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0736191\n",
      "\tspeed: 0.0427s/iter; left time: 667.9280s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757232\n",
      "\tspeed: 0.0219s/iter; left time: 339.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0759875 Vali Loss: 0.0745420 Test Loss: 0.0788668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0742540\n",
      "\tspeed: 0.0434s/iter; left time: 668.7807s\n",
      "\titers: 200, epoch: 32 | loss: 0.0766309\n",
      "\tspeed: 0.0209s/iter; left time: 320.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0758916 Vali Loss: 0.0745379 Test Loss: 0.0788726\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0806924\n",
      "\tspeed: 0.0426s/iter; left time: 647.6184s\n",
      "\titers: 200, epoch: 33 | loss: 0.0794868\n",
      "\tspeed: 0.0208s/iter; left time: 314.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0758924 Vali Loss: 0.0745164 Test Loss: 0.0788155\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0811082\n",
      "\tspeed: 0.0425s/iter; left time: 636.3328s\n",
      "\titers: 200, epoch: 34 | loss: 0.0749670\n",
      "\tspeed: 0.0210s/iter; left time: 311.9770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758676 Vali Loss: 0.0745435 Test Loss: 0.0788689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0753011\n",
      "\tspeed: 0.0430s/iter; left time: 633.9118s\n",
      "\titers: 200, epoch: 35 | loss: 0.0762374\n",
      "\tspeed: 0.0208s/iter; left time: 304.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0758858 Vali Loss: 0.0745267 Test Loss: 0.0788663\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0790051\n",
      "\tspeed: 0.0434s/iter; left time: 630.9701s\n",
      "\titers: 200, epoch: 36 | loss: 0.0784262\n",
      "\tspeed: 0.0207s/iter; left time: 298.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758194 Vali Loss: 0.0745543 Test Loss: 0.0789160\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0786390\n",
      "\tspeed: 0.0423s/iter; left time: 604.3992s\n",
      "\titers: 200, epoch: 37 | loss: 0.0717152\n",
      "\tspeed: 0.0208s/iter; left time: 295.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757936 Vali Loss: 0.0745547 Test Loss: 0.0788500\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0799452\n",
      "\tspeed: 0.0417s/iter; left time: 587.3101s\n",
      "\titers: 200, epoch: 38 | loss: 0.0723355\n",
      "\tspeed: 0.0211s/iter; left time: 294.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757439 Vali Loss: 0.0744955 Test Loss: 0.0787958\n",
      "Validation loss decreased (0.074501 --> 0.074495).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0733191\n",
      "\tspeed: 0.0428s/iter; left time: 592.7958s\n",
      "\titers: 200, epoch: 39 | loss: 0.0772472\n",
      "\tspeed: 0.0208s/iter; left time: 286.3662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0757125 Vali Loss: 0.0745277 Test Loss: 0.0788285\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0731022\n",
      "\tspeed: 0.0412s/iter; left time: 561.8233s\n",
      "\titers: 200, epoch: 40 | loss: 0.0813463\n",
      "\tspeed: 0.0208s/iter; left time: 281.5469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757605 Vali Loss: 0.0744777 Test Loss: 0.0787457\n",
      "Validation loss decreased (0.074495 --> 0.074478).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0726994\n",
      "\tspeed: 0.0424s/iter; left time: 567.6496s\n",
      "\titers: 200, epoch: 41 | loss: 0.0707508\n",
      "\tspeed: 0.0209s/iter; left time: 277.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0757570 Vali Loss: 0.0744992 Test Loss: 0.0788272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0751855\n",
      "\tspeed: 0.0425s/iter; left time: 559.6674s\n",
      "\titers: 200, epoch: 42 | loss: 0.0751205\n",
      "\tspeed: 0.0209s/iter; left time: 273.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0757228 Vali Loss: 0.0745397 Test Loss: 0.0788634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0758706\n",
      "\tspeed: 0.0418s/iter; left time: 541.9239s\n",
      "\titers: 200, epoch: 43 | loss: 0.0756615\n",
      "\tspeed: 0.0211s/iter; left time: 271.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756767 Vali Loss: 0.0745036 Test Loss: 0.0788214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0782793\n",
      "\tspeed: 0.0428s/iter; left time: 545.1089s\n",
      "\titers: 200, epoch: 44 | loss: 0.0709118\n",
      "\tspeed: 0.0208s/iter; left time: 262.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756931 Vali Loss: 0.0744941 Test Loss: 0.0787882\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769355\n",
      "\tspeed: 0.0436s/iter; left time: 544.8735s\n",
      "\titers: 200, epoch: 45 | loss: 0.0730018\n",
      "\tspeed: 0.0215s/iter; left time: 267.1578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0757256 Vali Loss: 0.0745007 Test Loss: 0.0788010\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0741454\n",
      "\tspeed: 0.0419s/iter; left time: 514.3173s\n",
      "\titers: 200, epoch: 46 | loss: 0.0757747\n",
      "\tspeed: 0.0208s/iter; left time: 252.7332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0757511 Vali Loss: 0.0745217 Test Loss: 0.0788470\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0733297\n",
      "\tspeed: 0.0424s/iter; left time: 511.4022s\n",
      "\titers: 200, epoch: 47 | loss: 0.0752435\n",
      "\tspeed: 0.0212s/iter; left time: 253.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0756909 Vali Loss: 0.0744966 Test Loss: 0.0787864\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0742979\n",
      "\tspeed: 0.0416s/iter; left time: 492.4860s\n",
      "\titers: 200, epoch: 48 | loss: 0.0754963\n",
      "\tspeed: 0.0208s/iter; left time: 244.2303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0756908 Vali Loss: 0.0744999 Test Loss: 0.0788212\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0724371\n",
      "\tspeed: 0.0419s/iter; left time: 485.7096s\n",
      "\titers: 200, epoch: 49 | loss: 0.0771678\n",
      "\tspeed: 0.0209s/iter; left time: 240.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756535 Vali Loss: 0.0745001 Test Loss: 0.0788215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0750389\n",
      "\tspeed: 0.0418s/iter; left time: 475.4922s\n",
      "\titers: 200, epoch: 50 | loss: 0.0723733\n",
      "\tspeed: 0.0208s/iter; left time: 234.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0756713 Vali Loss: 0.0744728 Test Loss: 0.0788004\n",
      "Validation loss decreased (0.074478 --> 0.074473).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0770440\n",
      "\tspeed: 0.0433s/iter; left time: 483.0598s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769106\n",
      "\tspeed: 0.0208s/iter; left time: 229.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0756731 Vali Loss: 0.0744990 Test Loss: 0.0788114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0742975\n",
      "\tspeed: 0.0423s/iter; left time: 462.5962s\n",
      "\titers: 200, epoch: 52 | loss: 0.0723217\n",
      "\tspeed: 0.0216s/iter; left time: 233.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0755942 Vali Loss: 0.0744465 Test Loss: 0.0787730\n",
      "Validation loss decreased (0.074473 --> 0.074446).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0775662\n",
      "\tspeed: 0.0423s/iter; left time: 452.9437s\n",
      "\titers: 200, epoch: 53 | loss: 0.0746110\n",
      "\tspeed: 0.0208s/iter; left time: 220.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756881 Vali Loss: 0.0744816 Test Loss: 0.0788015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0793720\n",
      "\tspeed: 0.0432s/iter; left time: 452.0537s\n",
      "\titers: 200, epoch: 54 | loss: 0.0751703\n",
      "\tspeed: 0.0208s/iter; left time: 215.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756899 Vali Loss: 0.0744729 Test Loss: 0.0787960\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0773408\n",
      "\tspeed: 0.0417s/iter; left time: 427.0356s\n",
      "\titers: 200, epoch: 55 | loss: 0.0790814\n",
      "\tspeed: 0.0208s/iter; left time: 211.1901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756388 Vali Loss: 0.0744965 Test Loss: 0.0788164\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0722554\n",
      "\tspeed: 0.0414s/iter; left time: 415.4101s\n",
      "\titers: 200, epoch: 56 | loss: 0.0734554\n",
      "\tspeed: 0.0207s/iter; left time: 205.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756295 Vali Loss: 0.0744851 Test Loss: 0.0788308\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0712699\n",
      "\tspeed: 0.0416s/iter; left time: 408.0694s\n",
      "\titers: 200, epoch: 57 | loss: 0.0767291\n",
      "\tspeed: 0.0209s/iter; left time: 203.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0756545 Vali Loss: 0.0744595 Test Loss: 0.0788006\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0736074\n",
      "\tspeed: 0.0417s/iter; left time: 399.2716s\n",
      "\titers: 200, epoch: 58 | loss: 0.0721901\n",
      "\tspeed: 0.0208s/iter; left time: 196.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0756565 Vali Loss: 0.0744689 Test Loss: 0.0787867\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0782748\n",
      "\tspeed: 0.0424s/iter; left time: 396.4029s\n",
      "\titers: 200, epoch: 59 | loss: 0.0734969\n",
      "\tspeed: 0.0208s/iter; left time: 192.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0756559 Vali Loss: 0.0744646 Test Loss: 0.0787873\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0761360\n",
      "\tspeed: 0.0428s/iter; left time: 390.8161s\n",
      "\titers: 200, epoch: 60 | loss: 0.0774208\n",
      "\tspeed: 0.0227s/iter; left time: 204.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0756059 Vali Loss: 0.0744760 Test Loss: 0.0788017\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0744535\n",
      "\tspeed: 0.0415s/iter; left time: 369.6899s\n",
      "\titers: 200, epoch: 61 | loss: 0.0719408\n",
      "\tspeed: 0.0211s/iter; left time: 185.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0756347 Vali Loss: 0.0744701 Test Loss: 0.0788029\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0716773\n",
      "\tspeed: 0.0423s/iter; left time: 367.0738s\n",
      "\titers: 200, epoch: 62 | loss: 0.0718452\n",
      "\tspeed: 0.0207s/iter; left time: 177.7702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0756371 Vali Loss: 0.0744701 Test Loss: 0.0787790\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01815042831003666, rmse:0.13472352921962738, mae:0.07877302914857864, rse:0.509404182434082\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1637366\n",
      "\tspeed: 0.0231s/iter; left time: 517.0028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1366874\n",
      "\tspeed: 0.0209s/iter; left time: 466.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.1638897 Vali Loss: 0.1186297 Test Loss: 0.1232584\n",
      "Validation loss decreased (inf --> 0.118630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1025519\n",
      "\tspeed: 0.0436s/iter; left time: 967.0378s\n",
      "\titers: 200, epoch: 2 | loss: 0.0871551\n",
      "\tspeed: 0.0208s/iter; left time: 459.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.1019576 Vali Loss: 0.0846024 Test Loss: 0.0879323\n",
      "Validation loss decreased (0.118630 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878244\n",
      "\tspeed: 0.0432s/iter; left time: 947.6436s\n",
      "\titers: 200, epoch: 3 | loss: 0.0881555\n",
      "\tspeed: 0.0208s/iter; left time: 454.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0882597 Vali Loss: 0.0806726 Test Loss: 0.0843868\n",
      "Validation loss decreased (0.084602 --> 0.080673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0828160\n",
      "\tspeed: 0.0432s/iter; left time: 939.3650s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839197\n",
      "\tspeed: 0.0208s/iter; left time: 449.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0853353 Vali Loss: 0.0792031 Test Loss: 0.0830309\n",
      "Validation loss decreased (0.080673 --> 0.079203).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871444\n",
      "\tspeed: 0.0431s/iter; left time: 927.0891s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783487\n",
      "\tspeed: 0.0208s/iter; left time: 445.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0834572 Vali Loss: 0.0779789 Test Loss: 0.0820830\n",
      "Validation loss decreased (0.079203 --> 0.077979).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861226\n",
      "\tspeed: 0.0424s/iter; left time: 903.0358s\n",
      "\titers: 200, epoch: 6 | loss: 0.0838076\n",
      "\tspeed: 0.0209s/iter; left time: 442.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0821980 Vali Loss: 0.0772114 Test Loss: 0.0812530\n",
      "Validation loss decreased (0.077979 --> 0.077211).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0826203\n",
      "\tspeed: 0.0424s/iter; left time: 891.6210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811351\n",
      "\tspeed: 0.0223s/iter; left time: 467.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0812458 Vali Loss: 0.0769910 Test Loss: 0.0810177\n",
      "Validation loss decreased (0.077211 --> 0.076991).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0833413\n",
      "\tspeed: 0.0428s/iter; left time: 890.9293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0802773\n",
      "\tspeed: 0.0208s/iter; left time: 430.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0805587 Vali Loss: 0.0763516 Test Loss: 0.0804884\n",
      "Validation loss decreased (0.076991 --> 0.076352).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844949\n",
      "\tspeed: 0.0437s/iter; left time: 901.2843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0781104\n",
      "\tspeed: 0.0216s/iter; left time: 442.0718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0798999 Vali Loss: 0.0760150 Test Loss: 0.0802005\n",
      "Validation loss decreased (0.076352 --> 0.076015).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0761344\n",
      "\tspeed: 0.0433s/iter; left time: 883.0924s\n",
      "\titers: 200, epoch: 10 | loss: 0.0780614\n",
      "\tspeed: 0.0215s/iter; left time: 435.1111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0794445 Vali Loss: 0.0758701 Test Loss: 0.0802442\n",
      "Validation loss decreased (0.076015 --> 0.075870).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0743540\n",
      "\tspeed: 0.0430s/iter; left time: 866.9888s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809893\n",
      "\tspeed: 0.0208s/iter; left time: 417.2845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0789785 Vali Loss: 0.0756105 Test Loss: 0.0798962\n",
      "Validation loss decreased (0.075870 --> 0.075610).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815798\n",
      "\tspeed: 0.0427s/iter; left time: 851.0189s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788627\n",
      "\tspeed: 0.0208s/iter; left time: 412.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0785684 Vali Loss: 0.0752351 Test Loss: 0.0795540\n",
      "Validation loss decreased (0.075610 --> 0.075235).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776551\n",
      "\tspeed: 0.0428s/iter; left time: 843.9088s\n",
      "\titers: 200, epoch: 13 | loss: 0.0810024\n",
      "\tspeed: 0.0208s/iter; left time: 408.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0782453 Vali Loss: 0.0750905 Test Loss: 0.0796944\n",
      "Validation loss decreased (0.075235 --> 0.075090).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825704\n",
      "\tspeed: 0.0427s/iter; left time: 831.7960s\n",
      "\titers: 200, epoch: 14 | loss: 0.0778248\n",
      "\tspeed: 0.0208s/iter; left time: 403.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0779376 Vali Loss: 0.0748365 Test Loss: 0.0794269\n",
      "Validation loss decreased (0.075090 --> 0.074837).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0827974\n",
      "\tspeed: 0.0433s/iter; left time: 832.9973s\n",
      "\titers: 200, epoch: 15 | loss: 0.0739762\n",
      "\tspeed: 0.0208s/iter; left time: 398.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0777293 Vali Loss: 0.0748100 Test Loss: 0.0795144\n",
      "Validation loss decreased (0.074837 --> 0.074810).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0784488\n",
      "\tspeed: 0.0427s/iter; left time: 813.1082s\n",
      "\titers: 200, epoch: 16 | loss: 0.0808750\n",
      "\tspeed: 0.0208s/iter; left time: 394.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0774809 Vali Loss: 0.0746060 Test Loss: 0.0792269\n",
      "Validation loss decreased (0.074810 --> 0.074606).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0773868\n",
      "\tspeed: 0.0459s/iter; left time: 862.9082s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736612\n",
      "\tspeed: 0.0219s/iter; left time: 409.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0773585 Vali Loss: 0.0745304 Test Loss: 0.0792232\n",
      "Validation loss decreased (0.074606 --> 0.074530).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773715\n",
      "\tspeed: 0.0442s/iter; left time: 820.4977s\n",
      "\titers: 200, epoch: 18 | loss: 0.0747276\n",
      "\tspeed: 0.0210s/iter; left time: 387.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0770840 Vali Loss: 0.0744964 Test Loss: 0.0793575\n",
      "Validation loss decreased (0.074530 --> 0.074496).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0817562\n",
      "\tspeed: 0.0428s/iter; left time: 784.5678s\n",
      "\titers: 200, epoch: 19 | loss: 0.0816317\n",
      "\tspeed: 0.0208s/iter; left time: 380.3266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0769545 Vali Loss: 0.0744677 Test Loss: 0.0792675\n",
      "Validation loss decreased (0.074496 --> 0.074468).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0807086\n",
      "\tspeed: 0.0424s/iter; left time: 767.8067s\n",
      "\titers: 200, epoch: 20 | loss: 0.0757208\n",
      "\tspeed: 0.0208s/iter; left time: 375.4239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0768689 Vali Loss: 0.0743737 Test Loss: 0.0792753\n",
      "Validation loss decreased (0.074468 --> 0.074374).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0757226\n",
      "\tspeed: 0.0429s/iter; left time: 767.8128s\n",
      "\titers: 200, epoch: 21 | loss: 0.0786389\n",
      "\tspeed: 0.0209s/iter; left time: 371.3083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0767737 Vali Loss: 0.0742612 Test Loss: 0.0792980\n",
      "Validation loss decreased (0.074374 --> 0.074261).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0767378\n",
      "\tspeed: 0.0428s/iter; left time: 755.7606s\n",
      "\titers: 200, epoch: 22 | loss: 0.0715712\n",
      "\tspeed: 0.0210s/iter; left time: 368.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0766468 Vali Loss: 0.0742626 Test Loss: 0.0791987\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740811\n",
      "\tspeed: 0.0424s/iter; left time: 739.8467s\n",
      "\titers: 200, epoch: 23 | loss: 0.0805914\n",
      "\tspeed: 0.0208s/iter; left time: 361.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0765060 Vali Loss: 0.0741969 Test Loss: 0.0790897\n",
      "Validation loss decreased (0.074261 --> 0.074197).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0789765\n",
      "\tspeed: 0.0431s/iter; left time: 741.6001s\n",
      "\titers: 200, epoch: 24 | loss: 0.0792555\n",
      "\tspeed: 0.0208s/iter; left time: 356.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0764295 Vali Loss: 0.0741928 Test Loss: 0.0790885\n",
      "Validation loss decreased (0.074197 --> 0.074193).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0770093\n",
      "\tspeed: 0.0438s/iter; left time: 744.7209s\n",
      "\titers: 200, epoch: 25 | loss: 0.0734579\n",
      "\tspeed: 0.0207s/iter; left time: 349.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0763085 Vali Loss: 0.0740530 Test Loss: 0.0790376\n",
      "Validation loss decreased (0.074193 --> 0.074053).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0832152\n",
      "\tspeed: 0.0453s/iter; left time: 759.3065s\n",
      "\titers: 200, epoch: 26 | loss: 0.0771939\n",
      "\tspeed: 0.0208s/iter; left time: 347.2092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0762396 Vali Loss: 0.0740980 Test Loss: 0.0791892\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0793880\n",
      "\tspeed: 0.0434s/iter; left time: 718.4866s\n",
      "\titers: 200, epoch: 27 | loss: 0.0780192\n",
      "\tspeed: 0.0211s/iter; left time: 347.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0762377 Vali Loss: 0.0741957 Test Loss: 0.0793163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0764170\n",
      "\tspeed: 0.0426s/iter; left time: 694.9966s\n",
      "\titers: 200, epoch: 28 | loss: 0.0761216\n",
      "\tspeed: 0.0208s/iter; left time: 338.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0761330 Vali Loss: 0.0740410 Test Loss: 0.0790464\n",
      "Validation loss decreased (0.074053 --> 0.074041).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0765215\n",
      "\tspeed: 0.0427s/iter; left time: 687.8919s\n",
      "\titers: 200, epoch: 29 | loss: 0.0725563\n",
      "\tspeed: 0.0208s/iter; left time: 332.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0760898 Vali Loss: 0.0741024 Test Loss: 0.0792137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0759419\n",
      "\tspeed: 0.0422s/iter; left time: 670.5457s\n",
      "\titers: 200, epoch: 30 | loss: 0.0745000\n",
      "\tspeed: 0.0209s/iter; left time: 330.2125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0760080 Vali Loss: 0.0740135 Test Loss: 0.0790522\n",
      "Validation loss decreased (0.074041 --> 0.074014).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778709\n",
      "\tspeed: 0.0429s/iter; left time: 671.6879s\n",
      "\titers: 200, epoch: 31 | loss: 0.0792639\n",
      "\tspeed: 0.0208s/iter; left time: 323.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0760577 Vali Loss: 0.0741240 Test Loss: 0.0792914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0790154\n",
      "\tspeed: 0.0419s/iter; left time: 645.6491s\n",
      "\titers: 200, epoch: 32 | loss: 0.0769542\n",
      "\tspeed: 0.0208s/iter; left time: 318.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0760318 Vali Loss: 0.0740355 Test Loss: 0.0791062\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0813910\n",
      "\tspeed: 0.0417s/iter; left time: 633.5168s\n",
      "\titers: 200, epoch: 33 | loss: 0.0737934\n",
      "\tspeed: 0.0213s/iter; left time: 321.0924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0759564 Vali Loss: 0.0739913 Test Loss: 0.0790909\n",
      "Validation loss decreased (0.074014 --> 0.073991).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0782049\n",
      "\tspeed: 0.0421s/iter; left time: 630.2455s\n",
      "\titers: 200, epoch: 34 | loss: 0.0774192\n",
      "\tspeed: 0.0209s/iter; left time: 311.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0759514 Vali Loss: 0.0739873 Test Loss: 0.0791798\n",
      "Validation loss decreased (0.073991 --> 0.073987).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0769778\n",
      "\tspeed: 0.0436s/iter; left time: 642.9995s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772953\n",
      "\tspeed: 0.0208s/iter; left time: 304.9065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0758533 Vali Loss: 0.0739304 Test Loss: 0.0789606\n",
      "Validation loss decreased (0.073987 --> 0.073930).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0746399\n",
      "\tspeed: 0.0455s/iter; left time: 661.3682s\n",
      "\titers: 200, epoch: 36 | loss: 0.0737523\n",
      "\tspeed: 0.0208s/iter; left time: 299.9973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0758686 Vali Loss: 0.0739765 Test Loss: 0.0790756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0740244\n",
      "\tspeed: 0.0424s/iter; left time: 605.7217s\n",
      "\titers: 200, epoch: 37 | loss: 0.0774450\n",
      "\tspeed: 0.0207s/iter; left time: 294.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0758347 Vali Loss: 0.0739992 Test Loss: 0.0791410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0760316\n",
      "\tspeed: 0.0423s/iter; left time: 594.7847s\n",
      "\titers: 200, epoch: 38 | loss: 0.0810028\n",
      "\tspeed: 0.0208s/iter; left time: 291.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0758681 Vali Loss: 0.0739593 Test Loss: 0.0791034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0781216\n",
      "\tspeed: 0.0430s/iter; left time: 595.2613s\n",
      "\titers: 200, epoch: 39 | loss: 0.0778835\n",
      "\tspeed: 0.0211s/iter; left time: 289.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0758622 Vali Loss: 0.0739404 Test Loss: 0.0790583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0765964\n",
      "\tspeed: 0.0419s/iter; left time: 570.6301s\n",
      "\titers: 200, epoch: 40 | loss: 0.0763901\n",
      "\tspeed: 0.0208s/iter; left time: 281.6789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 225 | Train Loss: 0.0758224 Vali Loss: 0.0739679 Test Loss: 0.0791334\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0790652\n",
      "\tspeed: 0.0421s/iter; left time: 563.5811s\n",
      "\titers: 200, epoch: 41 | loss: 0.0755022\n",
      "\tspeed: 0.0209s/iter; left time: 278.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0757684 Vali Loss: 0.0739002 Test Loss: 0.0790835\n",
      "Validation loss decreased (0.073930 --> 0.073900).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0815259\n",
      "\tspeed: 0.0429s/iter; left time: 565.5794s\n",
      "\titers: 200, epoch: 42 | loss: 0.0795795\n",
      "\tspeed: 0.0208s/iter; left time: 272.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757486 Vali Loss: 0.0739190 Test Loss: 0.0790768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742600\n",
      "\tspeed: 0.0424s/iter; left time: 548.7140s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753905\n",
      "\tspeed: 0.0208s/iter; left time: 267.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0758130 Vali Loss: 0.0739081 Test Loss: 0.0790901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0768929\n",
      "\tspeed: 0.0432s/iter; left time: 549.9354s\n",
      "\titers: 200, epoch: 44 | loss: 0.0757903\n",
      "\tspeed: 0.0212s/iter; left time: 267.8504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0757794 Vali Loss: 0.0738924 Test Loss: 0.0790688\n",
      "Validation loss decreased (0.073900 --> 0.073892).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0742073\n",
      "\tspeed: 0.0453s/iter; left time: 565.6969s\n",
      "\titers: 200, epoch: 45 | loss: 0.0791050\n",
      "\tspeed: 0.0209s/iter; left time: 259.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0756737 Vali Loss: 0.0739171 Test Loss: 0.0791214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0739328\n",
      "\tspeed: 0.0424s/iter; left time: 519.9308s\n",
      "\titers: 200, epoch: 46 | loss: 0.0770414\n",
      "\tspeed: 0.0207s/iter; left time: 252.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757725 Vali Loss: 0.0739116 Test Loss: 0.0790839\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0783244\n",
      "\tspeed: 0.0424s/iter; left time: 511.2184s\n",
      "\titers: 200, epoch: 47 | loss: 0.0803114\n",
      "\tspeed: 0.0207s/iter; left time: 247.8233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757178 Vali Loss: 0.0738894 Test Loss: 0.0791115\n",
      "Validation loss decreased (0.073892 --> 0.073889).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0748944\n",
      "\tspeed: 0.0432s/iter; left time: 510.9230s\n",
      "\titers: 200, epoch: 48 | loss: 0.0788200\n",
      "\tspeed: 0.0208s/iter; left time: 244.0267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0757473 Vali Loss: 0.0738987 Test Loss: 0.0791051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0736010\n",
      "\tspeed: 0.0431s/iter; left time: 500.0674s\n",
      "\titers: 200, epoch: 49 | loss: 0.0762456\n",
      "\tspeed: 0.0207s/iter; left time: 238.5617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0757577 Vali Loss: 0.0738834 Test Loss: 0.0790763\n",
      "Validation loss decreased (0.073889 --> 0.073883).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0700971\n",
      "\tspeed: 0.0430s/iter; left time: 488.8589s\n",
      "\titers: 200, epoch: 50 | loss: 0.0790049\n",
      "\tspeed: 0.0208s/iter; left time: 234.9732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0757238 Vali Loss: 0.0739081 Test Loss: 0.0790725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0741337\n",
      "\tspeed: 0.0434s/iter; left time: 483.5952s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769934\n",
      "\tspeed: 0.0213s/iter; left time: 235.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 225 | Train Loss: 0.0757236 Vali Loss: 0.0738909 Test Loss: 0.0790586\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0763995\n",
      "\tspeed: 0.0427s/iter; left time: 466.1849s\n",
      "\titers: 200, epoch: 52 | loss: 0.0747798\n",
      "\tspeed: 0.0208s/iter; left time: 225.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0757349 Vali Loss: 0.0738992 Test Loss: 0.0790633\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0728023\n",
      "\tspeed: 0.0423s/iter; left time: 452.7777s\n",
      "\titers: 200, epoch: 53 | loss: 0.0762027\n",
      "\tspeed: 0.0209s/iter; left time: 221.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756397 Vali Loss: 0.0739138 Test Loss: 0.0791167\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0740082\n",
      "\tspeed: 0.0450s/iter; left time: 471.0190s\n",
      "\titers: 200, epoch: 54 | loss: 0.0776390\n",
      "\tspeed: 0.0218s/iter; left time: 226.0427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 225 | Train Loss: 0.0756919 Vali Loss: 0.0738933 Test Loss: 0.0790710\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0747488\n",
      "\tspeed: 0.0422s/iter; left time: 433.0729s\n",
      "\titers: 200, epoch: 55 | loss: 0.0785796\n",
      "\tspeed: 0.0208s/iter; left time: 211.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757207 Vali Loss: 0.0739212 Test Loss: 0.0790721\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0747373\n",
      "\tspeed: 0.0422s/iter; left time: 423.0414s\n",
      "\titers: 200, epoch: 56 | loss: 0.0743050\n",
      "\tspeed: 0.0208s/iter; left time: 206.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0757606 Vali Loss: 0.0739115 Test Loss: 0.0790838\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0753724\n",
      "\tspeed: 0.0423s/iter; left time: 414.1041s\n",
      "\titers: 200, epoch: 57 | loss: 0.0762969\n",
      "\tspeed: 0.0208s/iter; left time: 202.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0756882 Vali Loss: 0.0739037 Test Loss: 0.0791009\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0766754\n",
      "\tspeed: 0.0419s/iter; left time: 400.8963s\n",
      "\titers: 200, epoch: 58 | loss: 0.0779277\n",
      "\tspeed: 0.0209s/iter; left time: 198.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0756607 Vali Loss: 0.0738946 Test Loss: 0.0790789\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0737864\n",
      "\tspeed: 0.0425s/iter; left time: 397.3271s\n",
      "\titers: 200, epoch: 59 | loss: 0.0765655\n",
      "\tspeed: 0.0208s/iter; left time: 192.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.89s\n",
      "Steps: 225 | Train Loss: 0.0757330 Vali Loss: 0.0738989 Test Loss: 0.0790683\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01840369589626789, rmse:0.13566021621227264, mae:0.07907634228467941, rse:0.5129459500312805\n",
      "Intermediate time for IT and pred_len 96: 00h:13m:02.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1675196\n",
      "\tspeed: 0.0455s/iter; left time: 1019.6653s\n",
      "\titers: 200, epoch: 1 | loss: 0.1351112\n",
      "\tspeed: 0.0208s/iter; left time: 464.3052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 225 | Train Loss: 0.1671171 Vali Loss: 0.1215574 Test Loss: 0.1261611\n",
      "Validation loss decreased (inf --> 0.121557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031348\n",
      "\tspeed: 0.0437s/iter; left time: 969.0172s\n",
      "\titers: 200, epoch: 2 | loss: 0.0999422\n",
      "\tspeed: 0.0220s/iter; left time: 485.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.1065610 Vali Loss: 0.0884258 Test Loss: 0.0920818\n",
      "Validation loss decreased (0.121557 --> 0.088426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0900225\n",
      "\tspeed: 0.0428s/iter; left time: 938.9655s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932892\n",
      "\tspeed: 0.0225s/iter; left time: 490.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0926197 Vali Loss: 0.0852258 Test Loss: 0.0879315\n",
      "Validation loss decreased (0.088426 --> 0.085226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0967898\n",
      "\tspeed: 0.0440s/iter; left time: 955.5760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888191\n",
      "\tspeed: 0.0210s/iter; left time: 454.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0894399 Vali Loss: 0.0838193 Test Loss: 0.0868821\n",
      "Validation loss decreased (0.085226 --> 0.083819).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0854920\n",
      "\tspeed: 0.0425s/iter; left time: 914.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858616\n",
      "\tspeed: 0.0209s/iter; left time: 446.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0877595 Vali Loss: 0.0828019 Test Loss: 0.0860332\n",
      "Validation loss decreased (0.083819 --> 0.082802).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0848903\n",
      "\tspeed: 0.0431s/iter; left time: 917.5603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884574\n",
      "\tspeed: 0.0213s/iter; left time: 451.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0865596 Vali Loss: 0.0821893 Test Loss: 0.0856452\n",
      "Validation loss decreased (0.082802 --> 0.082189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887724\n",
      "\tspeed: 0.0432s/iter; left time: 909.2714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0849123\n",
      "\tspeed: 0.0210s/iter; left time: 439.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0856343 Vali Loss: 0.0817578 Test Loss: 0.0851978\n",
      "Validation loss decreased (0.082189 --> 0.081758).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789314\n",
      "\tspeed: 0.0439s/iter; left time: 914.9497s\n",
      "\titers: 200, epoch: 8 | loss: 0.0849873\n",
      "\tspeed: 0.0210s/iter; left time: 435.0862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0849655 Vali Loss: 0.0811689 Test Loss: 0.0848261\n",
      "Validation loss decreased (0.081758 --> 0.081169).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0853073\n",
      "\tspeed: 0.0431s/iter; left time: 887.0343s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846582\n",
      "\tspeed: 0.0215s/iter; left time: 441.0142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.0844583 Vali Loss: 0.0811148 Test Loss: 0.0850324\n",
      "Validation loss decreased (0.081169 --> 0.081115).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0830734\n",
      "\tspeed: 0.0443s/iter; left time: 903.2897s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843825\n",
      "\tspeed: 0.0211s/iter; left time: 428.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0839714 Vali Loss: 0.0809264 Test Loss: 0.0847705\n",
      "Validation loss decreased (0.081115 --> 0.080926).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843134\n",
      "\tspeed: 0.0446s/iter; left time: 898.3811s\n",
      "\titers: 200, epoch: 11 | loss: 0.0844380\n",
      "\tspeed: 0.0212s/iter; left time: 424.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0835984 Vali Loss: 0.0808471 Test Loss: 0.0847906\n",
      "Validation loss decreased (0.080926 --> 0.080847).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0834019\n",
      "\tspeed: 0.0448s/iter; left time: 892.2764s\n",
      "\titers: 200, epoch: 12 | loss: 0.0831338\n",
      "\tspeed: 0.0216s/iter; left time: 427.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0832907 Vali Loss: 0.0806723 Test Loss: 0.0847298\n",
      "Validation loss decreased (0.080847 --> 0.080672).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0809376\n",
      "\tspeed: 0.0437s/iter; left time: 860.7938s\n",
      "\titers: 200, epoch: 13 | loss: 0.0834955\n",
      "\tspeed: 0.0214s/iter; left time: 419.2213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0829945 Vali Loss: 0.0804892 Test Loss: 0.0845646\n",
      "Validation loss decreased (0.080672 --> 0.080489).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0804204\n",
      "\tspeed: 0.0460s/iter; left time: 896.7504s\n",
      "\titers: 200, epoch: 14 | loss: 0.0837203\n",
      "\tspeed: 0.0226s/iter; left time: 437.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0827314 Vali Loss: 0.0807291 Test Loss: 0.0849005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0817830\n",
      "\tspeed: 0.0452s/iter; left time: 870.7303s\n",
      "\titers: 200, epoch: 15 | loss: 0.0796863\n",
      "\tspeed: 0.0223s/iter; left time: 426.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0825446 Vali Loss: 0.0806930 Test Loss: 0.0848130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0841687\n",
      "\tspeed: 0.0451s/iter; left time: 858.3058s\n",
      "\titers: 200, epoch: 16 | loss: 0.0846400\n",
      "\tspeed: 0.0212s/iter; left time: 400.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0823802 Vali Loss: 0.0802775 Test Loss: 0.0843863\n",
      "Validation loss decreased (0.080489 --> 0.080277).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0783478\n",
      "\tspeed: 0.0432s/iter; left time: 812.7774s\n",
      "\titers: 200, epoch: 17 | loss: 0.0813191\n",
      "\tspeed: 0.0215s/iter; left time: 401.9716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0821796 Vali Loss: 0.0805252 Test Loss: 0.0847103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0785803\n",
      "\tspeed: 0.0444s/iter; left time: 824.1841s\n",
      "\titers: 200, epoch: 18 | loss: 0.0818048\n",
      "\tspeed: 0.0222s/iter; left time: 410.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0820156 Vali Loss: 0.0805238 Test Loss: 0.0847063\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800474\n",
      "\tspeed: 0.0458s/iter; left time: 840.6102s\n",
      "\titers: 200, epoch: 19 | loss: 0.0857451\n",
      "\tspeed: 0.0214s/iter; left time: 390.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0818886 Vali Loss: 0.0803709 Test Loss: 0.0845447\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0820571\n",
      "\tspeed: 0.0427s/iter; left time: 774.2087s\n",
      "\titers: 200, epoch: 20 | loss: 0.0827842\n",
      "\tspeed: 0.0211s/iter; left time: 379.9213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0817707 Vali Loss: 0.0800992 Test Loss: 0.0843321\n",
      "Validation loss decreased (0.080277 --> 0.080099).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0820213\n",
      "\tspeed: 0.0448s/iter; left time: 801.3819s\n",
      "\titers: 200, epoch: 21 | loss: 0.0828019\n",
      "\tspeed: 0.0214s/iter; left time: 381.5673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0816757 Vali Loss: 0.0801997 Test Loss: 0.0845056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0833179\n",
      "\tspeed: 0.0437s/iter; left time: 771.6586s\n",
      "\titers: 200, epoch: 22 | loss: 0.0828262\n",
      "\tspeed: 0.0213s/iter; left time: 374.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0816062 Vali Loss: 0.0802053 Test Loss: 0.0843733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830522\n",
      "\tspeed: 0.0426s/iter; left time: 742.5511s\n",
      "\titers: 200, epoch: 23 | loss: 0.0795102\n",
      "\tspeed: 0.0209s/iter; left time: 361.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0814414 Vali Loss: 0.0802630 Test Loss: 0.0844419\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0818892\n",
      "\tspeed: 0.0440s/iter; left time: 757.4071s\n",
      "\titers: 200, epoch: 24 | loss: 0.0818965\n",
      "\tspeed: 0.0213s/iter; left time: 365.4885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0813995 Vali Loss: 0.0802461 Test Loss: 0.0845363\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0841812\n",
      "\tspeed: 0.0458s/iter; left time: 779.0422s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822478\n",
      "\tspeed: 0.0225s/iter; left time: 380.5194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 225 | Train Loss: 0.0813018 Vali Loss: 0.0802634 Test Loss: 0.0843812\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0777834\n",
      "\tspeed: 0.0458s/iter; left time: 768.9485s\n",
      "\titers: 200, epoch: 26 | loss: 0.0825829\n",
      "\tspeed: 0.0231s/iter; left time: 385.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0812938 Vali Loss: 0.0803251 Test Loss: 0.0844741\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0830875\n",
      "\tspeed: 0.0447s/iter; left time: 739.8634s\n",
      "\titers: 200, epoch: 27 | loss: 0.0833670\n",
      "\tspeed: 0.0211s/iter; left time: 347.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0812281 Vali Loss: 0.0802615 Test Loss: 0.0844546\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0843309\n",
      "\tspeed: 0.0485s/iter; left time: 791.9854s\n",
      "\titers: 200, epoch: 28 | loss: 0.0831686\n",
      "\tspeed: 0.0210s/iter; left time: 340.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.0811787 Vali Loss: 0.0801265 Test Loss: 0.0844517\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0850645\n",
      "\tspeed: 0.0454s/iter; left time: 730.9687s\n",
      "\titers: 200, epoch: 29 | loss: 0.0777995\n",
      "\tspeed: 0.0213s/iter; left time: 341.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 225 | Train Loss: 0.0811257 Vali Loss: 0.0802395 Test Loss: 0.0844292\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0833312\n",
      "\tspeed: 0.0437s/iter; left time: 694.2218s\n",
      "\titers: 200, epoch: 30 | loss: 0.0835697\n",
      "\tspeed: 0.0210s/iter; left time: 331.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 225 | Train Loss: 0.0810430 Vali Loss: 0.0800870 Test Loss: 0.0843664\n",
      "Validation loss decreased (0.080099 --> 0.080087).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0794675\n",
      "\tspeed: 0.0447s/iter; left time: 698.9395s\n",
      "\titers: 200, epoch: 31 | loss: 0.0752372\n",
      "\tspeed: 0.0214s/iter; left time: 332.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0810523 Vali Loss: 0.0801989 Test Loss: 0.0844223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761456\n",
      "\tspeed: 0.0427s/iter; left time: 658.7947s\n",
      "\titers: 200, epoch: 32 | loss: 0.0814829\n",
      "\tspeed: 0.0209s/iter; left time: 321.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0809560 Vali Loss: 0.0802140 Test Loss: 0.0844132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0846063\n",
      "\tspeed: 0.0426s/iter; left time: 648.2480s\n",
      "\titers: 200, epoch: 33 | loss: 0.0834327\n",
      "\tspeed: 0.0215s/iter; left time: 324.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0809523 Vali Loss: 0.0801794 Test Loss: 0.0844204\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0829760\n",
      "\tspeed: 0.0445s/iter; left time: 665.9268s\n",
      "\titers: 200, epoch: 34 | loss: 0.0789234\n",
      "\tspeed: 0.0211s/iter; left time: 314.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0809624 Vali Loss: 0.0801088 Test Loss: 0.0844282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0787716\n",
      "\tspeed: 0.0434s/iter; left time: 640.1970s\n",
      "\titers: 200, epoch: 35 | loss: 0.0819648\n",
      "\tspeed: 0.0210s/iter; left time: 307.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0809053 Vali Loss: 0.0802213 Test Loss: 0.0844526\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0825160\n",
      "\tspeed: 0.0430s/iter; left time: 624.7136s\n",
      "\titers: 200, epoch: 36 | loss: 0.0825815\n",
      "\tspeed: 0.0236s/iter; left time: 340.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 225 | Train Loss: 0.0809145 Vali Loss: 0.0801888 Test Loss: 0.0844691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0832706\n",
      "\tspeed: 0.0461s/iter; left time: 659.4208s\n",
      "\titers: 200, epoch: 37 | loss: 0.0800724\n",
      "\tspeed: 0.0247s/iter; left time: 350.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 225 | Train Loss: 0.0809248 Vali Loss: 0.0802255 Test Loss: 0.0845230\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0829193\n",
      "\tspeed: 0.0446s/iter; left time: 627.5722s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800956\n",
      "\tspeed: 0.0214s/iter; left time: 299.3514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0808739 Vali Loss: 0.0801478 Test Loss: 0.0844169\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0799479\n",
      "\tspeed: 0.0425s/iter; left time: 588.2335s\n",
      "\titers: 200, epoch: 39 | loss: 0.0808654\n",
      "\tspeed: 0.0212s/iter; left time: 291.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0808252 Vali Loss: 0.0801744 Test Loss: 0.0843554\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0795623\n",
      "\tspeed: 0.0441s/iter; left time: 601.1513s\n",
      "\titers: 200, epoch: 40 | loss: 0.0801233\n",
      "\tspeed: 0.0211s/iter; left time: 285.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0808554 Vali Loss: 0.0801609 Test Loss: 0.0843641\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019854335114359856, rmse:0.14090541005134583, mae:0.0843663439154625, rse:0.5332736968994141\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1652622\n",
      "\tspeed: 0.0232s/iter; left time: 519.1311s\n",
      "\titers: 200, epoch: 1 | loss: 0.1404813\n",
      "\tspeed: 0.0210s/iter; left time: 469.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.1664556 Vali Loss: 0.1211868 Test Loss: 0.1257116\n",
      "Validation loss decreased (inf --> 0.121187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1001732\n",
      "\tspeed: 0.0443s/iter; left time: 981.5909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941014\n",
      "\tspeed: 0.0212s/iter; left time: 467.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 225 | Train Loss: 0.1058553 Vali Loss: 0.0880442 Test Loss: 0.0913735\n",
      "Validation loss decreased (0.121187 --> 0.088044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0931144\n",
      "\tspeed: 0.0447s/iter; left time: 981.7382s\n",
      "\titers: 200, epoch: 3 | loss: 0.0911077\n",
      "\tspeed: 0.0211s/iter; left time: 461.4357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0923617 Vali Loss: 0.0853995 Test Loss: 0.0880064\n",
      "Validation loss decreased (0.088044 --> 0.085400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853205\n",
      "\tspeed: 0.0446s/iter; left time: 968.7180s\n",
      "\titers: 200, epoch: 4 | loss: 0.0874901\n",
      "\tspeed: 0.0210s/iter; left time: 454.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0895202 Vali Loss: 0.0841055 Test Loss: 0.0870050\n",
      "Validation loss decreased (0.085400 --> 0.084106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884530\n",
      "\tspeed: 0.0443s/iter; left time: 951.4534s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848126\n",
      "\tspeed: 0.0212s/iter; left time: 454.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0878166 Vali Loss: 0.0832510 Test Loss: 0.0864866\n",
      "Validation loss decreased (0.084106 --> 0.083251).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0878976\n",
      "\tspeed: 0.0458s/iter; left time: 973.4764s\n",
      "\titers: 200, epoch: 6 | loss: 0.0865265\n",
      "\tspeed: 0.0211s/iter; left time: 447.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 225 | Train Loss: 0.0865827 Vali Loss: 0.0824401 Test Loss: 0.0857387\n",
      "Validation loss decreased (0.083251 --> 0.082440).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860272\n",
      "\tspeed: 0.0474s/iter; left time: 998.4010s\n",
      "\titers: 200, epoch: 7 | loss: 0.0851911\n",
      "\tspeed: 0.0226s/iter; left time: 472.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 225 | Train Loss: 0.0856870 Vali Loss: 0.0824135 Test Loss: 0.0859005\n",
      "Validation loss decreased (0.082440 --> 0.082414).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0836059\n",
      "\tspeed: 0.0474s/iter; left time: 987.9994s\n",
      "\titers: 200, epoch: 8 | loss: 0.0850868\n",
      "\tspeed: 0.0240s/iter; left time: 497.4643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 225 | Train Loss: 0.0850325 Vali Loss: 0.0819788 Test Loss: 0.0854102\n",
      "Validation loss decreased (0.082414 --> 0.081979).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0825220\n",
      "\tspeed: 0.0448s/iter; left time: 922.1460s\n",
      "\titers: 200, epoch: 9 | loss: 0.0837478\n",
      "\tspeed: 0.0209s/iter; left time: 429.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0845037 Vali Loss: 0.0815998 Test Loss: 0.0851035\n",
      "Validation loss decreased (0.081979 --> 0.081600).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0803746\n",
      "\tspeed: 0.0453s/iter; left time: 923.0652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0891691\n",
      "\tspeed: 0.0210s/iter; left time: 425.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0840277 Vali Loss: 0.0817864 Test Loss: 0.0854826\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0864499\n",
      "\tspeed: 0.0432s/iter; left time: 870.8315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0839852\n",
      "\tspeed: 0.0208s/iter; left time: 417.1957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.91s\n",
      "Steps: 225 | Train Loss: 0.0836376 Vali Loss: 0.0811616 Test Loss: 0.0847526\n",
      "Validation loss decreased (0.081600 --> 0.081162).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767773\n",
      "\tspeed: 0.0456s/iter; left time: 907.7313s\n",
      "\titers: 200, epoch: 12 | loss: 0.0848929\n",
      "\tspeed: 0.0209s/iter; left time: 414.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0832515 Vali Loss: 0.0814082 Test Loss: 0.0850126\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802320\n",
      "\tspeed: 0.0440s/iter; left time: 866.5832s\n",
      "\titers: 200, epoch: 13 | loss: 0.0809709\n",
      "\tspeed: 0.0216s/iter; left time: 424.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0829782 Vali Loss: 0.0811389 Test Loss: 0.0850046\n",
      "Validation loss decreased (0.081162 --> 0.081139).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0820090\n",
      "\tspeed: 0.0441s/iter; left time: 858.8439s\n",
      "\titers: 200, epoch: 14 | loss: 0.0813529\n",
      "\tspeed: 0.0212s/iter; left time: 409.8720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0827546 Vali Loss: 0.0811062 Test Loss: 0.0849319\n",
      "Validation loss decreased (0.081139 --> 0.081106).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0848976\n",
      "\tspeed: 0.0447s/iter; left time: 860.7876s\n",
      "\titers: 200, epoch: 15 | loss: 0.0821725\n",
      "\tspeed: 0.0211s/iter; left time: 404.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 225 | Train Loss: 0.0825002 Vali Loss: 0.0809575 Test Loss: 0.0847491\n",
      "Validation loss decreased (0.081106 --> 0.080958).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0843849\n",
      "\tspeed: 0.0445s/iter; left time: 846.6210s\n",
      "\titers: 200, epoch: 16 | loss: 0.0846112\n",
      "\tspeed: 0.0211s/iter; left time: 400.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0823768 Vali Loss: 0.0810634 Test Loss: 0.0850165\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0804768\n",
      "\tspeed: 0.0445s/iter; left time: 837.5316s\n",
      "\titers: 200, epoch: 17 | loss: 0.0819272\n",
      "\tspeed: 0.0215s/iter; left time: 401.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0821746 Vali Loss: 0.0809309 Test Loss: 0.0847746\n",
      "Validation loss decreased (0.080958 --> 0.080931).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0849409\n",
      "\tspeed: 0.0486s/iter; left time: 902.0315s\n",
      "\titers: 200, epoch: 18 | loss: 0.0796754\n",
      "\tspeed: 0.0231s/iter; left time: 426.0683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0820180 Vali Loss: 0.0812055 Test Loss: 0.0849243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0853030\n",
      "\tspeed: 0.0452s/iter; left time: 829.6599s\n",
      "\titers: 200, epoch: 19 | loss: 0.0831308\n",
      "\tspeed: 0.0222s/iter; left time: 405.4055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0819087 Vali Loss: 0.0809420 Test Loss: 0.0848769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0851120\n",
      "\tspeed: 0.0440s/iter; left time: 798.2612s\n",
      "\titers: 200, epoch: 20 | loss: 0.0824348\n",
      "\tspeed: 0.0214s/iter; left time: 385.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0817413 Vali Loss: 0.0807580 Test Loss: 0.0846950\n",
      "Validation loss decreased (0.080931 --> 0.080758).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814391\n",
      "\tspeed: 0.0443s/iter; left time: 793.3440s\n",
      "\titers: 200, epoch: 21 | loss: 0.0771562\n",
      "\tspeed: 0.0210s/iter; left time: 373.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0816750 Vali Loss: 0.0808036 Test Loss: 0.0846861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778086\n",
      "\tspeed: 0.0451s/iter; left time: 797.0586s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811467\n",
      "\tspeed: 0.0215s/iter; left time: 377.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0815788 Vali Loss: 0.0809256 Test Loss: 0.0848525\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0824416\n",
      "\tspeed: 0.0441s/iter; left time: 770.0673s\n",
      "\titers: 200, epoch: 23 | loss: 0.0784462\n",
      "\tspeed: 0.0213s/iter; left time: 369.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0814378 Vali Loss: 0.0809654 Test Loss: 0.0849848\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0791086\n",
      "\tspeed: 0.0436s/iter; left time: 751.3391s\n",
      "\titers: 200, epoch: 24 | loss: 0.0820934\n",
      "\tspeed: 0.0216s/iter; left time: 370.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 225 | Train Loss: 0.0814123 Vali Loss: 0.0806765 Test Loss: 0.0846652\n",
      "Validation loss decreased (0.080758 --> 0.080677).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0811704\n",
      "\tspeed: 0.0457s/iter; left time: 776.4811s\n",
      "\titers: 200, epoch: 25 | loss: 0.0821694\n",
      "\tspeed: 0.0217s/iter; left time: 367.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0813322 Vali Loss: 0.0805845 Test Loss: 0.0845726\n",
      "Validation loss decreased (0.080677 --> 0.080584).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0817250\n",
      "\tspeed: 0.0462s/iter; left time: 774.3704s\n",
      "\titers: 200, epoch: 26 | loss: 0.0778832\n",
      "\tspeed: 0.0218s/iter; left time: 363.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0812857 Vali Loss: 0.0807814 Test Loss: 0.0848495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0824615\n",
      "\tspeed: 0.0433s/iter; left time: 717.2513s\n",
      "\titers: 200, epoch: 27 | loss: 0.0821413\n",
      "\tspeed: 0.0214s/iter; left time: 352.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 225 | Train Loss: 0.0812399 Vali Loss: 0.0807473 Test Loss: 0.0846913\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0795153\n",
      "\tspeed: 0.0441s/iter; left time: 720.7613s\n",
      "\titers: 200, epoch: 28 | loss: 0.0785849\n",
      "\tspeed: 0.0215s/iter; left time: 348.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0811807 Vali Loss: 0.0805473 Test Loss: 0.0845542\n",
      "Validation loss decreased (0.080584 --> 0.080547).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0777873\n",
      "\tspeed: 0.0468s/iter; left time: 752.7332s\n",
      "\titers: 200, epoch: 29 | loss: 0.0784044\n",
      "\tspeed: 0.0228s/iter; left time: 364.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 225 | Train Loss: 0.0810897 Vali Loss: 0.0807531 Test Loss: 0.0847337\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0815641\n",
      "\tspeed: 0.0487s/iter; left time: 773.2801s\n",
      "\titers: 200, epoch: 30 | loss: 0.0812558\n",
      "\tspeed: 0.0239s/iter; left time: 376.5028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0810745 Vali Loss: 0.0806763 Test Loss: 0.0847119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0809474\n",
      "\tspeed: 0.0474s/iter; left time: 742.0042s\n",
      "\titers: 200, epoch: 31 | loss: 0.0841402\n",
      "\tspeed: 0.0215s/iter; left time: 334.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0810559 Vali Loss: 0.0807105 Test Loss: 0.0848644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0809512\n",
      "\tspeed: 0.0464s/iter; left time: 715.3745s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841629\n",
      "\tspeed: 0.0218s/iter; left time: 333.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0810150 Vali Loss: 0.0805942 Test Loss: 0.0846576\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0792692\n",
      "\tspeed: 0.0456s/iter; left time: 693.1431s\n",
      "\titers: 200, epoch: 33 | loss: 0.0807642\n",
      "\tspeed: 0.0216s/iter; left time: 325.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0809633 Vali Loss: 0.0807331 Test Loss: 0.0847103\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0831877\n",
      "\tspeed: 0.0474s/iter; left time: 709.9593s\n",
      "\titers: 200, epoch: 34 | loss: 0.0842134\n",
      "\tspeed: 0.0216s/iter; left time: 321.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 225 | Train Loss: 0.0809410 Vali Loss: 0.0806199 Test Loss: 0.0846308\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0810156\n",
      "\tspeed: 0.0443s/iter; left time: 653.5369s\n",
      "\titers: 200, epoch: 35 | loss: 0.0843082\n",
      "\tspeed: 0.0222s/iter; left time: 325.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0809370 Vali Loss: 0.0806307 Test Loss: 0.0846762\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0791221\n",
      "\tspeed: 0.0443s/iter; left time: 643.9385s\n",
      "\titers: 200, epoch: 36 | loss: 0.0835913\n",
      "\tspeed: 0.0218s/iter; left time: 314.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.0809455 Vali Loss: 0.0806180 Test Loss: 0.0845773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0796506\n",
      "\tspeed: 0.0471s/iter; left time: 673.1462s\n",
      "\titers: 200, epoch: 37 | loss: 0.0805812\n",
      "\tspeed: 0.0217s/iter; left time: 307.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 225 | Train Loss: 0.0809259 Vali Loss: 0.0806551 Test Loss: 0.0846410\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0800527\n",
      "\tspeed: 0.0454s/iter; left time: 638.7925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819848\n",
      "\tspeed: 0.0221s/iter; left time: 309.4819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 225 | Train Loss: 0.0809210 Vali Loss: 0.0806320 Test Loss: 0.0846083\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019946319982409477, rmse:0.1412314474582672, mae:0.08455415815114975, rse:0.5345075726509094\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:50.21s\n",
      "Intermediate time for IT: 00h:33m:43.72s\n",
      "Total time: 01h:52m:05.01s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/21                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0212  0.1456  0.0882\n",
       "        96            0.0372  0.1928  0.1265\n",
       "        168           0.0408  0.2020  0.1344\n",
       "ES      24            0.0098  0.0991  0.0591\n",
       "        96            0.0191  0.1382  0.0861\n",
       "        168           0.0215  0.1465  0.0927\n",
       "FR      24            0.0100  0.0998  0.0544\n",
       "        96            0.0192  0.1385  0.0789\n",
       "        168           0.0210  0.1450  0.0856\n",
       "GB      24            0.0254  0.1592  0.1001\n",
       "        96            0.0455  0.2133  0.1443\n",
       "        168           0.0486  0.2204  0.1508\n",
       "IT      24            0.0100  0.1000  0.0566\n",
       "        96            0.0183  0.1352  0.0789\n",
       "        168           0.0199  0.1411  0.0845"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "#os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "#os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
