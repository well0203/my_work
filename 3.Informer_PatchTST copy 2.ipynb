{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 168](#3-patchtst-168)\n",
    "- [4. PatchTST 336](#4-patchtst-336)\n",
    "- [5. PatchTST 512](#5-patchtst-512)\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with input look-back windows =168, 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A6000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MSE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0844291\n",
      "\tspeed: 0.1427s/iter; left time: 2572.1345s\n",
      "\titers: 200, epoch: 1 | loss: 0.0693888\n",
      "\tspeed: 0.0494s/iter; left time: 885.8380s\n",
      "\titers: 300, epoch: 1 | loss: 0.0655493\n",
      "\tspeed: 0.0499s/iter; left time: 890.1312s\n",
      "\titers: 400, epoch: 1 | loss: 0.0564399\n",
      "\tspeed: 0.0496s/iter; left time: 879.7680s\n",
      "\titers: 500, epoch: 1 | loss: 0.0501456\n",
      "\tspeed: 0.0501s/iter; left time: 882.9455s\n",
      "\titers: 600, epoch: 1 | loss: 0.0479440\n",
      "\tspeed: 0.0499s/iter; left time: 873.8236s\n",
      "\titers: 700, epoch: 1 | loss: 0.0540418\n",
      "\tspeed: 0.0497s/iter; left time: 866.1543s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0257  0.1603  0.1028\n",
       "        96         0.0427  0.2066  0.1433\n",
       "        168        0.0503  0.2243  0.1545\n",
       "ES      24         0.0267  0.1632  0.0977\n",
       "        96         0.0608  0.2465  0.1540\n",
       "        168        0.0550  0.2343  0.1495\n",
       "FR      24         0.0130  0.1139  0.0647\n",
       "        96         0.0222  0.1491  0.0907\n",
       "        168        0.0239  0.1547  0.0971\n",
       "GB      24         0.0366  0.1903  0.1242\n",
       "        96         0.0557  0.2361  0.1630\n",
       "        168        0.0570  0.2386  0.1661\n",
       "IT      24         0.0122  0.1102  0.0646\n",
       "        96         0.0211  0.1451  0.0898\n",
       "        168        0.0220  0.1482  0.0937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 168\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values.\n",
    "\n",
    "Again, we separated all look-back windows into different cells, to settle up training on remote servers. Here is first with look-back 168 time steps, the next will be 336 and finally 512. In the following 3 parts all arguments are the same except seq_lem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0383199\n",
      "\tspeed: 0.0538s/iter; left time: 1210.6422s\n",
      "\titers: 200, epoch: 1 | loss: 0.0312549\n",
      "\tspeed: 0.0263s/iter; left time: 590.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 226 | Train Loss: 0.0377966 Vali Loss: 0.0340360 Test Loss: 0.0390400\n",
      "Validation loss decreased (inf --> 0.034036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0153823\n",
      "\tspeed: 0.0444s/iter; left time: 988.6494s\n",
      "\titers: 200, epoch: 2 | loss: 0.0156625\n",
      "\tspeed: 0.0235s/iter; left time: 521.2420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 226 | Train Loss: 0.0177919 Vali Loss: 0.0212845 Test Loss: 0.0229115\n",
      "Validation loss decreased (0.034036 --> 0.021285).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0143448\n",
      "\tspeed: 0.0464s/iter; left time: 1022.2165s\n",
      "\titers: 200, epoch: 3 | loss: 0.0157216\n",
      "\tspeed: 0.0227s/iter; left time: 499.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 226 | Train Loss: 0.0150513 Vali Loss: 0.0200835 Test Loss: 0.0220109\n",
      "Validation loss decreased (0.021285 --> 0.020084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0155801\n",
      "\tspeed: 0.0444s/iter; left time: 968.1773s\n",
      "\titers: 200, epoch: 4 | loss: 0.0138919\n",
      "\tspeed: 0.0219s/iter; left time: 475.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 226 | Train Loss: 0.0143696 Vali Loss: 0.0197017 Test Loss: 0.0216145\n",
      "Validation loss decreased (0.020084 --> 0.019702).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0155787\n",
      "\tspeed: 0.0520s/iter; left time: 1123.7833s\n",
      "\titers: 200, epoch: 5 | loss: 0.0120253\n",
      "\tspeed: 0.0255s/iter; left time: 547.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0140176 Vali Loss: 0.0197954 Test Loss: 0.0217132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0116973\n",
      "\tspeed: 0.0473s/iter; left time: 1010.2116s\n",
      "\titers: 200, epoch: 6 | loss: 0.0129933\n",
      "\tspeed: 0.0275s/iter; left time: 584.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0137816 Vali Loss: 0.0194198 Test Loss: 0.0212227\n",
      "Validation loss decreased (0.019702 --> 0.019420).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0148134\n",
      "\tspeed: 0.0510s/iter; left time: 1077.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0137267\n",
      "\tspeed: 0.0265s/iter; left time: 558.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0136141 Vali Loss: 0.0193366 Test Loss: 0.0213316\n",
      "Validation loss decreased (0.019420 --> 0.019337).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0116126\n",
      "\tspeed: 0.0460s/iter; left time: 961.8929s\n",
      "\titers: 200, epoch: 8 | loss: 0.0123869\n",
      "\tspeed: 0.0185s/iter; left time: 385.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 226 | Train Loss: 0.0135009 Vali Loss: 0.0191222 Test Loss: 0.0213271\n",
      "Validation loss decreased (0.019337 --> 0.019122).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0126129\n",
      "\tspeed: 0.0480s/iter; left time: 994.0540s\n",
      "\titers: 200, epoch: 9 | loss: 0.0113241\n",
      "\tspeed: 0.0280s/iter; left time: 575.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0133891 Vali Loss: 0.0191334 Test Loss: 0.0211914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0143735\n",
      "\tspeed: 0.0497s/iter; left time: 1017.7869s\n",
      "\titers: 200, epoch: 10 | loss: 0.0132874\n",
      "\tspeed: 0.0210s/iter; left time: 427.3026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0132893 Vali Loss: 0.0191786 Test Loss: 0.0212638\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0139704\n",
      "\tspeed: 0.0473s/iter; left time: 957.6863s\n",
      "\titers: 200, epoch: 11 | loss: 0.0125956\n",
      "\tspeed: 0.0253s/iter; left time: 509.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0132077 Vali Loss: 0.0191151 Test Loss: 0.0212688\n",
      "Validation loss decreased (0.019122 --> 0.019115).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0130513\n",
      "\tspeed: 0.0502s/iter; left time: 1004.8599s\n",
      "\titers: 200, epoch: 12 | loss: 0.0148896\n",
      "\tspeed: 0.0255s/iter; left time: 508.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 226 | Train Loss: 0.0131658 Vali Loss: 0.0190011 Test Loss: 0.0211472\n",
      "Validation loss decreased (0.019115 --> 0.019001).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0128899\n",
      "\tspeed: 0.0478s/iter; left time: 946.5364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0118731\n",
      "\tspeed: 0.0253s/iter; left time: 498.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 226 | Train Loss: 0.0131046 Vali Loss: 0.0189218 Test Loss: 0.0210358\n",
      "Validation loss decreased (0.019001 --> 0.018922).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0133532\n",
      "\tspeed: 0.0469s/iter; left time: 917.2947s\n",
      "\titers: 200, epoch: 14 | loss: 0.0144624\n",
      "\tspeed: 0.0254s/iter; left time: 494.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 226 | Train Loss: 0.0130366 Vali Loss: 0.0189040 Test Loss: 0.0210546\n",
      "Validation loss decreased (0.018922 --> 0.018904).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0130911\n",
      "\tspeed: 0.0488s/iter; left time: 943.7265s\n",
      "\titers: 200, epoch: 15 | loss: 0.0122813\n",
      "\tspeed: 0.0263s/iter; left time: 506.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 226 | Train Loss: 0.0129929 Vali Loss: 0.0188822 Test Loss: 0.0209941\n",
      "Validation loss decreased (0.018904 --> 0.018882).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0127345\n",
      "\tspeed: 0.0504s/iter; left time: 963.2289s\n",
      "\titers: 200, epoch: 16 | loss: 0.0142818\n",
      "\tspeed: 0.0271s/iter; left time: 514.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0129400 Vali Loss: 0.0188522 Test Loss: 0.0209537\n",
      "Validation loss decreased (0.018882 --> 0.018852).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0127672\n",
      "\tspeed: 0.0469s/iter; left time: 886.4343s\n",
      "\titers: 200, epoch: 17 | loss: 0.0128871\n",
      "\tspeed: 0.0204s/iter; left time: 382.6192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 226 | Train Loss: 0.0129139 Vali Loss: 0.0188519 Test Loss: 0.0210161\n",
      "Validation loss decreased (0.018852 --> 0.018852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0121936\n",
      "\tspeed: 0.0476s/iter; left time: 887.5064s\n",
      "\titers: 200, epoch: 18 | loss: 0.0122830\n",
      "\tspeed: 0.0253s/iter; left time: 469.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0128742 Vali Loss: 0.0188405 Test Loss: 0.0209885\n",
      "Validation loss decreased (0.018852 --> 0.018841).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0152183\n",
      "\tspeed: 0.0461s/iter; left time: 848.9115s\n",
      "\titers: 200, epoch: 19 | loss: 0.0130465\n",
      "\tspeed: 0.0257s/iter; left time: 470.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 226 | Train Loss: 0.0128390 Vali Loss: 0.0188048 Test Loss: 0.0209550\n",
      "Validation loss decreased (0.018841 --> 0.018805).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0138098\n",
      "\tspeed: 0.0483s/iter; left time: 879.3514s\n",
      "\titers: 200, epoch: 20 | loss: 0.0152119\n",
      "\tspeed: 0.0266s/iter; left time: 480.9686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0128229 Vali Loss: 0.0186983 Test Loss: 0.0209512\n",
      "Validation loss decreased (0.018805 --> 0.018698).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0121355\n",
      "\tspeed: 0.0476s/iter; left time: 855.5641s\n",
      "\titers: 200, epoch: 21 | loss: 0.0112943\n",
      "\tspeed: 0.0263s/iter; left time: 470.2271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0127835 Vali Loss: 0.0188119 Test Loss: 0.0209863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0121620\n",
      "\tspeed: 0.0465s/iter; left time: 826.2803s\n",
      "\titers: 200, epoch: 22 | loss: 0.0122019\n",
      "\tspeed: 0.0278s/iter; left time: 490.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0127699 Vali Loss: 0.0188123 Test Loss: 0.0210200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0129834\n",
      "\tspeed: 0.0496s/iter; left time: 869.7931s\n",
      "\titers: 200, epoch: 23 | loss: 0.0121842\n",
      "\tspeed: 0.0200s/iter; left time: 348.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0127693 Vali Loss: 0.0187909 Test Loss: 0.0210002\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0110590\n",
      "\tspeed: 0.0414s/iter; left time: 717.1757s\n",
      "\titers: 200, epoch: 24 | loss: 0.0139926\n",
      "\tspeed: 0.0188s/iter; left time: 324.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.0127507 Vali Loss: 0.0187344 Test Loss: 0.0209447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0128071\n",
      "\tspeed: 0.0464s/iter; left time: 791.6337s\n",
      "\titers: 200, epoch: 25 | loss: 0.0132529\n",
      "\tspeed: 0.0251s/iter; left time: 426.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0127247 Vali Loss: 0.0188031 Test Loss: 0.0209953\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0114409\n",
      "\tspeed: 0.0433s/iter; left time: 729.4194s\n",
      "\titers: 200, epoch: 26 | loss: 0.0129284\n",
      "\tspeed: 0.0234s/iter; left time: 392.6331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 226 | Train Loss: 0.0127187 Vali Loss: 0.0188277 Test Loss: 0.0209686\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0145785\n",
      "\tspeed: 0.0469s/iter; left time: 780.0009s\n",
      "\titers: 200, epoch: 27 | loss: 0.0137299\n",
      "\tspeed: 0.0258s/iter; left time: 426.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 226 | Train Loss: 0.0127071 Vali Loss: 0.0187976 Test Loss: 0.0209546\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0120018\n",
      "\tspeed: 0.0482s/iter; left time: 791.0466s\n",
      "\titers: 200, epoch: 28 | loss: 0.0117700\n",
      "\tspeed: 0.0273s/iter; left time: 445.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0126744 Vali Loss: 0.0187394 Test Loss: 0.0209601\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0133241\n",
      "\tspeed: 0.0510s/iter; left time: 824.5815s\n",
      "\titers: 200, epoch: 29 | loss: 0.0133722\n",
      "\tspeed: 0.0264s/iter; left time: 424.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0126740 Vali Loss: 0.0187694 Test Loss: 0.0209734\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0131072\n",
      "\tspeed: 0.0468s/iter; left time: 746.9519s\n",
      "\titers: 200, epoch: 30 | loss: 0.0118285\n",
      "\tspeed: 0.0256s/iter; left time: 405.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 226 | Train Loss: 0.0126849 Vali Loss: 0.0186991 Test Loss: 0.0209547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020951194688677788, rmse:0.14474527537822723, mae:0.09142162650823593, rse:0.5108261108398438\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:48.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0411841\n",
      "\tspeed: 0.0479s/iter; left time: 1072.1390s\n",
      "\titers: 200, epoch: 1 | loss: 0.0347563\n",
      "\tspeed: 0.0200s/iter; left time: 445.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0428926 Vali Loss: 0.0408700 Test Loss: 0.0488379\n",
      "Validation loss decreased (inf --> 0.040870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0280918\n",
      "\tspeed: 0.0529s/iter; left time: 1172.3212s\n",
      "\titers: 200, epoch: 2 | loss: 0.0259415\n",
      "\tspeed: 0.0274s/iter; left time: 604.1406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 225 | Train Loss: 0.0278961 Vali Loss: 0.0323799 Test Loss: 0.0383353\n",
      "Validation loss decreased (0.040870 --> 0.032380).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0256202\n",
      "\tspeed: 0.0543s/iter; left time: 1191.7391s\n",
      "\titers: 200, epoch: 3 | loss: 0.0249472\n",
      "\tspeed: 0.0268s/iter; left time: 586.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0248436 Vali Loss: 0.0313352 Test Loss: 0.0374697\n",
      "Validation loss decreased (0.032380 --> 0.031335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0231897\n",
      "\tspeed: 0.0543s/iter; left time: 1179.5102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0219180\n",
      "\tspeed: 0.0273s/iter; left time: 590.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 225 | Train Loss: 0.0240810 Vali Loss: 0.0309673 Test Loss: 0.0371241\n",
      "Validation loss decreased (0.031335 --> 0.030967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0224635\n",
      "\tspeed: 0.0535s/iter; left time: 1150.8540s\n",
      "\titers: 200, epoch: 5 | loss: 0.0248532\n",
      "\tspeed: 0.0252s/iter; left time: 539.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0236383 Vali Loss: 0.0312279 Test Loss: 0.0370489\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0259781\n",
      "\tspeed: 0.0527s/iter; left time: 1120.8972s\n",
      "\titers: 200, epoch: 6 | loss: 0.0241365\n",
      "\tspeed: 0.0239s/iter; left time: 505.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0232959 Vali Loss: 0.0309534 Test Loss: 0.0370188\n",
      "Validation loss decreased (0.030967 --> 0.030953).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0221646\n",
      "\tspeed: 0.0525s/iter; left time: 1105.9718s\n",
      "\titers: 200, epoch: 7 | loss: 0.0239294\n",
      "\tspeed: 0.0302s/iter; left time: 632.4346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 225 | Train Loss: 0.0231015 Vali Loss: 0.0309000 Test Loss: 0.0367180\n",
      "Validation loss decreased (0.030953 --> 0.030900).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0237838\n",
      "\tspeed: 0.0575s/iter; left time: 1197.4413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0253054\n",
      "\tspeed: 0.0306s/iter; left time: 633.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 225 | Train Loss: 0.0229007 Vali Loss: 0.0309551 Test Loss: 0.0369570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0234542\n",
      "\tspeed: 0.0540s/iter; left time: 1112.7232s\n",
      "\titers: 200, epoch: 9 | loss: 0.0214983\n",
      "\tspeed: 0.0306s/iter; left time: 626.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 225 | Train Loss: 0.0227605 Vali Loss: 0.0308411 Test Loss: 0.0365352\n",
      "Validation loss decreased (0.030900 --> 0.030841).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0219778\n",
      "\tspeed: 0.0546s/iter; left time: 1113.0700s\n",
      "\titers: 200, epoch: 10 | loss: 0.0220064\n",
      "\tspeed: 0.0286s/iter; left time: 578.9570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0225765 Vali Loss: 0.0307082 Test Loss: 0.0365368\n",
      "Validation loss decreased (0.030841 --> 0.030708).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/21                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0212  0.1456  0.0882\n",
       "        96            0.0372  0.1928  0.1265\n",
       "        168           0.0408  0.2020  0.1344\n",
       "ES      24            0.0098  0.0991  0.0591\n",
       "        96            0.0191  0.1382  0.0861\n",
       "        168           0.0215  0.1465  0.0927\n",
       "FR      24            0.0100  0.0998  0.0544\n",
       "        96            0.0192  0.1385  0.0789\n",
       "        168           0.0210  0.1450  0.0856\n",
       "GB      24            0.0254  0.1592  0.1001\n",
       "        96            0.0455  0.2133  0.1443\n",
       "        168           0.0486  0.2204  0.1508\n",
       "IT      24            0.0100  0.1000  0.0566\n",
       "        96            0.0183  0.1352  0.0789\n",
       "        168           0.0199  0.1411  0.0845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "#os.rename(\"results_transformers\", 'patchtst_npy_168')\n",
    "#os.rename(\"test_results\", \"patchtst_pics_168\")\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/21'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_168_21_patch.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0331299\n",
      "\tspeed: 0.0707s/iter; left time: 1575.6582s\n",
      "\titers: 200, epoch: 1 | loss: 0.0287433\n",
      "\tspeed: 0.0384s/iter; left time: 851.8963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 224 | Train Loss: 0.0354802 Vali Loss: 0.0319702 Test Loss: 0.0360805\n",
      "Validation loss decreased (inf --> 0.031970).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0159255\n",
      "\tspeed: 0.0674s/iter; left time: 1487.0161s\n",
      "\titers: 200, epoch: 2 | loss: 0.0169086\n",
      "\tspeed: 0.0336s/iter; left time: 738.9185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0172425 Vali Loss: 0.0207260 Test Loss: 0.0221175\n",
      "Validation loss decreased (0.031970 --> 0.020726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0144151\n",
      "\tspeed: 0.0790s/iter; left time: 1726.1905s\n",
      "\titers: 200, epoch: 3 | loss: 0.0146772\n",
      "\tspeed: 0.0416s/iter; left time: 903.9022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 224 | Train Loss: 0.0146521 Vali Loss: 0.0201139 Test Loss: 0.0216509\n",
      "Validation loss decreased (0.020726 --> 0.020114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0158383\n",
      "\tspeed: 0.0821s/iter; left time: 1775.0880s\n",
      "\titers: 200, epoch: 4 | loss: 0.0160625\n",
      "\tspeed: 0.0384s/iter; left time: 826.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 224 | Train Loss: 0.0140296 Vali Loss: 0.0195571 Test Loss: 0.0211821\n",
      "Validation loss decreased (0.020114 --> 0.019557).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0142890\n",
      "\tspeed: 0.0822s/iter; left time: 1758.5232s\n",
      "\titers: 200, epoch: 5 | loss: 0.0131326\n",
      "\tspeed: 0.0412s/iter; left time: 877.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 224 | Train Loss: 0.0136609 Vali Loss: 0.0193199 Test Loss: 0.0209985\n",
      "Validation loss decreased (0.019557 --> 0.019320).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0164826\n",
      "\tspeed: 0.0817s/iter; left time: 1730.5515s\n",
      "\titers: 200, epoch: 6 | loss: 0.0126204\n",
      "\tspeed: 0.0443s/iter; left time: 933.5930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 224 | Train Loss: 0.0134594 Vali Loss: 0.0192443 Test Loss: 0.0211259\n",
      "Validation loss decreased (0.019320 --> 0.019244).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0128278\n",
      "\tspeed: 0.0834s/iter; left time: 1747.2703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0147099\n",
      "\tspeed: 0.0536s/iter; left time: 1116.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0132826 Vali Loss: 0.0190823 Test Loss: 0.0211098\n",
      "Validation loss decreased (0.019244 --> 0.019082).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0118263\n",
      "\tspeed: 0.1093s/iter; left time: 2265.2138s\n",
      "\titers: 200, epoch: 8 | loss: 0.0127398\n",
      "\tspeed: 0.0483s/iter; left time: 996.3191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.01s\n",
      "Steps: 224 | Train Loss: 0.0131595 Vali Loss: 0.0192576 Test Loss: 0.0208804\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0148438\n",
      "\tspeed: 0.1102s/iter; left time: 2259.8762s\n",
      "\titers: 200, epoch: 9 | loss: 0.0141029\n",
      "\tspeed: 0.0637s/iter; left time: 1300.4499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.94s\n",
      "Steps: 224 | Train Loss: 0.0130791 Vali Loss: 0.0191878 Test Loss: 0.0210775\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0133966\n",
      "\tspeed: 0.1038s/iter; left time: 2106.1482s\n",
      "\titers: 200, epoch: 10 | loss: 0.0124890\n",
      "\tspeed: 0.0477s/iter; left time: 962.0660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0129684 Vali Loss: 0.0189475 Test Loss: 0.0207936\n",
      "Validation loss decreased (0.019082 --> 0.018948).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0106154\n",
      "\tspeed: 0.1090s/iter; left time: 2186.6887s\n",
      "\titers: 200, epoch: 11 | loss: 0.0129889\n",
      "\tspeed: 0.0557s/iter; left time: 1112.4528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.57s\n",
      "Steps: 224 | Train Loss: 0.0129028 Vali Loss: 0.0188844 Test Loss: 0.0209089\n",
      "Validation loss decreased (0.018948 --> 0.018884).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0125292\n",
      "\tspeed: 0.1107s/iter; left time: 2196.0378s\n",
      "\titers: 200, epoch: 12 | loss: 0.0131749\n",
      "\tspeed: 0.0459s/iter; left time: 905.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0128195 Vali Loss: 0.0188164 Test Loss: 0.0208695\n",
      "Validation loss decreased (0.018884 --> 0.018816).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0113560\n",
      "\tspeed: 0.1107s/iter; left time: 2171.3120s\n",
      "\titers: 200, epoch: 13 | loss: 0.0122889\n",
      "\tspeed: 0.0522s/iter; left time: 1018.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0127381 Vali Loss: 0.0188539 Test Loss: 0.0208254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0127220\n",
      "\tspeed: 0.1141s/iter; left time: 2212.7356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0135412\n",
      "\tspeed: 0.0512s/iter; left time: 987.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 224 | Train Loss: 0.0127018 Vali Loss: 0.0187021 Test Loss: 0.0206928\n",
      "Validation loss decreased (0.018816 --> 0.018702).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0127345\n",
      "\tspeed: 0.1138s/iter; left time: 2181.9086s\n",
      "\titers: 200, epoch: 15 | loss: 0.0107379\n",
      "\tspeed: 0.0581s/iter; left time: 1107.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.32s\n",
      "Steps: 224 | Train Loss: 0.0126647 Vali Loss: 0.0187818 Test Loss: 0.0208291\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0131628\n",
      "\tspeed: 0.1331s/iter; left time: 2520.5197s\n",
      "\titers: 200, epoch: 16 | loss: 0.0119425\n",
      "\tspeed: 0.0613s/iter; left time: 1155.0066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.05s\n",
      "Steps: 224 | Train Loss: 0.0126147 Vali Loss: 0.0187834 Test Loss: 0.0210146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0133438\n",
      "\tspeed: 0.1468s/iter; left time: 2747.9899s\n",
      "\titers: 200, epoch: 17 | loss: 0.0122820\n",
      "\tspeed: 0.0577s/iter; left time: 1074.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.21s\n",
      "Steps: 224 | Train Loss: 0.0125655 Vali Loss: 0.0185552 Test Loss: 0.0206705\n",
      "Validation loss decreased (0.018702 --> 0.018555).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0129390\n",
      "\tspeed: 0.1468s/iter; left time: 2715.0802s\n",
      "\titers: 200, epoch: 18 | loss: 0.0157475\n",
      "\tspeed: 0.0836s/iter; left time: 1538.2893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.27s\n",
      "Steps: 224 | Train Loss: 0.0125308 Vali Loss: 0.0186281 Test Loss: 0.0207464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0110804\n",
      "\tspeed: 0.1466s/iter; left time: 2677.9508s\n",
      "\titers: 200, epoch: 19 | loss: 0.0113313\n",
      "\tspeed: 0.0694s/iter; left time: 1260.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.99s\n",
      "Steps: 224 | Train Loss: 0.0125154 Vali Loss: 0.0187080 Test Loss: 0.0210039\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0120892\n",
      "\tspeed: 0.1453s/iter; left time: 2622.2886s\n",
      "\titers: 200, epoch: 20 | loss: 0.0129364\n",
      "\tspeed: 0.0577s/iter; left time: 1035.4401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.27s\n",
      "Steps: 224 | Train Loss: 0.0124660 Vali Loss: 0.0186161 Test Loss: 0.0207673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0110016\n",
      "\tspeed: 0.1372s/iter; left time: 2444.2884s\n",
      "\titers: 200, epoch: 21 | loss: 0.0132078\n",
      "\tspeed: 0.0635s/iter; left time: 1125.2830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.06s\n",
      "Steps: 224 | Train Loss: 0.0124346 Vali Loss: 0.0186258 Test Loss: 0.0207704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0102475\n",
      "\tspeed: 0.1537s/iter; left time: 2704.5341s\n",
      "\titers: 200, epoch: 22 | loss: 0.0119495\n",
      "\tspeed: 0.0742s/iter; left time: 1298.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:16.61s\n",
      "Steps: 224 | Train Loss: 0.0124349 Vali Loss: 0.0185870 Test Loss: 0.0208066\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0129670\n",
      "\tspeed: 0.1210s/iter; left time: 2102.5517s\n",
      "\titers: 200, epoch: 23 | loss: 0.0114171\n",
      "\tspeed: 0.0690s/iter; left time: 1191.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.87s\n",
      "Steps: 224 | Train Loss: 0.0124044 Vali Loss: 0.0185987 Test Loss: 0.0207789\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0116020\n",
      "\tspeed: 0.0766s/iter; left time: 1312.9771s\n",
      "\titers: 200, epoch: 24 | loss: 0.0120706\n",
      "\tspeed: 0.0434s/iter; left time: 739.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0123961 Vali Loss: 0.0185948 Test Loss: 0.0207864\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0124222\n",
      "\tspeed: 0.1250s/iter; left time: 2115.7450s\n",
      "\titers: 200, epoch: 25 | loss: 0.0153793\n",
      "\tspeed: 0.0649s/iter; left time: 1091.5692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 224 | Train Loss: 0.0123830 Vali Loss: 0.0185996 Test Loss: 0.0207961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0122711\n",
      "\tspeed: 0.1567s/iter; left time: 2616.6654s\n",
      "\titers: 200, epoch: 26 | loss: 0.0115288\n",
      "\tspeed: 0.0651s/iter; left time: 1080.2294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.79s\n",
      "Steps: 224 | Train Loss: 0.0123559 Vali Loss: 0.0185369 Test Loss: 0.0206521\n",
      "Validation loss decreased (0.018555 --> 0.018537).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0131443\n",
      "\tspeed: 0.1325s/iter; left time: 2182.9369s\n",
      "\titers: 200, epoch: 27 | loss: 0.0136372\n",
      "\tspeed: 0.0636s/iter; left time: 1041.6113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:13.97s\n",
      "Steps: 224 | Train Loss: 0.0123368 Vali Loss: 0.0186206 Test Loss: 0.0208083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0118613\n",
      "\tspeed: 0.1272s/iter; left time: 2067.6074s\n",
      "\titers: 200, epoch: 28 | loss: 0.0137763\n",
      "\tspeed: 0.0586s/iter; left time: 946.7049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 224 | Train Loss: 0.0123275 Vali Loss: 0.0185284 Test Loss: 0.0208035\n",
      "Validation loss decreased (0.018537 --> 0.018528).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0121510\n",
      "\tspeed: 0.1405s/iter; left time: 2252.2776s\n",
      "\titers: 200, epoch: 29 | loss: 0.0107840\n",
      "\tspeed: 0.0712s/iter; left time: 1134.5924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:16.30s\n",
      "Steps: 224 | Train Loss: 0.0123369 Vali Loss: 0.0185281 Test Loss: 0.0207493\n",
      "Validation loss decreased (0.018528 --> 0.018528).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0138683\n",
      "\tspeed: 0.1391s/iter; left time: 2198.7351s\n",
      "\titers: 200, epoch: 30 | loss: 0.0133592\n",
      "\tspeed: 0.0617s/iter; left time: 969.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:14.09s\n",
      "Steps: 224 | Train Loss: 0.0123014 Vali Loss: 0.0185362 Test Loss: 0.0208496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0119280\n",
      "\tspeed: 0.1239s/iter; left time: 1930.4301s\n",
      "\titers: 200, epoch: 31 | loss: 0.0113524\n",
      "\tspeed: 0.0678s/iter; left time: 1050.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:14.30s\n",
      "Steps: 224 | Train Loss: 0.0123056 Vali Loss: 0.0185103 Test Loss: 0.0208459\n",
      "Validation loss decreased (0.018528 --> 0.018510).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0114114\n",
      "\tspeed: 0.1271s/iter; left time: 1951.3709s\n",
      "\titers: 200, epoch: 32 | loss: 0.0130700\n",
      "\tspeed: 0.0614s/iter; left time: 937.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0123037 Vali Loss: 0.0185335 Test Loss: 0.0207588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0132595\n",
      "\tspeed: 0.1552s/iter; left time: 2348.9561s\n",
      "\titers: 200, epoch: 33 | loss: 0.0107495\n",
      "\tspeed: 0.0586s/iter; left time: 880.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:14.24s\n",
      "Steps: 224 | Train Loss: 0.0122890 Vali Loss: 0.0185438 Test Loss: 0.0208019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0122293\n",
      "\tspeed: 0.1298s/iter; left time: 1935.9060s\n",
      "\titers: 200, epoch: 34 | loss: 0.0126933\n",
      "\tspeed: 0.0633s/iter; left time: 937.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:14.02s\n",
      "Steps: 224 | Train Loss: 0.0122830 Vali Loss: 0.0185324 Test Loss: 0.0207754\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0129222\n",
      "\tspeed: 0.1343s/iter; left time: 1972.1209s\n",
      "\titers: 200, epoch: 35 | loss: 0.0108182\n",
      "\tspeed: 0.0615s/iter; left time: 897.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:14.57s\n",
      "Steps: 224 | Train Loss: 0.0122650 Vali Loss: 0.0185707 Test Loss: 0.0208121\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0125490\n",
      "\tspeed: 0.1408s/iter; left time: 2036.5078s\n",
      "\titers: 200, epoch: 36 | loss: 0.0140222\n",
      "\tspeed: 0.0683s/iter; left time: 980.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0122610 Vali Loss: 0.0185492 Test Loss: 0.0208118\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0152776\n",
      "\tspeed: 0.1168s/iter; left time: 1663.3829s\n",
      "\titers: 200, epoch: 37 | loss: 0.0121370\n",
      "\tspeed: 0.0571s/iter; left time: 806.8245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:12.74s\n",
      "Steps: 224 | Train Loss: 0.0122684 Vali Loss: 0.0185470 Test Loss: 0.0208452\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0121063\n",
      "\tspeed: 0.1275s/iter; left time: 1786.5817s\n",
      "\titers: 200, epoch: 38 | loss: 0.0114475\n",
      "\tspeed: 0.0562s/iter; left time: 782.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 224 | Train Loss: 0.0122699 Vali Loss: 0.0185565 Test Loss: 0.0208614\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0134420\n",
      "\tspeed: 0.1198s/iter; left time: 1651.4766s\n",
      "\titers: 200, epoch: 39 | loss: 0.0113555\n",
      "\tspeed: 0.0696s/iter; left time: 953.4177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.03s\n",
      "Steps: 224 | Train Loss: 0.0122534 Vali Loss: 0.0185123 Test Loss: 0.0208491\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0111702\n",
      "\tspeed: 0.1392s/iter; left time: 1887.5824s\n",
      "\titers: 200, epoch: 40 | loss: 0.0136204\n",
      "\tspeed: 0.0584s/iter; left time: 785.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:13.67s\n",
      "Steps: 224 | Train Loss: 0.0122599 Vali Loss: 0.0185720 Test Loss: 0.0208392\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0110373\n",
      "\tspeed: 0.1189s/iter; left time: 1585.5869s\n",
      "\titers: 200, epoch: 41 | loss: 0.0121039\n",
      "\tspeed: 0.0601s/iter; left time: 796.0753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 224 | Train Loss: 0.0122421 Vali Loss: 0.0184958 Test Loss: 0.0207846\n",
      "Validation loss decreased (0.018510 --> 0.018496).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0117363\n",
      "\tspeed: 0.1270s/iter; left time: 1665.2070s\n",
      "\titers: 200, epoch: 42 | loss: 0.0141523\n",
      "\tspeed: 0.0556s/iter; left time: 723.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 224 | Train Loss: 0.0122492 Vali Loss: 0.0185481 Test Loss: 0.0208161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0135011\n",
      "\tspeed: 0.1422s/iter; left time: 1833.2903s\n",
      "\titers: 200, epoch: 43 | loss: 0.0126329\n",
      "\tspeed: 0.0631s/iter; left time: 807.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0122592 Vali Loss: 0.0185243 Test Loss: 0.0208267\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0100381\n",
      "\tspeed: 0.1192s/iter; left time: 1510.3343s\n",
      "\titers: 200, epoch: 44 | loss: 0.0122319\n",
      "\tspeed: 0.0520s/iter; left time: 653.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0122403 Vali Loss: 0.0185204 Test Loss: 0.0207974\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0127638\n",
      "\tspeed: 0.0910s/iter; left time: 1132.3478s\n",
      "\titers: 200, epoch: 45 | loss: 0.0129958\n",
      "\tspeed: 0.0476s/iter; left time: 587.6923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:11.09s\n",
      "Steps: 224 | Train Loss: 0.0122323 Vali Loss: 0.0185284 Test Loss: 0.0208220\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0121234\n",
      "\tspeed: 0.0910s/iter; left time: 1112.1473s\n",
      "\titers: 200, epoch: 46 | loss: 0.0132324\n",
      "\tspeed: 0.0441s/iter; left time: 534.9395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0122421 Vali Loss: 0.0185286 Test Loss: 0.0207993\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0124325\n",
      "\tspeed: 0.0878s/iter; left time: 1053.5875s\n",
      "\titers: 200, epoch: 47 | loss: 0.0115689\n",
      "\tspeed: 0.0497s/iter; left time: 591.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:10.76s\n",
      "Steps: 224 | Train Loss: 0.0122320 Vali Loss: 0.0185471 Test Loss: 0.0208486\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0131577\n",
      "\tspeed: 0.1046s/iter; left time: 1230.9453s\n",
      "\titers: 200, epoch: 48 | loss: 0.0117313\n",
      "\tspeed: 0.0462s/iter; left time: 538.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 224 | Train Loss: 0.0122374 Vali Loss: 0.0185213 Test Loss: 0.0208071\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0126173\n",
      "\tspeed: 0.1129s/iter; left time: 1304.1703s\n",
      "\titers: 200, epoch: 49 | loss: 0.0135240\n",
      "\tspeed: 0.0472s/iter; left time: 540.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.56s\n",
      "Steps: 224 | Train Loss: 0.0122360 Vali Loss: 0.0184857 Test Loss: 0.0208153\n",
      "Validation loss decreased (0.018496 --> 0.018486).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0112510\n",
      "\tspeed: 0.0976s/iter; left time: 1105.7939s\n",
      "\titers: 200, epoch: 50 | loss: 0.0112302\n",
      "\tspeed: 0.0548s/iter; left time: 615.6263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:12.03s\n",
      "Steps: 224 | Train Loss: 0.0122434 Vali Loss: 0.0185543 Test Loss: 0.0208179\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0113205\n",
      "\tspeed: 0.1005s/iter; left time: 1116.0836s\n",
      "\titers: 200, epoch: 51 | loss: 0.0120899\n",
      "\tspeed: 0.0567s/iter; left time: 623.6655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:12.34s\n",
      "Steps: 224 | Train Loss: 0.0122339 Vali Loss: 0.0185324 Test Loss: 0.0208079\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0130218\n",
      "\tspeed: 0.1070s/iter; left time: 1163.7954s\n",
      "\titers: 200, epoch: 52 | loss: 0.0135182\n",
      "\tspeed: 0.0462s/iter; left time: 497.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:10.78s\n",
      "Steps: 224 | Train Loss: 0.0122330 Vali Loss: 0.0185057 Test Loss: 0.0208085\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0123628\n",
      "\tspeed: 0.1162s/iter; left time: 1237.6015s\n",
      "\titers: 200, epoch: 53 | loss: 0.0136013\n",
      "\tspeed: 0.0489s/iter; left time: 516.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:11.57s\n",
      "Steps: 224 | Train Loss: 0.0122287 Vali Loss: 0.0185395 Test Loss: 0.0208171\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0124737\n",
      "\tspeed: 0.1097s/iter; left time: 1144.2586s\n",
      "\titers: 200, epoch: 54 | loss: 0.0119168\n",
      "\tspeed: 0.0528s/iter; left time: 544.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 224 | Train Loss: 0.0122233 Vali Loss: 0.0185316 Test Loss: 0.0208232\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0115388\n",
      "\tspeed: 0.0969s/iter; left time: 988.4192s\n",
      "\titers: 200, epoch: 55 | loss: 0.0133567\n",
      "\tspeed: 0.0584s/iter; left time: 590.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:12.14s\n",
      "Steps: 224 | Train Loss: 0.0122370 Vali Loss: 0.0185180 Test Loss: 0.0208282\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0134816\n",
      "\tspeed: 0.1025s/iter; left time: 1022.7812s\n",
      "\titers: 200, epoch: 56 | loss: 0.0113304\n",
      "\tspeed: 0.0492s/iter; left time: 485.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:11.49s\n",
      "Steps: 224 | Train Loss: 0.0122237 Vali Loss: 0.0184812 Test Loss: 0.0208191\n",
      "Validation loss decreased (0.018486 --> 0.018481).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0127599\n",
      "\tspeed: 0.1228s/iter; left time: 1197.7781s\n",
      "\titers: 200, epoch: 57 | loss: 0.0126832\n",
      "\tspeed: 0.0487s/iter; left time: 470.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:11.19s\n",
      "Steps: 224 | Train Loss: 0.0122149 Vali Loss: 0.0185322 Test Loss: 0.0208272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0128764\n",
      "\tspeed: 0.1076s/iter; left time: 1025.8135s\n",
      "\titers: 200, epoch: 58 | loss: 0.0134127\n",
      "\tspeed: 0.0420s/iter; left time: 395.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:11.67s\n",
      "Steps: 224 | Train Loss: 0.0122195 Vali Loss: 0.0185319 Test Loss: 0.0208226\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0128281\n",
      "\tspeed: 0.0714s/iter; left time: 664.3876s\n",
      "\titers: 200, epoch: 59 | loss: 0.0132629\n",
      "\tspeed: 0.0470s/iter; left time: 432.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0122318 Vali Loss: 0.0185162 Test Loss: 0.0208412\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0120071\n",
      "\tspeed: 0.0985s/iter; left time: 894.8921s\n",
      "\titers: 200, epoch: 60 | loss: 0.0123658\n",
      "\tspeed: 0.0424s/iter; left time: 380.5809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 224 | Train Loss: 0.0122378 Vali Loss: 0.0185121 Test Loss: 0.0208320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0136733\n",
      "\tspeed: 0.1227s/iter; left time: 1087.6455s\n",
      "\titers: 200, epoch: 61 | loss: 0.0110619\n",
      "\tspeed: 0.0548s/iter; left time: 479.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:11.57s\n",
      "Steps: 224 | Train Loss: 0.0122343 Vali Loss: 0.0185155 Test Loss: 0.0208189\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0118293\n",
      "\tspeed: 0.1127s/iter; left time: 973.2033s\n",
      "\titers: 200, epoch: 62 | loss: 0.0110706\n",
      "\tspeed: 0.0456s/iter; left time: 389.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:12.87s\n",
      "Steps: 224 | Train Loss: 0.0122327 Vali Loss: 0.0185753 Test Loss: 0.0208160\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0124438\n",
      "\tspeed: 0.0982s/iter; left time: 825.7776s\n",
      "\titers: 200, epoch: 63 | loss: 0.0103165\n",
      "\tspeed: 0.0650s/iter; left time: 540.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 224 | Train Loss: 0.0122317 Vali Loss: 0.0185079 Test Loss: 0.0208250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0115705\n",
      "\tspeed: 0.1035s/iter; left time: 847.7687s\n",
      "\titers: 200, epoch: 64 | loss: 0.0128942\n",
      "\tspeed: 0.0482s/iter; left time: 389.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0122176 Vali Loss: 0.0185142 Test Loss: 0.0208247\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0127902\n",
      "\tspeed: 0.1255s/iter; left time: 999.6059s\n",
      "\titers: 200, epoch: 65 | loss: 0.0122773\n",
      "\tspeed: 0.0529s/iter; left time: 415.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:11.59s\n",
      "Steps: 224 | Train Loss: 0.0122278 Vali Loss: 0.0184961 Test Loss: 0.0208173\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0115899\n",
      "\tspeed: 0.1097s/iter; left time: 849.0888s\n",
      "\titers: 200, epoch: 66 | loss: 0.0130514\n",
      "\tspeed: 0.0504s/iter; left time: 385.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 224 | Train Loss: 0.0122333 Vali Loss: 0.0185431 Test Loss: 0.0208185\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020819105207920074, rmse:0.14428827166557312, mae:0.09108439832925797, rse:0.5092132687568665\n",
      "Intermediate time for DE and pred_len 24: 00h:18m:52.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0377843\n",
      "\tspeed: 0.0664s/iter; left time: 1480.6712s\n",
      "\titers: 200, epoch: 1 | loss: 0.0344038\n",
      "\tspeed: 0.0434s/iter; left time: 963.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.99s\n",
      "Steps: 224 | Train Loss: 0.0388491 Vali Loss: 0.0371462 Test Loss: 0.0431195\n",
      "Validation loss decreased (inf --> 0.037146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0295151\n",
      "\tspeed: 0.1346s/iter; left time: 2972.3932s\n",
      "\titers: 200, epoch: 2 | loss: 0.0236684\n",
      "\tspeed: 0.0402s/iter; left time: 883.2348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 224 | Train Loss: 0.0264033 Vali Loss: 0.0309098 Test Loss: 0.0364046\n",
      "Validation loss decreased (0.037146 --> 0.030910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0219902\n",
      "\tspeed: 0.0939s/iter; left time: 2052.1336s\n",
      "\titers: 200, epoch: 3 | loss: 0.0236232\n",
      "\tspeed: 0.0450s/iter; left time: 978.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.75s\n",
      "Steps: 224 | Train Loss: 0.0239233 Vali Loss: 0.0303387 Test Loss: 0.0362125\n",
      "Validation loss decreased (0.030910 --> 0.030339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0230603\n",
      "\tspeed: 0.1200s/iter; left time: 2595.1718s\n",
      "\titers: 200, epoch: 4 | loss: 0.0216371\n",
      "\tspeed: 0.0476s/iter; left time: 1025.1456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 224 | Train Loss: 0.0233313 Vali Loss: 0.0303084 Test Loss: 0.0360353\n",
      "Validation loss decreased (0.030339 --> 0.030308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0232691\n",
      "\tspeed: 0.1140s/iter; left time: 2440.5904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0200354\n",
      "\tspeed: 0.0644s/iter; left time: 1372.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 224 | Train Loss: 0.0229674 Vali Loss: 0.0302206 Test Loss: 0.0355811\n",
      "Validation loss decreased (0.030308 --> 0.030221).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0257173\n",
      "\tspeed: 0.0781s/iter; left time: 1653.3021s\n",
      "\titers: 200, epoch: 6 | loss: 0.0252964\n",
      "\tspeed: 0.0441s/iter; left time: 929.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 224 | Train Loss: 0.0226332 Vali Loss: 0.0301113 Test Loss: 0.0356656\n",
      "Validation loss decreased (0.030221 --> 0.030111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0228483\n",
      "\tspeed: 0.1411s/iter; left time: 2956.4237s\n",
      "\titers: 200, epoch: 7 | loss: 0.0201746\n",
      "\tspeed: 0.0433s/iter; left time: 903.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 224 | Train Loss: 0.0223822 Vali Loss: 0.0301649 Test Loss: 0.0361735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0217567\n",
      "\tspeed: 0.1252s/iter; left time: 2594.8327s\n",
      "\titers: 200, epoch: 8 | loss: 0.0212575\n",
      "\tspeed: 0.0566s/iter; left time: 1168.7912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 224 | Train Loss: 0.0221981 Vali Loss: 0.0303818 Test Loss: 0.0366595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0209937\n",
      "\tspeed: 0.1061s/iter; left time: 2176.4208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0226185\n",
      "\tspeed: 0.0535s/iter; left time: 1092.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 224 | Train Loss: 0.0220167 Vali Loss: 0.0303453 Test Loss: 0.0365737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0213579\n",
      "\tspeed: 0.1082s/iter; left time: 2194.6800s\n",
      "\titers: 200, epoch: 10 | loss: 0.0205298\n",
      "\tspeed: 0.0425s/iter; left time: 857.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.94s\n",
      "Steps: 224 | Train Loss: 0.0218319 Vali Loss: 0.0301455 Test Loss: 0.0364236\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0205914\n",
      "\tspeed: 0.1483s/iter; left time: 2975.4447s\n",
      "\titers: 200, epoch: 11 | loss: 0.0229521\n",
      "\tspeed: 0.0510s/iter; left time: 1018.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.02s\n",
      "Steps: 224 | Train Loss: 0.0216898 Vali Loss: 0.0301673 Test Loss: 0.0366581\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0213532\n",
      "\tspeed: 0.1105s/iter; left time: 2192.2680s\n",
      "\titers: 200, epoch: 12 | loss: 0.0208601\n",
      "\tspeed: 0.0536s/iter; left time: 1057.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.29s\n",
      "Steps: 224 | Train Loss: 0.0215192 Vali Loss: 0.0302230 Test Loss: 0.0368246\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0199397\n",
      "\tspeed: 0.1140s/iter; left time: 2236.7315s\n",
      "\titers: 200, epoch: 13 | loss: 0.0213505\n",
      "\tspeed: 0.0566s/iter; left time: 1105.2538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 224 | Train Loss: 0.0213826 Vali Loss: 0.0304040 Test Loss: 0.0372023\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0217223\n",
      "\tspeed: 0.1183s/iter; left time: 2293.1308s\n",
      "\titers: 200, epoch: 14 | loss: 0.0203427\n",
      "\tspeed: 0.0478s/iter; left time: 921.3369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.27s\n",
      "Steps: 224 | Train Loss: 0.0212423 Vali Loss: 0.0303967 Test Loss: 0.0372141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0200363\n",
      "\tspeed: 0.1387s/iter; left time: 2658.2310s\n",
      "\titers: 200, epoch: 15 | loss: 0.0214020\n",
      "\tspeed: 0.0548s/iter; left time: 1045.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 224 | Train Loss: 0.0211565 Vali Loss: 0.0301792 Test Loss: 0.0372579\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0227665\n",
      "\tspeed: 0.1230s/iter; left time: 2330.6739s\n",
      "\titers: 200, epoch: 16 | loss: 0.0229693\n",
      "\tspeed: 0.0443s/iter; left time: 834.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.36s\n",
      "Steps: 224 | Train Loss: 0.0210283 Vali Loss: 0.0303737 Test Loss: 0.0374546\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03566562011837959, rmse:0.1888534426689148, mae:0.12909182906150818, rse:0.6687682271003723\n",
      "Intermediate time for DE and pred_len 96: 00h:04m:38.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0404512\n",
      "\tspeed: 0.0849s/iter; left time: 1884.2158s\n",
      "\titers: 200, epoch: 1 | loss: 0.0355846\n",
      "\tspeed: 0.0574s/iter; left time: 1268.2577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.17s\n",
      "Steps: 223 | Train Loss: 0.0402154 Vali Loss: 0.0383989 Test Loss: 0.0446866\n",
      "Validation loss decreased (inf --> 0.038399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0304991\n",
      "\tspeed: 0.1510s/iter; left time: 3318.3208s\n",
      "\titers: 200, epoch: 2 | loss: 0.0254042\n",
      "\tspeed: 0.0690s/iter; left time: 1508.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.10s\n",
      "Steps: 223 | Train Loss: 0.0286390 Vali Loss: 0.0326475 Test Loss: 0.0383843\n",
      "Validation loss decreased (0.038399 --> 0.032647).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0274383\n",
      "\tspeed: 0.1799s/iter; left time: 3913.8558s\n",
      "\titers: 200, epoch: 3 | loss: 0.0261717\n",
      "\tspeed: 0.0693s/iter; left time: 1499.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.76s\n",
      "Steps: 223 | Train Loss: 0.0262391 Vali Loss: 0.0323455 Test Loss: 0.0382562\n",
      "Validation loss decreased (0.032647 --> 0.032346).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0245347\n",
      "\tspeed: 0.1978s/iter; left time: 4258.7947s\n",
      "\titers: 200, epoch: 4 | loss: 0.0272657\n",
      "\tspeed: 0.0649s/iter; left time: 1390.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.48s\n",
      "Steps: 223 | Train Loss: 0.0256516 Vali Loss: 0.0320062 Test Loss: 0.0384216\n",
      "Validation loss decreased (0.032346 --> 0.032006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0242917\n",
      "\tspeed: 0.1065s/iter; left time: 2269.4284s\n",
      "\titers: 200, epoch: 5 | loss: 0.0264873\n",
      "\tspeed: 0.0371s/iter; left time: 786.0712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0252095 Vali Loss: 0.0319972 Test Loss: 0.0383190\n",
      "Validation loss decreased (0.032006 --> 0.031997).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0232972\n",
      "\tspeed: 0.1191s/iter; left time: 2512.3451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0272545\n",
      "\tspeed: 0.0593s/iter; left time: 1245.5091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.41s\n",
      "Steps: 223 | Train Loss: 0.0248804 Vali Loss: 0.0321177 Test Loss: 0.0387783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0248502\n",
      "\tspeed: 0.1626s/iter; left time: 3391.9986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0246590\n",
      "\tspeed: 0.0609s/iter; left time: 1264.0768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.44s\n",
      "Steps: 223 | Train Loss: 0.0245486 Vali Loss: 0.0322575 Test Loss: 0.0385280\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0231809\n",
      "\tspeed: 0.1776s/iter; left time: 3664.7994s\n",
      "\titers: 200, epoch: 8 | loss: 0.0264457\n",
      "\tspeed: 0.0693s/iter; left time: 1422.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.45s\n",
      "Steps: 223 | Train Loss: 0.0242934 Vali Loss: 0.0320401 Test Loss: 0.0383450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0242314\n",
      "\tspeed: 0.1477s/iter; left time: 3015.4758s\n",
      "\titers: 200, epoch: 9 | loss: 0.0211270\n",
      "\tspeed: 0.0601s/iter; left time: 1220.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.65s\n",
      "Steps: 223 | Train Loss: 0.0240388 Vali Loss: 0.0323531 Test Loss: 0.0390620\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0227715\n",
      "\tspeed: 0.1534s/iter; left time: 3098.5266s\n",
      "\titers: 200, epoch: 10 | loss: 0.0230594\n",
      "\tspeed: 0.0654s/iter; left time: 1314.7389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.52s\n",
      "Steps: 223 | Train Loss: 0.0237923 Vali Loss: 0.0326520 Test Loss: 0.0393335\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0234806\n",
      "\tspeed: 0.1480s/iter; left time: 2955.7649s\n",
      "\titers: 200, epoch: 11 | loss: 0.0218085\n",
      "\tspeed: 0.0751s/iter; left time: 1493.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 223 | Train Loss: 0.0235347 Vali Loss: 0.0327545 Test Loss: 0.0397263\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0224282\n",
      "\tspeed: 0.1723s/iter; left time: 3403.4856s\n",
      "\titers: 200, epoch: 12 | loss: 0.0245247\n",
      "\tspeed: 0.0573s/iter; left time: 1126.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 223 | Train Loss: 0.0233189 Vali Loss: 0.0326866 Test Loss: 0.0398961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0245513\n",
      "\tspeed: 0.1618s/iter; left time: 3160.0306s\n",
      "\titers: 200, epoch: 13 | loss: 0.0234690\n",
      "\tspeed: 0.0645s/iter; left time: 1253.2803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.69s\n",
      "Steps: 223 | Train Loss: 0.0231075 Vali Loss: 0.0328178 Test Loss: 0.0398631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0202346\n",
      "\tspeed: 0.1602s/iter; left time: 3091.2178s\n",
      "\titers: 200, epoch: 14 | loss: 0.0251649\n",
      "\tspeed: 0.0634s/iter; left time: 1217.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.31s\n",
      "Steps: 223 | Train Loss: 0.0229071 Vali Loss: 0.0329766 Test Loss: 0.0403753\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0229254\n",
      "\tspeed: 0.1855s/iter; left time: 3538.8579s\n",
      "\titers: 200, epoch: 15 | loss: 0.0261855\n",
      "\tspeed: 0.0613s/iter; left time: 1163.3658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.69s\n",
      "Steps: 223 | Train Loss: 0.0227360 Vali Loss: 0.0331558 Test Loss: 0.0409875\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03831901401281357, rmse:0.19575242698192596, mae:0.13659459352493286, rse:0.6933708786964417\n",
      "Intermediate time for DE and pred_len 168: 00h:05m:44.54s\n",
      "Intermediate time for DE: 00h:29m:15.85s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0269724\n",
      "\tspeed: 0.0949s/iter; left time: 2117.0566s\n",
      "\titers: 200, epoch: 1 | loss: 0.0243362\n",
      "\tspeed: 0.0577s/iter; left time: 1280.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.06s\n",
      "Steps: 224 | Train Loss: 0.0302129 Vali Loss: 0.0295490 Test Loss: 0.0403864\n",
      "Validation loss decreased (inf --> 0.029549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0150994\n",
      "\tspeed: 0.1301s/iter; left time: 2873.2971s\n",
      "\titers: 200, epoch: 2 | loss: 0.0153803\n",
      "\tspeed: 0.0772s/iter; left time: 1696.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.26s\n",
      "Steps: 224 | Train Loss: 0.0160300 Vali Loss: 0.0200448 Test Loss: 0.0257564\n",
      "Validation loss decreased (0.029549 --> 0.020045).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0125600\n",
      "\tspeed: 0.1311s/iter; left time: 2865.6311s\n",
      "\titers: 200, epoch: 3 | loss: 0.0146680\n",
      "\tspeed: 0.0579s/iter; left time: 1259.8559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0141722 Vali Loss: 0.0194474 Test Loss: 0.0255129\n",
      "Validation loss decreased (0.020045 --> 0.019447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0126545\n",
      "\tspeed: 0.1327s/iter; left time: 2869.7229s\n",
      "\titers: 200, epoch: 4 | loss: 0.0144309\n",
      "\tspeed: 0.0618s/iter; left time: 1330.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 224 | Train Loss: 0.0138278 Vali Loss: 0.0195728 Test Loss: 0.0255898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0136685\n",
      "\tspeed: 0.1314s/iter; left time: 2813.2953s\n",
      "\titers: 200, epoch: 5 | loss: 0.0130324\n",
      "\tspeed: 0.0590s/iter; left time: 1256.9042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.64s\n",
      "Steps: 224 | Train Loss: 0.0136225 Vali Loss: 0.0192595 Test Loss: 0.0253750\n",
      "Validation loss decreased (0.019447 --> 0.019259).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0141169\n",
      "\tspeed: 0.1540s/iter; left time: 3262.9077s\n",
      "\titers: 200, epoch: 6 | loss: 0.0152996\n",
      "\tspeed: 0.0685s/iter; left time: 1443.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.94s\n",
      "Steps: 224 | Train Loss: 0.0134702 Vali Loss: 0.0192517 Test Loss: 0.0253149\n",
      "Validation loss decreased (0.019259 --> 0.019252).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0136902\n",
      "\tspeed: 0.1234s/iter; left time: 2586.8724s\n",
      "\titers: 200, epoch: 7 | loss: 0.0145498\n",
      "\tspeed: 0.0653s/iter; left time: 1361.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.39s\n",
      "Steps: 224 | Train Loss: 0.0133439 Vali Loss: 0.0191847 Test Loss: 0.0253538\n",
      "Validation loss decreased (0.019252 --> 0.019185).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0131529\n",
      "\tspeed: 0.1294s/iter; left time: 2682.9253s\n",
      "\titers: 200, epoch: 8 | loss: 0.0136596\n",
      "\tspeed: 0.0565s/iter; left time: 1165.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 224 | Train Loss: 0.0132458 Vali Loss: 0.0190764 Test Loss: 0.0249816\n",
      "Validation loss decreased (0.019185 --> 0.019076).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0127635\n",
      "\tspeed: 0.1341s/iter; left time: 2749.5369s\n",
      "\titers: 200, epoch: 9 | loss: 0.0152654\n",
      "\tspeed: 0.0700s/iter; left time: 1428.7750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0131349 Vali Loss: 0.0190671 Test Loss: 0.0250864\n",
      "Validation loss decreased (0.019076 --> 0.019067).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0148076\n",
      "\tspeed: 0.1325s/iter; left time: 2687.5516s\n",
      "\titers: 200, epoch: 10 | loss: 0.0125041\n",
      "\tspeed: 0.0629s/iter; left time: 1269.6300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.74s\n",
      "Steps: 224 | Train Loss: 0.0130521 Vali Loss: 0.0188532 Test Loss: 0.0251634\n",
      "Validation loss decreased (0.019067 --> 0.018853).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0137696\n",
      "\tspeed: 0.1191s/iter; left time: 2389.7092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0129565\n",
      "\tspeed: 0.0569s/iter; left time: 1136.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.57s\n",
      "Steps: 224 | Train Loss: 0.0129698 Vali Loss: 0.0189545 Test Loss: 0.0249062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0138540\n",
      "\tspeed: 0.1267s/iter; left time: 2514.1986s\n",
      "\titers: 200, epoch: 12 | loss: 0.0117907\n",
      "\tspeed: 0.0545s/iter; left time: 1075.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.13s\n",
      "Steps: 224 | Train Loss: 0.0128797 Vali Loss: 0.0189448 Test Loss: 0.0250207\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0122733\n",
      "\tspeed: 0.1497s/iter; left time: 2935.8357s\n",
      "\titers: 200, epoch: 13 | loss: 0.0124052\n",
      "\tspeed: 0.0596s/iter; left time: 1162.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.95s\n",
      "Steps: 224 | Train Loss: 0.0128237 Vali Loss: 0.0189629 Test Loss: 0.0248485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0136241\n",
      "\tspeed: 0.1196s/iter; left time: 2319.5275s\n",
      "\titers: 200, epoch: 14 | loss: 0.0113933\n",
      "\tspeed: 0.0644s/iter; left time: 1241.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.78s\n",
      "Steps: 224 | Train Loss: 0.0127703 Vali Loss: 0.0189413 Test Loss: 0.0249125\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0105021\n",
      "\tspeed: 0.1229s/iter; left time: 2355.1425s\n",
      "\titers: 200, epoch: 15 | loss: 0.0112538\n",
      "\tspeed: 0.0582s/iter; left time: 1109.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 224 | Train Loss: 0.0127224 Vali Loss: 0.0189495 Test Loss: 0.0250717\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0118816\n",
      "\tspeed: 0.1369s/iter; left time: 2592.8825s\n",
      "\titers: 200, epoch: 16 | loss: 0.0133852\n",
      "\tspeed: 0.0708s/iter; left time: 1333.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0126632 Vali Loss: 0.0187300 Test Loss: 0.0250755\n",
      "Validation loss decreased (0.018853 --> 0.018730).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0128408\n",
      "\tspeed: 0.1243s/iter; left time: 2326.6923s\n",
      "\titers: 200, epoch: 17 | loss: 0.0137415\n",
      "\tspeed: 0.0612s/iter; left time: 1139.6783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.06s\n",
      "Steps: 224 | Train Loss: 0.0126192 Vali Loss: 0.0188007 Test Loss: 0.0249625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0120534\n",
      "\tspeed: 0.1170s/iter; left time: 2164.2999s\n",
      "\titers: 200, epoch: 18 | loss: 0.0132773\n",
      "\tspeed: 0.0579s/iter; left time: 1064.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.56s\n",
      "Steps: 224 | Train Loss: 0.0126237 Vali Loss: 0.0187780 Test Loss: 0.0249065\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0123758\n",
      "\tspeed: 0.1237s/iter; left time: 2260.2447s\n",
      "\titers: 200, epoch: 19 | loss: 0.0131285\n",
      "\tspeed: 0.0468s/iter; left time: 849.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0125494 Vali Loss: 0.0189852 Test Loss: 0.0251082\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0104999\n",
      "\tspeed: 0.1079s/iter; left time: 1946.6551s\n",
      "\titers: 200, epoch: 20 | loss: 0.0119633\n",
      "\tspeed: 0.0584s/iter; left time: 1048.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 224 | Train Loss: 0.0125140 Vali Loss: 0.0189457 Test Loss: 0.0251339\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0133592\n",
      "\tspeed: 0.1363s/iter; left time: 2428.5024s\n",
      "\titers: 200, epoch: 21 | loss: 0.0120427\n",
      "\tspeed: 0.0692s/iter; left time: 1227.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:14.69s\n",
      "Steps: 224 | Train Loss: 0.0124908 Vali Loss: 0.0188245 Test Loss: 0.0249186\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0118607\n",
      "\tspeed: 0.1304s/iter; left time: 2295.3449s\n",
      "\titers: 200, epoch: 22 | loss: 0.0109531\n",
      "\tspeed: 0.0607s/iter; left time: 1061.7371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.56s\n",
      "Steps: 224 | Train Loss: 0.0124526 Vali Loss: 0.0187356 Test Loss: 0.0249374\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0119522\n",
      "\tspeed: 0.1434s/iter; left time: 2491.7680s\n",
      "\titers: 200, epoch: 23 | loss: 0.0112567\n",
      "\tspeed: 0.0722s/iter; left time: 1247.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:16.07s\n",
      "Steps: 224 | Train Loss: 0.0124514 Vali Loss: 0.0188555 Test Loss: 0.0249920\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0119894\n",
      "\tspeed: 0.1292s/iter; left time: 2216.1683s\n",
      "\titers: 200, epoch: 24 | loss: 0.0123275\n",
      "\tspeed: 0.0445s/iter; left time: 758.9499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0124463 Vali Loss: 0.0188186 Test Loss: 0.0249083\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0132149\n",
      "\tspeed: 0.1291s/iter; left time: 2184.7322s\n",
      "\titers: 200, epoch: 25 | loss: 0.0138823\n",
      "\tspeed: 0.0669s/iter; left time: 1125.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:14.41s\n",
      "Steps: 224 | Train Loss: 0.0124279 Vali Loss: 0.0187712 Test Loss: 0.0249708\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0122586\n",
      "\tspeed: 0.1518s/iter; left time: 2534.7762s\n",
      "\titers: 200, epoch: 26 | loss: 0.0116505\n",
      "\tspeed: 0.0620s/iter; left time: 1029.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:14.47s\n",
      "Steps: 224 | Train Loss: 0.0123840 Vali Loss: 0.0188168 Test Loss: 0.0250552\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025075480341911316, rmse:0.15835238993167877, mae:0.10364750027656555, rse:0.5462708473205566\n",
      "Intermediate time for GB and pred_len 24: 00h:08m:36.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0330599\n",
      "\tspeed: 0.0721s/iter; left time: 1608.6119s\n",
      "\titers: 200, epoch: 1 | loss: 0.0320975\n",
      "\tspeed: 0.0488s/iter; left time: 1083.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0326172 Vali Loss: 0.0341243 Test Loss: 0.0486324\n",
      "Validation loss decreased (inf --> 0.034124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0248736\n",
      "\tspeed: 0.1356s/iter; left time: 2994.4345s\n",
      "\titers: 200, epoch: 2 | loss: 0.0204750\n",
      "\tspeed: 0.0480s/iter; left time: 1055.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 224 | Train Loss: 0.0233874 Vali Loss: 0.0292890 Test Loss: 0.0413262\n",
      "Validation loss decreased (0.034124 --> 0.029289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0213269\n",
      "\tspeed: 0.1554s/iter; left time: 3395.9949s\n",
      "\titers: 200, epoch: 3 | loss: 0.0210294\n",
      "\tspeed: 0.0511s/iter; left time: 1111.1576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.65s\n",
      "Steps: 224 | Train Loss: 0.0218675 Vali Loss: 0.0292476 Test Loss: 0.0413741\n",
      "Validation loss decreased (0.029289 --> 0.029248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0207670\n",
      "\tspeed: 0.1219s/iter; left time: 2636.4919s\n",
      "\titers: 200, epoch: 4 | loss: 0.0213264\n",
      "\tspeed: 0.0487s/iter; left time: 1048.5725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 224 | Train Loss: 0.0215076 Vali Loss: 0.0292306 Test Loss: 0.0416261\n",
      "Validation loss decreased (0.029248 --> 0.029231).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0218179\n",
      "\tspeed: 0.1079s/iter; left time: 2309.6949s\n",
      "\titers: 200, epoch: 5 | loss: 0.0186270\n",
      "\tspeed: 0.0542s/iter; left time: 1154.9270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.33s\n",
      "Steps: 224 | Train Loss: 0.0212008 Vali Loss: 0.0290131 Test Loss: 0.0415289\n",
      "Validation loss decreased (0.029231 --> 0.029013).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0219785\n",
      "\tspeed: 0.1077s/iter; left time: 2280.8785s\n",
      "\titers: 200, epoch: 6 | loss: 0.0216234\n",
      "\tspeed: 0.0547s/iter; left time: 1153.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 224 | Train Loss: 0.0209583 Vali Loss: 0.0289114 Test Loss: 0.0414900\n",
      "Validation loss decreased (0.029013 --> 0.028911).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0219029\n",
      "\tspeed: 0.1349s/iter; left time: 2827.5189s\n",
      "\titers: 200, epoch: 7 | loss: 0.0201141\n",
      "\tspeed: 0.0520s/iter; left time: 1084.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.79s\n",
      "Steps: 224 | Train Loss: 0.0207239 Vali Loss: 0.0289981 Test Loss: 0.0413217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0213522\n",
      "\tspeed: 0.1377s/iter; left time: 2855.3276s\n",
      "\titers: 200, epoch: 8 | loss: 0.0198995\n",
      "\tspeed: 0.0517s/iter; left time: 1066.8311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0205090 Vali Loss: 0.0290755 Test Loss: 0.0419447\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0203818\n",
      "\tspeed: 0.1119s/iter; left time: 2294.0607s\n",
      "\titers: 200, epoch: 9 | loss: 0.0208378\n",
      "\tspeed: 0.0504s/iter; left time: 1029.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.07s\n",
      "Steps: 224 | Train Loss: 0.0202890 Vali Loss: 0.0291642 Test Loss: 0.0433464\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0215469\n",
      "\tspeed: 0.0802s/iter; left time: 1627.7250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0189829\n",
      "\tspeed: 0.0403s/iter; left time: 813.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 224 | Train Loss: 0.0201078 Vali Loss: 0.0291582 Test Loss: 0.0431275\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0196008\n",
      "\tspeed: 0.1197s/iter; left time: 2401.1102s\n",
      "\titers: 200, epoch: 11 | loss: 0.0204214\n",
      "\tspeed: 0.0534s/iter; left time: 1066.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 224 | Train Loss: 0.0199237 Vali Loss: 0.0290428 Test Loss: 0.0433948\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0214353\n",
      "\tspeed: 0.1452s/iter; left time: 2880.7847s\n",
      "\titers: 200, epoch: 12 | loss: 0.0202651\n",
      "\tspeed: 0.0460s/iter; left time: 908.0462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 224 | Train Loss: 0.0197674 Vali Loss: 0.0287947 Test Loss: 0.0423261\n",
      "Validation loss decreased (0.028911 --> 0.028795).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0199370\n",
      "\tspeed: 0.1579s/iter; left time: 3097.2591s\n",
      "\titers: 200, epoch: 13 | loss: 0.0198088\n",
      "\tspeed: 0.0503s/iter; left time: 980.7151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.20s\n",
      "Steps: 224 | Train Loss: 0.0195824 Vali Loss: 0.0293069 Test Loss: 0.0439301\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0197234\n",
      "\tspeed: 0.1392s/iter; left time: 2699.0323s\n",
      "\titers: 200, epoch: 14 | loss: 0.0186938\n",
      "\tspeed: 0.0530s/iter; left time: 1022.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.91s\n",
      "Steps: 224 | Train Loss: 0.0194025 Vali Loss: 0.0294660 Test Loss: 0.0436790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0176121\n",
      "\tspeed: 0.1200s/iter; left time: 2299.3362s\n",
      "\titers: 200, epoch: 15 | loss: 0.0187093\n",
      "\tspeed: 0.0555s/iter; left time: 1058.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.26s\n",
      "Steps: 224 | Train Loss: 0.0192549 Vali Loss: 0.0296301 Test Loss: 0.0443228\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0197526\n",
      "\tspeed: 0.1209s/iter; left time: 2289.9882s\n",
      "\titers: 200, epoch: 16 | loss: 0.0209090\n",
      "\tspeed: 0.0619s/iter; left time: 1166.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.32s\n",
      "Steps: 224 | Train Loss: 0.0191137 Vali Loss: 0.0298030 Test Loss: 0.0447214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0185755\n",
      "\tspeed: 0.1009s/iter; left time: 1888.2981s\n",
      "\titers: 200, epoch: 17 | loss: 0.0183995\n",
      "\tspeed: 0.0401s/iter; left time: 745.7428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.86s\n",
      "Steps: 224 | Train Loss: 0.0189747 Vali Loss: 0.0297888 Test Loss: 0.0445576\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0186117\n",
      "\tspeed: 0.1168s/iter; left time: 2160.6665s\n",
      "\titers: 200, epoch: 18 | loss: 0.0184859\n",
      "\tspeed: 0.0502s/iter; left time: 922.6528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.29s\n",
      "Steps: 224 | Train Loss: 0.0188568 Vali Loss: 0.0300322 Test Loss: 0.0449636\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0194068\n",
      "\tspeed: 0.1304s/iter; left time: 2382.0724s\n",
      "\titers: 200, epoch: 19 | loss: 0.0204162\n",
      "\tspeed: 0.0452s/iter; left time: 821.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.19s\n",
      "Steps: 224 | Train Loss: 0.0187836 Vali Loss: 0.0299262 Test Loss: 0.0444477\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0171403\n",
      "\tspeed: 0.1235s/iter; left time: 2229.1043s\n",
      "\titers: 200, epoch: 20 | loss: 0.0184043\n",
      "\tspeed: 0.0503s/iter; left time: 902.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.99s\n",
      "Steps: 224 | Train Loss: 0.0186674 Vali Loss: 0.0300881 Test Loss: 0.0449346\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0191293\n",
      "\tspeed: 0.1142s/iter; left time: 2035.0315s\n",
      "\titers: 200, epoch: 21 | loss: 0.0157105\n",
      "\tspeed: 0.0595s/iter; left time: 1054.7874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0186050 Vali Loss: 0.0299886 Test Loss: 0.0451011\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0181225\n",
      "\tspeed: 0.1128s/iter; left time: 1984.6494s\n",
      "\titers: 200, epoch: 22 | loss: 0.0193367\n",
      "\tspeed: 0.0533s/iter; left time: 931.7766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:12.27s\n",
      "Steps: 224 | Train Loss: 0.0185242 Vali Loss: 0.0302375 Test Loss: 0.0453603\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.042326126247644424, rmse:0.20573315024375916, mae:0.14367079734802246, rse:0.711453914642334\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:35.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0324556\n",
      "\tspeed: 0.0669s/iter; left time: 1484.2263s\n",
      "\titers: 200, epoch: 1 | loss: 0.0294266\n",
      "\tspeed: 0.0447s/iter; left time: 986.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 223 | Train Loss: 0.0334026 Vali Loss: 0.0353121 Test Loss: 0.0505240\n",
      "Validation loss decreased (inf --> 0.035312).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0253777\n",
      "\tspeed: 0.1231s/iter; left time: 2704.9071s\n",
      "\titers: 200, epoch: 2 | loss: 0.0229065\n",
      "\tspeed: 0.0490s/iter; left time: 1072.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 223 | Train Loss: 0.0249163 Vali Loss: 0.0309957 Test Loss: 0.0438974\n",
      "Validation loss decreased (0.035312 --> 0.030996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0244064\n",
      "\tspeed: 0.1089s/iter; left time: 2368.8973s\n",
      "\titers: 200, epoch: 3 | loss: 0.0227683\n",
      "\tspeed: 0.0548s/iter; left time: 1186.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 223 | Train Loss: 0.0233406 Vali Loss: 0.0306889 Test Loss: 0.0435962\n",
      "Validation loss decreased (0.030996 --> 0.030689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0229893\n",
      "\tspeed: 0.1143s/iter; left time: 2461.5903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0252356\n",
      "\tspeed: 0.0499s/iter; left time: 1069.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 223 | Train Loss: 0.0229192 Vali Loss: 0.0309550 Test Loss: 0.0438111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0214661\n",
      "\tspeed: 0.1358s/iter; left time: 2894.1252s\n",
      "\titers: 200, epoch: 5 | loss: 0.0242698\n",
      "\tspeed: 0.0500s/iter; left time: 1060.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.02s\n",
      "Steps: 223 | Train Loss: 0.0225604 Vali Loss: 0.0310903 Test Loss: 0.0442144\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0217058\n",
      "\tspeed: 0.1231s/iter; left time: 2595.5265s\n",
      "\titers: 200, epoch: 6 | loss: 0.0224381\n",
      "\tspeed: 0.0541s/iter; left time: 1136.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.50s\n",
      "Steps: 223 | Train Loss: 0.0222235 Vali Loss: 0.0310295 Test Loss: 0.0448184\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0219715\n",
      "\tspeed: 0.1057s/iter; left time: 2205.3009s\n",
      "\titers: 200, epoch: 7 | loss: 0.0198097\n",
      "\tspeed: 0.0564s/iter; left time: 1170.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.31s\n",
      "Steps: 223 | Train Loss: 0.0219527 Vali Loss: 0.0310001 Test Loss: 0.0459959\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0215335\n",
      "\tspeed: 0.1103s/iter; left time: 2276.4955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0237119\n",
      "\tspeed: 0.0499s/iter; left time: 1024.1760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.27s\n",
      "Steps: 223 | Train Loss: 0.0217264 Vali Loss: 0.0306654 Test Loss: 0.0454366\n",
      "Validation loss decreased (0.030689 --> 0.030665).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0217619\n",
      "\tspeed: 0.1486s/iter; left time: 3034.0733s\n",
      "\titers: 200, epoch: 9 | loss: 0.0194218\n",
      "\tspeed: 0.0505s/iter; left time: 1026.0671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.60s\n",
      "Steps: 223 | Train Loss: 0.0215284 Vali Loss: 0.0308548 Test Loss: 0.0461860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0203193\n",
      "\tspeed: 0.1241s/iter; left time: 2505.8855s\n",
      "\titers: 200, epoch: 10 | loss: 0.0218020\n",
      "\tspeed: 0.0512s/iter; left time: 1029.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 223 | Train Loss: 0.0213034 Vali Loss: 0.0310266 Test Loss: 0.0474695\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0209533\n",
      "\tspeed: 0.1086s/iter; left time: 2168.0828s\n",
      "\titers: 200, epoch: 11 | loss: 0.0206968\n",
      "\tspeed: 0.0610s/iter; left time: 1211.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.48s\n",
      "Steps: 223 | Train Loss: 0.0211460 Vali Loss: 0.0307943 Test Loss: 0.0460785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0194066\n",
      "\tspeed: 0.1100s/iter; left time: 2172.6223s\n",
      "\titers: 200, epoch: 12 | loss: 0.0205669\n",
      "\tspeed: 0.0468s/iter; left time: 919.2826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.11s\n",
      "Steps: 223 | Train Loss: 0.0209543 Vali Loss: 0.0309621 Test Loss: 0.0466941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0209157\n",
      "\tspeed: 0.1305s/iter; left time: 2547.7339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0217956\n",
      "\tspeed: 0.0357s/iter; left time: 693.6325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 223 | Train Loss: 0.0207500 Vali Loss: 0.0310574 Test Loss: 0.0467395\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0201685\n",
      "\tspeed: 0.0900s/iter; left time: 1737.1115s\n",
      "\titers: 200, epoch: 14 | loss: 0.0209625\n",
      "\tspeed: 0.0554s/iter; left time: 1063.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 223 | Train Loss: 0.0206069 Vali Loss: 0.0311464 Test Loss: 0.0473922\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0213707\n",
      "\tspeed: 0.1168s/iter; left time: 2228.1034s\n",
      "\titers: 200, epoch: 15 | loss: 0.0221779\n",
      "\tspeed: 0.0542s/iter; left time: 1028.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.75s\n",
      "Steps: 223 | Train Loss: 0.0204338 Vali Loss: 0.0315270 Test Loss: 0.0482186\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0207527\n",
      "\tspeed: 0.1145s/iter; left time: 2159.6316s\n",
      "\titers: 200, epoch: 16 | loss: 0.0220013\n",
      "\tspeed: 0.0549s/iter; left time: 1029.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.21s\n",
      "Steps: 223 | Train Loss: 0.0202920 Vali Loss: 0.0313826 Test Loss: 0.0471232\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0202375\n",
      "\tspeed: 0.1286s/iter; left time: 2396.3411s\n",
      "\titers: 200, epoch: 17 | loss: 0.0214163\n",
      "\tspeed: 0.0499s/iter; left time: 923.9435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.79s\n",
      "Steps: 223 | Train Loss: 0.0201838 Vali Loss: 0.0314722 Test Loss: 0.0471828\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0205100\n",
      "\tspeed: 0.1199s/iter; left time: 2207.4392s\n",
      "\titers: 200, epoch: 18 | loss: 0.0198990\n",
      "\tspeed: 0.0499s/iter; left time: 913.4533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.50s\n",
      "Steps: 223 | Train Loss: 0.0200635 Vali Loss: 0.0314998 Test Loss: 0.0473011\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045436594635248184, rmse:0.21315860748291016, mae:0.1511395126581192, rse:0.7390515208244324\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:17.05s\n",
      "Intermediate time for GB: 00h:20m:29.67s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0296890\n",
      "\tspeed: 0.0636s/iter; left time: 1418.9647s\n",
      "\titers: 200, epoch: 1 | loss: 0.0237544\n",
      "\tspeed: 0.0316s/iter; left time: 702.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0329008 Vali Loss: 0.0190733 Test Loss: 0.0246103\n",
      "Validation loss decreased (inf --> 0.019073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0116199\n",
      "\tspeed: 0.0752s/iter; left time: 1659.3678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0107149\n",
      "\tspeed: 0.0344s/iter; left time: 756.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0124929 Vali Loss: 0.0097106 Test Loss: 0.0120963\n",
      "Validation loss decreased (0.019073 --> 0.009711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0093019\n",
      "\tspeed: 0.0783s/iter; left time: 1712.0487s\n",
      "\titers: 200, epoch: 3 | loss: 0.0094715\n",
      "\tspeed: 0.0379s/iter; left time: 824.7608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.0097760 Vali Loss: 0.0089975 Test Loss: 0.0112857\n",
      "Validation loss decreased (0.009711 --> 0.008997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0086354\n",
      "\tspeed: 0.0812s/iter; left time: 1755.5133s\n",
      "\titers: 200, epoch: 4 | loss: 0.0091337\n",
      "\tspeed: 0.0316s/iter; left time: 679.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0090991 Vali Loss: 0.0086354 Test Loss: 0.0108668\n",
      "Validation loss decreased (0.008997 --> 0.008635).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0083218\n",
      "\tspeed: 0.0765s/iter; left time: 1638.3038s\n",
      "\titers: 200, epoch: 5 | loss: 0.0086437\n",
      "\tspeed: 0.0295s/iter; left time: 628.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0086944 Vali Loss: 0.0083791 Test Loss: 0.0106129\n",
      "Validation loss decreased (0.008635 --> 0.008379).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0074544\n",
      "\tspeed: 0.0730s/iter; left time: 1546.9106s\n",
      "\titers: 200, epoch: 6 | loss: 0.0082814\n",
      "\tspeed: 0.0334s/iter; left time: 704.7319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0084254 Vali Loss: 0.0082155 Test Loss: 0.0103570\n",
      "Validation loss decreased (0.008379 --> 0.008215).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0101399\n",
      "\tspeed: 0.0800s/iter; left time: 1677.0133s\n",
      "\titers: 200, epoch: 7 | loss: 0.0085558\n",
      "\tspeed: 0.0337s/iter; left time: 703.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0082341 Vali Loss: 0.0081511 Test Loss: 0.0103137\n",
      "Validation loss decreased (0.008215 --> 0.008151).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0085888\n",
      "\tspeed: 0.0762s/iter; left time: 1579.7588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0073330\n",
      "\tspeed: 0.0305s/iter; left time: 629.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0080856 Vali Loss: 0.0080615 Test Loss: 0.0102863\n",
      "Validation loss decreased (0.008151 --> 0.008062).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0083045\n",
      "\tspeed: 0.0765s/iter; left time: 1567.9369s\n",
      "\titers: 200, epoch: 9 | loss: 0.0074788\n",
      "\tspeed: 0.0336s/iter; left time: 686.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0079546 Vali Loss: 0.0079857 Test Loss: 0.0101347\n",
      "Validation loss decreased (0.008062 --> 0.007986).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0087893\n",
      "\tspeed: 0.0782s/iter; left time: 1586.2101s\n",
      "\titers: 200, epoch: 10 | loss: 0.0075799\n",
      "\tspeed: 0.0296s/iter; left time: 598.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 224 | Train Loss: 0.0078699 Vali Loss: 0.0079657 Test Loss: 0.0100636\n",
      "Validation loss decreased (0.007986 --> 0.007966).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0083630\n",
      "\tspeed: 0.0793s/iter; left time: 1590.1206s\n",
      "\titers: 200, epoch: 11 | loss: 0.0083637\n",
      "\tspeed: 0.0298s/iter; left time: 594.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.07s\n",
      "Steps: 224 | Train Loss: 0.0078086 Vali Loss: 0.0079774 Test Loss: 0.0101389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0080166\n",
      "\tspeed: 0.0788s/iter; left time: 1563.7166s\n",
      "\titers: 200, epoch: 12 | loss: 0.0074236\n",
      "\tspeed: 0.0315s/iter; left time: 622.4686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 224 | Train Loss: 0.0077407 Vali Loss: 0.0078617 Test Loss: 0.0100172\n",
      "Validation loss decreased (0.007966 --> 0.007862).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0070259\n",
      "\tspeed: 0.0766s/iter; left time: 1501.5707s\n",
      "\titers: 200, epoch: 13 | loss: 0.0064969\n",
      "\tspeed: 0.0277s/iter; left time: 539.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0076735 Vali Loss: 0.0078890 Test Loss: 0.0099257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0083835\n",
      "\tspeed: 0.0809s/iter; left time: 1568.3910s\n",
      "\titers: 200, epoch: 14 | loss: 0.0070978\n",
      "\tspeed: 0.0352s/iter; left time: 679.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0076318 Vali Loss: 0.0078510 Test Loss: 0.0099501\n",
      "Validation loss decreased (0.007862 --> 0.007851).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0073405\n",
      "\tspeed: 0.0712s/iter; left time: 1364.7115s\n",
      "\titers: 200, epoch: 15 | loss: 0.0070576\n",
      "\tspeed: 0.0322s/iter; left time: 613.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 224 | Train Loss: 0.0075842 Vali Loss: 0.0077827 Test Loss: 0.0098846\n",
      "Validation loss decreased (0.007851 --> 0.007783).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0066532\n",
      "\tspeed: 0.0744s/iter; left time: 1409.1273s\n",
      "\titers: 200, epoch: 16 | loss: 0.0075404\n",
      "\tspeed: 0.0338s/iter; left time: 636.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0075499 Vali Loss: 0.0078112 Test Loss: 0.0098918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0072845\n",
      "\tspeed: 0.0728s/iter; left time: 1362.5500s\n",
      "\titers: 200, epoch: 17 | loss: 0.0075278\n",
      "\tspeed: 0.0364s/iter; left time: 678.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 224 | Train Loss: 0.0075029 Vali Loss: 0.0077626 Test Loss: 0.0098836\n",
      "Validation loss decreased (0.007783 --> 0.007763).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0070151\n",
      "\tspeed: 0.0572s/iter; left time: 1057.5788s\n",
      "\titers: 200, epoch: 18 | loss: 0.0067206\n",
      "\tspeed: 0.0233s/iter; left time: 428.7176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0074731 Vali Loss: 0.0077108 Test Loss: 0.0098255\n",
      "Validation loss decreased (0.007763 --> 0.007711).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0076519\n",
      "\tspeed: 0.0546s/iter; left time: 996.6237s\n",
      "\titers: 200, epoch: 19 | loss: 0.0072590\n",
      "\tspeed: 0.0332s/iter; left time: 604.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0074561 Vali Loss: 0.0077372 Test Loss: 0.0098622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0074429\n",
      "\tspeed: 0.0819s/iter; left time: 1477.1287s\n",
      "\titers: 200, epoch: 20 | loss: 0.0081411\n",
      "\tspeed: 0.0297s/iter; left time: 532.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0074083 Vali Loss: 0.0077439 Test Loss: 0.0098159\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0075138\n",
      "\tspeed: 0.0783s/iter; left time: 1394.8427s\n",
      "\titers: 200, epoch: 21 | loss: 0.0077157\n",
      "\tspeed: 0.0315s/iter; left time: 558.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0073987 Vali Loss: 0.0077213 Test Loss: 0.0098094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0079712\n",
      "\tspeed: 0.0855s/iter; left time: 1504.2407s\n",
      "\titers: 200, epoch: 22 | loss: 0.0067386\n",
      "\tspeed: 0.0331s/iter; left time: 579.6989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0073739 Vali Loss: 0.0076907 Test Loss: 0.0097665\n",
      "Validation loss decreased (0.007711 --> 0.007691).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0069302\n",
      "\tspeed: 0.0891s/iter; left time: 1547.8979s\n",
      "\titers: 200, epoch: 23 | loss: 0.0073624\n",
      "\tspeed: 0.0408s/iter; left time: 705.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0073590 Vali Loss: 0.0077081 Test Loss: 0.0097860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0074125\n",
      "\tspeed: 0.1093s/iter; left time: 1873.7194s\n",
      "\titers: 200, epoch: 24 | loss: 0.0077528\n",
      "\tspeed: 0.0396s/iter; left time: 675.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:10.39s\n",
      "Steps: 224 | Train Loss: 0.0073373 Vali Loss: 0.0077147 Test Loss: 0.0097757\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0084801\n",
      "\tspeed: 0.0980s/iter; left time: 1659.2641s\n",
      "\titers: 200, epoch: 25 | loss: 0.0073303\n",
      "\tspeed: 0.0413s/iter; left time: 695.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.34s\n",
      "Steps: 224 | Train Loss: 0.0073261 Vali Loss: 0.0076876 Test Loss: 0.0097680\n",
      "Validation loss decreased (0.007691 --> 0.007688).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0075227\n",
      "\tspeed: 0.0986s/iter; left time: 1647.3918s\n",
      "\titers: 200, epoch: 26 | loss: 0.0073098\n",
      "\tspeed: 0.0392s/iter; left time: 650.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 224 | Train Loss: 0.0073206 Vali Loss: 0.0077104 Test Loss: 0.0097499\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0066695\n",
      "\tspeed: 0.1103s/iter; left time: 1816.6040s\n",
      "\titers: 200, epoch: 27 | loss: 0.0084324\n",
      "\tspeed: 0.0460s/iter; left time: 753.1385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.67s\n",
      "Steps: 224 | Train Loss: 0.0072957 Vali Loss: 0.0077138 Test Loss: 0.0097647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0059264\n",
      "\tspeed: 0.0959s/iter; left time: 1557.9681s\n",
      "\titers: 200, epoch: 28 | loss: 0.0072996\n",
      "\tspeed: 0.0393s/iter; left time: 634.7760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0072941 Vali Loss: 0.0076749 Test Loss: 0.0097210\n",
      "Validation loss decreased (0.007688 --> 0.007675).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0069776\n",
      "\tspeed: 0.1001s/iter; left time: 1603.9535s\n",
      "\titers: 200, epoch: 29 | loss: 0.0073290\n",
      "\tspeed: 0.0380s/iter; left time: 604.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:10.05s\n",
      "Steps: 224 | Train Loss: 0.0072689 Vali Loss: 0.0076519 Test Loss: 0.0097318\n",
      "Validation loss decreased (0.007675 --> 0.007652).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0072907\n",
      "\tspeed: 0.0996s/iter; left time: 1573.9871s\n",
      "\titers: 200, epoch: 30 | loss: 0.0072649\n",
      "\tspeed: 0.0371s/iter; left time: 582.5170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 224 | Train Loss: 0.0072635 Vali Loss: 0.0076725 Test Loss: 0.0097222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0075929\n",
      "\tspeed: 0.0966s/iter; left time: 1505.1194s\n",
      "\titers: 200, epoch: 31 | loss: 0.0085643\n",
      "\tspeed: 0.0465s/iter; left time: 720.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:10.84s\n",
      "Steps: 224 | Train Loss: 0.0072595 Vali Loss: 0.0076283 Test Loss: 0.0097321\n",
      "Validation loss decreased (0.007652 --> 0.007628).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0068163\n",
      "\tspeed: 0.1045s/iter; left time: 1604.8593s\n",
      "\titers: 200, epoch: 32 | loss: 0.0068024\n",
      "\tspeed: 0.0427s/iter; left time: 650.7120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0072530 Vali Loss: 0.0076806 Test Loss: 0.0097346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0077122\n",
      "\tspeed: 0.0897s/iter; left time: 1357.2723s\n",
      "\titers: 200, epoch: 33 | loss: 0.0074561\n",
      "\tspeed: 0.0445s/iter; left time: 668.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.93s\n",
      "Steps: 224 | Train Loss: 0.0072397 Vali Loss: 0.0076467 Test Loss: 0.0097170\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0078902\n",
      "\tspeed: 0.0899s/iter; left time: 1339.7985s\n",
      "\titers: 200, epoch: 34 | loss: 0.0068785\n",
      "\tspeed: 0.0484s/iter; left time: 716.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 224 | Train Loss: 0.0072408 Vali Loss: 0.0076447 Test Loss: 0.0097050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0074193\n",
      "\tspeed: 0.0870s/iter; left time: 1277.6801s\n",
      "\titers: 200, epoch: 35 | loss: 0.0073635\n",
      "\tspeed: 0.0471s/iter; left time: 686.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0072479 Vali Loss: 0.0076825 Test Loss: 0.0097164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0075246\n",
      "\tspeed: 0.1072s/iter; left time: 1549.8557s\n",
      "\titers: 200, epoch: 36 | loss: 0.0068101\n",
      "\tspeed: 0.0490s/iter; left time: 704.1861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:10.88s\n",
      "Steps: 224 | Train Loss: 0.0072440 Vali Loss: 0.0076385 Test Loss: 0.0097149\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0068397\n",
      "\tspeed: 0.0899s/iter; left time: 1279.9625s\n",
      "\titers: 200, epoch: 37 | loss: 0.0073553\n",
      "\tspeed: 0.0465s/iter; left time: 657.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0072382 Vali Loss: 0.0076576 Test Loss: 0.0097067\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0065189\n",
      "\tspeed: 0.0923s/iter; left time: 1293.8674s\n",
      "\titers: 200, epoch: 38 | loss: 0.0077119\n",
      "\tspeed: 0.0504s/iter; left time: 701.5504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.46s\n",
      "Steps: 224 | Train Loss: 0.0072418 Vali Loss: 0.0076496 Test Loss: 0.0097053\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0072017\n",
      "\tspeed: 0.0923s/iter; left time: 1272.2152s\n",
      "\titers: 200, epoch: 39 | loss: 0.0068445\n",
      "\tspeed: 0.0508s/iter; left time: 694.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:10.68s\n",
      "Steps: 224 | Train Loss: 0.0072241 Vali Loss: 0.0076411 Test Loss: 0.0097058\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0064202\n",
      "\tspeed: 0.1032s/iter; left time: 1400.2378s\n",
      "\titers: 200, epoch: 40 | loss: 0.0071409\n",
      "\tspeed: 0.0560s/iter; left time: 754.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0072160 Vali Loss: 0.0076559 Test Loss: 0.0097114\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0072009\n",
      "\tspeed: 0.0931s/iter; left time: 1241.8648s\n",
      "\titers: 200, epoch: 41 | loss: 0.0074637\n",
      "\tspeed: 0.0449s/iter; left time: 594.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 224 | Train Loss: 0.0072244 Vali Loss: 0.0076395 Test Loss: 0.0096962\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00973209086805582, rmse:0.09865135699510574, mae:0.060730285942554474, rse:0.29031902551651\n",
      "Intermediate time for ES and pred_len 24: 00h:08m:40.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0309228\n",
      "\tspeed: 0.0551s/iter; left time: 1229.7799s\n",
      "\titers: 200, epoch: 1 | loss: 0.0244755\n",
      "\tspeed: 0.0362s/iter; left time: 804.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0342055 Vali Loss: 0.0226442 Test Loss: 0.0286723\n",
      "Validation loss decreased (inf --> 0.022644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0189586\n",
      "\tspeed: 0.1378s/iter; left time: 3041.1119s\n",
      "\titers: 200, epoch: 2 | loss: 0.0158069\n",
      "\tspeed: 0.0503s/iter; left time: 1104.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 224 | Train Loss: 0.0182901 Vali Loss: 0.0165065 Test Loss: 0.0204272\n",
      "Validation loss decreased (0.022644 --> 0.016506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0157190\n",
      "\tspeed: 0.1254s/iter; left time: 2740.7390s\n",
      "\titers: 200, epoch: 3 | loss: 0.0146123\n",
      "\tspeed: 0.0405s/iter; left time: 881.5793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.09s\n",
      "Steps: 224 | Train Loss: 0.0157535 Vali Loss: 0.0156040 Test Loss: 0.0193479\n",
      "Validation loss decreased (0.016506 --> 0.015604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0148218\n",
      "\tspeed: 0.1281s/iter; left time: 2770.4105s\n",
      "\titers: 200, epoch: 4 | loss: 0.0146640\n",
      "\tspeed: 0.0447s/iter; left time: 962.2575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.05s\n",
      "Steps: 224 | Train Loss: 0.0150019 Vali Loss: 0.0154184 Test Loss: 0.0190234\n",
      "Validation loss decreased (0.015604 --> 0.015418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0142901\n",
      "\tspeed: 0.1242s/iter; left time: 2657.7461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0133076\n",
      "\tspeed: 0.0255s/iter; left time: 543.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0145813 Vali Loss: 0.0150859 Test Loss: 0.0186584\n",
      "Validation loss decreased (0.015418 --> 0.015086).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0143639\n",
      "\tspeed: 0.0724s/iter; left time: 1533.7826s\n",
      "\titers: 200, epoch: 6 | loss: 0.0143160\n",
      "\tspeed: 0.0385s/iter; left time: 811.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 224 | Train Loss: 0.0142854 Vali Loss: 0.0149837 Test Loss: 0.0185050\n",
      "Validation loss decreased (0.015086 --> 0.014984).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0144117\n",
      "\tspeed: 0.1519s/iter; left time: 3183.2084s\n",
      "\titers: 200, epoch: 7 | loss: 0.0131367\n",
      "\tspeed: 0.0630s/iter; left time: 1314.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 224 | Train Loss: 0.0140586 Vali Loss: 0.0148926 Test Loss: 0.0182597\n",
      "Validation loss decreased (0.014984 --> 0.014893).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0140473\n",
      "\tspeed: 0.1388s/iter; left time: 2878.0148s\n",
      "\titers: 200, epoch: 8 | loss: 0.0135981\n",
      "\tspeed: 0.0693s/iter; left time: 1429.8117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.84s\n",
      "Steps: 224 | Train Loss: 0.0139104 Vali Loss: 0.0148134 Test Loss: 0.0183719\n",
      "Validation loss decreased (0.014893 --> 0.014813).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0138677\n",
      "\tspeed: 0.1296s/iter; left time: 2658.1521s\n",
      "\titers: 200, epoch: 9 | loss: 0.0129254\n",
      "\tspeed: 0.0649s/iter; left time: 1324.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 224 | Train Loss: 0.0137508 Vali Loss: 0.0147350 Test Loss: 0.0181817\n",
      "Validation loss decreased (0.014813 --> 0.014735).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0146253\n",
      "\tspeed: 0.1554s/iter; left time: 3152.8680s\n",
      "\titers: 200, epoch: 10 | loss: 0.0145938\n",
      "\tspeed: 0.0609s/iter; left time: 1228.8994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 224 | Train Loss: 0.0136046 Vali Loss: 0.0147417 Test Loss: 0.0182025\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0133169\n",
      "\tspeed: 0.1644s/iter; left time: 3297.8493s\n",
      "\titers: 200, epoch: 11 | loss: 0.0142514\n",
      "\tspeed: 0.0533s/iter; left time: 1063.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 224 | Train Loss: 0.0134796 Vali Loss: 0.0147851 Test Loss: 0.0181727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0135381\n",
      "\tspeed: 0.1606s/iter; left time: 3186.6268s\n",
      "\titers: 200, epoch: 12 | loss: 0.0134822\n",
      "\tspeed: 0.0533s/iter; left time: 1051.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.27s\n",
      "Steps: 224 | Train Loss: 0.0133539 Vali Loss: 0.0147297 Test Loss: 0.0181911\n",
      "Validation loss decreased (0.014735 --> 0.014730).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0121429\n",
      "\tspeed: 0.1758s/iter; left time: 3446.9937s\n",
      "\titers: 200, epoch: 13 | loss: 0.0133668\n",
      "\tspeed: 0.0495s/iter; left time: 965.4897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 224 | Train Loss: 0.0132528 Vali Loss: 0.0148262 Test Loss: 0.0182404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0116928\n",
      "\tspeed: 0.1594s/iter; left time: 3091.4192s\n",
      "\titers: 200, epoch: 14 | loss: 0.0132391\n",
      "\tspeed: 0.0477s/iter; left time: 920.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.19s\n",
      "Steps: 224 | Train Loss: 0.0131951 Vali Loss: 0.0147897 Test Loss: 0.0182665\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0122485\n",
      "\tspeed: 0.1298s/iter; left time: 2487.5700s\n",
      "\titers: 200, epoch: 15 | loss: 0.0145092\n",
      "\tspeed: 0.0621s/iter; left time: 1184.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.01s\n",
      "Steps: 224 | Train Loss: 0.0130912 Vali Loss: 0.0149205 Test Loss: 0.0182158\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0130883\n",
      "\tspeed: 0.1501s/iter; left time: 2843.5236s\n",
      "\titers: 200, epoch: 16 | loss: 0.0134652\n",
      "\tspeed: 0.0628s/iter; left time: 1183.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.74s\n",
      "Steps: 224 | Train Loss: 0.0129957 Vali Loss: 0.0149039 Test Loss: 0.0183016\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0127407\n",
      "\tspeed: 0.1116s/iter; left time: 2089.2602s\n",
      "\titers: 200, epoch: 17 | loss: 0.0138984\n",
      "\tspeed: 0.0422s/iter; left time: 785.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 224 | Train Loss: 0.0129110 Vali Loss: 0.0149141 Test Loss: 0.0182459\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0134658\n",
      "\tspeed: 0.1244s/iter; left time: 2300.0877s\n",
      "\titers: 200, epoch: 18 | loss: 0.0132504\n",
      "\tspeed: 0.0451s/iter; left time: 829.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 224 | Train Loss: 0.0128538 Vali Loss: 0.0148301 Test Loss: 0.0181864\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0130002\n",
      "\tspeed: 0.0592s/iter; left time: 1082.3587s\n",
      "\titers: 200, epoch: 19 | loss: 0.0141721\n",
      "\tspeed: 0.0367s/iter; left time: 667.5381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 224 | Train Loss: 0.0127877 Vali Loss: 0.0150252 Test Loss: 0.0182931\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0118381\n",
      "\tspeed: 0.0907s/iter; left time: 1636.6244s\n",
      "\titers: 200, epoch: 20 | loss: 0.0125709\n",
      "\tspeed: 0.0567s/iter; left time: 1016.9838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.42s\n",
      "Steps: 224 | Train Loss: 0.0127468 Vali Loss: 0.0150428 Test Loss: 0.0182738\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0119616\n",
      "\tspeed: 0.0973s/iter; left time: 1734.3317s\n",
      "\titers: 200, epoch: 21 | loss: 0.0113186\n",
      "\tspeed: 0.0446s/iter; left time: 790.8293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 224 | Train Loss: 0.0126835 Vali Loss: 0.0149792 Test Loss: 0.0182552\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0137008\n",
      "\tspeed: 0.1025s/iter; left time: 1804.5472s\n",
      "\titers: 200, epoch: 22 | loss: 0.0129450\n",
      "\tspeed: 0.0455s/iter; left time: 796.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 224 | Train Loss: 0.0126265 Vali Loss: 0.0150438 Test Loss: 0.0182974\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01819109171628952, rmse:0.1348743587732315, mae:0.08794556558132172, rse:0.39622026681900024\n",
      "Intermediate time for ES and pred_len 96: 00h:06m:40.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0327703\n",
      "\tspeed: 0.0641s/iter; left time: 1422.7227s\n",
      "\titers: 200, epoch: 1 | loss: 0.0277364\n",
      "\tspeed: 0.0435s/iter; left time: 961.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0350410 Vali Loss: 0.0238507 Test Loss: 0.0296973\n",
      "Validation loss decreased (inf --> 0.023851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0199245\n",
      "\tspeed: 0.1145s/iter; left time: 2517.2741s\n",
      "\titers: 200, epoch: 2 | loss: 0.0166473\n",
      "\tspeed: 0.0448s/iter; left time: 979.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.94s\n",
      "Steps: 223 | Train Loss: 0.0197155 Vali Loss: 0.0186296 Test Loss: 0.0224006\n",
      "Validation loss decreased (0.023851 --> 0.018630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0183971\n",
      "\tspeed: 0.1097s/iter; left time: 2387.2392s\n",
      "\titers: 200, epoch: 3 | loss: 0.0177713\n",
      "\tspeed: 0.0326s/iter; left time: 706.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0172167 Vali Loss: 0.0177712 Test Loss: 0.0211671\n",
      "Validation loss decreased (0.018630 --> 0.017771).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0174361\n",
      "\tspeed: 0.0605s/iter; left time: 1302.7380s\n",
      "\titers: 200, epoch: 4 | loss: 0.0157802\n",
      "\tspeed: 0.0393s/iter; left time: 842.2135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0164956 Vali Loss: 0.0173551 Test Loss: 0.0206725\n",
      "Validation loss decreased (0.017771 --> 0.017355).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0168731\n",
      "\tspeed: 0.1029s/iter; left time: 2191.6926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0152332\n",
      "\tspeed: 0.0509s/iter; left time: 1079.3175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 223 | Train Loss: 0.0160609 Vali Loss: 0.0171954 Test Loss: 0.0203742\n",
      "Validation loss decreased (0.017355 --> 0.017195).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0153892\n",
      "\tspeed: 0.0991s/iter; left time: 2089.3214s\n",
      "\titers: 200, epoch: 6 | loss: 0.0156782\n",
      "\tspeed: 0.0510s/iter; left time: 1069.8379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.79s\n",
      "Steps: 223 | Train Loss: 0.0157492 Vali Loss: 0.0170438 Test Loss: 0.0202812\n",
      "Validation loss decreased (0.017195 --> 0.017044).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0157425\n",
      "\tspeed: 0.1027s/iter; left time: 2142.8339s\n",
      "\titers: 200, epoch: 7 | loss: 0.0153941\n",
      "\tspeed: 0.0518s/iter; left time: 1075.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.14s\n",
      "Steps: 223 | Train Loss: 0.0154863 Vali Loss: 0.0169180 Test Loss: 0.0201942\n",
      "Validation loss decreased (0.017044 --> 0.016918).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0142000\n",
      "\tspeed: 0.1121s/iter; left time: 2313.0750s\n",
      "\titers: 200, epoch: 8 | loss: 0.0152045\n",
      "\tspeed: 0.0420s/iter; left time: 861.6695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 223 | Train Loss: 0.0152446 Vali Loss: 0.0170044 Test Loss: 0.0203218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0152434\n",
      "\tspeed: 0.1320s/iter; left time: 2695.3751s\n",
      "\titers: 200, epoch: 9 | loss: 0.0145945\n",
      "\tspeed: 0.0453s/iter; left time: 920.8837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.00s\n",
      "Steps: 223 | Train Loss: 0.0150549 Vali Loss: 0.0169346 Test Loss: 0.0202678\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0148309\n",
      "\tspeed: 0.1180s/iter; left time: 2382.4281s\n",
      "\titers: 200, epoch: 10 | loss: 0.0151564\n",
      "\tspeed: 0.0451s/iter; left time: 906.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 223 | Train Loss: 0.0148671 Vali Loss: 0.0169728 Test Loss: 0.0202405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0145157\n",
      "\tspeed: 0.1124s/iter; left time: 2244.3829s\n",
      "\titers: 200, epoch: 11 | loss: 0.0137834\n",
      "\tspeed: 0.0430s/iter; left time: 854.6198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.72s\n",
      "Steps: 223 | Train Loss: 0.0147031 Vali Loss: 0.0170753 Test Loss: 0.0201891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0135146\n",
      "\tspeed: 0.0886s/iter; left time: 1750.1451s\n",
      "\titers: 200, epoch: 12 | loss: 0.0152712\n",
      "\tspeed: 0.0567s/iter; left time: 1114.4220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.58s\n",
      "Steps: 223 | Train Loss: 0.0145602 Vali Loss: 0.0170106 Test Loss: 0.0202370\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0140620\n",
      "\tspeed: 0.0938s/iter; left time: 1831.6130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0136154\n",
      "\tspeed: 0.0531s/iter; left time: 1031.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 223 | Train Loss: 0.0143957 Vali Loss: 0.0172204 Test Loss: 0.0203622\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0139850\n",
      "\tspeed: 0.0885s/iter; left time: 1707.6003s\n",
      "\titers: 200, epoch: 14 | loss: 0.0148465\n",
      "\tspeed: 0.0415s/iter; left time: 797.6370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.10s\n",
      "Steps: 223 | Train Loss: 0.0142812 Vali Loss: 0.0173684 Test Loss: 0.0203415\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0141903\n",
      "\tspeed: 0.1223s/iter; left time: 2332.8992s\n",
      "\titers: 200, epoch: 15 | loss: 0.0156419\n",
      "\tspeed: 0.0487s/iter; left time: 924.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.0141361 Vali Loss: 0.0175488 Test Loss: 0.0205400\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0146647\n",
      "\tspeed: 0.1135s/iter; left time: 2140.0844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0141779\n",
      "\tspeed: 0.0412s/iter; left time: 772.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 223 | Train Loss: 0.0140371 Vali Loss: 0.0176834 Test Loss: 0.0205687\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0134907\n",
      "\tspeed: 0.1038s/iter; left time: 1933.7283s\n",
      "\titers: 200, epoch: 17 | loss: 0.0134168\n",
      "\tspeed: 0.0383s/iter; left time: 708.9371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.83s\n",
      "Steps: 223 | Train Loss: 0.0139591 Vali Loss: 0.0176696 Test Loss: 0.0204780\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0201941579580307, rmse:0.14210614562034607, mae:0.09476298838853836, rse:0.41749510169029236\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:25.17s\n",
      "Intermediate time for ES: 00h:19m:45.99s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0163190\n",
      "\tspeed: 0.0544s/iter; left time: 1214.2560s\n",
      "\titers: 200, epoch: 1 | loss: 0.0146600\n",
      "\tspeed: 0.0416s/iter; left time: 924.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 224 | Train Loss: 0.0202520 Vali Loss: 0.0160400 Test Loss: 0.0191508\n",
      "Validation loss decreased (inf --> 0.016040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0066351\n",
      "\tspeed: 0.0951s/iter; left time: 2100.3451s\n",
      "\titers: 200, epoch: 2 | loss: 0.0067104\n",
      "\tspeed: 0.0354s/iter; left time: 778.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0081940 Vali Loss: 0.0096639 Test Loss: 0.0110337\n",
      "Validation loss decreased (0.016040 --> 0.009664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0066599\n",
      "\tspeed: 0.0950s/iter; left time: 2075.5629s\n",
      "\titers: 200, epoch: 3 | loss: 0.0061675\n",
      "\tspeed: 0.0255s/iter; left time: 553.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0066374 Vali Loss: 0.0091936 Test Loss: 0.0107437\n",
      "Validation loss decreased (0.009664 --> 0.009194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0064794\n",
      "\tspeed: 0.0533s/iter; left time: 1153.0197s\n",
      "\titers: 200, epoch: 4 | loss: 0.0069979\n",
      "\tspeed: 0.0311s/iter; left time: 668.7697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 224 | Train Loss: 0.0062819 Vali Loss: 0.0089752 Test Loss: 0.0104317\n",
      "Validation loss decreased (0.009194 --> 0.008975).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0059530\n",
      "\tspeed: 0.0819s/iter; left time: 1753.4147s\n",
      "\titers: 200, epoch: 5 | loss: 0.0070641\n",
      "\tspeed: 0.0386s/iter; left time: 822.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 224 | Train Loss: 0.0060674 Vali Loss: 0.0087049 Test Loss: 0.0102102\n",
      "Validation loss decreased (0.008975 --> 0.008705).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0063576\n",
      "\tspeed: 0.0819s/iter; left time: 1735.2260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0049777\n",
      "\tspeed: 0.0347s/iter; left time: 731.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0059176 Vali Loss: 0.0086892 Test Loss: 0.0103117\n",
      "Validation loss decreased (0.008705 --> 0.008689).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0069176\n",
      "\tspeed: 0.0806s/iter; left time: 1689.9213s\n",
      "\titers: 200, epoch: 7 | loss: 0.0063449\n",
      "\tspeed: 0.0346s/iter; left time: 721.5283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0057757 Vali Loss: 0.0085956 Test Loss: 0.0101283\n",
      "Validation loss decreased (0.008689 --> 0.008596).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0059064\n",
      "\tspeed: 0.0844s/iter; left time: 1750.4521s\n",
      "\titers: 200, epoch: 8 | loss: 0.0056319\n",
      "\tspeed: 0.0388s/iter; left time: 800.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0057092 Vali Loss: 0.0085681 Test Loss: 0.0100957\n",
      "Validation loss decreased (0.008596 --> 0.008568).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0048203\n",
      "\tspeed: 0.0826s/iter; left time: 1694.0421s\n",
      "\titers: 200, epoch: 9 | loss: 0.0059386\n",
      "\tspeed: 0.0349s/iter; left time: 713.1985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0056026 Vali Loss: 0.0084239 Test Loss: 0.0101090\n",
      "Validation loss decreased (0.008568 --> 0.008424).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0058560\n",
      "\tspeed: 0.0812s/iter; left time: 1647.4570s\n",
      "\titers: 200, epoch: 10 | loss: 0.0055602\n",
      "\tspeed: 0.0341s/iter; left time: 688.8113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0055465 Vali Loss: 0.0083629 Test Loss: 0.0101492\n",
      "Validation loss decreased (0.008424 --> 0.008363).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0054779\n",
      "\tspeed: 0.0782s/iter; left time: 1568.5426s\n",
      "\titers: 200, epoch: 11 | loss: 0.0054597\n",
      "\tspeed: 0.0343s/iter; left time: 685.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0054899 Vali Loss: 0.0084630 Test Loss: 0.0102342\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0050498\n",
      "\tspeed: 0.0802s/iter; left time: 1590.8331s\n",
      "\titers: 200, epoch: 12 | loss: 0.0049490\n",
      "\tspeed: 0.0385s/iter; left time: 759.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 224 | Train Loss: 0.0054395 Vali Loss: 0.0083584 Test Loss: 0.0100740\n",
      "Validation loss decreased (0.008363 --> 0.008358).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0054406\n",
      "\tspeed: 0.0856s/iter; left time: 1678.9852s\n",
      "\titers: 200, epoch: 13 | loss: 0.0047616\n",
      "\tspeed: 0.0369s/iter; left time: 720.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0054074 Vali Loss: 0.0084354 Test Loss: 0.0101401\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0050504\n",
      "\tspeed: 0.0825s/iter; left time: 1598.9079s\n",
      "\titers: 200, epoch: 14 | loss: 0.0054030\n",
      "\tspeed: 0.0330s/iter; left time: 636.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.0053647 Vali Loss: 0.0083279 Test Loss: 0.0101184\n",
      "Validation loss decreased (0.008358 --> 0.008328).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0053471\n",
      "\tspeed: 0.0844s/iter; left time: 1616.8035s\n",
      "\titers: 200, epoch: 15 | loss: 0.0043377\n",
      "\tspeed: 0.0384s/iter; left time: 732.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0053162 Vali Loss: 0.0083566 Test Loss: 0.0100685\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0049260\n",
      "\tspeed: 0.0829s/iter; left time: 1570.2516s\n",
      "\titers: 200, epoch: 16 | loss: 0.0048694\n",
      "\tspeed: 0.0360s/iter; left time: 679.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0052947 Vali Loss: 0.0083633 Test Loss: 0.0101274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0060960\n",
      "\tspeed: 0.0845s/iter; left time: 1580.8268s\n",
      "\titers: 200, epoch: 17 | loss: 0.0050376\n",
      "\tspeed: 0.0379s/iter; left time: 705.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 224 | Train Loss: 0.0052817 Vali Loss: 0.0083467 Test Loss: 0.0100814\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0048779\n",
      "\tspeed: 0.0791s/iter; left time: 1463.4473s\n",
      "\titers: 200, epoch: 18 | loss: 0.0047544\n",
      "\tspeed: 0.0250s/iter; left time: 460.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0052451 Vali Loss: 0.0082610 Test Loss: 0.0100459\n",
      "Validation loss decreased (0.008328 --> 0.008261).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0045703\n",
      "\tspeed: 0.0535s/iter; left time: 977.4847s\n",
      "\titers: 200, epoch: 19 | loss: 0.0048963\n",
      "\tspeed: 0.0239s/iter; left time: 433.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0052210 Vali Loss: 0.0083092 Test Loss: 0.0100771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0050457\n",
      "\tspeed: 0.0817s/iter; left time: 1473.6391s\n",
      "\titers: 200, epoch: 20 | loss: 0.0050213\n",
      "\tspeed: 0.0384s/iter; left time: 688.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0051960 Vali Loss: 0.0082870 Test Loss: 0.0100884\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0052502\n",
      "\tspeed: 0.0800s/iter; left time: 1426.4232s\n",
      "\titers: 200, epoch: 21 | loss: 0.0049596\n",
      "\tspeed: 0.0381s/iter; left time: 674.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 224 | Train Loss: 0.0051845 Vali Loss: 0.0082839 Test Loss: 0.0100520\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0050836\n",
      "\tspeed: 0.0856s/iter; left time: 1507.1230s\n",
      "\titers: 200, epoch: 22 | loss: 0.0041651\n",
      "\tspeed: 0.0347s/iter; left time: 607.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.86s\n",
      "Steps: 224 | Train Loss: 0.0051848 Vali Loss: 0.0083158 Test Loss: 0.0100871\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0051514\n",
      "\tspeed: 0.0892s/iter; left time: 1549.4638s\n",
      "\titers: 200, epoch: 23 | loss: 0.0056497\n",
      "\tspeed: 0.0379s/iter; left time: 655.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 224 | Train Loss: 0.0051422 Vali Loss: 0.0083156 Test Loss: 0.0100756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0049192\n",
      "\tspeed: 0.0876s/iter; left time: 1502.2883s\n",
      "\titers: 200, epoch: 24 | loss: 0.0047177\n",
      "\tspeed: 0.0404s/iter; left time: 689.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 224 | Train Loss: 0.0051442 Vali Loss: 0.0083113 Test Loss: 0.0101006\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0050956\n",
      "\tspeed: 0.0833s/iter; left time: 1409.0926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0054086\n",
      "\tspeed: 0.0394s/iter; left time: 663.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 224 | Train Loss: 0.0051337 Vali Loss: 0.0082635 Test Loss: 0.0101114\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0049215\n",
      "\tspeed: 0.0808s/iter; left time: 1350.0991s\n",
      "\titers: 200, epoch: 26 | loss: 0.0042607\n",
      "\tspeed: 0.0419s/iter; left time: 695.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 224 | Train Loss: 0.0051240 Vali Loss: 0.0082871 Test Loss: 0.0101289\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0053276\n",
      "\tspeed: 0.0892s/iter; left time: 1469.0890s\n",
      "\titers: 200, epoch: 27 | loss: 0.0058882\n",
      "\tspeed: 0.0383s/iter; left time: 626.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 224 | Train Loss: 0.0051055 Vali Loss: 0.0082980 Test Loss: 0.0100792\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0057416\n",
      "\tspeed: 0.0973s/iter; left time: 1581.1841s\n",
      "\titers: 200, epoch: 28 | loss: 0.0043777\n",
      "\tspeed: 0.0423s/iter; left time: 683.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 224 | Train Loss: 0.0050962 Vali Loss: 0.0083100 Test Loss: 0.0101125\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010045873932540417, rmse:0.10022910684347153, mae:0.058125320822000504, rse:0.38668110966682434\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:41.44s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0192468\n",
      "\tspeed: 0.0735s/iter; left time: 1638.7207s\n",
      "\titers: 200, epoch: 1 | loss: 0.0168081\n",
      "\tspeed: 0.0560s/iter; left time: 1243.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.35s\n",
      "Steps: 224 | Train Loss: 0.0214459 Vali Loss: 0.0186825 Test Loss: 0.0227955\n",
      "Validation loss decreased (inf --> 0.018682).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0140202\n",
      "\tspeed: 0.1517s/iter; left time: 3349.0851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0098686\n",
      "\tspeed: 0.0633s/iter; left time: 1390.2830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.33s\n",
      "Steps: 224 | Train Loss: 0.0122427 Vali Loss: 0.0151879 Test Loss: 0.0189364\n",
      "Validation loss decreased (0.018682 --> 0.015188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0105417\n",
      "\tspeed: 0.1200s/iter; left time: 2622.8552s\n",
      "\titers: 200, epoch: 3 | loss: 0.0104323\n",
      "\tspeed: 0.0569s/iter; left time: 1238.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 224 | Train Loss: 0.0107077 Vali Loss: 0.0143052 Test Loss: 0.0187372\n",
      "Validation loss decreased (0.015188 --> 0.014305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0098304\n",
      "\tspeed: 0.1205s/iter; left time: 2607.0778s\n",
      "\titers: 200, epoch: 4 | loss: 0.0106838\n",
      "\tspeed: 0.0509s/iter; left time: 1096.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 224 | Train Loss: 0.0102742 Vali Loss: 0.0140303 Test Loss: 0.0184560\n",
      "Validation loss decreased (0.014305 --> 0.014030).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0104062\n",
      "\tspeed: 0.1245s/iter; left time: 2665.6016s\n",
      "\titers: 200, epoch: 5 | loss: 0.0088304\n",
      "\tspeed: 0.0395s/iter; left time: 841.8861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.19s\n",
      "Steps: 224 | Train Loss: 0.0099902 Vali Loss: 0.0139883 Test Loss: 0.0185109\n",
      "Validation loss decreased (0.014030 --> 0.013988).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0112083\n",
      "\tspeed: 0.0879s/iter; left time: 1862.5477s\n",
      "\titers: 200, epoch: 6 | loss: 0.0089282\n",
      "\tspeed: 0.0497s/iter; left time: 1046.9285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.43s\n",
      "Steps: 224 | Train Loss: 0.0097728 Vali Loss: 0.0139388 Test Loss: 0.0186560\n",
      "Validation loss decreased (0.013988 --> 0.013939).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0108884\n",
      "\tspeed: 0.1485s/iter; left time: 3112.5526s\n",
      "\titers: 200, epoch: 7 | loss: 0.0092326\n",
      "\tspeed: 0.0659s/iter; left time: 1373.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.58s\n",
      "Steps: 224 | Train Loss: 0.0096038 Vali Loss: 0.0141724 Test Loss: 0.0186877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0100623\n",
      "\tspeed: 0.1268s/iter; left time: 2628.0025s\n",
      "\titers: 200, epoch: 8 | loss: 0.0087844\n",
      "\tspeed: 0.0665s/iter; left time: 1372.4295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.08s\n",
      "Steps: 224 | Train Loss: 0.0094615 Vali Loss: 0.0140696 Test Loss: 0.0183964\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0090472\n",
      "\tspeed: 0.1424s/iter; left time: 2921.2276s\n",
      "\titers: 200, epoch: 9 | loss: 0.0091278\n",
      "\tspeed: 0.0658s/iter; left time: 1342.5450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0093288 Vali Loss: 0.0139739 Test Loss: 0.0187636\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0093390\n",
      "\tspeed: 0.1413s/iter; left time: 2866.3405s\n",
      "\titers: 200, epoch: 10 | loss: 0.0084434\n",
      "\tspeed: 0.0487s/iter; left time: 983.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.18s\n",
      "Steps: 224 | Train Loss: 0.0091933 Vali Loss: 0.0140088 Test Loss: 0.0184228\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0094005\n",
      "\tspeed: 0.1756s/iter; left time: 3522.1266s\n",
      "\titers: 200, epoch: 11 | loss: 0.0085185\n",
      "\tspeed: 0.0541s/iter; left time: 1079.1116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.06s\n",
      "Steps: 224 | Train Loss: 0.0090669 Vali Loss: 0.0143414 Test Loss: 0.0190096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0090827\n",
      "\tspeed: 0.1775s/iter; left time: 3520.4966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0082314\n",
      "\tspeed: 0.0644s/iter; left time: 1270.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.97s\n",
      "Steps: 224 | Train Loss: 0.0089487 Vali Loss: 0.0141372 Test Loss: 0.0194590\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0093521\n",
      "\tspeed: 0.1630s/iter; left time: 3197.0117s\n",
      "\titers: 200, epoch: 13 | loss: 0.0087221\n",
      "\tspeed: 0.0472s/iter; left time: 921.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 224 | Train Loss: 0.0088474 Vali Loss: 0.0141513 Test Loss: 0.0195888\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0090534\n",
      "\tspeed: 0.1495s/iter; left time: 2899.1199s\n",
      "\titers: 200, epoch: 14 | loss: 0.0085698\n",
      "\tspeed: 0.0510s/iter; left time: 983.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.84s\n",
      "Steps: 224 | Train Loss: 0.0087251 Vali Loss: 0.0144129 Test Loss: 0.0194788\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0078854\n",
      "\tspeed: 0.1578s/iter; left time: 3024.7998s\n",
      "\titers: 200, epoch: 15 | loss: 0.0094088\n",
      "\tspeed: 0.0638s/iter; left time: 1215.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.26s\n",
      "Steps: 224 | Train Loss: 0.0086403 Vali Loss: 0.0144602 Test Loss: 0.0199399\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0091333\n",
      "\tspeed: 0.1343s/iter; left time: 2544.7052s\n",
      "\titers: 200, epoch: 16 | loss: 0.0093283\n",
      "\tspeed: 0.0640s/iter; left time: 1206.0336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 224 | Train Loss: 0.0085441 Vali Loss: 0.0146382 Test Loss: 0.0203037\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01865600049495697, rmse:0.1365869641304016, mae:0.0842278003692627, rse:0.5283547043800354\n",
      "Intermediate time for FR and pred_len 96: 00h:05m:25.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0217671\n",
      "\tspeed: 0.0760s/iter; left time: 1687.2711s\n",
      "\titers: 200, epoch: 1 | loss: 0.0174734\n",
      "\tspeed: 0.0483s/iter; left time: 1066.8366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 223 | Train Loss: 0.0221774 Vali Loss: 0.0196754 Test Loss: 0.0230590\n",
      "Validation loss decreased (inf --> 0.019675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0151478\n",
      "\tspeed: 0.1619s/iter; left time: 3558.6095s\n",
      "\titers: 200, epoch: 2 | loss: 0.0122771\n",
      "\tspeed: 0.0515s/iter; left time: 1126.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.92s\n",
      "Steps: 223 | Train Loss: 0.0134631 Vali Loss: 0.0164465 Test Loss: 0.0201141\n",
      "Validation loss decreased (0.019675 --> 0.016447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0134099\n",
      "\tspeed: 0.1432s/iter; left time: 3114.7897s\n",
      "\titers: 200, epoch: 3 | loss: 0.0106679\n",
      "\tspeed: 0.0515s/iter; left time: 1114.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 223 | Train Loss: 0.0118243 Vali Loss: 0.0154997 Test Loss: 0.0201013\n",
      "Validation loss decreased (0.016447 --> 0.015500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0110507\n",
      "\tspeed: 0.1313s/iter; left time: 2826.7481s\n",
      "\titers: 200, epoch: 4 | loss: 0.0124329\n",
      "\tspeed: 0.0604s/iter; left time: 1294.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 223 | Train Loss: 0.0113176 Vali Loss: 0.0154131 Test Loss: 0.0202327\n",
      "Validation loss decreased (0.015500 --> 0.015413).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0114767\n",
      "\tspeed: 0.1510s/iter; left time: 3217.0880s\n",
      "\titers: 200, epoch: 5 | loss: 0.0113688\n",
      "\tspeed: 0.0515s/iter; left time: 1092.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.68s\n",
      "Steps: 223 | Train Loss: 0.0110176 Vali Loss: 0.0152929 Test Loss: 0.0205191\n",
      "Validation loss decreased (0.015413 --> 0.015293).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0099502\n",
      "\tspeed: 0.1506s/iter; left time: 3174.9071s\n",
      "\titers: 200, epoch: 6 | loss: 0.0114028\n",
      "\tspeed: 0.0469s/iter; left time: 984.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.07s\n",
      "Steps: 223 | Train Loss: 0.0108221 Vali Loss: 0.0151385 Test Loss: 0.0205659\n",
      "Validation loss decreased (0.015293 --> 0.015139).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0116266\n",
      "\tspeed: 0.1398s/iter; left time: 2915.7130s\n",
      "\titers: 200, epoch: 7 | loss: 0.0108079\n",
      "\tspeed: 0.0568s/iter; left time: 1178.8676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 223 | Train Loss: 0.0106779 Vali Loss: 0.0152505 Test Loss: 0.0202467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0092505\n",
      "\tspeed: 0.1495s/iter; left time: 3085.2713s\n",
      "\titers: 200, epoch: 8 | loss: 0.0118105\n",
      "\tspeed: 0.0542s/iter; left time: 1114.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.92s\n",
      "Steps: 223 | Train Loss: 0.0105538 Vali Loss: 0.0151836 Test Loss: 0.0212055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0112282\n",
      "\tspeed: 0.0479s/iter; left time: 977.9044s\n",
      "\titers: 200, epoch: 9 | loss: 0.0087360\n",
      "\tspeed: 0.0239s/iter; left time: 485.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 223 | Train Loss: 0.0104307 Vali Loss: 0.0151765 Test Loss: 0.0207481\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0098023\n",
      "\tspeed: 0.0868s/iter; left time: 1752.7006s\n",
      "\titers: 200, epoch: 10 | loss: 0.0097993\n",
      "\tspeed: 0.0284s/iter; left time: 570.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.0103014 Vali Loss: 0.0152652 Test Loss: 0.0218221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0115547\n",
      "\tspeed: 0.0619s/iter; left time: 1235.7968s\n",
      "\titers: 200, epoch: 11 | loss: 0.0088405\n",
      "\tspeed: 0.0471s/iter; left time: 936.0981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.06s\n",
      "Steps: 223 | Train Loss: 0.0101679 Vali Loss: 0.0155769 Test Loss: 0.0223729\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0094300\n",
      "\tspeed: 0.1061s/iter; left time: 2095.8478s\n",
      "\titers: 200, epoch: 12 | loss: 0.0104352\n",
      "\tspeed: 0.0447s/iter; left time: 878.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.18s\n",
      "Steps: 223 | Train Loss: 0.0100577 Vali Loss: 0.0154377 Test Loss: 0.0223074\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0102223\n",
      "\tspeed: 0.1029s/iter; left time: 2008.5873s\n",
      "\titers: 200, epoch: 13 | loss: 0.0098616\n",
      "\tspeed: 0.0493s/iter; left time: 958.5676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.79s\n",
      "Steps: 223 | Train Loss: 0.0098909 Vali Loss: 0.0153592 Test Loss: 0.0219094\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0099257\n",
      "\tspeed: 0.0966s/iter; left time: 1864.1323s\n",
      "\titers: 200, epoch: 14 | loss: 0.0105992\n",
      "\tspeed: 0.0382s/iter; left time: 734.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.0097699 Vali Loss: 0.0154899 Test Loss: 0.0228119\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0090252\n",
      "\tspeed: 0.1321s/iter; left time: 2520.5384s\n",
      "\titers: 200, epoch: 15 | loss: 0.0107843\n",
      "\tspeed: 0.0378s/iter; left time: 717.9941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0096513 Vali Loss: 0.0157378 Test Loss: 0.0234815\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0110678\n",
      "\tspeed: 0.1335s/iter; left time: 2516.6332s\n",
      "\titers: 200, epoch: 16 | loss: 0.0095977\n",
      "\tspeed: 0.0327s/iter; left time: 612.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 223 | Train Loss: 0.0095612 Vali Loss: 0.0156056 Test Loss: 0.0231728\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020565837621688843, rmse:0.143407940864563, mae:0.0905294120311737, rse:0.5554324984550476\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:36.80s\n",
      "Intermediate time for FR: 00h:15m:43.82s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0337719\n",
      "\tspeed: 0.0748s/iter; left time: 1667.5996s\n",
      "\titers: 200, epoch: 1 | loss: 0.0257990\n",
      "\tspeed: 0.0368s/iter; left time: 816.2001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 224 | Train Loss: 0.0372998 Vali Loss: 0.0199048 Test Loss: 0.0213673\n",
      "Validation loss decreased (inf --> 0.019905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0146027\n",
      "\tspeed: 0.0806s/iter; left time: 1778.8062s\n",
      "\titers: 200, epoch: 2 | loss: 0.0115269\n",
      "\tspeed: 0.0412s/iter; left time: 906.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 224 | Train Loss: 0.0142875 Vali Loss: 0.0105368 Test Loss: 0.0117939\n",
      "Validation loss decreased (0.019905 --> 0.010537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0094670\n",
      "\tspeed: 0.0772s/iter; left time: 1686.9764s\n",
      "\titers: 200, epoch: 3 | loss: 0.0109080\n",
      "\tspeed: 0.0407s/iter; left time: 884.3749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 224 | Train Loss: 0.0111489 Vali Loss: 0.0099324 Test Loss: 0.0110654\n",
      "Validation loss decreased (0.010537 --> 0.009932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0104475\n",
      "\tspeed: 0.0932s/iter; left time: 2015.7451s\n",
      "\titers: 200, epoch: 4 | loss: 0.0092308\n",
      "\tspeed: 0.0391s/iter; left time: 840.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 224 | Train Loss: 0.0104576 Vali Loss: 0.0096689 Test Loss: 0.0106889\n",
      "Validation loss decreased (0.009932 --> 0.009669).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0101719\n",
      "\tspeed: 0.0785s/iter; left time: 1679.2972s\n",
      "\titers: 200, epoch: 5 | loss: 0.0100693\n",
      "\tspeed: 0.0479s/iter; left time: 1020.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 224 | Train Loss: 0.0100438 Vali Loss: 0.0094782 Test Loss: 0.0104772\n",
      "Validation loss decreased (0.009669 --> 0.009478).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0088217\n",
      "\tspeed: 0.0747s/iter; left time: 1581.6100s\n",
      "\titers: 200, epoch: 6 | loss: 0.0084346\n",
      "\tspeed: 0.0410s/iter; left time: 864.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 224 | Train Loss: 0.0098076 Vali Loss: 0.0093499 Test Loss: 0.0103677\n",
      "Validation loss decreased (0.009478 --> 0.009350).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0102884\n",
      "\tspeed: 0.0907s/iter; left time: 1900.0656s\n",
      "\titers: 200, epoch: 7 | loss: 0.0085527\n",
      "\tspeed: 0.0388s/iter; left time: 809.9692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 224 | Train Loss: 0.0096329 Vali Loss: 0.0092716 Test Loss: 0.0102219\n",
      "Validation loss decreased (0.009350 --> 0.009272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0093430\n",
      "\tspeed: 0.0819s/iter; left time: 1698.3422s\n",
      "\titers: 200, epoch: 8 | loss: 0.0086638\n",
      "\tspeed: 0.0461s/iter; left time: 950.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 224 | Train Loss: 0.0094812 Vali Loss: 0.0092745 Test Loss: 0.0102459\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0080648\n",
      "\tspeed: 0.0765s/iter; left time: 1569.9152s\n",
      "\titers: 200, epoch: 9 | loss: 0.0098493\n",
      "\tspeed: 0.0400s/iter; left time: 816.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0093521 Vali Loss: 0.0092073 Test Loss: 0.0102064\n",
      "Validation loss decreased (0.009272 --> 0.009207).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0094067\n",
      "\tspeed: 0.0931s/iter; left time: 1888.5345s\n",
      "\titers: 200, epoch: 10 | loss: 0.0087228\n",
      "\tspeed: 0.0409s/iter; left time: 825.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0092702 Vali Loss: 0.0091450 Test Loss: 0.0101353\n",
      "Validation loss decreased (0.009207 --> 0.009145).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0100116\n",
      "\tspeed: 0.0836s/iter; left time: 1677.2674s\n",
      "\titers: 200, epoch: 11 | loss: 0.0076847\n",
      "\tspeed: 0.0422s/iter; left time: 843.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 224 | Train Loss: 0.0092088 Vali Loss: 0.0092084 Test Loss: 0.0101961\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0085566\n",
      "\tspeed: 0.0746s/iter; left time: 1479.5862s\n",
      "\titers: 200, epoch: 12 | loss: 0.0099394\n",
      "\tspeed: 0.0425s/iter; left time: 839.3870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.07s\n",
      "Steps: 224 | Train Loss: 0.0091057 Vali Loss: 0.0090851 Test Loss: 0.0100833\n",
      "Validation loss decreased (0.009145 --> 0.009085).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0082878\n",
      "\tspeed: 0.0950s/iter; left time: 1862.9662s\n",
      "\titers: 200, epoch: 13 | loss: 0.0094125\n",
      "\tspeed: 0.0318s/iter; left time: 619.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0090499 Vali Loss: 0.0091029 Test Loss: 0.0100914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0104545\n",
      "\tspeed: 0.0967s/iter; left time: 1875.6651s\n",
      "\titers: 200, epoch: 14 | loss: 0.0091111\n",
      "\tspeed: 0.0315s/iter; left time: 607.8311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0089776 Vali Loss: 0.0090998 Test Loss: 0.0100945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0089378\n",
      "\tspeed: 0.0834s/iter; left time: 1598.7685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0082186\n",
      "\tspeed: 0.0445s/iter; left time: 849.0974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 224 | Train Loss: 0.0089379 Vali Loss: 0.0090437 Test Loss: 0.0100269\n",
      "Validation loss decreased (0.009085 --> 0.009044).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0095094\n",
      "\tspeed: 0.0925s/iter; left time: 1752.9039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0091797\n",
      "\tspeed: 0.0321s/iter; left time: 604.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0088961 Vali Loss: 0.0090957 Test Loss: 0.0100385\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0103442\n",
      "\tspeed: 0.1009s/iter; left time: 1887.7796s\n",
      "\titers: 200, epoch: 17 | loss: 0.0105167\n",
      "\tspeed: 0.0336s/iter; left time: 625.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 224 | Train Loss: 0.0088648 Vali Loss: 0.0090046 Test Loss: 0.0099948\n",
      "Validation loss decreased (0.009044 --> 0.009005).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0080705\n",
      "\tspeed: 0.0915s/iter; left time: 1692.4111s\n",
      "\titers: 200, epoch: 18 | loss: 0.0091674\n",
      "\tspeed: 0.0391s/iter; left time: 719.6138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 224 | Train Loss: 0.0088095 Vali Loss: 0.0089891 Test Loss: 0.0100064\n",
      "Validation loss decreased (0.009005 --> 0.008989).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0084524\n",
      "\tspeed: 0.0606s/iter; left time: 1107.5950s\n",
      "\titers: 200, epoch: 19 | loss: 0.0092970\n",
      "\tspeed: 0.0235s/iter; left time: 426.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0087701 Vali Loss: 0.0090202 Test Loss: 0.0099850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0084774\n",
      "\tspeed: 0.0609s/iter; left time: 1099.1839s\n",
      "\titers: 200, epoch: 20 | loss: 0.0082826\n",
      "\tspeed: 0.0336s/iter; left time: 602.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 224 | Train Loss: 0.0087392 Vali Loss: 0.0089616 Test Loss: 0.0099696\n",
      "Validation loss decreased (0.008989 --> 0.008962).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0093423\n",
      "\tspeed: 0.0820s/iter; left time: 1461.7483s\n",
      "\titers: 200, epoch: 21 | loss: 0.0084285\n",
      "\tspeed: 0.0325s/iter; left time: 576.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0087088 Vali Loss: 0.0089967 Test Loss: 0.0099756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0086534\n",
      "\tspeed: 0.0827s/iter; left time: 1455.2713s\n",
      "\titers: 200, epoch: 22 | loss: 0.0072769\n",
      "\tspeed: 0.0370s/iter; left time: 647.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0086855 Vali Loss: 0.0090156 Test Loss: 0.0100246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0082621\n",
      "\tspeed: 0.0840s/iter; left time: 1460.0945s\n",
      "\titers: 200, epoch: 23 | loss: 0.0077030\n",
      "\tspeed: 0.0341s/iter; left time: 589.3892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0086702 Vali Loss: 0.0090501 Test Loss: 0.0100442\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0095401\n",
      "\tspeed: 0.0838s/iter; left time: 1436.8825s\n",
      "\titers: 200, epoch: 24 | loss: 0.0083708\n",
      "\tspeed: 0.0341s/iter; left time: 581.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.0086297 Vali Loss: 0.0089953 Test Loss: 0.0100381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0075658\n",
      "\tspeed: 0.0879s/iter; left time: 1488.5287s\n",
      "\titers: 200, epoch: 25 | loss: 0.0090909\n",
      "\tspeed: 0.0342s/iter; left time: 574.8488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0086283 Vali Loss: 0.0089546 Test Loss: 0.0100080\n",
      "Validation loss decreased (0.008962 --> 0.008955).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0093857\n",
      "\tspeed: 0.0850s/iter; left time: 1420.1487s\n",
      "\titers: 200, epoch: 26 | loss: 0.0090390\n",
      "\tspeed: 0.0339s/iter; left time: 563.3276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0086089 Vali Loss: 0.0089541 Test Loss: 0.0099845\n",
      "Validation loss decreased (0.008955 --> 0.008954).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0090468\n",
      "\tspeed: 0.0846s/iter; left time: 1394.1454s\n",
      "\titers: 200, epoch: 27 | loss: 0.0093831\n",
      "\tspeed: 0.0336s/iter; left time: 550.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0085981 Vali Loss: 0.0089757 Test Loss: 0.0099962\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0089399\n",
      "\tspeed: 0.0845s/iter; left time: 1373.9456s\n",
      "\titers: 200, epoch: 28 | loss: 0.0079743\n",
      "\tspeed: 0.0332s/iter; left time: 537.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0085586 Vali Loss: 0.0089295 Test Loss: 0.0099634\n",
      "Validation loss decreased (0.008954 --> 0.008930).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0084361\n",
      "\tspeed: 0.0865s/iter; left time: 1386.4688s\n",
      "\titers: 200, epoch: 29 | loss: 0.0077757\n",
      "\tspeed: 0.0327s/iter; left time: 520.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0085565 Vali Loss: 0.0089361 Test Loss: 0.0100059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0087085\n",
      "\tspeed: 0.0845s/iter; left time: 1335.0557s\n",
      "\titers: 200, epoch: 30 | loss: 0.0095842\n",
      "\tspeed: 0.0333s/iter; left time: 522.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0085303 Vali Loss: 0.0089562 Test Loss: 0.0099901\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0080835\n",
      "\tspeed: 0.0831s/iter; left time: 1295.4918s\n",
      "\titers: 200, epoch: 31 | loss: 0.0094568\n",
      "\tspeed: 0.0363s/iter; left time: 561.2539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0085279 Vali Loss: 0.0089598 Test Loss: 0.0100058\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0082462\n",
      "\tspeed: 0.0837s/iter; left time: 1284.7822s\n",
      "\titers: 200, epoch: 32 | loss: 0.0096425\n",
      "\tspeed: 0.0333s/iter; left time: 508.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0085532 Vali Loss: 0.0089628 Test Loss: 0.0099933\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0080213\n",
      "\tspeed: 0.0783s/iter; left time: 1184.3373s\n",
      "\titers: 200, epoch: 33 | loss: 0.0084753\n",
      "\tspeed: 0.0342s/iter; left time: 514.7524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 224 | Train Loss: 0.0085203 Vali Loss: 0.0089441 Test Loss: 0.0099886\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0096172\n",
      "\tspeed: 0.0823s/iter; left time: 1226.4733s\n",
      "\titers: 200, epoch: 34 | loss: 0.0091738\n",
      "\tspeed: 0.0327s/iter; left time: 484.3545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0085164 Vali Loss: 0.0089387 Test Loss: 0.0099906\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0081549\n",
      "\tspeed: 0.0832s/iter; left time: 1221.5979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0083837\n",
      "\tspeed: 0.0349s/iter; left time: 509.2585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0085096 Vali Loss: 0.0089591 Test Loss: 0.0099931\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0085839\n",
      "\tspeed: 0.0843s/iter; left time: 1219.0877s\n",
      "\titers: 200, epoch: 36 | loss: 0.0085593\n",
      "\tspeed: 0.0347s/iter; left time: 498.7204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 224 | Train Loss: 0.0085119 Vali Loss: 0.0089610 Test Loss: 0.0099651\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0082230\n",
      "\tspeed: 0.0865s/iter; left time: 1231.4378s\n",
      "\titers: 200, epoch: 37 | loss: 0.0077552\n",
      "\tspeed: 0.0340s/iter; left time: 480.2208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.93s\n",
      "Steps: 224 | Train Loss: 0.0084972 Vali Loss: 0.0089316 Test Loss: 0.0099725\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0084324\n",
      "\tspeed: 0.0802s/iter; left time: 1123.7365s\n",
      "\titers: 200, epoch: 38 | loss: 0.0086269\n",
      "\tspeed: 0.0355s/iter; left time: 493.6280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0084884 Vali Loss: 0.0089388 Test Loss: 0.0099787\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009963399730622768, rmse:0.09981682896614075, mae:0.058140531182289124, rse:0.37715864181518555\n",
      "Intermediate time for IT and pred_len 24: 00h:07m:49.35s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0371732\n",
      "\tspeed: 0.0425s/iter; left time: 948.1996s\n",
      "\titers: 200, epoch: 1 | loss: 0.0287763\n",
      "\tspeed: 0.0208s/iter; left time: 462.7846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0390735 Vali Loss: 0.0230477 Test Loss: 0.0248180\n",
      "Validation loss decreased (inf --> 0.023048).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0210800\n",
      "\tspeed: 0.0513s/iter; left time: 1132.7785s\n",
      "\titers: 200, epoch: 2 | loss: 0.0182079\n",
      "\tspeed: 0.0208s/iter; left time: 456.3942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0211989 Vali Loss: 0.0170225 Test Loss: 0.0186545\n",
      "Validation loss decreased (0.023048 --> 0.017022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0189358\n",
      "\tspeed: 0.0490s/iter; left time: 1070.6179s\n",
      "\titers: 200, epoch: 3 | loss: 0.0172008\n",
      "\tspeed: 0.0224s/iter; left time: 486.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0180473 Vali Loss: 0.0164983 Test Loss: 0.0179922\n",
      "Validation loss decreased (0.017022 --> 0.016498).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0170671\n",
      "\tspeed: 0.0470s/iter; left time: 1016.7012s\n",
      "\titers: 200, epoch: 4 | loss: 0.0164635\n",
      "\tspeed: 0.0209s/iter; left time: 450.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0173269 Vali Loss: 0.0162273 Test Loss: 0.0178494\n",
      "Validation loss decreased (0.016498 --> 0.016227).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0185882\n",
      "\tspeed: 0.0486s/iter; left time: 1041.1875s\n",
      "\titers: 200, epoch: 5 | loss: 0.0157344\n",
      "\tspeed: 0.0214s/iter; left time: 456.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0169245 Vali Loss: 0.0159996 Test Loss: 0.0178206\n",
      "Validation loss decreased (0.016227 --> 0.016000).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0168839\n",
      "\tspeed: 0.0491s/iter; left time: 1039.8157s\n",
      "\titers: 200, epoch: 6 | loss: 0.0167227\n",
      "\tspeed: 0.0238s/iter; left time: 501.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0166422 Vali Loss: 0.0158670 Test Loss: 0.0176874\n",
      "Validation loss decreased (0.016000 --> 0.015867).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0173547\n",
      "\tspeed: 0.0503s/iter; left time: 1054.3527s\n",
      "\titers: 200, epoch: 7 | loss: 0.0157185\n",
      "\tspeed: 0.0225s/iter; left time: 470.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0164024 Vali Loss: 0.0159056 Test Loss: 0.0178127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0160923\n",
      "\tspeed: 0.0510s/iter; left time: 1057.1580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0145047\n",
      "\tspeed: 0.0210s/iter; left time: 432.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0161933 Vali Loss: 0.0157249 Test Loss: 0.0177374\n",
      "Validation loss decreased (0.015867 --> 0.015725).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0155673\n",
      "\tspeed: 0.0488s/iter; left time: 1000.0195s\n",
      "\titers: 200, epoch: 9 | loss: 0.0142138\n",
      "\tspeed: 0.0216s/iter; left time: 440.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0159982 Vali Loss: 0.0157612 Test Loss: 0.0176047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0145641\n",
      "\tspeed: 0.0471s/iter; left time: 954.8946s\n",
      "\titers: 200, epoch: 10 | loss: 0.0170093\n",
      "\tspeed: 0.0212s/iter; left time: 428.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0158333 Vali Loss: 0.0156579 Test Loss: 0.0177839\n",
      "Validation loss decreased (0.015725 --> 0.015658).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0164054\n",
      "\tspeed: 0.0537s/iter; left time: 1078.2749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0158935\n",
      "\tspeed: 0.0214s/iter; left time: 426.6837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0157068 Vali Loss: 0.0157430 Test Loss: 0.0176609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0162831\n",
      "\tspeed: 0.0501s/iter; left time: 993.9899s\n",
      "\titers: 200, epoch: 12 | loss: 0.0157943\n",
      "\tspeed: 0.0214s/iter; left time: 421.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0155495 Vali Loss: 0.0157374 Test Loss: 0.0176193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0154624\n",
      "\tspeed: 0.0490s/iter; left time: 960.3477s\n",
      "\titers: 200, epoch: 13 | loss: 0.0158125\n",
      "\tspeed: 0.0212s/iter; left time: 414.2353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0154042 Vali Loss: 0.0157997 Test Loss: 0.0179022\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0144169\n",
      "\tspeed: 0.0494s/iter; left time: 958.7619s\n",
      "\titers: 200, epoch: 14 | loss: 0.0150392\n",
      "\tspeed: 0.0209s/iter; left time: 403.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0152836 Vali Loss: 0.0156491 Test Loss: 0.0178490\n",
      "Validation loss decreased (0.015658 --> 0.015649).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0151338\n",
      "\tspeed: 0.0492s/iter; left time: 942.6435s\n",
      "\titers: 200, epoch: 15 | loss: 0.0155342\n",
      "\tspeed: 0.0226s/iter; left time: 430.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0152057 Vali Loss: 0.0156826 Test Loss: 0.0177711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0172772\n",
      "\tspeed: 0.0478s/iter; left time: 906.2072s\n",
      "\titers: 200, epoch: 16 | loss: 0.0152490\n",
      "\tspeed: 0.0219s/iter; left time: 413.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0150662 Vali Loss: 0.0157058 Test Loss: 0.0177606\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0153979\n",
      "\tspeed: 0.0515s/iter; left time: 964.5141s\n",
      "\titers: 200, epoch: 17 | loss: 0.0151868\n",
      "\tspeed: 0.0223s/iter; left time: 415.8438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0149973 Vali Loss: 0.0157220 Test Loss: 0.0178153\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0147232\n",
      "\tspeed: 0.0501s/iter; left time: 926.7080s\n",
      "\titers: 200, epoch: 18 | loss: 0.0165930\n",
      "\tspeed: 0.0214s/iter; left time: 393.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0148880 Vali Loss: 0.0157485 Test Loss: 0.0178049\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0133762\n",
      "\tspeed: 0.0474s/iter; left time: 866.3181s\n",
      "\titers: 200, epoch: 19 | loss: 0.0149687\n",
      "\tspeed: 0.0217s/iter; left time: 394.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0148254 Vali Loss: 0.0157007 Test Loss: 0.0178293\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0147325\n",
      "\tspeed: 0.0480s/iter; left time: 866.2290s\n",
      "\titers: 200, epoch: 20 | loss: 0.0156527\n",
      "\tspeed: 0.0211s/iter; left time: 379.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0147292 Vali Loss: 0.0156710 Test Loss: 0.0177907\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0145474\n",
      "\tspeed: 0.0470s/iter; left time: 837.6363s\n",
      "\titers: 200, epoch: 21 | loss: 0.0122341\n",
      "\tspeed: 0.0216s/iter; left time: 383.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0146501 Vali Loss: 0.0157059 Test Loss: 0.0178243\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0147194\n",
      "\tspeed: 0.0479s/iter; left time: 843.2110s\n",
      "\titers: 200, epoch: 22 | loss: 0.0152239\n",
      "\tspeed: 0.0237s/iter; left time: 414.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0146113 Vali Loss: 0.0157876 Test Loss: 0.0178172\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0141952\n",
      "\tspeed: 0.0502s/iter; left time: 871.9619s\n",
      "\titers: 200, epoch: 23 | loss: 0.0136017\n",
      "\tspeed: 0.0213s/iter; left time: 367.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0145538 Vali Loss: 0.0157679 Test Loss: 0.0178681\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0145188\n",
      "\tspeed: 0.0495s/iter; left time: 848.8626s\n",
      "\titers: 200, epoch: 24 | loss: 0.0136532\n",
      "\tspeed: 0.0211s/iter; left time: 359.7698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0144843 Vali Loss: 0.0157702 Test Loss: 0.0179332\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01784895919263363, rmse:0.13359999656677246, mae:0.08161764591932297, rse:0.5051559805870056\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:59.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0369255\n",
      "\tspeed: 0.0507s/iter; left time: 1126.5050s\n",
      "\titers: 200, epoch: 1 | loss: 0.0297755\n",
      "\tspeed: 0.0213s/iter; left time: 470.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0397611 Vali Loss: 0.0237945 Test Loss: 0.0251291\n",
      "Validation loss decreased (inf --> 0.023794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0209399\n",
      "\tspeed: 0.0473s/iter; left time: 1038.6170s\n",
      "\titers: 200, epoch: 2 | loss: 0.0188481\n",
      "\tspeed: 0.0235s/iter; left time: 514.5731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0225348 Vali Loss: 0.0185233 Test Loss: 0.0195790\n",
      "Validation loss decreased (0.023794 --> 0.018523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0206072\n",
      "\tspeed: 0.0531s/iter; left time: 1156.0818s\n",
      "\titers: 200, epoch: 3 | loss: 0.0186305\n",
      "\tspeed: 0.0253s/iter; left time: 548.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0193464 Vali Loss: 0.0180038 Test Loss: 0.0191504\n",
      "Validation loss decreased (0.018523 --> 0.018004).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0191462\n",
      "\tspeed: 0.0498s/iter; left time: 1071.2509s\n",
      "\titers: 200, epoch: 4 | loss: 0.0204389\n",
      "\tspeed: 0.0212s/iter; left time: 453.2919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0186470 Vali Loss: 0.0178889 Test Loss: 0.0193618\n",
      "Validation loss decreased (0.018004 --> 0.017889).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0174371\n",
      "\tspeed: 0.0489s/iter; left time: 1042.8023s\n",
      "\titers: 200, epoch: 5 | loss: 0.0175992\n",
      "\tspeed: 0.0217s/iter; left time: 459.9728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0182212 Vali Loss: 0.0175770 Test Loss: 0.0193352\n",
      "Validation loss decreased (0.017889 --> 0.017577).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0169263\n",
      "\tspeed: 0.0493s/iter; left time: 1040.2883s\n",
      "\titers: 200, epoch: 6 | loss: 0.0189777\n",
      "\tspeed: 0.0212s/iter; left time: 445.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0178814 Vali Loss: 0.0174025 Test Loss: 0.0192189\n",
      "Validation loss decreased (0.017577 --> 0.017402).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0178873\n",
      "\tspeed: 0.0535s/iter; left time: 1116.6465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0182649\n",
      "\tspeed: 0.0214s/iter; left time: 444.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0176283 Vali Loss: 0.0174294 Test Loss: 0.0193924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0176257\n",
      "\tspeed: 0.0517s/iter; left time: 1067.7889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0169084\n",
      "\tspeed: 0.0236s/iter; left time: 484.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 223 | Train Loss: 0.0173846 Vali Loss: 0.0173592 Test Loss: 0.0194279\n",
      "Validation loss decreased (0.017402 --> 0.017359).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0171479\n",
      "\tspeed: 0.0499s/iter; left time: 1018.8378s\n",
      "\titers: 200, epoch: 9 | loss: 0.0163122\n",
      "\tspeed: 0.0213s/iter; left time: 433.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0171772 Vali Loss: 0.0172226 Test Loss: 0.0193564\n",
      "Validation loss decreased (0.017359 --> 0.017223).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0160433\n",
      "\tspeed: 0.0534s/iter; left time: 1078.1602s\n",
      "\titers: 200, epoch: 10 | loss: 0.0175120\n",
      "\tspeed: 0.0233s/iter; left time: 469.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0169679 Vali Loss: 0.0173008 Test Loss: 0.0195370\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0176645\n",
      "\tspeed: 0.0538s/iter; left time: 1074.1828s\n",
      "\titers: 200, epoch: 11 | loss: 0.0154894\n",
      "\tspeed: 0.0289s/iter; left time: 573.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0167844 Vali Loss: 0.0172710 Test Loss: 0.0197374\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0156374\n",
      "\tspeed: 0.0547s/iter; left time: 1079.7601s\n",
      "\titers: 200, epoch: 12 | loss: 0.0162350\n",
      "\tspeed: 0.0235s/iter; left time: 462.2320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 223 | Train Loss: 0.0165962 Vali Loss: 0.0172021 Test Loss: 0.0195468\n",
      "Validation loss decreased (0.017223 --> 0.017202).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0160061\n",
      "\tspeed: 0.0610s/iter; left time: 1190.6081s\n",
      "\titers: 200, epoch: 13 | loss: 0.0165230\n",
      "\tspeed: 0.0243s/iter; left time: 471.3065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0164414 Vali Loss: 0.0171890 Test Loss: 0.0197550\n",
      "Validation loss decreased (0.017202 --> 0.017189).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0159156\n",
      "\tspeed: 0.0548s/iter; left time: 1057.5153s\n",
      "\titers: 200, epoch: 14 | loss: 0.0163138\n",
      "\tspeed: 0.0287s/iter; left time: 550.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0162846 Vali Loss: 0.0172921 Test Loss: 0.0197784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0160599\n",
      "\tspeed: 0.0602s/iter; left time: 1148.8767s\n",
      "\titers: 200, epoch: 15 | loss: 0.0180776\n",
      "\tspeed: 0.0250s/iter; left time: 474.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0161662 Vali Loss: 0.0172911 Test Loss: 0.0196204\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0166016\n",
      "\tspeed: 0.0722s/iter; left time: 1361.6496s\n",
      "\titers: 200, epoch: 16 | loss: 0.0168872\n",
      "\tspeed: 0.0244s/iter; left time: 458.4343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 223 | Train Loss: 0.0160063 Vali Loss: 0.0173133 Test Loss: 0.0197688\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0163692\n",
      "\tspeed: 0.0502s/iter; left time: 935.2129s\n",
      "\titers: 200, epoch: 17 | loss: 0.0158019\n",
      "\tspeed: 0.0263s/iter; left time: 488.0951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0159090 Vali Loss: 0.0172856 Test Loss: 0.0198253\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0144021\n",
      "\tspeed: 0.0576s/iter; left time: 1060.1217s\n",
      "\titers: 200, epoch: 18 | loss: 0.0162366\n",
      "\tspeed: 0.0235s/iter; left time: 429.8685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0158164 Vali Loss: 0.0173659 Test Loss: 0.0198755\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0145723\n",
      "\tspeed: 0.0532s/iter; left time: 968.1630s\n",
      "\titers: 200, epoch: 19 | loss: 0.0150361\n",
      "\tspeed: 0.0277s/iter; left time: 501.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0157038 Vali Loss: 0.0173463 Test Loss: 0.0198465\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0164767\n",
      "\tspeed: 0.0564s/iter; left time: 1013.8309s\n",
      "\titers: 200, epoch: 20 | loss: 0.0145590\n",
      "\tspeed: 0.0258s/iter; left time: 460.2691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0156102 Vali Loss: 0.0173839 Test Loss: 0.0200144\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0158374\n",
      "\tspeed: 0.0604s/iter; left time: 1072.4078s\n",
      "\titers: 200, epoch: 21 | loss: 0.0149751\n",
      "\tspeed: 0.0270s/iter; left time: 475.7056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0155649 Vali Loss: 0.0173720 Test Loss: 0.0198600\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0163231\n",
      "\tspeed: 0.0707s/iter; left time: 1239.2860s\n",
      "\titers: 200, epoch: 22 | loss: 0.0162265\n",
      "\tspeed: 0.0241s/iter; left time: 420.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 223 | Train Loss: 0.0154726 Vali Loss: 0.0174812 Test Loss: 0.0200674\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0139256\n",
      "\tspeed: 0.0547s/iter; left time: 945.5040s\n",
      "\titers: 200, epoch: 23 | loss: 0.0155654\n",
      "\tspeed: 0.0296s/iter; left time: 508.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 223 | Train Loss: 0.0154203 Vali Loss: 0.0175127 Test Loss: 0.0199061\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019755041226744652, rmse:0.14055262506008148, mae:0.08749067783355713, rse:0.5319384932518005\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:14.98s\n",
      "Intermediate time for IT: 00h:14m:03.71s\n",
      "Total time: 01h:39m:19.06s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>0.0816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0208  0.1443  0.0911\n",
       "        96            0.0357  0.1889  0.1291\n",
       "        168           0.0383  0.1958  0.1366\n",
       "GB      24            0.0251  0.1584  0.1036\n",
       "        96            0.0423  0.2057  0.1437\n",
       "        168           0.0454  0.2132  0.1511\n",
       "ES      24            0.0097  0.0987  0.0607\n",
       "        96            0.0182  0.1349  0.0879\n",
       "        168           0.0202  0.1421  0.0948\n",
       "FR      24            0.0100  0.1002  0.0581\n",
       "        96            0.0187  0.1366  0.0842\n",
       "        168           0.0206  0.1434  0.0905\n",
       "IT      24            0.0100  0.0998  0.0581\n",
       "        96            0.0178  0.1336  0.0816\n",
       "        168           0.0198  0.1406  0.0875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False, itr=1)\n",
    "patchtst_df.drop(columns=['Iteration'], inplace=True)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_512.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1321916\n",
      "\tspeed: 0.0728s/iter; left time: 1615.8326s\n",
      "\titers: 200, epoch: 1 | loss: 0.1232382\n",
      "\tspeed: 0.0406s/iter; left time: 897.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 223 | Train Loss: 0.1358311 Vali Loss: 0.1260650 Test Loss: 0.1311714\n",
      "Validation loss decreased (inf --> 0.126065).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869880\n",
      "\tspeed: 0.0734s/iter; left time: 1612.4742s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813422\n",
      "\tspeed: 0.0409s/iter; left time: 895.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0881644 Vali Loss: 0.0929616 Test Loss: 0.0951003\n",
      "Validation loss decreased (0.126065 --> 0.092962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0751677\n",
      "\tspeed: 0.0736s/iter; left time: 1600.3763s\n",
      "\titers: 200, epoch: 3 | loss: 0.0759952\n",
      "\tspeed: 0.0407s/iter; left time: 881.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.28s\n",
      "Steps: 223 | Train Loss: 0.0788886 Vali Loss: 0.0895641 Test Loss: 0.0921896\n",
      "Validation loss decreased (0.092962 --> 0.089564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0797120\n",
      "\tspeed: 0.0735s/iter; left time: 1581.5937s\n",
      "\titers: 200, epoch: 4 | loss: 0.0827803\n",
      "\tspeed: 0.0406s/iter; left time: 870.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.24s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0885940 Test Loss: 0.0909947\n",
      "Validation loss decreased (0.089564 --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754906\n",
      "\tspeed: 0.0734s/iter; left time: 1563.9432s\n",
      "\titers: 200, epoch: 5 | loss: 0.0719414\n",
      "\tspeed: 0.0407s/iter; left time: 862.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.22s\n",
      "Steps: 223 | Train Loss: 0.0754300 Vali Loss: 0.0888515 Test Loss: 0.0910340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0806468\n",
      "\tspeed: 0.0728s/iter; left time: 1534.8053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0765860\n",
      "\tspeed: 0.0419s/iter; left time: 879.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0744171 Vali Loss: 0.0882697 Test Loss: 0.0900209\n",
      "Validation loss decreased (0.088594 --> 0.088270).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731639\n",
      "\tspeed: 0.0734s/iter; left time: 1530.8374s\n",
      "\titers: 200, epoch: 7 | loss: 0.0712213\n",
      "\tspeed: 0.0409s/iter; left time: 848.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0736002 Vali Loss: 0.0882780 Test Loss: 0.0900862\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0723158\n",
      "\tspeed: 0.0753s/iter; left time: 1553.8959s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739186\n",
      "\tspeed: 0.0408s/iter; left time: 838.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0730063 Vali Loss: 0.0872233 Test Loss: 0.0892780\n",
      "Validation loss decreased (0.088270 --> 0.087223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0720197\n",
      "\tspeed: 0.0736s/iter; left time: 1502.4429s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719693\n",
      "\tspeed: 0.0413s/iter; left time: 839.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0725142 Vali Loss: 0.0873214 Test Loss: 0.0893505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0731357\n",
      "\tspeed: 0.0740s/iter; left time: 1493.4336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0688657\n",
      "\tspeed: 0.0408s/iter; left time: 819.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0721618 Vali Loss: 0.0870030 Test Loss: 0.0891919\n",
      "Validation loss decreased (0.087223 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0748033\n",
      "\tspeed: 0.0759s/iter; left time: 1515.2200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0748860\n",
      "\tspeed: 0.0417s/iter; left time: 829.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0719345 Vali Loss: 0.0867141 Test Loss: 0.0886792\n",
      "Validation loss decreased (0.087003 --> 0.086714).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0690829\n",
      "\tspeed: 0.0745s/iter; left time: 1470.9406s\n",
      "\titers: 200, epoch: 12 | loss: 0.0754002\n",
      "\tspeed: 0.0429s/iter; left time: 842.0450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0716603 Vali Loss: 0.0863255 Test Loss: 0.0886338\n",
      "Validation loss decreased (0.086714 --> 0.086325).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0659539\n",
      "\tspeed: 0.0744s/iter; left time: 1452.1265s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692490\n",
      "\tspeed: 0.0412s/iter; left time: 799.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713583 Vali Loss: 0.0861463 Test Loss: 0.0882640\n",
      "Validation loss decreased (0.086325 --> 0.086146).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732110\n",
      "\tspeed: 0.0779s/iter; left time: 1503.5926s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664269\n",
      "\tspeed: 0.0411s/iter; left time: 788.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.31s\n",
      "Steps: 223 | Train Loss: 0.0712298 Vali Loss: 0.0862440 Test Loss: 0.0883915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0712718\n",
      "\tspeed: 0.0763s/iter; left time: 1455.3356s\n",
      "\titers: 200, epoch: 15 | loss: 0.0668620\n",
      "\tspeed: 0.0410s/iter; left time: 777.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0710672 Vali Loss: 0.0864471 Test Loss: 0.0887082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0729668\n",
      "\tspeed: 0.0740s/iter; left time: 1395.5402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0765959\n",
      "\tspeed: 0.0422s/iter; left time: 792.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0708319 Vali Loss: 0.0861513 Test Loss: 0.0883979\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0704609\n",
      "\tspeed: 0.0735s/iter; left time: 1369.5178s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766587\n",
      "\tspeed: 0.0433s/iter; left time: 802.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707372 Vali Loss: 0.0861647 Test Loss: 0.0883205\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0681143\n",
      "\tspeed: 0.0750s/iter; left time: 1381.5339s\n",
      "\titers: 200, epoch: 18 | loss: 0.0640077\n",
      "\tspeed: 0.0409s/iter; left time: 749.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0706291 Vali Loss: 0.0860309 Test Loss: 0.0882354\n",
      "Validation loss decreased (0.086146 --> 0.086031).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720396\n",
      "\tspeed: 0.0783s/iter; left time: 1423.7136s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769060\n",
      "\tspeed: 0.0409s/iter; left time: 740.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0705093 Vali Loss: 0.0859334 Test Loss: 0.0882176\n",
      "Validation loss decreased (0.086031 --> 0.085933).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0715498\n",
      "\tspeed: 0.0772s/iter; left time: 1386.4974s\n",
      "\titers: 200, epoch: 20 | loss: 0.0696223\n",
      "\tspeed: 0.0410s/iter; left time: 732.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0704253 Vali Loss: 0.0860697 Test Loss: 0.0881779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0699663\n",
      "\tspeed: 0.0728s/iter; left time: 1291.4193s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732786\n",
      "\tspeed: 0.0431s/iter; left time: 759.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0703514 Vali Loss: 0.0858988 Test Loss: 0.0881333\n",
      "Validation loss decreased (0.085933 --> 0.085899).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0708477\n",
      "\tspeed: 0.0742s/iter; left time: 1300.1863s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705403\n",
      "\tspeed: 0.0415s/iter; left time: 722.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0702229 Vali Loss: 0.0858154 Test Loss: 0.0882537\n",
      "Validation loss decreased (0.085899 --> 0.085815).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0727449\n",
      "\tspeed: 0.0758s/iter; left time: 1310.7424s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709735\n",
      "\tspeed: 0.0411s/iter; left time: 705.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0702576 Vali Loss: 0.0857304 Test Loss: 0.0880756\n",
      "Validation loss decreased (0.085815 --> 0.085730).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0739099\n",
      "\tspeed: 0.0758s/iter; left time: 1294.2116s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680970\n",
      "\tspeed: 0.0412s/iter; left time: 699.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0701341 Vali Loss: 0.0857846 Test Loss: 0.0882640\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0694140\n",
      "\tspeed: 0.0753s/iter; left time: 1268.9373s\n",
      "\titers: 200, epoch: 25 | loss: 0.0655354\n",
      "\tspeed: 0.0419s/iter; left time: 702.3440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0700403 Vali Loss: 0.0856874 Test Loss: 0.0880371\n",
      "Validation loss decreased (0.085730 --> 0.085687).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680513\n",
      "\tspeed: 0.0729s/iter; left time: 1211.8735s\n",
      "\titers: 200, epoch: 26 | loss: 0.0614008\n",
      "\tspeed: 0.0422s/iter; left time: 697.8320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0699876 Vali Loss: 0.0857602 Test Loss: 0.0880605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0681010\n",
      "\tspeed: 0.0737s/iter; left time: 1209.0005s\n",
      "\titers: 200, epoch: 27 | loss: 0.0719286\n",
      "\tspeed: 0.0409s/iter; left time: 666.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699794 Vali Loss: 0.0856203 Test Loss: 0.0880215\n",
      "Validation loss decreased (0.085687 --> 0.085620).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0715455\n",
      "\tspeed: 0.0777s/iter; left time: 1257.7111s\n",
      "\titers: 200, epoch: 28 | loss: 0.0702468\n",
      "\tspeed: 0.0411s/iter; left time: 661.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0698950 Vali Loss: 0.0855330 Test Loss: 0.0880139\n",
      "Validation loss decreased (0.085620 --> 0.085533).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0714828\n",
      "\tspeed: 0.0763s/iter; left time: 1217.9411s\n",
      "\titers: 200, epoch: 29 | loss: 0.0706265\n",
      "\tspeed: 0.0408s/iter; left time: 647.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0698917 Vali Loss: 0.0855195 Test Loss: 0.0880248\n",
      "Validation loss decreased (0.085533 --> 0.085519).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0714619\n",
      "\tspeed: 0.0742s/iter; left time: 1168.2092s\n",
      "\titers: 200, epoch: 30 | loss: 0.0664505\n",
      "\tspeed: 0.0418s/iter; left time: 654.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0698095 Vali Loss: 0.0856531 Test Loss: 0.0880330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0732058\n",
      "\tspeed: 0.0729s/iter; left time: 1130.9088s\n",
      "\titers: 200, epoch: 31 | loss: 0.0680768\n",
      "\tspeed: 0.0425s/iter; left time: 655.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0698472 Vali Loss: 0.0855296 Test Loss: 0.0879514\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0710819\n",
      "\tspeed: 0.0745s/iter; left time: 1138.8016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0653720\n",
      "\tspeed: 0.0412s/iter; left time: 625.7304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0697666 Vali Loss: 0.0855339 Test Loss: 0.0879451\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689314\n",
      "\tspeed: 0.0769s/iter; left time: 1158.4537s\n",
      "\titers: 200, epoch: 33 | loss: 0.0689489\n",
      "\tspeed: 0.0411s/iter; left time: 614.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0697218 Vali Loss: 0.0855810 Test Loss: 0.0879584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0722149\n",
      "\tspeed: 0.0771s/iter; left time: 1144.5327s\n",
      "\titers: 200, epoch: 34 | loss: 0.0753755\n",
      "\tspeed: 0.0413s/iter; left time: 609.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 223 | Train Loss: 0.0697024 Vali Loss: 0.0854558 Test Loss: 0.0879442\n",
      "Validation loss decreased (0.085519 --> 0.085456).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0695830\n",
      "\tspeed: 0.0736s/iter; left time: 1075.5888s\n",
      "\titers: 200, epoch: 35 | loss: 0.0714961\n",
      "\tspeed: 0.0434s/iter; left time: 630.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0696798 Vali Loss: 0.0855717 Test Loss: 0.0879177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0646781\n",
      "\tspeed: 0.0730s/iter; left time: 1051.0720s\n",
      "\titers: 200, epoch: 36 | loss: 0.0619496\n",
      "\tspeed: 0.0418s/iter; left time: 597.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0697064 Vali Loss: 0.0855166 Test Loss: 0.0879396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0669930\n",
      "\tspeed: 0.0744s/iter; left time: 1054.2108s\n",
      "\titers: 200, epoch: 37 | loss: 0.0625971\n",
      "\tspeed: 0.0409s/iter; left time: 575.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.27s\n",
      "Steps: 223 | Train Loss: 0.0696672 Vali Loss: 0.0855014 Test Loss: 0.0879528\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0678924\n",
      "\tspeed: 0.0749s/iter; left time: 1045.0660s\n",
      "\titers: 200, epoch: 38 | loss: 0.0688178\n",
      "\tspeed: 0.0409s/iter; left time: 566.8978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696622 Vali Loss: 0.0855257 Test Loss: 0.0879750\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0701673\n",
      "\tspeed: 0.0754s/iter; left time: 1034.4748s\n",
      "\titers: 200, epoch: 39 | loss: 0.0690970\n",
      "\tspeed: 0.0415s/iter; left time: 565.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0696282 Vali Loss: 0.0855480 Test Loss: 0.0879980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0651396\n",
      "\tspeed: 0.0732s/iter; left time: 988.9090s\n",
      "\titers: 200, epoch: 40 | loss: 0.0684225\n",
      "\tspeed: 0.0432s/iter; left time: 579.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0696272 Vali Loss: 0.0855301 Test Loss: 0.0879082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0700838\n",
      "\tspeed: 0.0731s/iter; left time: 971.4658s\n",
      "\titers: 200, epoch: 41 | loss: 0.0650603\n",
      "\tspeed: 0.0412s/iter; left time: 543.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0696333 Vali Loss: 0.0853576 Test Loss: 0.0879209\n",
      "Validation loss decreased (0.085456 --> 0.085358).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0721609\n",
      "\tspeed: 0.0791s/iter; left time: 1033.0047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0683571\n",
      "\tspeed: 0.0411s/iter; left time: 532.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0696497 Vali Loss: 0.0856114 Test Loss: 0.0879269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0659273\n",
      "\tspeed: 0.0750s/iter; left time: 962.9138s\n",
      "\titers: 200, epoch: 43 | loss: 0.0703276\n",
      "\tspeed: 0.0411s/iter; left time: 523.3529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0696177 Vali Loss: 0.0855228 Test Loss: 0.0879306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0707573\n",
      "\tspeed: 0.0740s/iter; left time: 933.1694s\n",
      "\titers: 200, epoch: 44 | loss: 0.0708191\n",
      "\tspeed: 0.0429s/iter; left time: 536.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0695830 Vali Loss: 0.0854188 Test Loss: 0.0879598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0725420\n",
      "\tspeed: 0.0733s/iter; left time: 908.7304s\n",
      "\titers: 200, epoch: 45 | loss: 0.0703637\n",
      "\tspeed: 0.0423s/iter; left time: 519.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696023 Vali Loss: 0.0854171 Test Loss: 0.0879375\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0657321\n",
      "\tspeed: 0.0741s/iter; left time: 901.0396s\n",
      "\titers: 200, epoch: 46 | loss: 0.0639107\n",
      "\tspeed: 0.0410s/iter; left time: 495.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0695614 Vali Loss: 0.0854853 Test Loss: 0.0879773\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0717126\n",
      "\tspeed: 0.0775s/iter; left time: 926.1534s\n",
      "\titers: 200, epoch: 47 | loss: 0.0683041\n",
      "\tspeed: 0.0410s/iter; left time: 485.7300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0695458 Vali Loss: 0.0855225 Test Loss: 0.0879506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0647682\n",
      "\tspeed: 0.0748s/iter; left time: 876.1091s\n",
      "\titers: 200, epoch: 48 | loss: 0.0752877\n",
      "\tspeed: 0.0412s/iter; left time: 479.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0695764 Vali Loss: 0.0855578 Test Loss: 0.0879192\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0669895\n",
      "\tspeed: 0.0739s/iter; left time: 849.1132s\n",
      "\titers: 200, epoch: 49 | loss: 0.0671645\n",
      "\tspeed: 0.0441s/iter; left time: 502.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 223 | Train Loss: 0.0695500 Vali Loss: 0.0854582 Test Loss: 0.0879122\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0681623\n",
      "\tspeed: 0.0729s/iter; left time: 822.0261s\n",
      "\titers: 200, epoch: 50 | loss: 0.0670224\n",
      "\tspeed: 0.0411s/iter; left time: 459.1101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0695453 Vali Loss: 0.0854244 Test Loss: 0.0879608\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0734773\n",
      "\tspeed: 0.0750s/iter; left time: 828.5580s\n",
      "\titers: 200, epoch: 51 | loss: 0.0709416\n",
      "\tspeed: 0.0409s/iter; left time: 447.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 223 | Train Loss: 0.0694864 Vali Loss: 0.0854223 Test Loss: 0.0879430\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02090967260301113, rmse:0.14460177719593048, mae:0.08792086690664291, rse:0.5103196501731873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1313960\n",
      "\tspeed: 0.0426s/iter; left time: 946.2350s\n",
      "\titers: 200, epoch: 1 | loss: 0.1188500\n",
      "\tspeed: 0.0409s/iter; left time: 903.4980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.1354943 Vali Loss: 0.1248697 Test Loss: 0.1301842\n",
      "Validation loss decreased (inf --> 0.124870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870410\n",
      "\tspeed: 0.0759s/iter; left time: 1669.0927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790940\n",
      "\tspeed: 0.0408s/iter; left time: 893.6806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0881939 Vali Loss: 0.0920127 Test Loss: 0.0943350\n",
      "Validation loss decreased (0.124870 --> 0.092013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0822242\n",
      "\tspeed: 0.0751s/iter; left time: 1634.8448s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795212\n",
      "\tspeed: 0.0421s/iter; left time: 912.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0792196 Vali Loss: 0.0897547 Test Loss: 0.0930960\n",
      "Validation loss decreased (0.092013 --> 0.089755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744526\n",
      "\tspeed: 0.0744s/iter; left time: 1602.0627s\n",
      "\titers: 200, epoch: 4 | loss: 0.0765585\n",
      "\tspeed: 0.0431s/iter; left time: 922.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0770492 Vali Loss: 0.0888159 Test Loss: 0.0912558\n",
      "Validation loss decreased (0.089755 --> 0.088816).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0781723\n",
      "\tspeed: 0.0752s/iter; left time: 1602.5429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0787505\n",
      "\tspeed: 0.0411s/iter; left time: 872.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0755762 Vali Loss: 0.0882391 Test Loss: 0.0905145\n",
      "Validation loss decreased (0.088816 --> 0.088239).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0734662\n",
      "\tspeed: 0.0779s/iter; left time: 1642.4975s\n",
      "\titers: 200, epoch: 6 | loss: 0.0701560\n",
      "\tspeed: 0.0412s/iter; left time: 865.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0744702 Vali Loss: 0.0880928 Test Loss: 0.0901387\n",
      "Validation loss decreased (0.088239 --> 0.088093).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0758411\n",
      "\tspeed: 0.0762s/iter; left time: 1589.9836s\n",
      "\titers: 200, epoch: 7 | loss: 0.0725631\n",
      "\tspeed: 0.0411s/iter; left time: 853.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0737651 Vali Loss: 0.0871508 Test Loss: 0.0891528\n",
      "Validation loss decreased (0.088093 --> 0.087151).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0738654\n",
      "\tspeed: 0.0756s/iter; left time: 1561.2701s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790533\n",
      "\tspeed: 0.0418s/iter; left time: 859.2039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0730526 Vali Loss: 0.0870921 Test Loss: 0.0889390\n",
      "Validation loss decreased (0.087151 --> 0.087092).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0699977\n",
      "\tspeed: 0.0750s/iter; left time: 1531.8871s\n",
      "\titers: 200, epoch: 9 | loss: 0.0693552\n",
      "\tspeed: 0.0424s/iter; left time: 862.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0725657 Vali Loss: 0.0867596 Test Loss: 0.0892174\n",
      "Validation loss decreased (0.087092 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688242\n",
      "\tspeed: 0.0754s/iter; left time: 1522.1999s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768644\n",
      "\tspeed: 0.0416s/iter; left time: 836.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0722564 Vali Loss: 0.0868287 Test Loss: 0.0888822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0725663\n",
      "\tspeed: 0.0791s/iter; left time: 1580.5377s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708728\n",
      "\tspeed: 0.0410s/iter; left time: 814.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0719054 Vali Loss: 0.0862284 Test Loss: 0.0885692\n",
      "Validation loss decreased (0.086760 --> 0.086228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0754657\n",
      "\tspeed: 0.0760s/iter; left time: 1500.0768s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690805\n",
      "\tspeed: 0.0418s/iter; left time: 821.9923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0715601 Vali Loss: 0.0863634 Test Loss: 0.0886728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0692426\n",
      "\tspeed: 0.0739s/iter; left time: 1443.7657s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709148\n",
      "\tspeed: 0.0431s/iter; left time: 836.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713889 Vali Loss: 0.0865801 Test Loss: 0.0886077\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719159\n",
      "\tspeed: 0.0740s/iter; left time: 1427.5372s\n",
      "\titers: 200, epoch: 14 | loss: 0.0689385\n",
      "\tspeed: 0.0410s/iter; left time: 786.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0711120 Vali Loss: 0.0861776 Test Loss: 0.0885576\n",
      "Validation loss decreased (0.086228 --> 0.086178).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0719024\n",
      "\tspeed: 0.0813s/iter; left time: 1550.3733s\n",
      "\titers: 200, epoch: 15 | loss: 0.0737916\n",
      "\tspeed: 0.0410s/iter; left time: 777.3012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0709302 Vali Loss: 0.0860182 Test Loss: 0.0885886\n",
      "Validation loss decreased (0.086178 --> 0.086018).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717600\n",
      "\tspeed: 0.0776s/iter; left time: 1464.1638s\n",
      "\titers: 200, epoch: 16 | loss: 0.0704221\n",
      "\tspeed: 0.0413s/iter; left time: 775.2639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0707807 Vali Loss: 0.0859530 Test Loss: 0.0883362\n",
      "Validation loss decreased (0.086018 --> 0.085953).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0685674\n",
      "\tspeed: 0.0748s/iter; left time: 1392.9540s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712534\n",
      "\tspeed: 0.0428s/iter; left time: 793.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0706162 Vali Loss: 0.0860626 Test Loss: 0.0882613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0664355\n",
      "\tspeed: 0.0736s/iter; left time: 1355.5983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0718288\n",
      "\tspeed: 0.0425s/iter; left time: 778.9355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0704577 Vali Loss: 0.0858960 Test Loss: 0.0883355\n",
      "Validation loss decreased (0.085953 --> 0.085896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726624\n",
      "\tspeed: 0.0749s/iter; left time: 1363.0548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0683349\n",
      "\tspeed: 0.0410s/iter; left time: 741.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0703722 Vali Loss: 0.0862532 Test Loss: 0.0885259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0739421\n",
      "\tspeed: 0.0768s/iter; left time: 1378.8048s\n",
      "\titers: 200, epoch: 20 | loss: 0.0741002\n",
      "\tspeed: 0.0422s/iter; left time: 753.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0702616 Vali Loss: 0.0857343 Test Loss: 0.0880173\n",
      "Validation loss decreased (0.085896 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0670575\n",
      "\tspeed: 0.0768s/iter; left time: 1363.3505s\n",
      "\titers: 200, epoch: 21 | loss: 0.0731600\n",
      "\tspeed: 0.0413s/iter; left time: 728.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 223 | Train Loss: 0.0701356 Vali Loss: 0.0856524 Test Loss: 0.0883831\n",
      "Validation loss decreased (0.085734 --> 0.085652).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0671976\n",
      "\tspeed: 0.0771s/iter; left time: 1350.7183s\n",
      "\titers: 200, epoch: 22 | loss: 0.0740734\n",
      "\tspeed: 0.0431s/iter; left time: 751.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0701010 Vali Loss: 0.0857823 Test Loss: 0.0880972\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0758784\n",
      "\tspeed: 0.0743s/iter; left time: 1285.6170s\n",
      "\titers: 200, epoch: 23 | loss: 0.0709538\n",
      "\tspeed: 0.0424s/iter; left time: 729.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0700068 Vali Loss: 0.0856148 Test Loss: 0.0881205\n",
      "Validation loss decreased (0.085652 --> 0.085615).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0685787\n",
      "\tspeed: 0.0758s/iter; left time: 1294.4500s\n",
      "\titers: 200, epoch: 24 | loss: 0.0710734\n",
      "\tspeed: 0.0412s/iter; left time: 699.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0699610 Vali Loss: 0.0856896 Test Loss: 0.0881782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0676588\n",
      "\tspeed: 0.0764s/iter; left time: 1288.0852s\n",
      "\titers: 200, epoch: 25 | loss: 0.0711828\n",
      "\tspeed: 0.0412s/iter; left time: 689.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0698800 Vali Loss: 0.0855946 Test Loss: 0.0882437\n",
      "Validation loss decreased (0.085615 --> 0.085595).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0661857\n",
      "\tspeed: 0.0764s/iter; left time: 1269.5660s\n",
      "\titers: 200, epoch: 26 | loss: 0.0734557\n",
      "\tspeed: 0.0415s/iter; left time: 685.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0698155 Vali Loss: 0.0855840 Test Loss: 0.0880812\n",
      "Validation loss decreased (0.085595 --> 0.085584).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697222\n",
      "\tspeed: 0.0741s/iter; left time: 1215.0588s\n",
      "\titers: 200, epoch: 27 | loss: 0.0661289\n",
      "\tspeed: 0.0433s/iter; left time: 706.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0697875 Vali Loss: 0.0856633 Test Loss: 0.0882748\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0737358\n",
      "\tspeed: 0.0768s/iter; left time: 1242.1764s\n",
      "\titers: 200, epoch: 28 | loss: 0.0681898\n",
      "\tspeed: 0.0414s/iter; left time: 665.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696683 Vali Loss: 0.0855569 Test Loss: 0.0882192\n",
      "Validation loss decreased (0.085584 --> 0.085557).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0692833\n",
      "\tspeed: 0.0779s/iter; left time: 1243.7463s\n",
      "\titers: 200, epoch: 29 | loss: 0.0726246\n",
      "\tspeed: 0.0413s/iter; left time: 655.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 223 | Train Loss: 0.0696357 Vali Loss: 0.0855218 Test Loss: 0.0881251\n",
      "Validation loss decreased (0.085557 --> 0.085522).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0657860\n",
      "\tspeed: 0.0770s/iter; left time: 1211.4838s\n",
      "\titers: 200, epoch: 30 | loss: 0.0708374\n",
      "\tspeed: 0.0408s/iter; left time: 638.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 223 | Train Loss: 0.0696056 Vali Loss: 0.0855264 Test Loss: 0.0880535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0701524\n",
      "\tspeed: 0.0745s/iter; left time: 1155.6664s\n",
      "\titers: 200, epoch: 31 | loss: 0.0725639\n",
      "\tspeed: 0.0423s/iter; left time: 651.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0695799 Vali Loss: 0.0855524 Test Loss: 0.0881440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0713260\n",
      "\tspeed: 0.0742s/iter; left time: 1133.8718s\n",
      "\titers: 200, epoch: 32 | loss: 0.0717980\n",
      "\tspeed: 0.0442s/iter; left time: 671.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 223 | Train Loss: 0.0695398 Vali Loss: 0.0854926 Test Loss: 0.0880160\n",
      "Validation loss decreased (0.085522 --> 0.085493).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0683134\n",
      "\tspeed: 0.0759s/iter; left time: 1143.2825s\n",
      "\titers: 200, epoch: 33 | loss: 0.0729751\n",
      "\tspeed: 0.0419s/iter; left time: 626.3768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0695101 Vali Loss: 0.0854646 Test Loss: 0.0880804\n",
      "Validation loss decreased (0.085493 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0691466\n",
      "\tspeed: 0.0784s/iter; left time: 1164.2330s\n",
      "\titers: 200, epoch: 34 | loss: 0.0703526\n",
      "\tspeed: 0.0408s/iter; left time: 601.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.29s\n",
      "Steps: 223 | Train Loss: 0.0695376 Vali Loss: 0.0855198 Test Loss: 0.0880577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0776221\n",
      "\tspeed: 0.0764s/iter; left time: 1116.7155s\n",
      "\titers: 200, epoch: 35 | loss: 0.0695363\n",
      "\tspeed: 0.0417s/iter; left time: 605.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 223 | Train Loss: 0.0694531 Vali Loss: 0.0854499 Test Loss: 0.0880845\n",
      "Validation loss decreased (0.085465 --> 0.085450).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0697098\n",
      "\tspeed: 0.0761s/iter; left time: 1094.8774s\n",
      "\titers: 200, epoch: 36 | loss: 0.0732048\n",
      "\tspeed: 0.0423s/iter; left time: 604.9613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0694773 Vali Loss: 0.0854531 Test Loss: 0.0880837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0732422\n",
      "\tspeed: 0.0739s/iter; left time: 1047.1660s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698277\n",
      "\tspeed: 0.0425s/iter; left time: 597.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0695019 Vali Loss: 0.0854309 Test Loss: 0.0880640\n",
      "Validation loss decreased (0.085450 --> 0.085431).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0662249\n",
      "\tspeed: 0.0747s/iter; left time: 1042.3577s\n",
      "\titers: 200, epoch: 38 | loss: 0.0669574\n",
      "\tspeed: 0.0411s/iter; left time: 569.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0694807 Vali Loss: 0.0854503 Test Loss: 0.0881496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0675080\n",
      "\tspeed: 0.0781s/iter; left time: 1072.2160s\n",
      "\titers: 200, epoch: 39 | loss: 0.0717927\n",
      "\tspeed: 0.0413s/iter; left time: 562.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0694395 Vali Loss: 0.0855308 Test Loss: 0.0881241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0681171\n",
      "\tspeed: 0.0763s/iter; left time: 1030.3686s\n",
      "\titers: 200, epoch: 40 | loss: 0.0687452\n",
      "\tspeed: 0.0418s/iter; left time: 559.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 223 | Train Loss: 0.0694168 Vali Loss: 0.0854836 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0687454\n",
      "\tspeed: 0.0746s/iter; left time: 991.3941s\n",
      "\titers: 200, epoch: 41 | loss: 0.0672896\n",
      "\tspeed: 0.0430s/iter; left time: 566.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0693724 Vali Loss: 0.0854263 Test Loss: 0.0880959\n",
      "Validation loss decreased (0.085431 --> 0.085426).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0690397\n",
      "\tspeed: 0.0747s/iter; left time: 975.1047s\n",
      "\titers: 200, epoch: 42 | loss: 0.0734327\n",
      "\tspeed: 0.0412s/iter; left time: 533.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0693399 Vali Loss: 0.0855006 Test Loss: 0.0881062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0726071\n",
      "\tspeed: 0.0752s/iter; left time: 965.0980s\n",
      "\titers: 200, epoch: 43 | loss: 0.0722188\n",
      "\tspeed: 0.0411s/iter; left time: 523.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:09.35s\n",
      "Steps: 223 | Train Loss: 0.0693658 Vali Loss: 0.0854671 Test Loss: 0.0881068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0688466\n",
      "\tspeed: 0.0761s/iter; left time: 960.0431s\n",
      "\titers: 200, epoch: 44 | loss: 0.0752073\n",
      "\tspeed: 0.0427s/iter; left time: 534.0069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0694005 Vali Loss: 0.0854169 Test Loss: 0.0880969\n",
      "Validation loss decreased (0.085426 --> 0.085417).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0694189\n",
      "\tspeed: 0.0771s/iter; left time: 955.1548s\n",
      "\titers: 200, epoch: 45 | loss: 0.0663738\n",
      "\tspeed: 0.0411s/iter; left time: 505.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693401 Vali Loss: 0.0854222 Test Loss: 0.0881163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0687163\n",
      "\tspeed: 0.0740s/iter; left time: 900.7709s\n",
      "\titers: 200, epoch: 46 | loss: 0.0681874\n",
      "\tspeed: 0.0429s/iter; left time: 517.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693499 Vali Loss: 0.0854475 Test Loss: 0.0880975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0698357\n",
      "\tspeed: 0.0733s/iter; left time: 875.7307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0708191\n",
      "\tspeed: 0.0421s/iter; left time: 498.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0693365 Vali Loss: 0.0854302 Test Loss: 0.0880839\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0703154\n",
      "\tspeed: 0.0770s/iter; left time: 902.2628s\n",
      "\titers: 200, epoch: 48 | loss: 0.0697617\n",
      "\tspeed: 0.0409s/iter; left time: 475.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0693081 Vali Loss: 0.0854606 Test Loss: 0.0881088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0689715\n",
      "\tspeed: 0.0781s/iter; left time: 898.0791s\n",
      "\titers: 200, epoch: 49 | loss: 0.0643823\n",
      "\tspeed: 0.0409s/iter; left time: 465.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0693539 Vali Loss: 0.0854463 Test Loss: 0.0881050\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0739108\n",
      "\tspeed: 0.0755s/iter; left time: 851.3720s\n",
      "\titers: 200, epoch: 50 | loss: 0.0687575\n",
      "\tspeed: 0.0411s/iter; left time: 459.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0693257 Vali Loss: 0.0853803 Test Loss: 0.0880668\n",
      "Validation loss decreased (0.085417 --> 0.085380).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0741657\n",
      "\tspeed: 0.0741s/iter; left time: 819.4238s\n",
      "\titers: 200, epoch: 51 | loss: 0.0745502\n",
      "\tspeed: 0.0424s/iter; left time: 464.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0693099 Vali Loss: 0.0854465 Test Loss: 0.0880877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0701798\n",
      "\tspeed: 0.0752s/iter; left time: 814.4153s\n",
      "\titers: 200, epoch: 52 | loss: 0.0675897\n",
      "\tspeed: 0.0407s/iter; left time: 437.0012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0692942 Vali Loss: 0.0854767 Test Loss: 0.0881183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0710436\n",
      "\tspeed: 0.0766s/iter; left time: 812.8227s\n",
      "\titers: 200, epoch: 53 | loss: 0.0713551\n",
      "\tspeed: 0.0412s/iter; left time: 432.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 223 | Train Loss: 0.0693223 Vali Loss: 0.0854564 Test Loss: 0.0880729\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0713452\n",
      "\tspeed: 0.0751s/iter; left time: 779.1887s\n",
      "\titers: 200, epoch: 54 | loss: 0.0682029\n",
      "\tspeed: 0.0412s/iter; left time: 423.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693280 Vali Loss: 0.0854152 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0675052\n",
      "\tspeed: 0.0767s/iter; left time: 779.4137s\n",
      "\titers: 200, epoch: 55 | loss: 0.0720875\n",
      "\tspeed: 0.0431s/iter; left time: 433.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 223 | Train Loss: 0.0692830 Vali Loss: 0.0854154 Test Loss: 0.0880911\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0677626\n",
      "\tspeed: 0.0738s/iter; left time: 732.9327s\n",
      "\titers: 200, epoch: 56 | loss: 0.0691914\n",
      "\tspeed: 0.0426s/iter; left time: 418.7587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693142 Vali Loss: 0.0854138 Test Loss: 0.0881014\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0713836\n",
      "\tspeed: 0.0741s/iter; left time: 719.9243s\n",
      "\titers: 200, epoch: 57 | loss: 0.0689744\n",
      "\tspeed: 0.0409s/iter; left time: 392.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:09.32s\n",
      "Steps: 223 | Train Loss: 0.0692971 Vali Loss: 0.0853321 Test Loss: 0.0880808\n",
      "Validation loss decreased (0.085380 --> 0.085332).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0728526\n",
      "\tspeed: 0.0785s/iter; left time: 744.8295s\n",
      "\titers: 200, epoch: 58 | loss: 0.0730912\n",
      "\tspeed: 0.0415s/iter; left time: 389.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0693028 Vali Loss: 0.0854990 Test Loss: 0.0880816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0685177\n",
      "\tspeed: 0.0763s/iter; left time: 706.6706s\n",
      "\titers: 200, epoch: 59 | loss: 0.0764130\n",
      "\tspeed: 0.0410s/iter; left time: 376.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0693449 Vali Loss: 0.0854073 Test Loss: 0.0880793\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0652238\n",
      "\tspeed: 0.0748s/iter; left time: 676.4479s\n",
      "\titers: 200, epoch: 60 | loss: 0.0730409\n",
      "\tspeed: 0.0425s/iter; left time: 380.3159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0693224 Vali Loss: 0.0854565 Test Loss: 0.0880748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0622156\n",
      "\tspeed: 0.0740s/iter; left time: 652.8614s\n",
      "\titers: 200, epoch: 61 | loss: 0.0695777\n",
      "\tspeed: 0.0423s/iter; left time: 369.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0693130 Vali Loss: 0.0853348 Test Loss: 0.0880779\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0691958\n",
      "\tspeed: 0.0746s/iter; left time: 641.5221s\n",
      "\titers: 200, epoch: 62 | loss: 0.0696925\n",
      "\tspeed: 0.0411s/iter; left time: 348.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0692719 Vali Loss: 0.0854249 Test Loss: 0.0880714\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0646419\n",
      "\tspeed: 0.0767s/iter; left time: 642.4102s\n",
      "\titers: 200, epoch: 63 | loss: 0.0696922\n",
      "\tspeed: 0.0415s/iter; left time: 343.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:09.42s\n",
      "Steps: 223 | Train Loss: 0.0692963 Vali Loss: 0.0855429 Test Loss: 0.0881021\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0697859\n",
      "\tspeed: 0.0767s/iter; left time: 625.5754s\n",
      "\titers: 200, epoch: 64 | loss: 0.0695441\n",
      "\tspeed: 0.0416s/iter; left time: 334.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0693159 Vali Loss: 0.0854452 Test Loss: 0.0880868\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0718862\n",
      "\tspeed: 0.0746s/iter; left time: 591.8343s\n",
      "\titers: 200, epoch: 65 | loss: 0.0714731\n",
      "\tspeed: 0.0427s/iter; left time: 334.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0692911 Vali Loss: 0.0855044 Test Loss: 0.0880898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0747009\n",
      "\tspeed: 0.0740s/iter; left time: 570.0327s\n",
      "\titers: 200, epoch: 66 | loss: 0.0683450\n",
      "\tspeed: 0.0414s/iter; left time: 315.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0692636 Vali Loss: 0.0854475 Test Loss: 0.0880977\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0644507\n",
      "\tspeed: 0.0754s/iter; left time: 564.0547s\n",
      "\titers: 200, epoch: 67 | loss: 0.0695106\n",
      "\tspeed: 0.0409s/iter; left time: 301.6847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.0692449 Vali Loss: 0.0854787 Test Loss: 0.0881008\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021135743707418442, rmse:0.1453813761472702, mae:0.08808080106973648, rse:0.5130710005760193\n",
      "Intermediate time for DE and pred_len 24: 00h:23m:13.92s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1385211\n",
      "\tspeed: 0.0689s/iter; left time: 1523.7622s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272170\n",
      "\tspeed: 0.0429s/iter; left time: 943.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.92s\n",
      "Steps: 222 | Train Loss: 0.1436296 Vali Loss: 0.1367209 Test Loss: 0.1443836\n",
      "Validation loss decreased (inf --> 0.136721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1119428\n",
      "\tspeed: 0.0752s/iter; left time: 1645.3605s\n",
      "\titers: 200, epoch: 2 | loss: 0.1102052\n",
      "\tspeed: 0.0433s/iter; left time: 942.5108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1122322 Vali Loss: 0.1209552 Test Loss: 0.1276630\n",
      "Validation loss decreased (0.136721 --> 0.120955).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019009\n",
      "\tspeed: 0.0775s/iter; left time: 1678.0483s\n",
      "\titers: 200, epoch: 3 | loss: 0.1073653\n",
      "\tspeed: 0.0414s/iter; left time: 893.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1050740 Vali Loss: 0.1188224 Test Loss: 0.1261629\n",
      "Validation loss decreased (0.120955 --> 0.118822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991714\n",
      "\tspeed: 0.0787s/iter; left time: 1687.2832s\n",
      "\titers: 200, epoch: 4 | loss: 0.1060414\n",
      "\tspeed: 0.0412s/iter; left time: 879.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 222 | Train Loss: 0.1032394 Vali Loss: 0.1185098 Test Loss: 0.1264228\n",
      "Validation loss decreased (0.118822 --> 0.118510).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1070811\n",
      "\tspeed: 0.0785s/iter; left time: 1664.3113s\n",
      "\titers: 200, epoch: 5 | loss: 0.1010344\n",
      "\tspeed: 0.0413s/iter; left time: 872.7381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1018696 Vali Loss: 0.1173460 Test Loss: 0.1256864\n",
      "Validation loss decreased (0.118510 --> 0.117346).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0988520\n",
      "\tspeed: 0.0769s/iter; left time: 1613.7952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993529\n",
      "\tspeed: 0.0432s/iter; left time: 902.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1007471 Vali Loss: 0.1172743 Test Loss: 0.1250511\n",
      "Validation loss decreased (0.117346 --> 0.117274).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0983264\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1289s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031795\n",
      "\tspeed: 0.0416s/iter; left time: 860.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0996418 Vali Loss: 0.1161049 Test Loss: 0.1247776\n",
      "Validation loss decreased (0.117274 --> 0.116105).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0968254\n",
      "\tspeed: 0.0767s/iter; left time: 1576.2278s\n",
      "\titers: 200, epoch: 8 | loss: 0.0976769\n",
      "\tspeed: 0.0433s/iter; left time: 885.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0990161 Vali Loss: 0.1161650 Test Loss: 0.1246663\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0972535\n",
      "\tspeed: 0.0757s/iter; left time: 1538.0982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0927693\n",
      "\tspeed: 0.0424s/iter; left time: 856.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 222 | Train Loss: 0.0982024 Vali Loss: 0.1159731 Test Loss: 0.1244971\n",
      "Validation loss decreased (0.116105 --> 0.115973).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1004171\n",
      "\tspeed: 0.0787s/iter; left time: 1581.5480s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019848\n",
      "\tspeed: 0.0417s/iter; left time: 833.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0975692 Vali Loss: 0.1164706 Test Loss: 0.1259885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969026\n",
      "\tspeed: 0.0806s/iter; left time: 1602.3917s\n",
      "\titers: 200, epoch: 11 | loss: 0.0972415\n",
      "\tspeed: 0.0417s/iter; left time: 825.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0970848 Vali Loss: 0.1161472 Test Loss: 0.1248178\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0945826\n",
      "\tspeed: 0.0765s/iter; left time: 1502.9973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0900184\n",
      "\tspeed: 0.0430s/iter; left time: 840.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0966333 Vali Loss: 0.1163193 Test Loss: 0.1255104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0919880\n",
      "\tspeed: 0.0762s/iter; left time: 1481.9078s\n",
      "\titers: 200, epoch: 13 | loss: 0.0924623\n",
      "\tspeed: 0.0448s/iter; left time: 866.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.0962716 Vali Loss: 0.1166060 Test Loss: 0.1256381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920922\n",
      "\tspeed: 0.0769s/iter; left time: 1478.2532s\n",
      "\titers: 200, epoch: 14 | loss: 0.0965592\n",
      "\tspeed: 0.0415s/iter; left time: 792.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0958053 Vali Loss: 0.1166250 Test Loss: 0.1259447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0982206\n",
      "\tspeed: 0.0792s/iter; left time: 1504.5394s\n",
      "\titers: 200, epoch: 15 | loss: 0.0993863\n",
      "\tspeed: 0.0412s/iter; left time: 777.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 222 | Train Loss: 0.0955025 Vali Loss: 0.1164518 Test Loss: 0.1254893\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0987729\n",
      "\tspeed: 0.0787s/iter; left time: 1477.8527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0852301\n",
      "\tspeed: 0.0420s/iter; left time: 784.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0951404 Vali Loss: 0.1169241 Test Loss: 0.1264961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0946120\n",
      "\tspeed: 0.0763s/iter; left time: 1415.3852s\n",
      "\titers: 200, epoch: 17 | loss: 0.0943329\n",
      "\tspeed: 0.0438s/iter; left time: 808.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0948563 Vali Loss: 0.1167530 Test Loss: 0.1260772\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0961872\n",
      "\tspeed: 0.0765s/iter; left time: 1402.3126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0899222\n",
      "\tspeed: 0.0421s/iter; left time: 767.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 222 | Train Loss: 0.0945491 Vali Loss: 0.1170323 Test Loss: 0.1264428\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0923800\n",
      "\tspeed: 0.0759s/iter; left time: 1373.4559s\n",
      "\titers: 200, epoch: 19 | loss: 0.0921431\n",
      "\tspeed: 0.0416s/iter; left time: 749.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 222 | Train Loss: 0.0942993 Vali Loss: 0.1170631 Test Loss: 0.1265067\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03561720997095108, rmse:0.18872521817684174, mae:0.12449711561203003, rse:0.6683141589164734\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1400388\n",
      "\tspeed: 0.0437s/iter; left time: 964.9514s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282806\n",
      "\tspeed: 0.0418s/iter; left time: 920.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 222 | Train Loss: 0.1451481 Vali Loss: 0.1368056 Test Loss: 0.1443637\n",
      "Validation loss decreased (inf --> 0.136806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1109583\n",
      "\tspeed: 0.0795s/iter; left time: 1738.7939s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087150\n",
      "\tspeed: 0.0413s/iter; left time: 898.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1123508 Vali Loss: 0.1206324 Test Loss: 0.1275795\n",
      "Validation loss decreased (0.136806 --> 0.120632).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1061414\n",
      "\tspeed: 0.0774s/iter; left time: 1676.6510s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020828\n",
      "\tspeed: 0.0427s/iter; left time: 921.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1054388 Vali Loss: 0.1195631 Test Loss: 0.1275751\n",
      "Validation loss decreased (0.120632 --> 0.119563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1002767\n",
      "\tspeed: 0.0766s/iter; left time: 1640.9971s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011909\n",
      "\tspeed: 0.0444s/iter; left time: 947.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.79s\n",
      "Steps: 222 | Train Loss: 0.1036856 Vali Loss: 0.1177835 Test Loss: 0.1259473\n",
      "Validation loss decreased (0.119563 --> 0.117784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005678\n",
      "\tspeed: 0.0804s/iter; left time: 1704.5139s\n",
      "\titers: 200, epoch: 5 | loss: 0.1012293\n",
      "\tspeed: 0.0422s/iter; left time: 892.0216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1022701 Vali Loss: 0.1182866 Test Loss: 0.1259687\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041436\n",
      "\tspeed: 0.0799s/iter; left time: 1677.0377s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036419\n",
      "\tspeed: 0.0416s/iter; left time: 868.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.1011227 Vali Loss: 0.1171968 Test Loss: 0.1266128\n",
      "Validation loss decreased (0.117784 --> 0.117197).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0986257\n",
      "\tspeed: 0.0798s/iter; left time: 1657.7720s\n",
      "\titers: 200, epoch: 7 | loss: 0.0996775\n",
      "\tspeed: 0.0414s/iter; left time: 856.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1001962 Vali Loss: 0.1165839 Test Loss: 0.1266569\n",
      "Validation loss decreased (0.117197 --> 0.116584).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0976779\n",
      "\tspeed: 0.0806s/iter; left time: 1656.7433s\n",
      "\titers: 200, epoch: 8 | loss: 0.0970001\n",
      "\tspeed: 0.0439s/iter; left time: 897.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.97s\n",
      "Steps: 222 | Train Loss: 0.0992992 Vali Loss: 0.1167001 Test Loss: 0.1258703\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027840\n",
      "\tspeed: 0.0771s/iter; left time: 1566.7971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060535\n",
      "\tspeed: 0.0430s/iter; left time: 869.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0985650 Vali Loss: 0.1167805 Test Loss: 0.1263607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0944021\n",
      "\tspeed: 0.0790s/iter; left time: 1588.0037s\n",
      "\titers: 200, epoch: 10 | loss: 0.1016151\n",
      "\tspeed: 0.0413s/iter; left time: 825.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.41s\n",
      "Steps: 222 | Train Loss: 0.0980308 Vali Loss: 0.1163658 Test Loss: 0.1254943\n",
      "Validation loss decreased (0.116584 --> 0.116366).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0977273\n",
      "\tspeed: 0.0795s/iter; left time: 1581.0516s\n",
      "\titers: 200, epoch: 11 | loss: 0.0998444\n",
      "\tspeed: 0.0419s/iter; left time: 829.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0972910 Vali Loss: 0.1168659 Test Loss: 0.1263906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0961552\n",
      "\tspeed: 0.0790s/iter; left time: 1552.8094s\n",
      "\titers: 200, epoch: 12 | loss: 0.0945634\n",
      "\tspeed: 0.0428s/iter; left time: 836.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.0967934 Vali Loss: 0.1168394 Test Loss: 0.1271407\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0975530\n",
      "\tspeed: 0.0768s/iter; left time: 1493.3065s\n",
      "\titers: 200, epoch: 13 | loss: 0.0979478\n",
      "\tspeed: 0.0447s/iter; left time: 864.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.0963015 Vali Loss: 0.1170192 Test Loss: 0.1264434\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0950694\n",
      "\tspeed: 0.0771s/iter; left time: 1481.7566s\n",
      "\titers: 200, epoch: 14 | loss: 0.0953018\n",
      "\tspeed: 0.0414s/iter; left time: 790.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.48s\n",
      "Steps: 222 | Train Loss: 0.0958852 Vali Loss: 0.1174900 Test Loss: 0.1265704\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0917451\n",
      "\tspeed: 0.0798s/iter; left time: 1516.0533s\n",
      "\titers: 200, epoch: 15 | loss: 0.0947973\n",
      "\tspeed: 0.0414s/iter; left time: 781.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 222 | Train Loss: 0.0954877 Vali Loss: 0.1173866 Test Loss: 0.1267025\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0963200\n",
      "\tspeed: 0.0788s/iter; left time: 1478.6512s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930423\n",
      "\tspeed: 0.0423s/iter; left time: 789.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0950855 Vali Loss: 0.1175980 Test Loss: 0.1277074\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0916373\n",
      "\tspeed: 0.0815s/iter; left time: 1511.0478s\n",
      "\titers: 200, epoch: 17 | loss: 0.0967468\n",
      "\tspeed: 0.0506s/iter; left time: 933.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.78s\n",
      "Steps: 222 | Train Loss: 0.0947534 Vali Loss: 0.1174741 Test Loss: 0.1267105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0973670\n",
      "\tspeed: 0.0786s/iter; left time: 1440.3332s\n",
      "\titers: 200, epoch: 18 | loss: 0.0952947\n",
      "\tspeed: 0.0429s/iter; left time: 782.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.81s\n",
      "Steps: 222 | Train Loss: 0.0943828 Vali Loss: 0.1179385 Test Loss: 0.1270582\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0973220\n",
      "\tspeed: 0.0781s/iter; left time: 1414.1248s\n",
      "\titers: 200, epoch: 19 | loss: 0.0969161\n",
      "\tspeed: 0.0420s/iter; left time: 756.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0941494 Vali Loss: 0.1176506 Test Loss: 0.1271805\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0945372\n",
      "\tspeed: 0.0828s/iter; left time: 1481.0696s\n",
      "\titers: 200, epoch: 20 | loss: 0.0925670\n",
      "\tspeed: 0.0417s/iter; left time: 741.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0939146 Vali Loss: 0.1181242 Test Loss: 0.1272864\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036110397428274155, rmse:0.1900273561477661, mae:0.12549425661563873, rse:0.6729252934455872\n",
      "Intermediate time for DE and pred_len 96: 00h:08m:04.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1397623\n",
      "\tspeed: 0.0685s/iter; left time: 1512.8747s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311453\n",
      "\tspeed: 0.0443s/iter; left time: 975.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.02s\n",
      "Steps: 222 | Train Loss: 0.1455157 Vali Loss: 0.1382303 Test Loss: 0.1469418\n",
      "Validation loss decreased (inf --> 0.138230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1118676\n",
      "\tspeed: 0.0769s/iter; left time: 1681.6863s\n",
      "\titers: 200, epoch: 2 | loss: 0.1124648\n",
      "\tspeed: 0.0422s/iter; left time: 918.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1173347 Vali Loss: 0.1244901 Test Loss: 0.1326688\n",
      "Validation loss decreased (0.138230 --> 0.124490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1142889\n",
      "\tspeed: 0.0829s/iter; left time: 1795.9465s\n",
      "\titers: 200, epoch: 3 | loss: 0.1112246\n",
      "\tspeed: 0.0419s/iter; left time: 903.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 222 | Train Loss: 0.1107566 Vali Loss: 0.1233068 Test Loss: 0.1331108\n",
      "Validation loss decreased (0.124490 --> 0.123307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125001\n",
      "\tspeed: 0.0796s/iter; left time: 1705.7956s\n",
      "\titers: 200, epoch: 4 | loss: 0.1047679\n",
      "\tspeed: 0.0422s/iter; left time: 900.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1088656 Vali Loss: 0.1225500 Test Loss: 0.1325692\n",
      "Validation loss decreased (0.123307 --> 0.122550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1045422\n",
      "\tspeed: 0.0778s/iter; left time: 1651.2061s\n",
      "\titers: 200, epoch: 5 | loss: 0.1108324\n",
      "\tspeed: 0.0443s/iter; left time: 934.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.88s\n",
      "Steps: 222 | Train Loss: 0.1072662 Vali Loss: 0.1221504 Test Loss: 0.1329006\n",
      "Validation loss decreased (0.122550 --> 0.122150).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041857\n",
      "\tspeed: 0.0778s/iter; left time: 1632.2456s\n",
      "\titers: 200, epoch: 6 | loss: 0.1052786\n",
      "\tspeed: 0.0448s/iter; left time: 936.7191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1058854 Vali Loss: 0.1215441 Test Loss: 0.1320615\n",
      "Validation loss decreased (0.122150 --> 0.121544).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1038428\n",
      "\tspeed: 0.0791s/iter; left time: 1641.9992s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040158\n",
      "\tspeed: 0.0420s/iter; left time: 868.4266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1048011 Vali Loss: 0.1215408 Test Loss: 0.1310547\n",
      "Validation loss decreased (0.121544 --> 0.121541).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1035512\n",
      "\tspeed: 0.0793s/iter; left time: 1629.1195s\n",
      "\titers: 200, epoch: 8 | loss: 0.1044740\n",
      "\tspeed: 0.0429s/iter; left time: 877.8017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1037952 Vali Loss: 0.1215836 Test Loss: 0.1319724\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1043236\n",
      "\tspeed: 0.0805s/iter; left time: 1636.7817s\n",
      "\titers: 200, epoch: 9 | loss: 0.1052697\n",
      "\tspeed: 0.0427s/iter; left time: 862.8355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1029094 Vali Loss: 0.1222514 Test Loss: 0.1315340\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0996455\n",
      "\tspeed: 0.0792s/iter; left time: 1591.9196s\n",
      "\titers: 200, epoch: 10 | loss: 0.1033757\n",
      "\tspeed: 0.0422s/iter; left time: 843.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1021399 Vali Loss: 0.1226193 Test Loss: 0.1322068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1056792\n",
      "\tspeed: 0.0812s/iter; left time: 1613.7792s\n",
      "\titers: 200, epoch: 11 | loss: 0.1029007\n",
      "\tspeed: 0.0430s/iter; left time: 849.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 222 | Train Loss: 0.1013839 Vali Loss: 0.1223948 Test Loss: 0.1326800\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1031876\n",
      "\tspeed: 0.0785s/iter; left time: 1543.2386s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028955\n",
      "\tspeed: 0.0448s/iter; left time: 876.2428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.87s\n",
      "Steps: 222 | Train Loss: 0.1008144 Vali Loss: 0.1228269 Test Loss: 0.1327951\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0969489\n",
      "\tspeed: 0.0775s/iter; left time: 1506.6652s\n",
      "\titers: 200, epoch: 13 | loss: 0.1018683\n",
      "\tspeed: 0.0420s/iter; left time: 811.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 222 | Train Loss: 0.1002138 Vali Loss: 0.1231768 Test Loss: 0.1335167\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0958620\n",
      "\tspeed: 0.0823s/iter; left time: 1582.0268s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960994\n",
      "\tspeed: 0.0425s/iter; left time: 812.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0996247 Vali Loss: 0.1232097 Test Loss: 0.1334005\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0970920\n",
      "\tspeed: 0.0815s/iter; left time: 1547.0298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0992540\n",
      "\tspeed: 0.0424s/iter; left time: 800.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.94s\n",
      "Steps: 222 | Train Loss: 0.0991395 Vali Loss: 0.1234243 Test Loss: 0.1337967\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0988758\n",
      "\tspeed: 0.0778s/iter; left time: 1460.0914s\n",
      "\titers: 200, epoch: 16 | loss: 0.1006009\n",
      "\tspeed: 0.0429s/iter; left time: 801.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.0986473 Vali Loss: 0.1236352 Test Loss: 0.1343386\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0987671\n",
      "\tspeed: 0.0773s/iter; left time: 1434.3332s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016840\n",
      "\tspeed: 0.0433s/iter; left time: 798.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0981912 Vali Loss: 0.1233611 Test Loss: 0.1350610\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.037683311849832535, rmse:0.19412189722061157, mae:0.13105474412441254, rse:0.6875953674316406\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1464187\n",
      "\tspeed: 0.0438s/iter; left time: 969.1262s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341484\n",
      "\tspeed: 0.0436s/iter; left time: 958.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1460951 Vali Loss: 0.1378723 Test Loss: 0.1467569\n",
      "Validation loss decreased (inf --> 0.137872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1244008\n",
      "\tspeed: 0.0783s/iter; left time: 1714.2119s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136181\n",
      "\tspeed: 0.0421s/iter; left time: 917.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1175792 Vali Loss: 0.1241931 Test Loss: 0.1332423\n",
      "Validation loss decreased (0.137872 --> 0.124193).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168221\n",
      "\tspeed: 0.0842s/iter; left time: 1822.6471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1108454\n",
      "\tspeed: 0.0422s/iter; left time: 908.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.1109203 Vali Loss: 0.1232760 Test Loss: 0.1326479\n",
      "Validation loss decreased (0.124193 --> 0.123276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1095669\n",
      "\tspeed: 0.0842s/iter; left time: 1805.3797s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056824\n",
      "\tspeed: 0.0417s/iter; left time: 889.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.1091623 Vali Loss: 0.1222856 Test Loss: 0.1327749\n",
      "Validation loss decreased (0.123276 --> 0.122286).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129397\n",
      "\tspeed: 0.0839s/iter; left time: 1779.1501s\n",
      "\titers: 200, epoch: 5 | loss: 0.1075838\n",
      "\tspeed: 0.0417s/iter; left time: 880.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 222 | Train Loss: 0.1076867 Vali Loss: 0.1218808 Test Loss: 0.1322782\n",
      "Validation loss decreased (0.122286 --> 0.121881).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021544\n",
      "\tspeed: 0.0803s/iter; left time: 1684.8417s\n",
      "\titers: 200, epoch: 6 | loss: 0.1099828\n",
      "\tspeed: 0.0436s/iter; left time: 911.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.1062730 Vali Loss: 0.1218795 Test Loss: 0.1329139\n",
      "Validation loss decreased (0.121881 --> 0.121879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1045288\n",
      "\tspeed: 0.0787s/iter; left time: 1635.3227s\n",
      "\titers: 200, epoch: 7 | loss: 0.1049782\n",
      "\tspeed: 0.0442s/iter; left time: 912.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.83s\n",
      "Steps: 222 | Train Loss: 0.1051721 Vali Loss: 0.1218529 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.121879 --> 0.121853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054067\n",
      "\tspeed: 0.0791s/iter; left time: 1625.8461s\n",
      "\titers: 200, epoch: 8 | loss: 0.1061499\n",
      "\tspeed: 0.0419s/iter; left time: 857.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1041193 Vali Loss: 0.1218142 Test Loss: 0.1342641\n",
      "Validation loss decreased (0.121853 --> 0.121814).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1012625\n",
      "\tspeed: 0.0818s/iter; left time: 1661.8316s\n",
      "\titers: 200, epoch: 9 | loss: 0.1050227\n",
      "\tspeed: 0.0420s/iter; left time: 848.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1032028 Vali Loss: 0.1221258 Test Loss: 0.1326769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1042934\n",
      "\tspeed: 0.0803s/iter; left time: 1613.4620s\n",
      "\titers: 200, epoch: 10 | loss: 0.0979124\n",
      "\tspeed: 0.0422s/iter; left time: 843.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 222 | Train Loss: 0.1022348 Vali Loss: 0.1229397 Test Loss: 0.1328034\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0992723\n",
      "\tspeed: 0.0782s/iter; left time: 1553.8170s\n",
      "\titers: 200, epoch: 11 | loss: 0.1031113\n",
      "\tspeed: 0.0429s/iter; left time: 848.0301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.1014518 Vali Loss: 0.1221524 Test Loss: 0.1333573\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0981024\n",
      "\tspeed: 0.0796s/iter; left time: 1564.1103s\n",
      "\titers: 200, epoch: 12 | loss: 0.1039329\n",
      "\tspeed: 0.0420s/iter; left time: 820.8737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1004923 Vali Loss: 0.1232195 Test Loss: 0.1345381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0996970\n",
      "\tspeed: 0.0800s/iter; left time: 1554.3746s\n",
      "\titers: 200, epoch: 13 | loss: 0.1020393\n",
      "\tspeed: 0.0420s/iter; left time: 812.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0998807 Vali Loss: 0.1230378 Test Loss: 0.1335723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1020292\n",
      "\tspeed: 0.0789s/iter; left time: 1515.2191s\n",
      "\titers: 200, epoch: 14 | loss: 0.0983770\n",
      "\tspeed: 0.0429s/iter; left time: 819.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 222 | Train Loss: 0.0993128 Vali Loss: 0.1233723 Test Loss: 0.1334894\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1019369\n",
      "\tspeed: 0.0786s/iter; left time: 1493.1534s\n",
      "\titers: 200, epoch: 15 | loss: 0.1003085\n",
      "\tspeed: 0.0438s/iter; left time: 827.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986477 Vali Loss: 0.1239124 Test Loss: 0.1339220\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0990376\n",
      "\tspeed: 0.0780s/iter; left time: 1463.5393s\n",
      "\titers: 200, epoch: 16 | loss: 0.0996671\n",
      "\tspeed: 0.0421s/iter; left time: 785.9176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0981405 Vali Loss: 0.1236752 Test Loss: 0.1338171\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0997125\n",
      "\tspeed: 0.0809s/iter; left time: 1500.4029s\n",
      "\titers: 200, epoch: 17 | loss: 0.0991643\n",
      "\tspeed: 0.0419s/iter; left time: 773.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.59s\n",
      "Steps: 222 | Train Loss: 0.0977311 Vali Loss: 0.1242002 Test Loss: 0.1341292\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0960976\n",
      "\tspeed: 0.0808s/iter; left time: 1481.3266s\n",
      "\titers: 200, epoch: 18 | loss: 0.0957674\n",
      "\tspeed: 0.0422s/iter; left time: 769.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.73s\n",
      "Steps: 222 | Train Loss: 0.0973472 Vali Loss: 0.1244612 Test Loss: 0.1344188\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03982341289520264, rmse:0.1995580494403839, mae:0.13426414132118225, rse:0.7068506479263306\n",
      "Intermediate time for DE and pred_len 168: 00h:07m:24.55s\n",
      "Intermediate time for DE: 00h:38m:43.17s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1188304\n",
      "\tspeed: 0.0652s/iter; left time: 1447.7247s\n",
      "\titers: 200, epoch: 1 | loss: 0.1158463\n",
      "\tspeed: 0.0436s/iter; left time: 964.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 223 | Train Loss: 0.1253345 Vali Loss: 0.1194196 Test Loss: 0.1384884\n",
      "Validation loss decreased (inf --> 0.119420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869500\n",
      "\tspeed: 0.0763s/iter; left time: 1677.7030s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823559\n",
      "\tspeed: 0.0412s/iter; left time: 901.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0858117 Vali Loss: 0.0921554 Test Loss: 0.1034357\n",
      "Validation loss decreased (0.119420 --> 0.092155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0806272\n",
      "\tspeed: 0.0785s/iter; left time: 1708.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.0780588\n",
      "\tspeed: 0.0411s/iter; left time: 889.2124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0789248 Vali Loss: 0.0894574 Test Loss: 0.1027660\n",
      "Validation loss decreased (0.092155 --> 0.089457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818409\n",
      "\tspeed: 0.0777s/iter; left time: 1672.5881s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826696\n",
      "\tspeed: 0.0420s/iter; left time: 900.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0773095 Vali Loss: 0.0896718 Test Loss: 0.1028447\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0730246\n",
      "\tspeed: 0.0752s/iter; left time: 1601.9405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0735860\n",
      "\tspeed: 0.0431s/iter; left time: 913.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0762145 Vali Loss: 0.0891013 Test Loss: 0.1017014\n",
      "Validation loss decreased (0.089457 --> 0.089101).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0732028\n",
      "\tspeed: 0.0745s/iter; left time: 1570.1271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779525\n",
      "\tspeed: 0.0428s/iter; left time: 898.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0755551 Vali Loss: 0.0885052 Test Loss: 0.1005966\n",
      "Validation loss decreased (0.089101 --> 0.088505).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749436\n",
      "\tspeed: 0.0767s/iter; left time: 1599.9896s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747769\n",
      "\tspeed: 0.0415s/iter; left time: 861.0585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0749858 Vali Loss: 0.0884487 Test Loss: 0.1012087\n",
      "Validation loss decreased (0.088505 --> 0.088449).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772606\n",
      "\tspeed: 0.0781s/iter; left time: 1611.0026s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730566\n",
      "\tspeed: 0.0413s/iter; left time: 847.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0745392 Vali Loss: 0.0878225 Test Loss: 0.1004115\n",
      "Validation loss decreased (0.088449 --> 0.087823).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0728021\n",
      "\tspeed: 0.0764s/iter; left time: 1560.4706s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704910\n",
      "\tspeed: 0.0421s/iter; left time: 855.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0741072 Vali Loss: 0.0878454 Test Loss: 0.0995688\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0727380\n",
      "\tspeed: 0.0741s/iter; left time: 1497.3165s\n",
      "\titers: 200, epoch: 10 | loss: 0.0768265\n",
      "\tspeed: 0.0429s/iter; left time: 862.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 223 | Train Loss: 0.0736922 Vali Loss: 0.0878476 Test Loss: 0.1003193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0790198\n",
      "\tspeed: 0.0768s/iter; left time: 1532.9696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737132\n",
      "\tspeed: 0.0415s/iter; left time: 823.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0733805 Vali Loss: 0.0875606 Test Loss: 0.1003940\n",
      "Validation loss decreased (0.087823 --> 0.087561).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0658553\n",
      "\tspeed: 0.0744s/iter; left time: 1469.1125s\n",
      "\titers: 200, epoch: 12 | loss: 0.0785903\n",
      "\tspeed: 0.0411s/iter; left time: 807.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0731744 Vali Loss: 0.0876214 Test Loss: 0.0995508\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719233\n",
      "\tspeed: 0.0767s/iter; left time: 1498.4702s\n",
      "\titers: 200, epoch: 13 | loss: 0.0742535\n",
      "\tspeed: 0.0416s/iter; left time: 808.2278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0729265 Vali Loss: 0.0874835 Test Loss: 0.0995281\n",
      "Validation loss decreased (0.087561 --> 0.087484).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0725279\n",
      "\tspeed: 0.0758s/iter; left time: 1464.0409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0729276\n",
      "\tspeed: 0.0411s/iter; left time: 788.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 223 | Train Loss: 0.0727757 Vali Loss: 0.0875945 Test Loss: 0.0995237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0727914\n",
      "\tspeed: 0.0749s/iter; left time: 1429.1084s\n",
      "\titers: 200, epoch: 15 | loss: 0.0719108\n",
      "\tspeed: 0.0424s/iter; left time: 804.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0725818 Vali Loss: 0.0873662 Test Loss: 0.0992842\n",
      "Validation loss decreased (0.087484 --> 0.087366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0703028\n",
      "\tspeed: 0.0752s/iter; left time: 1418.1670s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679876\n",
      "\tspeed: 0.0425s/iter; left time: 797.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0724623 Vali Loss: 0.0873758 Test Loss: 0.0991852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0762972\n",
      "\tspeed: 0.0754s/iter; left time: 1404.1466s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740745\n",
      "\tspeed: 0.0412s/iter; left time: 763.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.38s\n",
      "Steps: 223 | Train Loss: 0.0722771 Vali Loss: 0.0871907 Test Loss: 0.0993153\n",
      "Validation loss decreased (0.087366 --> 0.087191).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713437\n",
      "\tspeed: 0.0771s/iter; left time: 1419.2108s\n",
      "\titers: 200, epoch: 18 | loss: 0.0711351\n",
      "\tspeed: 0.0411s/iter; left time: 752.6492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.37s\n",
      "Steps: 223 | Train Loss: 0.0721830 Vali Loss: 0.0871974 Test Loss: 0.0992790\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0728786\n",
      "\tspeed: 0.0752s/iter; left time: 1366.7758s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766083\n",
      "\tspeed: 0.0418s/iter; left time: 756.3165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0720670 Vali Loss: 0.0873282 Test Loss: 0.0991362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0707023\n",
      "\tspeed: 0.0757s/iter; left time: 1360.3913s\n",
      "\titers: 200, epoch: 20 | loss: 0.0659706\n",
      "\tspeed: 0.0420s/iter; left time: 751.0556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0719200 Vali Loss: 0.0872897 Test Loss: 0.0990334\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683376\n",
      "\tspeed: 0.0744s/iter; left time: 1319.2726s\n",
      "\titers: 200, epoch: 21 | loss: 0.0744315\n",
      "\tspeed: 0.0418s/iter; left time: 738.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0718971 Vali Loss: 0.0872003 Test Loss: 0.0991050\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723205\n",
      "\tspeed: 0.0751s/iter; left time: 1315.7646s\n",
      "\titers: 200, epoch: 22 | loss: 0.0718565\n",
      "\tspeed: 0.0412s/iter; left time: 717.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.39s\n",
      "Steps: 223 | Train Loss: 0.0717617 Vali Loss: 0.0871217 Test Loss: 0.0991213\n",
      "Validation loss decreased (0.087191 --> 0.087122).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0754515\n",
      "\tspeed: 0.0776s/iter; left time: 1341.6347s\n",
      "\titers: 200, epoch: 23 | loss: 0.0666656\n",
      "\tspeed: 0.0417s/iter; left time: 716.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0717673 Vali Loss: 0.0870475 Test Loss: 0.0990244\n",
      "Validation loss decreased (0.087122 --> 0.087047).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0736613\n",
      "\tspeed: 0.0762s/iter; left time: 1300.7520s\n",
      "\titers: 200, epoch: 24 | loss: 0.0732239\n",
      "\tspeed: 0.0417s/iter; left time: 708.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716505 Vali Loss: 0.0871460 Test Loss: 0.0991912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0745001\n",
      "\tspeed: 0.0744s/iter; left time: 1253.5139s\n",
      "\titers: 200, epoch: 25 | loss: 0.0714629\n",
      "\tspeed: 0.0430s/iter; left time: 719.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0716034 Vali Loss: 0.0873583 Test Loss: 0.0990945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680236\n",
      "\tspeed: 0.0750s/iter; left time: 1246.2728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0676734\n",
      "\tspeed: 0.0411s/iter; left time: 679.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0715778 Vali Loss: 0.0872454 Test Loss: 0.0990852\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0735137\n",
      "\tspeed: 0.0766s/iter; left time: 1255.7564s\n",
      "\titers: 200, epoch: 27 | loss: 0.0742956\n",
      "\tspeed: 0.0412s/iter; left time: 671.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 223 | Train Loss: 0.0714903 Vali Loss: 0.0869934 Test Loss: 0.0989545\n",
      "Validation loss decreased (0.087047 --> 0.086993).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0663206\n",
      "\tspeed: 0.0771s/iter; left time: 1247.1326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0772928\n",
      "\tspeed: 0.0411s/iter; left time: 660.3537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0714377 Vali Loss: 0.0872516 Test Loss: 0.0991254\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742304\n",
      "\tspeed: 0.0751s/iter; left time: 1197.9225s\n",
      "\titers: 200, epoch: 29 | loss: 0.0696663\n",
      "\tspeed: 0.0418s/iter; left time: 663.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714469 Vali Loss: 0.0871852 Test Loss: 0.0990446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0752319\n",
      "\tspeed: 0.0737s/iter; left time: 1160.2209s\n",
      "\titers: 200, epoch: 30 | loss: 0.0767607\n",
      "\tspeed: 0.0421s/iter; left time: 657.6439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0714359 Vali Loss: 0.0872758 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0697839\n",
      "\tspeed: 0.0761s/iter; left time: 1180.0293s\n",
      "\titers: 200, epoch: 31 | loss: 0.0737064\n",
      "\tspeed: 0.0418s/iter; left time: 644.8325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0713810 Vali Loss: 0.0870711 Test Loss: 0.0990327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0747602\n",
      "\tspeed: 0.0786s/iter; left time: 1201.8673s\n",
      "\titers: 200, epoch: 32 | loss: 0.0749984\n",
      "\tspeed: 0.0408s/iter; left time: 620.2149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.34s\n",
      "Steps: 223 | Train Loss: 0.0713382 Vali Loss: 0.0871204 Test Loss: 0.0990219\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0712683\n",
      "\tspeed: 0.0751s/iter; left time: 1130.8837s\n",
      "\titers: 200, epoch: 33 | loss: 0.0691796\n",
      "\tspeed: 0.0413s/iter; left time: 618.4426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0713131 Vali Loss: 0.0871258 Test Loss: 0.0989417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0684355\n",
      "\tspeed: 0.0743s/iter; left time: 1103.0916s\n",
      "\titers: 200, epoch: 34 | loss: 0.0734600\n",
      "\tspeed: 0.0426s/iter; left time: 627.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.62s\n",
      "Steps: 223 | Train Loss: 0.0713078 Vali Loss: 0.0871348 Test Loss: 0.0989215\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0735072\n",
      "\tspeed: 0.0742s/iter; left time: 1084.6726s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741483\n",
      "\tspeed: 0.0473s/iter; left time: 686.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.01s\n",
      "Steps: 223 | Train Loss: 0.0713056 Vali Loss: 0.0871275 Test Loss: 0.0989961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0728918\n",
      "\tspeed: 0.0826s/iter; left time: 1188.9078s\n",
      "\titers: 200, epoch: 36 | loss: 0.0666929\n",
      "\tspeed: 0.0412s/iter; left time: 589.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0712683 Vali Loss: 0.0871395 Test Loss: 0.0990887\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0745390\n",
      "\tspeed: 0.0750s/iter; left time: 1062.3159s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715760\n",
      "\tspeed: 0.0411s/iter; left time: 578.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:09.40s\n",
      "Steps: 223 | Train Loss: 0.0712489 Vali Loss: 0.0871422 Test Loss: 0.0990047\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02461354248225689, rmse:0.15688703954219818, mae:0.09895447641611099, rse:0.5412158370018005\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1241236\n",
      "\tspeed: 0.0443s/iter; left time: 984.5030s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141754\n",
      "\tspeed: 0.0409s/iter; left time: 903.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.1244885 Vali Loss: 0.1183953 Test Loss: 0.1381955\n",
      "Validation loss decreased (inf --> 0.118395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0812800\n",
      "\tspeed: 0.0752s/iter; left time: 1651.8621s\n",
      "\titers: 200, epoch: 2 | loss: 0.0813031\n",
      "\tspeed: 0.0428s/iter; left time: 935.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0860217 Vali Loss: 0.0911778 Test Loss: 0.1037141\n",
      "Validation loss decreased (0.118395 --> 0.091178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0854152\n",
      "\tspeed: 0.0753s/iter; left time: 1638.5817s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821180\n",
      "\tspeed: 0.0424s/iter; left time: 918.0883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0792323 Vali Loss: 0.0901997 Test Loss: 0.1024127\n",
      "Validation loss decreased (0.091178 --> 0.090200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0771382\n",
      "\tspeed: 0.0779s/iter; left time: 1677.9186s\n",
      "\titers: 200, epoch: 4 | loss: 0.0748695\n",
      "\tspeed: 0.0417s/iter; left time: 892.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0776143 Vali Loss: 0.0893536 Test Loss: 0.1021961\n",
      "Validation loss decreased (0.090200 --> 0.089354).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0746484\n",
      "\tspeed: 0.0788s/iter; left time: 1679.8393s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762351\n",
      "\tspeed: 0.0423s/iter; left time: 897.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0765393 Vali Loss: 0.0895949 Test Loss: 0.1016256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0704589\n",
      "\tspeed: 0.0762s/iter; left time: 1607.5950s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779320\n",
      "\tspeed: 0.0453s/iter; left time: 949.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.96s\n",
      "Steps: 223 | Train Loss: 0.0757048 Vali Loss: 0.0887313 Test Loss: 0.1005883\n",
      "Validation loss decreased (0.089354 --> 0.088731).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787142\n",
      "\tspeed: 0.0764s/iter; left time: 1594.4792s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723651\n",
      "\tspeed: 0.0421s/iter; left time: 874.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0752229 Vali Loss: 0.0888143 Test Loss: 0.1010623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749634\n",
      "\tspeed: 0.0752s/iter; left time: 1552.5956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0779372\n",
      "\tspeed: 0.0415s/iter; left time: 851.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 223 | Train Loss: 0.0746250 Vali Loss: 0.0880766 Test Loss: 0.0999531\n",
      "Validation loss decreased (0.088731 --> 0.088077).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0755208\n",
      "\tspeed: 0.0779s/iter; left time: 1590.5388s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692909\n",
      "\tspeed: 0.0418s/iter; left time: 848.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0741197 Vali Loss: 0.0877385 Test Loss: 0.1002419\n",
      "Validation loss decreased (0.088077 --> 0.087739).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735870\n",
      "\tspeed: 0.0833s/iter; left time: 1682.1019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762803\n",
      "\tspeed: 0.0456s/iter; left time: 915.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 223 | Train Loss: 0.0737935 Vali Loss: 0.0875983 Test Loss: 0.0999065\n",
      "Validation loss decreased (0.087739 --> 0.087598).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0739966\n",
      "\tspeed: 0.0797s/iter; left time: 1590.8784s\n",
      "\titers: 200, epoch: 11 | loss: 0.0750790\n",
      "\tspeed: 0.0411s/iter; left time: 817.6321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 223 | Train Loss: 0.0734880 Vali Loss: 0.0874614 Test Loss: 0.0996489\n",
      "Validation loss decreased (0.087598 --> 0.087461).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0765056\n",
      "\tspeed: 0.0749s/iter; left time: 1479.6047s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719574\n",
      "\tspeed: 0.0430s/iter; left time: 844.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0731832 Vali Loss: 0.0875553 Test Loss: 0.0998995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0682084\n",
      "\tspeed: 0.0759s/iter; left time: 1482.3639s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720051\n",
      "\tspeed: 0.0425s/iter; left time: 825.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0729966 Vali Loss: 0.0875060 Test Loss: 0.0998122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706566\n",
      "\tspeed: 0.0761s/iter; left time: 1468.0225s\n",
      "\titers: 200, epoch: 14 | loss: 0.0754816\n",
      "\tspeed: 0.0429s/iter; left time: 823.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.55s\n",
      "Steps: 223 | Train Loss: 0.0728083 Vali Loss: 0.0875992 Test Loss: 0.0995544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706279\n",
      "\tspeed: 0.0773s/iter; left time: 1475.5315s\n",
      "\titers: 200, epoch: 15 | loss: 0.0750840\n",
      "\tspeed: 0.0413s/iter; left time: 783.1734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0726432 Vali Loss: 0.0872414 Test Loss: 0.0996507\n",
      "Validation loss decreased (0.087461 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0797694\n",
      "\tspeed: 0.0765s/iter; left time: 1442.0772s\n",
      "\titers: 200, epoch: 16 | loss: 0.0691095\n",
      "\tspeed: 0.0415s/iter; left time: 778.3577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 223 | Train Loss: 0.0724336 Vali Loss: 0.0874647 Test Loss: 0.0995680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0743775\n",
      "\tspeed: 0.0749s/iter; left time: 1394.9423s\n",
      "\titers: 200, epoch: 17 | loss: 0.0741325\n",
      "\tspeed: 0.0427s/iter; left time: 790.5807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0723469 Vali Loss: 0.0873769 Test Loss: 0.0993158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726027\n",
      "\tspeed: 0.0748s/iter; left time: 1377.1837s\n",
      "\titers: 200, epoch: 18 | loss: 0.0659239\n",
      "\tspeed: 0.0414s/iter; left time: 757.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:09.43s\n",
      "Steps: 223 | Train Loss: 0.0721854 Vali Loss: 0.0872896 Test Loss: 0.0991555\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711987\n",
      "\tspeed: 0.0784s/iter; left time: 1426.3078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0673086\n",
      "\tspeed: 0.0418s/iter; left time: 756.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0721364 Vali Loss: 0.0871735 Test Loss: 0.0992202\n",
      "Validation loss decreased (0.087241 --> 0.087173).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731464\n",
      "\tspeed: 0.0767s/iter; left time: 1378.0725s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776331\n",
      "\tspeed: 0.0412s/iter; left time: 736.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 223 | Train Loss: 0.0720103 Vali Loss: 0.0872837 Test Loss: 0.0991743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0711740\n",
      "\tspeed: 0.0755s/iter; left time: 1339.7905s\n",
      "\titers: 200, epoch: 21 | loss: 0.0753554\n",
      "\tspeed: 0.0427s/iter; left time: 752.5130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 223 | Train Loss: 0.0719040 Vali Loss: 0.0871968 Test Loss: 0.0992067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0715744\n",
      "\tspeed: 0.0759s/iter; left time: 1328.8578s\n",
      "\titers: 200, epoch: 22 | loss: 0.0681315\n",
      "\tspeed: 0.0428s/iter; left time: 744.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 223 | Train Loss: 0.0718549 Vali Loss: 0.0871228 Test Loss: 0.0991327\n",
      "Validation loss decreased (0.087173 --> 0.087123).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0704514\n",
      "\tspeed: 0.0766s/iter; left time: 1323.9731s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714713\n",
      "\tspeed: 0.0415s/iter; left time: 713.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.44s\n",
      "Steps: 223 | Train Loss: 0.0717374 Vali Loss: 0.0870542 Test Loss: 0.0989956\n",
      "Validation loss decreased (0.087123 --> 0.087054).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0751139\n",
      "\tspeed: 0.0781s/iter; left time: 1332.4945s\n",
      "\titers: 200, epoch: 24 | loss: 0.0752301\n",
      "\tspeed: 0.0419s/iter; left time: 711.1909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 223 | Train Loss: 0.0716789 Vali Loss: 0.0870215 Test Loss: 0.0990368\n",
      "Validation loss decreased (0.087054 --> 0.087022).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0707601\n",
      "\tspeed: 0.0786s/iter; left time: 1324.3908s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697482\n",
      "\tspeed: 0.0426s/iter; left time: 713.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:09.82s\n",
      "Steps: 223 | Train Loss: 0.0716772 Vali Loss: 0.0870498 Test Loss: 0.0989855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0707332\n",
      "\tspeed: 0.0748s/iter; left time: 1242.8210s\n",
      "\titers: 200, epoch: 26 | loss: 0.0765021\n",
      "\tspeed: 0.0425s/iter; left time: 702.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0716127 Vali Loss: 0.0868681 Test Loss: 0.0989585\n",
      "Validation loss decreased (0.087022 --> 0.086868).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0703442\n",
      "\tspeed: 0.0753s/iter; left time: 1234.9448s\n",
      "\titers: 200, epoch: 27 | loss: 0.0724373\n",
      "\tspeed: 0.0416s/iter; left time: 677.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 223 | Train Loss: 0.0715412 Vali Loss: 0.0870464 Test Loss: 0.0989664\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0742472\n",
      "\tspeed: 0.0774s/iter; left time: 1252.0073s\n",
      "\titers: 200, epoch: 28 | loss: 0.0691978\n",
      "\tspeed: 0.0415s/iter; left time: 666.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 223 | Train Loss: 0.0714920 Vali Loss: 0.0870631 Test Loss: 0.0991097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0707679\n",
      "\tspeed: 0.0762s/iter; left time: 1216.6364s\n",
      "\titers: 200, epoch: 29 | loss: 0.0695740\n",
      "\tspeed: 0.0421s/iter; left time: 667.9641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0714264 Vali Loss: 0.0870037 Test Loss: 0.0989200\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0688290\n",
      "\tspeed: 0.0779s/iter; left time: 1225.5661s\n",
      "\titers: 200, epoch: 30 | loss: 0.0660956\n",
      "\tspeed: 0.0414s/iter; left time: 647.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 223 | Train Loss: 0.0714084 Vali Loss: 0.0869053 Test Loss: 0.0989998\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0729475\n",
      "\tspeed: 0.0776s/iter; left time: 1204.0116s\n",
      "\titers: 200, epoch: 31 | loss: 0.0695744\n",
      "\tspeed: 0.0431s/iter; left time: 664.9611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 223 | Train Loss: 0.0713882 Vali Loss: 0.0870360 Test Loss: 0.0989691\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0672238\n",
      "\tspeed: 0.0760s/iter; left time: 1162.2643s\n",
      "\titers: 200, epoch: 32 | loss: 0.0767676\n",
      "\tspeed: 0.0418s/iter; left time: 634.6739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 223 | Train Loss: 0.0714459 Vali Loss: 0.0869485 Test Loss: 0.0989849\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0716598\n",
      "\tspeed: 0.0799s/iter; left time: 1203.7757s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718821\n",
      "\tspeed: 0.0415s/iter; left time: 621.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 223 | Train Loss: 0.0713694 Vali Loss: 0.0869131 Test Loss: 0.0990300\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0780078\n",
      "\tspeed: 0.0773s/iter; left time: 1147.5751s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725512\n",
      "\tspeed: 0.0423s/iter; left time: 623.3525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:09.72s\n",
      "Steps: 223 | Train Loss: 0.0713690 Vali Loss: 0.0870174 Test Loss: 0.0990362\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0721319\n",
      "\tspeed: 0.0758s/iter; left time: 1108.1308s\n",
      "\titers: 200, epoch: 35 | loss: 0.0699476\n",
      "\tspeed: 0.0417s/iter; left time: 605.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 223 | Train Loss: 0.0713216 Vali Loss: 0.0868933 Test Loss: 0.0989647\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0715593\n",
      "\tspeed: 0.0743s/iter; left time: 1068.9621s\n",
      "\titers: 200, epoch: 36 | loss: 0.0704235\n",
      "\tspeed: 0.0422s/iter; left time: 603.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 223 | Train Loss: 0.0713195 Vali Loss: 0.0871119 Test Loss: 0.0989298\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024664107710123062, rmse:0.15704810619354248, mae:0.09895854443311691, rse:0.5417714715003967\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:36.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1304873\n",
      "\tspeed: 0.0668s/iter; left time: 1476.8440s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175975\n",
      "\tspeed: 0.0416s/iter; left time: 914.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1310178 Vali Loss: 0.1288243 Test Loss: 0.1522491\n",
      "Validation loss decreased (inf --> 0.128824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1069379\n",
      "\tspeed: 0.0775s/iter; left time: 1694.8193s\n",
      "\titers: 200, epoch: 2 | loss: 0.1099608\n",
      "\tspeed: 0.0416s/iter; left time: 905.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1079090 Vali Loss: 0.1167949 Test Loss: 0.1385253\n",
      "Validation loss decreased (0.128824 --> 0.116795).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1021708\n",
      "\tspeed: 0.0785s/iter; left time: 1699.0059s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059996\n",
      "\tspeed: 0.0429s/iter; left time: 924.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1029873 Vali Loss: 0.1158553 Test Loss: 0.1394041\n",
      "Validation loss decreased (0.116795 --> 0.115855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966939\n",
      "\tspeed: 0.0764s/iter; left time: 1638.0518s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026029\n",
      "\tspeed: 0.0422s/iter; left time: 900.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1014688 Vali Loss: 0.1153081 Test Loss: 0.1391761\n",
      "Validation loss decreased (0.115855 --> 0.115308).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1027995\n",
      "\tspeed: 0.0787s/iter; left time: 1669.7876s\n",
      "\titers: 200, epoch: 5 | loss: 0.1021266\n",
      "\tspeed: 0.0419s/iter; left time: 885.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004789 Vali Loss: 0.1146756 Test Loss: 0.1379868\n",
      "Validation loss decreased (0.115308 --> 0.114676).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0975265\n",
      "\tspeed: 0.0800s/iter; left time: 1679.8588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0993915\n",
      "\tspeed: 0.0419s/iter; left time: 875.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.78s\n",
      "Steps: 222 | Train Loss: 0.0995412 Vali Loss: 0.1150273 Test Loss: 0.1383243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0968614\n",
      "\tspeed: 0.0781s/iter; left time: 1622.8290s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959852\n",
      "\tspeed: 0.0430s/iter; left time: 888.5696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.75s\n",
      "Steps: 222 | Train Loss: 0.0986773 Vali Loss: 0.1150765 Test Loss: 0.1379591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0994884\n",
      "\tspeed: 0.0775s/iter; left time: 1591.3927s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979322\n",
      "\tspeed: 0.0417s/iter; left time: 852.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0979208 Vali Loss: 0.1156444 Test Loss: 0.1380379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0953856\n",
      "\tspeed: 0.0769s/iter; left time: 1563.0344s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962101\n",
      "\tspeed: 0.0413s/iter; left time: 836.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0971903 Vali Loss: 0.1157434 Test Loss: 0.1375536\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941000\n",
      "\tspeed: 0.0782s/iter; left time: 1573.0348s\n",
      "\titers: 200, epoch: 10 | loss: 0.0939218\n",
      "\tspeed: 0.0415s/iter; left time: 829.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.0965265 Vali Loss: 0.1158402 Test Loss: 0.1391500\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0948607\n",
      "\tspeed: 0.0780s/iter; left time: 1551.6565s\n",
      "\titers: 200, epoch: 11 | loss: 0.0935992\n",
      "\tspeed: 0.0417s/iter; left time: 824.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0959107 Vali Loss: 0.1162248 Test Loss: 0.1396610\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0920896\n",
      "\tspeed: 0.0750s/iter; left time: 1474.6129s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940504\n",
      "\tspeed: 0.0425s/iter; left time: 830.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0953595 Vali Loss: 0.1159682 Test Loss: 0.1396242\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0913273\n",
      "\tspeed: 0.0759s/iter; left time: 1476.0173s\n",
      "\titers: 200, epoch: 13 | loss: 0.0974089\n",
      "\tspeed: 0.0413s/iter; left time: 798.9269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0947790 Vali Loss: 0.1162849 Test Loss: 0.1413390\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0933513\n",
      "\tspeed: 0.0777s/iter; left time: 1493.3694s\n",
      "\titers: 200, epoch: 14 | loss: 0.0954880\n",
      "\tspeed: 0.0418s/iter; left time: 799.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.46s\n",
      "Steps: 222 | Train Loss: 0.0943125 Vali Loss: 0.1169559 Test Loss: 0.1414862\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0993926\n",
      "\tspeed: 0.0776s/iter; left time: 1474.3737s\n",
      "\titers: 200, epoch: 15 | loss: 0.0961179\n",
      "\tspeed: 0.0415s/iter; left time: 783.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.0938692 Vali Loss: 0.1164688 Test Loss: 0.1422094\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.040224574506282806, rmse:0.20056064426898956, mae:0.13798677921295166, rse:0.6935666799545288\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1305858\n",
      "\tspeed: 0.0446s/iter; left time: 986.5156s\n",
      "\titers: 200, epoch: 1 | loss: 0.1279940\n",
      "\tspeed: 0.0419s/iter; left time: 920.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1310129 Vali Loss: 0.1287763 Test Loss: 0.1517726\n",
      "Validation loss decreased (inf --> 0.128776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1047999\n",
      "\tspeed: 0.0773s/iter; left time: 1691.8110s\n",
      "\titers: 200, epoch: 2 | loss: 0.1011871\n",
      "\tspeed: 0.0423s/iter; left time: 922.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1081233 Vali Loss: 0.1171175 Test Loss: 0.1384159\n",
      "Validation loss decreased (0.128776 --> 0.117118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041322\n",
      "\tspeed: 0.0768s/iter; left time: 1662.2105s\n",
      "\titers: 200, epoch: 3 | loss: 0.0997675\n",
      "\tspeed: 0.0435s/iter; left time: 936.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.1030756 Vali Loss: 0.1154505 Test Loss: 0.1378653\n",
      "Validation loss decreased (0.117118 --> 0.115451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1052338\n",
      "\tspeed: 0.0782s/iter; left time: 1676.5682s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011579\n",
      "\tspeed: 0.0418s/iter; left time: 891.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.58s\n",
      "Steps: 222 | Train Loss: 0.1016301 Vali Loss: 0.1150195 Test Loss: 0.1379458\n",
      "Validation loss decreased (0.115451 --> 0.115019).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0983982\n",
      "\tspeed: 0.0802s/iter; left time: 1702.1037s\n",
      "\titers: 200, epoch: 5 | loss: 0.0970867\n",
      "\tspeed: 0.0416s/iter; left time: 877.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.1004418 Vali Loss: 0.1147584 Test Loss: 0.1383713\n",
      "Validation loss decreased (0.115019 --> 0.114758).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1006362\n",
      "\tspeed: 0.0793s/iter; left time: 1664.9695s\n",
      "\titers: 200, epoch: 6 | loss: 0.0965790\n",
      "\tspeed: 0.0416s/iter; left time: 868.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0992838 Vali Loss: 0.1148322 Test Loss: 0.1393588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966187\n",
      "\tspeed: 0.0767s/iter; left time: 1593.1368s\n",
      "\titers: 200, epoch: 7 | loss: 0.0989298\n",
      "\tspeed: 0.0425s/iter; left time: 878.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0983812 Vali Loss: 0.1146387 Test Loss: 0.1399318\n",
      "Validation loss decreased (0.114758 --> 0.114639).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0930875\n",
      "\tspeed: 0.0778s/iter; left time: 1598.6296s\n",
      "\titers: 200, epoch: 8 | loss: 0.0929199\n",
      "\tspeed: 0.0429s/iter; left time: 877.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.0972934 Vali Loss: 0.1146473 Test Loss: 0.1403886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951188\n",
      "\tspeed: 0.0772s/iter; left time: 1568.9761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0949333\n",
      "\tspeed: 0.0414s/iter; left time: 838.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0964337 Vali Loss: 0.1151828 Test Loss: 0.1416367\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989180\n",
      "\tspeed: 0.0785s/iter; left time: 1577.9541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0938160\n",
      "\tspeed: 0.0416s/iter; left time: 831.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.47s\n",
      "Steps: 222 | Train Loss: 0.0956362 Vali Loss: 0.1152233 Test Loss: 0.1418035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0915988\n",
      "\tspeed: 0.0785s/iter; left time: 1560.3960s\n",
      "\titers: 200, epoch: 11 | loss: 0.0964191\n",
      "\tspeed: 0.0415s/iter; left time: 820.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.0949925 Vali Loss: 0.1158287 Test Loss: 0.1423944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0963742\n",
      "\tspeed: 0.0773s/iter; left time: 1519.4097s\n",
      "\titers: 200, epoch: 12 | loss: 0.0933959\n",
      "\tspeed: 0.0423s/iter; left time: 827.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.0941572 Vali Loss: 0.1160542 Test Loss: 0.1424110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961953\n",
      "\tspeed: 0.0762s/iter; left time: 1480.6556s\n",
      "\titers: 200, epoch: 13 | loss: 0.0965029\n",
      "\tspeed: 0.0421s/iter; left time: 814.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.49s\n",
      "Steps: 222 | Train Loss: 0.0936945 Vali Loss: 0.1154687 Test Loss: 0.1416178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0912792\n",
      "\tspeed: 0.0774s/iter; left time: 1486.3895s\n",
      "\titers: 200, epoch: 14 | loss: 0.0940753\n",
      "\tspeed: 0.0413s/iter; left time: 789.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0929719 Vali Loss: 0.1157708 Test Loss: 0.1427507\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0968269\n",
      "\tspeed: 0.0794s/iter; left time: 1507.9914s\n",
      "\titers: 200, epoch: 15 | loss: 0.0915315\n",
      "\tspeed: 0.0417s/iter; left time: 787.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.45s\n",
      "Steps: 222 | Train Loss: 0.0925117 Vali Loss: 0.1161520 Test Loss: 0.1430477\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0888845\n",
      "\tspeed: 0.0785s/iter; left time: 1474.0309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0930691\n",
      "\tspeed: 0.0414s/iter; left time: 772.2440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:09.65s\n",
      "Steps: 222 | Train Loss: 0.0921011 Vali Loss: 0.1164447 Test Loss: 0.1432250\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0904549\n",
      "\tspeed: 0.0771s/iter; left time: 1431.0215s\n",
      "\titers: 200, epoch: 17 | loss: 0.0925897\n",
      "\tspeed: 0.0430s/iter; left time: 792.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.0916482 Vali Loss: 0.1165479 Test Loss: 0.1434288\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041966523975133896, rmse:0.20485731959342957, mae:0.13993188738822937, rse:0.7084251642227173\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:36.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1260497\n",
      "\tspeed: 0.0661s/iter; left time: 1461.0643s\n",
      "\titers: 200, epoch: 1 | loss: 0.1233853\n",
      "\tspeed: 0.0420s/iter; left time: 924.4995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.85s\n",
      "Steps: 222 | Train Loss: 0.1326778 Vali Loss: 0.1309269 Test Loss: 0.1548633\n",
      "Validation loss decreased (inf --> 0.130927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1094469\n",
      "\tspeed: 0.0794s/iter; left time: 1737.2973s\n",
      "\titers: 200, epoch: 2 | loss: 0.1086948\n",
      "\tspeed: 0.0417s/iter; left time: 908.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.60s\n",
      "Steps: 222 | Train Loss: 0.1121342 Vali Loss: 0.1213708 Test Loss: 0.1448956\n",
      "Validation loss decreased (0.130927 --> 0.121371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1085828\n",
      "\tspeed: 0.0805s/iter; left time: 1744.2921s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110668\n",
      "\tspeed: 0.0420s/iter; left time: 905.8066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1075699 Vali Loss: 0.1199603 Test Loss: 0.1443719\n",
      "Validation loss decreased (0.121371 --> 0.119960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1096162\n",
      "\tspeed: 0.0780s/iter; left time: 1671.4152s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028981\n",
      "\tspeed: 0.0438s/iter; left time: 934.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.71s\n",
      "Steps: 222 | Train Loss: 0.1060007 Vali Loss: 0.1197756 Test Loss: 0.1440592\n",
      "Validation loss decreased (0.119960 --> 0.119776).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043223\n",
      "\tspeed: 0.0785s/iter; left time: 1664.7745s\n",
      "\titers: 200, epoch: 5 | loss: 0.1071000\n",
      "\tspeed: 0.0431s/iter; left time: 908.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1046242 Vali Loss: 0.1203860 Test Loss: 0.1448624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994743\n",
      "\tspeed: 0.0777s/iter; left time: 1630.2978s\n",
      "\titers: 200, epoch: 6 | loss: 0.1044898\n",
      "\tspeed: 0.0422s/iter; left time: 881.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.53s\n",
      "Steps: 222 | Train Loss: 0.1033739 Vali Loss: 0.1210232 Test Loss: 0.1450372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1018771\n",
      "\tspeed: 0.0785s/iter; left time: 1630.0362s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027877\n",
      "\tspeed: 0.0421s/iter; left time: 869.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 222 | Train Loss: 0.1023430 Vali Loss: 0.1218093 Test Loss: 0.1471738\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995843\n",
      "\tspeed: 0.0778s/iter; left time: 1599.1551s\n",
      "\titers: 200, epoch: 8 | loss: 0.0966036\n",
      "\tspeed: 0.0417s/iter; left time: 853.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1014311 Vali Loss: 0.1216973 Test Loss: 0.1467350\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1010340\n",
      "\tspeed: 0.0765s/iter; left time: 1554.9552s\n",
      "\titers: 200, epoch: 9 | loss: 0.1001390\n",
      "\tspeed: 0.0433s/iter; left time: 875.0557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.1004857 Vali Loss: 0.1226195 Test Loss: 0.1462484\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983590\n",
      "\tspeed: 0.0768s/iter; left time: 1543.3019s\n",
      "\titers: 200, epoch: 10 | loss: 0.0999743\n",
      "\tspeed: 0.0422s/iter; left time: 844.8185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.0997015 Vali Loss: 0.1216679 Test Loss: 0.1459581\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1025495\n",
      "\tspeed: 0.0789s/iter; left time: 1567.7444s\n",
      "\titers: 200, epoch: 11 | loss: 0.0974560\n",
      "\tspeed: 0.0419s/iter; left time: 828.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.61s\n",
      "Steps: 222 | Train Loss: 0.0988213 Vali Loss: 0.1222738 Test Loss: 0.1464456\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1022936\n",
      "\tspeed: 0.0794s/iter; left time: 1561.1810s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971468\n",
      "\tspeed: 0.0421s/iter; left time: 823.0657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.69s\n",
      "Steps: 222 | Train Loss: 0.0980070 Vali Loss: 0.1221250 Test Loss: 0.1460842\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0957897\n",
      "\tspeed: 0.0791s/iter; left time: 1537.1685s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973659\n",
      "\tspeed: 0.0420s/iter; left time: 811.4997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.0972951 Vali Loss: 0.1227004 Test Loss: 0.1479962\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0920695\n",
      "\tspeed: 0.0766s/iter; left time: 1471.0401s\n",
      "\titers: 200, epoch: 14 | loss: 0.0948682\n",
      "\tspeed: 0.0431s/iter; left time: 823.2108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.0966523 Vali Loss: 0.1230309 Test Loss: 0.1473147\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04283905029296875, rmse:0.20697596669197083, mae:0.14405910670757294, rse:0.7176154255867004\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1354174\n",
      "\tspeed: 0.0440s/iter; left time: 971.9497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272134\n",
      "\tspeed: 0.0429s/iter; left time: 944.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.66s\n",
      "Steps: 222 | Train Loss: 0.1335480 Vali Loss: 0.1309509 Test Loss: 0.1545976\n",
      "Validation loss decreased (inf --> 0.130951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1133488\n",
      "\tspeed: 0.0801s/iter; left time: 1753.2463s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126153\n",
      "\tspeed: 0.0433s/iter; left time: 942.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.86s\n",
      "Steps: 222 | Train Loss: 0.1122327 Vali Loss: 0.1214331 Test Loss: 0.1448028\n",
      "Validation loss decreased (0.130951 --> 0.121433).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069784\n",
      "\tspeed: 0.0798s/iter; left time: 1727.5802s\n",
      "\titers: 200, epoch: 3 | loss: 0.1111818\n",
      "\tspeed: 0.0419s/iter; left time: 903.1948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 222 | Train Loss: 0.1077125 Vali Loss: 0.1202011 Test Loss: 0.1457766\n",
      "Validation loss decreased (0.121433 --> 0.120201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072374\n",
      "\tspeed: 0.0850s/iter; left time: 1821.7096s\n",
      "\titers: 200, epoch: 4 | loss: 0.1061509\n",
      "\tspeed: 0.0422s/iter; left time: 901.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.1062208 Vali Loss: 0.1202800 Test Loss: 0.1458177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077023\n",
      "\tspeed: 0.0798s/iter; left time: 1693.2286s\n",
      "\titers: 200, epoch: 5 | loss: 0.1043039\n",
      "\tspeed: 0.0420s/iter; left time: 886.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:09.76s\n",
      "Steps: 222 | Train Loss: 0.1048119 Vali Loss: 0.1204090 Test Loss: 0.1450815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1053132\n",
      "\tspeed: 0.0778s/iter; left time: 1633.7682s\n",
      "\titers: 200, epoch: 6 | loss: 0.1045556\n",
      "\tspeed: 0.0430s/iter; left time: 897.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 222 | Train Loss: 0.1033933 Vali Loss: 0.1211432 Test Loss: 0.1460922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1010433\n",
      "\tspeed: 0.0777s/iter; left time: 1614.5203s\n",
      "\titers: 200, epoch: 7 | loss: 0.0984273\n",
      "\tspeed: 0.0427s/iter; left time: 883.2299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.63s\n",
      "Steps: 222 | Train Loss: 0.1019883 Vali Loss: 0.1219406 Test Loss: 0.1475383\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1020061\n",
      "\tspeed: 0.0777s/iter; left time: 1596.4580s\n",
      "\titers: 200, epoch: 8 | loss: 0.0999632\n",
      "\tspeed: 0.0422s/iter; left time: 862.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.70s\n",
      "Steps: 222 | Train Loss: 0.1006895 Vali Loss: 0.1223867 Test Loss: 0.1473340\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0978350\n",
      "\tspeed: 0.0805s/iter; left time: 1636.4255s\n",
      "\titers: 200, epoch: 9 | loss: 0.0947712\n",
      "\tspeed: 0.0417s/iter; left time: 843.6268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.51s\n",
      "Steps: 222 | Train Loss: 0.0993827 Vali Loss: 0.1230524 Test Loss: 0.1467847\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0975076\n",
      "\tspeed: 0.0788s/iter; left time: 1583.7119s\n",
      "\titers: 200, epoch: 10 | loss: 0.0976299\n",
      "\tspeed: 0.0428s/iter; left time: 856.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.74s\n",
      "Steps: 222 | Train Loss: 0.0981397 Vali Loss: 0.1236404 Test Loss: 0.1466535\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0939989\n",
      "\tspeed: 0.0793s/iter; left time: 1575.7932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0989537\n",
      "\tspeed: 0.0428s/iter; left time: 846.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.80s\n",
      "Steps: 222 | Train Loss: 0.0970986 Vali Loss: 0.1238450 Test Loss: 0.1473410\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0958038\n",
      "\tspeed: 0.0792s/iter; left time: 1556.7527s\n",
      "\titers: 200, epoch: 12 | loss: 0.0997026\n",
      "\tspeed: 0.0424s/iter; left time: 829.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.64s\n",
      "Steps: 222 | Train Loss: 0.0961723 Vali Loss: 0.1241202 Test Loss: 0.1478169\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0963423\n",
      "\tspeed: 0.0793s/iter; left time: 1542.2571s\n",
      "\titers: 200, epoch: 13 | loss: 0.0922489\n",
      "\tspeed: 0.0446s/iter; left time: 861.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.90s\n",
      "Steps: 222 | Train Loss: 0.0953029 Vali Loss: 0.1242875 Test Loss: 0.1478923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0440988764166832, rmse:0.20999732613563538, mae:0.14577659964561462, rse:0.7280909419059753\n",
      "Intermediate time for GB and pred_len 168: 00h:05m:42.00s\n",
      "Intermediate time for GB: 00h:26m:55.22s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1177848\n",
      "\tspeed: 0.0475s/iter; left time: 1054.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1059930\n",
      "\tspeed: 0.0268s/iter; left time: 591.6345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.1258416 Vali Loss: 0.0933806 Test Loss: 0.1067235\n",
      "Validation loss decreased (inf --> 0.093381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721758\n",
      "\tspeed: 0.0526s/iter; left time: 1155.1685s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688074\n",
      "\tspeed: 0.0265s/iter; left time: 578.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0746695 Vali Loss: 0.0630054 Test Loss: 0.0701760\n",
      "Validation loss decreased (0.093381 --> 0.063005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640021\n",
      "\tspeed: 0.0541s/iter; left time: 1177.7243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631628\n",
      "\tspeed: 0.0266s/iter; left time: 575.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0643662 Vali Loss: 0.0596727 Test Loss: 0.0664817\n",
      "Validation loss decreased (0.063005 --> 0.059673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0633358\n",
      "\tspeed: 0.0522s/iter; left time: 1123.8531s\n",
      "\titers: 200, epoch: 4 | loss: 0.0598588\n",
      "\tspeed: 0.0274s/iter; left time: 587.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0616559 Vali Loss: 0.0577069 Test Loss: 0.0649258\n",
      "Validation loss decreased (0.059673 --> 0.057707).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0600730\n",
      "\tspeed: 0.0542s/iter; left time: 1154.8282s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604561\n",
      "\tspeed: 0.0269s/iter; left time: 569.8563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0598165 Vali Loss: 0.0575377 Test Loss: 0.0640054\n",
      "Validation loss decreased (0.057707 --> 0.057538).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0562785\n",
      "\tspeed: 0.0525s/iter; left time: 1107.4072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0579553\n",
      "\tspeed: 0.0270s/iter; left time: 566.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0587862 Vali Loss: 0.0562634 Test Loss: 0.0629574\n",
      "Validation loss decreased (0.057538 --> 0.056263).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542753\n",
      "\tspeed: 0.0552s/iter; left time: 1152.4921s\n",
      "\titers: 200, epoch: 7 | loss: 0.0573975\n",
      "\tspeed: 0.0267s/iter; left time: 554.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0578910 Vali Loss: 0.0557560 Test Loss: 0.0622238\n",
      "Validation loss decreased (0.056263 --> 0.055756).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0539824\n",
      "\tspeed: 0.0533s/iter; left time: 1100.2134s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542981\n",
      "\tspeed: 0.0279s/iter; left time: 572.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0572106 Vali Loss: 0.0555416 Test Loss: 0.0623640\n",
      "Validation loss decreased (0.055756 --> 0.055542).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0544912\n",
      "\tspeed: 0.0526s/iter; left time: 1073.0902s\n",
      "\titers: 200, epoch: 9 | loss: 0.0562044\n",
      "\tspeed: 0.0275s/iter; left time: 558.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0565972 Vali Loss: 0.0552657 Test Loss: 0.0625549\n",
      "Validation loss decreased (0.055542 --> 0.055266).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0573178\n",
      "\tspeed: 0.0530s/iter; left time: 1070.0248s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550786\n",
      "\tspeed: 0.0288s/iter; left time: 577.9575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0561248 Vali Loss: 0.0548072 Test Loss: 0.0617649\n",
      "Validation loss decreased (0.055266 --> 0.054807).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0549671\n",
      "\tspeed: 0.0519s/iter; left time: 1037.4837s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561140\n",
      "\tspeed: 0.0264s/iter; left time: 525.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0556483 Vali Loss: 0.0546315 Test Loss: 0.0615806\n",
      "Validation loss decreased (0.054807 --> 0.054632).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561196\n",
      "\tspeed: 0.0520s/iter; left time: 1025.9605s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555787\n",
      "\tspeed: 0.0272s/iter; left time: 533.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0552293 Vali Loss: 0.0543794 Test Loss: 0.0613876\n",
      "Validation loss decreased (0.054632 --> 0.054379).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533709\n",
      "\tspeed: 0.0533s/iter; left time: 1041.6509s\n",
      "\titers: 200, epoch: 13 | loss: 0.0539893\n",
      "\tspeed: 0.0267s/iter; left time: 517.7904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0549254 Vali Loss: 0.0543318 Test Loss: 0.0609576\n",
      "Validation loss decreased (0.054379 --> 0.054332).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530030\n",
      "\tspeed: 0.0521s/iter; left time: 1006.1253s\n",
      "\titers: 200, epoch: 14 | loss: 0.0533630\n",
      "\tspeed: 0.0285s/iter; left time: 547.7245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0545588 Vali Loss: 0.0541453 Test Loss: 0.0611451\n",
      "Validation loss decreased (0.054332 --> 0.054145).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500635\n",
      "\tspeed: 0.0516s/iter; left time: 985.3657s\n",
      "\titers: 200, epoch: 15 | loss: 0.0591192\n",
      "\tspeed: 0.0266s/iter; left time: 504.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0543057 Vali Loss: 0.0539221 Test Loss: 0.0611182\n",
      "Validation loss decreased (0.054145 --> 0.053922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0566576\n",
      "\tspeed: 0.0524s/iter; left time: 987.9545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0502781\n",
      "\tspeed: 0.0268s/iter; left time: 502.5444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0540829 Vali Loss: 0.0538061 Test Loss: 0.0607462\n",
      "Validation loss decreased (0.053922 --> 0.053806).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0566290\n",
      "\tspeed: 0.0521s/iter; left time: 971.4521s\n",
      "\titers: 200, epoch: 17 | loss: 0.0503884\n",
      "\tspeed: 0.0265s/iter; left time: 490.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0539302 Vali Loss: 0.0534953 Test Loss: 0.0605199\n",
      "Validation loss decreased (0.053806 --> 0.053495).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572149\n",
      "\tspeed: 0.0537s/iter; left time: 988.0298s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543917\n",
      "\tspeed: 0.0265s/iter; left time: 485.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0537375 Vali Loss: 0.0535588 Test Loss: 0.0605998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0552805\n",
      "\tspeed: 0.0514s/iter; left time: 935.1159s\n",
      "\titers: 200, epoch: 19 | loss: 0.0523237\n",
      "\tspeed: 0.0263s/iter; left time: 474.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0535796 Vali Loss: 0.0535295 Test Loss: 0.0603616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0545848\n",
      "\tspeed: 0.0537s/iter; left time: 965.2525s\n",
      "\titers: 200, epoch: 20 | loss: 0.0549286\n",
      "\tspeed: 0.0268s/iter; left time: 478.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0534138 Vali Loss: 0.0532950 Test Loss: 0.0604182\n",
      "Validation loss decreased (0.053495 --> 0.053295).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0529836\n",
      "\tspeed: 0.0532s/iter; left time: 944.3567s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538217\n",
      "\tspeed: 0.0264s/iter; left time: 465.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533455 Vali Loss: 0.0530735 Test Loss: 0.0601349\n",
      "Validation loss decreased (0.053295 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0533596\n",
      "\tspeed: 0.0563s/iter; left time: 986.5509s\n",
      "\titers: 200, epoch: 22 | loss: 0.0551906\n",
      "\tspeed: 0.0264s/iter; left time: 459.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0531747 Vali Loss: 0.0531457 Test Loss: 0.0603495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0533368\n",
      "\tspeed: 0.0512s/iter; left time: 885.7195s\n",
      "\titers: 200, epoch: 23 | loss: 0.0566950\n",
      "\tspeed: 0.0280s/iter; left time: 481.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0530683 Vali Loss: 0.0531179 Test Loss: 0.0601824\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560505\n",
      "\tspeed: 0.0540s/iter; left time: 922.4103s\n",
      "\titers: 200, epoch: 24 | loss: 0.0509092\n",
      "\tspeed: 0.0274s/iter; left time: 465.6859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0529976 Vali Loss: 0.0531084 Test Loss: 0.0601074\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0558175\n",
      "\tspeed: 0.0519s/iter; left time: 873.8136s\n",
      "\titers: 200, epoch: 25 | loss: 0.0517861\n",
      "\tspeed: 0.0268s/iter; left time: 449.0302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0529033 Vali Loss: 0.0531205 Test Loss: 0.0602300\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513149\n",
      "\tspeed: 0.0511s/iter; left time: 849.6052s\n",
      "\titers: 200, epoch: 26 | loss: 0.0500016\n",
      "\tspeed: 0.0263s/iter; left time: 434.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0528154 Vali Loss: 0.0529059 Test Loss: 0.0601533\n",
      "Validation loss decreased (0.053073 --> 0.052906).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0518654\n",
      "\tspeed: 0.0519s/iter; left time: 851.0316s\n",
      "\titers: 200, epoch: 27 | loss: 0.0523646\n",
      "\tspeed: 0.0278s/iter; left time: 453.0433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0527788 Vali Loss: 0.0531640 Test Loss: 0.0602123\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0533427\n",
      "\tspeed: 0.0525s/iter; left time: 849.6665s\n",
      "\titers: 200, epoch: 28 | loss: 0.0546841\n",
      "\tspeed: 0.0264s/iter; left time: 424.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0527124 Vali Loss: 0.0528726 Test Loss: 0.0599036\n",
      "Validation loss decreased (0.052906 --> 0.052873).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0509959\n",
      "\tspeed: 0.0522s/iter; left time: 833.0148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0543811\n",
      "\tspeed: 0.0274s/iter; left time: 435.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0526367 Vali Loss: 0.0528099 Test Loss: 0.0598749\n",
      "Validation loss decreased (0.052873 --> 0.052810).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0536711\n",
      "\tspeed: 0.0540s/iter; left time: 849.1549s\n",
      "\titers: 200, epoch: 30 | loss: 0.0521599\n",
      "\tspeed: 0.0265s/iter; left time: 414.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525897 Vali Loss: 0.0528667 Test Loss: 0.0601898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0525367\n",
      "\tspeed: 0.0504s/iter; left time: 781.6923s\n",
      "\titers: 200, epoch: 31 | loss: 0.0528346\n",
      "\tspeed: 0.0267s/iter; left time: 411.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0525614 Vali Loss: 0.0528139 Test Loss: 0.0600230\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0510059\n",
      "\tspeed: 0.0549s/iter; left time: 839.7299s\n",
      "\titers: 200, epoch: 32 | loss: 0.0555225\n",
      "\tspeed: 0.0267s/iter; left time: 405.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0525297 Vali Loss: 0.0528147 Test Loss: 0.0600315\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0553756\n",
      "\tspeed: 0.0517s/iter; left time: 778.7115s\n",
      "\titers: 200, epoch: 33 | loss: 0.0561647\n",
      "\tspeed: 0.0269s/iter; left time: 402.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0524675 Vali Loss: 0.0527943 Test Loss: 0.0599646\n",
      "Validation loss decreased (0.052810 --> 0.052794).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547888\n",
      "\tspeed: 0.0546s/iter; left time: 810.3476s\n",
      "\titers: 200, epoch: 34 | loss: 0.0502540\n",
      "\tspeed: 0.0264s/iter; left time: 389.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0524123 Vali Loss: 0.0527812 Test Loss: 0.0600052\n",
      "Validation loss decreased (0.052794 --> 0.052781).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0539715\n",
      "\tspeed: 0.0522s/iter; left time: 763.3288s\n",
      "\titers: 200, epoch: 35 | loss: 0.0542529\n",
      "\tspeed: 0.0288s/iter; left time: 417.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0523824 Vali Loss: 0.0526560 Test Loss: 0.0598498\n",
      "Validation loss decreased (0.052781 --> 0.052656).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0540629\n",
      "\tspeed: 0.0551s/iter; left time: 793.6323s\n",
      "\titers: 200, epoch: 36 | loss: 0.0535191\n",
      "\tspeed: 0.0267s/iter; left time: 381.9144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0523539 Vali Loss: 0.0526808 Test Loss: 0.0598498\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0506244\n",
      "\tspeed: 0.0521s/iter; left time: 738.5504s\n",
      "\titers: 200, epoch: 37 | loss: 0.0530473\n",
      "\tspeed: 0.0274s/iter; left time: 385.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523549 Vali Loss: 0.0526425 Test Loss: 0.0598658\n",
      "Validation loss decreased (0.052656 --> 0.052643).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0527134\n",
      "\tspeed: 0.0556s/iter; left time: 775.5018s\n",
      "\titers: 200, epoch: 38 | loss: 0.0536440\n",
      "\tspeed: 0.0265s/iter; left time: 366.8005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523354 Vali Loss: 0.0528015 Test Loss: 0.0598641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0523238\n",
      "\tspeed: 0.0513s/iter; left time: 704.6534s\n",
      "\titers: 200, epoch: 39 | loss: 0.0517573\n",
      "\tspeed: 0.0294s/iter; left time: 400.9276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0523230 Vali Loss: 0.0526925 Test Loss: 0.0598390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0538465\n",
      "\tspeed: 0.0518s/iter; left time: 699.8013s\n",
      "\titers: 200, epoch: 40 | loss: 0.0512804\n",
      "\tspeed: 0.0268s/iter; left time: 359.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522718 Vali Loss: 0.0526854 Test Loss: 0.0598257\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530373\n",
      "\tspeed: 0.0519s/iter; left time: 689.1349s\n",
      "\titers: 200, epoch: 41 | loss: 0.0532438\n",
      "\tspeed: 0.0281s/iter; left time: 370.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522268 Vali Loss: 0.0526668 Test Loss: 0.0599239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0498807\n",
      "\tspeed: 0.0514s/iter; left time: 670.6596s\n",
      "\titers: 200, epoch: 42 | loss: 0.0523962\n",
      "\tspeed: 0.0267s/iter; left time: 346.4268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522847 Vali Loss: 0.0526407 Test Loss: 0.0598294\n",
      "Validation loss decreased (0.052643 --> 0.052641).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0534996\n",
      "\tspeed: 0.0540s/iter; left time: 692.4492s\n",
      "\titers: 200, epoch: 43 | loss: 0.0532958\n",
      "\tspeed: 0.0271s/iter; left time: 345.1474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0523306 Vali Loss: 0.0525946 Test Loss: 0.0597619\n",
      "Validation loss decreased (0.052641 --> 0.052595).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0526985\n",
      "\tspeed: 0.0521s/iter; left time: 656.6391s\n",
      "\titers: 200, epoch: 44 | loss: 0.0511877\n",
      "\tspeed: 0.0270s/iter; left time: 337.4740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0521692 Vali Loss: 0.0526428 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556191\n",
      "\tspeed: 0.0533s/iter; left time: 660.9343s\n",
      "\titers: 200, epoch: 45 | loss: 0.0514222\n",
      "\tspeed: 0.0284s/iter; left time: 349.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0522454 Vali Loss: 0.0526971 Test Loss: 0.0597938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0529044\n",
      "\tspeed: 0.0522s/iter; left time: 635.0330s\n",
      "\titers: 200, epoch: 46 | loss: 0.0533347\n",
      "\tspeed: 0.0263s/iter; left time: 316.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0522511 Vali Loss: 0.0526150 Test Loss: 0.0598379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0525579\n",
      "\tspeed: 0.0556s/iter; left time: 663.7137s\n",
      "\titers: 200, epoch: 47 | loss: 0.0559584\n",
      "\tspeed: 0.0270s/iter; left time: 319.5735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522442 Vali Loss: 0.0526613 Test Loss: 0.0597907\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0522379\n",
      "\tspeed: 0.0513s/iter; left time: 601.7284s\n",
      "\titers: 200, epoch: 48 | loss: 0.0542752\n",
      "\tspeed: 0.0267s/iter; left time: 310.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0521854 Vali Loss: 0.0526289 Test Loss: 0.0597892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549363\n",
      "\tspeed: 0.0526s/iter; left time: 604.4033s\n",
      "\titers: 200, epoch: 49 | loss: 0.0465775\n",
      "\tspeed: 0.0264s/iter; left time: 300.7727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0522630 Vali Loss: 0.0526140 Test Loss: 0.0598117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0494051\n",
      "\tspeed: 0.0507s/iter; left time: 571.0883s\n",
      "\titers: 200, epoch: 50 | loss: 0.0522640\n",
      "\tspeed: 0.0267s/iter; left time: 298.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 223 | Train Loss: 0.0522751 Vali Loss: 0.0526901 Test Loss: 0.0599105\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0573033\n",
      "\tspeed: 0.0538s/iter; left time: 594.8035s\n",
      "\titers: 200, epoch: 51 | loss: 0.0508314\n",
      "\tspeed: 0.0268s/iter; left time: 293.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521932 Vali Loss: 0.0526688 Test Loss: 0.0598051\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0495923\n",
      "\tspeed: 0.0525s/iter; left time: 568.0226s\n",
      "\titers: 200, epoch: 52 | loss: 0.0519124\n",
      "\tspeed: 0.0267s/iter; left time: 286.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522027 Vali Loss: 0.0526402 Test Loss: 0.0598215\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0548224\n",
      "\tspeed: 0.0537s/iter; left time: 569.8401s\n",
      "\titers: 200, epoch: 53 | loss: 0.0511640\n",
      "\tspeed: 0.0267s/iter; left time: 280.9340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521802 Vali Loss: 0.0526538 Test Loss: 0.0598073\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009856260381639004, rmse:0.09927870333194733, mae:0.059761930257081985, rse:0.29216518998146057\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1225064\n",
      "\tspeed: 0.0293s/iter; left time: 649.8441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1018515\n",
      "\tspeed: 0.0285s/iter; left time: 630.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.1260264 Vali Loss: 0.0930495 Test Loss: 0.1065131\n",
      "Validation loss decreased (inf --> 0.093049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0733656\n",
      "\tspeed: 0.0531s/iter; left time: 1166.1485s\n",
      "\titers: 200, epoch: 2 | loss: 0.0689993\n",
      "\tspeed: 0.0264s/iter; left time: 578.3729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0747297 Vali Loss: 0.0627035 Test Loss: 0.0696848\n",
      "Validation loss decreased (0.093049 --> 0.062703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0641976\n",
      "\tspeed: 0.0527s/iter; left time: 1147.3285s\n",
      "\titers: 200, epoch: 3 | loss: 0.0600092\n",
      "\tspeed: 0.0267s/iter; left time: 577.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0643813 Vali Loss: 0.0594397 Test Loss: 0.0659568\n",
      "Validation loss decreased (0.062703 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0578316\n",
      "\tspeed: 0.0529s/iter; left time: 1139.9557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639258\n",
      "\tspeed: 0.0266s/iter; left time: 570.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0614354 Vali Loss: 0.0580388 Test Loss: 0.0646078\n",
      "Validation loss decreased (0.059440 --> 0.058039).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601949\n",
      "\tspeed: 0.0529s/iter; left time: 1127.1254s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646062\n",
      "\tspeed: 0.0263s/iter; left time: 557.4764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0598467 Vali Loss: 0.0574702 Test Loss: 0.0642393\n",
      "Validation loss decreased (0.058039 --> 0.057470).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582525\n",
      "\tspeed: 0.0531s/iter; left time: 1120.5297s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598998\n",
      "\tspeed: 0.0264s/iter; left time: 554.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0587508 Vali Loss: 0.0564080 Test Loss: 0.0630445\n",
      "Validation loss decreased (0.057470 --> 0.056408).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556834\n",
      "\tspeed: 0.0529s/iter; left time: 1104.6372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605512\n",
      "\tspeed: 0.0266s/iter; left time: 552.5662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0577860 Vali Loss: 0.0561291 Test Loss: 0.0630853\n",
      "Validation loss decreased (0.056408 --> 0.056129).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0619714\n",
      "\tspeed: 0.0538s/iter; left time: 1110.8849s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560631\n",
      "\tspeed: 0.0274s/iter; left time: 563.5240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570553 Vali Loss: 0.0551744 Test Loss: 0.0620771\n",
      "Validation loss decreased (0.056129 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543769\n",
      "\tspeed: 0.0527s/iter; left time: 1076.3225s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573231\n",
      "\tspeed: 0.0267s/iter; left time: 542.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0564490 Vali Loss: 0.0553923 Test Loss: 0.0621985\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564896\n",
      "\tspeed: 0.0536s/iter; left time: 1082.7952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0550005\n",
      "\tspeed: 0.0266s/iter; left time: 533.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0559311 Vali Loss: 0.0548954 Test Loss: 0.0616808\n",
      "Validation loss decreased (0.055174 --> 0.054895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559047\n",
      "\tspeed: 0.0522s/iter; left time: 1042.0117s\n",
      "\titers: 200, epoch: 11 | loss: 0.0561010\n",
      "\tspeed: 0.0267s/iter; left time: 530.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0554993 Vali Loss: 0.0547145 Test Loss: 0.0616678\n",
      "Validation loss decreased (0.054895 --> 0.054715).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0549887\n",
      "\tspeed: 0.0530s/iter; left time: 1046.4545s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535350\n",
      "\tspeed: 0.0274s/iter; left time: 537.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0550779 Vali Loss: 0.0541503 Test Loss: 0.0611615\n",
      "Validation loss decreased (0.054715 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564112\n",
      "\tspeed: 0.0521s/iter; left time: 1016.2813s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547302\n",
      "\tspeed: 0.0267s/iter; left time: 518.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0548484 Vali Loss: 0.0540437 Test Loss: 0.0611038\n",
      "Validation loss decreased (0.054150 --> 0.054044).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563114\n",
      "\tspeed: 0.0555s/iter; left time: 1071.2768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546800\n",
      "\tspeed: 0.0265s/iter; left time: 508.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0545632 Vali Loss: 0.0538223 Test Loss: 0.0608727\n",
      "Validation loss decreased (0.054044 --> 0.053822).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582940\n",
      "\tspeed: 0.0523s/iter; left time: 997.0774s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569442\n",
      "\tspeed: 0.0268s/iter; left time: 507.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0542870 Vali Loss: 0.0536832 Test Loss: 0.0606616\n",
      "Validation loss decreased (0.053822 --> 0.053683).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569478\n",
      "\tspeed: 0.0532s/iter; left time: 1003.7836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0538614\n",
      "\tspeed: 0.0274s/iter; left time: 513.2290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0540642 Vali Loss: 0.0534916 Test Loss: 0.0607154\n",
      "Validation loss decreased (0.053683 --> 0.053492).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0559539\n",
      "\tspeed: 0.0518s/iter; left time: 965.5459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0532772\n",
      "\tspeed: 0.0265s/iter; left time: 491.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0538495 Vali Loss: 0.0537074 Test Loss: 0.0608297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547949\n",
      "\tspeed: 0.0536s/iter; left time: 986.6825s\n",
      "\titers: 200, epoch: 18 | loss: 0.0560665\n",
      "\tspeed: 0.0266s/iter; left time: 486.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0536505 Vali Loss: 0.0534455 Test Loss: 0.0606475\n",
      "Validation loss decreased (0.053492 --> 0.053446).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0518258\n",
      "\tspeed: 0.0518s/iter; left time: 942.7260s\n",
      "\titers: 200, epoch: 19 | loss: 0.0533621\n",
      "\tspeed: 0.0271s/iter; left time: 489.3186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0534612 Vali Loss: 0.0531519 Test Loss: 0.0604471\n",
      "Validation loss decreased (0.053446 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0547985\n",
      "\tspeed: 0.0555s/iter; left time: 997.1039s\n",
      "\titers: 200, epoch: 20 | loss: 0.0515255\n",
      "\tspeed: 0.0269s/iter; left time: 480.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0534055 Vali Loss: 0.0532615 Test Loss: 0.0602668\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0534183\n",
      "\tspeed: 0.0526s/iter; left time: 932.3127s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536347\n",
      "\tspeed: 0.0276s/iter; left time: 487.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0532890 Vali Loss: 0.0531846 Test Loss: 0.0605303\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0549916\n",
      "\tspeed: 0.0541s/iter; left time: 947.9029s\n",
      "\titers: 200, epoch: 22 | loss: 0.0554341\n",
      "\tspeed: 0.0266s/iter; left time: 462.4595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0531466 Vali Loss: 0.0528900 Test Loss: 0.0601454\n",
      "Validation loss decreased (0.053152 --> 0.052890).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0513683\n",
      "\tspeed: 0.0526s/iter; left time: 909.7789s\n",
      "\titers: 200, epoch: 23 | loss: 0.0579329\n",
      "\tspeed: 0.0269s/iter; left time: 463.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0530312 Vali Loss: 0.0530480 Test Loss: 0.0602246\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499048\n",
      "\tspeed: 0.0535s/iter; left time: 913.9284s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510843\n",
      "\tspeed: 0.0267s/iter; left time: 453.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0529737 Vali Loss: 0.0528694 Test Loss: 0.0602031\n",
      "Validation loss decreased (0.052890 --> 0.052869).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0577566\n",
      "\tspeed: 0.0523s/iter; left time: 881.3431s\n",
      "\titers: 200, epoch: 25 | loss: 0.0551628\n",
      "\tspeed: 0.0270s/iter; left time: 451.8035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0528067 Vali Loss: 0.0529870 Test Loss: 0.0601069\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0513571\n",
      "\tspeed: 0.0522s/iter; left time: 867.8912s\n",
      "\titers: 200, epoch: 26 | loss: 0.0499296\n",
      "\tspeed: 0.0266s/iter; left time: 438.8673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0527925 Vali Loss: 0.0529492 Test Loss: 0.0600720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0509044\n",
      "\tspeed: 0.0517s/iter; left time: 848.6226s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493349\n",
      "\tspeed: 0.0272s/iter; left time: 443.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0527369 Vali Loss: 0.0528136 Test Loss: 0.0599594\n",
      "Validation loss decreased (0.052869 --> 0.052814).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532001\n",
      "\tspeed: 0.0525s/iter; left time: 849.3808s\n",
      "\titers: 200, epoch: 28 | loss: 0.0511784\n",
      "\tspeed: 0.0267s/iter; left time: 430.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526384 Vali Loss: 0.0528487 Test Loss: 0.0599587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0495770\n",
      "\tspeed: 0.0530s/iter; left time: 844.9906s\n",
      "\titers: 200, epoch: 29 | loss: 0.0464556\n",
      "\tspeed: 0.0269s/iter; left time: 427.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0526565 Vali Loss: 0.0527931 Test Loss: 0.0599919\n",
      "Validation loss decreased (0.052814 --> 0.052793).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0552674\n",
      "\tspeed: 0.0517s/iter; left time: 813.9372s\n",
      "\titers: 200, epoch: 30 | loss: 0.0527033\n",
      "\tspeed: 0.0268s/iter; left time: 418.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0525646 Vali Loss: 0.0527250 Test Loss: 0.0599071\n",
      "Validation loss decreased (0.052793 --> 0.052725).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0544455\n",
      "\tspeed: 0.0538s/iter; left time: 834.2253s\n",
      "\titers: 200, epoch: 31 | loss: 0.0547280\n",
      "\tspeed: 0.0275s/iter; left time: 424.3143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0525626 Vali Loss: 0.0527098 Test Loss: 0.0599193\n",
      "Validation loss decreased (0.052725 --> 0.052710).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0535513\n",
      "\tspeed: 0.0526s/iter; left time: 804.2974s\n",
      "\titers: 200, epoch: 32 | loss: 0.0491902\n",
      "\tspeed: 0.0270s/iter; left time: 409.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0524858 Vali Loss: 0.0527489 Test Loss: 0.0599410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0548159\n",
      "\tspeed: 0.0537s/iter; left time: 809.7204s\n",
      "\titers: 200, epoch: 33 | loss: 0.0534750\n",
      "\tspeed: 0.0265s/iter; left time: 396.1187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0524737 Vali Loss: 0.0526946 Test Loss: 0.0599220\n",
      "Validation loss decreased (0.052710 --> 0.052695).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0547238\n",
      "\tspeed: 0.0519s/iter; left time: 770.9554s\n",
      "\titers: 200, epoch: 34 | loss: 0.0526712\n",
      "\tspeed: 0.0265s/iter; left time: 390.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0524465 Vali Loss: 0.0526699 Test Loss: 0.0598708\n",
      "Validation loss decreased (0.052695 --> 0.052670).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548534\n",
      "\tspeed: 0.0549s/iter; left time: 802.6370s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521703\n",
      "\tspeed: 0.0267s/iter; left time: 387.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0524024 Vali Loss: 0.0526626 Test Loss: 0.0597937\n",
      "Validation loss decreased (0.052670 --> 0.052663).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0503881\n",
      "\tspeed: 0.0526s/iter; left time: 757.2531s\n",
      "\titers: 200, epoch: 36 | loss: 0.0522587\n",
      "\tspeed: 0.0269s/iter; left time: 384.2234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0523866 Vali Loss: 0.0526656 Test Loss: 0.0598915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0512503\n",
      "\tspeed: 0.0535s/iter; left time: 758.3364s\n",
      "\titers: 200, epoch: 37 | loss: 0.0500938\n",
      "\tspeed: 0.0262s/iter; left time: 368.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0523500 Vali Loss: 0.0526616 Test Loss: 0.0599231\n",
      "Validation loss decreased (0.052663 --> 0.052662).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0501655\n",
      "\tspeed: 0.0518s/iter; left time: 722.8999s\n",
      "\titers: 200, epoch: 38 | loss: 0.0534852\n",
      "\tspeed: 0.0268s/iter; left time: 371.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523321 Vali Loss: 0.0527160 Test Loss: 0.0598248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0514224\n",
      "\tspeed: 0.0545s/iter; left time: 748.3258s\n",
      "\titers: 200, epoch: 39 | loss: 0.0514188\n",
      "\tspeed: 0.0269s/iter; left time: 366.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0523240 Vali Loss: 0.0526534 Test Loss: 0.0597652\n",
      "Validation loss decreased (0.052662 --> 0.052653).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0530570\n",
      "\tspeed: 0.0540s/iter; left time: 729.2703s\n",
      "\titers: 200, epoch: 40 | loss: 0.0543625\n",
      "\tspeed: 0.0265s/iter; left time: 355.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0523358 Vali Loss: 0.0526050 Test Loss: 0.0597801\n",
      "Validation loss decreased (0.052653 --> 0.052605).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0526280\n",
      "\tspeed: 0.0538s/iter; left time: 714.3920s\n",
      "\titers: 200, epoch: 41 | loss: 0.0502842\n",
      "\tspeed: 0.0269s/iter; left time: 354.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0523034 Vali Loss: 0.0525962 Test Loss: 0.0597211\n",
      "Validation loss decreased (0.052605 --> 0.052596).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0504601\n",
      "\tspeed: 0.0519s/iter; left time: 677.2080s\n",
      "\titers: 200, epoch: 42 | loss: 0.0522450\n",
      "\tspeed: 0.0267s/iter; left time: 346.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0522315 Vali Loss: 0.0525362 Test Loss: 0.0597368\n",
      "Validation loss decreased (0.052596 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0511504\n",
      "\tspeed: 0.0536s/iter; left time: 687.5830s\n",
      "\titers: 200, epoch: 43 | loss: 0.0488503\n",
      "\tspeed: 0.0271s/iter; left time: 344.9455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0522311 Vali Loss: 0.0525445 Test Loss: 0.0597039\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0522164\n",
      "\tspeed: 0.0529s/iter; left time: 667.3444s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535703\n",
      "\tspeed: 0.0284s/iter; left time: 354.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0522388 Vali Loss: 0.0525645 Test Loss: 0.0597437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0495954\n",
      "\tspeed: 0.0542s/iter; left time: 671.1270s\n",
      "\titers: 200, epoch: 45 | loss: 0.0532957\n",
      "\tspeed: 0.0266s/iter; left time: 327.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0521830 Vali Loss: 0.0525358 Test Loss: 0.0597217\n",
      "Validation loss decreased (0.052536 --> 0.052536).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0547444\n",
      "\tspeed: 0.0524s/iter; left time: 637.6216s\n",
      "\titers: 200, epoch: 46 | loss: 0.0496140\n",
      "\tspeed: 0.0269s/iter; left time: 324.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521675 Vali Loss: 0.0525339 Test Loss: 0.0597081\n",
      "Validation loss decreased (0.052536 --> 0.052534).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0506746\n",
      "\tspeed: 0.0548s/iter; left time: 654.9451s\n",
      "\titers: 200, epoch: 47 | loss: 0.0512049\n",
      "\tspeed: 0.0264s/iter; left time: 313.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0522126 Vali Loss: 0.0525633 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0528504\n",
      "\tspeed: 0.0519s/iter; left time: 608.0480s\n",
      "\titers: 200, epoch: 48 | loss: 0.0515653\n",
      "\tspeed: 0.0264s/iter; left time: 306.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 223 | Train Loss: 0.0522133 Vali Loss: 0.0525448 Test Loss: 0.0597099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0548897\n",
      "\tspeed: 0.0561s/iter; left time: 644.8778s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546200\n",
      "\tspeed: 0.0264s/iter; left time: 301.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0521772 Vali Loss: 0.0526311 Test Loss: 0.0597383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0529519\n",
      "\tspeed: 0.0521s/iter; left time: 586.9512s\n",
      "\titers: 200, epoch: 50 | loss: 0.0546627\n",
      "\tspeed: 0.0266s/iter; left time: 297.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0522163 Vali Loss: 0.0525349 Test Loss: 0.0597257\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0562787\n",
      "\tspeed: 0.0549s/iter; left time: 606.1844s\n",
      "\titers: 200, epoch: 51 | loss: 0.0525578\n",
      "\tspeed: 0.0263s/iter; left time: 288.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0522028 Vali Loss: 0.0525564 Test Loss: 0.0597158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0567538\n",
      "\tspeed: 0.0519s/iter; left time: 561.7646s\n",
      "\titers: 200, epoch: 52 | loss: 0.0543848\n",
      "\tspeed: 0.0270s/iter; left time: 289.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0521792 Vali Loss: 0.0525038 Test Loss: 0.0596972\n",
      "Validation loss decreased (0.052534 --> 0.052504).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0541374\n",
      "\tspeed: 0.0558s/iter; left time: 591.2647s\n",
      "\titers: 200, epoch: 53 | loss: 0.0519631\n",
      "\tspeed: 0.0267s/iter; left time: 280.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525617 Test Loss: 0.0597053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0510549\n",
      "\tspeed: 0.0519s/iter; left time: 538.9647s\n",
      "\titers: 200, epoch: 54 | loss: 0.0498644\n",
      "\tspeed: 0.0276s/iter; left time: 283.4121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0521371 Vali Loss: 0.0525328 Test Loss: 0.0597132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0494472\n",
      "\tspeed: 0.0524s/iter; left time: 532.0514s\n",
      "\titers: 200, epoch: 55 | loss: 0.0542947\n",
      "\tspeed: 0.0265s/iter; left time: 266.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521456 Vali Loss: 0.0525355 Test Loss: 0.0597412\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0560386\n",
      "\tspeed: 0.0519s/iter; left time: 515.1972s\n",
      "\titers: 200, epoch: 56 | loss: 0.0490938\n",
      "\tspeed: 0.0275s/iter; left time: 270.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0521942 Vali Loss: 0.0525360 Test Loss: 0.0596775\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0516569\n",
      "\tspeed: 0.0533s/iter; left time: 517.2387s\n",
      "\titers: 200, epoch: 57 | loss: 0.0514586\n",
      "\tspeed: 0.0265s/iter; left time: 255.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521401 Vali Loss: 0.0525131 Test Loss: 0.0596987\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0532000\n",
      "\tspeed: 0.0516s/iter; left time: 490.0769s\n",
      "\titers: 200, epoch: 58 | loss: 0.0498075\n",
      "\tspeed: 0.0280s/iter; left time: 263.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521895 Vali Loss: 0.0524485 Test Loss: 0.0596977\n",
      "Validation loss decreased (0.052504 --> 0.052448).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0487121\n",
      "\tspeed: 0.0521s/iter; left time: 482.9457s\n",
      "\titers: 200, epoch: 59 | loss: 0.0520011\n",
      "\tspeed: 0.0263s/iter; left time: 241.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0520815 Vali Loss: 0.0525329 Test Loss: 0.0597163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0499147\n",
      "\tspeed: 0.0515s/iter; left time: 465.4498s\n",
      "\titers: 200, epoch: 60 | loss: 0.0494750\n",
      "\tspeed: 0.0274s/iter; left time: 245.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0521364 Vali Loss: 0.0525106 Test Loss: 0.0596920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0571291\n",
      "\tspeed: 0.0513s/iter; left time: 452.4577s\n",
      "\titers: 200, epoch: 61 | loss: 0.0492495\n",
      "\tspeed: 0.0267s/iter; left time: 232.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0520912 Vali Loss: 0.0525052 Test Loss: 0.0597109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0515710\n",
      "\tspeed: 0.0543s/iter; left time: 467.0255s\n",
      "\titers: 200, epoch: 62 | loss: 0.0511826\n",
      "\tspeed: 0.0270s/iter; left time: 229.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0521550 Vali Loss: 0.0525164 Test Loss: 0.0596776\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0522274\n",
      "\tspeed: 0.0521s/iter; left time: 436.1762s\n",
      "\titers: 200, epoch: 63 | loss: 0.0504325\n",
      "\tspeed: 0.0266s/iter; left time: 220.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0521259 Vali Loss: 0.0525472 Test Loss: 0.0597064\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0529144\n",
      "\tspeed: 0.0533s/iter; left time: 434.1040s\n",
      "\titers: 200, epoch: 64 | loss: 0.0512218\n",
      "\tspeed: 0.0271s/iter; left time: 218.0110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0521278 Vali Loss: 0.0525165 Test Loss: 0.0596788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0476370\n",
      "\tspeed: 0.0525s/iter; left time: 416.5912s\n",
      "\titers: 200, epoch: 65 | loss: 0.0538774\n",
      "\tspeed: 0.0265s/iter; left time: 207.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0521600 Vali Loss: 0.0525308 Test Loss: 0.0596834\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0497716\n",
      "\tspeed: 0.0539s/iter; left time: 415.6925s\n",
      "\titers: 200, epoch: 66 | loss: 0.0530621\n",
      "\tspeed: 0.0270s/iter; left time: 205.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0521674 Vali Loss: 0.0524973 Test Loss: 0.0596974\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0499892\n",
      "\tspeed: 0.0513s/iter; left time: 383.7247s\n",
      "\titers: 200, epoch: 67 | loss: 0.0548931\n",
      "\tspeed: 0.0257s/iter; left time: 190.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 223 | Train Loss: 0.0520809 Vali Loss: 0.0525215 Test Loss: 0.0597028\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0492604\n",
      "\tspeed: 0.0538s/iter; left time: 390.9405s\n",
      "\titers: 200, epoch: 68 | loss: 0.0565043\n",
      "\tspeed: 0.0269s/iter; left time: 192.2992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0521187 Vali Loss: 0.0525102 Test Loss: 0.0596645\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009862316772341728, rmse:0.09930919855833054, mae:0.0596977174282074, rse:0.2922549545764923\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:15.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1265439\n",
      "\tspeed: 0.0400s/iter; left time: 884.7212s\n",
      "\titers: 200, epoch: 1 | loss: 0.1094258\n",
      "\tspeed: 0.0289s/iter; left time: 636.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.1312871 Vali Loss: 0.1025756 Test Loss: 0.1179928\n",
      "Validation loss decreased (inf --> 0.102576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0907331\n",
      "\tspeed: 0.0535s/iter; left time: 1170.6404s\n",
      "\titers: 200, epoch: 2 | loss: 0.0867114\n",
      "\tspeed: 0.0266s/iter; left time: 579.1231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0917246 Vali Loss: 0.0830300 Test Loss: 0.0950562\n",
      "Validation loss decreased (0.102576 --> 0.083030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829765\n",
      "\tspeed: 0.0554s/iter; left time: 1198.8487s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798829\n",
      "\tspeed: 0.0265s/iter; left time: 571.3860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 222 | Train Loss: 0.0835803 Vali Loss: 0.0801783 Test Loss: 0.0919009\n",
      "Validation loss decreased (0.083030 --> 0.080178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0821674\n",
      "\tspeed: 0.0559s/iter; left time: 1197.5539s\n",
      "\titers: 200, epoch: 4 | loss: 0.0791295\n",
      "\tspeed: 0.0266s/iter; left time: 567.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0809995 Vali Loss: 0.0792776 Test Loss: 0.0911379\n",
      "Validation loss decreased (0.080178 --> 0.079278).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795954\n",
      "\tspeed: 0.0537s/iter; left time: 1138.2492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775064\n",
      "\tspeed: 0.0284s/iter; left time: 600.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0793633 Vali Loss: 0.0774794 Test Loss: 0.0889028\n",
      "Validation loss decreased (0.079278 --> 0.077479).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782045\n",
      "\tspeed: 0.0539s/iter; left time: 1131.9822s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778508\n",
      "\tspeed: 0.0279s/iter; left time: 583.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0779934 Vali Loss: 0.0769796 Test Loss: 0.0893228\n",
      "Validation loss decreased (0.077479 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745626\n",
      "\tspeed: 0.0550s/iter; left time: 1143.0104s\n",
      "\titers: 200, epoch: 7 | loss: 0.0762473\n",
      "\tspeed: 0.0267s/iter; left time: 552.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 222 | Train Loss: 0.0769873 Vali Loss: 0.0768754 Test Loss: 0.0889773\n",
      "Validation loss decreased (0.076980 --> 0.076875).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770923\n",
      "\tspeed: 0.0562s/iter; left time: 1155.5033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742162\n",
      "\tspeed: 0.0270s/iter; left time: 552.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0761248 Vali Loss: 0.0765266 Test Loss: 0.0878974\n",
      "Validation loss decreased (0.076875 --> 0.076527).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738049\n",
      "\tspeed: 0.0546s/iter; left time: 1110.0115s\n",
      "\titers: 200, epoch: 9 | loss: 0.0768474\n",
      "\tspeed: 0.0268s/iter; left time: 542.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0753436 Vali Loss: 0.0767246 Test Loss: 0.0876410\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751446\n",
      "\tspeed: 0.0528s/iter; left time: 1061.9707s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730382\n",
      "\tspeed: 0.0278s/iter; left time: 556.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0746837 Vali Loss: 0.0759690 Test Loss: 0.0876617\n",
      "Validation loss decreased (0.076527 --> 0.075969).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0742704\n",
      "\tspeed: 0.0547s/iter; left time: 1088.1799s\n",
      "\titers: 200, epoch: 11 | loss: 0.0734047\n",
      "\tspeed: 0.0283s/iter; left time: 558.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0740411 Vali Loss: 0.0764244 Test Loss: 0.0878260\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752044\n",
      "\tspeed: 0.0543s/iter; left time: 1066.5819s\n",
      "\titers: 200, epoch: 12 | loss: 0.0752981\n",
      "\tspeed: 0.0268s/iter; left time: 523.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0736232 Vali Loss: 0.0767008 Test Loss: 0.0877754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0746256\n",
      "\tspeed: 0.0564s/iter; left time: 1096.2401s\n",
      "\titers: 200, epoch: 13 | loss: 0.0724523\n",
      "\tspeed: 0.0268s/iter; left time: 518.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0732229 Vali Loss: 0.0764604 Test Loss: 0.0875878\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0758144\n",
      "\tspeed: 0.0548s/iter; left time: 1053.8924s\n",
      "\titers: 200, epoch: 14 | loss: 0.0700375\n",
      "\tspeed: 0.0271s/iter; left time: 518.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0728587 Vali Loss: 0.0766782 Test Loss: 0.0877830\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0706620\n",
      "\tspeed: 0.0543s/iter; left time: 1030.7524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763170\n",
      "\tspeed: 0.0296s/iter; left time: 559.0234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0725805 Vali Loss: 0.0769847 Test Loss: 0.0880434\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0747856\n",
      "\tspeed: 0.0537s/iter; left time: 1007.8252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0682468\n",
      "\tspeed: 0.0276s/iter; left time: 515.9298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0722561 Vali Loss: 0.0771711 Test Loss: 0.0879989\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0709803\n",
      "\tspeed: 0.0552s/iter; left time: 1024.6003s\n",
      "\titers: 200, epoch: 17 | loss: 0.0700381\n",
      "\tspeed: 0.0273s/iter; left time: 503.1803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0719847 Vali Loss: 0.0766064 Test Loss: 0.0875815\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0710720\n",
      "\tspeed: 0.0554s/iter; left time: 1014.6048s\n",
      "\titers: 200, epoch: 18 | loss: 0.0727012\n",
      "\tspeed: 0.0283s/iter; left time: 516.3897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0717268 Vali Loss: 0.0767684 Test Loss: 0.0876820\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0743508\n",
      "\tspeed: 0.0547s/iter; left time: 989.5579s\n",
      "\titers: 200, epoch: 19 | loss: 0.0689420\n",
      "\tspeed: 0.0275s/iter; left time: 494.3742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0715864 Vali Loss: 0.0769818 Test Loss: 0.0876034\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0733923\n",
      "\tspeed: 0.0529s/iter; left time: 946.8320s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733492\n",
      "\tspeed: 0.0284s/iter; left time: 505.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0712923 Vali Loss: 0.0767117 Test Loss: 0.0876483\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018943050876259804, rmse:0.13763375580310822, mae:0.08766170591115952, rse:0.40432655811309814\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1253982\n",
      "\tspeed: 0.0289s/iter; left time: 638.4441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1141047\n",
      "\tspeed: 0.0291s/iter; left time: 639.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1341000 Vali Loss: 0.1022669 Test Loss: 0.1178293\n",
      "Validation loss decreased (inf --> 0.102267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0919906\n",
      "\tspeed: 0.0538s/iter; left time: 1177.6209s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841853\n",
      "\tspeed: 0.0281s/iter; left time: 612.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0917120 Vali Loss: 0.0828372 Test Loss: 0.0952215\n",
      "Validation loss decreased (0.102267 --> 0.082837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804817\n",
      "\tspeed: 0.0553s/iter; left time: 1197.2060s\n",
      "\titers: 200, epoch: 3 | loss: 0.0846727\n",
      "\tspeed: 0.0272s/iter; left time: 585.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 222 | Train Loss: 0.0834201 Vali Loss: 0.0801691 Test Loss: 0.0913734\n",
      "Validation loss decreased (0.082837 --> 0.080169).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814359\n",
      "\tspeed: 0.0549s/iter; left time: 1177.4784s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801016\n",
      "\tspeed: 0.0268s/iter; left time: 570.8222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0809782 Vali Loss: 0.0786221 Test Loss: 0.0896895\n",
      "Validation loss decreased (0.080169 --> 0.078622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0773623\n",
      "\tspeed: 0.0557s/iter; left time: 1181.5318s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807470\n",
      "\tspeed: 0.0269s/iter; left time: 567.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0791465 Vali Loss: 0.0776870 Test Loss: 0.0884282\n",
      "Validation loss decreased (0.078622 --> 0.077687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0764767\n",
      "\tspeed: 0.0557s/iter; left time: 1168.8908s\n",
      "\titers: 200, epoch: 6 | loss: 0.0776939\n",
      "\tspeed: 0.0288s/iter; left time: 601.9911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0779017 Vali Loss: 0.0774003 Test Loss: 0.0885492\n",
      "Validation loss decreased (0.077687 --> 0.077400).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0810065\n",
      "\tspeed: 0.0550s/iter; left time: 1142.0334s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755886\n",
      "\tspeed: 0.0274s/iter; left time: 566.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0769723 Vali Loss: 0.0767423 Test Loss: 0.0886906\n",
      "Validation loss decreased (0.077400 --> 0.076742).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772487\n",
      "\tspeed: 0.0547s/iter; left time: 1123.3866s\n",
      "\titers: 200, epoch: 8 | loss: 0.0774471\n",
      "\tspeed: 0.0271s/iter; left time: 555.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0761289 Vali Loss: 0.0762937 Test Loss: 0.0885289\n",
      "Validation loss decreased (0.076742 --> 0.076294).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766210\n",
      "\tspeed: 0.0558s/iter; left time: 1134.4816s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749435\n",
      "\tspeed: 0.0269s/iter; left time: 544.2993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0755007 Vali Loss: 0.0760306 Test Loss: 0.0880587\n",
      "Validation loss decreased (0.076294 --> 0.076031).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0746958\n",
      "\tspeed: 0.0559s/iter; left time: 1123.7180s\n",
      "\titers: 200, epoch: 10 | loss: 0.0730645\n",
      "\tspeed: 0.0275s/iter; left time: 550.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0748742 Vali Loss: 0.0756054 Test Loss: 0.0881646\n",
      "Validation loss decreased (0.076031 --> 0.075605).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0716690\n",
      "\tspeed: 0.0534s/iter; left time: 1061.9451s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740186\n",
      "\tspeed: 0.0284s/iter; left time: 561.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0743888 Vali Loss: 0.0763426 Test Loss: 0.0880540\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0735602\n",
      "\tspeed: 0.0538s/iter; left time: 1057.8847s\n",
      "\titers: 200, epoch: 12 | loss: 0.0751355\n",
      "\tspeed: 0.0281s/iter; left time: 549.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0739728 Vali Loss: 0.0759540 Test Loss: 0.0883263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0716493\n",
      "\tspeed: 0.0541s/iter; left time: 1051.5080s\n",
      "\titers: 200, epoch: 13 | loss: 0.0773238\n",
      "\tspeed: 0.0267s/iter; left time: 515.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0734238 Vali Loss: 0.0758260 Test Loss: 0.0877946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0718031\n",
      "\tspeed: 0.0554s/iter; left time: 1064.5978s\n",
      "\titers: 200, epoch: 14 | loss: 0.0764564\n",
      "\tspeed: 0.0270s/iter; left time: 516.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0731561 Vali Loss: 0.0764050 Test Loss: 0.0881921\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733460\n",
      "\tspeed: 0.0543s/iter; left time: 1032.1122s\n",
      "\titers: 200, epoch: 15 | loss: 0.0726849\n",
      "\tspeed: 0.0273s/iter; left time: 515.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0728082 Vali Loss: 0.0762584 Test Loss: 0.0878794\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713056\n",
      "\tspeed: 0.0524s/iter; left time: 982.8385s\n",
      "\titers: 200, epoch: 16 | loss: 0.0673408\n",
      "\tspeed: 0.0280s/iter; left time: 523.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0725102 Vali Loss: 0.0764893 Test Loss: 0.0877887\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0729090\n",
      "\tspeed: 0.0530s/iter; left time: 982.7459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736606\n",
      "\tspeed: 0.0270s/iter; left time: 498.6336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0722571 Vali Loss: 0.0764543 Test Loss: 0.0877635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0751263\n",
      "\tspeed: 0.0551s/iter; left time: 1010.3302s\n",
      "\titers: 200, epoch: 18 | loss: 0.0732667\n",
      "\tspeed: 0.0264s/iter; left time: 480.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 222 | Train Loss: 0.0720145 Vali Loss: 0.0763173 Test Loss: 0.0881959\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0712821\n",
      "\tspeed: 0.0561s/iter; left time: 1015.0635s\n",
      "\titers: 200, epoch: 19 | loss: 0.0737556\n",
      "\tspeed: 0.0275s/iter; left time: 494.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0717988 Vali Loss: 0.0764204 Test Loss: 0.0878492\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0701951\n",
      "\tspeed: 0.0559s/iter; left time: 1000.3240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730100\n",
      "\tspeed: 0.0292s/iter; left time: 519.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0715539 Vali Loss: 0.0763633 Test Loss: 0.0877618\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01899096928536892, rmse:0.1378077268600464, mae:0.08816458284854889, rse:0.40483760833740234\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:36.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1250355\n",
      "\tspeed: 0.0545s/iter; left time: 1204.7699s\n",
      "\titers: 200, epoch: 1 | loss: 0.1118319\n",
      "\tspeed: 0.0281s/iter; left time: 617.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 222 | Train Loss: 0.1330013 Vali Loss: 0.1052809 Test Loss: 0.1202528\n",
      "Validation loss decreased (inf --> 0.105281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916071\n",
      "\tspeed: 0.0549s/iter; left time: 1200.7462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897428\n",
      "\tspeed: 0.0272s/iter; left time: 591.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0956554 Vali Loss: 0.0879480 Test Loss: 0.1003329\n",
      "Validation loss decreased (0.105281 --> 0.087948).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0914022\n",
      "\tspeed: 0.0579s/iter; left time: 1254.3048s\n",
      "\titers: 200, epoch: 3 | loss: 0.0906762\n",
      "\tspeed: 0.0270s/iter; left time: 582.6198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0882966 Vali Loss: 0.0851394 Test Loss: 0.0968764\n",
      "Validation loss decreased (0.087948 --> 0.085139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0883625\n",
      "\tspeed: 0.0564s/iter; left time: 1209.4570s\n",
      "\titers: 200, epoch: 4 | loss: 0.0835357\n",
      "\tspeed: 0.0272s/iter; left time: 580.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0856180 Vali Loss: 0.0840554 Test Loss: 0.0959844\n",
      "Validation loss decreased (0.085139 --> 0.084055).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803824\n",
      "\tspeed: 0.0554s/iter; left time: 1175.9016s\n",
      "\titers: 200, epoch: 5 | loss: 0.0853965\n",
      "\tspeed: 0.0286s/iter; left time: 603.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0838570 Vali Loss: 0.0833926 Test Loss: 0.0951348\n",
      "Validation loss decreased (0.084055 --> 0.083393).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797744\n",
      "\tspeed: 0.0533s/iter; left time: 1118.2968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826659\n",
      "\tspeed: 0.0287s/iter; left time: 600.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0822528 Vali Loss: 0.0830472 Test Loss: 0.0943015\n",
      "Validation loss decreased (0.083393 --> 0.083047).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828038\n",
      "\tspeed: 0.0536s/iter; left time: 1112.2997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825458\n",
      "\tspeed: 0.0272s/iter; left time: 562.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0811129 Vali Loss: 0.0834605 Test Loss: 0.0947691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0849840\n",
      "\tspeed: 0.0559s/iter; left time: 1148.1936s\n",
      "\titers: 200, epoch: 8 | loss: 0.0815625\n",
      "\tspeed: 0.0274s/iter; left time: 559.4835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0801981 Vali Loss: 0.0829874 Test Loss: 0.0947762\n",
      "Validation loss decreased (0.083047 --> 0.082987).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0781479\n",
      "\tspeed: 0.0549s/iter; left time: 1115.8102s\n",
      "\titers: 200, epoch: 9 | loss: 0.0818327\n",
      "\tspeed: 0.0275s/iter; left time: 555.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0794156 Vali Loss: 0.0829935 Test Loss: 0.0946946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794938\n",
      "\tspeed: 0.0533s/iter; left time: 1071.4783s\n",
      "\titers: 200, epoch: 10 | loss: 0.0774823\n",
      "\tspeed: 0.0288s/iter; left time: 576.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0786948 Vali Loss: 0.0832779 Test Loss: 0.0945250\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782731\n",
      "\tspeed: 0.0537s/iter; left time: 1068.0314s\n",
      "\titers: 200, epoch: 11 | loss: 0.0724275\n",
      "\tspeed: 0.0286s/iter; left time: 565.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0781504 Vali Loss: 0.0839142 Test Loss: 0.0944648\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0773756\n",
      "\tspeed: 0.0547s/iter; left time: 1075.9521s\n",
      "\titers: 200, epoch: 12 | loss: 0.0790120\n",
      "\tspeed: 0.0270s/iter; left time: 528.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0776322 Vali Loss: 0.0839175 Test Loss: 0.0947209\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0759633\n",
      "\tspeed: 0.0562s/iter; left time: 1091.6846s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766064\n",
      "\tspeed: 0.0270s/iter; left time: 522.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0772161 Vali Loss: 0.0840464 Test Loss: 0.0945042\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0776728\n",
      "\tspeed: 0.0551s/iter; left time: 1058.3260s\n",
      "\titers: 200, epoch: 14 | loss: 0.0716171\n",
      "\tspeed: 0.0279s/iter; left time: 533.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0768410 Vali Loss: 0.0839806 Test Loss: 0.0951329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770181\n",
      "\tspeed: 0.0529s/iter; left time: 1004.0617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740275\n",
      "\tspeed: 0.0280s/iter; left time: 529.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0765493 Vali Loss: 0.0842260 Test Loss: 0.0949700\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0760478\n",
      "\tspeed: 0.0558s/iter; left time: 1047.1025s\n",
      "\titers: 200, epoch: 16 | loss: 0.0732501\n",
      "\tspeed: 0.0275s/iter; left time: 512.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0762004 Vali Loss: 0.0838910 Test Loss: 0.0946376\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0764160\n",
      "\tspeed: 0.0565s/iter; left time: 1047.8797s\n",
      "\titers: 200, epoch: 17 | loss: 0.0790075\n",
      "\tspeed: 0.0273s/iter; left time: 504.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0759705 Vali Loss: 0.0844240 Test Loss: 0.0951427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0746448\n",
      "\tspeed: 0.0552s/iter; left time: 1012.1262s\n",
      "\titers: 200, epoch: 18 | loss: 0.0749086\n",
      "\tspeed: 0.0282s/iter; left time: 513.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0756720 Vali Loss: 0.0843374 Test Loss: 0.0958508\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021302737295627594, rmse:0.14595457911491394, mae:0.0947762206196785, rse:0.42880141735076904\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1263854\n",
      "\tspeed: 0.0309s/iter; left time: 682.9684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1156874\n",
      "\tspeed: 0.0276s/iter; left time: 606.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.1330581 Vali Loss: 0.1057428 Test Loss: 0.1209379\n",
      "Validation loss decreased (inf --> 0.105743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964121\n",
      "\tspeed: 0.0557s/iter; left time: 1218.0535s\n",
      "\titers: 200, epoch: 2 | loss: 0.0929709\n",
      "\tspeed: 0.0288s/iter; left time: 628.1006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0959172 Vali Loss: 0.0880870 Test Loss: 0.1012052\n",
      "Validation loss decreased (0.105743 --> 0.088087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0905122\n",
      "\tspeed: 0.0563s/iter; left time: 1219.2802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0891663\n",
      "\tspeed: 0.0291s/iter; left time: 628.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0886181 Vali Loss: 0.0859668 Test Loss: 0.0981919\n",
      "Validation loss decreased (0.088087 --> 0.085967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836552\n",
      "\tspeed: 0.0574s/iter; left time: 1231.0096s\n",
      "\titers: 200, epoch: 4 | loss: 0.0862615\n",
      "\tspeed: 0.0272s/iter; left time: 580.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0859728 Vali Loss: 0.0844449 Test Loss: 0.0958727\n",
      "Validation loss decreased (0.085967 --> 0.084445).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788982\n",
      "\tspeed: 0.0583s/iter; left time: 1237.0605s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824617\n",
      "\tspeed: 0.0274s/iter; left time: 577.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0840970 Vali Loss: 0.0829465 Test Loss: 0.0956325\n",
      "Validation loss decreased (0.084445 --> 0.082947).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843147\n",
      "\tspeed: 0.0562s/iter; left time: 1179.0831s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826297\n",
      "\tspeed: 0.0283s/iter; left time: 591.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0826575 Vali Loss: 0.0833131 Test Loss: 0.0959734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0814445\n",
      "\tspeed: 0.0537s/iter; left time: 1115.2986s\n",
      "\titers: 200, epoch: 7 | loss: 0.0826768\n",
      "\tspeed: 0.0289s/iter; left time: 597.0329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0814408 Vali Loss: 0.0830539 Test Loss: 0.0944358\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832167\n",
      "\tspeed: 0.0560s/iter; left time: 1149.8094s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797981\n",
      "\tspeed: 0.0274s/iter; left time: 560.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0804610 Vali Loss: 0.0830255 Test Loss: 0.0940806\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808557\n",
      "\tspeed: 0.0570s/iter; left time: 1159.0573s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788599\n",
      "\tspeed: 0.0269s/iter; left time: 544.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0795982 Vali Loss: 0.0830813 Test Loss: 0.0943129\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0793939\n",
      "\tspeed: 0.0553s/iter; left time: 1112.2653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804769\n",
      "\tspeed: 0.0272s/iter; left time: 543.1426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 222 | Train Loss: 0.0789372 Vali Loss: 0.0844544 Test Loss: 0.0946267\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0799205\n",
      "\tspeed: 0.0563s/iter; left time: 1120.1130s\n",
      "\titers: 200, epoch: 11 | loss: 0.0787828\n",
      "\tspeed: 0.0275s/iter; left time: 543.6759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0783694 Vali Loss: 0.0832267 Test Loss: 0.0936449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794356\n",
      "\tspeed: 0.0537s/iter; left time: 1055.5499s\n",
      "\titers: 200, epoch: 12 | loss: 0.0780849\n",
      "\tspeed: 0.0296s/iter; left time: 579.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0777887 Vali Loss: 0.0834535 Test Loss: 0.0943098\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0778237\n",
      "\tspeed: 0.0542s/iter; left time: 1054.2259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0756606\n",
      "\tspeed: 0.0274s/iter; left time: 529.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0773796 Vali Loss: 0.0838258 Test Loss: 0.0945887\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0753599\n",
      "\tspeed: 0.0570s/iter; left time: 1094.4866s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772503\n",
      "\tspeed: 0.0280s/iter; left time: 534.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0769784 Vali Loss: 0.0844897 Test Loss: 0.0947630\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747140\n",
      "\tspeed: 0.0574s/iter; left time: 1090.5105s\n",
      "\titers: 200, epoch: 15 | loss: 0.0749678\n",
      "\tspeed: 0.0272s/iter; left time: 514.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0766025 Vali Loss: 0.0839631 Test Loss: 0.0942935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021356923505663872, rmse:0.14614008367061615, mae:0.09563247114419937, rse:0.4293464124202728\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:47.34s\n",
      "Intermediate time for ES: 00h:26m:39.90s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0843132\n",
      "\tspeed: 0.0528s/iter; left time: 1172.4564s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826993\n",
      "\tspeed: 0.0273s/iter; left time: 602.6090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0928899 Vali Loss: 0.0809973 Test Loss: 0.0874650\n",
      "Validation loss decreased (inf --> 0.080997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0540009\n",
      "\tspeed: 0.0541s/iter; left time: 1189.4851s\n",
      "\titers: 200, epoch: 2 | loss: 0.0534995\n",
      "\tspeed: 0.0274s/iter; left time: 599.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0554808 Vali Loss: 0.0583653 Test Loss: 0.0612634\n",
      "Validation loss decreased (0.080997 --> 0.058365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0485997\n",
      "\tspeed: 0.0511s/iter; left time: 1112.2014s\n",
      "\titers: 200, epoch: 3 | loss: 0.0472784\n",
      "\tspeed: 0.0265s/iter; left time: 574.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0488961 Vali Loss: 0.0559211 Test Loss: 0.0598280\n",
      "Validation loss decreased (0.058365 --> 0.055921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495222\n",
      "\tspeed: 0.0554s/iter; left time: 1193.9438s\n",
      "\titers: 200, epoch: 4 | loss: 0.0483923\n",
      "\tspeed: 0.0266s/iter; left time: 569.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0470500 Vali Loss: 0.0548929 Test Loss: 0.0586228\n",
      "Validation loss decreased (0.055921 --> 0.054893).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0458255\n",
      "\tspeed: 0.0540s/iter; left time: 1151.1256s\n",
      "\titers: 200, epoch: 5 | loss: 0.0433537\n",
      "\tspeed: 0.0277s/iter; left time: 587.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0458443 Vali Loss: 0.0543292 Test Loss: 0.0576505\n",
      "Validation loss decreased (0.054893 --> 0.054329).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0430197\n",
      "\tspeed: 0.0517s/iter; left time: 1090.1838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0458188\n",
      "\tspeed: 0.0268s/iter; left time: 562.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0450522 Vali Loss: 0.0533698 Test Loss: 0.0574189\n",
      "Validation loss decreased (0.054329 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0436309\n",
      "\tspeed: 0.0533s/iter; left time: 1111.0120s\n",
      "\titers: 200, epoch: 7 | loss: 0.0437001\n",
      "\tspeed: 0.0274s/iter; left time: 568.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0443619 Vali Loss: 0.0534138 Test Loss: 0.0570331\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0455056\n",
      "\tspeed: 0.0547s/iter; left time: 1129.6775s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435005\n",
      "\tspeed: 0.0267s/iter; left time: 547.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0438976 Vali Loss: 0.0529732 Test Loss: 0.0568599\n",
      "Validation loss decreased (0.053370 --> 0.052973).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0422169\n",
      "\tspeed: 0.0547s/iter; left time: 1116.5035s\n",
      "\titers: 200, epoch: 9 | loss: 0.0433253\n",
      "\tspeed: 0.0267s/iter; left time: 542.1505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0434878 Vali Loss: 0.0527236 Test Loss: 0.0561925\n",
      "Validation loss decreased (0.052973 --> 0.052724).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0444294\n",
      "\tspeed: 0.0521s/iter; left time: 1051.5519s\n",
      "\titers: 200, epoch: 10 | loss: 0.0413240\n",
      "\tspeed: 0.0280s/iter; left time: 562.0882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0431111 Vali Loss: 0.0524848 Test Loss: 0.0564840\n",
      "Validation loss decreased (0.052724 --> 0.052485).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0447372\n",
      "\tspeed: 0.0547s/iter; left time: 1091.9684s\n",
      "\titers: 200, epoch: 11 | loss: 0.0443235\n",
      "\tspeed: 0.0272s/iter; left time: 539.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0428224 Vali Loss: 0.0525295 Test Loss: 0.0564360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0440985\n",
      "\tspeed: 0.0526s/iter; left time: 1039.4210s\n",
      "\titers: 200, epoch: 12 | loss: 0.0438725\n",
      "\tspeed: 0.0282s/iter; left time: 553.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0425661 Vali Loss: 0.0519805 Test Loss: 0.0558995\n",
      "Validation loss decreased (0.052485 --> 0.051981).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0421945\n",
      "\tspeed: 0.0540s/iter; left time: 1054.1201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0413549\n",
      "\tspeed: 0.0263s/iter; left time: 511.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0423398 Vali Loss: 0.0518698 Test Loss: 0.0560660\n",
      "Validation loss decreased (0.051981 --> 0.051870).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0388299\n",
      "\tspeed: 0.0537s/iter; left time: 1036.0091s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418125\n",
      "\tspeed: 0.0280s/iter; left time: 538.1113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0421227 Vali Loss: 0.0520392 Test Loss: 0.0560852\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0425634\n",
      "\tspeed: 0.0541s/iter; left time: 1032.7221s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422673\n",
      "\tspeed: 0.0281s/iter; left time: 532.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0419951 Vali Loss: 0.0516969 Test Loss: 0.0556645\n",
      "Validation loss decreased (0.051870 --> 0.051697).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0408609\n",
      "\tspeed: 0.0569s/iter; left time: 1073.5040s\n",
      "\titers: 200, epoch: 16 | loss: 0.0428541\n",
      "\tspeed: 0.0264s/iter; left time: 495.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0417983 Vali Loss: 0.0516113 Test Loss: 0.0556568\n",
      "Validation loss decreased (0.051697 --> 0.051611).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0433161\n",
      "\tspeed: 0.0539s/iter; left time: 1004.8645s\n",
      "\titers: 200, epoch: 17 | loss: 0.0422571\n",
      "\tspeed: 0.0269s/iter; left time: 497.8583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0416500 Vali Loss: 0.0514052 Test Loss: 0.0555000\n",
      "Validation loss decreased (0.051611 --> 0.051405).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0451433\n",
      "\tspeed: 0.0543s/iter; left time: 1000.5573s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420981\n",
      "\tspeed: 0.0266s/iter; left time: 487.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0415242 Vali Loss: 0.0517223 Test Loss: 0.0556480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0410448\n",
      "\tspeed: 0.0513s/iter; left time: 932.6076s\n",
      "\titers: 200, epoch: 19 | loss: 0.0432532\n",
      "\tspeed: 0.0282s/iter; left time: 509.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0414556 Vali Loss: 0.0513815 Test Loss: 0.0556669\n",
      "Validation loss decreased (0.051405 --> 0.051381).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0432690\n",
      "\tspeed: 0.0525s/iter; left time: 942.6680s\n",
      "\titers: 200, epoch: 20 | loss: 0.0416686\n",
      "\tspeed: 0.0271s/iter; left time: 484.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0412836 Vali Loss: 0.0514204 Test Loss: 0.0554169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0411735\n",
      "\tspeed: 0.0527s/iter; left time: 935.6835s\n",
      "\titers: 200, epoch: 21 | loss: 0.0403434\n",
      "\tspeed: 0.0275s/iter; left time: 485.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0411740 Vali Loss: 0.0512162 Test Loss: 0.0553809\n",
      "Validation loss decreased (0.051381 --> 0.051216).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410238\n",
      "\tspeed: 0.0536s/iter; left time: 939.4560s\n",
      "\titers: 200, epoch: 22 | loss: 0.0431798\n",
      "\tspeed: 0.0267s/iter; left time: 464.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0411241 Vali Loss: 0.0512545 Test Loss: 0.0554124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0430400\n",
      "\tspeed: 0.0530s/iter; left time: 916.0372s\n",
      "\titers: 200, epoch: 23 | loss: 0.0405390\n",
      "\tspeed: 0.0280s/iter; left time: 481.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0410707 Vali Loss: 0.0511939 Test Loss: 0.0553393\n",
      "Validation loss decreased (0.051216 --> 0.051194).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0420456\n",
      "\tspeed: 0.0517s/iter; left time: 882.1424s\n",
      "\titers: 200, epoch: 24 | loss: 0.0422551\n",
      "\tspeed: 0.0284s/iter; left time: 482.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0409819 Vali Loss: 0.0512411 Test Loss: 0.0552675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0419776\n",
      "\tspeed: 0.0554s/iter; left time: 933.9544s\n",
      "\titers: 200, epoch: 25 | loss: 0.0394762\n",
      "\tspeed: 0.0267s/iter; left time: 447.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0409476 Vali Loss: 0.0512755 Test Loss: 0.0553754\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0415562\n",
      "\tspeed: 0.0537s/iter; left time: 893.2178s\n",
      "\titers: 200, epoch: 26 | loss: 0.0394714\n",
      "\tspeed: 0.0278s/iter; left time: 459.1665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408676 Vali Loss: 0.0510152 Test Loss: 0.0553677\n",
      "Validation loss decreased (0.051194 --> 0.051015).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0425590\n",
      "\tspeed: 0.0547s/iter; left time: 897.5023s\n",
      "\titers: 200, epoch: 27 | loss: 0.0395341\n",
      "\tspeed: 0.0267s/iter; left time: 435.8227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0408256 Vali Loss: 0.0510102 Test Loss: 0.0553386\n",
      "Validation loss decreased (0.051015 --> 0.051010).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0406038\n",
      "\tspeed: 0.0527s/iter; left time: 853.1032s\n",
      "\titers: 200, epoch: 28 | loss: 0.0398112\n",
      "\tspeed: 0.0281s/iter; left time: 452.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0407815 Vali Loss: 0.0511237 Test Loss: 0.0552632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0404074\n",
      "\tspeed: 0.0522s/iter; left time: 832.5402s\n",
      "\titers: 200, epoch: 29 | loss: 0.0439339\n",
      "\tspeed: 0.0265s/iter; left time: 419.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0407395 Vali Loss: 0.0510612 Test Loss: 0.0552591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0436032\n",
      "\tspeed: 0.0548s/iter; left time: 861.7810s\n",
      "\titers: 200, epoch: 30 | loss: 0.0381865\n",
      "\tspeed: 0.0266s/iter; left time: 415.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0406719 Vali Loss: 0.0511291 Test Loss: 0.0551437\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0385469\n",
      "\tspeed: 0.0521s/iter; left time: 808.2974s\n",
      "\titers: 200, epoch: 31 | loss: 0.0384711\n",
      "\tspeed: 0.0265s/iter; left time: 408.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0406380 Vali Loss: 0.0509718 Test Loss: 0.0551497\n",
      "Validation loss decreased (0.051010 --> 0.050972).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0395896\n",
      "\tspeed: 0.0563s/iter; left time: 860.3259s\n",
      "\titers: 200, epoch: 32 | loss: 0.0421091\n",
      "\tspeed: 0.0276s/iter; left time: 419.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0406369 Vali Loss: 0.0510668 Test Loss: 0.0552206\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0381517\n",
      "\tspeed: 0.0534s/iter; left time: 805.1249s\n",
      "\titers: 200, epoch: 33 | loss: 0.0395394\n",
      "\tspeed: 0.0287s/iter; left time: 429.9415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0406346 Vali Loss: 0.0509685 Test Loss: 0.0552220\n",
      "Validation loss decreased (0.050972 --> 0.050968).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0390877\n",
      "\tspeed: 0.0529s/iter; left time: 784.9570s\n",
      "\titers: 200, epoch: 34 | loss: 0.0426558\n",
      "\tspeed: 0.0271s/iter; left time: 399.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0406084 Vali Loss: 0.0509817 Test Loss: 0.0551818\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0396101\n",
      "\tspeed: 0.0550s/iter; left time: 804.7154s\n",
      "\titers: 200, epoch: 35 | loss: 0.0452002\n",
      "\tspeed: 0.0268s/iter; left time: 388.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0405750 Vali Loss: 0.0510232 Test Loss: 0.0551961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0396727\n",
      "\tspeed: 0.0535s/iter; left time: 770.7884s\n",
      "\titers: 200, epoch: 36 | loss: 0.0376845\n",
      "\tspeed: 0.0274s/iter; left time: 391.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0405536 Vali Loss: 0.0509294 Test Loss: 0.0551972\n",
      "Validation loss decreased (0.050968 --> 0.050929).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0383235\n",
      "\tspeed: 0.0553s/iter; left time: 784.1062s\n",
      "\titers: 200, epoch: 37 | loss: 0.0379358\n",
      "\tspeed: 0.0283s/iter; left time: 398.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0405320 Vali Loss: 0.0509095 Test Loss: 0.0551600\n",
      "Validation loss decreased (0.050929 --> 0.050909).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0440550\n",
      "\tspeed: 0.0517s/iter; left time: 721.2223s\n",
      "\titers: 200, epoch: 38 | loss: 0.0409360\n",
      "\tspeed: 0.0271s/iter; left time: 375.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0405302 Vali Loss: 0.0509632 Test Loss: 0.0551483\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0424551\n",
      "\tspeed: 0.0544s/iter; left time: 746.2891s\n",
      "\titers: 200, epoch: 39 | loss: 0.0407349\n",
      "\tspeed: 0.0268s/iter; left time: 364.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404400 Vali Loss: 0.0509475 Test Loss: 0.0551755\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0399665\n",
      "\tspeed: 0.0539s/iter; left time: 727.9944s\n",
      "\titers: 200, epoch: 40 | loss: 0.0386363\n",
      "\tspeed: 0.0276s/iter; left time: 370.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 223 | Train Loss: 0.0405515 Vali Loss: 0.0509822 Test Loss: 0.0551663\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0414642\n",
      "\tspeed: 0.0536s/iter; left time: 711.4697s\n",
      "\titers: 200, epoch: 41 | loss: 0.0414216\n",
      "\tspeed: 0.0270s/iter; left time: 356.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0405032 Vali Loss: 0.0509070 Test Loss: 0.0551836\n",
      "Validation loss decreased (0.050909 --> 0.050907).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0396513\n",
      "\tspeed: 0.0547s/iter; left time: 714.2081s\n",
      "\titers: 200, epoch: 42 | loss: 0.0407175\n",
      "\tspeed: 0.0273s/iter; left time: 354.3178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0404501 Vali Loss: 0.0509050 Test Loss: 0.0551621\n",
      "Validation loss decreased (0.050907 --> 0.050905).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0419802\n",
      "\tspeed: 0.0522s/iter; left time: 669.5941s\n",
      "\titers: 200, epoch: 43 | loss: 0.0435936\n",
      "\tspeed: 0.0268s/iter; left time: 341.9310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0404785 Vali Loss: 0.0510068 Test Loss: 0.0551562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0377414\n",
      "\tspeed: 0.0557s/iter; left time: 702.0427s\n",
      "\titers: 200, epoch: 44 | loss: 0.0404162\n",
      "\tspeed: 0.0268s/iter; left time: 335.1467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0404870 Vali Loss: 0.0509230 Test Loss: 0.0551347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0397641\n",
      "\tspeed: 0.0534s/iter; left time: 661.6692s\n",
      "\titers: 200, epoch: 45 | loss: 0.0363073\n",
      "\tspeed: 0.0280s/iter; left time: 343.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0404352 Vali Loss: 0.0509129 Test Loss: 0.0551449\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0382217\n",
      "\tspeed: 0.0512s/iter; left time: 622.3970s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383492\n",
      "\tspeed: 0.0275s/iter; left time: 331.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0404233 Vali Loss: 0.0509525 Test Loss: 0.0551411\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0375880\n",
      "\tspeed: 0.0539s/iter; left time: 644.2997s\n",
      "\titers: 200, epoch: 47 | loss: 0.0388351\n",
      "\tspeed: 0.0276s/iter; left time: 326.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404278 Vali Loss: 0.0509438 Test Loss: 0.0551423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0394593\n",
      "\tspeed: 0.0537s/iter; left time: 628.9858s\n",
      "\titers: 200, epoch: 48 | loss: 0.0419493\n",
      "\tspeed: 0.0263s/iter; left time: 305.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0404258 Vali Loss: 0.0509123 Test Loss: 0.0551539\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0434436\n",
      "\tspeed: 0.0508s/iter; left time: 584.4281s\n",
      "\titers: 200, epoch: 49 | loss: 0.0394077\n",
      "\tspeed: 0.0265s/iter; left time: 301.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0404041 Vali Loss: 0.0509195 Test Loss: 0.0551415\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0392535\n",
      "\tspeed: 0.0513s/iter; left time: 577.8123s\n",
      "\titers: 200, epoch: 50 | loss: 0.0380202\n",
      "\tspeed: 0.0285s/iter; left time: 318.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0404302 Vali Loss: 0.0509391 Test Loss: 0.0551524\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0440110\n",
      "\tspeed: 0.0531s/iter; left time: 586.7326s\n",
      "\titers: 200, epoch: 51 | loss: 0.0394740\n",
      "\tspeed: 0.0266s/iter; left time: 291.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0404130 Vali Loss: 0.0508948 Test Loss: 0.0551422\n",
      "Validation loss decreased (0.050905 --> 0.050895).  Saving model ...\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0448568\n",
      "\tspeed: 0.0530s/iter; left time: 573.4647s\n",
      "\titers: 200, epoch: 52 | loss: 0.0377624\n",
      "\tspeed: 0.0274s/iter; left time: 294.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403924 Vali Loss: 0.0509185 Test Loss: 0.0551236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0432277\n",
      "\tspeed: 0.0544s/iter; left time: 577.3631s\n",
      "\titers: 200, epoch: 53 | loss: 0.0382022\n",
      "\tspeed: 0.0266s/iter; left time: 278.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0403406 Vali Loss: 0.0509090 Test Loss: 0.0551386\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0392583\n",
      "\tspeed: 0.0539s/iter; left time: 559.1625s\n",
      "\titers: 200, epoch: 54 | loss: 0.0379959\n",
      "\tspeed: 0.0282s/iter; left time: 289.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 223 | Train Loss: 0.0403821 Vali Loss: 0.0509590 Test Loss: 0.0551205\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0424123\n",
      "\tspeed: 0.0516s/iter; left time: 524.5061s\n",
      "\titers: 200, epoch: 55 | loss: 0.0390990\n",
      "\tspeed: 0.0277s/iter; left time: 278.7551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404026 Vali Loss: 0.0508852 Test Loss: 0.0551308\n",
      "Validation loss decreased (0.050895 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0409146\n",
      "\tspeed: 0.0545s/iter; left time: 541.4831s\n",
      "\titers: 200, epoch: 56 | loss: 0.0394938\n",
      "\tspeed: 0.0264s/iter; left time: 259.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403666 Vali Loss: 0.0509080 Test Loss: 0.0551149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0383278\n",
      "\tspeed: 0.0563s/iter; left time: 546.3756s\n",
      "\titers: 200, epoch: 57 | loss: 0.0380404\n",
      "\tspeed: 0.0269s/iter; left time: 258.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0403914 Vali Loss: 0.0508964 Test Loss: 0.0551263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0374241\n",
      "\tspeed: 0.0562s/iter; left time: 533.1406s\n",
      "\titers: 200, epoch: 58 | loss: 0.0384800\n",
      "\tspeed: 0.0266s/iter; left time: 250.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0404106 Vali Loss: 0.0509074 Test Loss: 0.0551193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0425259\n",
      "\tspeed: 0.0510s/iter; left time: 472.3618s\n",
      "\titers: 200, epoch: 59 | loss: 0.0383911\n",
      "\tspeed: 0.0300s/iter; left time: 275.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0403796 Vali Loss: 0.0508939 Test Loss: 0.0551248\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0411102\n",
      "\tspeed: 0.0529s/iter; left time: 478.6612s\n",
      "\titers: 200, epoch: 60 | loss: 0.0403990\n",
      "\tspeed: 0.0263s/iter; left time: 235.0986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0403918 Vali Loss: 0.0508964 Test Loss: 0.0551259\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0418877\n",
      "\tspeed: 0.0570s/iter; left time: 502.4903s\n",
      "\titers: 200, epoch: 61 | loss: 0.0403620\n",
      "\tspeed: 0.0272s/iter; left time: 236.8564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0403829 Vali Loss: 0.0509169 Test Loss: 0.0551298\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0394381\n",
      "\tspeed: 0.0554s/iter; left time: 476.7332s\n",
      "\titers: 200, epoch: 62 | loss: 0.0413030\n",
      "\tspeed: 0.0270s/iter; left time: 229.3679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403858 Vali Loss: 0.0509289 Test Loss: 0.0551388\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0361456\n",
      "\tspeed: 0.0547s/iter; left time: 458.4112s\n",
      "\titers: 200, epoch: 63 | loss: 0.0410837\n",
      "\tspeed: 0.0283s/iter; left time: 234.1365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403752 Vali Loss: 0.0509146 Test Loss: 0.0551340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0410504\n",
      "\tspeed: 0.0519s/iter; left time: 422.6970s\n",
      "\titers: 200, epoch: 64 | loss: 0.0393771\n",
      "\tspeed: 0.0273s/iter; left time: 220.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0403604 Vali Loss: 0.0509011 Test Loss: 0.0551318\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0404327\n",
      "\tspeed: 0.0566s/iter; left time: 448.6071s\n",
      "\titers: 200, epoch: 65 | loss: 0.0426011\n",
      "\tspeed: 0.0267s/iter; left time: 209.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0403942 Vali Loss: 0.0509536 Test Loss: 0.0551359\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010024277493357658, rmse:0.10012131184339523, mae:0.055130843073129654, rse:0.38626524806022644\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0906341\n",
      "\tspeed: 0.0301s/iter; left time: 667.8155s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826328\n",
      "\tspeed: 0.0263s/iter; left time: 582.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0938272 Vali Loss: 0.0805418 Test Loss: 0.0871429\n",
      "Validation loss decreased (inf --> 0.080542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0551709\n",
      "\tspeed: 0.0576s/iter; left time: 1265.1429s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524309\n",
      "\tspeed: 0.0271s/iter; left time: 592.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0558666 Vali Loss: 0.0584886 Test Loss: 0.0616178\n",
      "Validation loss decreased (0.080542 --> 0.058489).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0486506\n",
      "\tspeed: 0.0536s/iter; left time: 1166.1015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0469318\n",
      "\tspeed: 0.0284s/iter; left time: 615.9902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0488140 Vali Loss: 0.0560299 Test Loss: 0.0600615\n",
      "Validation loss decreased (0.058489 --> 0.056030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0490200\n",
      "\tspeed: 0.0527s/iter; left time: 1134.7966s\n",
      "\titers: 200, epoch: 4 | loss: 0.0490843\n",
      "\tspeed: 0.0289s/iter; left time: 619.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 223 | Train Loss: 0.0470409 Vali Loss: 0.0548938 Test Loss: 0.0585970\n",
      "Validation loss decreased (0.056030 --> 0.054894).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0493169\n",
      "\tspeed: 0.0564s/iter; left time: 1202.6886s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423416\n",
      "\tspeed: 0.0264s/iter; left time: 560.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0458134 Vali Loss: 0.0537671 Test Loss: 0.0576985\n",
      "Validation loss decreased (0.054894 --> 0.053767).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0481958\n",
      "\tspeed: 0.0571s/iter; left time: 1204.8272s\n",
      "\titers: 200, epoch: 6 | loss: 0.0447032\n",
      "\tspeed: 0.0268s/iter; left time: 561.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0449244 Vali Loss: 0.0531660 Test Loss: 0.0571905\n",
      "Validation loss decreased (0.053767 --> 0.053166).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0444714\n",
      "\tspeed: 0.0541s/iter; left time: 1128.9689s\n",
      "\titers: 200, epoch: 7 | loss: 0.0447756\n",
      "\tspeed: 0.0277s/iter; left time: 575.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0443288 Vali Loss: 0.0529909 Test Loss: 0.0570281\n",
      "Validation loss decreased (0.053166 --> 0.052991).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460659\n",
      "\tspeed: 0.0543s/iter; left time: 1119.9415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0454672\n",
      "\tspeed: 0.0291s/iter; left time: 598.5550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 223 | Train Loss: 0.0438346 Vali Loss: 0.0530107 Test Loss: 0.0570792\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458995\n",
      "\tspeed: 0.0516s/iter; left time: 1054.2843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0426223\n",
      "\tspeed: 0.0270s/iter; left time: 548.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0434338 Vali Loss: 0.0526153 Test Loss: 0.0565650\n",
      "Validation loss decreased (0.052991 --> 0.052615).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0406584\n",
      "\tspeed: 0.0555s/iter; left time: 1121.0964s\n",
      "\titers: 200, epoch: 10 | loss: 0.0479837\n",
      "\tspeed: 0.0265s/iter; left time: 533.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0430610 Vali Loss: 0.0523429 Test Loss: 0.0565098\n",
      "Validation loss decreased (0.052615 --> 0.052343).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441144\n",
      "\tspeed: 0.0565s/iter; left time: 1127.7538s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424211\n",
      "\tspeed: 0.0273s/iter; left time: 543.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 223 | Train Loss: 0.0427796 Vali Loss: 0.0520273 Test Loss: 0.0561341\n",
      "Validation loss decreased (0.052343 --> 0.052027).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0395642\n",
      "\tspeed: 0.0539s/iter; left time: 1064.6384s\n",
      "\titers: 200, epoch: 12 | loss: 0.0417812\n",
      "\tspeed: 0.0275s/iter; left time: 541.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0424066 Vali Loss: 0.0522500 Test Loss: 0.0566746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465006\n",
      "\tspeed: 0.0542s/iter; left time: 1057.6991s\n",
      "\titers: 200, epoch: 13 | loss: 0.0409592\n",
      "\tspeed: 0.0280s/iter; left time: 543.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0422092 Vali Loss: 0.0518321 Test Loss: 0.0560570\n",
      "Validation loss decreased (0.052027 --> 0.051832).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417979\n",
      "\tspeed: 0.0529s/iter; left time: 1020.2572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0418281\n",
      "\tspeed: 0.0271s/iter; left time: 520.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0420007 Vali Loss: 0.0518557 Test Loss: 0.0559012\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0409619\n",
      "\tspeed: 0.0591s/iter; left time: 1127.5658s\n",
      "\titers: 200, epoch: 15 | loss: 0.0422560\n",
      "\tspeed: 0.0264s/iter; left time: 501.5630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0418025 Vali Loss: 0.0515299 Test Loss: 0.0558530\n",
      "Validation loss decreased (0.051832 --> 0.051530).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0418751\n",
      "\tspeed: 0.0557s/iter; left time: 1050.5298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0431925\n",
      "\tspeed: 0.0278s/iter; left time: 521.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 223 | Train Loss: 0.0416322 Vali Loss: 0.0516220 Test Loss: 0.0559839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0416599\n",
      "\tspeed: 0.0536s/iter; left time: 998.4634s\n",
      "\titers: 200, epoch: 17 | loss: 0.0385930\n",
      "\tspeed: 0.0288s/iter; left time: 533.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0415159 Vali Loss: 0.0515925 Test Loss: 0.0557896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0403570\n",
      "\tspeed: 0.0546s/iter; left time: 1005.0983s\n",
      "\titers: 200, epoch: 18 | loss: 0.0396579\n",
      "\tspeed: 0.0271s/iter; left time: 496.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0413374 Vali Loss: 0.0514856 Test Loss: 0.0555889\n",
      "Validation loss decreased (0.051530 --> 0.051486).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0426625\n",
      "\tspeed: 0.0550s/iter; left time: 999.9825s\n",
      "\titers: 200, epoch: 19 | loss: 0.0415856\n",
      "\tspeed: 0.0267s/iter; left time: 483.7707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0412477 Vali Loss: 0.0512750 Test Loss: 0.0556268\n",
      "Validation loss decreased (0.051486 --> 0.051275).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0406603\n",
      "\tspeed: 0.0572s/iter; left time: 1027.6752s\n",
      "\titers: 200, epoch: 20 | loss: 0.0444297\n",
      "\tspeed: 0.0266s/iter; left time: 475.1067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0412201 Vali Loss: 0.0512715 Test Loss: 0.0556442\n",
      "Validation loss decreased (0.051275 --> 0.051271).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0446360\n",
      "\tspeed: 0.0541s/iter; left time: 959.2371s\n",
      "\titers: 200, epoch: 21 | loss: 0.0451247\n",
      "\tspeed: 0.0288s/iter; left time: 508.2968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 223 | Train Loss: 0.0410562 Vali Loss: 0.0510677 Test Loss: 0.0556257\n",
      "Validation loss decreased (0.051271 --> 0.051068).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0413175\n",
      "\tspeed: 0.0525s/iter; left time: 920.2055s\n",
      "\titers: 200, epoch: 22 | loss: 0.0406883\n",
      "\tspeed: 0.0282s/iter; left time: 491.7806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0409632 Vali Loss: 0.0511050 Test Loss: 0.0554848\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0413638\n",
      "\tspeed: 0.0532s/iter; left time: 920.3822s\n",
      "\titers: 200, epoch: 23 | loss: 0.0385806\n",
      "\tspeed: 0.0282s/iter; left time: 485.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0408717 Vali Loss: 0.0511044 Test Loss: 0.0554944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0418123\n",
      "\tspeed: 0.0560s/iter; left time: 956.3025s\n",
      "\titers: 200, epoch: 24 | loss: 0.0407323\n",
      "\tspeed: 0.0265s/iter; left time: 450.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0408074 Vali Loss: 0.0511794 Test Loss: 0.0554869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0389306\n",
      "\tspeed: 0.0548s/iter; left time: 924.0469s\n",
      "\titers: 200, epoch: 25 | loss: 0.0398802\n",
      "\tspeed: 0.0273s/iter; left time: 457.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0407822 Vali Loss: 0.0511632 Test Loss: 0.0554472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0406251\n",
      "\tspeed: 0.0514s/iter; left time: 854.9484s\n",
      "\titers: 200, epoch: 26 | loss: 0.0404109\n",
      "\tspeed: 0.0297s/iter; left time: 491.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 223 | Train Loss: 0.0406947 Vali Loss: 0.0510870 Test Loss: 0.0554563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0426260\n",
      "\tspeed: 0.0533s/iter; left time: 873.7834s\n",
      "\titers: 200, epoch: 27 | loss: 0.0422118\n",
      "\tspeed: 0.0264s/iter; left time: 430.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0406440 Vali Loss: 0.0510169 Test Loss: 0.0554277\n",
      "Validation loss decreased (0.051068 --> 0.051017).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0433261\n",
      "\tspeed: 0.0584s/iter; left time: 944.4422s\n",
      "\titers: 200, epoch: 28 | loss: 0.0414303\n",
      "\tspeed: 0.0272s/iter; left time: 438.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0406054 Vali Loss: 0.0510836 Test Loss: 0.0553864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0386375\n",
      "\tspeed: 0.0533s/iter; left time: 849.9980s\n",
      "\titers: 200, epoch: 29 | loss: 0.0398392\n",
      "\tspeed: 0.0267s/iter; left time: 422.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0405403 Vali Loss: 0.0510816 Test Loss: 0.0554030\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0395849\n",
      "\tspeed: 0.0570s/iter; left time: 897.0832s\n",
      "\titers: 200, epoch: 30 | loss: 0.0434685\n",
      "\tspeed: 0.0287s/iter; left time: 447.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0405472 Vali Loss: 0.0509714 Test Loss: 0.0553758\n",
      "Validation loss decreased (0.051017 --> 0.050971).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0404055\n",
      "\tspeed: 0.0524s/iter; left time: 812.5939s\n",
      "\titers: 200, epoch: 31 | loss: 0.0423716\n",
      "\tspeed: 0.0274s/iter; left time: 422.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0404917 Vali Loss: 0.0509903 Test Loss: 0.0553255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0410218\n",
      "\tspeed: 0.0558s/iter; left time: 853.0859s\n",
      "\titers: 200, epoch: 32 | loss: 0.0379313\n",
      "\tspeed: 0.0265s/iter; left time: 403.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0404833 Vali Loss: 0.0509146 Test Loss: 0.0553534\n",
      "Validation loss decreased (0.050971 --> 0.050915).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0403348\n",
      "\tspeed: 0.0554s/iter; left time: 834.4094s\n",
      "\titers: 200, epoch: 33 | loss: 0.0399958\n",
      "\tspeed: 0.0270s/iter; left time: 404.0324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0404073 Vali Loss: 0.0508854 Test Loss: 0.0553828\n",
      "Validation loss decreased (0.050915 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0402859\n",
      "\tspeed: 0.0528s/iter; left time: 784.3565s\n",
      "\titers: 200, epoch: 34 | loss: 0.0393198\n",
      "\tspeed: 0.0278s/iter; left time: 410.3908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0404330 Vali Loss: 0.0509054 Test Loss: 0.0553213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0399488\n",
      "\tspeed: 0.0524s/iter; left time: 766.7168s\n",
      "\titers: 200, epoch: 35 | loss: 0.0390085\n",
      "\tspeed: 0.0271s/iter; left time: 392.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0403941 Vali Loss: 0.0509035 Test Loss: 0.0553123\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0437253\n",
      "\tspeed: 0.0543s/iter; left time: 781.3251s\n",
      "\titers: 200, epoch: 36 | loss: 0.0389777\n",
      "\tspeed: 0.0265s/iter; left time: 379.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0403536 Vali Loss: 0.0508838 Test Loss: 0.0553374\n",
      "Validation loss decreased (0.050885 --> 0.050884).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0410785\n",
      "\tspeed: 0.0546s/iter; left time: 773.2454s\n",
      "\titers: 200, epoch: 37 | loss: 0.0399544\n",
      "\tspeed: 0.0268s/iter; left time: 377.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 223 | Train Loss: 0.0403515 Vali Loss: 0.0509292 Test Loss: 0.0553296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0391543\n",
      "\tspeed: 0.0525s/iter; left time: 732.7616s\n",
      "\titers: 200, epoch: 38 | loss: 0.0413559\n",
      "\tspeed: 0.0273s/iter; left time: 378.2236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0403439 Vali Loss: 0.0508500 Test Loss: 0.0553205\n",
      "Validation loss decreased (0.050884 --> 0.050850).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0417169\n",
      "\tspeed: 0.0569s/iter; left time: 780.8474s\n",
      "\titers: 200, epoch: 39 | loss: 0.0405512\n",
      "\tspeed: 0.0267s/iter; left time: 363.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0403442 Vali Loss: 0.0508796 Test Loss: 0.0553248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0447844\n",
      "\tspeed: 0.0542s/iter; left time: 731.6767s\n",
      "\titers: 200, epoch: 40 | loss: 0.0395523\n",
      "\tspeed: 0.0269s/iter; left time: 360.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0403389 Vali Loss: 0.0507638 Test Loss: 0.0552910\n",
      "Validation loss decreased (0.050850 --> 0.050764).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0417288\n",
      "\tspeed: 0.0538s/iter; left time: 714.9267s\n",
      "\titers: 200, epoch: 41 | loss: 0.0412049\n",
      "\tspeed: 0.0273s/iter; left time: 359.9401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0403560 Vali Loss: 0.0508435 Test Loss: 0.0553101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0378692\n",
      "\tspeed: 0.0529s/iter; left time: 690.6556s\n",
      "\titers: 200, epoch: 42 | loss: 0.0401617\n",
      "\tspeed: 0.0272s/iter; left time: 351.9640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0403200 Vali Loss: 0.0508418 Test Loss: 0.0553548\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0384229\n",
      "\tspeed: 0.0534s/iter; left time: 685.2592s\n",
      "\titers: 200, epoch: 43 | loss: 0.0370391\n",
      "\tspeed: 0.0282s/iter; left time: 359.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0402477 Vali Loss: 0.0508064 Test Loss: 0.0553414\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0432439\n",
      "\tspeed: 0.0566s/iter; left time: 713.6192s\n",
      "\titers: 200, epoch: 44 | loss: 0.0400607\n",
      "\tspeed: 0.0265s/iter; left time: 331.6480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0402985 Vali Loss: 0.0508538 Test Loss: 0.0553522\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0387721\n",
      "\tspeed: 0.0530s/iter; left time: 656.5277s\n",
      "\titers: 200, epoch: 45 | loss: 0.0426491\n",
      "\tspeed: 0.0284s/iter; left time: 349.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0402648 Vali Loss: 0.0508805 Test Loss: 0.0553688\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0391906\n",
      "\tspeed: 0.0538s/iter; left time: 654.6966s\n",
      "\titers: 200, epoch: 46 | loss: 0.0383839\n",
      "\tspeed: 0.0274s/iter; left time: 331.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0401979 Vali Loss: 0.0508143 Test Loss: 0.0553381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0380304\n",
      "\tspeed: 0.0531s/iter; left time: 634.4437s\n",
      "\titers: 200, epoch: 47 | loss: 0.0415097\n",
      "\tspeed: 0.0281s/iter; left time: 332.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0402226 Vali Loss: 0.0507866 Test Loss: 0.0553593\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0386002\n",
      "\tspeed: 0.0554s/iter; left time: 649.1937s\n",
      "\titers: 200, epoch: 48 | loss: 0.0388776\n",
      "\tspeed: 0.0274s/iter; left time: 318.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0401984 Vali Loss: 0.0508578 Test Loss: 0.0553353\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0421254\n",
      "\tspeed: 0.0550s/iter; left time: 632.6324s\n",
      "\titers: 200, epoch: 49 | loss: 0.0385936\n",
      "\tspeed: 0.0279s/iter; left time: 318.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0402498 Vali Loss: 0.0508001 Test Loss: 0.0553192\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0405090\n",
      "\tspeed: 0.0519s/iter; left time: 584.6391s\n",
      "\titers: 200, epoch: 50 | loss: 0.0411080\n",
      "\tspeed: 0.0275s/iter; left time: 307.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0402468 Vali Loss: 0.0508563 Test Loss: 0.0553059\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010074619203805923, rmse:0.10037240386009216, mae:0.055291011929512024, rse:0.3872339427471161\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:47.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0946442\n",
      "\tspeed: 0.0544s/iter; left time: 1201.8179s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807172\n",
      "\tspeed: 0.0280s/iter; left time: 615.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 222 | Train Loss: 0.0976983 Vali Loss: 0.0885321 Test Loss: 0.0971842\n",
      "Validation loss decreased (inf --> 0.088532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723190\n",
      "\tspeed: 0.0547s/iter; left time: 1197.6152s\n",
      "\titers: 200, epoch: 2 | loss: 0.0639201\n",
      "\tspeed: 0.0271s/iter; left time: 589.6803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0691408 Vali Loss: 0.0740071 Test Loss: 0.0823792\n",
      "Validation loss decreased (0.088532 --> 0.074007).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0629653\n",
      "\tspeed: 0.0547s/iter; left time: 1183.5931s\n",
      "\titers: 200, epoch: 3 | loss: 0.0609960\n",
      "\tspeed: 0.0295s/iter; left time: 635.9466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0631580 Vali Loss: 0.0724165 Test Loss: 0.0810770\n",
      "Validation loss decreased (0.074007 --> 0.072416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0591992\n",
      "\tspeed: 0.0530s/iter; left time: 1135.7080s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622611\n",
      "\tspeed: 0.0286s/iter; left time: 609.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0616025 Vali Loss: 0.0718696 Test Loss: 0.0810709\n",
      "Validation loss decreased (0.072416 --> 0.071870).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633924\n",
      "\tspeed: 0.0580s/iter; left time: 1231.3352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584497\n",
      "\tspeed: 0.0269s/iter; left time: 567.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0605206 Vali Loss: 0.0706461 Test Loss: 0.0808803\n",
      "Validation loss decreased (0.071870 --> 0.070646).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0617116\n",
      "\tspeed: 0.0574s/iter; left time: 1203.8881s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603344\n",
      "\tspeed: 0.0279s/iter; left time: 581.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0597658 Vali Loss: 0.0708851 Test Loss: 0.0804708\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572835\n",
      "\tspeed: 0.0551s/iter; left time: 1143.7419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595429\n",
      "\tspeed: 0.0276s/iter; left time: 569.7530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0592192 Vali Loss: 0.0702724 Test Loss: 0.0811357\n",
      "Validation loss decreased (0.070646 --> 0.070272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0600042\n",
      "\tspeed: 0.0542s/iter; left time: 1114.4691s\n",
      "\titers: 200, epoch: 8 | loss: 0.0576544\n",
      "\tspeed: 0.0292s/iter; left time: 597.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0586930 Vali Loss: 0.0699404 Test Loss: 0.0809467\n",
      "Validation loss decreased (0.070272 --> 0.069940).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0586163\n",
      "\tspeed: 0.0551s/iter; left time: 1119.9328s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577755\n",
      "\tspeed: 0.0277s/iter; left time: 560.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0582909 Vali Loss: 0.0698899 Test Loss: 0.0808146\n",
      "Validation loss decreased (0.069940 --> 0.069890).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633654\n",
      "\tspeed: 0.0606s/iter; left time: 1218.7369s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593716\n",
      "\tspeed: 0.0269s/iter; left time: 537.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0578296 Vali Loss: 0.0697316 Test Loss: 0.0806795\n",
      "Validation loss decreased (0.069890 --> 0.069732).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0568299\n",
      "\tspeed: 0.0564s/iter; left time: 1121.0738s\n",
      "\titers: 200, epoch: 11 | loss: 0.0571765\n",
      "\tspeed: 0.0281s/iter; left time: 556.7197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 222 | Train Loss: 0.0575434 Vali Loss: 0.0695331 Test Loss: 0.0808393\n",
      "Validation loss decreased (0.069732 --> 0.069533).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0532095\n",
      "\tspeed: 0.0540s/iter; left time: 1061.8762s\n",
      "\titers: 200, epoch: 12 | loss: 0.0552783\n",
      "\tspeed: 0.0286s/iter; left time: 559.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0572077 Vali Loss: 0.0695406 Test Loss: 0.0809313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564464\n",
      "\tspeed: 0.0544s/iter; left time: 1058.2301s\n",
      "\titers: 200, epoch: 13 | loss: 0.0570819\n",
      "\tspeed: 0.0273s/iter; left time: 527.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0568615 Vali Loss: 0.0693137 Test Loss: 0.0810390\n",
      "Validation loss decreased (0.069533 --> 0.069314).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0539912\n",
      "\tspeed: 0.0568s/iter; left time: 1090.8423s\n",
      "\titers: 200, epoch: 14 | loss: 0.0568080\n",
      "\tspeed: 0.0266s/iter; left time: 507.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 222 | Train Loss: 0.0565855 Vali Loss: 0.0695845 Test Loss: 0.0809268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0593582\n",
      "\tspeed: 0.0516s/iter; left time: 979.2710s\n",
      "\titers: 200, epoch: 15 | loss: 0.0566474\n",
      "\tspeed: 0.0271s/iter; left time: 511.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0563461 Vali Loss: 0.0693047 Test Loss: 0.0811887\n",
      "Validation loss decreased (0.069314 --> 0.069305).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0594476\n",
      "\tspeed: 0.0555s/iter; left time: 1040.9186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0533540\n",
      "\tspeed: 0.0293s/iter; left time: 546.7886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0560892 Vali Loss: 0.0693481 Test Loss: 0.0814752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0553667\n",
      "\tspeed: 0.0528s/iter; left time: 979.3788s\n",
      "\titers: 200, epoch: 17 | loss: 0.0557630\n",
      "\tspeed: 0.0302s/iter; left time: 556.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 222 | Train Loss: 0.0558328 Vali Loss: 0.0694838 Test Loss: 0.0814889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601683\n",
      "\tspeed: 0.0535s/iter; left time: 980.2696s\n",
      "\titers: 200, epoch: 18 | loss: 0.0555220\n",
      "\tspeed: 0.0278s/iter; left time: 506.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0556501 Vali Loss: 0.0696565 Test Loss: 0.0816849\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0553780\n",
      "\tspeed: 0.0552s/iter; left time: 999.6674s\n",
      "\titers: 200, epoch: 19 | loss: 0.0562586\n",
      "\tspeed: 0.0275s/iter; left time: 495.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0554732 Vali Loss: 0.0695040 Test Loss: 0.0815747\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0575418\n",
      "\tspeed: 0.0550s/iter; left time: 983.9110s\n",
      "\titers: 200, epoch: 20 | loss: 0.0529493\n",
      "\tspeed: 0.0278s/iter; left time: 494.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0552923 Vali Loss: 0.0695789 Test Loss: 0.0819936\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0552874\n",
      "\tspeed: 0.0537s/iter; left time: 949.1304s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571044\n",
      "\tspeed: 0.0302s/iter; left time: 530.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0551806 Vali Loss: 0.0696505 Test Loss: 0.0819064\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523697\n",
      "\tspeed: 0.0560s/iter; left time: 975.7897s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539634\n",
      "\tspeed: 0.0272s/iter; left time: 471.0802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0550097 Vali Loss: 0.0697481 Test Loss: 0.0818706\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570134\n",
      "\tspeed: 0.0566s/iter; left time: 973.8350s\n",
      "\titers: 200, epoch: 23 | loss: 0.0503240\n",
      "\tspeed: 0.0277s/iter; left time: 473.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0549191 Vali Loss: 0.0695426 Test Loss: 0.0819507\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0564718\n",
      "\tspeed: 0.0544s/iter; left time: 924.8548s\n",
      "\titers: 200, epoch: 24 | loss: 0.0560874\n",
      "\tspeed: 0.0284s/iter; left time: 479.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0547920 Vali Loss: 0.0694288 Test Loss: 0.0827027\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0538619\n",
      "\tspeed: 0.0546s/iter; left time: 916.5744s\n",
      "\titers: 200, epoch: 25 | loss: 0.0557052\n",
      "\tspeed: 0.0294s/iter; left time: 490.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0546779 Vali Loss: 0.0694937 Test Loss: 0.0824538\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019583983346819878, rmse:0.13994278013706207, mae:0.08118870854377747, rse:0.5413358807563782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0952129\n",
      "\tspeed: 0.0302s/iter; left time: 667.3766s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885167\n",
      "\tspeed: 0.0308s/iter; left time: 677.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0985027 Vali Loss: 0.0886972 Test Loss: 0.0972691\n",
      "Validation loss decreased (inf --> 0.088697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0681498\n",
      "\tspeed: 0.0563s/iter; left time: 1232.1622s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649547\n",
      "\tspeed: 0.0270s/iter; left time: 587.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0695079 Vali Loss: 0.0742967 Test Loss: 0.0827173\n",
      "Validation loss decreased (0.088697 --> 0.074297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636618\n",
      "\tspeed: 0.0621s/iter; left time: 1344.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.0675858\n",
      "\tspeed: 0.0272s/iter; left time: 585.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0632788 Vali Loss: 0.0724602 Test Loss: 0.0818352\n",
      "Validation loss decreased (0.074297 --> 0.072460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0607947\n",
      "\tspeed: 0.0583s/iter; left time: 1248.7349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615927\n",
      "\tspeed: 0.0288s/iter; left time: 613.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0616307 Vali Loss: 0.0715656 Test Loss: 0.0804375\n",
      "Validation loss decreased (0.072460 --> 0.071566).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622085\n",
      "\tspeed: 0.0546s/iter; left time: 1158.1798s\n",
      "\titers: 200, epoch: 5 | loss: 0.0607410\n",
      "\tspeed: 0.0310s/iter; left time: 653.6964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0605575 Vali Loss: 0.0711619 Test Loss: 0.0811173\n",
      "Validation loss decreased (0.071566 --> 0.071162).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0583275\n",
      "\tspeed: 0.0554s/iter; left time: 1163.7437s\n",
      "\titers: 200, epoch: 6 | loss: 0.0605036\n",
      "\tspeed: 0.0276s/iter; left time: 576.9671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 222 | Train Loss: 0.0598762 Vali Loss: 0.0707136 Test Loss: 0.0810201\n",
      "Validation loss decreased (0.071162 --> 0.070714).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571717\n",
      "\tspeed: 0.0581s/iter; left time: 1205.9736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580162\n",
      "\tspeed: 0.0270s/iter; left time: 558.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0591734 Vali Loss: 0.0701467 Test Loss: 0.0805756\n",
      "Validation loss decreased (0.070714 --> 0.070147).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549409\n",
      "\tspeed: 0.0596s/iter; left time: 1225.5543s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589893\n",
      "\tspeed: 0.0269s/iter; left time: 549.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0587496 Vali Loss: 0.0706592 Test Loss: 0.0805735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562943\n",
      "\tspeed: 0.0540s/iter; left time: 1097.0223s\n",
      "\titers: 200, epoch: 9 | loss: 0.0623835\n",
      "\tspeed: 0.0310s/iter; left time: 626.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 222 | Train Loss: 0.0582612 Vali Loss: 0.0701556 Test Loss: 0.0809764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0560510\n",
      "\tspeed: 0.0546s/iter; left time: 1098.6045s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569311\n",
      "\tspeed: 0.0277s/iter; left time: 553.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0579194 Vali Loss: 0.0698631 Test Loss: 0.0805883\n",
      "Validation loss decreased (0.070147 --> 0.069863).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0552880\n",
      "\tspeed: 0.0576s/iter; left time: 1145.5217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567831\n",
      "\tspeed: 0.0276s/iter; left time: 546.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0575630 Vali Loss: 0.0698857 Test Loss: 0.0814239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0589652\n",
      "\tspeed: 0.0585s/iter; left time: 1149.6359s\n",
      "\titers: 200, epoch: 12 | loss: 0.0571650\n",
      "\tspeed: 0.0272s/iter; left time: 531.7563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0572331 Vali Loss: 0.0696580 Test Loss: 0.0805479\n",
      "Validation loss decreased (0.069863 --> 0.069658).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596699\n",
      "\tspeed: 0.0590s/iter; left time: 1146.2923s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586063\n",
      "\tspeed: 0.0274s/iter; left time: 529.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0569622 Vali Loss: 0.0694498 Test Loss: 0.0804356\n",
      "Validation loss decreased (0.069658 --> 0.069450).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589501\n",
      "\tspeed: 0.0537s/iter; left time: 1032.2106s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569431\n",
      "\tspeed: 0.0325s/iter; left time: 620.9112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 222 | Train Loss: 0.0566912 Vali Loss: 0.0693219 Test Loss: 0.0799958\n",
      "Validation loss decreased (0.069450 --> 0.069322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506507\n",
      "\tspeed: 0.0546s/iter; left time: 1037.9295s\n",
      "\titers: 200, epoch: 15 | loss: 0.0569483\n",
      "\tspeed: 0.0267s/iter; left time: 503.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0564393 Vali Loss: 0.0695112 Test Loss: 0.0806874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0580912\n",
      "\tspeed: 0.0570s/iter; left time: 1069.7731s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560368\n",
      "\tspeed: 0.0276s/iter; left time: 514.8626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0562285 Vali Loss: 0.0692488 Test Loss: 0.0806654\n",
      "Validation loss decreased (0.069322 --> 0.069249).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0560966\n",
      "\tspeed: 0.0579s/iter; left time: 1074.1554s\n",
      "\titers: 200, epoch: 17 | loss: 0.0546358\n",
      "\tspeed: 0.0272s/iter; left time: 501.0310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0560600 Vali Loss: 0.0693445 Test Loss: 0.0808701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0536982\n",
      "\tspeed: 0.0545s/iter; left time: 998.5697s\n",
      "\titers: 200, epoch: 18 | loss: 0.0576510\n",
      "\tspeed: 0.0297s/iter; left time: 541.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0558209 Vali Loss: 0.0692960 Test Loss: 0.0809055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0568429\n",
      "\tspeed: 0.0538s/iter; left time: 974.8709s\n",
      "\titers: 200, epoch: 19 | loss: 0.0548730\n",
      "\tspeed: 0.0272s/iter; left time: 488.8693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0556284 Vali Loss: 0.0691479 Test Loss: 0.0808090\n",
      "Validation loss decreased (0.069249 --> 0.069148).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542075\n",
      "\tspeed: 0.0588s/iter; left time: 1052.1349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543660\n",
      "\tspeed: 0.0270s/iter; left time: 480.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0555214 Vali Loss: 0.0692614 Test Loss: 0.0808009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0560614\n",
      "\tspeed: 0.0583s/iter; left time: 1029.5537s\n",
      "\titers: 200, epoch: 21 | loss: 0.0538527\n",
      "\tspeed: 0.0276s/iter; left time: 483.8444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0553980 Vali Loss: 0.0693827 Test Loss: 0.0812554\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0574554\n",
      "\tspeed: 0.0532s/iter; left time: 927.7367s\n",
      "\titers: 200, epoch: 22 | loss: 0.0532297\n",
      "\tspeed: 0.0295s/iter; left time: 511.7947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0552347 Vali Loss: 0.0692179 Test Loss: 0.0811274\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0512069\n",
      "\tspeed: 0.0557s/iter; left time: 958.7464s\n",
      "\titers: 200, epoch: 23 | loss: 0.0576784\n",
      "\tspeed: 0.0279s/iter; left time: 476.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0551042 Vali Loss: 0.0693131 Test Loss: 0.0809331\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0545038\n",
      "\tspeed: 0.0566s/iter; left time: 961.7671s\n",
      "\titers: 200, epoch: 24 | loss: 0.0525213\n",
      "\tspeed: 0.0287s/iter; left time: 484.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0549631 Vali Loss: 0.0693683 Test Loss: 0.0808207\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0531886\n",
      "\tspeed: 0.0581s/iter; left time: 974.3355s\n",
      "\titers: 200, epoch: 25 | loss: 0.0607770\n",
      "\tspeed: 0.0270s/iter; left time: 450.1486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0548838 Vali Loss: 0.0693077 Test Loss: 0.0809227\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0545997\n",
      "\tspeed: 0.0576s/iter; left time: 953.2549s\n",
      "\titers: 200, epoch: 26 | loss: 0.0549107\n",
      "\tspeed: 0.0294s/iter; left time: 483.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 222 | Train Loss: 0.0547993 Vali Loss: 0.0692610 Test Loss: 0.0812203\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0559376\n",
      "\tspeed: 0.0530s/iter; left time: 865.3901s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532648\n",
      "\tspeed: 0.0288s/iter; left time: 467.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0547550 Vali Loss: 0.0691140 Test Loss: 0.0808653\n",
      "Validation loss decreased (0.069148 --> 0.069114).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0582528\n",
      "\tspeed: 0.0569s/iter; left time: 915.8264s\n",
      "\titers: 200, epoch: 28 | loss: 0.0525920\n",
      "\tspeed: 0.0273s/iter; left time: 436.6005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0546527 Vali Loss: 0.0690959 Test Loss: 0.0806358\n",
      "Validation loss decreased (0.069114 --> 0.069096).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0547554\n",
      "\tspeed: 0.0570s/iter; left time: 905.6622s\n",
      "\titers: 200, epoch: 29 | loss: 0.0558492\n",
      "\tspeed: 0.0281s/iter; left time: 444.1322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0545580 Vali Loss: 0.0692201 Test Loss: 0.0810624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0513949\n",
      "\tspeed: 0.0554s/iter; left time: 867.4813s\n",
      "\titers: 200, epoch: 30 | loss: 0.0538825\n",
      "\tspeed: 0.0268s/iter; left time: 417.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0545313 Vali Loss: 0.0691521 Test Loss: 0.0810161\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517632\n",
      "\tspeed: 0.0559s/iter; left time: 862.8661s\n",
      "\titers: 200, epoch: 31 | loss: 0.0539208\n",
      "\tspeed: 0.0308s/iter; left time: 472.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 222 | Train Loss: 0.0545053 Vali Loss: 0.0692572 Test Loss: 0.0809226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0550982\n",
      "\tspeed: 0.0542s/iter; left time: 824.9185s\n",
      "\titers: 200, epoch: 32 | loss: 0.0533233\n",
      "\tspeed: 0.0273s/iter; left time: 412.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0544201 Vali Loss: 0.0691529 Test Loss: 0.0810605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533810\n",
      "\tspeed: 0.0567s/iter; left time: 850.9174s\n",
      "\titers: 200, epoch: 33 | loss: 0.0557891\n",
      "\tspeed: 0.0270s/iter; left time: 402.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0543391 Vali Loss: 0.0690889 Test Loss: 0.0809323\n",
      "Validation loss decreased (0.069096 --> 0.069089).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0543540\n",
      "\tspeed: 0.0533s/iter; left time: 787.3487s\n",
      "\titers: 200, epoch: 34 | loss: 0.0501789\n",
      "\tspeed: 0.0319s/iter; left time: 467.4994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 222 | Train Loss: 0.0543403 Vali Loss: 0.0692075 Test Loss: 0.0809898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572097\n",
      "\tspeed: 0.0542s/iter; left time: 789.1576s\n",
      "\titers: 200, epoch: 35 | loss: 0.0554948\n",
      "\tspeed: 0.0274s/iter; left time: 396.0129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0543257 Vali Loss: 0.0691925 Test Loss: 0.0809306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0536229\n",
      "\tspeed: 0.0581s/iter; left time: 832.6273s\n",
      "\titers: 200, epoch: 36 | loss: 0.0524175\n",
      "\tspeed: 0.0276s/iter; left time: 392.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0542763 Vali Loss: 0.0691631 Test Loss: 0.0809931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568595\n",
      "\tspeed: 0.0557s/iter; left time: 786.2092s\n",
      "\titers: 200, epoch: 37 | loss: 0.0558364\n",
      "\tspeed: 0.0270s/iter; left time: 378.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0542079 Vali Loss: 0.0692795 Test Loss: 0.0810558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0523561\n",
      "\tspeed: 0.0560s/iter; left time: 777.7551s\n",
      "\titers: 200, epoch: 38 | loss: 0.0541448\n",
      "\tspeed: 0.0290s/iter; left time: 400.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0541932 Vali Loss: 0.0691731 Test Loss: 0.0809929\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0515040\n",
      "\tspeed: 0.0532s/iter; left time: 727.3661s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538739\n",
      "\tspeed: 0.0318s/iter; left time: 430.8552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 222 | Train Loss: 0.0542231 Vali Loss: 0.0692040 Test Loss: 0.0808713\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0547240\n",
      "\tspeed: 0.0587s/iter; left time: 789.4755s\n",
      "\titers: 200, epoch: 40 | loss: 0.0544746\n",
      "\tspeed: 0.0281s/iter; left time: 374.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0541712 Vali Loss: 0.0691869 Test Loss: 0.0810898\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535738\n",
      "\tspeed: 0.0576s/iter; left time: 762.1386s\n",
      "\titers: 200, epoch: 41 | loss: 0.0521586\n",
      "\tspeed: 0.0274s/iter; left time: 359.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0541541 Vali Loss: 0.0692053 Test Loss: 0.0810138\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0560169\n",
      "\tspeed: 0.0569s/iter; left time: 739.6913s\n",
      "\titers: 200, epoch: 42 | loss: 0.0550496\n",
      "\tspeed: 0.0286s/iter; left time: 368.3939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0541010 Vali Loss: 0.0692285 Test Loss: 0.0811099\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0485699\n",
      "\tspeed: 0.0567s/iter; left time: 724.9226s\n",
      "\titers: 200, epoch: 43 | loss: 0.0563646\n",
      "\tspeed: 0.0295s/iter; left time: 374.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0541447 Vali Loss: 0.0692108 Test Loss: 0.0810611\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019895073026418686, rmse:0.14104989171028137, mae:0.08093231916427612, rse:0.54561847448349\n",
      "Intermediate time for FR and pred_len 96: 00h:09m:44.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0938556\n",
      "\tspeed: 0.0537s/iter; left time: 1187.7679s\n",
      "\titers: 200, epoch: 1 | loss: 0.0854498\n",
      "\tspeed: 0.0275s/iter; left time: 605.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0996454 Vali Loss: 0.0909195 Test Loss: 0.0982277\n",
      "Validation loss decreased (inf --> 0.090919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0675109\n",
      "\tspeed: 0.0616s/iter; left time: 1348.6246s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670425\n",
      "\tspeed: 0.0271s/iter; left time: 591.2223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0727755 Vali Loss: 0.0776914 Test Loss: 0.0867592\n",
      "Validation loss decreased (0.090919 --> 0.077691).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0661314\n",
      "\tspeed: 0.0576s/iter; left time: 1247.1888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0677241\n",
      "\tspeed: 0.0282s/iter; left time: 608.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0669249 Vali Loss: 0.0761548 Test Loss: 0.0854462\n",
      "Validation loss decreased (0.077691 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0679322\n",
      "\tspeed: 0.0568s/iter; left time: 1217.4635s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632045\n",
      "\tspeed: 0.0299s/iter; left time: 637.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0654356 Vali Loss: 0.0749669 Test Loss: 0.0855714\n",
      "Validation loss decreased (0.076155 --> 0.074967).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612492\n",
      "\tspeed: 0.0552s/iter; left time: 1171.6811s\n",
      "\titers: 200, epoch: 5 | loss: 0.0665668\n",
      "\tspeed: 0.0289s/iter; left time: 609.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 222 | Train Loss: 0.0643432 Vali Loss: 0.0746899 Test Loss: 0.0860002\n",
      "Validation loss decreased (0.074967 --> 0.074690).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619588\n",
      "\tspeed: 0.0563s/iter; left time: 1181.4707s\n",
      "\titers: 200, epoch: 6 | loss: 0.0662285\n",
      "\tspeed: 0.0271s/iter; left time: 566.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0634915 Vali Loss: 0.0741637 Test Loss: 0.0862336\n",
      "Validation loss decreased (0.074690 --> 0.074164).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630885\n",
      "\tspeed: 0.0599s/iter; left time: 1244.1855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0668416\n",
      "\tspeed: 0.0271s/iter; left time: 560.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0628616 Vali Loss: 0.0739373 Test Loss: 0.0866496\n",
      "Validation loss decreased (0.074164 --> 0.073937).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0633949\n",
      "\tspeed: 0.0595s/iter; left time: 1222.1403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0597458\n",
      "\tspeed: 0.0301s/iter; left time: 615.7145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 222 | Train Loss: 0.0622367 Vali Loss: 0.0738674 Test Loss: 0.0874078\n",
      "Validation loss decreased (0.073937 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600061\n",
      "\tspeed: 0.0550s/iter; left time: 1118.5541s\n",
      "\titers: 200, epoch: 9 | loss: 0.0622538\n",
      "\tspeed: 0.0301s/iter; left time: 608.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0617032 Vali Loss: 0.0734540 Test Loss: 0.0876739\n",
      "Validation loss decreased (0.073867 --> 0.073454).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0591503\n",
      "\tspeed: 0.0574s/iter; left time: 1153.2995s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608495\n",
      "\tspeed: 0.0293s/iter; left time: 585.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0612152 Vali Loss: 0.0735651 Test Loss: 0.0878582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628291\n",
      "\tspeed: 0.0580s/iter; left time: 1152.1630s\n",
      "\titers: 200, epoch: 11 | loss: 0.0591405\n",
      "\tspeed: 0.0276s/iter; left time: 546.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0608145 Vali Loss: 0.0734721 Test Loss: 0.0884252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0628089\n",
      "\tspeed: 0.0565s/iter; left time: 1110.0706s\n",
      "\titers: 200, epoch: 12 | loss: 0.0601851\n",
      "\tspeed: 0.0275s/iter; left time: 537.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0604573 Vali Loss: 0.0732824 Test Loss: 0.0882674\n",
      "Validation loss decreased (0.073454 --> 0.073282).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586489\n",
      "\tspeed: 0.0549s/iter; left time: 1067.0806s\n",
      "\titers: 200, epoch: 13 | loss: 0.0620482\n",
      "\tspeed: 0.0302s/iter; left time: 583.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 222 | Train Loss: 0.0600379 Vali Loss: 0.0735289 Test Loss: 0.0874406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0555771\n",
      "\tspeed: 0.0543s/iter; left time: 1044.1961s\n",
      "\titers: 200, epoch: 14 | loss: 0.0605145\n",
      "\tspeed: 0.0276s/iter; left time: 527.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 222 | Train Loss: 0.0596907 Vali Loss: 0.0732599 Test Loss: 0.0885390\n",
      "Validation loss decreased (0.073282 --> 0.073260).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584461\n",
      "\tspeed: 0.0618s/iter; left time: 1173.1642s\n",
      "\titers: 200, epoch: 15 | loss: 0.0568878\n",
      "\tspeed: 0.0271s/iter; left time: 511.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 222 | Train Loss: 0.0593595 Vali Loss: 0.0733622 Test Loss: 0.0882639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593707\n",
      "\tspeed: 0.0574s/iter; left time: 1076.9710s\n",
      "\titers: 200, epoch: 16 | loss: 0.0584661\n",
      "\tspeed: 0.0274s/iter; left time: 512.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0590356 Vali Loss: 0.0734783 Test Loss: 0.0876160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0588905\n",
      "\tspeed: 0.0564s/iter; left time: 1045.8583s\n",
      "\titers: 200, epoch: 17 | loss: 0.0621994\n",
      "\tspeed: 0.0304s/iter; left time: 560.8945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0587787 Vali Loss: 0.0732299 Test Loss: 0.0877349\n",
      "Validation loss decreased (0.073260 --> 0.073230).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0621530\n",
      "\tspeed: 0.0544s/iter; left time: 996.3035s\n",
      "\titers: 200, epoch: 18 | loss: 0.0605658\n",
      "\tspeed: 0.0306s/iter; left time: 556.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0585481 Vali Loss: 0.0734606 Test Loss: 0.0877434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0583042\n",
      "\tspeed: 0.0553s/iter; left time: 1000.5556s\n",
      "\titers: 200, epoch: 19 | loss: 0.0605425\n",
      "\tspeed: 0.0278s/iter; left time: 500.8201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0582981 Vali Loss: 0.0732683 Test Loss: 0.0879471\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0579087\n",
      "\tspeed: 0.0598s/iter; left time: 1069.7862s\n",
      "\titers: 200, epoch: 20 | loss: 0.0559152\n",
      "\tspeed: 0.0272s/iter; left time: 484.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0581190 Vali Loss: 0.0734302 Test Loss: 0.0868313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0566728\n",
      "\tspeed: 0.0571s/iter; left time: 1009.1655s\n",
      "\titers: 200, epoch: 21 | loss: 0.0573363\n",
      "\tspeed: 0.0278s/iter; left time: 488.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 222 | Train Loss: 0.0579168 Vali Loss: 0.0733025 Test Loss: 0.0868867\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0599002\n",
      "\tspeed: 0.0547s/iter; left time: 953.8582s\n",
      "\titers: 200, epoch: 22 | loss: 0.0579244\n",
      "\tspeed: 0.0308s/iter; left time: 534.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0577381 Vali Loss: 0.0734787 Test Loss: 0.0877282\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0576215\n",
      "\tspeed: 0.0563s/iter; left time: 968.5148s\n",
      "\titers: 200, epoch: 23 | loss: 0.0555970\n",
      "\tspeed: 0.0275s/iter; left time: 471.0447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0576474 Vali Loss: 0.0734664 Test Loss: 0.0873497\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0549140\n",
      "\tspeed: 0.0574s/iter; left time: 976.1575s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565494\n",
      "\tspeed: 0.0277s/iter; left time: 467.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0575239 Vali Loss: 0.0731563 Test Loss: 0.0869676\n",
      "Validation loss decreased (0.073230 --> 0.073156).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0596233\n",
      "\tspeed: 0.0578s/iter; left time: 968.7979s\n",
      "\titers: 200, epoch: 25 | loss: 0.0541902\n",
      "\tspeed: 0.0281s/iter; left time: 468.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.0573391 Vali Loss: 0.0734023 Test Loss: 0.0868268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0555391\n",
      "\tspeed: 0.0544s/iter; left time: 900.2221s\n",
      "\titers: 200, epoch: 26 | loss: 0.0553594\n",
      "\tspeed: 0.0313s/iter; left time: 514.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0572754 Vali Loss: 0.0733688 Test Loss: 0.0870272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0564770\n",
      "\tspeed: 0.0558s/iter; left time: 910.6911s\n",
      "\titers: 200, epoch: 27 | loss: 0.0569422\n",
      "\tspeed: 0.0281s/iter; left time: 455.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0571740 Vali Loss: 0.0734585 Test Loss: 0.0868808\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0568383\n",
      "\tspeed: 0.0574s/iter; left time: 923.9326s\n",
      "\titers: 200, epoch: 28 | loss: 0.0575890\n",
      "\tspeed: 0.0276s/iter; left time: 442.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0571011 Vali Loss: 0.0735396 Test Loss: 0.0867445\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0602893\n",
      "\tspeed: 0.0554s/iter; left time: 879.4234s\n",
      "\titers: 200, epoch: 29 | loss: 0.0582584\n",
      "\tspeed: 0.0274s/iter; left time: 432.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0570145 Vali Loss: 0.0735997 Test Loss: 0.0871782\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0537078\n",
      "\tspeed: 0.0572s/iter; left time: 896.0460s\n",
      "\titers: 200, epoch: 30 | loss: 0.0555406\n",
      "\tspeed: 0.0280s/iter; left time: 436.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 222 | Train Loss: 0.0569776 Vali Loss: 0.0735232 Test Loss: 0.0871077\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0557368\n",
      "\tspeed: 0.0533s/iter; left time: 822.2656s\n",
      "\titers: 200, epoch: 31 | loss: 0.0554728\n",
      "\tspeed: 0.0318s/iter; left time: 488.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 222 | Train Loss: 0.0569504 Vali Loss: 0.0735121 Test Loss: 0.0870237\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584505\n",
      "\tspeed: 0.0546s/iter; left time: 831.0824s\n",
      "\titers: 200, epoch: 32 | loss: 0.0585560\n",
      "\tspeed: 0.0277s/iter; left time: 419.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0568485 Vali Loss: 0.0734587 Test Loss: 0.0867984\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0601608\n",
      "\tspeed: 0.0571s/iter; left time: 855.6341s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542788\n",
      "\tspeed: 0.0279s/iter; left time: 416.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0568110 Vali Loss: 0.0735852 Test Loss: 0.0870490\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0593282\n",
      "\tspeed: 0.0565s/iter; left time: 834.2108s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566462\n",
      "\tspeed: 0.0280s/iter; left time: 410.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0568219 Vali Loss: 0.0735635 Test Loss: 0.0869921\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02209530398249626, rmse:0.14864489436149597, mae:0.0869675725698471, rse:0.5757157206535339\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0926753\n",
      "\tspeed: 0.0322s/iter; left time: 711.0785s\n",
      "\titers: 200, epoch: 1 | loss: 0.0864850\n",
      "\tspeed: 0.0273s/iter; left time: 601.1498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0998092 Vali Loss: 0.0912169 Test Loss: 0.0984884\n",
      "Validation loss decreased (inf --> 0.091217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0706366\n",
      "\tspeed: 0.0576s/iter; left time: 1260.3439s\n",
      "\titers: 200, epoch: 2 | loss: 0.0685956\n",
      "\tspeed: 0.0308s/iter; left time: 670.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 222 | Train Loss: 0.0732876 Vali Loss: 0.0785562 Test Loss: 0.0867374\n",
      "Validation loss decreased (0.091217 --> 0.078556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0673651\n",
      "\tspeed: 0.0541s/iter; left time: 1171.8726s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663863\n",
      "\tspeed: 0.0280s/iter; left time: 604.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0673279 Vali Loss: 0.0765334 Test Loss: 0.0856419\n",
      "Validation loss decreased (0.078556 --> 0.076533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0669243\n",
      "\tspeed: 0.0600s/iter; left time: 1286.9608s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647952\n",
      "\tspeed: 0.0271s/iter; left time: 578.9654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0655516 Vali Loss: 0.0755698 Test Loss: 0.0860987\n",
      "Validation loss decreased (0.076533 --> 0.075570).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0669611\n",
      "\tspeed: 0.0548s/iter; left time: 1161.8915s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653353\n",
      "\tspeed: 0.0279s/iter; left time: 588.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0644662 Vali Loss: 0.0751957 Test Loss: 0.0860627\n",
      "Validation loss decreased (0.075570 --> 0.075196).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0651973\n",
      "\tspeed: 0.0596s/iter; left time: 1250.0752s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602959\n",
      "\tspeed: 0.0282s/iter; left time: 589.1540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0636211 Vali Loss: 0.0742472 Test Loss: 0.0868280\n",
      "Validation loss decreased (0.075196 --> 0.074247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0617981\n",
      "\tspeed: 0.0553s/iter; left time: 1148.7227s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661122\n",
      "\tspeed: 0.0295s/iter; left time: 609.3023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0629225 Vali Loss: 0.0737034 Test Loss: 0.0874572\n",
      "Validation loss decreased (0.074247 --> 0.073703).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0658991\n",
      "\tspeed: 0.0551s/iter; left time: 1132.5147s\n",
      "\titers: 200, epoch: 8 | loss: 0.0613267\n",
      "\tspeed: 0.0280s/iter; left time: 571.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0623983 Vali Loss: 0.0734330 Test Loss: 0.0871008\n",
      "Validation loss decreased (0.073703 --> 0.073433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0611679\n",
      "\tspeed: 0.0582s/iter; left time: 1182.8415s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620157\n",
      "\tspeed: 0.0271s/iter; left time: 547.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0617476 Vali Loss: 0.0734691 Test Loss: 0.0874490\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0648440\n",
      "\tspeed: 0.0565s/iter; left time: 1135.3078s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623541\n",
      "\tspeed: 0.0273s/iter; left time: 546.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0612791 Vali Loss: 0.0735913 Test Loss: 0.0876361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0566490\n",
      "\tspeed: 0.0557s/iter; left time: 1106.8575s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592110\n",
      "\tspeed: 0.0281s/iter; left time: 555.7768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0607181 Vali Loss: 0.0732275 Test Loss: 0.0882248\n",
      "Validation loss decreased (0.073433 --> 0.073228).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0632455\n",
      "\tspeed: 0.0554s/iter; left time: 1089.5562s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584063\n",
      "\tspeed: 0.0298s/iter; left time: 582.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 222 | Train Loss: 0.0603093 Vali Loss: 0.0735247 Test Loss: 0.0875141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0591289\n",
      "\tspeed: 0.0542s/iter; left time: 1053.2718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0583428\n",
      "\tspeed: 0.0280s/iter; left time: 540.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0599433 Vali Loss: 0.0735825 Test Loss: 0.0874094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605066\n",
      "\tspeed: 0.0570s/iter; left time: 1095.4285s\n",
      "\titers: 200, epoch: 14 | loss: 0.0622422\n",
      "\tspeed: 0.0276s/iter; left time: 526.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0595383 Vali Loss: 0.0733542 Test Loss: 0.0877012\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0608642\n",
      "\tspeed: 0.0570s/iter; left time: 1083.1895s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595879\n",
      "\tspeed: 0.0279s/iter; left time: 526.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0591768 Vali Loss: 0.0733836 Test Loss: 0.0872333\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0593759\n",
      "\tspeed: 0.0561s/iter; left time: 1053.7193s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591774\n",
      "\tspeed: 0.0282s/iter; left time: 527.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 222 | Train Loss: 0.0589033 Vali Loss: 0.0735029 Test Loss: 0.0868597\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616219\n",
      "\tspeed: 0.0540s/iter; left time: 1001.4667s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582787\n",
      "\tspeed: 0.0291s/iter; left time: 536.0442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0586167 Vali Loss: 0.0735510 Test Loss: 0.0873291\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0608582\n",
      "\tspeed: 0.0538s/iter; left time: 986.6374s\n",
      "\titers: 200, epoch: 18 | loss: 0.0558169\n",
      "\tspeed: 0.0274s/iter; left time: 499.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0583472 Vali Loss: 0.0736005 Test Loss: 0.0866306\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0579800\n",
      "\tspeed: 0.0574s/iter; left time: 1039.8457s\n",
      "\titers: 200, epoch: 19 | loss: 0.0586734\n",
      "\tspeed: 0.0274s/iter; left time: 492.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 222 | Train Loss: 0.0581088 Vali Loss: 0.0736148 Test Loss: 0.0869817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0582891\n",
      "\tspeed: 0.0546s/iter; left time: 976.7968s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546571\n",
      "\tspeed: 0.0274s/iter; left time: 487.8506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0578948 Vali Loss: 0.0738315 Test Loss: 0.0869170\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0569176\n",
      "\tspeed: 0.0556s/iter; left time: 982.4490s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584212\n",
      "\tspeed: 0.0285s/iter; left time: 499.6546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0577929 Vali Loss: 0.0737043 Test Loss: 0.0868128\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02231057547032833, rmse:0.14936724305152893, mae:0.08822478353977203, rse:0.578513503074646\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:00.54s\n",
      "Intermediate time for FR: 00h:33m:33.22s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1220752\n",
      "\tspeed: 0.0509s/iter; left time: 1130.2764s\n",
      "\titers: 200, epoch: 1 | loss: 0.1124015\n",
      "\tspeed: 0.0281s/iter; left time: 622.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 223 | Train Loss: 0.1325993 Vali Loss: 0.0942944 Test Loss: 0.0955565\n",
      "Validation loss decreased (inf --> 0.094294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0693890\n",
      "\tspeed: 0.0528s/iter; left time: 1159.9153s\n",
      "\titers: 200, epoch: 2 | loss: 0.0668445\n",
      "\tspeed: 0.0266s/iter; left time: 582.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0759136 Vali Loss: 0.0627112 Test Loss: 0.0656406\n",
      "Validation loss decreased (0.094294 --> 0.062711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662491\n",
      "\tspeed: 0.0544s/iter; left time: 1183.8244s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660577\n",
      "\tspeed: 0.0273s/iter; left time: 591.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0650764 Vali Loss: 0.0596654 Test Loss: 0.0621885\n",
      "Validation loss decreased (0.062711 --> 0.059665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611442\n",
      "\tspeed: 0.0533s/iter; left time: 1147.3704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643807\n",
      "\tspeed: 0.0267s/iter; left time: 571.7833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0621614 Vali Loss: 0.0590315 Test Loss: 0.0613040\n",
      "Validation loss decreased (0.059665 --> 0.059032).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575514\n",
      "\tspeed: 0.0530s/iter; left time: 1129.6298s\n",
      "\titers: 200, epoch: 5 | loss: 0.0622045\n",
      "\tspeed: 0.0281s/iter; left time: 596.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0607118 Vali Loss: 0.0582237 Test Loss: 0.0606797\n",
      "Validation loss decreased (0.059032 --> 0.058224).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0604667\n",
      "\tspeed: 0.0516s/iter; left time: 1088.1781s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586946\n",
      "\tspeed: 0.0273s/iter; left time: 572.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0596630 Vali Loss: 0.0575096 Test Loss: 0.0601424\n",
      "Validation loss decreased (0.058224 --> 0.057510).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0605737\n",
      "\tspeed: 0.0555s/iter; left time: 1157.0877s\n",
      "\titers: 200, epoch: 7 | loss: 0.0577191\n",
      "\tspeed: 0.0267s/iter; left time: 553.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0587539 Vali Loss: 0.0573150 Test Loss: 0.0599158\n",
      "Validation loss decreased (0.057510 --> 0.057315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569133\n",
      "\tspeed: 0.0554s/iter; left time: 1144.2128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609494\n",
      "\tspeed: 0.0269s/iter; left time: 552.8415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0581800 Vali Loss: 0.0571470 Test Loss: 0.0595391\n",
      "Validation loss decreased (0.057315 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0543008\n",
      "\tspeed: 0.0537s/iter; left time: 1096.9061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0545223\n",
      "\tspeed: 0.0267s/iter; left time: 542.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0575996 Vali Loss: 0.0566902 Test Loss: 0.0590270\n",
      "Validation loss decreased (0.057147 --> 0.056690).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564065\n",
      "\tspeed: 0.0527s/iter; left time: 1064.7117s\n",
      "\titers: 200, epoch: 10 | loss: 0.0549191\n",
      "\tspeed: 0.0283s/iter; left time: 569.3037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0571505 Vali Loss: 0.0567421 Test Loss: 0.0591187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0562808\n",
      "\tspeed: 0.0510s/iter; left time: 1019.5154s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546165\n",
      "\tspeed: 0.0269s/iter; left time: 533.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0566563 Vali Loss: 0.0563506 Test Loss: 0.0590622\n",
      "Validation loss decreased (0.056690 --> 0.056351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594916\n",
      "\tspeed: 0.0541s/iter; left time: 1068.2255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0550755\n",
      "\tspeed: 0.0265s/iter; left time: 520.1228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0563721 Vali Loss: 0.0559727 Test Loss: 0.0584474\n",
      "Validation loss decreased (0.056351 --> 0.055973).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533181\n",
      "\tspeed: 0.0545s/iter; left time: 1064.3111s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591052\n",
      "\tspeed: 0.0266s/iter; left time: 516.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0560483 Vali Loss: 0.0560773 Test Loss: 0.0585655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0576542\n",
      "\tspeed: 0.0512s/iter; left time: 988.1637s\n",
      "\titers: 200, epoch: 14 | loss: 0.0536710\n",
      "\tspeed: 0.0273s/iter; left time: 524.5586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0557588 Vali Loss: 0.0557475 Test Loss: 0.0584036\n",
      "Validation loss decreased (0.055973 --> 0.055747).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0577584\n",
      "\tspeed: 0.0550s/iter; left time: 1048.6455s\n",
      "\titers: 200, epoch: 15 | loss: 0.0573185\n",
      "\tspeed: 0.0283s/iter; left time: 536.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 223 | Train Loss: 0.0554317 Vali Loss: 0.0554833 Test Loss: 0.0582388\n",
      "Validation loss decreased (0.055747 --> 0.055483).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574488\n",
      "\tspeed: 0.0530s/iter; left time: 998.9107s\n",
      "\titers: 200, epoch: 16 | loss: 0.0597576\n",
      "\tspeed: 0.0268s/iter; left time: 502.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0553067 Vali Loss: 0.0555447 Test Loss: 0.0582300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0528388\n",
      "\tspeed: 0.0548s/iter; left time: 1020.4668s\n",
      "\titers: 200, epoch: 17 | loss: 0.0528586\n",
      "\tspeed: 0.0266s/iter; left time: 492.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0550844 Vali Loss: 0.0555010 Test Loss: 0.0580867\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0575727\n",
      "\tspeed: 0.0531s/iter; left time: 978.1223s\n",
      "\titers: 200, epoch: 18 | loss: 0.0554257\n",
      "\tspeed: 0.0283s/iter; left time: 518.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0548954 Vali Loss: 0.0554527 Test Loss: 0.0580303\n",
      "Validation loss decreased (0.055483 --> 0.055453).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0514130\n",
      "\tspeed: 0.0530s/iter; left time: 964.1856s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547660\n",
      "\tspeed: 0.0275s/iter; left time: 496.5606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0548206 Vali Loss: 0.0552508 Test Loss: 0.0577160\n",
      "Validation loss decreased (0.055453 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0535157\n",
      "\tspeed: 0.0514s/iter; left time: 923.5797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577883\n",
      "\tspeed: 0.0279s/iter; left time: 498.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0545696 Vali Loss: 0.0552697 Test Loss: 0.0577830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555147\n",
      "\tspeed: 0.0520s/iter; left time: 923.1396s\n",
      "\titers: 200, epoch: 21 | loss: 0.0544950\n",
      "\tspeed: 0.0266s/iter; left time: 469.6798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0544441 Vali Loss: 0.0549807 Test Loss: 0.0576976\n",
      "Validation loss decreased (0.055251 --> 0.054981).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0534422\n",
      "\tspeed: 0.0547s/iter; left time: 957.8440s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564228\n",
      "\tspeed: 0.0264s/iter; left time: 459.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0543254 Vali Loss: 0.0550190 Test Loss: 0.0575762\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0517031\n",
      "\tspeed: 0.0519s/iter; left time: 897.4414s\n",
      "\titers: 200, epoch: 23 | loss: 0.0587856\n",
      "\tspeed: 0.0267s/iter; left time: 458.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0543248 Vali Loss: 0.0550559 Test Loss: 0.0577396\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0560705\n",
      "\tspeed: 0.0509s/iter; left time: 869.2080s\n",
      "\titers: 200, epoch: 24 | loss: 0.0528798\n",
      "\tspeed: 0.0286s/iter; left time: 486.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0541613 Vali Loss: 0.0549477 Test Loss: 0.0576477\n",
      "Validation loss decreased (0.054981 --> 0.054948).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0560655\n",
      "\tspeed: 0.0556s/iter; left time: 937.5092s\n",
      "\titers: 200, epoch: 25 | loss: 0.0542304\n",
      "\tspeed: 0.0268s/iter; left time: 448.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0541076 Vali Loss: 0.0548136 Test Loss: 0.0576309\n",
      "Validation loss decreased (0.054948 --> 0.054814).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0548747\n",
      "\tspeed: 0.0533s/iter; left time: 885.5314s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538855\n",
      "\tspeed: 0.0266s/iter; left time: 439.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0540087 Vali Loss: 0.0549526 Test Loss: 0.0575554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0517120\n",
      "\tspeed: 0.0527s/iter; left time: 864.8934s\n",
      "\titers: 200, epoch: 27 | loss: 0.0527826\n",
      "\tspeed: 0.0266s/iter; left time: 434.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0539188 Vali Loss: 0.0549253 Test Loss: 0.0575773\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0549809\n",
      "\tspeed: 0.0516s/iter; left time: 835.4098s\n",
      "\titers: 200, epoch: 28 | loss: 0.0554980\n",
      "\tspeed: 0.0271s/iter; left time: 435.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538956 Vali Loss: 0.0548986 Test Loss: 0.0574903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0527975\n",
      "\tspeed: 0.0508s/iter; left time: 809.8721s\n",
      "\titers: 200, epoch: 29 | loss: 0.0547849\n",
      "\tspeed: 0.0276s/iter; left time: 437.1923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0538247 Vali Loss: 0.0547120 Test Loss: 0.0574399\n",
      "Validation loss decreased (0.054814 --> 0.054712).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0507995\n",
      "\tspeed: 0.0515s/iter; left time: 809.8363s\n",
      "\titers: 200, epoch: 30 | loss: 0.0500010\n",
      "\tspeed: 0.0266s/iter; left time: 415.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0537853 Vali Loss: 0.0547885 Test Loss: 0.0574554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550639\n",
      "\tspeed: 0.0535s/iter; left time: 829.3732s\n",
      "\titers: 200, epoch: 31 | loss: 0.0518903\n",
      "\tspeed: 0.0264s/iter; left time: 407.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0537086 Vali Loss: 0.0547136 Test Loss: 0.0574395\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0559142\n",
      "\tspeed: 0.0537s/iter; left time: 820.9508s\n",
      "\titers: 200, epoch: 32 | loss: 0.0563869\n",
      "\tspeed: 0.0273s/iter; left time: 415.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0537152 Vali Loss: 0.0546903 Test Loss: 0.0574024\n",
      "Validation loss decreased (0.054712 --> 0.054690).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0501247\n",
      "\tspeed: 0.0517s/iter; left time: 779.3576s\n",
      "\titers: 200, epoch: 33 | loss: 0.0544526\n",
      "\tspeed: 0.0277s/iter; left time: 413.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0536137 Vali Loss: 0.0547255 Test Loss: 0.0573914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0529143\n",
      "\tspeed: 0.0514s/iter; left time: 762.4844s\n",
      "\titers: 200, epoch: 34 | loss: 0.0530024\n",
      "\tspeed: 0.0265s/iter; left time: 389.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0535995 Vali Loss: 0.0547244 Test Loss: 0.0574674\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0510959\n",
      "\tspeed: 0.0529s/iter; left time: 773.3129s\n",
      "\titers: 200, epoch: 35 | loss: 0.0544512\n",
      "\tspeed: 0.0266s/iter; left time: 385.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0535950 Vali Loss: 0.0546488 Test Loss: 0.0574228\n",
      "Validation loss decreased (0.054690 --> 0.054649).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0535187\n",
      "\tspeed: 0.0517s/iter; left time: 743.7813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0523912\n",
      "\tspeed: 0.0271s/iter; left time: 386.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0535439 Vali Loss: 0.0546921 Test Loss: 0.0573547\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519122\n",
      "\tspeed: 0.0512s/iter; left time: 726.0438s\n",
      "\titers: 200, epoch: 37 | loss: 0.0526450\n",
      "\tspeed: 0.0276s/iter; left time: 388.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535251 Vali Loss: 0.0546742 Test Loss: 0.0573575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0550824\n",
      "\tspeed: 0.0506s/iter; left time: 705.9884s\n",
      "\titers: 200, epoch: 38 | loss: 0.0517140\n",
      "\tspeed: 0.0267s/iter; left time: 370.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0535045 Vali Loss: 0.0546824 Test Loss: 0.0573583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0504631\n",
      "\tspeed: 0.0538s/iter; left time: 737.9139s\n",
      "\titers: 200, epoch: 39 | loss: 0.0540452\n",
      "\tspeed: 0.0267s/iter; left time: 364.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0535086 Vali Loss: 0.0546178 Test Loss: 0.0573389\n",
      "Validation loss decreased (0.054649 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0553547\n",
      "\tspeed: 0.0533s/iter; left time: 719.5076s\n",
      "\titers: 200, epoch: 40 | loss: 0.0607494\n",
      "\tspeed: 0.0266s/iter; left time: 355.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0534950 Vali Loss: 0.0546346 Test Loss: 0.0573255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0535479\n",
      "\tspeed: 0.0517s/iter; left time: 686.2660s\n",
      "\titers: 200, epoch: 41 | loss: 0.0538877\n",
      "\tspeed: 0.0283s/iter; left time: 373.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 223 | Train Loss: 0.0534341 Vali Loss: 0.0546129 Test Loss: 0.0573383\n",
      "Validation loss decreased (0.054618 --> 0.054613).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0530539\n",
      "\tspeed: 0.0519s/iter; left time: 677.9868s\n",
      "\titers: 200, epoch: 42 | loss: 0.0503627\n",
      "\tspeed: 0.0266s/iter; left time: 344.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534945 Vali Loss: 0.0546511 Test Loss: 0.0573564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522355\n",
      "\tspeed: 0.0524s/iter; left time: 672.6512s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554015\n",
      "\tspeed: 0.0266s/iter; left time: 338.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0534944 Vali Loss: 0.0545573 Test Loss: 0.0572970\n",
      "Validation loss decreased (0.054613 --> 0.054557).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0508118\n",
      "\tspeed: 0.0527s/iter; left time: 664.7909s\n",
      "\titers: 200, epoch: 44 | loss: 0.0487365\n",
      "\tspeed: 0.0265s/iter; left time: 331.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0534317 Vali Loss: 0.0546139 Test Loss: 0.0573201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0559016\n",
      "\tspeed: 0.0525s/iter; left time: 650.4442s\n",
      "\titers: 200, epoch: 45 | loss: 0.0545299\n",
      "\tspeed: 0.0274s/iter; left time: 336.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533953 Vali Loss: 0.0546057 Test Loss: 0.0572799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0540960\n",
      "\tspeed: 0.0502s/iter; left time: 611.0743s\n",
      "\titers: 200, epoch: 46 | loss: 0.0512552\n",
      "\tspeed: 0.0266s/iter; left time: 321.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533736 Vali Loss: 0.0546207 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0561732\n",
      "\tspeed: 0.0534s/iter; left time: 637.7349s\n",
      "\titers: 200, epoch: 47 | loss: 0.0581061\n",
      "\tspeed: 0.0267s/iter; left time: 316.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0533965 Vali Loss: 0.0546026 Test Loss: 0.0573136\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520449\n",
      "\tspeed: 0.0535s/iter; left time: 627.0966s\n",
      "\titers: 200, epoch: 48 | loss: 0.0524969\n",
      "\tspeed: 0.0268s/iter; left time: 311.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0534021 Vali Loss: 0.0545990 Test Loss: 0.0572868\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0543634\n",
      "\tspeed: 0.0521s/iter; left time: 599.3406s\n",
      "\titers: 200, epoch: 49 | loss: 0.0546120\n",
      "\tspeed: 0.0273s/iter; left time: 311.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0533844 Vali Loss: 0.0545882 Test Loss: 0.0572972\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0534620\n",
      "\tspeed: 0.0506s/iter; left time: 570.4850s\n",
      "\titers: 200, epoch: 50 | loss: 0.0547533\n",
      "\tspeed: 0.0275s/iter; left time: 307.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0533451 Vali Loss: 0.0545814 Test Loss: 0.0573124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0546054\n",
      "\tspeed: 0.0523s/iter; left time: 578.0639s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510880\n",
      "\tspeed: 0.0267s/iter; left time: 292.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533503 Vali Loss: 0.0546255 Test Loss: 0.0573027\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0514563\n",
      "\tspeed: 0.0527s/iter; left time: 570.8214s\n",
      "\titers: 200, epoch: 52 | loss: 0.0495366\n",
      "\tspeed: 0.0267s/iter; left time: 286.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0533897 Vali Loss: 0.0545539 Test Loss: 0.0572905\n",
      "Validation loss decreased (0.054557 --> 0.054554).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0526214\n",
      "\tspeed: 0.0521s/iter; left time: 552.3314s\n",
      "\titers: 200, epoch: 53 | loss: 0.0528501\n",
      "\tspeed: 0.0272s/iter; left time: 285.3972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533348 Vali Loss: 0.0545499 Test Loss: 0.0572744\n",
      "Validation loss decreased (0.054554 --> 0.054550).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0534821\n",
      "\tspeed: 0.0511s/iter; left time: 530.3323s\n",
      "\titers: 200, epoch: 54 | loss: 0.0502692\n",
      "\tspeed: 0.0278s/iter; left time: 286.2061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533270 Vali Loss: 0.0546059 Test Loss: 0.0572837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0566965\n",
      "\tspeed: 0.0525s/iter; left time: 533.3248s\n",
      "\titers: 200, epoch: 55 | loss: 0.0537091\n",
      "\tspeed: 0.0265s/iter; left time: 266.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0533742 Vali Loss: 0.0545576 Test Loss: 0.0572765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0570078\n",
      "\tspeed: 0.0548s/iter; left time: 544.3453s\n",
      "\titers: 200, epoch: 56 | loss: 0.0543868\n",
      "\tspeed: 0.0266s/iter; left time: 262.0291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533093 Vali Loss: 0.0545547 Test Loss: 0.0572905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0484664\n",
      "\tspeed: 0.0542s/iter; left time: 526.0091s\n",
      "\titers: 200, epoch: 57 | loss: 0.0509104\n",
      "\tspeed: 0.0266s/iter; left time: 255.6188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0533533 Vali Loss: 0.0545238 Test Loss: 0.0572867\n",
      "Validation loss decreased (0.054550 --> 0.054524).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0565883\n",
      "\tspeed: 0.0532s/iter; left time: 505.2635s\n",
      "\titers: 200, epoch: 58 | loss: 0.0582136\n",
      "\tspeed: 0.0271s/iter; left time: 254.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0533185 Vali Loss: 0.0546001 Test Loss: 0.0572918\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0523805\n",
      "\tspeed: 0.0508s/iter; left time: 470.7098s\n",
      "\titers: 200, epoch: 59 | loss: 0.0535988\n",
      "\tspeed: 0.0265s/iter; left time: 242.7708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0533365 Vali Loss: 0.0545593 Test Loss: 0.0572962\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0546732\n",
      "\tspeed: 0.0535s/iter; left time: 483.9101s\n",
      "\titers: 200, epoch: 60 | loss: 0.0520667\n",
      "\tspeed: 0.0265s/iter; left time: 237.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0533063 Vali Loss: 0.0545351 Test Loss: 0.0572758\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0580502\n",
      "\tspeed: 0.0526s/iter; left time: 464.3747s\n",
      "\titers: 200, epoch: 61 | loss: 0.0520758\n",
      "\tspeed: 0.0265s/iter; left time: 230.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0533507 Vali Loss: 0.0545636 Test Loss: 0.0572944\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0565598\n",
      "\tspeed: 0.0535s/iter; left time: 460.1389s\n",
      "\titers: 200, epoch: 62 | loss: 0.0505943\n",
      "\tspeed: 0.0289s/iter; left time: 245.6082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 223 | Train Loss: 0.0533690 Vali Loss: 0.0546163 Test Loss: 0.0573110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0569731\n",
      "\tspeed: 0.0512s/iter; left time: 428.7700s\n",
      "\titers: 200, epoch: 63 | loss: 0.0532570\n",
      "\tspeed: 0.0279s/iter; left time: 230.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 223 | Train Loss: 0.0533448 Vali Loss: 0.0545721 Test Loss: 0.0572936\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0568857\n",
      "\tspeed: 0.0515s/iter; left time: 419.9548s\n",
      "\titers: 200, epoch: 64 | loss: 0.0522906\n",
      "\tspeed: 0.0266s/iter; left time: 214.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0533268 Vali Loss: 0.0545559 Test Loss: 0.0572829\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0549613\n",
      "\tspeed: 0.0542s/iter; left time: 429.4227s\n",
      "\titers: 200, epoch: 65 | loss: 0.0547876\n",
      "\tspeed: 0.0264s/iter; left time: 206.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0533261 Vali Loss: 0.0546123 Test Loss: 0.0572819\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0571021\n",
      "\tspeed: 0.0533s/iter; left time: 410.3956s\n",
      "\titers: 200, epoch: 66 | loss: 0.0556666\n",
      "\tspeed: 0.0267s/iter; left time: 203.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0533458 Vali Loss: 0.0545249 Test Loss: 0.0572845\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0536378\n",
      "\tspeed: 0.0511s/iter; left time: 382.4235s\n",
      "\titers: 200, epoch: 67 | loss: 0.0556360\n",
      "\tspeed: 0.0278s/iter; left time: 205.4955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0533135 Vali Loss: 0.0545504 Test Loss: 0.0572871\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01012159138917923, rmse:0.10060612112283707, mae:0.057286690920591354, rse:0.3801409900188446\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248728\n",
      "\tspeed: 0.0282s/iter; left time: 626.4181s\n",
      "\titers: 200, epoch: 1 | loss: 0.1110343\n",
      "\tspeed: 0.0278s/iter; left time: 615.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.1324539 Vali Loss: 0.0937511 Test Loss: 0.0949556\n",
      "Validation loss decreased (inf --> 0.093751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0720905\n",
      "\tspeed: 0.0539s/iter; left time: 1184.2051s\n",
      "\titers: 200, epoch: 2 | loss: 0.0645590\n",
      "\tspeed: 0.0274s/iter; left time: 599.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 223 | Train Loss: 0.0755588 Vali Loss: 0.0620441 Test Loss: 0.0650663\n",
      "Validation loss decreased (0.093751 --> 0.062044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0640341\n",
      "\tspeed: 0.0545s/iter; left time: 1186.3514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0612153\n",
      "\tspeed: 0.0269s/iter; left time: 582.5923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0647354 Vali Loss: 0.0599341 Test Loss: 0.0626789\n",
      "Validation loss decreased (0.062044 --> 0.059934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0636144\n",
      "\tspeed: 0.0552s/iter; left time: 1188.4956s\n",
      "\titers: 200, epoch: 4 | loss: 0.0610736\n",
      "\tspeed: 0.0266s/iter; left time: 569.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0622370 Vali Loss: 0.0586477 Test Loss: 0.0611086\n",
      "Validation loss decreased (0.059934 --> 0.058648).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597302\n",
      "\tspeed: 0.0525s/iter; left time: 1118.1597s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593400\n",
      "\tspeed: 0.0267s/iter; left time: 565.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 223 | Train Loss: 0.0605518 Vali Loss: 0.0583430 Test Loss: 0.0606032\n",
      "Validation loss decreased (0.058648 --> 0.058343).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601675\n",
      "\tspeed: 0.0519s/iter; left time: 1094.6959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0591417\n",
      "\tspeed: 0.0276s/iter; left time: 580.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0595355 Vali Loss: 0.0577077 Test Loss: 0.0602866\n",
      "Validation loss decreased (0.058343 --> 0.057708).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0616218\n",
      "\tspeed: 0.0527s/iter; left time: 1100.1340s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583670\n",
      "\tspeed: 0.0267s/iter; left time: 554.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0587154 Vali Loss: 0.0572509 Test Loss: 0.0596006\n",
      "Validation loss decreased (0.057708 --> 0.057251).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0568723\n",
      "\tspeed: 0.0575s/iter; left time: 1187.0474s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633062\n",
      "\tspeed: 0.0266s/iter; left time: 545.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0581127 Vali Loss: 0.0571833 Test Loss: 0.0592898\n",
      "Validation loss decreased (0.057251 --> 0.057183).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0551414\n",
      "\tspeed: 0.0534s/iter; left time: 1090.9052s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602552\n",
      "\tspeed: 0.0265s/iter; left time: 538.2335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0575728 Vali Loss: 0.0565193 Test Loss: 0.0591429\n",
      "Validation loss decreased (0.057183 --> 0.056519).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0542222\n",
      "\tspeed: 0.0522s/iter; left time: 1053.9653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0603032\n",
      "\tspeed: 0.0276s/iter; left time: 554.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0570322 Vali Loss: 0.0563715 Test Loss: 0.0591157\n",
      "Validation loss decreased (0.056519 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0570678\n",
      "\tspeed: 0.0515s/iter; left time: 1029.4251s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550144\n",
      "\tspeed: 0.0277s/iter; left time: 550.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0566705 Vali Loss: 0.0562801 Test Loss: 0.0587650\n",
      "Validation loss decreased (0.056372 --> 0.056280).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0574326\n",
      "\tspeed: 0.0526s/iter; left time: 1038.9030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0546103\n",
      "\tspeed: 0.0268s/iter; left time: 527.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 223 | Train Loss: 0.0563215 Vali Loss: 0.0561686 Test Loss: 0.0584310\n",
      "Validation loss decreased (0.056280 --> 0.056169).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0557495\n",
      "\tspeed: 0.0545s/iter; left time: 1063.4217s\n",
      "\titers: 200, epoch: 13 | loss: 0.0531652\n",
      "\tspeed: 0.0266s/iter; left time: 516.0870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0559293 Vali Loss: 0.0560087 Test Loss: 0.0585652\n",
      "Validation loss decreased (0.056169 --> 0.056009).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552769\n",
      "\tspeed: 0.0533s/iter; left time: 1029.0034s\n",
      "\titers: 200, epoch: 14 | loss: 0.0531435\n",
      "\tspeed: 0.0268s/iter; left time: 515.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0556957 Vali Loss: 0.0558831 Test Loss: 0.0582514\n",
      "Validation loss decreased (0.056009 --> 0.055883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521481\n",
      "\tspeed: 0.0524s/iter; left time: 999.6095s\n",
      "\titers: 200, epoch: 15 | loss: 0.0553430\n",
      "\tspeed: 0.0283s/iter; left time: 536.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0555145 Vali Loss: 0.0557019 Test Loss: 0.0581627\n",
      "Validation loss decreased (0.055883 --> 0.055702).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609594\n",
      "\tspeed: 0.0527s/iter; left time: 993.4804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542896\n",
      "\tspeed: 0.0272s/iter; left time: 509.3344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0552573 Vali Loss: 0.0554980 Test Loss: 0.0579392\n",
      "Validation loss decreased (0.055702 --> 0.055498).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0568106\n",
      "\tspeed: 0.0542s/iter; left time: 1009.8471s\n",
      "\titers: 200, epoch: 17 | loss: 0.0526110\n",
      "\tspeed: 0.0264s/iter; left time: 489.3135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0551050 Vali Loss: 0.0555646 Test Loss: 0.0581667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543328\n",
      "\tspeed: 0.0534s/iter; left time: 982.9672s\n",
      "\titers: 200, epoch: 18 | loss: 0.0529872\n",
      "\tspeed: 0.0265s/iter; left time: 484.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0549972 Vali Loss: 0.0554904 Test Loss: 0.0578824\n",
      "Validation loss decreased (0.055498 --> 0.055490).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0561036\n",
      "\tspeed: 0.0511s/iter; left time: 929.3392s\n",
      "\titers: 200, epoch: 19 | loss: 0.0585789\n",
      "\tspeed: 0.0269s/iter; left time: 486.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 223 | Train Loss: 0.0547228 Vali Loss: 0.0551855 Test Loss: 0.0576403\n",
      "Validation loss decreased (0.055490 --> 0.055185).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0551048\n",
      "\tspeed: 0.0535s/iter; left time: 961.2267s\n",
      "\titers: 200, epoch: 20 | loss: 0.0540609\n",
      "\tspeed: 0.0283s/iter; left time: 505.7844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0546380 Vali Loss: 0.0555217 Test Loss: 0.0577946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0542702\n",
      "\tspeed: 0.0516s/iter; left time: 916.2719s\n",
      "\titers: 200, epoch: 21 | loss: 0.0512278\n",
      "\tspeed: 0.0263s/iter; left time: 464.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 223 | Train Loss: 0.0545288 Vali Loss: 0.0553299 Test Loss: 0.0576920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0561697\n",
      "\tspeed: 0.0550s/iter; left time: 962.6244s\n",
      "\titers: 200, epoch: 22 | loss: 0.0527409\n",
      "\tspeed: 0.0268s/iter; left time: 466.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0544019 Vali Loss: 0.0552929 Test Loss: 0.0575224\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529760\n",
      "\tspeed: 0.0534s/iter; left time: 923.4529s\n",
      "\titers: 200, epoch: 23 | loss: 0.0520137\n",
      "\tspeed: 0.0270s/iter; left time: 463.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0542588 Vali Loss: 0.0552379 Test Loss: 0.0575204\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0544704\n",
      "\tspeed: 0.0515s/iter; left time: 878.6230s\n",
      "\titers: 200, epoch: 24 | loss: 0.0581453\n",
      "\tspeed: 0.0287s/iter; left time: 486.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0542069 Vali Loss: 0.0551895 Test Loss: 0.0574684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0549121\n",
      "\tspeed: 0.0518s/iter; left time: 872.9043s\n",
      "\titers: 200, epoch: 25 | loss: 0.0512915\n",
      "\tspeed: 0.0269s/iter; left time: 450.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0541660 Vali Loss: 0.0550061 Test Loss: 0.0575668\n",
      "Validation loss decreased (0.055185 --> 0.055006).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0542531\n",
      "\tspeed: 0.0547s/iter; left time: 910.0617s\n",
      "\titers: 200, epoch: 26 | loss: 0.0534555\n",
      "\tspeed: 0.0271s/iter; left time: 447.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0540092 Vali Loss: 0.0549437 Test Loss: 0.0573728\n",
      "Validation loss decreased (0.055006 --> 0.054944).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0522741\n",
      "\tspeed: 0.0547s/iter; left time: 897.5644s\n",
      "\titers: 200, epoch: 27 | loss: 0.0540177\n",
      "\tspeed: 0.0269s/iter; left time: 438.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0539847 Vali Loss: 0.0550816 Test Loss: 0.0574916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0527179\n",
      "\tspeed: 0.0518s/iter; left time: 838.5554s\n",
      "\titers: 200, epoch: 28 | loss: 0.0534733\n",
      "\tspeed: 0.0276s/iter; left time: 443.3765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0539413 Vali Loss: 0.0550135 Test Loss: 0.0575341\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0502411\n",
      "\tspeed: 0.0513s/iter; left time: 819.2275s\n",
      "\titers: 200, epoch: 29 | loss: 0.0528361\n",
      "\tspeed: 0.0275s/iter; left time: 435.9257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0538017 Vali Loss: 0.0548889 Test Loss: 0.0573778\n",
      "Validation loss decreased (0.054944 --> 0.054889).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0518792\n",
      "\tspeed: 0.0524s/iter; left time: 824.7375s\n",
      "\titers: 200, epoch: 30 | loss: 0.0557014\n",
      "\tspeed: 0.0265s/iter; left time: 414.4736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0537871 Vali Loss: 0.0549768 Test Loss: 0.0574409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0499483\n",
      "\tspeed: 0.0546s/iter; left time: 847.1963s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548199\n",
      "\tspeed: 0.0265s/iter; left time: 408.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0537241 Vali Loss: 0.0548849 Test Loss: 0.0573524\n",
      "Validation loss decreased (0.054889 --> 0.054885).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0519677\n",
      "\tspeed: 0.0530s/iter; left time: 809.8001s\n",
      "\titers: 200, epoch: 32 | loss: 0.0509725\n",
      "\tspeed: 0.0269s/iter; left time: 408.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 223 | Train Loss: 0.0537428 Vali Loss: 0.0548889 Test Loss: 0.0573561\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0516712\n",
      "\tspeed: 0.0519s/iter; left time: 781.2646s\n",
      "\titers: 200, epoch: 33 | loss: 0.0521875\n",
      "\tspeed: 0.0286s/iter; left time: 428.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536519 Vali Loss: 0.0549251 Test Loss: 0.0573139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0525791\n",
      "\tspeed: 0.0522s/iter; left time: 775.0032s\n",
      "\titers: 200, epoch: 34 | loss: 0.0539121\n",
      "\tspeed: 0.0266s/iter; left time: 392.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 223 | Train Loss: 0.0536618 Vali Loss: 0.0548495 Test Loss: 0.0573276\n",
      "Validation loss decreased (0.054885 --> 0.054850).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548193\n",
      "\tspeed: 0.0559s/iter; left time: 817.7348s\n",
      "\titers: 200, epoch: 35 | loss: 0.0560694\n",
      "\tspeed: 0.0269s/iter; left time: 390.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 223 | Train Loss: 0.0536223 Vali Loss: 0.0549313 Test Loss: 0.0573653\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0531555\n",
      "\tspeed: 0.0537s/iter; left time: 772.3500s\n",
      "\titers: 200, epoch: 36 | loss: 0.0529074\n",
      "\tspeed: 0.0270s/iter; left time: 385.8289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0535724 Vali Loss: 0.0548796 Test Loss: 0.0573130\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0542191\n",
      "\tspeed: 0.0515s/iter; left time: 729.6216s\n",
      "\titers: 200, epoch: 37 | loss: 0.0521309\n",
      "\tspeed: 0.0284s/iter; left time: 399.6735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0536354 Vali Loss: 0.0548213 Test Loss: 0.0573156\n",
      "Validation loss decreased (0.054850 --> 0.054821).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0513455\n",
      "\tspeed: 0.0514s/iter; left time: 716.9502s\n",
      "\titers: 200, epoch: 38 | loss: 0.0484909\n",
      "\tspeed: 0.0283s/iter; left time: 391.7052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 223 | Train Loss: 0.0535302 Vali Loss: 0.0548031 Test Loss: 0.0572883\n",
      "Validation loss decreased (0.054821 --> 0.054803).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0567436\n",
      "\tspeed: 0.0533s/iter; left time: 731.9007s\n",
      "\titers: 200, epoch: 39 | loss: 0.0543030\n",
      "\tspeed: 0.0268s/iter; left time: 364.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0535580 Vali Loss: 0.0548298 Test Loss: 0.0572565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0577767\n",
      "\tspeed: 0.0542s/iter; left time: 731.7697s\n",
      "\titers: 200, epoch: 40 | loss: 0.0489657\n",
      "\tspeed: 0.0265s/iter; left time: 355.5326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0535311 Vali Loss: 0.0547384 Test Loss: 0.0572284\n",
      "Validation loss decreased (0.054803 --> 0.054738).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0492260\n",
      "\tspeed: 0.0523s/iter; left time: 695.0258s\n",
      "\titers: 200, epoch: 41 | loss: 0.0530771\n",
      "\tspeed: 0.0274s/iter; left time: 361.2924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 223 | Train Loss: 0.0535195 Vali Loss: 0.0547555 Test Loss: 0.0572335\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536120\n",
      "\tspeed: 0.0524s/iter; left time: 683.8322s\n",
      "\titers: 200, epoch: 42 | loss: 0.0539439\n",
      "\tspeed: 0.0290s/iter; left time: 375.9186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0535063 Vali Loss: 0.0547998 Test Loss: 0.0572487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0516886\n",
      "\tspeed: 0.0513s/iter; left time: 659.0389s\n",
      "\titers: 200, epoch: 43 | loss: 0.0514923\n",
      "\tspeed: 0.0263s/iter; left time: 335.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0534249 Vali Loss: 0.0548376 Test Loss: 0.0572255\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0577250\n",
      "\tspeed: 0.0549s/iter; left time: 692.4608s\n",
      "\titers: 200, epoch: 44 | loss: 0.0516380\n",
      "\tspeed: 0.0269s/iter; left time: 336.5462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0534548 Vali Loss: 0.0547533 Test Loss: 0.0572155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551903\n",
      "\tspeed: 0.0531s/iter; left time: 657.8252s\n",
      "\titers: 200, epoch: 45 | loss: 0.0587276\n",
      "\tspeed: 0.0268s/iter; left time: 329.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0534890 Vali Loss: 0.0547240 Test Loss: 0.0572646\n",
      "Validation loss decreased (0.054738 --> 0.054724).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0569799\n",
      "\tspeed: 0.0520s/iter; left time: 632.1113s\n",
      "\titers: 200, epoch: 46 | loss: 0.0528706\n",
      "\tspeed: 0.0281s/iter; left time: 339.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0534028 Vali Loss: 0.0548343 Test Loss: 0.0572270\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0535365\n",
      "\tspeed: 0.0521s/iter; left time: 622.7815s\n",
      "\titers: 200, epoch: 47 | loss: 0.0522014\n",
      "\tspeed: 0.0276s/iter; left time: 327.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0534371 Vali Loss: 0.0548092 Test Loss: 0.0572257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0540526\n",
      "\tspeed: 0.0528s/iter; left time: 618.2454s\n",
      "\titers: 200, epoch: 48 | loss: 0.0521358\n",
      "\tspeed: 0.0267s/iter; left time: 309.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0534032 Vali Loss: 0.0547515 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0514734\n",
      "\tspeed: 0.0548s/iter; left time: 630.1869s\n",
      "\titers: 200, epoch: 49 | loss: 0.0515570\n",
      "\tspeed: 0.0268s/iter; left time: 305.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0533995 Vali Loss: 0.0547729 Test Loss: 0.0572376\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0553200\n",
      "\tspeed: 0.0539s/iter; left time: 607.7663s\n",
      "\titers: 200, epoch: 50 | loss: 0.0507628\n",
      "\tspeed: 0.0283s/iter; left time: 316.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 223 | Train Loss: 0.0534180 Vali Loss: 0.0548830 Test Loss: 0.0572152\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0522079\n",
      "\tspeed: 0.0516s/iter; left time: 570.3257s\n",
      "\titers: 200, epoch: 51 | loss: 0.0526080\n",
      "\tspeed: 0.0291s/iter; left time: 319.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0533703 Vali Loss: 0.0547865 Test Loss: 0.0572359\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0549524\n",
      "\tspeed: 0.0527s/iter; left time: 570.7138s\n",
      "\titers: 200, epoch: 52 | loss: 0.0532417\n",
      "\tspeed: 0.0268s/iter; left time: 287.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 223 | Train Loss: 0.0534304 Vali Loss: 0.0547305 Test Loss: 0.0572217\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0537086\n",
      "\tspeed: 0.0548s/iter; left time: 580.8395s\n",
      "\titers: 200, epoch: 53 | loss: 0.0529253\n",
      "\tspeed: 0.0266s/iter; left time: 279.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0533663 Vali Loss: 0.0548078 Test Loss: 0.0572288\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0523412\n",
      "\tspeed: 0.0540s/iter; left time: 560.4656s\n",
      "\titers: 200, epoch: 54 | loss: 0.0549152\n",
      "\tspeed: 0.0271s/iter; left time: 278.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 223 | Train Loss: 0.0533426 Vali Loss: 0.0547861 Test Loss: 0.0572313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0475683\n",
      "\tspeed: 0.0546s/iter; left time: 554.5516s\n",
      "\titers: 200, epoch: 55 | loss: 0.0524945\n",
      "\tspeed: 0.0275s/iter; left time: 276.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0534049 Vali Loss: 0.0548184 Test Loss: 0.0572309\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010083268396556377, rmse:0.10041547566652298, mae:0.05726462975144386, rse:0.3794206380844116\n",
      "Intermediate time for IT and pred_len 24: 00h:16m:28.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1321838\n",
      "\tspeed: 0.0528s/iter; left time: 1166.6778s\n",
      "\titers: 200, epoch: 1 | loss: 0.1144970\n",
      "\tspeed: 0.0271s/iter; left time: 597.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.1387064 Vali Loss: 0.1032817 Test Loss: 0.1052682\n",
      "Validation loss decreased (inf --> 0.103282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853616\n",
      "\tspeed: 0.0561s/iter; left time: 1228.0293s\n",
      "\titers: 200, epoch: 2 | loss: 0.0828326\n",
      "\tspeed: 0.0272s/iter; left time: 592.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932694 Vali Loss: 0.0822700 Test Loss: 0.0855554\n",
      "Validation loss decreased (0.103282 --> 0.082270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840157\n",
      "\tspeed: 0.0575s/iter; left time: 1245.1145s\n",
      "\titers: 200, epoch: 3 | loss: 0.0772976\n",
      "\tspeed: 0.0294s/iter; left time: 633.0791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0837174 Vali Loss: 0.0802281 Test Loss: 0.0841231\n",
      "Validation loss decreased (0.082270 --> 0.080228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776535\n",
      "\tspeed: 0.0538s/iter; left time: 1152.2520s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804181\n",
      "\tspeed: 0.0279s/iter; left time: 595.0900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0811037 Vali Loss: 0.0788419 Test Loss: 0.0832654\n",
      "Validation loss decreased (0.080228 --> 0.078842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817597\n",
      "\tspeed: 0.0555s/iter; left time: 1177.6018s\n",
      "\titers: 200, epoch: 5 | loss: 0.0780218\n",
      "\tspeed: 0.0272s/iter; left time: 573.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0794239 Vali Loss: 0.0786723 Test Loss: 0.0830877\n",
      "Validation loss decreased (0.078842 --> 0.078672).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774737\n",
      "\tspeed: 0.0564s/iter; left time: 1183.8263s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789120\n",
      "\tspeed: 0.0275s/iter; left time: 574.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0783094 Vali Loss: 0.0786543 Test Loss: 0.0826141\n",
      "Validation loss decreased (0.078672 --> 0.078654).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0756353\n",
      "\tspeed: 0.0550s/iter; left time: 1142.9273s\n",
      "\titers: 200, epoch: 7 | loss: 0.0770764\n",
      "\tspeed: 0.0279s/iter; left time: 577.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 222 | Train Loss: 0.0773383 Vali Loss: 0.0779212 Test Loss: 0.0822634\n",
      "Validation loss decreased (0.078654 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771187\n",
      "\tspeed: 0.0532s/iter; left time: 1092.8138s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760235\n",
      "\tspeed: 0.0281s/iter; left time: 574.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0764953 Vali Loss: 0.0783359 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729671\n",
      "\tspeed: 0.0537s/iter; left time: 1091.8457s\n",
      "\titers: 200, epoch: 9 | loss: 0.0753743\n",
      "\tspeed: 0.0275s/iter; left time: 555.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0758295 Vali Loss: 0.0776675 Test Loss: 0.0825013\n",
      "Validation loss decreased (0.077921 --> 0.077668).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0795718\n",
      "\tspeed: 0.0567s/iter; left time: 1138.8475s\n",
      "\titers: 200, epoch: 10 | loss: 0.0746166\n",
      "\tspeed: 0.0272s/iter; left time: 543.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0753310 Vali Loss: 0.0781949 Test Loss: 0.0824108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762351\n",
      "\tspeed: 0.0550s/iter; left time: 1093.5082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735926\n",
      "\tspeed: 0.0272s/iter; left time: 537.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0748693 Vali Loss: 0.0781084 Test Loss: 0.0827782\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725338\n",
      "\tspeed: 0.0526s/iter; left time: 1033.7681s\n",
      "\titers: 200, epoch: 12 | loss: 0.0750147\n",
      "\tspeed: 0.0284s/iter; left time: 555.6160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0743695 Vali Loss: 0.0778181 Test Loss: 0.0824795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0748884\n",
      "\tspeed: 0.0529s/iter; left time: 1028.8589s\n",
      "\titers: 200, epoch: 13 | loss: 0.0768396\n",
      "\tspeed: 0.0279s/iter; left time: 539.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0740004 Vali Loss: 0.0777673 Test Loss: 0.0825389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0698381\n",
      "\tspeed: 0.0549s/iter; left time: 1055.0927s\n",
      "\titers: 200, epoch: 14 | loss: 0.0717925\n",
      "\tspeed: 0.0269s/iter; left time: 513.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0736021 Vali Loss: 0.0778859 Test Loss: 0.0826246\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0710938\n",
      "\tspeed: 0.0559s/iter; left time: 1062.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687255\n",
      "\tspeed: 0.0270s/iter; left time: 510.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0732304 Vali Loss: 0.0778723 Test Loss: 0.0830562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0749232\n",
      "\tspeed: 0.0533s/iter; left time: 1000.4663s\n",
      "\titers: 200, epoch: 16 | loss: 0.0746401\n",
      "\tspeed: 0.0276s/iter; left time: 516.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0729620 Vali Loss: 0.0777781 Test Loss: 0.0827808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733482\n",
      "\tspeed: 0.0528s/iter; left time: 979.8157s\n",
      "\titers: 200, epoch: 17 | loss: 0.0715483\n",
      "\tspeed: 0.0288s/iter; left time: 531.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0726490 Vali Loss: 0.0779078 Test Loss: 0.0832266\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0739253\n",
      "\tspeed: 0.0536s/iter; left time: 981.6920s\n",
      "\titers: 200, epoch: 18 | loss: 0.0751582\n",
      "\tspeed: 0.0272s/iter; left time: 495.0143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0724323 Vali Loss: 0.0774746 Test Loss: 0.0825534\n",
      "Validation loss decreased (0.077668 --> 0.077475).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0730057\n",
      "\tspeed: 0.0590s/iter; left time: 1068.9870s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744534\n",
      "\tspeed: 0.0269s/iter; left time: 484.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0721436 Vali Loss: 0.0777745 Test Loss: 0.0828253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0702813\n",
      "\tspeed: 0.0554s/iter; left time: 989.9029s\n",
      "\titers: 200, epoch: 20 | loss: 0.0714406\n",
      "\tspeed: 0.0274s/iter; left time: 486.6499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0719519 Vali Loss: 0.0777934 Test Loss: 0.0831720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0752490\n",
      "\tspeed: 0.0530s/iter; left time: 936.4262s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729214\n",
      "\tspeed: 0.0297s/iter; left time: 522.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0717573 Vali Loss: 0.0775301 Test Loss: 0.0829119\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0729312\n",
      "\tspeed: 0.0534s/iter; left time: 930.4178s\n",
      "\titers: 200, epoch: 22 | loss: 0.0712821\n",
      "\tspeed: 0.0279s/iter; left time: 483.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0716219 Vali Loss: 0.0775715 Test Loss: 0.0831647\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0745800\n",
      "\tspeed: 0.0545s/iter; left time: 939.0949s\n",
      "\titers: 200, epoch: 23 | loss: 0.0710693\n",
      "\tspeed: 0.0268s/iter; left time: 458.5333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 222 | Train Loss: 0.0714176 Vali Loss: 0.0774375 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.077475 --> 0.077438).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0726332\n",
      "\tspeed: 0.0550s/iter; left time: 934.8110s\n",
      "\titers: 200, epoch: 24 | loss: 0.0703410\n",
      "\tspeed: 0.0270s/iter; left time: 455.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0712783 Vali Loss: 0.0776950 Test Loss: 0.0831947\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0688102\n",
      "\tspeed: 0.0542s/iter; left time: 908.8879s\n",
      "\titers: 200, epoch: 25 | loss: 0.0745878\n",
      "\tspeed: 0.0288s/iter; left time: 480.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 222 | Train Loss: 0.0710946 Vali Loss: 0.0775712 Test Loss: 0.0831804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0722734\n",
      "\tspeed: 0.0529s/iter; left time: 874.8612s\n",
      "\titers: 200, epoch: 26 | loss: 0.0690523\n",
      "\tspeed: 0.0284s/iter; left time: 467.9860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0710367 Vali Loss: 0.0774692 Test Loss: 0.0832843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0757137\n",
      "\tspeed: 0.0539s/iter; left time: 880.8381s\n",
      "\titers: 200, epoch: 27 | loss: 0.0672927\n",
      "\tspeed: 0.0275s/iter; left time: 445.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0709873 Vali Loss: 0.0775369 Test Loss: 0.0832190\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0734061\n",
      "\tspeed: 0.0564s/iter; left time: 908.3009s\n",
      "\titers: 200, epoch: 28 | loss: 0.0689125\n",
      "\tspeed: 0.0269s/iter; left time: 430.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 222 | Train Loss: 0.0708438 Vali Loss: 0.0776351 Test Loss: 0.0832205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0706797\n",
      "\tspeed: 0.0549s/iter; left time: 871.6611s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731136\n",
      "\tspeed: 0.0278s/iter; left time: 439.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 222 | Train Loss: 0.0707727 Vali Loss: 0.0773896 Test Loss: 0.0832303\n",
      "Validation loss decreased (0.077438 --> 0.077390).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0717404\n",
      "\tspeed: 0.0534s/iter; left time: 835.9623s\n",
      "\titers: 200, epoch: 30 | loss: 0.0729116\n",
      "\tspeed: 0.0290s/iter; left time: 451.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.0706910 Vali Loss: 0.0774434 Test Loss: 0.0832887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0757121\n",
      "\tspeed: 0.0534s/iter; left time: 825.1587s\n",
      "\titers: 200, epoch: 31 | loss: 0.0711617\n",
      "\tspeed: 0.0271s/iter; left time: 415.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0706033 Vali Loss: 0.0776396 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0712611\n",
      "\tspeed: 0.0575s/iter; left time: 874.6293s\n",
      "\titers: 200, epoch: 32 | loss: 0.0727751\n",
      "\tspeed: 0.0272s/iter; left time: 411.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0705892 Vali Loss: 0.0775814 Test Loss: 0.0833558\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0709131\n",
      "\tspeed: 0.0545s/iter; left time: 817.8930s\n",
      "\titers: 200, epoch: 33 | loss: 0.0718555\n",
      "\tspeed: 0.0271s/iter; left time: 403.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0705573 Vali Loss: 0.0772810 Test Loss: 0.0833159\n",
      "Validation loss decreased (0.077390 --> 0.077281).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0690060\n",
      "\tspeed: 0.0518s/iter; left time: 765.6173s\n",
      "\titers: 200, epoch: 34 | loss: 0.0711988\n",
      "\tspeed: 0.0280s/iter; left time: 410.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 222 | Train Loss: 0.0705202 Vali Loss: 0.0774535 Test Loss: 0.0832982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0732094\n",
      "\tspeed: 0.0534s/iter; left time: 776.4035s\n",
      "\titers: 200, epoch: 35 | loss: 0.0739846\n",
      "\tspeed: 0.0278s/iter; left time: 401.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0704378 Vali Loss: 0.0774655 Test Loss: 0.0832758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0734195\n",
      "\tspeed: 0.0536s/iter; left time: 768.0877s\n",
      "\titers: 200, epoch: 36 | loss: 0.0688326\n",
      "\tspeed: 0.0276s/iter; left time: 393.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0703314 Vali Loss: 0.0775375 Test Loss: 0.0834405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0667930\n",
      "\tspeed: 0.0559s/iter; left time: 788.8954s\n",
      "\titers: 200, epoch: 37 | loss: 0.0698663\n",
      "\tspeed: 0.0271s/iter; left time: 379.4721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 222 | Train Loss: 0.0703407 Vali Loss: 0.0774669 Test Loss: 0.0833736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0679398\n",
      "\tspeed: 0.0555s/iter; left time: 771.3706s\n",
      "\titers: 200, epoch: 38 | loss: 0.0724612\n",
      "\tspeed: 0.0274s/iter; left time: 377.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0703553 Vali Loss: 0.0775958 Test Loss: 0.0833337\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0718481\n",
      "\tspeed: 0.0526s/iter; left time: 718.1055s\n",
      "\titers: 200, epoch: 39 | loss: 0.0735828\n",
      "\tspeed: 0.0286s/iter; left time: 388.2652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702385 Vali Loss: 0.0774214 Test Loss: 0.0832950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0657273\n",
      "\tspeed: 0.0537s/iter; left time: 722.4613s\n",
      "\titers: 200, epoch: 40 | loss: 0.0679445\n",
      "\tspeed: 0.0268s/iter; left time: 357.9045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0702638 Vali Loss: 0.0775013 Test Loss: 0.0834430\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673170\n",
      "\tspeed: 0.0568s/iter; left time: 750.9906s\n",
      "\titers: 200, epoch: 41 | loss: 0.0687927\n",
      "\tspeed: 0.0269s/iter; left time: 352.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 222 | Train Loss: 0.0702658 Vali Loss: 0.0773642 Test Loss: 0.0834067\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0763263\n",
      "\tspeed: 0.0575s/iter; left time: 746.9921s\n",
      "\titers: 200, epoch: 42 | loss: 0.0653355\n",
      "\tspeed: 0.0279s/iter; left time: 359.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0701891 Vali Loss: 0.0775082 Test Loss: 0.0834283\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0718496\n",
      "\tspeed: 0.0548s/iter; left time: 700.0664s\n",
      "\titers: 200, epoch: 43 | loss: 0.0727848\n",
      "\tspeed: 0.0281s/iter; left time: 355.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0702348 Vali Loss: 0.0775226 Test Loss: 0.0834311\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019748352468013763, rmse:0.1405288279056549, mae:0.0833158940076828, rse:0.5313546657562256\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1307300\n",
      "\tspeed: 0.0299s/iter; left time: 661.4012s\n",
      "\titers: 200, epoch: 1 | loss: 0.1169153\n",
      "\tspeed: 0.0295s/iter; left time: 649.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.1395382 Vali Loss: 0.1032388 Test Loss: 0.1049907\n",
      "Validation loss decreased (inf --> 0.103239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0917928\n",
      "\tspeed: 0.0557s/iter; left time: 1217.6038s\n",
      "\titers: 200, epoch: 2 | loss: 0.0827175\n",
      "\tspeed: 0.0287s/iter; left time: 624.5582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0932693 Vali Loss: 0.0824907 Test Loss: 0.0859276\n",
      "Validation loss decreased (0.103239 --> 0.082491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0872422\n",
      "\tspeed: 0.0548s/iter; left time: 1186.2276s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782116\n",
      "\tspeed: 0.0270s/iter; left time: 582.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 222 | Train Loss: 0.0836970 Vali Loss: 0.0801819 Test Loss: 0.0838659\n",
      "Validation loss decreased (0.082491 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816273\n",
      "\tspeed: 0.0592s/iter; left time: 1268.5184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826085\n",
      "\tspeed: 0.0267s/iter; left time: 569.6264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 222 | Train Loss: 0.0810833 Vali Loss: 0.0788540 Test Loss: 0.0829947\n",
      "Validation loss decreased (0.080182 --> 0.078854).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0761694\n",
      "\tspeed: 0.0566s/iter; left time: 1201.0110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0798683\n",
      "\tspeed: 0.0270s/iter; left time: 569.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0795185 Vali Loss: 0.0781875 Test Loss: 0.0825942\n",
      "Validation loss decreased (0.078854 --> 0.078187).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777261\n",
      "\tspeed: 0.0551s/iter; left time: 1156.6782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0814498\n",
      "\tspeed: 0.0286s/iter; left time: 598.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0783964 Vali Loss: 0.0775421 Test Loss: 0.0821851\n",
      "Validation loss decreased (0.078187 --> 0.077542).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0739338\n",
      "\tspeed: 0.0550s/iter; left time: 1142.5101s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811702\n",
      "\tspeed: 0.0280s/iter; left time: 578.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0774509 Vali Loss: 0.0783391 Test Loss: 0.0824711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753421\n",
      "\tspeed: 0.0553s/iter; left time: 1136.8596s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756552\n",
      "\tspeed: 0.0269s/iter; left time: 550.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0767014 Vali Loss: 0.0771883 Test Loss: 0.0820175\n",
      "Validation loss decreased (0.077542 --> 0.077188).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738878\n",
      "\tspeed: 0.0593s/iter; left time: 1204.7930s\n",
      "\titers: 200, epoch: 9 | loss: 0.0749177\n",
      "\tspeed: 0.0268s/iter; left time: 542.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 222 | Train Loss: 0.0760252 Vali Loss: 0.0781950 Test Loss: 0.0820919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0755344\n",
      "\tspeed: 0.0569s/iter; left time: 1143.6002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0751255\n",
      "\tspeed: 0.0270s/iter; left time: 539.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0755306 Vali Loss: 0.0778631 Test Loss: 0.0822712\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0782155\n",
      "\tspeed: 0.0549s/iter; left time: 1091.8220s\n",
      "\titers: 200, epoch: 11 | loss: 0.0755833\n",
      "\tspeed: 0.0290s/iter; left time: 573.2812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0749816 Vali Loss: 0.0776737 Test Loss: 0.0817804\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0693621\n",
      "\tspeed: 0.0548s/iter; left time: 1077.9669s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719745\n",
      "\tspeed: 0.0273s/iter; left time: 533.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0745667 Vali Loss: 0.0779224 Test Loss: 0.0818569\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0694613\n",
      "\tspeed: 0.0573s/iter; left time: 1113.5811s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725119\n",
      "\tspeed: 0.0269s/iter; left time: 521.0562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 222 | Train Loss: 0.0740950 Vali Loss: 0.0777880 Test Loss: 0.0819785\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0775695\n",
      "\tspeed: 0.0581s/iter; left time: 1115.6870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0681774\n",
      "\tspeed: 0.0270s/iter; left time: 516.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0736995 Vali Loss: 0.0773107 Test Loss: 0.0820360\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733372\n",
      "\tspeed: 0.0569s/iter; left time: 1081.2037s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732900\n",
      "\tspeed: 0.0273s/iter; left time: 516.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0734037 Vali Loss: 0.0772424 Test Loss: 0.0821582\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0713919\n",
      "\tspeed: 0.0549s/iter; left time: 1030.8488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0709377\n",
      "\tspeed: 0.0313s/iter; left time: 583.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 222 | Train Loss: 0.0731161 Vali Loss: 0.0773405 Test Loss: 0.0820549\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754753\n",
      "\tspeed: 0.0540s/iter; left time: 1001.8352s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705882\n",
      "\tspeed: 0.0272s/iter; left time: 501.7343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 222 | Train Loss: 0.0728018 Vali Loss: 0.0775164 Test Loss: 0.0821095\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0719491\n",
      "\tspeed: 0.0591s/iter; left time: 1083.3750s\n",
      "\titers: 200, epoch: 18 | loss: 0.0699536\n",
      "\tspeed: 0.0275s/iter; left time: 500.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 222 | Train Loss: 0.0726074 Vali Loss: 0.0776926 Test Loss: 0.0821289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01836535520851612, rmse:0.13551883399486542, mae:0.08201750367879868, rse:0.51241135597229\n",
      "Intermediate time for IT and pred_len 96: 00h:08m:37.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1298100\n",
      "\tspeed: 0.0534s/iter; left time: 1180.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.1176691\n",
      "\tspeed: 0.0292s/iter; left time: 643.0642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 222 | Train Loss: 0.1401385 Vali Loss: 0.1051041 Test Loss: 0.1060515\n",
      "Validation loss decreased (inf --> 0.105104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0925689\n",
      "\tspeed: 0.0530s/iter; left time: 1158.9939s\n",
      "\titers: 200, epoch: 2 | loss: 0.0874640\n",
      "\tspeed: 0.0274s/iter; left time: 597.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 222 | Train Loss: 0.0966582 Vali Loss: 0.0868458 Test Loss: 0.0894829\n",
      "Validation loss decreased (0.105104 --> 0.086846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0902038\n",
      "\tspeed: 0.0607s/iter; left time: 1313.8809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0879562\n",
      "\tspeed: 0.0273s/iter; left time: 588.1558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 222 | Train Loss: 0.0874138 Vali Loss: 0.0842694 Test Loss: 0.0879542\n",
      "Validation loss decreased (0.086846 --> 0.084269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857633\n",
      "\tspeed: 0.0538s/iter; left time: 1153.1748s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834477\n",
      "\tspeed: 0.0272s/iter; left time: 580.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0846647 Vali Loss: 0.0835778 Test Loss: 0.0880411\n",
      "Validation loss decreased (0.084269 --> 0.083578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838752\n",
      "\tspeed: 0.0540s/iter; left time: 1144.7333s\n",
      "\titers: 200, epoch: 5 | loss: 0.0841271\n",
      "\tspeed: 0.0300s/iter; left time: 632.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0829673 Vali Loss: 0.0838262 Test Loss: 0.0883332\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0792901\n",
      "\tspeed: 0.0527s/iter; left time: 1106.0900s\n",
      "\titers: 200, epoch: 6 | loss: 0.0827553\n",
      "\tspeed: 0.0281s/iter; left time: 587.3857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 222 | Train Loss: 0.0816290 Vali Loss: 0.0842234 Test Loss: 0.0882273\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829263\n",
      "\tspeed: 0.0550s/iter; left time: 1142.8870s\n",
      "\titers: 200, epoch: 7 | loss: 0.0831176\n",
      "\tspeed: 0.0273s/iter; left time: 563.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 222 | Train Loss: 0.0805962 Vali Loss: 0.0847038 Test Loss: 0.0883791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0816610\n",
      "\tspeed: 0.0575s/iter; left time: 1181.3405s\n",
      "\titers: 200, epoch: 8 | loss: 0.0787463\n",
      "\tspeed: 0.0276s/iter; left time: 564.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 222 | Train Loss: 0.0797245 Vali Loss: 0.0845396 Test Loss: 0.0883748\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766695\n",
      "\tspeed: 0.0528s/iter; left time: 1073.0838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0811797\n",
      "\tspeed: 0.0309s/iter; left time: 625.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 222 | Train Loss: 0.0790013 Vali Loss: 0.0842658 Test Loss: 0.0882581\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0773436\n",
      "\tspeed: 0.0541s/iter; left time: 1086.6544s\n",
      "\titers: 200, epoch: 10 | loss: 0.0750153\n",
      "\tspeed: 0.0282s/iter; left time: 563.2027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 222 | Train Loss: 0.0784806 Vali Loss: 0.0848489 Test Loss: 0.0890048\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781072\n",
      "\tspeed: 0.0543s/iter; left time: 1079.4039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0776325\n",
      "\tspeed: 0.0273s/iter; left time: 540.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0778847 Vali Loss: 0.0847653 Test Loss: 0.0893754\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0796271\n",
      "\tspeed: 0.0551s/iter; left time: 1082.2326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788494\n",
      "\tspeed: 0.0272s/iter; left time: 532.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 222 | Train Loss: 0.0774273 Vali Loss: 0.0847762 Test Loss: 0.0897269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719526\n",
      "\tspeed: 0.0518s/iter; left time: 1006.1097s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759829\n",
      "\tspeed: 0.0291s/iter; left time: 562.6513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 222 | Train Loss: 0.0770110 Vali Loss: 0.0850721 Test Loss: 0.0895426\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745691\n",
      "\tspeed: 0.0531s/iter; left time: 1020.3689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0722817\n",
      "\tspeed: 0.0281s/iter; left time: 537.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 222 | Train Loss: 0.0765886 Vali Loss: 0.0847122 Test Loss: 0.0897249\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0201936773955822, rmse:0.14210446178913116, mae:0.08804111182689667, rse:0.5378115773200989\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1329002\n",
      "\tspeed: 0.0291s/iter; left time: 642.7910s\n",
      "\titers: 200, epoch: 1 | loss: 0.1175623\n",
      "\tspeed: 0.0281s/iter; left time: 619.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 222 | Train Loss: 0.1417617 Vali Loss: 0.1047845 Test Loss: 0.1055077\n",
      "Validation loss decreased (inf --> 0.104784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0927295\n",
      "\tspeed: 0.0578s/iter; left time: 1264.0138s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941170\n",
      "\tspeed: 0.0277s/iter; left time: 604.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 222 | Train Loss: 0.0963996 Vali Loss: 0.0871643 Test Loss: 0.0895704\n",
      "Validation loss decreased (0.104784 --> 0.087164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878410\n",
      "\tspeed: 0.0590s/iter; left time: 1278.2876s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902920\n",
      "\tspeed: 0.0280s/iter; left time: 603.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0870747 Vali Loss: 0.0847243 Test Loss: 0.0878319\n",
      "Validation loss decreased (0.087164 --> 0.084724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853640\n",
      "\tspeed: 0.0566s/iter; left time: 1213.5422s\n",
      "\titers: 200, epoch: 4 | loss: 0.0840227\n",
      "\tspeed: 0.0282s/iter; left time: 601.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 222 | Train Loss: 0.0846555 Vali Loss: 0.0835151 Test Loss: 0.0876056\n",
      "Validation loss decreased (0.084724 --> 0.083515).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0851938\n",
      "\tspeed: 0.0580s/iter; left time: 1229.8414s\n",
      "\titers: 200, epoch: 5 | loss: 0.0813548\n",
      "\tspeed: 0.0306s/iter; left time: 645.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 222 | Train Loss: 0.0830201 Vali Loss: 0.0840696 Test Loss: 0.0879182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0852846\n",
      "\tspeed: 0.0531s/iter; left time: 1114.5854s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810560\n",
      "\tspeed: 0.0272s/iter; left time: 567.2324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0818896 Vali Loss: 0.0842003 Test Loss: 0.0879094\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0802038\n",
      "\tspeed: 0.0572s/iter; left time: 1187.9462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809201\n",
      "\tspeed: 0.0271s/iter; left time: 559.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 222 | Train Loss: 0.0808258 Vali Loss: 0.0832934 Test Loss: 0.0873938\n",
      "Validation loss decreased (0.083515 --> 0.083293).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792483\n",
      "\tspeed: 0.0624s/iter; left time: 1281.8376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819951\n",
      "\tspeed: 0.0279s/iter; left time: 570.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 222 | Train Loss: 0.0800518 Vali Loss: 0.0839962 Test Loss: 0.0880267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0774117\n",
      "\tspeed: 0.0541s/iter; left time: 1098.8363s\n",
      "\titers: 200, epoch: 9 | loss: 0.0775325\n",
      "\tspeed: 0.0285s/iter; left time: 576.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 222 | Train Loss: 0.0793224 Vali Loss: 0.0844191 Test Loss: 0.0877155\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0806580\n",
      "\tspeed: 0.0556s/iter; left time: 1116.7889s\n",
      "\titers: 200, epoch: 10 | loss: 0.0799583\n",
      "\tspeed: 0.0277s/iter; left time: 555.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 222 | Train Loss: 0.0787225 Vali Loss: 0.0840966 Test Loss: 0.0883957\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771481\n",
      "\tspeed: 0.0573s/iter; left time: 1138.9736s\n",
      "\titers: 200, epoch: 11 | loss: 0.0804428\n",
      "\tspeed: 0.0278s/iter; left time: 549.0437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 222 | Train Loss: 0.0780882 Vali Loss: 0.0844000 Test Loss: 0.0881920\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0766762\n",
      "\tspeed: 0.0586s/iter; left time: 1151.7988s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793117\n",
      "\tspeed: 0.0274s/iter; left time: 535.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 222 | Train Loss: 0.0776378 Vali Loss: 0.0840316 Test Loss: 0.0880184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0769361\n",
      "\tspeed: 0.0577s/iter; left time: 1121.7394s\n",
      "\titers: 200, epoch: 13 | loss: 0.0785047\n",
      "\tspeed: 0.0276s/iter; left time: 532.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 222 | Train Loss: 0.0771586 Vali Loss: 0.0841548 Test Loss: 0.0880232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0777556\n",
      "\tspeed: 0.0529s/iter; left time: 1017.3781s\n",
      "\titers: 200, epoch: 14 | loss: 0.0767437\n",
      "\tspeed: 0.0300s/iter; left time: 573.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 222 | Train Loss: 0.0767452 Vali Loss: 0.0836313 Test Loss: 0.0883247\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0787518\n",
      "\tspeed: 0.0534s/iter; left time: 1014.7503s\n",
      "\titers: 200, epoch: 15 | loss: 0.0794870\n",
      "\tspeed: 0.0274s/iter; left time: 518.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 222 | Train Loss: 0.0763562 Vali Loss: 0.0837894 Test Loss: 0.0880314\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0768457\n",
      "\tspeed: 0.0613s/iter; left time: 1150.8829s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772194\n",
      "\tspeed: 0.0280s/iter; left time: 523.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 222 | Train Loss: 0.0760031 Vali Loss: 0.0840183 Test Loss: 0.0883679\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0778723\n",
      "\tspeed: 0.0571s/iter; left time: 1058.7481s\n",
      "\titers: 200, epoch: 17 | loss: 0.0730445\n",
      "\tspeed: 0.0282s/iter; left time: 519.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 222 | Train Loss: 0.0756556 Vali Loss: 0.0837157 Test Loss: 0.0881411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020205043256282806, rmse:0.14214444160461426, mae:0.08739381283521652, rse:0.5379629135131836\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:33.10s\n",
      "Intermediate time for IT: 00h:29m:38.75s\n",
      "Total time: 02h:35m:30.27s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.0827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1450  0.0880\n",
       "        96            0.0359  0.1894  0.1250\n",
       "        168           0.0388  0.1968  0.1327\n",
       "ES      24            0.0099  0.0993  0.0597\n",
       "        96            0.0190  0.1377  0.0879\n",
       "        168           0.0213  0.1460  0.0952\n",
       "FR      24            0.0100  0.1002  0.0552\n",
       "        96            0.0197  0.1405  0.0811\n",
       "        168           0.0222  0.1490  0.0876\n",
       "GB      24            0.0246  0.1570  0.0990\n",
       "        96            0.0411  0.2027  0.1390\n",
       "        168           0.0435  0.2085  0.1449\n",
       "IT      24            0.0101  0.1005  0.0573\n",
       "        96            0.0191  0.1380  0.0827\n",
       "        168           0.0202  0.1421  0.0877"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
