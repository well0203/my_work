{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. TimeLLM](#1-timellm)\n",
    "- [2. TimeLLM](#2-timellm-336)\n",
    "\n",
    "Results for TimeLLM. The first one is default input length 512, the second one: 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"2\"\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['FR', 'IT']\n",
    "num_cols = [3, 3]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TimeLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 168\n",
    "model = \"TimeLLM\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_168.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32\n",
    "\n",
    "# List to store the results\n",
    "timellm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 86835\n",
      "val 18651\n",
      "test 18651\n",
      "[2024-11-05 15:31:47,401] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 15:31:48,391] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 15:31:48,391] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 15:31:48,391] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 15:31:48,478] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 15:31:48,478] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 15:31:49,482] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 15:31:49,483] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 15:31:49,483] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 15:31:49,484] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 15:31:49,484] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 15:31:49,485] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 15:31:49,485] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 15:31:49,485] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 15:31:49,485] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 15:31:49,485] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 15:31:49,843] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 15:31:49,844] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 15:31:49,844] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 165.14 GB, percent = 21.9%\n",
      "[2024-11-05 15:31:49,990] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 15:31:49,991] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 15:31:49,992] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 165.15 GB, percent = 21.9%\n",
      "[2024-11-05 15:31:49,992] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 15:31:50,126] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 15:31:50,127] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 15:31:50,127] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 165.15 GB, percent = 21.9%\n",
      "[2024-11-05 15:31:50,128] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 15:31:50,128] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 15:31:50,128] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 15:31:50,128] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 15:31:50,129] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fadfc64b110>\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 15:31:50,130] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 15:31:50,131] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 15:31:50,132] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 15:31:50,132] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 15:31:50,132] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 15:31:50,132] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 15:31:50,132] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1354474\n",
      "\tspeed: 0.2591s/iter; left time: 14034.0735s\n",
      "\titers: 200, epoch: 1 | loss: 0.1104270\n",
      "\tspeed: 0.2227s/iter; left time: 12040.8836s\n",
      "\titers: 300, epoch: 1 | loss: 0.0970104\n",
      "\tspeed: 0.2164s/iter; left time: 11678.6479s\n",
      "\titers: 400, epoch: 1 | loss: 0.0873522\n",
      "\tspeed: 0.2165s/iter; left time: 11660.9982s\n",
      "\titers: 500, epoch: 1 | loss: 0.0952150\n",
      "\tspeed: 0.2096s/iter; left time: 11268.8866s\n",
      "\titers: 600, epoch: 1 | loss: 0.0775518\n",
      "\tspeed: 0.2170s/iter; left time: 11644.5295s\n",
      "\titers: 700, epoch: 1 | loss: 0.0573632\n",
      "\tspeed: 0.2204s/iter; left time: 11806.5206s\n",
      "\titers: 800, epoch: 1 | loss: 0.0748523\n",
      "\tspeed: 0.2164s/iter; left time: 11569.7418s\n",
      "\titers: 900, epoch: 1 | loss: 0.0780433\n",
      "\tspeed: 0.2176s/iter; left time: 11610.3619s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0557578\n",
      "\tspeed: 0.2112s/iter; left time: 11249.8614s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0642440\n",
      "\tspeed: 0.2235s/iter; left time: 11879.6474s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0581125\n",
      "\tspeed: 0.2155s/iter; left time: 11433.7981s\n",
      "\titers: 1300, epoch: 1 | loss: 0.0653733\n",
      "\tspeed: 0.2175s/iter; left time: 11521.5568s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0488294\n",
      "\tspeed: 0.2194s/iter; left time: 11599.3987s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0503552\n",
      "\tspeed: 0.2179s/iter; left time: 11496.0640s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0823918\n",
      "\tspeed: 0.2188s/iter; left time: 11520.0131s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0652934\n",
      "\tspeed: 0.2189s/iter; left time: 11504.3949s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0500252\n",
      "\tspeed: 0.2464s/iter; left time: 12928.6646s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0572330\n",
      "\tspeed: 0.2149s/iter; left time: 11251.1869s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0619874\n",
      "\tspeed: 0.2131s/iter; left time: 11134.2435s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0681035\n",
      "\tspeed: 0.2163s/iter; left time: 11281.9667s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0608845\n",
      "\tspeed: 0.2181s/iter; left time: 11355.7731s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0644549\n",
      "\tspeed: 0.2186s/iter; left time: 11360.1216s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0775569\n",
      "\tspeed: 0.2171s/iter; left time: 11261.1064s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0627126\n",
      "\tspeed: 0.2183s/iter; left time: 11298.8666s\n",
      "\titers: 2600, epoch: 1 | loss: 0.0516025\n",
      "\tspeed: 0.2199s/iter; left time: 11358.5092s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0530432\n",
      "\tspeed: 0.2149s/iter; left time: 11082.1732s\n",
      "Epoch: 1 cost time: 00h:09m:53.36s\n",
      "Epoch: 1 | Train Loss: 0.0728902 Vali Loss: 0.0621570 Test Loss: 0.0659448\n",
      "Validation loss decreased (inf --> 0.062157).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0542284\n",
      "\tspeed: 1.9763s/iter; left time: 101676.8662s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670467\n",
      "\tspeed: 0.2129s/iter; left time: 10930.1586s\n",
      "\titers: 300, epoch: 2 | loss: 0.0648869\n",
      "\tspeed: 0.2097s/iter; left time: 10747.4073s\n",
      "\titers: 400, epoch: 2 | loss: 0.0566343\n",
      "\tspeed: 0.2138s/iter; left time: 10934.5464s\n",
      "\titers: 500, epoch: 2 | loss: 0.0552219\n",
      "\tspeed: 0.2122s/iter; left time: 10830.1725s\n",
      "\titers: 600, epoch: 2 | loss: 0.0683327\n",
      "\tspeed: 0.2102s/iter; left time: 10711.6429s\n",
      "\titers: 700, epoch: 2 | loss: 0.0712316\n",
      "\tspeed: 0.2146s/iter; left time: 10912.1678s\n",
      "\titers: 800, epoch: 2 | loss: 0.0804125\n",
      "\tspeed: 0.2081s/iter; left time: 10558.6040s\n",
      "\titers: 900, epoch: 2 | loss: 0.0530134\n",
      "\tspeed: 0.2131s/iter; left time: 10791.4381s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0582712\n",
      "\tspeed: 0.2129s/iter; left time: 10762.2762s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0622718\n",
      "\tspeed: 0.2152s/iter; left time: 10858.9148s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0549985\n",
      "\tspeed: 0.2088s/iter; left time: 10514.8254s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0656118\n",
      "\tspeed: 0.2152s/iter; left time: 10814.7492s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0517154\n",
      "\tspeed: 0.2151s/iter; left time: 10786.4496s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0427679\n",
      "\tspeed: 0.2208s/iter; left time: 11051.2654s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0651983\n",
      "\tspeed: 0.2297s/iter; left time: 11474.2805s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0515183\n",
      "\tspeed: 0.2239s/iter; left time: 11160.2922s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0569872\n",
      "\tspeed: 0.1775s/iter; left time: 8830.8806s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0680767\n",
      "\tspeed: 0.1172s/iter; left time: 5820.9757s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0464256\n",
      "\tspeed: 0.1203s/iter; left time: 5962.9559s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0640577\n",
      "\tspeed: 0.1096s/iter; left time: 5420.1528s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0648689\n",
      "\tspeed: 0.1101s/iter; left time: 5430.9392s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0449513\n",
      "\tspeed: 0.1154s/iter; left time: 5684.4578s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0613574\n",
      "\tspeed: 0.1205s/iter; left time: 5921.9085s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0518990\n",
      "\tspeed: 0.1178s/iter; left time: 5777.7689s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0474766\n",
      "\tspeed: 0.1134s/iter; left time: 5549.6701s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0680457\n",
      "\tspeed: 0.1204s/iter; left time: 5882.9410s\n",
      "Epoch: 2 cost time: 00h:08m:08.62s\n",
      "Epoch: 2 | Train Loss: 0.0595214 Vali Loss: 0.0592604 Test Loss: 0.0632206\n",
      "Validation loss decreased (0.062157 --> 0.059260).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0527481\n",
      "\tspeed: 0.9126s/iter; left time: 44477.0197s\n",
      "\titers: 200, epoch: 3 | loss: 0.0537563\n",
      "\tspeed: 0.1134s/iter; left time: 5513.0319s\n",
      "\titers: 300, epoch: 3 | loss: 0.0542177\n",
      "\tspeed: 0.1116s/iter; left time: 5414.5008s\n",
      "\titers: 400, epoch: 3 | loss: 0.0633696\n",
      "\tspeed: 0.1141s/iter; left time: 5526.7363s\n",
      "\titers: 500, epoch: 3 | loss: 0.0534021\n",
      "\tspeed: 0.1164s/iter; left time: 5628.3911s\n",
      "\titers: 600, epoch: 3 | loss: 0.0545771\n",
      "\tspeed: 0.1117s/iter; left time: 5387.5639s\n",
      "\titers: 700, epoch: 3 | loss: 0.0464762\n",
      "\tspeed: 0.1132s/iter; left time: 5447.3560s\n",
      "\titers: 800, epoch: 3 | loss: 0.0627529\n",
      "\tspeed: 0.1135s/iter; left time: 5454.2292s\n",
      "\titers: 900, epoch: 3 | loss: 0.0454887\n",
      "\tspeed: 0.1126s/iter; left time: 5399.2700s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0584920\n",
      "\tspeed: 0.1136s/iter; left time: 5433.2468s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0574579\n",
      "\tspeed: 0.1124s/iter; left time: 5367.1382s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0545672\n",
      "\tspeed: 0.1109s/iter; left time: 5284.6314s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0527900\n",
      "\tspeed: 0.1109s/iter; left time: 5269.2604s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0470590\n",
      "\tspeed: 0.1108s/iter; left time: 5257.6031s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0458568\n",
      "\tspeed: 0.1113s/iter; left time: 5267.8173s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0699025\n",
      "\tspeed: 0.1126s/iter; left time: 5319.8695s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0668973\n",
      "\tspeed: 0.1120s/iter; left time: 5280.4437s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0553001\n",
      "\tspeed: 0.1109s/iter; left time: 5217.4612s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0509166\n",
      "\tspeed: 0.1103s/iter; left time: 5177.8885s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0639876\n",
      "\tspeed: 0.1110s/iter; left time: 5198.7579s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0520401\n",
      "\tspeed: 0.1108s/iter; left time: 5180.3813s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0500856\n",
      "\tspeed: 0.1110s/iter; left time: 5174.6324s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0568108\n",
      "\tspeed: 0.1106s/iter; left time: 5148.0353s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0540239\n",
      "\tspeed: 0.1108s/iter; left time: 5145.0891s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0509569\n",
      "\tspeed: 0.1135s/iter; left time: 5259.7202s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0659207\n",
      "\tspeed: 0.1127s/iter; left time: 5209.3862s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0683112\n",
      "\tspeed: 0.1063s/iter; left time: 4903.7197s\n",
      "Epoch: 3 cost time: 00h:05m:03.89s\n",
      "Epoch: 3 | Train Loss: 0.0574231 Vali Loss: 0.0575017 Test Loss: 0.0612840\n",
      "Validation loss decreased (0.059260 --> 0.057502).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0781622\n",
      "\tspeed: 0.8711s/iter; left time: 40090.3548s\n",
      "\titers: 200, epoch: 4 | loss: 0.0560807\n",
      "\tspeed: 0.1107s/iter; left time: 5084.8653s\n",
      "\titers: 300, epoch: 4 | loss: 0.0589079\n",
      "\tspeed: 0.1110s/iter; left time: 5088.5189s\n",
      "\titers: 400, epoch: 4 | loss: 0.0561776\n",
      "\tspeed: 0.1109s/iter; left time: 5072.1553s\n",
      "\titers: 500, epoch: 4 | loss: 0.0670672\n",
      "\tspeed: 0.1109s/iter; left time: 5060.7683s\n",
      "\titers: 600, epoch: 4 | loss: 0.0503391\n",
      "\tspeed: 0.1108s/iter; left time: 5045.1517s\n",
      "\titers: 700, epoch: 4 | loss: 0.0583979\n",
      "\tspeed: 0.1086s/iter; left time: 4934.4879s\n",
      "\titers: 800, epoch: 4 | loss: 0.0665963\n",
      "\tspeed: 0.1109s/iter; left time: 5027.8037s\n",
      "\titers: 900, epoch: 4 | loss: 0.0550917\n",
      "\tspeed: 0.1113s/iter; left time: 5035.0514s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0679721\n",
      "\tspeed: 0.1109s/iter; left time: 5005.6508s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0764208\n",
      "\tspeed: 0.1055s/iter; left time: 4750.0522s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0676172\n",
      "\tspeed: 0.1108s/iter; left time: 4978.1846s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0591371\n",
      "\tspeed: 0.1112s/iter; left time: 4986.0732s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0634342\n",
      "\tspeed: 0.1111s/iter; left time: 4970.7442s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0473038\n",
      "\tspeed: 0.1107s/iter; left time: 4937.4385s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0534925\n",
      "\tspeed: 0.1112s/iter; left time: 4950.9783s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0474229\n",
      "\tspeed: 0.1067s/iter; left time: 4741.3010s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0530520\n",
      "\tspeed: 0.1068s/iter; left time: 4732.7810s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0509128\n",
      "\tspeed: 0.1109s/iter; left time: 4903.6747s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0509156\n",
      "\tspeed: 0.1108s/iter; left time: 4890.5896s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0578413\n",
      "\tspeed: 0.1106s/iter; left time: 4868.4525s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0589333\n",
      "\tspeed: 0.1087s/iter; left time: 4775.5445s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0512787\n",
      "\tspeed: 0.1015s/iter; left time: 4446.8317s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0698794\n",
      "\tspeed: 0.1109s/iter; left time: 4847.2575s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0507337\n",
      "\tspeed: 0.1109s/iter; left time: 4838.5527s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0569324\n",
      "\tspeed: 0.0999s/iter; left time: 4346.3539s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0545301\n",
      "\tspeed: 0.0927s/iter; left time: 4023.0501s\n",
      "Epoch: 4 cost time: 00h:04m:54.56s\n",
      "Epoch: 4 | Train Loss: 0.0560099 Vali Loss: 0.0569086 Test Loss: 0.0609416\n",
      "Validation loss decreased (0.057502 --> 0.056909).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0523451\n",
      "\tspeed: 0.8777s/iter; left time: 38012.3800s\n",
      "\titers: 200, epoch: 5 | loss: 0.0497674\n",
      "\tspeed: 0.0975s/iter; left time: 4212.5904s\n",
      "\titers: 300, epoch: 5 | loss: 0.0677950\n",
      "\tspeed: 0.1109s/iter; left time: 4781.1550s\n",
      "\titers: 400, epoch: 5 | loss: 0.0410538\n",
      "\tspeed: 0.1120s/iter; left time: 4815.8743s\n",
      "\titers: 500, epoch: 5 | loss: 0.0496694\n",
      "\tspeed: 0.1111s/iter; left time: 4765.1119s\n",
      "\titers: 600, epoch: 5 | loss: 0.0560091\n",
      "\tspeed: 0.1111s/iter; left time: 4755.8606s\n",
      "\titers: 700, epoch: 5 | loss: 0.0574259\n",
      "\tspeed: 0.1124s/iter; left time: 4801.1081s\n",
      "\titers: 800, epoch: 5 | loss: 0.0590554\n",
      "\tspeed: 0.1105s/iter; left time: 4708.8077s\n",
      "\titers: 900, epoch: 5 | loss: 0.0660535\n",
      "\tspeed: 0.1145s/iter; left time: 4868.1909s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0557318\n",
      "\tspeed: 0.1124s/iter; left time: 4767.0612s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0514192\n",
      "\tspeed: 0.1116s/iter; left time: 4723.3019s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0523998\n",
      "\tspeed: 0.1130s/iter; left time: 4769.8180s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0702193\n",
      "\tspeed: 0.1118s/iter; left time: 4707.0421s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0504459\n",
      "\tspeed: 0.1113s/iter; left time: 4674.5882s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0524809\n",
      "\tspeed: 0.1101s/iter; left time: 4615.0836s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0419785\n",
      "\tspeed: 0.1119s/iter; left time: 4680.0119s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0602485\n",
      "\tspeed: 0.1108s/iter; left time: 4621.6964s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0465609\n",
      "\tspeed: 0.1111s/iter; left time: 4623.7379s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0668926\n",
      "\tspeed: 0.1097s/iter; left time: 4552.4582s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0561600\n",
      "\tspeed: 0.1108s/iter; left time: 4589.6600s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0525165\n",
      "\tspeed: 0.1108s/iter; left time: 4579.0800s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0475404\n",
      "\tspeed: 0.1105s/iter; left time: 4554.0453s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0609381\n",
      "\tspeed: 0.1114s/iter; left time: 4580.1540s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0569825\n",
      "\tspeed: 0.1086s/iter; left time: 4453.6233s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0503497\n",
      "\tspeed: 0.1107s/iter; left time: 4530.4399s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0623354\n",
      "\tspeed: 0.1108s/iter; left time: 4520.5441s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0581161\n",
      "\tspeed: 0.1109s/iter; left time: 4514.2804s\n",
      "Epoch: 5 cost time: 00h:05m:00.59s\n",
      "Epoch: 5 | Train Loss: 0.0549737 Vali Loss: 0.0551702 Test Loss: 0.0595538\n",
      "Validation loss decreased (0.056909 --> 0.055170).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0640795\n",
      "\tspeed: 0.8723s/iter; left time: 35411.5024s\n",
      "\titers: 200, epoch: 6 | loss: 0.0591650\n",
      "\tspeed: 0.1109s/iter; left time: 4491.5914s\n",
      "\titers: 300, epoch: 6 | loss: 0.0403310\n",
      "\tspeed: 0.1110s/iter; left time: 4482.1664s\n",
      "\titers: 400, epoch: 6 | loss: 0.0585927\n",
      "\tspeed: 0.1109s/iter; left time: 4469.8408s\n",
      "\titers: 500, epoch: 6 | loss: 0.0706630\n",
      "\tspeed: 0.1111s/iter; left time: 4464.9878s\n",
      "\titers: 600, epoch: 6 | loss: 0.0629400\n",
      "\tspeed: 0.1113s/iter; left time: 4463.0852s\n",
      "\titers: 700, epoch: 6 | loss: 0.0465301\n",
      "\tspeed: 0.1109s/iter; left time: 4436.6538s\n",
      "\titers: 800, epoch: 6 | loss: 0.0500698\n",
      "\tspeed: 0.1108s/iter; left time: 4420.4313s\n",
      "\titers: 900, epoch: 6 | loss: 0.0374198\n",
      "\tspeed: 0.1107s/iter; left time: 4405.7459s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0572367\n",
      "\tspeed: 0.1106s/iter; left time: 4391.2228s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0585453\n",
      "\tspeed: 0.1111s/iter; left time: 4397.7238s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0552741\n",
      "\tspeed: 0.1127s/iter; left time: 4450.8512s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0588804\n",
      "\tspeed: 0.1122s/iter; left time: 4419.4419s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0558417\n",
      "\tspeed: 0.1103s/iter; left time: 4335.4584s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0464093\n",
      "\tspeed: 0.0920s/iter; left time: 3604.0767s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0549806\n",
      "\tspeed: 0.0919s/iter; left time: 3591.3316s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0530618\n",
      "\tspeed: 0.0916s/iter; left time: 3570.9643s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0517453\n",
      "\tspeed: 0.1071s/iter; left time: 4164.9926s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0441919\n",
      "\tspeed: 0.0946s/iter; left time: 3668.4081s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0632877\n",
      "\tspeed: 0.1087s/iter; left time: 4206.0688s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0537774\n",
      "\tspeed: 0.1109s/iter; left time: 4280.5467s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0450462\n",
      "\tspeed: 0.1109s/iter; left time: 4270.0751s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0424794\n",
      "\tspeed: 0.1099s/iter; left time: 4219.4955s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0694882\n",
      "\tspeed: 0.1097s/iter; left time: 4200.3325s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0587732\n",
      "\tspeed: 0.1164s/iter; left time: 4447.1646s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0412575\n",
      "\tspeed: 0.1190s/iter; left time: 4534.2713s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0436005\n",
      "\tspeed: 0.1131s/iter; left time: 4296.3140s\n",
      "Epoch: 6 cost time: 00h:04m:54.93s\n",
      "Epoch: 6 | Train Loss: 0.0540165 Vali Loss: 0.0547559 Test Loss: 0.0589155\n",
      "Validation loss decreased (0.055170 --> 0.054756).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0437865\n",
      "\tspeed: 0.8732s/iter; left time: 33080.6078s\n",
      "\titers: 200, epoch: 7 | loss: 0.0635800\n",
      "\tspeed: 0.1116s/iter; left time: 4218.1614s\n",
      "\titers: 300, epoch: 7 | loss: 0.0539604\n",
      "\tspeed: 0.1141s/iter; left time: 4299.9118s\n",
      "\titers: 400, epoch: 7 | loss: 0.0468464\n",
      "\tspeed: 0.0929s/iter; left time: 3490.7970s\n",
      "\titers: 500, epoch: 7 | loss: 0.0673882\n",
      "\tspeed: 0.1008s/iter; left time: 3776.6413s\n",
      "\titers: 600, epoch: 7 | loss: 0.0433701\n",
      "\tspeed: 0.1059s/iter; left time: 3958.2061s\n",
      "\titers: 700, epoch: 7 | loss: 0.0496241\n",
      "\tspeed: 0.1110s/iter; left time: 4139.5052s\n",
      "\titers: 800, epoch: 7 | loss: 0.0539288\n",
      "\tspeed: 0.1138s/iter; left time: 4230.7716s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559073\n",
      "\tspeed: 0.1117s/iter; left time: 4143.6135s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0429134\n",
      "\tspeed: 0.1029s/iter; left time: 3804.5203s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0474347\n",
      "\tspeed: 0.1105s/iter; left time: 4074.0083s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0658824\n",
      "\tspeed: 0.1108s/iter; left time: 4075.7753s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0500594\n",
      "\tspeed: 0.1108s/iter; left time: 4066.0631s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0414436\n",
      "\tspeed: 0.1111s/iter; left time: 4063.5314s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0401539\n",
      "\tspeed: 0.1106s/iter; left time: 4035.6196s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0647994\n",
      "\tspeed: 0.1103s/iter; left time: 4011.7274s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0431331\n",
      "\tspeed: 0.1103s/iter; left time: 4001.9119s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0427611\n",
      "\tspeed: 0.1113s/iter; left time: 4027.9339s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0491915\n",
      "\tspeed: 0.1101s/iter; left time: 3973.6753s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0504405\n",
      "\tspeed: 0.1109s/iter; left time: 3992.0200s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0658533\n",
      "\tspeed: 0.1134s/iter; left time: 4068.0596s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0528282\n",
      "\tspeed: 0.1115s/iter; left time: 3991.2717s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0440166\n",
      "\tspeed: 0.1112s/iter; left time: 3967.3699s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0523644\n",
      "\tspeed: 0.1110s/iter; left time: 3949.9050s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0418222\n",
      "\tspeed: 0.1118s/iter; left time: 3968.5076s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0577403\n",
      "\tspeed: 0.1111s/iter; left time: 3929.7766s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0498971\n",
      "\tspeed: 0.1110s/iter; left time: 3916.9036s\n",
      "Epoch: 7 cost time: 00h:04m:58.29s\n",
      "Epoch: 7 | Train Loss: 0.0532535 Vali Loss: 0.0542020 Test Loss: 0.0582736\n",
      "Validation loss decreased (0.054756 --> 0.054202).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0573966\n",
      "\tspeed: 0.8634s/iter; left time: 30364.2258s\n",
      "\titers: 200, epoch: 8 | loss: 0.0378367\n",
      "\tspeed: 0.1040s/iter; left time: 3648.3091s\n",
      "\titers: 300, epoch: 8 | loss: 0.0562231\n",
      "\tspeed: 0.1080s/iter; left time: 3777.5464s\n",
      "\titers: 400, epoch: 8 | loss: 0.0488417\n",
      "\tspeed: 0.1110s/iter; left time: 3868.8661s\n",
      "\titers: 500, epoch: 8 | loss: 0.0503265\n",
      "\tspeed: 0.1110s/iter; left time: 3857.9257s\n",
      "\titers: 600, epoch: 8 | loss: 0.0405856\n",
      "\tspeed: 0.1100s/iter; left time: 3812.7357s\n",
      "\titers: 700, epoch: 8 | loss: 0.0551430\n",
      "\tspeed: 0.1094s/iter; left time: 3782.1265s\n",
      "\titers: 800, epoch: 8 | loss: 0.0555346\n",
      "\tspeed: 0.1109s/iter; left time: 3823.3447s\n",
      "\titers: 900, epoch: 8 | loss: 0.0408218\n",
      "\tspeed: 0.1112s/iter; left time: 3821.1163s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0541077\n",
      "\tspeed: 0.1111s/iter; left time: 3807.6217s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0542165\n",
      "\tspeed: 0.1114s/iter; left time: 3805.1563s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0430974\n",
      "\tspeed: 0.1110s/iter; left time: 3782.8548s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0546644\n",
      "\tspeed: 0.1112s/iter; left time: 3777.2991s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0473207\n",
      "\tspeed: 0.1109s/iter; left time: 3757.3171s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0554659\n",
      "\tspeed: 0.1123s/iter; left time: 3792.4681s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0602234\n",
      "\tspeed: 0.1108s/iter; left time: 3731.5737s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0496314\n",
      "\tspeed: 0.1120s/iter; left time: 3758.6903s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0466059\n",
      "\tspeed: 0.1111s/iter; left time: 3716.9101s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0463335\n",
      "\tspeed: 0.1096s/iter; left time: 3659.0152s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0426725\n",
      "\tspeed: 0.1169s/iter; left time: 3887.8152s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0589549\n",
      "\tspeed: 0.1098s/iter; left time: 3643.5174s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0500997\n",
      "\tspeed: 0.1152s/iter; left time: 3809.2419s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0411206\n",
      "\tspeed: 0.1114s/iter; left time: 3672.4689s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0632741\n",
      "\tspeed: 0.1112s/iter; left time: 3653.6316s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0388545\n",
      "\tspeed: 0.1107s/iter; left time: 3628.5295s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0507245\n",
      "\tspeed: 0.1125s/iter; left time: 3674.3473s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0499838\n",
      "\tspeed: 0.1111s/iter; left time: 3618.3725s\n",
      "Epoch: 8 cost time: 00h:05m:00.22s\n",
      "Epoch: 8 | Train Loss: 0.0526945 Vali Loss: 0.0546429 Test Loss: 0.0590354\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0452876\n",
      "\tspeed: 0.8630s/iter; left time: 28009.2190s\n",
      "\titers: 200, epoch: 9 | loss: 0.0480845\n",
      "\tspeed: 0.1090s/iter; left time: 3527.0210s\n",
      "\titers: 300, epoch: 9 | loss: 0.0544482\n",
      "\tspeed: 0.0983s/iter; left time: 3170.1837s\n",
      "\titers: 400, epoch: 9 | loss: 0.0746930\n",
      "\tspeed: 0.1211s/iter; left time: 3892.7801s\n",
      "\titers: 500, epoch: 9 | loss: 0.0501334\n",
      "\tspeed: 0.1149s/iter; left time: 3683.0776s\n",
      "\titers: 600, epoch: 9 | loss: 0.0635273\n",
      "\tspeed: 0.1113s/iter; left time: 3556.1694s\n",
      "\titers: 700, epoch: 9 | loss: 0.0512731\n",
      "\tspeed: 0.1122s/iter; left time: 3574.8318s\n",
      "\titers: 800, epoch: 9 | loss: 0.0456901\n",
      "\tspeed: 0.1111s/iter; left time: 3528.5457s\n",
      "\titers: 900, epoch: 9 | loss: 0.0357962\n",
      "\tspeed: 0.1122s/iter; left time: 3553.1673s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0669423\n",
      "\tspeed: 0.1128s/iter; left time: 3558.5420s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0517661\n",
      "\tspeed: 0.1118s/iter; left time: 3517.3112s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0524863\n",
      "\tspeed: 0.1100s/iter; left time: 3449.3096s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0638670\n",
      "\tspeed: 0.1073s/iter; left time: 3353.6620s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0642590\n",
      "\tspeed: 0.0943s/iter; left time: 2938.7844s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0405757\n",
      "\tspeed: 0.0998s/iter; left time: 3100.7564s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0553760\n",
      "\tspeed: 0.0973s/iter; left time: 3012.5257s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0406495\n",
      "\tspeed: 0.1112s/iter; left time: 3432.3600s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0517201\n",
      "\tspeed: 0.1009s/iter; left time: 3102.9521s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0603963\n",
      "\tspeed: 0.1108s/iter; left time: 3397.5328s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0596839\n",
      "\tspeed: 0.1110s/iter; left time: 3391.7599s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0531674\n",
      "\tspeed: 0.1102s/iter; left time: 3356.4490s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0617280\n",
      "\tspeed: 0.1109s/iter; left time: 3365.6925s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0490168\n",
      "\tspeed: 0.1116s/iter; left time: 3378.1811s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0517670\n",
      "\tspeed: 0.1109s/iter; left time: 3345.2566s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0449308\n",
      "\tspeed: 0.1087s/iter; left time: 3267.8483s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0445644\n",
      "\tspeed: 0.1109s/iter; left time: 3322.9108s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0493163\n",
      "\tspeed: 0.1115s/iter; left time: 3329.7663s\n",
      "Epoch: 9 cost time: 00h:04m:56.99s\n",
      "Epoch: 9 | Train Loss: 0.0521549 Vali Loss: 0.0539455 Test Loss: 0.0584838\n",
      "Validation loss decreased (0.054202 --> 0.053945).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0550047\n",
      "\tspeed: 0.8691s/iter; left time: 25849.7416s\n",
      "\titers: 200, epoch: 10 | loss: 0.0475402\n",
      "\tspeed: 0.1113s/iter; left time: 3300.2138s\n",
      "\titers: 300, epoch: 10 | loss: 0.0488127\n",
      "\tspeed: 0.1006s/iter; left time: 2973.2373s\n",
      "\titers: 400, epoch: 10 | loss: 0.0480546\n",
      "\tspeed: 0.1036s/iter; left time: 3049.8281s\n",
      "\titers: 500, epoch: 10 | loss: 0.0767341\n",
      "\tspeed: 0.1104s/iter; left time: 3238.3780s\n",
      "\titers: 600, epoch: 10 | loss: 0.0561193\n",
      "\tspeed: 0.1111s/iter; left time: 3248.6235s\n",
      "\titers: 700, epoch: 10 | loss: 0.0496133\n",
      "\tspeed: 0.1162s/iter; left time: 3385.5100s\n",
      "\titers: 800, epoch: 10 | loss: 0.0508256\n",
      "\tspeed: 0.1087s/iter; left time: 3158.0448s\n",
      "\titers: 900, epoch: 10 | loss: 0.0678400\n",
      "\tspeed: 0.0973s/iter; left time: 2814.9004s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0481478\n",
      "\tspeed: 0.1092s/iter; left time: 3150.9274s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0505144\n",
      "\tspeed: 0.1108s/iter; left time: 3184.4705s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0530811\n",
      "\tspeed: 0.1109s/iter; left time: 3176.6995s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0448338\n",
      "\tspeed: 0.1108s/iter; left time: 3163.7812s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0473159\n",
      "\tspeed: 0.1107s/iter; left time: 3147.4913s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0576004\n",
      "\tspeed: 0.0971s/iter; left time: 2751.7864s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0600859\n",
      "\tspeed: 0.1013s/iter; left time: 2861.9520s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0436083\n",
      "\tspeed: 0.0987s/iter; left time: 2777.3876s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0549228\n",
      "\tspeed: 0.1029s/iter; left time: 2884.3842s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0522889\n",
      "\tspeed: 0.1073s/iter; left time: 2998.3941s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0441791\n",
      "\tspeed: 0.1093s/iter; left time: 3044.3099s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0370428\n",
      "\tspeed: 0.1109s/iter; left time: 3075.9128s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0543491\n",
      "\tspeed: 0.1113s/iter; left time: 3077.7975s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0456150\n",
      "\tspeed: 0.1103s/iter; left time: 3037.9881s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0533350\n",
      "\tspeed: 0.1089s/iter; left time: 2989.9881s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0417818\n",
      "\tspeed: 0.1108s/iter; left time: 3029.9698s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0665143\n",
      "\tspeed: 0.1110s/iter; left time: 3024.7915s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0492287\n",
      "\tspeed: 0.1035s/iter; left time: 2808.0645s\n",
      "Epoch: 10 cost time: 00h:04m:52.37s\n",
      "Epoch: 10 | Train Loss: 0.0517371 Vali Loss: 0.0541538 Test Loss: 0.0582333\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0495415\n",
      "\tspeed: 0.8515s/iter; left time: 23018.2442s\n",
      "\titers: 200, epoch: 11 | loss: 0.0639661\n",
      "\tspeed: 0.1117s/iter; left time: 3009.5320s\n",
      "\titers: 300, epoch: 11 | loss: 0.0394840\n",
      "\tspeed: 0.1106s/iter; left time: 2966.7132s\n",
      "\titers: 400, epoch: 11 | loss: 0.0479258\n",
      "\tspeed: 0.1092s/iter; left time: 2918.7301s\n",
      "\titers: 500, epoch: 11 | loss: 0.0605572\n",
      "\tspeed: 0.1149s/iter; left time: 3058.6292s\n",
      "\titers: 600, epoch: 11 | loss: 0.0410986\n",
      "\tspeed: 0.1112s/iter; left time: 2949.0238s\n",
      "\titers: 700, epoch: 11 | loss: 0.0496964\n",
      "\tspeed: 0.1080s/iter; left time: 2855.5384s\n",
      "\titers: 800, epoch: 11 | loss: 0.0561572\n",
      "\tspeed: 0.1113s/iter; left time: 2929.8883s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498041\n",
      "\tspeed: 0.1088s/iter; left time: 2854.9491s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0640917\n",
      "\tspeed: 0.1057s/iter; left time: 2760.9851s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0404759\n",
      "\tspeed: 0.1110s/iter; left time: 2888.3340s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0475856\n",
      "\tspeed: 0.1110s/iter; left time: 2878.4555s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0453046\n",
      "\tspeed: 0.1109s/iter; left time: 2865.0192s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0415090\n",
      "\tspeed: 0.1073s/iter; left time: 2760.5301s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0474752\n",
      "\tspeed: 0.0922s/iter; left time: 2363.4676s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.0920s/iter; left time: 2349.3287s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0548703\n",
      "\tspeed: 0.1100s/iter; left time: 2798.2253s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0471928\n",
      "\tspeed: 0.1082s/iter; left time: 2742.0046s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0565440\n",
      "\tspeed: 0.1108s/iter; left time: 2796.1183s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0390263\n",
      "\tspeed: 0.1108s/iter; left time: 2785.2885s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0482574\n",
      "\tspeed: 0.1108s/iter; left time: 2773.4576s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0472797\n",
      "\tspeed: 0.1110s/iter; left time: 2768.3178s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0409271\n",
      "\tspeed: 0.1106s/iter; left time: 2747.0768s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0562022\n",
      "\tspeed: 0.1111s/iter; left time: 2747.8697s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0520623\n",
      "\tspeed: 0.1109s/iter; left time: 2732.2817s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0492270\n",
      "\tspeed: 0.1100s/iter; left time: 2698.9633s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0518520\n",
      "\tspeed: 0.0993s/iter; left time: 2425.2742s\n",
      "Epoch: 11 cost time: 00h:04m:54.75s\n",
      "Epoch: 11 | Train Loss: 0.0514131 Vali Loss: 0.0529610 Test Loss: 0.0576995\n",
      "Validation loss decreased (0.053945 --> 0.052961).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0502807\n",
      "\tspeed: 0.8793s/iter; left time: 21383.9051s\n",
      "\titers: 200, epoch: 12 | loss: 0.0557354\n",
      "\tspeed: 0.1103s/iter; left time: 2670.9648s\n",
      "\titers: 300, epoch: 12 | loss: 0.0386777\n",
      "\tspeed: 0.1117s/iter; left time: 2692.8731s\n",
      "\titers: 400, epoch: 12 | loss: 0.0553932\n",
      "\tspeed: 0.1113s/iter; left time: 2673.9663s\n",
      "\titers: 500, epoch: 12 | loss: 0.0378364\n",
      "\tspeed: 0.1105s/iter; left time: 2641.8863s\n",
      "\titers: 600, epoch: 12 | loss: 0.0540264\n",
      "\tspeed: 0.1108s/iter; left time: 2637.9407s\n",
      "\titers: 700, epoch: 12 | loss: 0.0621938\n",
      "\tspeed: 0.1113s/iter; left time: 2640.2477s\n",
      "\titers: 800, epoch: 12 | loss: 0.0448379\n",
      "\tspeed: 0.1006s/iter; left time: 2376.3520s\n",
      "\titers: 900, epoch: 12 | loss: 0.0561696\n",
      "\tspeed: 0.1017s/iter; left time: 2390.7340s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0486420\n",
      "\tspeed: 0.1112s/iter; left time: 2604.8591s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0610481\n",
      "\tspeed: 0.1111s/iter; left time: 2590.6774s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0372218\n",
      "\tspeed: 0.1103s/iter; left time: 2560.5024s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0546993\n",
      "\tspeed: 0.1042s/iter; left time: 2408.9068s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0634329\n",
      "\tspeed: 0.1112s/iter; left time: 2559.1929s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0394930\n",
      "\tspeed: 0.1100s/iter; left time: 2521.6488s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0403461\n",
      "\tspeed: 0.1096s/iter; left time: 2499.9424s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0504131\n",
      "\tspeed: 0.1125s/iter; left time: 2556.8536s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0509365\n",
      "\tspeed: 0.1131s/iter; left time: 2558.9853s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0800472\n",
      "\tspeed: 0.1168s/iter; left time: 2630.6880s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0498694\n",
      "\tspeed: 0.1160s/iter; left time: 2601.0468s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0703021\n",
      "\tspeed: 0.1112s/iter; left time: 2482.2008s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0438494\n",
      "\tspeed: 0.1121s/iter; left time: 2490.2222s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0436303\n",
      "\tspeed: 0.1116s/iter; left time: 2469.4104s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0613145\n",
      "\tspeed: 0.1115s/iter; left time: 2454.6683s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0408842\n",
      "\tspeed: 0.1117s/iter; left time: 2447.5488s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0455322\n",
      "\tspeed: 0.1105s/iter; left time: 2411.1669s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0498312\n",
      "\tspeed: 0.1122s/iter; left time: 2437.1576s\n",
      "Epoch: 12 cost time: 00h:05m:00.88s\n",
      "Epoch: 12 | Train Loss: 0.0509285 Vali Loss: 0.0533803 Test Loss: 0.0574770\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0473562\n",
      "\tspeed: 0.8597s/iter; left time: 18573.7778s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477646\n",
      "\tspeed: 0.1085s/iter; left time: 2332.9936s\n",
      "\titers: 300, epoch: 13 | loss: 0.0395454\n",
      "\tspeed: 0.1093s/iter; left time: 2339.3833s\n",
      "\titers: 400, epoch: 13 | loss: 0.0617377\n",
      "\tspeed: 0.1108s/iter; left time: 2360.9677s\n",
      "\titers: 500, epoch: 13 | loss: 0.0466661\n",
      "\tspeed: 0.1054s/iter; left time: 2234.4629s\n",
      "\titers: 600, epoch: 13 | loss: 0.0459740\n",
      "\tspeed: 0.0979s/iter; left time: 2065.1549s\n",
      "\titers: 700, epoch: 13 | loss: 0.0358780\n",
      "\tspeed: 0.1123s/iter; left time: 2357.8114s\n",
      "\titers: 800, epoch: 13 | loss: 0.0430494\n",
      "\tspeed: 0.1141s/iter; left time: 2386.0767s\n",
      "\titers: 900, epoch: 13 | loss: 0.0609718\n",
      "\tspeed: 0.0989s/iter; left time: 2058.1199s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0560533\n",
      "\tspeed: 0.1058s/iter; left time: 2189.6659s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0503981\n",
      "\tspeed: 0.1194s/iter; left time: 2459.3231s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0347893\n",
      "\tspeed: 0.1109s/iter; left time: 2273.8329s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0692828\n",
      "\tspeed: 0.1128s/iter; left time: 2302.1376s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0522809\n",
      "\tspeed: 0.1143s/iter; left time: 2321.6722s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0531173\n",
      "\tspeed: 0.1140s/iter; left time: 2302.8581s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0422813\n",
      "\tspeed: 0.1124s/iter; left time: 2259.9099s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0572872\n",
      "\tspeed: 0.0963s/iter; left time: 1926.2239s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0473013\n",
      "\tspeed: 0.1106s/iter; left time: 2202.2611s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0517932\n",
      "\tspeed: 0.1081s/iter; left time: 2140.0021s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0525181\n",
      "\tspeed: 0.1113s/iter; left time: 2193.2804s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0514347\n",
      "\tspeed: 0.1112s/iter; left time: 2180.1385s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0526717\n",
      "\tspeed: 0.1083s/iter; left time: 2111.4213s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0463375\n",
      "\tspeed: 0.0924s/iter; left time: 1792.1440s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0481802\n",
      "\tspeed: 0.0991s/iter; left time: 1913.2725s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0474825\n",
      "\tspeed: 0.1099s/iter; left time: 2110.2834s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0461329\n",
      "\tspeed: 0.1136s/iter; left time: 2171.2802s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0459378\n",
      "\tspeed: 0.1121s/iter; left time: 2130.8006s\n",
      "Epoch: 13 cost time: 00h:04m:55.10s\n",
      "Epoch: 13 | Train Loss: 0.0506729 Vali Loss: 0.0530220 Test Loss: 0.0578316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0657005\n",
      "\tspeed: 0.8604s/iter; left time: 16255.3232s\n",
      "\titers: 200, epoch: 14 | loss: 0.0501025\n",
      "\tspeed: 0.1067s/iter; left time: 2004.9801s\n",
      "\titers: 300, epoch: 14 | loss: 0.0531937\n",
      "\tspeed: 0.1111s/iter; left time: 2077.1341s\n",
      "\titers: 400, epoch: 14 | loss: 0.0399528\n",
      "\tspeed: 0.1098s/iter; left time: 2041.9739s\n",
      "\titers: 500, epoch: 14 | loss: 0.0502588\n",
      "\tspeed: 0.1046s/iter; left time: 1933.7942s\n",
      "\titers: 600, epoch: 14 | loss: 0.0481835\n",
      "\tspeed: 0.1104s/iter; left time: 2030.9015s\n",
      "\titers: 700, epoch: 14 | loss: 0.0441985\n",
      "\tspeed: 0.1103s/iter; left time: 2016.8780s\n",
      "\titers: 800, epoch: 14 | loss: 0.0487092\n",
      "\tspeed: 0.1111s/iter; left time: 2021.3647s\n",
      "\titers: 900, epoch: 14 | loss: 0.0387260\n",
      "\tspeed: 0.1098s/iter; left time: 1985.8162s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0497734\n",
      "\tspeed: 0.1100s/iter; left time: 1978.9188s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0448196\n",
      "\tspeed: 0.1107s/iter; left time: 1981.1092s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0617918\n",
      "\tspeed: 0.1103s/iter; left time: 1962.8256s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0521033\n",
      "\tspeed: 0.1101s/iter; left time: 1947.4503s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0631672\n",
      "\tspeed: 0.1109s/iter; left time: 1951.2630s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0497660\n",
      "\tspeed: 0.1122s/iter; left time: 1961.8106s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0527748\n",
      "\tspeed: 0.1107s/iter; left time: 1925.8647s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0401833\n",
      "\tspeed: 0.1110s/iter; left time: 1918.8484s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0646718\n",
      "\tspeed: 0.1112s/iter; left time: 1911.1005s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0461747\n",
      "\tspeed: 0.1107s/iter; left time: 1891.3522s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0555299\n",
      "\tspeed: 0.1116s/iter; left time: 1895.6192s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0489289\n",
      "\tspeed: 0.1136s/iter; left time: 1918.3147s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0530368\n",
      "\tspeed: 0.1094s/iter; left time: 1836.4552s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0565491\n",
      "\tspeed: 0.1111s/iter; left time: 1855.1287s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0374595\n",
      "\tspeed: 0.1118s/iter; left time: 1854.2880s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0439480\n",
      "\tspeed: 0.1013s/iter; left time: 1671.3710s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0447525\n",
      "\tspeed: 0.1073s/iter; left time: 1758.9126s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0427074\n",
      "\tspeed: 0.1116s/iter; left time: 1818.2851s\n",
      "Epoch: 14 cost time: 00h:04m:58.93s\n",
      "Epoch: 14 | Train Loss: 0.0503469 Vali Loss: 0.0530163 Test Loss: 0.0572603\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0475976\n",
      "\tspeed: 0.8541s/iter; left time: 13817.9009s\n",
      "\titers: 200, epoch: 15 | loss: 0.0496813\n",
      "\tspeed: 0.1110s/iter; left time: 1784.1637s\n",
      "\titers: 300, epoch: 15 | loss: 0.0528194\n",
      "\tspeed: 0.1109s/iter; left time: 1771.9485s\n",
      "\titers: 400, epoch: 15 | loss: 0.0485182\n",
      "\tspeed: 0.1087s/iter; left time: 1725.2785s\n",
      "\titers: 500, epoch: 15 | loss: 0.0504476\n",
      "\tspeed: 0.1106s/iter; left time: 1745.6386s\n",
      "\titers: 600, epoch: 15 | loss: 0.0500270\n",
      "\tspeed: 0.1110s/iter; left time: 1739.8569s\n",
      "\titers: 700, epoch: 15 | loss: 0.0390998\n",
      "\tspeed: 0.1094s/iter; left time: 1703.9590s\n",
      "\titers: 800, epoch: 15 | loss: 0.0446774\n",
      "\tspeed: 0.1151s/iter; left time: 1781.3298s\n",
      "\titers: 900, epoch: 15 | loss: 0.0552191\n",
      "\tspeed: 0.0959s/iter; left time: 1474.3858s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0480956\n",
      "\tspeed: 0.1087s/iter; left time: 1660.5388s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0563352\n",
      "\tspeed: 0.1128s/iter; left time: 1712.8594s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0470802\n",
      "\tspeed: 0.1119s/iter; left time: 1687.2466s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0426255\n",
      "\tspeed: 0.1097s/iter; left time: 1643.6709s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0568796\n",
      "\tspeed: 0.1034s/iter; left time: 1538.3449s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0468034\n",
      "\tspeed: 0.1121s/iter; left time: 1656.0991s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0503813\n",
      "\tspeed: 0.1108s/iter; left time: 1627.0735s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0526259\n",
      "\tspeed: 0.1091s/iter; left time: 1591.0966s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0433962\n",
      "\tspeed: 0.1117s/iter; left time: 1616.6072s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0518279\n",
      "\tspeed: 0.1147s/iter; left time: 1648.6857s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0688984\n",
      "\tspeed: 0.1112s/iter; left time: 1588.1804s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0473993\n",
      "\tspeed: 0.1085s/iter; left time: 1538.9757s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0679344\n",
      "\tspeed: 0.1111s/iter; left time: 1564.3941s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0412253\n",
      "\tspeed: 0.1016s/iter; left time: 1419.9045s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0508351\n",
      "\tspeed: 0.1015s/iter; left time: 1408.6068s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0516523\n",
      "\tspeed: 0.1049s/iter; left time: 1445.4169s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0560802\n",
      "\tspeed: 0.1078s/iter; left time: 1474.0408s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0496466\n",
      "\tspeed: 0.1116s/iter; left time: 1515.4885s\n",
      "Epoch: 15 cost time: 00h:04m:56.53s\n",
      "Epoch: 15 | Train Loss: 0.0501232 Vali Loss: 0.0528784 Test Loss: 0.0574421\n",
      "Validation loss decreased (0.052961 --> 0.052878).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0592056\n",
      "\tspeed: 0.8749s/iter; left time: 11781.1020s\n",
      "\titers: 200, epoch: 16 | loss: 0.0455804\n",
      "\tspeed: 0.1054s/iter; left time: 1408.4864s\n",
      "\titers: 300, epoch: 16 | loss: 0.0491524\n",
      "\tspeed: 0.1094s/iter; left time: 1451.3334s\n",
      "\titers: 400, epoch: 16 | loss: 0.0579208\n",
      "\tspeed: 0.1082s/iter; left time: 1425.0621s\n",
      "\titers: 500, epoch: 16 | loss: 0.0550992\n",
      "\tspeed: 0.1103s/iter; left time: 1441.3789s\n",
      "\titers: 600, epoch: 16 | loss: 0.0417632\n",
      "\tspeed: 0.1114s/iter; left time: 1444.8547s\n",
      "\titers: 700, epoch: 16 | loss: 0.0493300\n",
      "\tspeed: 0.1065s/iter; left time: 1370.1581s\n",
      "\titers: 800, epoch: 16 | loss: 0.0447646\n",
      "\tspeed: 0.1160s/iter; left time: 1480.8508s\n",
      "\titers: 900, epoch: 16 | loss: 0.0361148\n",
      "\tspeed: 0.1122s/iter; left time: 1421.0364s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0575270\n",
      "\tspeed: 0.1102s/iter; left time: 1384.5336s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0508707\n",
      "\tspeed: 0.1096s/iter; left time: 1366.6071s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0627444\n",
      "\tspeed: 0.1133s/iter; left time: 1401.5158s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0539518\n",
      "\tspeed: 0.1071s/iter; left time: 1313.9729s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0662120\n",
      "\tspeed: 0.1080s/iter; left time: 1314.2608s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0524773\n",
      "\tspeed: 0.1109s/iter; left time: 1338.0411s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0491869\n",
      "\tspeed: 0.1111s/iter; left time: 1329.1983s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0545447\n",
      "\tspeed: 0.1090s/iter; left time: 1293.1612s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0401777\n",
      "\tspeed: 0.1111s/iter; left time: 1307.3868s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0377282\n",
      "\tspeed: 0.1116s/iter; left time: 1301.8086s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0500316\n",
      "\tspeed: 0.1113s/iter; left time: 1287.7644s\n",
      "\titers: 2100, epoch: 16 | loss: 0.0506953\n",
      "\tspeed: 0.1103s/iter; left time: 1264.5487s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0641350\n",
      "\tspeed: 0.1115s/iter; left time: 1266.9830s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0503439\n",
      "\tspeed: 0.1104s/iter; left time: 1243.8813s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0517973\n",
      "\tspeed: 0.1098s/iter; left time: 1225.8960s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0474104\n",
      "\tspeed: 0.1106s/iter; left time: 1223.4268s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0474249\n",
      "\tspeed: 0.0971s/iter; left time: 1064.5909s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0513577\n",
      "\tspeed: 0.1095s/iter; left time: 1190.2843s\n",
      "Epoch: 16 cost time: 00h:04m:57.95s\n",
      "Epoch: 16 | Train Loss: 0.0498373 Vali Loss: 0.0525651 Test Loss: 0.0572174\n",
      "Validation loss decreased (0.052878 --> 0.052565).  Saving model ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/./Time-LLM/run_main.py\", line 274, in <module>\n",
      "    early_stopping(vali_loss, model, path)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/Time-LLM/utils/tools.py\", line 85, in __call__\n",
      "    self.save_checkpoint(val_loss, model, path)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/Time-LLM/utils/tools.py\", line 99, in save_checkpoint\n",
      "    torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/serialization.py\", line 628, in save\n",
      "    with _open_zipfile_writer(f) as opened_zipfile:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/serialization.py\", line 502, in _open_zipfile_writer\n",
      "    return container(name_or_buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/serialization.py\", line 473, in __init__\n",
      "    super().__init__(torch._C.PyTorchFileWriter(self.name))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Parent directory ./checkpoints/long_term_forecast_1_TimeLLM_FR_ftM_sl168_ll48_pl24_dm16_nh8_el2_dl1_df64_fc3_ebtimeF_Exp_0-TimeLLM+FR does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1067, in <module>\n",
      "    main()\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1063, in main\n",
      "    launch_command(args)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 1057, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 673, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/bin/python', './Time-LLM/run_main.py', '--task_name', 'long_term_forecast', '--is_training', '1', '--root_path', './datasets/', '--data_path', 'FR_data.csv', '--model_id', '1', '--model', 'TimeLLM', '--data', 'FR', '--features', 'M', '--seq_len', '168', '--pred_len', '24', '--factor', '3', '--enc_in', '3', '--c_out', '3', '--des', 'Exp', '--itr', '1', '--d_model', '16', '--d_ff', '64', '--batch_size', '32', '--learning_rate', '0.001', '--llm_model', 'GPT2', '--llm_dim', '768', '--llm_layers', '12', '--train_epochs', '20', '--patience', '5', '--model_comment', 'TimeLLM+FR']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected at least 1 iterations, but found only 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m process\u001b[38;5;241m.\u001b[39mwait()  \u001b[38;5;66;03m# Wait for process to finish\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Extract metrics for each iteration\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m iteration_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mextract_metrics_from_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     64\u001b[0m mse, rmse, mae, _ \u001b[38;5;241m=\u001b[39m iteration_metrics\n\u001b[1;32m     65\u001b[0m timellm_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m: country,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred_len\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_len,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: mae\n\u001b[1;32m     71\u001b[0m     })\n",
      "File \u001b[0;32m~/my_work/utils/helper.py:177\u001b[0m, in \u001b[0;36mextract_metrics_from_output\u001b[0;34m(output, itr, if_scaled, if_supervised)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Throw an error if there are not enough matches\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches) \u001b[38;5;241m<\u001b[39m itr:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iterations, but found only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(matches)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# List with tuples of metrics for all iterations\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Map string matches to floats\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, match)) \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches[:itr]]\n",
      "\u001b[0;31mValueError\u001b[0m: Expected at least 1 iterations, but found only 0."
     ]
    }
   ],
   "source": [
    "# DE 24 mae:0.09314965456724167\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2068</td>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.0620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0227  0.1508  0.0954\n",
       "        96        0.0358  0.1892  0.1282\n",
       "        168       0.0377  0.1941  0.1336\n",
       "GB      24        0.0256  0.1599  0.1040\n",
       "        96        0.0420  0.2049  0.1405\n",
       "        168       0.0428  0.2068  0.1438\n",
       "ES      24        0.0107  0.1033  0.0665\n",
       "        96        0.0209  0.1445  0.0956\n",
       "        168       0.0211  0.1454  0.0968\n",
       "FR      24        0.0111  0.1052  0.0600\n",
       "        96        0.0185  0.1359  0.0817\n",
       "        168       0.0204  0.1428  0.0872\n",
       "IT      24        0.0108  0.1038  0.0620\n",
       "        96        0.0198  0.1406  0.0868\n",
       "        168       0.0198  0.1406  0.0889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(timellm_results, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/48'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_48.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TimeLLM 336\n",
    "\n",
    "Sequence length 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "model = \"TimeLLM\"\n",
    "seq_len = 96\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_96.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 00:58:33,801] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 00:58:34,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 00:58:34,957] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 00:58:34,959] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 00:58:35,302] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.98 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,463] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.95 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,464] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 00:58:35,595] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.89 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4f91ff2f50>\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1823448\n",
      "\tspeed: 0.1567s/iter; left time: 14192.7792s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593933\n",
      "\tspeed: 0.1131s/iter; left time: 10230.2692s\n",
      "\titers: 300, epoch: 1 | loss: 0.1570632\n",
      "\tspeed: 0.1123s/iter; left time: 10143.7090s\n",
      "\titers: 400, epoch: 1 | loss: 0.1664988\n",
      "\tspeed: 0.1087s/iter; left time: 9810.8326s\n",
      "\titers: 500, epoch: 1 | loss: 0.1712038\n",
      "\tspeed: 0.1117s/iter; left time: 10073.0936s\n",
      "\titers: 600, epoch: 1 | loss: 0.1680950\n",
      "\tspeed: 0.1105s/iter; left time: 9953.8048s\n",
      "\titers: 700, epoch: 1 | loss: 0.1328567\n",
      "\tspeed: 0.1077s/iter; left time: 9689.5208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485084\n",
      "\tspeed: 0.1072s/iter; left time: 9629.3103s\n",
      "\titers: 900, epoch: 1 | loss: 0.1505876\n",
      "\tspeed: 0.1104s/iter; left time: 9911.4520s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1391718\n",
      "\tspeed: 0.1091s/iter; left time: 9781.6024s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1510044\n",
      "\tspeed: 0.1108s/iter; left time: 9927.7978s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1176484\n",
      "\tspeed: 0.1098s/iter; left time: 9823.3877s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1278661\n",
      "\tspeed: 0.1088s/iter; left time: 9724.8452s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1284621\n",
      "\tspeed: 0.1094s/iter; left time: 9765.7738s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0933571\n",
      "\tspeed: 0.1088s/iter; left time: 9698.9234s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1202643\n",
      "\tspeed: 0.1071s/iter; left time: 9540.1155s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1062317\n",
      "\tspeed: 0.1088s/iter; left time: 9675.7239s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0913426\n",
      "\tspeed: 0.1079s/iter; left time: 9585.7625s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0931644\n",
      "\tspeed: 0.1107s/iter; left time: 9829.9579s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0901813\n",
      "\tspeed: 0.1073s/iter; left time: 9512.1458s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0864648\n",
      "\tspeed: 0.1096s/iter; left time: 9701.9117s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0947707\n",
      "\tspeed: 0.1096s/iter; left time: 9691.2401s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1199264\n",
      "\tspeed: 0.1075s/iter; left time: 9494.6664s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1026568\n",
      "\tspeed: 0.1078s/iter; left time: 9513.9813s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1165116\n",
      "\tspeed: 0.1107s/iter; left time: 9763.0537s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1033131\n",
      "\tspeed: 0.1088s/iter; left time: 9581.6819s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0916886\n",
      "\tspeed: 0.1100s/iter; left time: 9677.2541s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0883022\n",
      "\tspeed: 0.1102s/iter; left time: 9683.9716s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1323129\n",
      "\tspeed: 0.1111s/iter; left time: 9754.3916s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1020587\n",
      "\tspeed: 0.1093s/iter; left time: 9583.4643s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0923530\n",
      "\tspeed: 0.1135s/iter; left time: 9937.2899s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0844439\n",
      "\tspeed: 0.1075s/iter; left time: 9399.6741s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1020005\n",
      "\tspeed: 0.1104s/iter; left time: 9643.9181s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1202909\n",
      "\tspeed: 0.1069s/iter; left time: 9329.4238s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0919176\n",
      "\tspeed: 0.1082s/iter; left time: 9429.4043s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1073375\n",
      "\tspeed: 0.1110s/iter; left time: 9664.3999s\n",
      "\titers: 3700, epoch: 1 | loss: 0.1052466\n",
      "\tspeed: 0.1101s/iter; left time: 9572.9709s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0875165\n",
      "\tspeed: 0.1063s/iter; left time: 9235.6391s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0930548\n",
      "\tspeed: 0.1081s/iter; left time: 9381.0162s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1260701\n",
      "\tspeed: 0.1123s/iter; left time: 9732.7146s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0895162\n",
      "\tspeed: 0.1114s/iter; left time: 9639.0711s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1139867\n",
      "\tspeed: 0.1107s/iter; left time: 9573.0378s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1168468\n",
      "\tspeed: 0.1118s/iter; left time: 9658.4796s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0850648\n",
      "\tspeed: 0.1137s/iter; left time: 9805.3898s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0921275\n",
      "\tspeed: 0.1121s/iter; left time: 9662.0191s\n",
      "Epoch: 1 cost time: 00h:08m:20.08s\n",
      "Epoch: 1 | Train Loss: 0.1182731 Vali Loss: 0.1048069 Test Loss: 0.1061743\n",
      "Validation loss decreased (inf --> 0.104807).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0926168\n",
      "\tspeed: 1.6075s/iter; left time: 138286.9299s\n",
      "\titers: 200, epoch: 2 | loss: 0.1175821\n",
      "\tspeed: 0.1018s/iter; left time: 8748.6040s\n",
      "\titers: 300, epoch: 2 | loss: 0.0875412\n",
      "\tspeed: 0.1005s/iter; left time: 8629.0758s\n",
      "\titers: 400, epoch: 2 | loss: 0.1002984\n",
      "\tspeed: 0.1016s/iter; left time: 8710.4225s\n",
      "\titers: 500, epoch: 2 | loss: 0.0936466\n",
      "\tspeed: 0.1012s/iter; left time: 8669.1776s\n",
      "\titers: 600, epoch: 2 | loss: 0.0745555\n",
      "\tspeed: 0.0958s/iter; left time: 8195.4123s\n",
      "\titers: 700, epoch: 2 | loss: 0.0955112\n",
      "\tspeed: 0.0995s/iter; left time: 8501.9022s\n",
      "\titers: 800, epoch: 2 | loss: 0.1059108\n",
      "\tspeed: 0.0966s/iter; left time: 8244.1258s\n",
      "\titers: 900, epoch: 2 | loss: 0.0846592\n",
      "\tspeed: 0.1003s/iter; left time: 8547.7261s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0743872\n",
      "\tspeed: 0.0997s/iter; left time: 8488.8023s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0877253\n",
      "\tspeed: 0.0973s/iter; left time: 8271.2659s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0847517\n",
      "\tspeed: 0.0982s/iter; left time: 8340.2651s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1021993\n",
      "\tspeed: 0.1003s/iter; left time: 8505.3193s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0897969\n",
      "\tspeed: 0.0983s/iter; left time: 8325.4910s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0716018\n",
      "\tspeed: 0.0987s/iter; left time: 8354.8012s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0807362\n",
      "\tspeed: 0.0984s/iter; left time: 8316.4733s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0934259\n",
      "\tspeed: 0.0973s/iter; left time: 8218.7837s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1289299\n",
      "\tspeed: 0.0973s/iter; left time: 8203.3695s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0885335\n",
      "\tspeed: 0.1022s/iter; left time: 8611.4285s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0812071\n",
      "\tspeed: 0.0986s/iter; left time: 8295.3380s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1080786\n",
      "\tspeed: 0.0976s/iter; left time: 8203.2712s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0983471\n",
      "\tspeed: 0.0973s/iter; left time: 8164.1360s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1013250\n",
      "\tspeed: 0.0968s/iter; left time: 8113.0099s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0806270\n",
      "\tspeed: 0.0995s/iter; left time: 8332.9754s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0910785\n",
      "\tspeed: 0.0975s/iter; left time: 8151.0682s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0853698\n",
      "\tspeed: 0.0976s/iter; left time: 8155.8282s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1056066\n",
      "\tspeed: 0.0991s/iter; left time: 8266.5479s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0951345\n",
      "\tspeed: 0.0963s/iter; left time: 8023.7844s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0933933\n",
      "\tspeed: 0.0973s/iter; left time: 8098.5418s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0762453\n",
      "\tspeed: 0.1005s/iter; left time: 8355.5888s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0909215\n",
      "\tspeed: 0.0980s/iter; left time: 8139.8000s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0976593\n",
      "\tspeed: 0.0974s/iter; left time: 8073.2693s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0855530\n",
      "\tspeed: 0.1000s/iter; left time: 8280.0740s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0961046\n",
      "\tspeed: 0.0976s/iter; left time: 8076.5088s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0753835\n",
      "\tspeed: 0.0985s/iter; left time: 8134.7859s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0882990\n",
      "\tspeed: 0.1015s/iter; left time: 8377.4895s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1059739\n",
      "\tspeed: 0.0999s/iter; left time: 8234.1388s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0958683\n",
      "\tspeed: 0.1041s/iter; left time: 8569.3236s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1044519\n",
      "\tspeed: 0.0973s/iter; left time: 8001.3171s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0814047\n",
      "\tspeed: 0.0980s/iter; left time: 8044.6382s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0822755\n",
      "\tspeed: 0.0988s/iter; left time: 8107.3554s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0739301\n",
      "\tspeed: 0.1024s/iter; left time: 8386.1515s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0980485\n",
      "\tspeed: 0.0992s/iter; left time: 8113.6176s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0897213\n",
      "\tspeed: 0.0942s/iter; left time: 7698.5429s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0883879\n",
      "\tspeed: 0.0945s/iter; left time: 7714.3174s\n",
      "Epoch: 2 cost time: 00h:07m:28.46s\n",
      "Epoch: 2 | Train Loss: 0.0958203 Vali Loss: 0.1006848 Test Loss: 0.1015933\n",
      "Validation loss decreased (0.104807 --> 0.100685).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0841110\n",
      "\tspeed: 1.3316s/iter; left time: 108517.9794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0894022\n",
      "\tspeed: 0.0979s/iter; left time: 7966.0863s\n",
      "\titers: 300, epoch: 3 | loss: 0.0833011\n",
      "\tspeed: 0.0978s/iter; left time: 7952.1508s\n",
      "\titers: 400, epoch: 3 | loss: 0.0866618\n",
      "\tspeed: 0.1017s/iter; left time: 8256.6719s\n",
      "\titers: 500, epoch: 3 | loss: 0.0953845\n",
      "\tspeed: 0.0981s/iter; left time: 7958.0230s\n",
      "\titers: 600, epoch: 3 | loss: 0.0896195\n",
      "\tspeed: 0.0974s/iter; left time: 7890.0073s\n",
      "\titers: 700, epoch: 3 | loss: 0.0734763\n",
      "\tspeed: 0.0993s/iter; left time: 8030.9663s\n",
      "\titers: 800, epoch: 3 | loss: 0.0991940\n",
      "\tspeed: 0.0988s/iter; left time: 7981.8519s\n",
      "\titers: 900, epoch: 3 | loss: 0.0878340\n",
      "\tspeed: 0.0974s/iter; left time: 7860.7648s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0929727\n",
      "\tspeed: 0.0971s/iter; left time: 7827.2904s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0975781\n",
      "\tspeed: 0.1043s/iter; left time: 8397.7573s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0862777\n",
      "\tspeed: 0.0984s/iter; left time: 7912.0126s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0819142\n",
      "\tspeed: 0.0976s/iter; left time: 7832.9259s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1080137\n",
      "\tspeed: 0.0992s/iter; left time: 7952.3061s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0914959\n",
      "\tspeed: 0.1000s/iter; left time: 8009.8340s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0939515\n",
      "\tspeed: 0.1009s/iter; left time: 8070.1451s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0999542\n",
      "\tspeed: 0.1011s/iter; left time: 8080.9149s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0778705\n",
      "\tspeed: 0.0950s/iter; left time: 7580.1028s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0989400\n",
      "\tspeed: 0.1046s/iter; left time: 8337.3815s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1245918\n",
      "\tspeed: 0.0985s/iter; left time: 7841.9201s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0766051\n",
      "\tspeed: 0.1012s/iter; left time: 8047.8288s\n",
      "\titers: 2200, epoch: 3 | loss: 0.1048279\n",
      "\tspeed: 0.0952s/iter; left time: 7560.7894s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1057464\n",
      "\tspeed: 0.0947s/iter; left time: 7509.9755s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0974280\n",
      "\tspeed: 0.0962s/iter; left time: 7619.2757s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0859704\n",
      "\tspeed: 0.0997s/iter; left time: 7883.8792s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0879753\n",
      "\tspeed: 0.0986s/iter; left time: 7790.8897s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0848551\n",
      "\tspeed: 0.0989s/iter; left time: 7802.5963s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0755866\n",
      "\tspeed: 0.1001s/iter; left time: 7888.9594s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1117945\n",
      "\tspeed: 0.0990s/iter; left time: 7789.9277s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0859069\n",
      "\tspeed: 0.1032s/iter; left time: 8111.8854s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0947104\n",
      "\tspeed: 0.1001s/iter; left time: 7861.1467s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0981154\n",
      "\tspeed: 0.1015s/iter; left time: 7956.8118s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0940440\n",
      "\tspeed: 0.0947s/iter; left time: 7412.2293s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0983612\n",
      "\tspeed: 0.1000s/iter; left time: 7823.2266s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0836072\n",
      "\tspeed: 0.1002s/iter; left time: 7824.1603s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0788918\n",
      "\tspeed: 0.0999s/iter; left time: 7792.9068s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0732648\n",
      "\tspeed: 0.0988s/iter; left time: 7698.6423s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0901658\n",
      "\tspeed: 0.0977s/iter; left time: 7598.8195s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0971151\n",
      "\tspeed: 0.0978s/iter; left time: 7601.7202s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0896691\n",
      "\tspeed: 0.0979s/iter; left time: 7593.3154s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0813452\n",
      "\tspeed: 0.0988s/iter; left time: 7658.9424s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0852726\n",
      "\tspeed: 0.0993s/iter; left time: 7685.7856s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0909429\n",
      "\tspeed: 0.1024s/iter; left time: 7916.7954s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956288\n",
      "\tspeed: 0.0995s/iter; left time: 7677.8155s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0904642\n",
      "\tspeed: 0.0974s/iter; left time: 7511.6010s\n",
      "Epoch: 3 cost time: 00h:07m:29.53s\n",
      "Epoch: 3 | Train Loss: 0.0920011 Vali Loss: 0.0961987 Test Loss: 0.0974472\n",
      "Validation loss decreased (0.100685 --> 0.096199).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0854296\n",
      "\tspeed: 1.3142s/iter; left time: 101141.8138s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780370\n",
      "\tspeed: 0.0996s/iter; left time: 7658.6109s\n",
      "\titers: 300, epoch: 4 | loss: 0.0826013\n",
      "\tspeed: 0.1029s/iter; left time: 7902.0616s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769120\n",
      "\tspeed: 0.1018s/iter; left time: 7801.0230s\n",
      "\titers: 500, epoch: 4 | loss: 0.0974223\n",
      "\tspeed: 0.0986s/iter; left time: 7548.5106s\n",
      "\titers: 600, epoch: 4 | loss: 0.0936587\n",
      "\tspeed: 0.0965s/iter; left time: 7381.9201s\n",
      "\titers: 700, epoch: 4 | loss: 0.0737562\n",
      "\tspeed: 0.0985s/iter; left time: 7525.3560s\n",
      "\titers: 800, epoch: 4 | loss: 0.1083352\n",
      "\tspeed: 0.0983s/iter; left time: 7496.0994s\n",
      "\titers: 900, epoch: 4 | loss: 0.0773530\n",
      "\tspeed: 0.0981s/iter; left time: 7472.3147s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0801422\n",
      "\tspeed: 0.0965s/iter; left time: 7342.2084s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0897846\n",
      "\tspeed: 0.0967s/iter; left time: 7341.8274s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1164535\n",
      "\tspeed: 0.0993s/iter; left time: 7533.1355s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0910549\n",
      "\tspeed: 0.0972s/iter; left time: 7361.4885s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0885448\n",
      "\tspeed: 0.0961s/iter; left time: 7272.9170s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1008844\n",
      "\tspeed: 0.0993s/iter; left time: 7500.6766s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0783211\n",
      "\tspeed: 0.0988s/iter; left time: 7457.4286s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0906300\n",
      "\tspeed: 0.0994s/iter; left time: 7491.3826s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0950228\n",
      "\tspeed: 0.0988s/iter; left time: 7434.0902s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0826172\n",
      "\tspeed: 0.0987s/iter; left time: 7420.0613s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0946391\n",
      "\tspeed: 0.1013s/iter; left time: 7603.5128s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0991539\n",
      "\tspeed: 0.0979s/iter; left time: 7335.9758s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0967136\n",
      "\tspeed: 0.0959s/iter; left time: 7180.0891s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0812481\n",
      "\tspeed: 0.0990s/iter; left time: 7398.1803s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0714268\n",
      "\tspeed: 0.0989s/iter; left time: 7387.6641s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0870069\n",
      "\tspeed: 0.0968s/iter; left time: 7213.9709s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1008413\n",
      "\tspeed: 0.0959s/iter; left time: 7144.2811s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0958331\n",
      "\tspeed: 0.0998s/iter; left time: 7422.6353s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0862275\n",
      "\tspeed: 0.1001s/iter; left time: 7436.5217s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0995362\n",
      "\tspeed: 0.0987s/iter; left time: 7317.1975s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0776753\n",
      "\tspeed: 0.0969s/iter; left time: 7177.2502s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0969164\n",
      "\tspeed: 0.0976s/iter; left time: 7216.0729s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0818957\n",
      "\tspeed: 0.1013s/iter; left time: 7480.6053s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1021598\n",
      "\tspeed: 0.1045s/iter; left time: 7708.6485s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0792934\n",
      "\tspeed: 0.1025s/iter; left time: 7550.8808s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0889132\n",
      "\tspeed: 0.0966s/iter; left time: 7105.1246s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0714224\n",
      "\tspeed: 0.1058s/iter; left time: 7770.6666s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1041591\n",
      "\tspeed: 0.1056s/iter; left time: 7746.5082s\n",
      "\titers: 3800, epoch: 4 | loss: 0.1012451\n",
      "\tspeed: 0.0995s/iter; left time: 7289.8450s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0812839\n",
      "\tspeed: 0.0965s/iter; left time: 7060.3051s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0673504\n",
      "\tspeed: 0.0994s/iter; left time: 7265.6753s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0983212\n",
      "\tspeed: 0.0998s/iter; left time: 7284.9942s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0892445\n",
      "\tspeed: 0.1024s/iter; left time: 7457.9601s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0736814\n",
      "\tspeed: 0.0982s/iter; left time: 7142.0700s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1024650\n",
      "\tspeed: 0.1000s/iter; left time: 7262.9893s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0878941\n",
      "\tspeed: 0.1002s/iter; left time: 7269.0189s\n",
      "Epoch: 4 cost time: 00h:07m:30.25s\n",
      "Epoch: 4 | Train Loss: 0.0894738 Vali Loss: 0.0959204 Test Loss: 0.0978855\n",
      "Validation loss decreased (0.096199 --> 0.095920).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0796165\n",
      "\tspeed: 1.3415s/iter; left time: 97165.2517s\n",
      "\titers: 200, epoch: 5 | loss: 0.0959185\n",
      "\tspeed: 0.1042s/iter; left time: 7536.7067s\n",
      "\titers: 300, epoch: 5 | loss: 0.0750006\n",
      "\tspeed: 0.1038s/iter; left time: 7498.0770s\n",
      "\titers: 400, epoch: 5 | loss: 0.0928235\n",
      "\tspeed: 0.1059s/iter; left time: 7635.1819s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928443\n",
      "\tspeed: 0.1006s/iter; left time: 7249.6675s\n",
      "\titers: 600, epoch: 5 | loss: 0.0831500\n",
      "\tspeed: 0.1000s/iter; left time: 7195.5720s\n",
      "\titers: 700, epoch: 5 | loss: 0.0872387\n",
      "\tspeed: 0.1034s/iter; left time: 7426.1119s\n",
      "\titers: 800, epoch: 5 | loss: 0.0713760\n",
      "\tspeed: 0.1018s/iter; left time: 7302.8275s\n",
      "\titers: 900, epoch: 5 | loss: 0.0977144\n",
      "\tspeed: 0.1022s/iter; left time: 7321.8485s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0899376\n",
      "\tspeed: 0.1063s/iter; left time: 7603.0771s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0909452\n",
      "\tspeed: 0.1073s/iter; left time: 7663.6423s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0850678\n",
      "\tspeed: 0.1005s/iter; left time: 7171.5266s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0866611\n",
      "\tspeed: 0.1041s/iter; left time: 7412.7031s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0814596\n",
      "\tspeed: 0.1056s/iter; left time: 7512.2304s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1011155\n",
      "\tspeed: 0.1026s/iter; left time: 7284.9512s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0806876\n",
      "\tspeed: 0.0930s/iter; left time: 6597.8508s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0924520\n",
      "\tspeed: 0.1020s/iter; left time: 7226.4722s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0869739\n",
      "\tspeed: 0.1018s/iter; left time: 7198.5440s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0844609\n",
      "\tspeed: 0.1005s/iter; left time: 7095.0675s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0788910\n",
      "\tspeed: 0.0977s/iter; left time: 6892.0472s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0919405\n",
      "\tspeed: 0.1064s/iter; left time: 7495.0567s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0726033\n",
      "\tspeed: 0.1026s/iter; left time: 7214.0181s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0916889\n",
      "\tspeed: 0.0995s/iter; left time: 6985.1730s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0683158\n",
      "\tspeed: 0.1053s/iter; left time: 7385.7452s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0925977\n",
      "\tspeed: 0.0931s/iter; left time: 6519.8642s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0985155\n",
      "\tspeed: 0.0997s/iter; left time: 6972.4979s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1006452\n",
      "\tspeed: 0.0997s/iter; left time: 6963.8701s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0845333\n",
      "\tspeed: 0.1049s/iter; left time: 7313.5824s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0966101\n",
      "\tspeed: 0.1014s/iter; left time: 7060.6279s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0780502\n",
      "\tspeed: 0.0953s/iter; left time: 6623.1762s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0809835\n",
      "\tspeed: 0.1046s/iter; left time: 7263.6035s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0696071\n",
      "\tspeed: 0.0979s/iter; left time: 6785.3214s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0723333\n",
      "\tspeed: 0.1023s/iter; left time: 7078.8098s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0702593\n",
      "\tspeed: 0.1029s/iter; left time: 7112.6566s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0938417\n",
      "\tspeed: 0.1010s/iter; left time: 6970.7326s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0951235\n",
      "\tspeed: 0.1047s/iter; left time: 7217.6933s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0845446\n",
      "\tspeed: 0.1052s/iter; left time: 7238.1443s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0840251\n",
      "\tspeed: 0.1046s/iter; left time: 7189.5553s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0870530\n",
      "\tspeed: 0.1008s/iter; left time: 6919.6613s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0931989\n",
      "\tspeed: 0.1001s/iter; left time: 6862.8567s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0680944\n",
      "\tspeed: 0.1060s/iter; left time: 7254.4370s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0768961\n",
      "\tspeed: 0.1004s/iter; left time: 6858.2873s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0758227\n",
      "\tspeed: 0.1064s/iter; left time: 7256.3985s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1047759\n",
      "\tspeed: 0.1054s/iter; left time: 7180.0354s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0782504\n",
      "\tspeed: 0.1003s/iter; left time: 6820.2225s\n",
      "Epoch: 5 cost time: 00h:07m:43.98s\n",
      "Epoch: 5 | Train Loss: 0.0879004 Vali Loss: 0.0939386 Test Loss: 0.0954783\n",
      "Validation loss decreased (0.095920 --> 0.093939).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0823750\n",
      "\tspeed: 1.3467s/iter; left time: 91432.2667s\n",
      "\titers: 200, epoch: 6 | loss: 0.1063394\n",
      "\tspeed: 0.1011s/iter; left time: 6852.1673s\n",
      "\titers: 300, epoch: 6 | loss: 0.0728738\n",
      "\tspeed: 0.1053s/iter; left time: 7128.8050s\n",
      "\titers: 400, epoch: 6 | loss: 0.0747061\n",
      "\tspeed: 0.1033s/iter; left time: 6984.8315s\n",
      "\titers: 500, epoch: 6 | loss: 0.0784984\n",
      "\tspeed: 0.0981s/iter; left time: 6624.1158s\n",
      "\titers: 600, epoch: 6 | loss: 0.0822229\n",
      "\tspeed: 0.1049s/iter; left time: 7066.7080s\n",
      "\titers: 700, epoch: 6 | loss: 0.0869800\n",
      "\tspeed: 0.0996s/iter; left time: 6702.8915s\n",
      "\titers: 800, epoch: 6 | loss: 0.0766805\n",
      "\tspeed: 0.0974s/iter; left time: 6544.9165s\n",
      "\titers: 900, epoch: 6 | loss: 0.0896778\n",
      "\tspeed: 0.1038s/iter; left time: 6962.6192s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0828632\n",
      "\tspeed: 0.1026s/iter; left time: 6874.3296s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0825213\n",
      "\tspeed: 0.0975s/iter; left time: 6520.8000s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0879269\n",
      "\tspeed: 0.0937s/iter; left time: 6258.6510s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0936004\n",
      "\tspeed: 0.1004s/iter; left time: 6698.7948s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0839023\n",
      "\tspeed: 0.1057s/iter; left time: 7042.4448s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0895705\n",
      "\tspeed: 0.1039s/iter; left time: 6907.9788s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0983923\n",
      "\tspeed: 0.1008s/iter; left time: 6692.5768s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1097069\n",
      "\tspeed: 0.1004s/iter; left time: 6655.7966s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0855282\n",
      "\tspeed: 0.1078s/iter; left time: 7135.9823s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0760626\n",
      "\tspeed: 0.1063s/iter; left time: 7028.1996s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1028426\n",
      "\tspeed: 0.1004s/iter; left time: 6629.2103s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0760202\n",
      "\tspeed: 0.1032s/iter; left time: 6802.0068s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1046149\n",
      "\tspeed: 0.1025s/iter; left time: 6745.4336s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0722455\n",
      "\tspeed: 0.1020s/iter; left time: 6699.4281s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1001926\n",
      "\tspeed: 0.1030s/iter; left time: 6757.3764s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0948031\n",
      "\tspeed: 0.1050s/iter; left time: 6879.1840s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0821364\n",
      "\tspeed: 0.1016s/iter; left time: 6646.8049s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1087020\n",
      "\tspeed: 0.1021s/iter; left time: 6663.7645s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0879368\n",
      "\tspeed: 0.1057s/iter; left time: 6889.1856s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0837349\n",
      "\tspeed: 0.1006s/iter; left time: 6549.8715s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0855312\n",
      "\tspeed: 0.1009s/iter; left time: 6556.2153s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0753525\n",
      "\tspeed: 0.0976s/iter; left time: 6330.6146s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0820278\n",
      "\tspeed: 0.1049s/iter; left time: 6797.0102s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0888730\n",
      "\tspeed: 0.0964s/iter; left time: 6237.5931s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0932008\n",
      "\tspeed: 0.1036s/iter; left time: 6691.5403s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0900321\n",
      "\tspeed: 0.1000s/iter; left time: 6446.3871s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0867740\n",
      "\tspeed: 0.1013s/iter; left time: 6525.5733s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1079047\n",
      "\tspeed: 0.1025s/iter; left time: 6593.2241s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0729139\n",
      "\tspeed: 0.0991s/iter; left time: 6359.5930s\n",
      "\titers: 3900, epoch: 6 | loss: 0.1025409\n",
      "\tspeed: 0.1046s/iter; left time: 6705.2597s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0916645\n",
      "\tspeed: 0.1020s/iter; left time: 6525.8738s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0854311\n",
      "\tspeed: 0.1047s/iter; left time: 6690.2627s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0886655\n",
      "\tspeed: 0.1016s/iter; left time: 6480.8821s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0818150\n",
      "\tspeed: 0.1003s/iter; left time: 6389.3058s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0888074\n",
      "\tspeed: 0.1036s/iter; left time: 6587.3938s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0821429\n",
      "\tspeed: 0.0965s/iter; left time: 6127.9679s\n",
      "Epoch: 6 cost time: 00h:07m:42.51s\n",
      "Epoch: 6 | Train Loss: 0.0867662 Vali Loss: 0.0923030 Test Loss: 0.0944841\n",
      "Validation loss decreased (0.093939 --> 0.092303).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0740339\n",
      "\tspeed: 1.3279s/iter; left time: 84142.3451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806055\n",
      "\tspeed: 0.1011s/iter; left time: 6397.4817s\n",
      "\titers: 300, epoch: 7 | loss: 0.0792400\n",
      "\tspeed: 0.1023s/iter; left time: 6459.3339s\n",
      "\titers: 400, epoch: 7 | loss: 0.0885487\n",
      "\tspeed: 0.1026s/iter; left time: 6470.6621s\n",
      "\titers: 500, epoch: 7 | loss: 0.0872176\n",
      "\tspeed: 0.1014s/iter; left time: 6385.0139s\n",
      "\titers: 600, epoch: 7 | loss: 0.0869710\n",
      "\tspeed: 0.1041s/iter; left time: 6542.1420s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786874\n",
      "\tspeed: 0.1020s/iter; left time: 6399.5723s\n",
      "\titers: 800, epoch: 7 | loss: 0.0897944\n",
      "\tspeed: 0.1053s/iter; left time: 6599.0058s\n",
      "\titers: 900, epoch: 7 | loss: 0.0814298\n",
      "\tspeed: 0.0958s/iter; left time: 5994.0173s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0705729\n",
      "\tspeed: 0.1023s/iter; left time: 6389.5788s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0569545\n",
      "\tspeed: 0.0955s/iter; left time: 5958.6051s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0850203\n",
      "\tspeed: 0.0976s/iter; left time: 6074.2025s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0733617\n",
      "\tspeed: 0.0945s/iter; left time: 5874.5316s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1048769\n",
      "\tspeed: 0.1002s/iter; left time: 6218.0586s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0904823\n",
      "\tspeed: 0.1018s/iter; left time: 6310.8287s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0865115\n",
      "\tspeed: 0.1024s/iter; left time: 6337.0242s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0868625\n",
      "\tspeed: 0.1012s/iter; left time: 6250.8231s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0834711\n",
      "\tspeed: 0.1003s/iter; left time: 6186.8268s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0972821\n",
      "\tspeed: 0.0981s/iter; left time: 6040.5447s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0822335\n",
      "\tspeed: 0.1007s/iter; left time: 6186.3172s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0901200\n",
      "\tspeed: 0.0978s/iter; left time: 6000.9481s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0892411\n",
      "\tspeed: 0.1023s/iter; left time: 6267.9073s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0871298\n",
      "\tspeed: 0.1040s/iter; left time: 6359.9234s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0816868\n",
      "\tspeed: 0.0998s/iter; left time: 6092.9299s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1097169\n",
      "\tspeed: 0.1034s/iter; left time: 6302.4151s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0667246\n",
      "\tspeed: 0.1003s/iter; left time: 6101.9371s\n",
      "\titers: 2700, epoch: 7 | loss: 0.1001452\n",
      "\tspeed: 0.1028s/iter; left time: 6246.1959s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0926842\n",
      "\tspeed: 0.0986s/iter; left time: 5978.4639s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0792861\n",
      "\tspeed: 0.0990s/iter; left time: 5998.3412s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0924478\n",
      "\tspeed: 0.0994s/iter; left time: 6008.8689s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061495\n",
      "\tspeed: 0.1059s/iter; left time: 6393.1014s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0846756\n",
      "\tspeed: 0.1005s/iter; left time: 6053.9868s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0878668\n",
      "\tspeed: 0.0962s/iter; left time: 5787.7234s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0904202\n",
      "\tspeed: 0.1011s/iter; left time: 6073.0991s\n",
      "\titers: 3500, epoch: 7 | loss: 0.1028529\n",
      "\tspeed: 0.1002s/iter; left time: 6009.5951s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0663122\n",
      "\tspeed: 0.0990s/iter; left time: 5924.3264s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0938098\n",
      "\tspeed: 0.1023s/iter; left time: 6114.2053s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0904512\n",
      "\tspeed: 0.0972s/iter; left time: 5801.5553s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0924167\n",
      "\tspeed: 0.1027s/iter; left time: 6118.6491s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0838463\n",
      "\tspeed: 0.0957s/iter; left time: 5689.0299s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0746771\n",
      "\tspeed: 0.0985s/iter; left time: 5844.6515s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0833501\n",
      "\tspeed: 0.0981s/iter; left time: 5815.3194s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0937628\n",
      "\tspeed: 0.1039s/iter; left time: 6149.5759s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0842075\n",
      "\tspeed: 0.1015s/iter; left time: 5993.1336s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1038213\n",
      "\tspeed: 0.1019s/iter; left time: 6005.7299s\n",
      "Epoch: 7 cost time: 00h:07m:36.00s\n",
      "Epoch: 7 | Train Loss: 0.0858412 Vali Loss: 0.0921237 Test Loss: 0.0943098\n",
      "Validation loss decreased (0.092303 --> 0.092124).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0808295\n",
      "\tspeed: 1.3484s/iter; left time: 79324.9407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0785601\n",
      "\tspeed: 0.1013s/iter; left time: 5948.3385s\n",
      "\titers: 300, epoch: 8 | loss: 0.0913709\n",
      "\tspeed: 0.1049s/iter; left time: 6150.9803s\n",
      "\titers: 400, epoch: 8 | loss: 0.0863424\n",
      "\tspeed: 0.1015s/iter; left time: 5943.1978s\n",
      "\titers: 500, epoch: 8 | loss: 0.0919085\n",
      "\tspeed: 0.1026s/iter; left time: 5995.7721s\n",
      "\titers: 600, epoch: 8 | loss: 0.0952189\n",
      "\tspeed: 0.1094s/iter; left time: 6384.0770s\n",
      "\titers: 700, epoch: 8 | loss: 0.0938345\n",
      "\tspeed: 0.1051s/iter; left time: 6118.7782s\n",
      "\titers: 800, epoch: 8 | loss: 0.0633808\n",
      "\tspeed: 0.1066s/iter; left time: 6195.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0932870\n",
      "\tspeed: 0.1001s/iter; left time: 5805.9081s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0710422\n",
      "\tspeed: 0.1059s/iter; left time: 6136.8467s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0793336\n",
      "\tspeed: 0.1107s/iter; left time: 6403.0260s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0701465\n",
      "\tspeed: 0.1109s/iter; left time: 6400.0567s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0760521\n",
      "\tspeed: 0.1001s/iter; left time: 5769.7115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0881910\n",
      "\tspeed: 0.1119s/iter; left time: 6437.5889s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0892492\n",
      "\tspeed: 0.1112s/iter; left time: 6386.6952s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0819665\n",
      "\tspeed: 0.1109s/iter; left time: 6358.0637s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0787609\n",
      "\tspeed: 0.0940s/iter; left time: 5381.0757s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0747100\n",
      "\tspeed: 0.0985s/iter; left time: 5624.7843s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1021912\n",
      "\tspeed: 0.1037s/iter; left time: 5911.1690s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0817584\n",
      "\tspeed: 0.0979s/iter; left time: 5570.9904s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0737849\n",
      "\tspeed: 0.1033s/iter; left time: 5870.7968s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0738396\n",
      "\tspeed: 0.1043s/iter; left time: 5916.2166s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0792134\n",
      "\tspeed: 0.1023s/iter; left time: 5793.2293s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0833495\n",
      "\tspeed: 0.0969s/iter; left time: 5475.1824s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0985885\n",
      "\tspeed: 0.0998s/iter; left time: 5632.6808s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0903379\n",
      "\tspeed: 0.1009s/iter; left time: 5681.0624s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0958151\n",
      "\tspeed: 0.0916s/iter; left time: 5149.8239s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0752126\n",
      "\tspeed: 0.0982s/iter; left time: 5513.6748s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0844900\n",
      "\tspeed: 0.1055s/iter; left time: 5911.9269s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0992072\n",
      "\tspeed: 0.1010s/iter; left time: 5648.5090s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0779921\n",
      "\tspeed: 0.0948s/iter; left time: 5293.3490s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0817788\n",
      "\tspeed: 0.1028s/iter; left time: 5729.8750s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0698256\n",
      "\tspeed: 0.1052s/iter; left time: 5851.0588s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1009030\n",
      "\tspeed: 0.1011s/iter; left time: 5613.4136s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0794296\n",
      "\tspeed: 0.1089s/iter; left time: 6036.6832s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0652106\n",
      "\tspeed: 0.1036s/iter; left time: 5733.3627s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0883530\n",
      "\tspeed: 0.0991s/iter; left time: 5471.9486s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0876575\n",
      "\tspeed: 0.0938s/iter; left time: 5169.8339s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0858913\n",
      "\tspeed: 0.1035s/iter; left time: 5693.3468s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0873493\n",
      "\tspeed: 0.0944s/iter; left time: 5187.3501s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0958864\n",
      "\tspeed: 0.0958s/iter; left time: 5251.1785s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0893509\n",
      "\tspeed: 0.1090s/iter; left time: 5966.4078s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0774665\n",
      "\tspeed: 0.0961s/iter; left time: 5250.4544s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0878850\n",
      "\tspeed: 0.1060s/iter; left time: 5780.8161s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0725639\n",
      "\tspeed: 0.1012s/iter; left time: 5508.9953s\n",
      "Epoch: 8 cost time: 00h:07m:45.04s\n",
      "Epoch: 8 | Train Loss: 0.0850912 Vali Loss: 0.0910974 Test Loss: 0.0931037\n",
      "Validation loss decreased (0.092124 --> 0.091097).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0839187\n",
      "\tspeed: 1.3393s/iter; left time: 72719.7064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809305\n",
      "\tspeed: 0.0985s/iter; left time: 5340.6867s\n",
      "\titers: 300, epoch: 9 | loss: 0.0818261\n",
      "\tspeed: 0.1001s/iter; left time: 5413.2822s\n",
      "\titers: 400, epoch: 9 | loss: 0.0826800\n",
      "\tspeed: 0.1054s/iter; left time: 5690.5036s\n",
      "\titers: 500, epoch: 9 | loss: 0.0678031\n",
      "\tspeed: 0.1062s/iter; left time: 5724.4040s\n",
      "\titers: 600, epoch: 9 | loss: 0.0687698\n",
      "\tspeed: 0.0947s/iter; left time: 5096.4144s\n",
      "\titers: 700, epoch: 9 | loss: 0.1053366\n",
      "\tspeed: 0.1048s/iter; left time: 5626.3520s\n",
      "\titers: 800, epoch: 9 | loss: 0.0873797\n",
      "\tspeed: 0.1019s/iter; left time: 5462.2545s\n",
      "\titers: 900, epoch: 9 | loss: 0.0993194\n",
      "\tspeed: 0.1073s/iter; left time: 5738.7548s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0958880\n",
      "\tspeed: 0.1031s/iter; left time: 5505.4965s\n",
      "\titers: 1100, epoch: 9 | loss: 0.1099369\n",
      "\tspeed: 0.1053s/iter; left time: 5609.8455s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0775966\n",
      "\tspeed: 0.1065s/iter; left time: 5664.7452s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0886414\n",
      "\tspeed: 0.1023s/iter; left time: 5429.9298s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0764013\n",
      "\tspeed: 0.0982s/iter; left time: 5203.6006s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0902908\n",
      "\tspeed: 0.1062s/iter; left time: 5620.2334s\n",
      "\titers: 1600, epoch: 9 | loss: 0.1045604\n",
      "\tspeed: 0.1032s/iter; left time: 5446.7768s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0727765\n",
      "\tspeed: 0.1031s/iter; left time: 5433.1033s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0630156\n",
      "\tspeed: 0.0991s/iter; left time: 5211.3352s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0870845\n",
      "\tspeed: 0.1059s/iter; left time: 5559.2011s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0690623\n",
      "\tspeed: 0.1020s/iter; left time: 5343.4981s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0762401\n",
      "\tspeed: 0.1029s/iter; left time: 5378.7984s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0842778\n",
      "\tspeed: 0.1055s/iter; left time: 5506.7273s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0593234\n",
      "\tspeed: 0.0989s/iter; left time: 5149.8009s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0558220\n",
      "\tspeed: 0.1029s/iter; left time: 5351.7705s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0766593\n",
      "\tspeed: 0.1043s/iter; left time: 5413.7909s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1005495\n",
      "\tspeed: 0.1078s/iter; left time: 5585.5454s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0827615\n",
      "\tspeed: 0.1037s/iter; left time: 5361.2156s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0824010\n",
      "\tspeed: 0.0998s/iter; left time: 5150.6259s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0834433\n",
      "\tspeed: 0.1104s/iter; left time: 5684.0355s\n",
      "\titers: 3000, epoch: 9 | loss: 0.1030053\n",
      "\tspeed: 0.1007s/iter; left time: 5175.0512s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0827309\n",
      "\tspeed: 0.0956s/iter; left time: 4905.6988s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0985053\n",
      "\tspeed: 0.1020s/iter; left time: 5222.4325s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0913691\n",
      "\tspeed: 0.1020s/iter; left time: 5209.3681s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0674509\n",
      "\tspeed: 0.1025s/iter; left time: 5225.3279s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0651387\n",
      "\tspeed: 0.1120s/iter; left time: 5700.8219s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0786256\n",
      "\tspeed: 0.1069s/iter; left time: 5430.1683s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0702851\n",
      "\tspeed: 0.1056s/iter; left time: 5352.5572s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0919049\n",
      "\tspeed: 0.1059s/iter; left time: 5356.1552s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1030596\n",
      "\tspeed: 0.1029s/iter; left time: 5198.5737s\n",
      "\titers: 4000, epoch: 9 | loss: 0.1027514\n",
      "\tspeed: 0.1025s/iter; left time: 5163.8451s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0780454\n",
      "\tspeed: 0.1002s/iter; left time: 5037.6974s\n",
      "\titers: 4200, epoch: 9 | loss: 0.1132283\n",
      "\tspeed: 0.1056s/iter; left time: 5299.3248s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0697139\n",
      "\tspeed: 0.1034s/iter; left time: 5178.2915s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0739302\n",
      "\tspeed: 0.1013s/iter; left time: 5065.2817s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0807885\n",
      "\tspeed: 0.1038s/iter; left time: 5179.2621s\n",
      "Epoch: 9 cost time: 00h:07m:48.76s\n",
      "Epoch: 9 | Train Loss: 0.0844597 Vali Loss: 0.0919761 Test Loss: 0.0936041\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.1010430\n",
      "\tspeed: 1.3346s/iter; left time: 66416.5087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0755394\n",
      "\tspeed: 0.1040s/iter; left time: 5166.6819s\n",
      "\titers: 300, epoch: 10 | loss: 0.0786103\n",
      "\tspeed: 0.1036s/iter; left time: 5135.9702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0899143\n",
      "\tspeed: 0.1051s/iter; left time: 5197.7291s\n",
      "\titers: 500, epoch: 10 | loss: 0.0636813\n",
      "\tspeed: 0.1041s/iter; left time: 5136.9201s\n",
      "\titers: 600, epoch: 10 | loss: 0.0777985\n",
      "\tspeed: 0.1002s/iter; left time: 4937.8216s\n",
      "\titers: 700, epoch: 10 | loss: 0.0812854\n",
      "\tspeed: 0.1027s/iter; left time: 5047.7730s\n",
      "\titers: 800, epoch: 10 | loss: 0.0824201\n",
      "\tspeed: 0.1019s/iter; left time: 4998.2648s\n",
      "\titers: 900, epoch: 10 | loss: 0.0969159\n",
      "\tspeed: 0.0977s/iter; left time: 4782.6161s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0650369\n",
      "\tspeed: 0.1116s/iter; left time: 5452.5445s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0965921\n",
      "\tspeed: 0.1048s/iter; left time: 5112.7270s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0686363\n",
      "\tspeed: 0.1007s/iter; left time: 4902.0690s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0707972\n",
      "\tspeed: 0.1103s/iter; left time: 5356.6364s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0846506\n",
      "\tspeed: 0.1042s/iter; left time: 5051.8875s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0771418\n",
      "\tspeed: 0.1023s/iter; left time: 4947.0735s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0756956\n",
      "\tspeed: 0.1023s/iter; left time: 4937.4101s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0902093\n",
      "\tspeed: 0.1056s/iter; left time: 5086.7251s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0785837\n",
      "\tspeed: 0.1014s/iter; left time: 4875.0373s\n",
      "\titers: 1900, epoch: 10 | loss: 0.1091566\n",
      "\tspeed: 0.1062s/iter; left time: 5092.8788s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0851738\n",
      "\tspeed: 0.1011s/iter; left time: 4840.8315s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0617394\n",
      "\tspeed: 0.1004s/iter; left time: 4793.4138s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0630960\n",
      "\tspeed: 0.1062s/iter; left time: 5062.1527s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0792385\n",
      "\tspeed: 0.1075s/iter; left time: 5114.0433s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0815424\n",
      "\tspeed: 0.1021s/iter; left time: 4847.8636s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0834371\n",
      "\tspeed: 0.1003s/iter; left time: 4751.5089s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0859960\n",
      "\tspeed: 0.1043s/iter; left time: 4930.6460s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0943459\n",
      "\tspeed: 0.1014s/iter; left time: 4781.8720s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0859495\n",
      "\tspeed: 0.0961s/iter; left time: 4524.2340s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0788042\n",
      "\tspeed: 0.1023s/iter; left time: 4802.3900s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0783276\n",
      "\tspeed: 0.1028s/iter; left time: 4817.8440s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0720328\n",
      "\tspeed: 0.0935s/iter; left time: 4372.6421s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0770221\n",
      "\tspeed: 0.1070s/iter; left time: 4993.5091s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0816277\n",
      "\tspeed: 0.1020s/iter; left time: 4748.6206s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0734417\n",
      "\tspeed: 0.1047s/iter; left time: 4865.7704s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0925057\n",
      "\tspeed: 0.0959s/iter; left time: 4448.4863s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0732646\n",
      "\tspeed: 0.1029s/iter; left time: 4761.7844s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0714871\n",
      "\tspeed: 0.0950s/iter; left time: 4383.2843s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0829047\n",
      "\tspeed: 0.1033s/iter; left time: 4756.3233s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0768411\n",
      "\tspeed: 0.1053s/iter; left time: 4839.7838s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0718129\n",
      "\tspeed: 0.0958s/iter; left time: 4391.5425s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0926463\n",
      "\tspeed: 0.1017s/iter; left time: 4654.4916s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0805132\n",
      "\tspeed: 0.1010s/iter; left time: 4609.8388s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0772594\n",
      "\tspeed: 0.1059s/iter; left time: 4825.7171s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0775610\n",
      "\tspeed: 0.1026s/iter; left time: 4663.3316s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0796847\n",
      "\tspeed: 0.0989s/iter; left time: 4488.3419s\n",
      "Epoch: 10 cost time: 00h:07m:45.98s\n",
      "Epoch: 10 | Train Loss: 0.0838264 Vali Loss: 0.0909270 Test Loss: 0.0934180\n",
      "Validation loss decreased (0.091097 --> 0.090927).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0868814\n",
      "\tspeed: 1.3530s/iter; left time: 61195.7743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0833030\n",
      "\tspeed: 0.1028s/iter; left time: 4638.8924s\n",
      "\titers: 300, epoch: 11 | loss: 0.0659933\n",
      "\tspeed: 0.1062s/iter; left time: 4781.5714s\n",
      "\titers: 400, epoch: 11 | loss: 0.0918775\n",
      "\tspeed: 0.0975s/iter; left time: 4380.8138s\n",
      "\titers: 500, epoch: 11 | loss: 0.0899109\n",
      "\tspeed: 0.1013s/iter; left time: 4542.9191s\n",
      "\titers: 600, epoch: 11 | loss: 0.0993830\n",
      "\tspeed: 0.1029s/iter; left time: 4603.1110s\n",
      "\titers: 700, epoch: 11 | loss: 0.0819754\n",
      "\tspeed: 0.1035s/iter; left time: 4619.2550s\n",
      "\titers: 800, epoch: 11 | loss: 0.0924889\n",
      "\tspeed: 0.1063s/iter; left time: 4733.0434s\n",
      "\titers: 900, epoch: 11 | loss: 0.0992053\n",
      "\tspeed: 0.1055s/iter; left time: 4686.5319s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0837300\n",
      "\tspeed: 0.1015s/iter; left time: 4500.3296s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0934541\n",
      "\tspeed: 0.0986s/iter; left time: 4362.1410s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0743836\n",
      "\tspeed: 0.1009s/iter; left time: 4452.3462s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0676240\n",
      "\tspeed: 0.1067s/iter; left time: 4698.3471s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0818041\n",
      "\tspeed: 0.1027s/iter; left time: 4509.9466s\n",
      "\titers: 1500, epoch: 11 | loss: 0.1061748\n",
      "\tspeed: 0.1008s/iter; left time: 4417.7841s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0742621\n",
      "\tspeed: 0.1059s/iter; left time: 4632.5696s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0765426\n",
      "\tspeed: 0.0977s/iter; left time: 4261.9754s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0633865\n",
      "\tspeed: 0.1004s/iter; left time: 4370.3637s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0719905\n",
      "\tspeed: 0.1036s/iter; left time: 4497.5792s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0846679\n",
      "\tspeed: 0.0987s/iter; left time: 4276.0389s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0660811\n",
      "\tspeed: 0.1049s/iter; left time: 4535.5453s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0933878\n",
      "\tspeed: 0.1022s/iter; left time: 4407.1591s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0863511\n",
      "\tspeed: 0.1039s/iter; left time: 4471.8153s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0862527\n",
      "\tspeed: 0.0982s/iter; left time: 4217.8503s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0868275\n",
      "\tspeed: 0.0992s/iter; left time: 4249.6541s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0819848\n",
      "\tspeed: 0.1020s/iter; left time: 4359.7169s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0776399\n",
      "\tspeed: 0.1049s/iter; left time: 4470.5936s\n",
      "\titers: 2800, epoch: 11 | loss: 0.1002442\n",
      "\tspeed: 0.1003s/iter; left time: 4264.1523s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0772504\n",
      "\tspeed: 0.1051s/iter; left time: 4457.6660s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0814845\n",
      "\tspeed: 0.1022s/iter; left time: 4327.1347s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0988288\n",
      "\tspeed: 0.0996s/iter; left time: 4204.4656s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0900506\n",
      "\tspeed: 0.1018s/iter; left time: 4287.1075s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0772932\n",
      "\tspeed: 0.1056s/iter; left time: 4438.8326s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0745195\n",
      "\tspeed: 0.0993s/iter; left time: 4162.6894s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0994061\n",
      "\tspeed: 0.1038s/iter; left time: 4342.0000s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0809238\n",
      "\tspeed: 0.1025s/iter; left time: 4277.6527s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0847667\n",
      "\tspeed: 0.0977s/iter; left time: 4065.7991s\n",
      "\titers: 3800, epoch: 11 | loss: 0.0905470\n",
      "\tspeed: 0.1051s/iter; left time: 4362.8507s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1020130\n",
      "\tspeed: 0.0958s/iter; left time: 3969.3467s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0703370\n",
      "\tspeed: 0.1018s/iter; left time: 4207.0264s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0917754\n",
      "\tspeed: 0.1018s/iter; left time: 4196.2700s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0985425\n",
      "\tspeed: 0.1031s/iter; left time: 4239.0728s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0730693\n",
      "\tspeed: 0.1041s/iter; left time: 4273.2968s\n",
      "\titers: 4400, epoch: 11 | loss: 0.0959341\n",
      "\tspeed: 0.1032s/iter; left time: 4223.2262s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0771418\n",
      "\tspeed: 0.1011s/iter; left time: 4129.3341s\n",
      "Epoch: 11 cost time: 00h:07m:43.67s\n",
      "Epoch: 11 | Train Loss: 0.0834381 Vali Loss: 0.0909066 Test Loss: 0.0931787\n",
      "Validation loss decreased (0.090927 --> 0.090907).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0886225\n",
      "\tspeed: 1.3803s/iter; left time: 56173.7156s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704846\n",
      "\tspeed: 0.1109s/iter; left time: 4503.3354s\n",
      "\titers: 300, epoch: 12 | loss: 0.0843104\n",
      "\tspeed: 0.1131s/iter; left time: 4578.4616s\n",
      "\titers: 400, epoch: 12 | loss: 0.0762128\n",
      "\tspeed: 0.0966s/iter; left time: 3900.9972s\n",
      "\titers: 500, epoch: 12 | loss: 0.0877431\n",
      "\tspeed: 0.0898s/iter; left time: 3619.8648s\n",
      "\titers: 600, epoch: 12 | loss: 0.0772243\n",
      "\tspeed: 0.0976s/iter; left time: 3922.9558s\n",
      "\titers: 700, epoch: 12 | loss: 0.0802122\n",
      "\tspeed: 0.1115s/iter; left time: 4471.3897s\n",
      "\titers: 800, epoch: 12 | loss: 0.0783113\n",
      "\tspeed: 0.1018s/iter; left time: 4073.2087s\n",
      "\titers: 900, epoch: 12 | loss: 0.0922541\n",
      "\tspeed: 0.0910s/iter; left time: 3630.3006s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0961081\n",
      "\tspeed: 0.1046s/iter; left time: 4161.5621s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0833521\n",
      "\tspeed: 0.1108s/iter; left time: 4398.7509s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0738913\n",
      "\tspeed: 0.1108s/iter; left time: 4388.5681s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0856553\n",
      "\tspeed: 0.1114s/iter; left time: 4400.9010s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0767801\n",
      "\tspeed: 0.1115s/iter; left time: 4391.3045s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0789911\n",
      "\tspeed: 0.1122s/iter; left time: 4407.6882s\n",
      "\titers: 1600, epoch: 12 | loss: 0.1014416\n",
      "\tspeed: 0.1125s/iter; left time: 4411.6716s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0787071\n",
      "\tspeed: 0.1127s/iter; left time: 4404.5828s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0898735\n",
      "\tspeed: 0.1114s/iter; left time: 4342.8016s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0726669\n",
      "\tspeed: 0.1109s/iter; left time: 4314.4575s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0864183\n",
      "\tspeed: 0.1114s/iter; left time: 4320.3633s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0647909\n",
      "\tspeed: 0.1117s/iter; left time: 4324.4055s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0833790\n",
      "\tspeed: 0.1118s/iter; left time: 4316.1799s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0672993\n",
      "\tspeed: 0.1104s/iter; left time: 4250.7136s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0770334\n",
      "\tspeed: 0.1140s/iter; left time: 4379.2232s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0722176\n",
      "\tspeed: 0.1175s/iter; left time: 4499.6213s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0794186\n",
      "\tspeed: 0.1131s/iter; left time: 4321.0988s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0768241\n",
      "\tspeed: 0.1122s/iter; left time: 4272.7457s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0862142\n",
      "\tspeed: 0.1113s/iter; left time: 4230.8027s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0829330\n",
      "\tspeed: 0.1113s/iter; left time: 4219.5043s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0871102\n",
      "\tspeed: 0.1110s/iter; left time: 4193.7760s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0841428\n",
      "\tspeed: 0.1109s/iter; left time: 4179.8843s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0871388\n",
      "\tspeed: 0.1108s/iter; left time: 4167.0181s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0876352\n",
      "\tspeed: 0.1117s/iter; left time: 4187.0873s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0692153\n",
      "\tspeed: 0.1111s/iter; left time: 4153.5511s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0942930\n",
      "\tspeed: 0.1113s/iter; left time: 4152.1312s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0974538\n",
      "\tspeed: 0.1109s/iter; left time: 4124.2492s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0789281\n",
      "\tspeed: 0.1108s/iter; left time: 4111.4908s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0951056\n",
      "\tspeed: 0.1108s/iter; left time: 4099.9487s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0798555\n",
      "\tspeed: 0.1110s/iter; left time: 4093.8582s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0776716\n",
      "\tspeed: 0.1110s/iter; left time: 4085.7079s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0741630\n",
      "\tspeed: 0.1112s/iter; left time: 4079.3293s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0646463\n",
      "\tspeed: 0.1130s/iter; left time: 4137.0240s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0909856\n",
      "\tspeed: 0.1144s/iter; left time: 4174.2874s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0871067\n",
      "\tspeed: 0.1165s/iter; left time: 4240.1633s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0992545\n",
      "\tspeed: 0.1170s/iter; left time: 4246.8881s\n",
      "Epoch: 12 cost time: 00h:08m:19.65s\n",
      "Epoch: 12 | Train Loss: 0.0829866 Vali Loss: 0.0906585 Test Loss: 0.0937089\n",
      "Validation loss decreased (0.090907 --> 0.090658).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0791249\n",
      "\tspeed: 1.3686s/iter; left time: 49494.4113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0801380\n",
      "\tspeed: 0.1176s/iter; left time: 4240.9751s\n",
      "\titers: 300, epoch: 13 | loss: 0.0883047\n",
      "\tspeed: 0.1201s/iter; left time: 4320.6687s\n",
      "\titers: 400, epoch: 13 | loss: 0.0885546\n",
      "\tspeed: 0.1132s/iter; left time: 4059.8484s\n",
      "\titers: 500, epoch: 13 | loss: 0.0820055\n",
      "\tspeed: 0.1117s/iter; left time: 3994.1113s\n",
      "\titers: 600, epoch: 13 | loss: 0.0886124\n",
      "\tspeed: 0.1128s/iter; left time: 4024.6045s\n",
      "\titers: 700, epoch: 13 | loss: 0.0714438\n",
      "\tspeed: 0.1156s/iter; left time: 4110.3409s\n",
      "\titers: 800, epoch: 13 | loss: 0.1015169\n",
      "\tspeed: 0.1172s/iter; left time: 4157.3575s\n",
      "\titers: 900, epoch: 13 | loss: 0.0811925\n",
      "\tspeed: 0.1167s/iter; left time: 4126.6244s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0657136\n",
      "\tspeed: 0.1122s/iter; left time: 3956.2513s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0817874\n",
      "\tspeed: 0.1112s/iter; left time: 3908.8363s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0827836\n",
      "\tspeed: 0.1065s/iter; left time: 3735.8571s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0906617\n",
      "\tspeed: 0.1134s/iter; left time: 3965.2034s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0743353\n",
      "\tspeed: 0.1108s/iter; left time: 3864.5048s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0843722\n",
      "\tspeed: 0.1130s/iter; left time: 3927.1964s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0961763\n",
      "\tspeed: 0.1164s/iter; left time: 4036.3358s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0756035\n",
      "\tspeed: 0.1163s/iter; left time: 4019.9631s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0759710\n",
      "\tspeed: 0.1164s/iter; left time: 4012.3950s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0960970\n",
      "\tspeed: 0.1160s/iter; left time: 3985.9931s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0852554\n",
      "\tspeed: 0.1153s/iter; left time: 3949.7180s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0826193\n",
      "\tspeed: 0.1107s/iter; left time: 3783.4062s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0701863\n",
      "\tspeed: 0.1107s/iter; left time: 3771.1392s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0795562\n",
      "\tspeed: 0.1109s/iter; left time: 3768.1809s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0949270\n",
      "\tspeed: 0.1109s/iter; left time: 3756.7527s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0853140\n",
      "\tspeed: 0.1110s/iter; left time: 3746.5461s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0787078\n",
      "\tspeed: 0.1113s/iter; left time: 3747.9117s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0833492\n",
      "\tspeed: 0.1113s/iter; left time: 3736.4199s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0813542\n",
      "\tspeed: 0.1108s/iter; left time: 3708.9582s\n",
      "\titers: 2900, epoch: 13 | loss: 0.1056878\n",
      "\tspeed: 0.1111s/iter; left time: 3705.5921s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0806301\n",
      "\tspeed: 0.1109s/iter; left time: 3689.5989s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0857160\n",
      "\tspeed: 0.1110s/iter; left time: 3680.1804s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0664781\n",
      "\tspeed: 0.1109s/iter; left time: 3666.4144s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0840124\n",
      "\tspeed: 0.1110s/iter; left time: 3657.5803s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0705491\n",
      "\tspeed: 0.1108s/iter; left time: 3641.5789s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0935380\n",
      "\tspeed: 0.1149s/iter; left time: 3763.5672s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0906575\n",
      "\tspeed: 0.1126s/iter; left time: 3678.9123s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0968636\n",
      "\tspeed: 0.1108s/iter; left time: 3606.6664s\n",
      "\titers: 3800, epoch: 13 | loss: 0.0919440\n",
      "\tspeed: 0.1153s/iter; left time: 3742.8749s\n",
      "\titers: 3900, epoch: 13 | loss: 0.0788422\n",
      "\tspeed: 0.1112s/iter; left time: 3600.5200s\n",
      "\titers: 4000, epoch: 13 | loss: 0.0863206\n",
      "\tspeed: 0.1111s/iter; left time: 3583.5639s\n",
      "\titers: 4100, epoch: 13 | loss: 0.0730646\n",
      "\tspeed: 0.1108s/iter; left time: 3565.3403s\n",
      "\titers: 4200, epoch: 13 | loss: 0.0905983\n",
      "\tspeed: 0.1143s/iter; left time: 3664.4059s\n",
      "\titers: 4300, epoch: 13 | loss: 0.0929489\n",
      "\tspeed: 0.1143s/iter; left time: 3654.7118s\n",
      "\titers: 4400, epoch: 13 | loss: 0.0747109\n",
      "\tspeed: 0.1124s/iter; left time: 3581.2646s\n",
      "\titers: 4500, epoch: 13 | loss: 0.0708904\n",
      "\tspeed: 0.1111s/iter; left time: 3527.7849s\n",
      "Epoch: 13 cost time: 00h:08m:32.35s\n",
      "Epoch: 13 | Train Loss: 0.0825152 Vali Loss: 0.0904522 Test Loss: 0.0932098\n",
      "Validation loss decreased (0.090658 --> 0.090452).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0660638\n",
      "\tspeed: 1.3859s/iter; left time: 43839.3476s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745506\n",
      "\tspeed: 0.1121s/iter; left time: 3534.6208s\n",
      "\titers: 300, epoch: 14 | loss: 0.0715450\n",
      "\tspeed: 0.0973s/iter; left time: 3056.7949s\n",
      "\titers: 400, epoch: 14 | loss: 0.0766391\n",
      "\tspeed: 0.1168s/iter; left time: 3660.8783s\n",
      "\titers: 500, epoch: 14 | loss: 0.0950110\n",
      "\tspeed: 0.1161s/iter; left time: 3626.3020s\n",
      "\titers: 600, epoch: 14 | loss: 0.0777599\n",
      "\tspeed: 0.1142s/iter; left time: 3555.9614s\n",
      "\titers: 700, epoch: 14 | loss: 0.0903370\n",
      "\tspeed: 0.1160s/iter; left time: 3600.6101s\n",
      "\titers: 800, epoch: 14 | loss: 0.0700843\n",
      "\tspeed: 0.1163s/iter; left time: 3596.8290s\n",
      "\titers: 900, epoch: 14 | loss: 0.0727566\n",
      "\tspeed: 0.1163s/iter; left time: 3585.2722s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0758147\n",
      "\tspeed: 0.1118s/iter; left time: 3435.2970s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0972789\n",
      "\tspeed: 0.1163s/iter; left time: 3561.4343s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0837456\n",
      "\tspeed: 0.1154s/iter; left time: 3523.6903s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0850364\n",
      "\tspeed: 0.1158s/iter; left time: 3524.2120s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0846834\n",
      "\tspeed: 0.1161s/iter; left time: 3522.6790s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0751023\n",
      "\tspeed: 0.1159s/iter; left time: 3503.7232s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0751074\n",
      "\tspeed: 0.1163s/iter; left time: 3504.3758s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0639160\n",
      "\tspeed: 0.1175s/iter; left time: 3530.1114s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0911648\n",
      "\tspeed: 0.1161s/iter; left time: 3473.8712s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0872721\n",
      "\tspeed: 0.1185s/iter; left time: 3534.2849s\n",
      "\titers: 2000, epoch: 14 | loss: 0.1031610\n",
      "\tspeed: 0.1161s/iter; left time: 3451.0559s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0678420\n",
      "\tspeed: 0.1161s/iter; left time: 3440.9047s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0803739\n",
      "\tspeed: 0.1187s/iter; left time: 3506.5313s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0830740\n",
      "\tspeed: 0.1170s/iter; left time: 3444.3197s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0877171\n",
      "\tspeed: 0.1175s/iter; left time: 3447.0706s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0903826\n",
      "\tspeed: 0.1154s/iter; left time: 3372.8699s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0659819\n",
      "\tspeed: 0.1173s/iter; left time: 3416.7058s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0935967\n",
      "\tspeed: 0.1173s/iter; left time: 3404.4416s\n",
      "\titers: 2800, epoch: 14 | loss: 0.0878704\n",
      "\tspeed: 0.1159s/iter; left time: 3353.0340s\n",
      "\titers: 2900, epoch: 14 | loss: 0.1039079\n",
      "\tspeed: 0.1180s/iter; left time: 3403.2731s\n",
      "\titers: 3000, epoch: 14 | loss: 0.0661499\n",
      "\tspeed: 0.1169s/iter; left time: 3359.0228s\n",
      "\titers: 3100, epoch: 14 | loss: 0.0741001\n",
      "\tspeed: 0.1170s/iter; left time: 3348.6389s\n",
      "\titers: 3200, epoch: 14 | loss: 0.0819949\n",
      "\tspeed: 0.1123s/iter; left time: 3203.8603s\n",
      "\titers: 3300, epoch: 14 | loss: 0.0826454\n",
      "\tspeed: 0.1056s/iter; left time: 3002.4439s\n",
      "\titers: 3400, epoch: 14 | loss: 0.0878785\n",
      "\tspeed: 0.1002s/iter; left time: 2838.1174s\n",
      "\titers: 3500, epoch: 14 | loss: 0.0842458\n",
      "\tspeed: 0.1091s/iter; left time: 3081.2243s\n",
      "\titers: 3600, epoch: 14 | loss: 0.0751131\n",
      "\tspeed: 0.1157s/iter; left time: 3255.4836s\n",
      "\titers: 3700, epoch: 14 | loss: 0.0962623\n",
      "\tspeed: 0.1110s/iter; left time: 3112.8241s\n",
      "\titers: 3800, epoch: 14 | loss: 0.0715155\n",
      "\tspeed: 0.1150s/iter; left time: 3211.9123s\n",
      "\titers: 3900, epoch: 14 | loss: 0.0696548\n",
      "\tspeed: 0.1142s/iter; left time: 3177.4661s\n",
      "\titers: 4000, epoch: 14 | loss: 0.0932395\n",
      "\tspeed: 0.1043s/iter; left time: 2892.2692s\n",
      "\titers: 4100, epoch: 14 | loss: 0.0887267\n",
      "\tspeed: 0.1020s/iter; left time: 2817.4186s\n",
      "\titers: 4200, epoch: 14 | loss: 0.0927753\n",
      "\tspeed: 0.1067s/iter; left time: 2936.5083s\n",
      "\titers: 4300, epoch: 14 | loss: 0.0820033\n",
      "\tspeed: 0.1059s/iter; left time: 2904.5411s\n",
      "\titers: 4400, epoch: 14 | loss: 0.0966658\n",
      "\tspeed: 0.1029s/iter; left time: 2811.1885s\n",
      "\titers: 4500, epoch: 14 | loss: 0.0918710\n",
      "\tspeed: 0.1504s/iter; left time: 4096.4239s\n",
      "Epoch: 14 cost time: 00h:08m:41.24s\n",
      "Epoch: 14 | Train Loss: 0.0821637 Vali Loss: 0.0901667 Test Loss: 0.0932900\n",
      "Validation loss decreased (0.090452 --> 0.090167).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0781592\n",
      "\tspeed: 2.8223s/iter; left time: 76482.0644s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817208\n",
      "\tspeed: 0.2120s/iter; left time: 5723.8413s\n",
      "\titers: 300, epoch: 15 | loss: 0.0733876\n",
      "\tspeed: 0.2091s/iter; left time: 5625.0584s\n",
      "\titers: 400, epoch: 15 | loss: 0.1039848\n",
      "\tspeed: 0.2054s/iter; left time: 5504.5373s\n",
      "\titers: 500, epoch: 15 | loss: 0.0775597\n",
      "\tspeed: 0.2084s/iter; left time: 5565.1773s\n",
      "\titers: 600, epoch: 15 | loss: 0.0997102\n",
      "\tspeed: 0.2066s/iter; left time: 5496.0954s\n",
      "\titers: 700, epoch: 15 | loss: 0.0608641\n",
      "\tspeed: 0.2041s/iter; left time: 5407.3185s\n",
      "\titers: 800, epoch: 15 | loss: 0.1097342\n",
      "\tspeed: 0.2023s/iter; left time: 5341.8230s\n",
      "\titers: 900, epoch: 15 | loss: 0.0934608\n",
      "\tspeed: 0.2119s/iter; left time: 5572.8130s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0922303\n",
      "\tspeed: 0.2064s/iter; left time: 5407.4919s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0907400\n",
      "\tspeed: 0.2079s/iter; left time: 5426.9764s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0798248\n",
      "\tspeed: 0.2045s/iter; left time: 5316.9901s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0796295\n",
      "\tspeed: 0.2043s/iter; left time: 5291.0223s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0715901\n",
      "\tspeed: 0.2115s/iter; left time: 5457.2872s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0915216\n",
      "\tspeed: 0.2109s/iter; left time: 5420.5268s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0679636\n",
      "\tspeed: 0.2092s/iter; left time: 5356.3357s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0982192\n",
      "\tspeed: 0.2106s/iter; left time: 5370.2612s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0891062\n",
      "\tspeed: 0.2149s/iter; left time: 5457.5333s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0957525\n",
      "\tspeed: 0.2107s/iter; left time: 5330.9234s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0853636\n",
      "\tspeed: 0.2123s/iter; left time: 5350.3660s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0831941\n",
      "\tspeed: 0.2128s/iter; left time: 5341.3730s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0627448\n",
      "\tspeed: 0.2039s/iter; left time: 5096.9805s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0774590\n",
      "\tspeed: 0.2027s/iter; left time: 5048.1416s\n",
      "\titers: 2400, epoch: 15 | loss: 0.1005073\n",
      "\tspeed: 0.2048s/iter; left time: 5077.8762s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0733369\n",
      "\tspeed: 0.2032s/iter; left time: 5020.0269s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0717259\n",
      "\tspeed: 0.2107s/iter; left time: 5183.1453s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0817308\n",
      "\tspeed: 0.2066s/iter; left time: 5060.4979s\n",
      "\titers: 2800, epoch: 15 | loss: 0.0867810\n",
      "\tspeed: 0.2053s/iter; left time: 5009.8421s\n",
      "\titers: 2900, epoch: 15 | loss: 0.0729885\n",
      "\tspeed: 0.2042s/iter; left time: 4961.4739s\n",
      "\titers: 3000, epoch: 15 | loss: 0.0958132\n",
      "\tspeed: 0.2001s/iter; left time: 4841.2194s\n",
      "\titers: 3100, epoch: 15 | loss: 0.0956142\n",
      "\tspeed: 0.2031s/iter; left time: 4893.6308s\n",
      "\titers: 3200, epoch: 15 | loss: 0.0817815\n",
      "\tspeed: 0.2058s/iter; left time: 4937.9433s\n",
      "\titers: 3300, epoch: 15 | loss: 0.0741010\n",
      "\tspeed: 0.2110s/iter; left time: 5041.7216s\n",
      "\titers: 3400, epoch: 15 | loss: 0.0857117\n",
      "\tspeed: 0.2063s/iter; left time: 4908.7933s\n",
      "\titers: 3500, epoch: 15 | loss: 0.0769775\n",
      "\tspeed: 0.2056s/iter; left time: 4873.5452s\n",
      "\titers: 3600, epoch: 15 | loss: 0.0921145\n",
      "\tspeed: 0.2051s/iter; left time: 4841.1853s\n",
      "\titers: 3700, epoch: 15 | loss: 0.0749342\n",
      "\tspeed: 0.2005s/iter; left time: 4710.4518s\n",
      "\titers: 3800, epoch: 15 | loss: 0.0706256\n",
      "\tspeed: 0.2044s/iter; left time: 4783.7027s\n",
      "\titers: 3900, epoch: 15 | loss: 0.0814783\n",
      "\tspeed: 0.2074s/iter; left time: 4832.5463s\n",
      "\titers: 4000, epoch: 15 | loss: 0.0876609\n",
      "\tspeed: 0.2053s/iter; left time: 4761.8819s\n",
      "\titers: 4100, epoch: 15 | loss: 0.0729776\n",
      "\tspeed: 0.2054s/iter; left time: 4745.6866s\n",
      "\titers: 4200, epoch: 15 | loss: 0.0701113\n",
      "\tspeed: 0.2089s/iter; left time: 4804.1412s\n",
      "\titers: 4300, epoch: 15 | loss: 0.0847608\n",
      "\tspeed: 0.2095s/iter; left time: 4797.8228s\n",
      "\titers: 4400, epoch: 15 | loss: 0.0657880\n",
      "\tspeed: 0.2073s/iter; left time: 4725.3065s\n",
      "\titers: 4500, epoch: 15 | loss: 0.0572933\n",
      "\tspeed: 0.2061s/iter; left time: 4677.9496s\n",
      "Epoch: 15 cost time: 00h:15m:38.93s\n",
      "Epoch: 15 | Train Loss: 0.0819345 Vali Loss: 0.0900722 Test Loss: 0.0930771\n",
      "Validation loss decreased (0.090167 --> 0.090072).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0724645\n",
      "\tspeed: 2.8432s/iter; left time: 64158.8405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0767992\n",
      "\tspeed: 0.2079s/iter; left time: 4670.3308s\n",
      "\titers: 300, epoch: 16 | loss: 0.0709932\n",
      "\tspeed: 0.2068s/iter; left time: 4626.0887s\n",
      "\titers: 400, epoch: 16 | loss: 0.0831184\n",
      "\tspeed: 0.2060s/iter; left time: 4586.4097s\n",
      "\titers: 500, epoch: 16 | loss: 0.0966128\n",
      "\tspeed: 0.2034s/iter; left time: 4508.8265s\n",
      "\titers: 600, epoch: 16 | loss: 0.0895692\n",
      "\tspeed: 0.2073s/iter; left time: 4575.3632s\n",
      "\titers: 700, epoch: 16 | loss: 0.0863161\n",
      "\tspeed: 0.1983s/iter; left time: 4356.6491s\n",
      "\titers: 800, epoch: 16 | loss: 0.0756211\n",
      "\tspeed: 0.2050s/iter; left time: 4482.5904s\n",
      "\titers: 900, epoch: 16 | loss: 0.0764739\n",
      "\tspeed: 0.2092s/iter; left time: 4552.5830s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0625793\n",
      "\tspeed: 0.2033s/iter; left time: 4405.7471s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0810612\n",
      "\tspeed: 0.2096s/iter; left time: 4520.4336s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0767624\n",
      "\tspeed: 0.2099s/iter; left time: 4505.1103s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0753944\n",
      "\tspeed: 0.2261s/iter; left time: 4829.9879s\n",
      "\titers: 1400, epoch: 16 | loss: 0.1056277\n",
      "\tspeed: 0.2113s/iter; left time: 4493.9029s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0988726\n",
      "\tspeed: 0.2050s/iter; left time: 4339.6184s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0924941\n",
      "\tspeed: 0.1992s/iter; left time: 4196.0328s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0742520\n",
      "\tspeed: 0.2005s/iter; left time: 4204.2425s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0763841\n",
      "\tspeed: 0.2055s/iter; left time: 4288.9494s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0803828\n",
      "\tspeed: 0.2053s/iter; left time: 4262.2218s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0858300\n",
      "\tspeed: 0.2081s/iter; left time: 4300.9927s\n",
      "\titers: 2100, epoch: 16 | loss: 0.1063153\n",
      "\tspeed: 0.2060s/iter; left time: 4235.9114s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0874704\n",
      "\tspeed: 0.2082s/iter; left time: 4260.4045s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0813350\n",
      "\tspeed: 0.2088s/iter; left time: 4253.2919s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0635194\n",
      "\tspeed: 0.2006s/iter; left time: 4065.5371s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0828632\n",
      "\tspeed: 0.2080s/iter; left time: 4195.1115s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0861115\n",
      "\tspeed: 0.2107s/iter; left time: 4228.1337s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0758510\n",
      "\tspeed: 0.2032s/iter; left time: 4056.4580s\n",
      "\titers: 2800, epoch: 16 | loss: 0.0841146\n",
      "\tspeed: 0.2007s/iter; left time: 3986.2553s\n",
      "\titers: 2900, epoch: 16 | loss: 0.0860678\n",
      "\tspeed: 0.2042s/iter; left time: 4036.6045s\n",
      "\titers: 3000, epoch: 16 | loss: 0.0766806\n",
      "\tspeed: 0.1981s/iter; left time: 3895.3242s\n",
      "\titers: 3100, epoch: 16 | loss: 0.0732827\n",
      "\tspeed: 0.2047s/iter; left time: 4005.8632s\n",
      "\titers: 3200, epoch: 16 | loss: 0.0707445\n",
      "\tspeed: 0.1998s/iter; left time: 3889.9151s\n",
      "\titers: 3300, epoch: 16 | loss: 0.0873484\n",
      "\tspeed: 0.2016s/iter; left time: 3903.3641s\n",
      "\titers: 3400, epoch: 16 | loss: 0.0758336\n",
      "\tspeed: 0.1937s/iter; left time: 3730.8910s\n",
      "\titers: 3500, epoch: 16 | loss: 0.0919489\n",
      "\tspeed: 0.1988s/iter; left time: 3809.7119s\n",
      "\titers: 3600, epoch: 16 | loss: 0.0717335\n",
      "\tspeed: 0.1965s/iter; left time: 3745.7750s\n",
      "\titers: 3700, epoch: 16 | loss: 0.0677496\n",
      "\tspeed: 0.2005s/iter; left time: 3801.9967s\n",
      "\titers: 3800, epoch: 16 | loss: 0.0932850\n",
      "\tspeed: 0.2034s/iter; left time: 3837.5194s\n",
      "\titers: 3900, epoch: 16 | loss: 0.0753954\n",
      "\tspeed: 0.1967s/iter; left time: 3690.3947s\n",
      "\titers: 4000, epoch: 16 | loss: 0.0843962\n",
      "\tspeed: 0.2013s/iter; left time: 3757.8746s\n",
      "\titers: 4100, epoch: 16 | loss: 0.0828186\n",
      "\tspeed: 0.1992s/iter; left time: 3698.4082s\n",
      "\titers: 4200, epoch: 16 | loss: 0.0648547\n",
      "\tspeed: 0.1951s/iter; left time: 3602.4349s\n",
      "\titers: 4300, epoch: 16 | loss: 0.0725025\n",
      "\tspeed: 0.2016s/iter; left time: 3703.4556s\n",
      "\titers: 4400, epoch: 16 | loss: 0.0648678\n",
      "\tspeed: 0.2099s/iter; left time: 3834.2663s\n",
      "\titers: 4500, epoch: 16 | loss: 0.0682965\n",
      "\tspeed: 0.2090s/iter; left time: 3795.9003s\n",
      "Epoch: 16 cost time: 00h:15m:26.99s\n",
      "Epoch: 16 | Train Loss: 0.0814862 Vali Loss: 0.0900890 Test Loss: 0.0928981\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0779907\n",
      "\tspeed: 2.8336s/iter; left time: 51098.5405s\n",
      "\titers: 200, epoch: 17 | loss: 0.0804352\n",
      "\tspeed: 0.2036s/iter; left time: 3651.9649s\n",
      "\titers: 300, epoch: 17 | loss: 0.0810385\n",
      "\tspeed: 0.2085s/iter; left time: 3718.7163s\n",
      "\titers: 400, epoch: 17 | loss: 0.0795031\n",
      "\tspeed: 0.2053s/iter; left time: 3640.1134s\n",
      "\titers: 500, epoch: 17 | loss: 0.0691069\n",
      "\tspeed: 0.2082s/iter; left time: 3670.9166s\n",
      "\titers: 600, epoch: 17 | loss: 0.0998175\n",
      "\tspeed: 0.2103s/iter; left time: 3687.7238s\n",
      "\titers: 700, epoch: 17 | loss: 0.0868025\n",
      "\tspeed: 0.2083s/iter; left time: 3630.5217s\n",
      "\titers: 800, epoch: 17 | loss: 0.0653060\n",
      "\tspeed: 0.2044s/iter; left time: 3543.2673s\n",
      "\titers: 900, epoch: 17 | loss: 0.0652221\n",
      "\tspeed: 0.2112s/iter; left time: 3638.8770s\n",
      "\titers: 1000, epoch: 17 | loss: 0.1059849\n",
      "\tspeed: 0.2070s/iter; left time: 3546.5671s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0640589\n",
      "\tspeed: 0.2054s/iter; left time: 3498.1711s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0844095\n",
      "\tspeed: 0.2092s/iter; left time: 3542.7772s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0829859\n",
      "\tspeed: 0.2079s/iter; left time: 3499.3629s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0754173\n",
      "\tspeed: 0.2081s/iter; left time: 3482.4673s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0830839\n",
      "\tspeed: 0.2082s/iter; left time: 3463.4556s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0756477\n",
      "\tspeed: 0.2103s/iter; left time: 3476.3702s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0747706\n",
      "\tspeed: 0.2117s/iter; left time: 3478.7441s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0718630\n",
      "\tspeed: 0.2074s/iter; left time: 3387.7211s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0996768\n",
      "\tspeed: 0.2020s/iter; left time: 3279.4076s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0655960\n",
      "\tspeed: 0.2011s/iter; left time: 3244.7255s\n",
      "\titers: 2100, epoch: 17 | loss: 0.1009256\n",
      "\tspeed: 0.2104s/iter; left time: 3374.0252s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0617915\n",
      "\tspeed: 0.2047s/iter; left time: 3261.7863s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0757957\n",
      "\tspeed: 0.2080s/iter; left time: 3293.2961s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0729246\n",
      "\tspeed: 0.2056s/iter; left time: 3235.3514s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0803725\n",
      "\tspeed: 0.2055s/iter; left time: 3212.3184s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0918309\n",
      "\tspeed: 0.2104s/iter; left time: 3267.7813s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0632335\n",
      "\tspeed: 0.2044s/iter; left time: 3153.9923s\n",
      "\titers: 2800, epoch: 17 | loss: 0.0943785\n",
      "\tspeed: 0.2067s/iter; left time: 3169.0661s\n",
      "\titers: 2900, epoch: 17 | loss: 0.0760062\n",
      "\tspeed: 0.2097s/iter; left time: 3193.7571s\n",
      "\titers: 3000, epoch: 17 | loss: 0.0784810\n",
      "\tspeed: 0.2106s/iter; left time: 3186.5442s\n",
      "\titers: 3100, epoch: 17 | loss: 0.1016624\n",
      "\tspeed: 0.2089s/iter; left time: 3140.0077s\n",
      "\titers: 3200, epoch: 17 | loss: 0.0930956\n",
      "\tspeed: 0.1992s/iter; left time: 2975.0185s\n",
      "\titers: 3300, epoch: 17 | loss: 0.0864676\n",
      "\tspeed: 0.2146s/iter; left time: 3182.6882s\n",
      "\titers: 3400, epoch: 17 | loss: 0.1175842\n",
      "\tspeed: 0.2141s/iter; left time: 3154.6536s\n",
      "\titers: 3500, epoch: 17 | loss: 0.0861637\n",
      "\tspeed: 0.2090s/iter; left time: 3057.6854s\n",
      "\titers: 3600, epoch: 17 | loss: 0.0755142\n",
      "\tspeed: 0.2074s/iter; left time: 3014.4588s\n",
      "\titers: 3700, epoch: 17 | loss: 0.0779291\n",
      "\tspeed: 0.2050s/iter; left time: 2959.3447s\n",
      "\titers: 3800, epoch: 17 | loss: 0.0678985\n",
      "\tspeed: 0.2100s/iter; left time: 3010.5441s\n",
      "\titers: 3900, epoch: 17 | loss: 0.0767063\n",
      "\tspeed: 0.2067s/iter; left time: 2941.8799s\n",
      "\titers: 4000, epoch: 17 | loss: 0.0977842\n",
      "\tspeed: 0.2091s/iter; left time: 2954.8832s\n",
      "\titers: 4100, epoch: 17 | loss: 0.0707132\n",
      "\tspeed: 0.2186s/iter; left time: 3067.0416s\n",
      "\titers: 4200, epoch: 17 | loss: 0.0659148\n",
      "\tspeed: 0.2256s/iter; left time: 3143.2843s\n",
      "\titers: 4300, epoch: 17 | loss: 0.0854227\n",
      "\tspeed: 0.2073s/iter; left time: 2868.1639s\n",
      "\titers: 4400, epoch: 17 | loss: 0.0686285\n",
      "\tspeed: 0.2109s/iter; left time: 2896.4402s\n",
      "\titers: 4500, epoch: 17 | loss: 0.0824729\n",
      "\tspeed: 0.2091s/iter; left time: 2851.2364s\n",
      "Epoch: 17 cost time: 00h:15m:44.61s\n",
      "Epoch: 17 | Train Loss: 0.0812407 Vali Loss: 0.0900395 Test Loss: 0.0928835\n",
      "Validation loss decreased (0.090072 --> 0.090040).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0795694\n",
      "\tspeed: 2.9009s/iter; left time: 39162.1895s\n",
      "\titers: 200, epoch: 18 | loss: 0.0838256\n",
      "\tspeed: 0.2086s/iter; left time: 2795.5966s\n",
      "\titers: 300, epoch: 18 | loss: 0.0811552\n",
      "\tspeed: 0.2036s/iter; left time: 2707.2805s\n",
      "\titers: 400, epoch: 18 | loss: 0.0848344\n",
      "\tspeed: 0.2011s/iter; left time: 2654.4536s\n",
      "\titers: 500, epoch: 18 | loss: 0.0849858\n",
      "\tspeed: 0.2107s/iter; left time: 2759.9852s\n",
      "\titers: 600, epoch: 18 | loss: 0.1082629\n",
      "\tspeed: 0.2046s/iter; left time: 2659.7627s\n",
      "\titers: 700, epoch: 18 | loss: 0.0725619\n",
      "\tspeed: 0.2071s/iter; left time: 2671.4557s\n",
      "\titers: 800, epoch: 18 | loss: 0.0965610\n",
      "\tspeed: 0.2076s/iter; left time: 2656.9527s\n",
      "\titers: 900, epoch: 18 | loss: 0.0722590\n",
      "\tspeed: 0.2098s/iter; left time: 2664.5000s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0755065\n",
      "\tspeed: 0.2118s/iter; left time: 2668.7763s\n",
      "\titers: 1100, epoch: 18 | loss: 0.1057993\n",
      "\tspeed: 0.2077s/iter; left time: 2596.6814s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0953928\n",
      "\tspeed: 0.2061s/iter; left time: 2555.4371s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0883500\n",
      "\tspeed: 0.2075s/iter; left time: 2551.7381s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0757185\n",
      "\tspeed: 0.2083s/iter; left time: 2541.2731s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0573659\n",
      "\tspeed: 0.2122s/iter; left time: 2568.1037s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0921795\n",
      "\tspeed: 0.2088s/iter; left time: 2506.0242s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0920135\n",
      "\tspeed: 0.2089s/iter; left time: 2485.9251s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0972895\n",
      "\tspeed: 0.2049s/iter; left time: 2418.2577s\n",
      "\titers: 1900, epoch: 18 | loss: 0.1059940\n",
      "\tspeed: 0.2045s/iter; left time: 2393.1070s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0868188\n",
      "\tspeed: 0.2082s/iter; left time: 2415.0229s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0829052\n",
      "\tspeed: 0.2059s/iter; left time: 2367.6520s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0690750\n",
      "\tspeed: 0.2045s/iter; left time: 2331.1394s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0917492\n",
      "\tspeed: 0.2042s/iter; left time: 2307.6904s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0779928\n",
      "\tspeed: 0.2039s/iter; left time: 2284.0471s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0669884\n",
      "\tspeed: 0.2084s/iter; left time: 2312.8528s\n",
      "\titers: 2600, epoch: 18 | loss: 0.1034114\n",
      "\tspeed: 0.2071s/iter; left time: 2278.0434s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0774817\n",
      "\tspeed: 0.2041s/iter; left time: 2224.9345s\n",
      "\titers: 2800, epoch: 18 | loss: 0.1134784\n",
      "\tspeed: 0.2062s/iter; left time: 2226.8521s\n",
      "\titers: 2900, epoch: 18 | loss: 0.0700959\n",
      "\tspeed: 0.2083s/iter; left time: 2229.2835s\n",
      "\titers: 3000, epoch: 18 | loss: 0.0714843\n",
      "\tspeed: 0.2094s/iter; left time: 2219.3680s\n",
      "\titers: 3100, epoch: 18 | loss: 0.0604120\n",
      "\tspeed: 0.2001s/iter; left time: 2100.6559s\n",
      "\titers: 3200, epoch: 18 | loss: 0.0796753\n",
      "\tspeed: 0.1967s/iter; left time: 2045.8406s\n",
      "\titers: 3300, epoch: 18 | loss: 0.0790297\n",
      "\tspeed: 0.2042s/iter; left time: 2102.8270s\n",
      "\titers: 3400, epoch: 18 | loss: 0.0765088\n",
      "\tspeed: 0.1921s/iter; left time: 1959.0332s\n",
      "\titers: 3500, epoch: 18 | loss: 0.0811823\n",
      "\tspeed: 0.2033s/iter; left time: 2053.4265s\n",
      "\titers: 3600, epoch: 18 | loss: 0.0719975\n",
      "\tspeed: 0.2044s/iter; left time: 2044.1146s\n",
      "\titers: 3700, epoch: 18 | loss: 0.0851909\n",
      "\tspeed: 0.2109s/iter; left time: 2088.3015s\n",
      "\titers: 3800, epoch: 18 | loss: 0.0555599\n",
      "\tspeed: 0.2112s/iter; left time: 2070.1878s\n",
      "\titers: 3900, epoch: 18 | loss: 0.0767860\n",
      "\tspeed: 0.2089s/iter; left time: 2026.0258s\n",
      "\titers: 4000, epoch: 18 | loss: 0.0693482\n",
      "\tspeed: 0.2009s/iter; left time: 1928.8345s\n",
      "\titers: 4100, epoch: 18 | loss: 0.0781907\n",
      "\tspeed: 0.2102s/iter; left time: 1997.2952s\n",
      "\titers: 4200, epoch: 18 | loss: 0.1100252\n",
      "\tspeed: 0.2051s/iter; left time: 1928.0051s\n",
      "\titers: 4300, epoch: 18 | loss: 0.0990154\n",
      "\tspeed: 0.2101s/iter; left time: 1953.7715s\n",
      "\titers: 4400, epoch: 18 | loss: 0.0885110\n",
      "\tspeed: 0.2044s/iter; left time: 1880.2665s\n",
      "\titers: 4500, epoch: 18 | loss: 0.0706306\n",
      "\tspeed: 0.2129s/iter; left time: 1937.6158s\n",
      "Epoch: 18 cost time: 00h:15m:36.12s\n",
      "Epoch: 18 | Train Loss: 0.0809277 Vali Loss: 0.0905383 Test Loss: 0.0940927\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0678311\n",
      "\tspeed: 2.8291s/iter; left time: 25368.0979s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636820\n",
      "\tspeed: 0.2058s/iter; left time: 1824.5938s\n",
      "\titers: 300, epoch: 19 | loss: 0.0705757\n",
      "\tspeed: 0.2093s/iter; left time: 1835.0891s\n",
      "\titers: 400, epoch: 19 | loss: 0.0886685\n",
      "\tspeed: 0.2105s/iter; left time: 1824.3555s\n",
      "\titers: 500, epoch: 19 | loss: 0.0733912\n",
      "\tspeed: 0.2157s/iter; left time: 1848.0562s\n",
      "\titers: 600, epoch: 19 | loss: 0.0603996\n",
      "\tspeed: 0.2040s/iter; left time: 1727.0098s\n",
      "\titers: 700, epoch: 19 | loss: 0.0834332\n",
      "\tspeed: 0.2028s/iter; left time: 1696.4689s\n",
      "\titers: 800, epoch: 19 | loss: 0.0668500\n",
      "\tspeed: 0.2047s/iter; left time: 1692.3785s\n",
      "\titers: 900, epoch: 19 | loss: 0.0698706\n",
      "\tspeed: 0.1954s/iter; left time: 1595.6778s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0701428\n",
      "\tspeed: 0.2040s/iter; left time: 1646.0556s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0967482\n",
      "\tspeed: 0.2234s/iter; left time: 1779.9832s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0881656\n",
      "\tspeed: 0.2114s/iter; left time: 1663.1216s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0794173\n",
      "\tspeed: 0.2035s/iter; left time: 1580.4837s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0853789\n",
      "\tspeed: 0.1992s/iter; left time: 1527.6462s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0708005\n",
      "\tspeed: 0.2021s/iter; left time: 1529.4352s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0919588\n",
      "\tspeed: 0.2018s/iter; left time: 1506.5494s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0928475\n",
      "\tspeed: 0.2037s/iter; left time: 1500.9408s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0829979\n",
      "\tspeed: 0.1955s/iter; left time: 1420.5680s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0985053\n",
      "\tspeed: 0.2010s/iter; left time: 1440.8036s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0800848\n",
      "\tspeed: 0.2002s/iter; left time: 1415.0442s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0809004\n",
      "\tspeed: 0.2015s/iter; left time: 1403.9233s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0806112\n",
      "\tspeed: 0.2001s/iter; left time: 1373.9345s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0761665\n",
      "\tspeed: 0.1971s/iter; left time: 1333.7263s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0870542\n",
      "\tspeed: 0.1988s/iter; left time: 1325.3090s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0851789\n",
      "\tspeed: 0.2069s/iter; left time: 1358.4801s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0812989\n",
      "\tspeed: 0.2059s/iter; left time: 1331.5937s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0844561\n",
      "\tspeed: 0.2068s/iter; left time: 1316.6312s\n",
      "\titers: 2800, epoch: 19 | loss: 0.0822394\n",
      "\tspeed: 0.2086s/iter; left time: 1307.5242s\n",
      "\titers: 2900, epoch: 19 | loss: 0.0910384\n",
      "\tspeed: 0.2064s/iter; left time: 1273.0267s\n",
      "\titers: 3000, epoch: 19 | loss: 0.0712404\n",
      "\tspeed: 0.2090s/iter; left time: 1268.2191s\n",
      "\titers: 3100, epoch: 19 | loss: 0.0772290\n",
      "\tspeed: 0.2059s/iter; left time: 1228.7986s\n",
      "\titers: 3200, epoch: 19 | loss: 0.0868724\n",
      "\tspeed: 0.2016s/iter; left time: 1183.0231s\n",
      "\titers: 3300, epoch: 19 | loss: 0.0636199\n",
      "\tspeed: 0.2023s/iter; left time: 1166.9013s\n",
      "\titers: 3400, epoch: 19 | loss: 0.0758771\n",
      "\tspeed: 0.2002s/iter; left time: 1134.6117s\n",
      "\titers: 3500, epoch: 19 | loss: 0.1098609\n",
      "\tspeed: 0.1993s/iter; left time: 1109.3235s\n",
      "\titers: 3600, epoch: 19 | loss: 0.0684652\n",
      "\tspeed: 0.2043s/iter; left time: 1116.8297s\n",
      "\titers: 3700, epoch: 19 | loss: 0.0755343\n",
      "\tspeed: 0.2024s/iter; left time: 1086.2647s\n",
      "\titers: 3800, epoch: 19 | loss: 0.0831554\n",
      "\tspeed: 0.2001s/iter; left time: 1053.8952s\n",
      "\titers: 3900, epoch: 19 | loss: 0.0682368\n",
      "\tspeed: 0.2000s/iter; left time: 1033.4583s\n",
      "\titers: 4000, epoch: 19 | loss: 0.0710025\n",
      "\tspeed: 0.2007s/iter; left time: 1016.7533s\n",
      "\titers: 4100, epoch: 19 | loss: 0.0701880\n",
      "\tspeed: 0.2037s/iter; left time: 1011.6413s\n",
      "\titers: 4200, epoch: 19 | loss: 0.0823526\n",
      "\tspeed: 0.1979s/iter; left time: 963.2654s\n",
      "\titers: 4300, epoch: 19 | loss: 0.0952930\n",
      "\tspeed: 0.2056s/iter; left time: 980.0332s\n",
      "\titers: 4400, epoch: 19 | loss: 0.1095706\n",
      "\tspeed: 0.2009s/iter; left time: 937.5569s\n",
      "\titers: 4500, epoch: 19 | loss: 0.0967065\n",
      "\tspeed: 0.1933s/iter; left time: 882.7541s\n",
      "Epoch: 19 cost time: 00h:15m:23.36s\n",
      "Epoch: 19 | Train Loss: 0.0806650 Vali Loss: 0.0901411 Test Loss: 0.0933280\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0760543\n",
      "\tspeed: 2.8271s/iter; left time: 12535.2177s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744823\n",
      "\tspeed: 0.2029s/iter; left time: 879.1754s\n",
      "\titers: 300, epoch: 20 | loss: 0.0709615\n",
      "\tspeed: 0.2118s/iter; left time: 896.7642s\n",
      "\titers: 400, epoch: 20 | loss: 0.0833951\n",
      "\tspeed: 0.2103s/iter; left time: 869.5154s\n",
      "\titers: 500, epoch: 20 | loss: 0.0606842\n",
      "\tspeed: 0.2085s/iter; left time: 841.1313s\n",
      "\titers: 600, epoch: 20 | loss: 0.0635488\n",
      "\tspeed: 0.2060s/iter; left time: 810.5230s\n",
      "\titers: 700, epoch: 20 | loss: 0.0798145\n",
      "\tspeed: 0.2016s/iter; left time: 772.7893s\n",
      "\titers: 800, epoch: 20 | loss: 0.0853463\n",
      "\tspeed: 0.2062s/iter; left time: 770.1007s\n",
      "\titers: 900, epoch: 20 | loss: 0.0578192\n",
      "\tspeed: 0.2108s/iter; left time: 766.0542s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0921262\n",
      "\tspeed: 0.2064s/iter; left time: 729.3396s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0867362\n",
      "\tspeed: 0.2096s/iter; left time: 719.6436s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0892997\n",
      "\tspeed: 0.2078s/iter; left time: 692.7852s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0832107\n",
      "\tspeed: 0.2015s/iter; left time: 651.5240s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0918721\n",
      "\tspeed: 0.2131s/iter; left time: 667.7509s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0806802\n",
      "\tspeed: 0.2074s/iter; left time: 629.1552s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0931721\n",
      "\tspeed: 0.2089s/iter; left time: 612.9422s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0625069\n",
      "\tspeed: 0.2089s/iter; left time: 591.9393s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0801823\n",
      "\tspeed: 0.2081s/iter; left time: 569.0584s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0904002\n",
      "\tspeed: 0.2047s/iter; left time: 539.2312s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0669209\n",
      "\tspeed: 0.2103s/iter; left time: 532.7918s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0685574\n",
      "\tspeed: 0.2053s/iter; left time: 499.7197s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0820071\n",
      "\tspeed: 0.2023s/iter; left time: 472.0549s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0823876\n",
      "\tspeed: 0.2063s/iter; left time: 460.8569s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0704435\n",
      "\tspeed: 0.2083s/iter; left time: 444.5805s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0991650\n",
      "\tspeed: 0.2052s/iter; left time: 417.3092s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0949979\n",
      "\tspeed: 0.2070s/iter; left time: 400.4148s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0615428\n",
      "\tspeed: 0.2060s/iter; left time: 377.8297s\n",
      "\titers: 2800, epoch: 20 | loss: 0.0940507\n",
      "\tspeed: 0.2083s/iter; left time: 361.1888s\n",
      "\titers: 2900, epoch: 20 | loss: 0.1000341\n",
      "\tspeed: 0.2112s/iter; left time: 345.0975s\n",
      "\titers: 3000, epoch: 20 | loss: 0.0742691\n",
      "\tspeed: 0.2128s/iter; left time: 326.4433s\n",
      "\titers: 3100, epoch: 20 | loss: 0.0858070\n",
      "\tspeed: 0.2054s/iter; left time: 294.5184s\n",
      "\titers: 3200, epoch: 20 | loss: 0.0774105\n",
      "\tspeed: 0.2063s/iter; left time: 275.1544s\n",
      "\titers: 3300, epoch: 20 | loss: 0.0847270\n",
      "\tspeed: 0.2076s/iter; left time: 256.1494s\n",
      "\titers: 3400, epoch: 20 | loss: 0.0793911\n",
      "\tspeed: 0.1992s/iter; left time: 225.9193s\n",
      "\titers: 3500, epoch: 20 | loss: 0.0810547\n",
      "\tspeed: 0.2029s/iter; left time: 209.7782s\n",
      "\titers: 3600, epoch: 20 | loss: 0.0906097\n",
      "\tspeed: 0.1948s/iter; left time: 181.9836s\n",
      "\titers: 3700, epoch: 20 | loss: 0.0921640\n",
      "\tspeed: 0.2034s/iter; left time: 169.6410s\n",
      "\titers: 3800, epoch: 20 | loss: 0.0885331\n",
      "\tspeed: 0.2057s/iter; left time: 150.9737s\n",
      "\titers: 3900, epoch: 20 | loss: 0.0753125\n",
      "\tspeed: 0.2033s/iter; left time: 128.8854s\n",
      "\titers: 4000, epoch: 20 | loss: 0.0635969\n",
      "\tspeed: 0.2251s/iter; left time: 120.2038s\n",
      "\titers: 4100, epoch: 20 | loss: 0.0736005\n",
      "\tspeed: 0.2192s/iter; left time: 95.1326s\n",
      "\titers: 4200, epoch: 20 | loss: 0.0756893\n",
      "\tspeed: 0.2069s/iter; left time: 69.1063s\n",
      "\titers: 4300, epoch: 20 | loss: 0.0709732\n",
      "\tspeed: 0.2072s/iter; left time: 48.4940s\n",
      "\titers: 4400, epoch: 20 | loss: 0.0741631\n",
      "\tspeed: 0.1969s/iter; left time: 26.3822s\n",
      "\titers: 4500, epoch: 20 | loss: 0.0897707\n",
      "\tspeed: 0.2057s/iter; left time: 6.9946s\n",
      "Epoch: 20 cost time: 00h:15m:37.85s\n",
      "Epoch: 20 | Train Loss: 0.0803315 Vali Loss: 0.0891302 Test Loss: 0.0921191\n",
      "Validation loss decreased (0.090040 --> 0.089130).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.022726772353053093, rmse:0.15075401961803436, mae:0.09211910516023636, rse:0.5324346423149109\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 24: 04h:22m:42.83s\n",
      "\n",
      "Intermediate time for DE: 04h:22m:42.83s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 05:21:21,820] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 05:21:22,942] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 05:21:24,017] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 05:21:24,021] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 05:21:24,388] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,519] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,521] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 05:21:24,687] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.34 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 05:21:24,689] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1c6d0db6d0>\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1546985\n",
      "\tspeed: 0.2596s/iter; left time: 23513.6039s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291576\n",
      "\tspeed: 0.2112s/iter; left time: 19107.4209s\n",
      "\titers: 300, epoch: 1 | loss: 0.1251203\n",
      "\tspeed: 0.2173s/iter; left time: 19632.7933s\n",
      "\titers: 400, epoch: 1 | loss: 0.1450771\n",
      "\tspeed: 0.2129s/iter; left time: 19217.7231s\n",
      "\titers: 500, epoch: 1 | loss: 0.1154369\n",
      "\tspeed: 0.2128s/iter; left time: 19190.4734s\n",
      "\titers: 600, epoch: 1 | loss: 0.1156310\n",
      "\tspeed: 0.2168s/iter; left time: 19521.3204s\n",
      "\titers: 700, epoch: 1 | loss: 0.0748791\n",
      "\tspeed: 0.2180s/iter; left time: 19609.8554s\n",
      "\titers: 800, epoch: 1 | loss: 0.0951292\n",
      "\tspeed: 0.2105s/iter; left time: 18911.7193s\n",
      "\titers: 900, epoch: 1 | loss: 0.0913136\n",
      "\tspeed: 0.2157s/iter; left time: 19357.6229s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0939970\n",
      "\tspeed: 0.2104s/iter; left time: 18864.9255s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1140969\n",
      "\tspeed: 0.2136s/iter; left time: 19126.0187s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1022235\n",
      "\tspeed: 0.2160s/iter; left time: 19323.3010s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1111957\n",
      "\tspeed: 0.2104s/iter; left time: 18797.3674s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0884303\n",
      "\tspeed: 0.2082s/iter; left time: 18584.9150s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0778883\n",
      "\tspeed: 0.2110s/iter; left time: 18815.6921s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0953508\n",
      "\tspeed: 0.2122s/iter; left time: 18902.2907s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0806738\n",
      "\tspeed: 0.2096s/iter; left time: 18649.7251s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1003466\n",
      "\tspeed: 0.2133s/iter; left time: 18957.9592s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0863623\n",
      "\tspeed: 0.2215s/iter; left time: 19663.8832s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0829440\n",
      "\tspeed: 0.2146s/iter; left time: 19030.7614s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0841652\n",
      "\tspeed: 0.2099s/iter; left time: 18588.2588s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0827532\n",
      "\tspeed: 0.2146s/iter; left time: 18983.2339s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0860752\n",
      "\tspeed: 0.2138s/iter; left time: 18892.4743s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0947314\n",
      "\tspeed: 0.2123s/iter; left time: 18736.8141s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1185496\n",
      "\tspeed: 0.2159s/iter; left time: 19031.1048s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1035847\n",
      "\tspeed: 0.2222s/iter; left time: 19568.5601s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0843291\n",
      "\tspeed: 0.2135s/iter; left time: 18775.7073s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0796181\n",
      "\tspeed: 0.2109s/iter; left time: 18527.3093s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1128176\n",
      "\tspeed: 0.2083s/iter; left time: 18277.6396s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0965046\n",
      "\tspeed: 0.2138s/iter; left time: 18740.1358s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0985267\n",
      "\tspeed: 0.2158s/iter; left time: 18898.2363s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0976374\n",
      "\tspeed: 0.2127s/iter; left time: 18603.3204s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1047641\n",
      "\tspeed: 0.2155s/iter; left time: 18827.4525s\n",
      "\titers: 3400, epoch: 1 | loss: 0.0967885\n",
      "\tspeed: 0.2118s/iter; left time: 18482.1399s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1069563\n",
      "\tspeed: 0.2097s/iter; left time: 18277.4770s\n",
      "\titers: 3600, epoch: 1 | loss: 0.0921024\n",
      "\tspeed: 0.2117s/iter; left time: 18433.2546s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0950448\n",
      "\tspeed: 0.2166s/iter; left time: 18838.3472s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0770328\n",
      "\tspeed: 0.2239s/iter; left time: 19444.9302s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0866609\n",
      "\tspeed: 0.2177s/iter; left time: 18888.8326s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1140960\n",
      "\tspeed: 0.2150s/iter; left time: 18634.6285s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0745960\n",
      "\tspeed: 0.2126s/iter; left time: 18403.7787s\n",
      "\titers: 4200, epoch: 1 | loss: 0.0948094\n",
      "\tspeed: 0.2160s/iter; left time: 18672.9990s\n",
      "\titers: 4300, epoch: 1 | loss: 0.0925089\n",
      "\tspeed: 0.2164s/iter; left time: 18690.5643s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0839602\n",
      "\tspeed: 0.2203s/iter; left time: 19001.7579s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0861143\n",
      "\tspeed: 0.2183s/iter; left time: 18808.0370s\n",
      "Epoch: 1 cost time: 00h:16m:12.46s\n",
      "Epoch: 1 | Train Loss: 0.1012164 Vali Loss: 0.0977652 Test Loss: 0.1118243\n",
      "Validation loss decreased (inf --> 0.097765).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0937784\n",
      "\tspeed: 3.1437s/iter; left time: 270449.9509s\n",
      "\titers: 200, epoch: 2 | loss: 0.0925049\n",
      "\tspeed: 0.2042s/iter; left time: 17547.8746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0792080\n",
      "\tspeed: 0.2054s/iter; left time: 17633.3070s\n",
      "\titers: 400, epoch: 2 | loss: 0.1067672\n",
      "\tspeed: 0.2102s/iter; left time: 18020.7759s\n",
      "\titers: 500, epoch: 2 | loss: 0.0805422\n",
      "\tspeed: 0.2076s/iter; left time: 17778.1836s\n",
      "\titers: 600, epoch: 2 | loss: 0.0674901\n",
      "\tspeed: 0.2049s/iter; left time: 17528.9570s\n",
      "\titers: 700, epoch: 2 | loss: 0.0926194\n",
      "\tspeed: 0.2104s/iter; left time: 17970.9439s\n",
      "\titers: 800, epoch: 2 | loss: 0.0842856\n",
      "\tspeed: 0.2088s/iter; left time: 17813.8312s\n",
      "\titers: 900, epoch: 2 | loss: 0.0672636\n",
      "\tspeed: 0.2050s/iter; left time: 17472.1212s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0877642\n",
      "\tspeed: 0.2079s/iter; left time: 17694.7509s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0978035\n",
      "\tspeed: 0.2097s/iter; left time: 17826.8112s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0698678\n",
      "\tspeed: 0.2059s/iter; left time: 17486.0444s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0882811\n",
      "\tspeed: 0.2050s/iter; left time: 17385.9232s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0911639\n",
      "\tspeed: 0.2088s/iter; left time: 17693.4504s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0743035\n",
      "\tspeed: 0.2045s/iter; left time: 17307.9439s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0864886\n",
      "\tspeed: 0.2051s/iter; left time: 17340.5950s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0971036\n",
      "\tspeed: 0.2081s/iter; left time: 17567.2209s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0993157\n",
      "\tspeed: 0.2041s/iter; left time: 17213.8291s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0668235\n",
      "\tspeed: 0.2090s/iter; left time: 17605.6554s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0908750\n",
      "\tspeed: 0.2090s/iter; left time: 17586.0225s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0931186\n",
      "\tspeed: 0.2036s/iter; left time: 17108.0480s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0834960\n",
      "\tspeed: 0.2127s/iter; left time: 17851.3031s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0740703\n",
      "\tspeed: 0.2062s/iter; left time: 17287.2931s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0833978\n",
      "\tspeed: 0.2071s/iter; left time: 17342.7146s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0961250\n",
      "\tspeed: 0.2071s/iter; left time: 17319.5875s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1048870\n",
      "\tspeed: 0.2068s/iter; left time: 17277.2299s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0799315\n",
      "\tspeed: 0.2021s/iter; left time: 16862.5321s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0876554\n",
      "\tspeed: 0.1995s/iter; left time: 16628.0431s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0985768\n",
      "\tspeed: 0.1961s/iter; left time: 16319.7431s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0851371\n",
      "\tspeed: 0.2087s/iter; left time: 17348.0643s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0835325\n",
      "\tspeed: 0.2039s/iter; left time: 16929.3412s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0846814\n",
      "\tspeed: 0.2032s/iter; left time: 16853.4020s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1017231\n",
      "\tspeed: 0.2067s/iter; left time: 17116.8465s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0944130\n",
      "\tspeed: 0.2054s/iter; left time: 16990.1746s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0778886\n",
      "\tspeed: 0.2026s/iter; left time: 16744.3527s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0969510\n",
      "\tspeed: 0.2104s/iter; left time: 17361.0954s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1037317\n",
      "\tspeed: 0.2130s/iter; left time: 17557.4597s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0846262\n",
      "\tspeed: 0.2078s/iter; left time: 17110.1884s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0849839\n",
      "\tspeed: 0.2077s/iter; left time: 17077.5685s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0747749\n",
      "\tspeed: 0.2093s/iter; left time: 17192.3186s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0879758\n",
      "\tspeed: 0.2073s/iter; left time: 17001.2923s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0780901\n",
      "\tspeed: 0.2062s/iter; left time: 16897.2507s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0768861\n",
      "\tspeed: 0.2032s/iter; left time: 16626.1937s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0925877\n",
      "\tspeed: 0.2075s/iter; left time: 16959.7075s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1027337\n",
      "\tspeed: 0.2075s/iter; left time: 16938.6186s\n",
      "Epoch: 2 cost time: 00h:15m:36.14s\n",
      "Epoch: 2 | Train Loss: 0.0897730 Vali Loss: 0.0947562 Test Loss: 0.1064046\n",
      "Validation loss decreased (0.097765 --> 0.094756).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0810658\n",
      "\tspeed: 2.8829s/iter; left time: 234943.0725s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800776\n",
      "\tspeed: 0.2065s/iter; left time: 16808.2880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0864822\n",
      "\tspeed: 0.2107s/iter; left time: 17130.5311s\n",
      "\titers: 400, epoch: 3 | loss: 0.0833262\n",
      "\tspeed: 0.2081s/iter; left time: 16896.7296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1016066\n",
      "\tspeed: 0.2066s/iter; left time: 16751.8452s\n",
      "\titers: 600, epoch: 3 | loss: 0.0743249\n",
      "\tspeed: 0.2081s/iter; left time: 16856.4713s\n",
      "\titers: 700, epoch: 3 | loss: 0.0947935\n",
      "\tspeed: 0.2041s/iter; left time: 16506.9052s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972273\n",
      "\tspeed: 0.2015s/iter; left time: 16283.4889s\n",
      "\titers: 900, epoch: 3 | loss: 0.0753759\n",
      "\tspeed: 0.2080s/iter; left time: 16783.1574s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0977198\n",
      "\tspeed: 0.2078s/iter; left time: 16749.1853s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0708147\n",
      "\tspeed: 0.2123s/iter; left time: 17085.5556s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1041960\n",
      "\tspeed: 0.2047s/iter; left time: 16458.2318s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0813768\n",
      "\tspeed: 0.2037s/iter; left time: 16358.0012s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0833640\n",
      "\tspeed: 0.2057s/iter; left time: 16498.0856s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0912660\n",
      "\tspeed: 0.2052s/iter; left time: 16432.8780s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0964458\n",
      "\tspeed: 0.2025s/iter; left time: 16197.2866s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0746260\n",
      "\tspeed: 0.2082s/iter; left time: 16634.3750s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0821514\n",
      "\tspeed: 0.2079s/iter; left time: 16586.5981s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0930947\n",
      "\tspeed: 0.2083s/iter; left time: 16600.2893s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0983000\n",
      "\tspeed: 0.2039s/iter; left time: 16232.1842s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0888522\n",
      "\tspeed: 0.2121s/iter; left time: 16863.4827s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0999592\n",
      "\tspeed: 0.2072s/iter; left time: 16453.4128s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0848825\n",
      "\tspeed: 0.2047s/iter; left time: 16235.5531s\n",
      "\titers: 2400, epoch: 3 | loss: 0.1003277\n",
      "\tspeed: 0.2079s/iter; left time: 16462.0069s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1023490\n",
      "\tspeed: 0.2165s/iter; left time: 17123.3664s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0994273\n",
      "\tspeed: 0.2198s/iter; left time: 17363.5078s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0884067\n",
      "\tspeed: 0.2086s/iter; left time: 16458.3750s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0817370\n",
      "\tspeed: 0.2113s/iter; left time: 16647.8347s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0865126\n",
      "\tspeed: 0.2073s/iter; left time: 16310.8194s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0781461\n",
      "\tspeed: 0.2094s/iter; left time: 16456.1587s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0961022\n",
      "\tspeed: 0.2073s/iter; left time: 16273.9645s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0833025\n",
      "\tspeed: 0.2039s/iter; left time: 15981.1719s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0868474\n",
      "\tspeed: 0.2071s/iter; left time: 16213.4939s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0948126\n",
      "\tspeed: 0.2097s/iter; left time: 16401.3564s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0747255\n",
      "\tspeed: 0.2048s/iter; left time: 15990.0912s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0783070\n",
      "\tspeed: 0.2028s/iter; left time: 15816.6193s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0824283\n",
      "\tspeed: 0.2073s/iter; left time: 16144.4528s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0840960\n",
      "\tspeed: 0.2041s/iter; left time: 15874.1738s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0793464\n",
      "\tspeed: 0.2061s/iter; left time: 16015.1940s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1106913\n",
      "\tspeed: 0.2043s/iter; left time: 15850.1320s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0804906\n",
      "\tspeed: 0.2063s/iter; left time: 15985.3942s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0840885\n",
      "\tspeed: 0.2087s/iter; left time: 16150.6999s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0973125\n",
      "\tspeed: 0.2041s/iter; left time: 15777.5095s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956219\n",
      "\tspeed: 0.2078s/iter; left time: 16043.9459s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0949254\n",
      "\tspeed: 0.2013s/iter; left time: 15521.4229s\n",
      "Epoch: 3 cost time: 00h:15m:39.38s\n",
      "Epoch: 3 | Train Loss: 0.0880390 Vali Loss: 0.0942308 Test Loss: 0.1069798\n",
      "Validation loss decreased (0.094756 --> 0.094231).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0629435\n",
      "\tspeed: 2.8681s/iter; left time: 220738.1901s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817626\n",
      "\tspeed: 0.2044s/iter; left time: 15713.9321s\n",
      "\titers: 300, epoch: 4 | loss: 0.0863294\n",
      "\tspeed: 0.2145s/iter; left time: 16465.9000s\n",
      "\titers: 400, epoch: 4 | loss: 0.0795554\n",
      "\tspeed: 0.2070s/iter; left time: 15868.4153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0831481\n",
      "\tspeed: 0.2064s/iter; left time: 15801.3037s\n",
      "\titers: 600, epoch: 4 | loss: 0.0922075\n",
      "\tspeed: 0.2068s/iter; left time: 15816.1630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0939702\n",
      "\tspeed: 0.2019s/iter; left time: 15420.2685s\n",
      "\titers: 800, epoch: 4 | loss: 0.1038905\n",
      "\tspeed: 0.2087s/iter; left time: 15914.4344s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906302\n",
      "\tspeed: 0.2063s/iter; left time: 15711.4453s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0878862\n",
      "\tspeed: 0.2116s/iter; left time: 16091.3031s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0860731\n",
      "\tspeed: 0.2078s/iter; left time: 15782.9574s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0774423\n",
      "\tspeed: 0.2087s/iter; left time: 15832.6079s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0769600\n",
      "\tspeed: 0.2072s/iter; left time: 15698.5154s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0720468\n",
      "\tspeed: 0.2087s/iter; left time: 15787.4081s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0859341\n",
      "\tspeed: 0.2079s/iter; left time: 15709.5172s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0894901\n",
      "\tspeed: 0.2063s/iter; left time: 15567.5086s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0890460\n",
      "\tspeed: 0.2056s/iter; left time: 15493.3883s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1076474\n",
      "\tspeed: 0.2044s/iter; left time: 15383.1545s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0765705\n",
      "\tspeed: 0.2093s/iter; left time: 15734.6450s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0851438\n",
      "\tspeed: 0.2086s/iter; left time: 15660.6367s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1141284\n",
      "\tspeed: 0.2090s/iter; left time: 15670.2835s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0862813\n",
      "\tspeed: 0.2055s/iter; left time: 15385.4751s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1139401\n",
      "\tspeed: 0.2002s/iter; left time: 14967.7757s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0752189\n",
      "\tspeed: 0.2099s/iter; left time: 15672.1886s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0758349\n",
      "\tspeed: 0.2134s/iter; left time: 15911.7240s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0949885\n",
      "\tspeed: 0.2142s/iter; left time: 15951.0429s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0871932\n",
      "\tspeed: 0.2085s/iter; left time: 15504.4323s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0932991\n",
      "\tspeed: 0.2045s/iter; left time: 15185.7253s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0893083\n",
      "\tspeed: 0.2119s/iter; left time: 15716.6822s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0879167\n",
      "\tspeed: 0.2083s/iter; left time: 15425.7544s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1030891\n",
      "\tspeed: 0.2106s/iter; left time: 15574.3678s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0765157\n",
      "\tspeed: 0.2074s/iter; left time: 15321.3984s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0882305\n",
      "\tspeed: 0.2110s/iter; left time: 15561.7669s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0930053\n",
      "\tspeed: 0.2085s/iter; left time: 15356.6312s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0871002\n",
      "\tspeed: 0.2130s/iter; left time: 15666.8357s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0690684\n",
      "\tspeed: 0.2110s/iter; left time: 15499.5806s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0998551\n",
      "\tspeed: 0.2034s/iter; left time: 14924.0017s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0960040\n",
      "\tspeed: 0.2043s/iter; left time: 14964.2663s\n",
      "\titers: 3900, epoch: 4 | loss: 0.1019153\n",
      "\tspeed: 0.2079s/iter; left time: 15210.7189s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0860887\n",
      "\tspeed: 0.2067s/iter; left time: 15099.5227s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0949487\n",
      "\tspeed: 0.2011s/iter; left time: 14671.3155s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1033828\n",
      "\tspeed: 0.2100s/iter; left time: 15298.9955s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0717965\n",
      "\tspeed: 0.2068s/iter; left time: 15044.0467s\n",
      "\titers: 4400, epoch: 4 | loss: 0.0878067\n",
      "\tspeed: 0.2067s/iter; left time: 15017.9687s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0918676\n",
      "\tspeed: 0.2032s/iter; left time: 14743.3131s\n",
      "Epoch: 4 cost time: 00h:15m:42.27s\n",
      "Epoch: 4 | Train Loss: 0.0868472 Vali Loss: 0.0933003 Test Loss: 0.1048385\n",
      "Validation loss decreased (0.094231 --> 0.093300).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0741384\n",
      "\tspeed: 3.0208s/iter; left time: 218794.2469s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076432\n",
      "\tspeed: 0.2059s/iter; left time: 14893.4791s\n",
      "\titers: 300, epoch: 5 | loss: 0.0760020\n",
      "\tspeed: 0.2065s/iter; left time: 14913.9063s\n",
      "\titers: 400, epoch: 5 | loss: 0.0853055\n",
      "\tspeed: 0.2079s/iter; left time: 14992.0139s\n",
      "\titers: 500, epoch: 5 | loss: 0.0548117\n",
      "\tspeed: 0.2100s/iter; left time: 15126.9888s\n",
      "\titers: 600, epoch: 5 | loss: 0.1007220\n",
      "\tspeed: 0.2071s/iter; left time: 14897.5417s\n",
      "\titers: 700, epoch: 5 | loss: 0.0747483\n",
      "\tspeed: 0.2058s/iter; left time: 14781.0316s\n",
      "\titers: 800, epoch: 5 | loss: 0.0905776\n",
      "\tspeed: 0.2094s/iter; left time: 15017.5738s\n",
      "\titers: 900, epoch: 5 | loss: 0.0860225\n",
      "\tspeed: 0.2055s/iter; left time: 14716.4011s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0738990\n",
      "\tspeed: 0.2039s/iter; left time: 14583.4945s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0933961\n",
      "\tspeed: 0.2038s/iter; left time: 14554.6116s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0883273\n",
      "\tspeed: 0.2103s/iter; left time: 14997.0152s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0698245\n",
      "\tspeed: 0.2066s/iter; left time: 14718.0606s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0771358\n",
      "\tspeed: 0.2088s/iter; left time: 14850.0622s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0988944\n",
      "\tspeed: 0.2052s/iter; left time: 14575.3074s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0769319\n",
      "\tspeed: 0.2078s/iter; left time: 14737.6505s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0906119\n",
      "\tspeed: 0.2100s/iter; left time: 14871.9827s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0767788\n",
      "\tspeed: 0.2077s/iter; left time: 14689.9590s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0871070\n",
      "\tspeed: 0.2076s/iter; left time: 14661.8704s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0943331\n",
      "\tspeed: 0.2070s/iter; left time: 14601.3388s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0935991\n",
      "\tspeed: 0.2056s/iter; left time: 14480.3503s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0794097\n",
      "\tspeed: 0.2056s/iter; left time: 14457.5957s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0865870\n",
      "\tspeed: 0.2038s/iter; left time: 14312.2838s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0800633\n",
      "\tspeed: 0.2057s/iter; left time: 14423.5427s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1094643\n",
      "\tspeed: 0.2040s/iter; left time: 14288.6274s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0919437\n",
      "\tspeed: 0.2071s/iter; left time: 14480.3289s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0853646\n",
      "\tspeed: 0.2092s/iter; left time: 14610.1158s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0692050\n",
      "\tspeed: 0.2061s/iter; left time: 14367.8777s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0830063\n",
      "\tspeed: 0.2056s/iter; left time: 14314.8213s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0872543\n",
      "\tspeed: 0.2085s/iter; left time: 14500.0672s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0803247\n",
      "\tspeed: 0.2118s/iter; left time: 14707.0644s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0736554\n",
      "\tspeed: 0.2069s/iter; left time: 14344.9226s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0921012\n",
      "\tspeed: 0.2056s/iter; left time: 14236.4392s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0835762\n",
      "\tspeed: 0.2044s/iter; left time: 14128.3308s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0950097\n",
      "\tspeed: 0.2093s/iter; left time: 14449.9958s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1110827\n",
      "\tspeed: 0.2088s/iter; left time: 14389.0822s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0821992\n",
      "\tspeed: 0.2090s/iter; left time: 14387.8506s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0676025\n",
      "\tspeed: 0.2057s/iter; left time: 14135.6071s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0814962\n",
      "\tspeed: 0.2069s/iter; left time: 14197.1448s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0887165\n",
      "\tspeed: 0.2081s/iter; left time: 14257.5858s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0728875\n",
      "\tspeed: 0.2102s/iter; left time: 14382.3587s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0656401\n",
      "\tspeed: 0.2015s/iter; left time: 13771.1031s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0732421\n",
      "\tspeed: 0.1986s/iter; left time: 13551.3038s\n",
      "\titers: 4400, epoch: 5 | loss: 0.0835454\n",
      "\tspeed: 0.2059s/iter; left time: 14024.9159s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0843670\n",
      "\tspeed: 0.2040s/iter; left time: 13876.0773s\n",
      "Epoch: 5 cost time: 00h:15m:37.22s\n",
      "Epoch: 5 | Train Loss: 0.0859530 Vali Loss: 0.0931037 Test Loss: 0.1048710\n",
      "Validation loss decreased (0.093300 --> 0.093104).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0801860\n",
      "\tspeed: 2.8737s/iter; left time: 195111.3389s\n",
      "\titers: 200, epoch: 6 | loss: 0.1101087\n",
      "\tspeed: 0.1975s/iter; left time: 13390.7818s\n",
      "\titers: 300, epoch: 6 | loss: 0.0762284\n",
      "\tspeed: 0.2055s/iter; left time: 13913.0098s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788697\n",
      "\tspeed: 0.2142s/iter; left time: 14480.3936s\n",
      "\titers: 500, epoch: 6 | loss: 0.0804758\n",
      "\tspeed: 0.2040s/iter; left time: 13770.7405s\n",
      "\titers: 600, epoch: 6 | loss: 0.0990776\n",
      "\tspeed: 0.2051s/iter; left time: 13825.7709s\n",
      "\titers: 700, epoch: 6 | loss: 0.0806546\n",
      "\tspeed: 0.2084s/iter; left time: 14025.7677s\n",
      "\titers: 800, epoch: 6 | loss: 0.0906101\n",
      "\tspeed: 0.2085s/iter; left time: 14007.3173s\n",
      "\titers: 900, epoch: 6 | loss: 0.0941866\n",
      "\tspeed: 0.2097s/iter; left time: 14069.0933s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0684057\n",
      "\tspeed: 0.2112s/iter; left time: 14152.7443s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0810384\n",
      "\tspeed: 0.2071s/iter; left time: 13851.6608s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0821972\n",
      "\tspeed: 0.2061s/iter; left time: 13764.2379s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0927051\n",
      "\tspeed: 0.2051s/iter; left time: 13676.7886s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0708853\n",
      "\tspeed: 0.2095s/iter; left time: 13951.3347s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0932269\n",
      "\tspeed: 0.2032s/iter; left time: 13511.2427s\n",
      "\titers: 1600, epoch: 6 | loss: 0.1037990\n",
      "\tspeed: 0.2132s/iter; left time: 14155.8141s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0954990\n",
      "\tspeed: 0.2113s/iter; left time: 14009.8887s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0848894\n",
      "\tspeed: 0.2128s/iter; left time: 14089.0052s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0855536\n",
      "\tspeed: 0.2159s/iter; left time: 14269.0809s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0943525\n",
      "\tspeed: 0.2289s/iter; left time: 15105.8938s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0667500\n",
      "\tspeed: 0.2082s/iter; left time: 13720.9368s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0840006\n",
      "\tspeed: 0.2030s/iter; left time: 13353.5205s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0643740\n",
      "\tspeed: 0.2079s/iter; left time: 13655.4606s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0742748\n",
      "\tspeed: 0.2097s/iter; left time: 13754.3743s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0909706\n",
      "\tspeed: 0.2064s/iter; left time: 13519.7340s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0844907\n",
      "\tspeed: 0.2115s/iter; left time: 13830.4778s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0878555\n",
      "\tspeed: 0.1953s/iter; left time: 12752.9357s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0970411\n",
      "\tspeed: 0.2000s/iter; left time: 13036.8062s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0734473\n",
      "\tspeed: 0.2022s/iter; left time: 13159.1833s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0836401\n",
      "\tspeed: 0.2024s/iter; left time: 13153.1787s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0964884\n",
      "\tspeed: 0.1983s/iter; left time: 12871.5985s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0760528\n",
      "\tspeed: 0.2089s/iter; left time: 13534.0938s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0759267\n",
      "\tspeed: 0.2076s/iter; left time: 13433.2749s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0775311\n",
      "\tspeed: 0.2033s/iter; left time: 13135.2763s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1126537\n",
      "\tspeed: 0.1980s/iter; left time: 12767.3191s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0685594\n",
      "\tspeed: 0.1995s/iter; left time: 12847.3320s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0926302\n",
      "\tspeed: 0.2017s/iter; left time: 12968.6101s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0759674\n",
      "\tspeed: 0.1989s/iter; left time: 12770.8511s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0886815\n",
      "\tspeed: 0.1997s/iter; left time: 12797.5558s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0981110\n",
      "\tspeed: 0.1990s/iter; left time: 12736.9493s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0808471\n",
      "\tspeed: 0.1954s/iter; left time: 12486.0146s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0831465\n",
      "\tspeed: 0.2033s/iter; left time: 12967.4624s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0743688\n",
      "\tspeed: 0.2068s/iter; left time: 13171.3811s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0812875\n",
      "\tspeed: 0.2004s/iter; left time: 12742.0970s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0805463\n",
      "\tspeed: 0.2080s/iter; left time: 13204.2397s\n",
      "Epoch: 6 cost time: 00h:15m:32.46s\n",
      "Epoch: 6 | Train Loss: 0.0852381 Vali Loss: 0.0928212 Test Loss: 0.1050314\n",
      "Validation loss decreased (0.093104 --> 0.092821).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.1047151\n",
      "\tspeed: 2.8811s/iter; left time: 182552.0419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953454\n",
      "\tspeed: 0.2083s/iter; left time: 13176.4326s\n",
      "\titers: 300, epoch: 7 | loss: 0.0660141\n",
      "\tspeed: 0.2037s/iter; left time: 12863.9467s\n",
      "\titers: 400, epoch: 7 | loss: 0.0820844\n",
      "\tspeed: 0.2087s/iter; left time: 13160.8212s\n",
      "\titers: 500, epoch: 7 | loss: 0.0738224\n",
      "\tspeed: 0.2077s/iter; left time: 13078.4402s\n",
      "\titers: 600, epoch: 7 | loss: 0.0880774\n",
      "\tspeed: 0.2033s/iter; left time: 12777.8105s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794524\n",
      "\tspeed: 0.2063s/iter; left time: 12948.4159s\n",
      "\titers: 800, epoch: 7 | loss: 0.0785445\n",
      "\tspeed: 0.2057s/iter; left time: 12888.7997s\n",
      "\titers: 900, epoch: 7 | loss: 0.0827400\n",
      "\tspeed: 0.2071s/iter; left time: 12957.8705s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0876613\n",
      "\tspeed: 0.2084s/iter; left time: 13015.7919s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0604013\n",
      "\tspeed: 0.2037s/iter; left time: 12701.1737s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0944318\n",
      "\tspeed: 0.2066s/iter; left time: 12864.6877s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0725799\n",
      "\tspeed: 0.2003s/iter; left time: 12452.0728s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0708223\n",
      "\tspeed: 0.1944s/iter; left time: 12067.4824s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0984242\n",
      "\tspeed: 0.1997s/iter; left time: 12371.3325s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0892823\n",
      "\tspeed: 0.2068s/iter; left time: 12790.8313s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0822393\n",
      "\tspeed: 0.2038s/iter; left time: 12587.3085s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0994398\n",
      "\tspeed: 0.2089s/iter; left time: 12881.3839s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0783563\n",
      "\tspeed: 0.2128s/iter; left time: 13102.9007s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0797199\n",
      "\tspeed: 0.2112s/iter; left time: 12980.4427s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0682478\n",
      "\tspeed: 0.2055s/iter; left time: 12611.0825s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0854917\n",
      "\tspeed: 0.2112s/iter; left time: 12936.7978s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0815612\n",
      "\tspeed: 0.2117s/iter; left time: 12947.0108s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0776256\n",
      "\tspeed: 0.2068s/iter; left time: 12625.8607s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0890070\n",
      "\tspeed: 0.2126s/iter; left time: 12958.3575s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0713369\n",
      "\tspeed: 0.2070s/iter; left time: 12600.4614s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0917580\n",
      "\tspeed: 0.2044s/iter; left time: 12421.1305s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0853298\n",
      "\tspeed: 0.2092s/iter; left time: 12690.9202s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0683254\n",
      "\tspeed: 0.2034s/iter; left time: 12320.2604s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0674208\n",
      "\tspeed: 0.1999s/iter; left time: 12088.0291s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061399\n",
      "\tspeed: 0.2043s/iter; left time: 12332.9736s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0806480\n",
      "\tspeed: 0.2022s/iter; left time: 12185.1757s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0896547\n",
      "\tspeed: 0.2063s/iter; left time: 12412.6946s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0737791\n",
      "\tspeed: 0.2067s/iter; left time: 12416.4516s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0934617\n",
      "\tspeed: 0.2093s/iter; left time: 12551.3680s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0644973\n",
      "\tspeed: 0.2144s/iter; left time: 12835.2340s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0979190\n",
      "\tspeed: 0.2066s/iter; left time: 12344.9806s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0881604\n",
      "\tspeed: 0.2069s/iter; left time: 12342.0743s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0841230\n",
      "\tspeed: 0.2043s/iter; left time: 12169.2925s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0985560\n",
      "\tspeed: 0.2058s/iter; left time: 12239.0234s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0721457\n",
      "\tspeed: 0.2107s/iter; left time: 12506.1717s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0912469\n",
      "\tspeed: 0.2099s/iter; left time: 12441.9679s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0834451\n",
      "\tspeed: 0.2091s/iter; left time: 12371.3268s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0763505\n",
      "\tspeed: 0.2079s/iter; left time: 12282.0368s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0864378\n",
      "\tspeed: 0.2088s/iter; left time: 12311.4423s\n",
      "Epoch: 7 cost time: 00h:15m:37.79s\n",
      "Epoch: 7 | Train Loss: 0.0846115 Vali Loss: 0.0920109 Test Loss: 0.1030820\n",
      "Validation loss decreased (0.092821 --> 0.092011).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0959323\n",
      "\tspeed: 2.9705s/iter; left time: 174757.1464s\n",
      "\titers: 200, epoch: 8 | loss: 0.0614587\n",
      "\tspeed: 0.2147s/iter; left time: 12607.9893s\n",
      "\titers: 300, epoch: 8 | loss: 0.1047958\n",
      "\tspeed: 0.2045s/iter; left time: 11987.6007s\n",
      "\titers: 400, epoch: 8 | loss: 0.0672435\n",
      "\tspeed: 0.2023s/iter; left time: 11837.9279s\n",
      "\titers: 500, epoch: 8 | loss: 0.0932711\n",
      "\tspeed: 0.2015s/iter; left time: 11772.5302s\n",
      "\titers: 600, epoch: 8 | loss: 0.0958791\n",
      "\tspeed: 0.2063s/iter; left time: 12036.3643s\n",
      "\titers: 700, epoch: 8 | loss: 0.0793360\n",
      "\tspeed: 0.2047s/iter; left time: 11918.9334s\n",
      "\titers: 800, epoch: 8 | loss: 0.0753882\n",
      "\tspeed: 0.1990s/iter; left time: 11566.7016s\n",
      "\titers: 900, epoch: 8 | loss: 0.0943302\n",
      "\tspeed: 0.2074s/iter; left time: 12036.4248s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0702697\n",
      "\tspeed: 0.2045s/iter; left time: 11844.1021s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0750135\n",
      "\tspeed: 0.2100s/iter; left time: 12141.6900s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0680853\n",
      "\tspeed: 0.2055s/iter; left time: 11864.1696s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0832931\n",
      "\tspeed: 0.2077s/iter; left time: 11971.1115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0833303\n",
      "\tspeed: 0.2096s/iter; left time: 12056.4310s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0828459\n",
      "\tspeed: 0.2167s/iter; left time: 12445.6579s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0849369\n",
      "\tspeed: 0.2099s/iter; left time: 12033.3152s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0814050\n",
      "\tspeed: 0.2043s/iter; left time: 11690.5031s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0743382\n",
      "\tspeed: 0.2078s/iter; left time: 11869.8021s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0840637\n",
      "\tspeed: 0.2080s/iter; left time: 11859.5128s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0879681\n",
      "\tspeed: 0.2114s/iter; left time: 12035.5906s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0817242\n",
      "\tspeed: 0.2090s/iter; left time: 11875.9685s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0798136\n",
      "\tspeed: 0.2056s/iter; left time: 11662.5593s\n",
      "\titers: 2300, epoch: 8 | loss: 0.1019480\n",
      "\tspeed: 0.2025s/iter; left time: 11468.0164s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0801811\n",
      "\tspeed: 0.2083s/iter; left time: 11772.7732s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0829113\n",
      "\tspeed: 0.2023s/iter; left time: 11413.5219s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0967366\n",
      "\tspeed: 0.2028s/iter; left time: 11424.3856s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0840562\n",
      "\tspeed: 0.2042s/iter; left time: 11480.6080s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0779026\n",
      "\tspeed: 0.2084s/iter; left time: 11697.0390s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0962122\n",
      "\tspeed: 0.2061s/iter; left time: 11548.1397s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0935820\n",
      "\tspeed: 0.2160s/iter; left time: 12081.8666s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0829191\n",
      "\tspeed: 0.2094s/iter; left time: 11690.5081s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0710387\n",
      "\tspeed: 0.2087s/iter; left time: 11630.4804s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0894845\n",
      "\tspeed: 0.2124s/iter; left time: 11817.3435s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0926941\n",
      "\tspeed: 0.2059s/iter; left time: 11433.9536s\n",
      "\titers: 3500, epoch: 8 | loss: 0.1105087\n",
      "\tspeed: 0.1943s/iter; left time: 10767.8637s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0872025\n",
      "\tspeed: 0.2024s/iter; left time: 11197.3750s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0861788\n",
      "\tspeed: 0.2108s/iter; left time: 11643.3364s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0885966\n",
      "\tspeed: 0.2090s/iter; left time: 11521.3090s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0713039\n",
      "\tspeed: 0.2019s/iter; left time: 11109.2651s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0886188\n",
      "\tspeed: 0.2030s/iter; left time: 11148.1414s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0810110\n",
      "\tspeed: 0.2022s/iter; left time: 11085.0714s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0742318\n",
      "\tspeed: 0.1941s/iter; left time: 10622.7644s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0750491\n",
      "\tspeed: 0.2049s/iter; left time: 11196.2452s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0823885\n",
      "\tspeed: 0.2116s/iter; left time: 11540.6292s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0682080\n",
      "\tspeed: 0.2089s/iter; left time: 11371.7167s\n",
      "Epoch: 8 cost time: 00h:15m:36.23s\n",
      "Epoch: 8 | Train Loss: 0.0840220 Vali Loss: 0.0924658 Test Loss: 0.1032606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.1014510\n",
      "\tspeed: 2.8537s/iter; left time: 154947.4982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0732115\n",
      "\tspeed: 0.2032s/iter; left time: 11013.3979s\n",
      "\titers: 300, epoch: 9 | loss: 0.0672111\n",
      "\tspeed: 0.2135s/iter; left time: 11547.5595s\n",
      "\titers: 400, epoch: 9 | loss: 0.0704000\n",
      "\tspeed: 0.2128s/iter; left time: 11491.8370s\n",
      "\titers: 500, epoch: 9 | loss: 0.0818704\n",
      "\tspeed: 0.2048s/iter; left time: 11037.3855s\n",
      "\titers: 600, epoch: 9 | loss: 0.0715541\n",
      "\tspeed: 0.2051s/iter; left time: 11035.8301s\n",
      "\titers: 700, epoch: 9 | loss: 0.1105956\n",
      "\tspeed: 0.2095s/iter; left time: 11250.5845s\n",
      "\titers: 800, epoch: 9 | loss: 0.0845100\n",
      "\tspeed: 0.2104s/iter; left time: 11278.5344s\n",
      "\titers: 900, epoch: 9 | loss: 0.0731403\n",
      "\tspeed: 0.2030s/iter; left time: 10860.9777s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0902069\n",
      "\tspeed: 0.2052s/iter; left time: 10959.6923s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0874258\n",
      "\tspeed: 0.2048s/iter; left time: 10914.0901s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0794950\n",
      "\tspeed: 0.2048s/iter; left time: 10893.1266s\n",
      "\titers: 1300, epoch: 9 | loss: 0.1164204\n",
      "\tspeed: 0.2101s/iter; left time: 11153.6165s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0773649\n",
      "\tspeed: 0.2090s/iter; left time: 11074.0395s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0806947\n",
      "\tspeed: 0.2295s/iter; left time: 12139.5612s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0846206\n",
      "\tspeed: 0.2093s/iter; left time: 11049.5450s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0888354\n",
      "\tspeed: 0.2126s/iter; left time: 11203.2563s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0787957\n",
      "\tspeed: 0.2070s/iter; left time: 10887.3510s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0875736\n",
      "\tspeed: 0.2063s/iter; left time: 10832.7090s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0798719\n",
      "\tspeed: 0.2107s/iter; left time: 11041.0365s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0696464\n",
      "\tspeed: 0.2105s/iter; left time: 11009.0840s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0806052\n",
      "\tspeed: 0.2097s/iter; left time: 10946.9617s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0751054\n",
      "\tspeed: 0.2076s/iter; left time: 10812.9726s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0679254\n",
      "\tspeed: 0.2100s/iter; left time: 10920.0388s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0896055\n",
      "\tspeed: 0.2087s/iter; left time: 10830.7340s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0963080\n",
      "\tspeed: 0.2115s/iter; left time: 10954.3016s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0976607\n",
      "\tspeed: 0.2101s/iter; left time: 10861.8111s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0960976\n",
      "\tspeed: 0.2073s/iter; left time: 10697.8326s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0740882\n",
      "\tspeed: 0.2041s/iter; left time: 10509.9026s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0925232\n",
      "\tspeed: 0.2073s/iter; left time: 10656.8542s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0872741\n",
      "\tspeed: 0.2091s/iter; left time: 10728.4834s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0927054\n",
      "\tspeed: 0.2125s/iter; left time: 10880.2444s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0926027\n",
      "\tspeed: 0.2049s/iter; left time: 10468.7964s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0748180\n",
      "\tspeed: 0.2070s/iter; left time: 10558.8309s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0865958\n",
      "\tspeed: 0.2093s/iter; left time: 10651.8763s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0942663\n",
      "\tspeed: 0.2105s/iter; left time: 10693.4518s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0669860\n",
      "\tspeed: 0.2112s/iter; left time: 10709.4440s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0851723\n",
      "\tspeed: 0.2055s/iter; left time: 10398.6932s\n",
      "\titers: 3900, epoch: 9 | loss: 0.0820740\n",
      "\tspeed: 0.2023s/iter; left time: 10213.4391s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0780144\n",
      "\tspeed: 0.2069s/iter; left time: 10425.2287s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0814089\n",
      "\tspeed: 0.2089s/iter; left time: 10507.8837s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0962178\n",
      "\tspeed: 0.2070s/iter; left time: 10389.6826s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0851158\n",
      "\tspeed: 0.2086s/iter; left time: 10449.8671s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0686529\n",
      "\tspeed: 0.2062s/iter; left time: 10311.8181s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.2002s/iter; left time: 9987.7916s\n",
      "Epoch: 9 cost time: 00h:15m:44.34s\n",
      "Epoch: 9 | Train Loss: 0.0836118 Vali Loss: 0.0916400 Test Loss: 0.1035914\n",
      "Validation loss decreased (0.092011 --> 0.091640).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0922346\n",
      "\tspeed: 2.8582s/iter; left time: 142237.5401s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827963\n",
      "\tspeed: 0.2100s/iter; left time: 10431.1019s\n",
      "\titers: 300, epoch: 10 | loss: 0.0725681\n",
      "\tspeed: 0.2117s/iter; left time: 10491.4324s\n",
      "\titers: 400, epoch: 10 | loss: 0.0845144\n",
      "\tspeed: 0.2062s/iter; left time: 10197.1332s\n",
      "\titers: 500, epoch: 10 | loss: 0.0973951\n",
      "\tspeed: 0.2051s/iter; left time: 10122.9933s\n",
      "\titers: 600, epoch: 10 | loss: 0.0669774\n",
      "\tspeed: 0.2115s/iter; left time: 10417.2510s\n",
      "\titers: 700, epoch: 10 | loss: 0.0811357\n",
      "\tspeed: 0.2078s/iter; left time: 10216.2978s\n",
      "\titers: 800, epoch: 10 | loss: 0.0769972\n",
      "\tspeed: 0.2086s/iter; left time: 10233.3081s\n",
      "\titers: 900, epoch: 10 | loss: 0.0785766\n",
      "\tspeed: 0.2060s/iter; left time: 10085.1869s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0721540\n",
      "\tspeed: 0.2079s/iter; left time: 10157.5177s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0780357\n",
      "\tspeed: 0.2051s/iter; left time: 10000.1983s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0628892\n",
      "\tspeed: 0.2028s/iter; left time: 9869.3829s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0867144\n",
      "\tspeed: 0.2027s/iter; left time: 9845.6505s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0705752\n",
      "\tspeed: 0.2079s/iter; left time: 10077.8918s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0764625\n",
      "\tspeed: 0.2131s/iter; left time: 10305.6577s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0668899\n",
      "\tspeed: 0.2099s/iter; left time: 10129.1452s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0745432\n",
      "\tspeed: 0.1985s/iter; left time: 9559.4946s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0846424\n",
      "\tspeed: 0.1999s/iter; left time: 9606.2629s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0850989\n",
      "\tspeed: 0.1995s/iter; left time: 9567.8076s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0688419\n",
      "\tspeed: 0.2059s/iter; left time: 9853.2287s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0732007\n",
      "\tspeed: 0.1921s/iter; left time: 9174.4169s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0551585\n",
      "\tspeed: 0.2001s/iter; left time: 9537.2863s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0780649\n",
      "\tspeed: 0.2023s/iter; left time: 9623.7304s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0777197\n",
      "\tspeed: 0.2074s/iter; left time: 9844.1685s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0629792\n",
      "\tspeed: 0.2088s/iter; left time: 9887.6228s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0627633\n",
      "\tspeed: 0.2082s/iter; left time: 9840.6308s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0915789\n",
      "\tspeed: 0.2106s/iter; left time: 9934.9471s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0956732\n",
      "\tspeed: 0.2080s/iter; left time: 9790.2877s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0978506\n",
      "\tspeed: 0.2011s/iter; left time: 9442.4463s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0958144\n",
      "\tspeed: 0.2105s/iter; left time: 9866.6382s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0634759\n",
      "\tspeed: 0.2070s/iter; left time: 9679.0685s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0850318\n",
      "\tspeed: 0.2119s/iter; left time: 9888.1211s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0951718\n",
      "\tspeed: 0.2069s/iter; left time: 9632.4278s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0604331\n",
      "\tspeed: 0.2161s/iter; left time: 10041.8519s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0863831\n",
      "\tspeed: 0.2086s/iter; left time: 9669.8258s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0834125\n",
      "\tspeed: 0.2059s/iter; left time: 9525.5533s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0860748\n",
      "\tspeed: 0.2138s/iter; left time: 9871.6050s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0807017\n",
      "\tspeed: 0.2099s/iter; left time: 9668.1149s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0948860\n",
      "\tspeed: 0.2066s/iter; left time: 9496.2855s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0667045\n",
      "\tspeed: 0.2054s/iter; left time: 9418.3610s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0953892\n",
      "\tspeed: 0.2083s/iter; left time: 9533.4707s\n",
      "\titers: 4200, epoch: 10 | loss: 0.1057899\n",
      "\tspeed: 0.2285s/iter; left time: 10432.9748s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0854646\n",
      "\tspeed: 0.2115s/iter; left time: 9635.5818s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0952444\n",
      "\tspeed: 0.2067s/iter; left time: 9398.9828s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0909593\n",
      "\tspeed: 0.2076s/iter; left time: 9419.3097s\n",
      "Epoch: 10 cost time: 00h:15m:40.41s\n",
      "Epoch: 10 | Train Loss: 0.0831709 Vali Loss: 0.0917714 Test Loss: 0.1027734\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0831171\n",
      "\tspeed: 2.8817s/iter; left time: 130342.9083s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760654\n",
      "\tspeed: 0.2087s/iter; left time: 9418.2588s\n",
      "\titers: 300, epoch: 11 | loss: 0.0676253\n",
      "\tspeed: 0.2065s/iter; left time: 9298.5589s\n",
      "\titers: 400, epoch: 11 | loss: 0.1150495\n",
      "\tspeed: 0.2069s/iter; left time: 9295.3398s\n",
      "\titers: 500, epoch: 11 | loss: 0.0861939\n",
      "\tspeed: 0.2066s/iter; left time: 9263.6129s\n",
      "\titers: 600, epoch: 11 | loss: 0.1202399\n",
      "\tspeed: 0.2121s/iter; left time: 9486.0471s\n",
      "\titers: 700, epoch: 11 | loss: 0.0713722\n",
      "\tspeed: 0.2123s/iter; left time: 9474.7945s\n",
      "\titers: 800, epoch: 11 | loss: 0.0841707\n",
      "\tspeed: 0.2088s/iter; left time: 9296.2961s\n",
      "\titers: 900, epoch: 11 | loss: 0.0706428\n",
      "\tspeed: 0.2032s/iter; left time: 9026.7012s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0783792\n",
      "\tspeed: 0.2100s/iter; left time: 9308.6294s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0755092\n",
      "\tspeed: 0.2072s/iter; left time: 9164.5589s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0712842\n",
      "\tspeed: 0.2102s/iter; left time: 9275.6769s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0775973\n",
      "\tspeed: 0.2039s/iter; left time: 8977.7339s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0768260\n",
      "\tspeed: 0.2083s/iter; left time: 9151.9148s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0978865\n",
      "\tspeed: 0.2103s/iter; left time: 9216.5358s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0887017\n",
      "\tspeed: 0.2104s/iter; left time: 9201.6183s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0848004\n",
      "\tspeed: 0.2086s/iter; left time: 9102.4207s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0720866\n",
      "\tspeed: 0.2006s/iter; left time: 8732.7789s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0970763\n",
      "\tspeed: 0.2020s/iter; left time: 8772.5618s\n",
      "\titers: 2000, epoch: 11 | loss: 0.1055982\n",
      "\tspeed: 0.2028s/iter; left time: 8786.9344s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0810075\n",
      "\tspeed: 0.2052s/iter; left time: 8871.1912s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0754189\n",
      "\tspeed: 0.2091s/iter; left time: 9018.6253s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0723282\n",
      "\tspeed: 0.1987s/iter; left time: 8551.6666s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0780134\n",
      "\tspeed: 0.1997s/iter; left time: 8573.6291s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0767258\n",
      "\tspeed: 0.1976s/iter; left time: 8462.0010s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0836462\n",
      "\tspeed: 0.2066s/iter; left time: 8827.9592s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0815188\n",
      "\tspeed: 0.2051s/iter; left time: 8743.1324s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0932637\n",
      "\tspeed: 0.2019s/iter; left time: 8587.2621s\n",
      "\titers: 2900, epoch: 11 | loss: 0.1080622\n",
      "\tspeed: 0.1999s/iter; left time: 8481.8730s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0838806\n",
      "\tspeed: 0.2037s/iter; left time: 8623.5369s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0917139\n",
      "\tspeed: 0.2058s/iter; left time: 8691.8585s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0728604\n",
      "\tspeed: 0.2087s/iter; left time: 8794.6896s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0765374\n",
      "\tspeed: 0.2089s/iter; left time: 8779.8091s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0869917\n",
      "\tspeed: 0.2073s/iter; left time: 8691.9496s\n",
      "\titers: 3500, epoch: 11 | loss: 0.1024831\n",
      "\tspeed: 0.2130s/iter; left time: 8908.1749s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0874722\n",
      "\tspeed: 0.2082s/iter; left time: 8690.1439s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0937591\n",
      "\tspeed: 0.2048s/iter; left time: 8524.0244s\n",
      "\titers: 3800, epoch: 11 | loss: 0.1035393\n",
      "\tspeed: 0.2102s/iter; left time: 8728.3784s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1090173\n",
      "\tspeed: 0.2062s/iter; left time: 8542.7912s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0618905\n",
      "\tspeed: 0.2053s/iter; left time: 8484.7243s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0943761\n",
      "\tspeed: 0.2034s/iter; left time: 8386.7505s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0912680\n",
      "\tspeed: 0.2072s/iter; left time: 8522.4293s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0760508\n",
      "\tspeed: 0.2002s/iter; left time: 8213.3524s\n",
      "\titers: 4400, epoch: 11 | loss: 0.1074579\n",
      "\tspeed: 0.2010s/iter; left time: 8226.3412s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0892026\n",
      "\tspeed: 0.2083s/iter; left time: 8506.9017s\n",
      "Epoch: 11 cost time: 00h:15m:35.54s\n",
      "Epoch: 11 | Train Loss: 0.0828589 Vali Loss: 0.0916625 Test Loss: 0.1039719\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.1107441\n",
      "\tspeed: 2.9255s/iter; left time: 119062.3005s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788576\n",
      "\tspeed: 0.2046s/iter; left time: 8304.8388s\n",
      "\titers: 300, epoch: 12 | loss: 0.0659967\n",
      "\tspeed: 0.2059s/iter; left time: 8337.9879s\n",
      "\titers: 400, epoch: 12 | loss: 0.0706586\n",
      "\tspeed: 0.2074s/iter; left time: 8378.1466s\n",
      "\titers: 500, epoch: 12 | loss: 0.0756243\n",
      "\tspeed: 0.2068s/iter; left time: 8332.8156s\n",
      "\titers: 600, epoch: 12 | loss: 0.0702241\n",
      "\tspeed: 0.2114s/iter; left time: 8497.5896s\n",
      "\titers: 700, epoch: 12 | loss: 0.0794594\n",
      "\tspeed: 0.2074s/iter; left time: 8317.2887s\n",
      "\titers: 800, epoch: 12 | loss: 0.0771929\n",
      "\tspeed: 0.2023s/iter; left time: 8090.8364s\n",
      "\titers: 900, epoch: 12 | loss: 0.0743011\n",
      "\tspeed: 0.2199s/iter; left time: 8773.2326s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0905746\n",
      "\tspeed: 0.2251s/iter; left time: 8959.5643s\n",
      "\titers: 1100, epoch: 12 | loss: 0.1068195\n",
      "\tspeed: 0.2082s/iter; left time: 8264.4714s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0629381\n",
      "\tspeed: 0.2121s/iter; left time: 8400.5335s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0803293\n",
      "\tspeed: 0.2098s/iter; left time: 8285.2291s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0934114\n",
      "\tspeed: 0.2094s/iter; left time: 8250.1952s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0726073\n",
      "\tspeed: 0.2078s/iter; left time: 8165.8378s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0928714\n",
      "\tspeed: 0.2117s/iter; left time: 8299.6592s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0842601\n",
      "\tspeed: 0.2090s/iter; left time: 8169.8199s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0871204\n",
      "\tspeed: 0.2067s/iter; left time: 8061.5385s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0869684\n",
      "\tspeed: 0.2053s/iter; left time: 7987.3525s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0896044\n",
      "\tspeed: 0.2042s/iter; left time: 7924.1125s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0892930\n",
      "\tspeed: 0.2102s/iter; left time: 8134.4180s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0785727\n",
      "\tspeed: 0.2053s/iter; left time: 7925.2022s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0655281\n",
      "\tspeed: 0.2068s/iter; left time: 7961.3379s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0941407\n",
      "\tspeed: 0.2052s/iter; left time: 7879.3166s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0824777\n",
      "\tspeed: 0.2081s/iter; left time: 7969.6767s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0843000\n",
      "\tspeed: 0.2072s/iter; left time: 7916.3379s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0749287\n",
      "\tspeed: 0.2067s/iter; left time: 7876.7516s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0777160\n",
      "\tspeed: 0.2097s/iter; left time: 7969.2220s\n",
      "\titers: 2900, epoch: 12 | loss: 0.1096275\n",
      "\tspeed: 0.2090s/iter; left time: 7920.7917s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0781749\n",
      "\tspeed: 0.2019s/iter; left time: 7630.3932s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0840687\n",
      "\tspeed: 0.2085s/iter; left time: 7861.7842s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0815316\n",
      "\tspeed: 0.2134s/iter; left time: 8021.9205s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0798401\n",
      "\tspeed: 0.2068s/iter; left time: 7755.3049s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0896733\n",
      "\tspeed: 0.2079s/iter; left time: 7774.0832s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0939660\n",
      "\tspeed: 0.2096s/iter; left time: 7816.4147s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0806810\n",
      "\tspeed: 0.2080s/iter; left time: 7735.3458s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0831135\n",
      "\tspeed: 0.2068s/iter; left time: 7673.0408s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0972236\n",
      "\tspeed: 0.2040s/iter; left time: 7546.7665s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0667614\n",
      "\tspeed: 0.2108s/iter; left time: 7777.5438s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0731204\n",
      "\tspeed: 0.2106s/iter; left time: 7750.9609s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0678291\n",
      "\tspeed: 0.2061s/iter; left time: 7561.9346s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0690682\n",
      "\tspeed: 0.2083s/iter; left time: 7624.8098s\n",
      "\titers: 4300, epoch: 12 | loss: 0.1088947\n",
      "\tspeed: 0.2121s/iter; left time: 7741.9932s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0743459\n",
      "\tspeed: 0.2052s/iter; left time: 7467.3271s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0860502\n",
      "\tspeed: 0.2021s/iter; left time: 7336.8973s\n",
      "Epoch: 12 cost time: 00h:15m:43.96s\n",
      "Epoch: 12 | Train Loss: 0.0825203 Vali Loss: 0.0916567 Test Loss: 0.1027902\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0783379\n",
      "\tspeed: 2.8986s/iter; left time: 104829.4755s\n",
      "\titers: 200, epoch: 13 | loss: 0.0738363\n",
      "\tspeed: 0.2037s/iter; left time: 7348.0087s\n",
      "\titers: 300, epoch: 13 | loss: 0.0749852\n",
      "\tspeed: 0.2038s/iter; left time: 7329.8585s\n",
      "\titers: 400, epoch: 13 | loss: 0.0879915\n",
      "\tspeed: 0.2112s/iter; left time: 7573.5920s\n",
      "\titers: 500, epoch: 13 | loss: 0.1001487\n",
      "\tspeed: 0.2057s/iter; left time: 7358.0682s\n",
      "\titers: 600, epoch: 13 | loss: 0.0878043\n",
      "\tspeed: 0.2106s/iter; left time: 7509.5530s\n",
      "\titers: 700, epoch: 13 | loss: 0.0682022\n",
      "\tspeed: 0.2020s/iter; left time: 7184.9157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0907041\n",
      "\tspeed: 0.2028s/iter; left time: 7193.5316s\n",
      "\titers: 900, epoch: 13 | loss: 0.0719263\n",
      "\tspeed: 0.2003s/iter; left time: 7084.6013s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0821333\n",
      "\tspeed: 0.2021s/iter; left time: 7127.7967s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0916378\n",
      "\tspeed: 0.2078s/iter; left time: 7307.2581s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0779572\n",
      "\tspeed: 0.2098s/iter; left time: 7355.7181s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0896925\n",
      "\tspeed: 0.2061s/iter; left time: 7205.3371s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0888662\n",
      "\tspeed: 0.2112s/iter; left time: 7362.9053s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0672289\n",
      "\tspeed: 0.2101s/iter; left time: 7303.3775s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0743646\n",
      "\tspeed: 0.2045s/iter; left time: 7087.5901s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0798930\n",
      "\tspeed: 0.2028s/iter; left time: 7009.7953s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0719059\n",
      "\tspeed: 0.1994s/iter; left time: 6871.7587s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0909283\n",
      "\tspeed: 0.2120s/iter; left time: 7285.5241s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0848830\n",
      "\tspeed: 0.2096s/iter; left time: 7181.8074s\n",
      "\titers: 2100, epoch: 13 | loss: 0.1008925\n",
      "\tspeed: 0.2058s/iter; left time: 7032.7138s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0732174\n",
      "\tspeed: 0.2049s/iter; left time: 6979.1657s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0867420\n",
      "\tspeed: 0.2065s/iter; left time: 7012.5722s\n",
      "\titers: 2400, epoch: 13 | loss: 0.1244981\n",
      "\tspeed: 0.2054s/iter; left time: 6954.5250s\n",
      "\titers: 2500, epoch: 13 | loss: 0.1019368\n",
      "\tspeed: 0.2097s/iter; left time: 7080.3613s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0934693\n",
      "\tspeed: 0.2051s/iter; left time: 6905.2862s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0734084\n",
      "\tspeed: 0.2082s/iter; left time: 6987.0629s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0933964\n",
      "\tspeed: 0.2053s/iter; left time: 6869.4792s\n",
      "\titers: 2900, epoch: 13 | loss: 0.0927303\n",
      "\tspeed: 0.2028s/iter; left time: 6767.3623s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0820297\n",
      "\tspeed: 0.1950s/iter; left time: 6485.3066s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0925897\n",
      "\tspeed: 0.2006s/iter; left time: 6651.4775s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0724766\n",
      "\tspeed: 0.2045s/iter; left time: 6761.9935s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0795591\n",
      "\tspeed: 0.2144s/iter; left time: 7069.2097s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0698357\n",
      "\tspeed: 0.2094s/iter; left time: 6883.5561s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0791542\n",
      "\tspeed: 0.2078s/iter; left time: 6809.2753s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0944202\n",
      "\tspeed: 0.2257s/iter; left time: 7371.9854s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0822768\n",
      "\tspeed: 0.2192s/iter; left time: 7137.6408s\n",
      "\titers: 3800, epoch: 13 | loss: 0.1007117\n",
      "\tspeed: 0.2084s/iter; left time: 6766.2169s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Capture and log output in real-time\u001b[39;00m\n\u001b[1;32m     56\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 57\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1474  0.0920\n",
       "        96        0.0395  0.1989  0.1324\n",
       "        168       0.0395  0.1988  0.1348\n",
       "GB      24        0.0252  0.1588  0.1012\n",
       "        96        0.0437  0.2091  0.1434\n",
       "        168       0.0469  0.2166  0.1487\n",
       "ES      24        0.0108  0.1039  0.0672\n",
       "        96        0.0198  0.1409  0.0941\n",
       "        168       0.0217  0.1472  0.0970\n",
       "FR      24        0.0104  0.1017  0.0586\n",
       "        96        0.0186  0.1365  0.0824\n",
       "        168       0.0205  0.1430  0.0878\n",
       "IT      24        0.0104  0.1022  0.0607\n",
       "        96        0.0188  0.1370  0.0839\n",
       "        168       0.0204  0.1428  0.0892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(timellm_results, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/96'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_96.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
